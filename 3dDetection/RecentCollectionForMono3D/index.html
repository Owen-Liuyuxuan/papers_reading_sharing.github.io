<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../../img/favicon.ico">
        <title>Recent Collections for Mono 3D detection - Reading Collections</title>
        <link href="../../css/bootstrap.min.css" rel="stylesheet">
        <link href="../../css/font-awesome.min.css" rel="stylesheet">
        <link href="../../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">

        <script src="../../js/jquery-1.10.2.min.js" defer></script>
        <script src="../../js/bootstrap.min.js" defer></script>
        <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script>
      <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-158625144-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-158625144-1');
</script>
        <!-- --> 
    </head>

    <body>

        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">

                <!-- Collapsed navigation -->
                <div class="navbar-header">
                    <!-- Expander button -->
                    <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                        <span class="navbar-toggler-icon"></span>
                    </button>
                    <a class="navbar-brand" href="../..">Reading Collections</a>
                </div>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Others <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-item">
          2D Object Detection
      </a>
      <ul class="dropdown-menu">
              
    <li>
        <a href="../../other_categories/object_detection_2D/AP_loss/" class="dropdown-item">
            AP-Loss for Accurate One-Stage Object Detection
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/Associative_Embedding%3AEnd-to-End_Learning_for_Joint_Detection_and_Grouping/" class="dropdown-item">
            Associative Embedding
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/BoFDetection/" class="dropdown-item">
            BoF for object detection (tricks)
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/CPN/" class="dropdown-item">
            Cornet Proposal Network
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/CenterNet%3A_Keypoint_Triplets_for_Object_Detection/" class="dropdown-item">
            CenterNet
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/CornerNet-Lite_Efficient_Keypoint_Based_Object_Detection/" class="dropdown-item">
            CornetNet-Lite
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/CornerNet_Detecting_Objects_as_Paired_Keypoints/" class="dropdown-item">
            CornetNet
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/DIoULoss/" class="dropdown-item">
            Distance-IoU Loss
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/DRN_and_SKU110K-R/" class="dropdown-item">
            Dynamic Refinement Network
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/DynamicRCNN/" class="dropdown-item">
            Dynamic RCNN
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/EfficientDet/" class="dropdown-item">
            EfficientDet
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/FCOS/" class="dropdown-item">
            FCOS, anchorless one-stage object detection
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/GFocalLoss/" class="dropdown-item">
            Generalized Focal Loss
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/Gaussian_YOLOv3%3A_An_Accurate_and_Fast_Object_Detector_Using_Localization_Uncertainty_for_Autonomous_Driving/" class="dropdown-item">
            Gaussian YOLOv3
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/IoU-uniform_R-CNN/" class="dropdown-item">
            IoU-uniform R-CNN
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/IoUNet%28s%29/" class="dropdown-item">
            IoU Net(s) - A summary
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/MMDetection/" class="dropdown-item">
            Some Collections around MMDetection
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/NGA/" class="dropdown-item">
            Exploiting Event Cameras by Using a Network Grafting Algorithm
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/Object_as_points/" class="dropdown-item">
            Detection and Tracking as Point
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/PAA/" class="dropdown-item">
            Probabilistic Anchor Assignment with IoU Prediction for Object Detection
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/RVT/" class="dropdown-item">
            Recurrent Vision Transformers for Object Detection with Event Cameras
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/Reppoints/" class="dropdown-item">
            The RepPoints Series
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/SSD/" class="dropdown-item">
            SSD
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/ThunderNet%3A_Towards_Real-time_Generic_Object_Detection_on_Mobile_Devices/" class="dropdown-item">
            ThunderNet
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/YOLOv4/" class="dropdown-item">
            YOLOv4
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/aLRPLoss/" class="dropdown-item">
            A Ranking-based, Balanced Loss Function Unifying Classification and Localisation in Object Detection
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/anchordetr/" class="dropdown-item">
            Anchor DETR
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/balanced_oriented_focal_loss/" class="dropdown-item">
            Balance-Oriented Focal Loss with Linear Scheduling for Anchor Free Object Detection
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/deformable_detr/" class="dropdown-item">
            Deformable DETR
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/detr/" class="dropdown-item">
            DE⫶TR
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/implicit_FPN/" class="dropdown-item">
            Implicit Feature Pyramid Network for Object Detection
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/onenet/" class="dropdown-item">
            OneNet: Towards End-to-End One-Stage Object Detection
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/pix2seq/" class="dropdown-item">
            PIX2SEQ: A Language Modeling Framework for Object Detection
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/polarnet/" class="dropdown-item">
            PolarNet
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/slender_object_detection/" class="dropdown-item">
            Slender Object Detection: Diagnoses and Improvements
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/toward_open_world_detection/" class="dropdown-item">
            Towards Open World Object Detection
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/uncertainty_detector/" class="dropdown-item">
            Estimating and Evaluating Regression Predictive Uncertainty in Deep Object Detectors
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/yolof/" class="dropdown-item">
            You Only Look One-level Feature
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/object_detection_2D/yolox/" class="dropdown-item">
            YOLOX: Exceeding YOLO Series in 2021
        </a>
    </li>
          
      </ul>
    </li>
                                    
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-item">
          Deep Navigation
      </a>
      <ul class="dropdown-menu">
              
    <li>
        <a href="../../other_categories/Deep-Navigation/ChauffeurNet%3A%20Learning%20to%20Drive%20by%20Imitating%20the%20Best%20and%20Synthesizing%20the%20Worst/" class="dropdown-item">
            ChauffeurNet
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Deep-Navigation/DriftingCaiRal/" class="dropdown-item">
            Drifting with RL (Cai, Mei)
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Deep-Navigation/DroNet%20Learning%20to%20Fly%20by%20Driving/" class="dropdown-item">
            DroNet
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Deep-Navigation/End-to-end%20Driving%20Deploying%20through%20Uncertainty-Aware%20ImitationLearning%20and%20Stochastic%20Visual%20Domain%20Adaptation/" class="dropdown-item">
            Domain Transfer Imitation - Tai Lei
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Deep-Navigation/Gaze%20%20Training%20%20by%20%20Modulated%20%20Dropout%20%20Improves%20%20Imitation%20%20Learning/" class="dropdown-item">
            Gaze Training - Chen Yuying
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Deep-Navigation/ModEL/" class="dropdown-item">
            ModEL: A Modularized End-to-end Reinforcement Learning Framework for Autonomous Driving
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Deep-Navigation/Robustness_to_Out-of-Distribution_Inputs_via_Task-Aware_Generative_Uncertainty/" class="dropdown-item">
            Task-Aware Generative Uncertainty
        </a>
    </li>
          
      </ul>
    </li>
                                    
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-item">
          Segmentation
      </a>
      <ul class="dropdown-menu">
              
    <li>
        <a href="../../other_categories/Segmentation/Actor-Critic%20Instance%20Segmentation/" class="dropdown-item">
            Actor-Critic Instance Segmentation
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Segmentation/BEV_segmentation/" class="dropdown-item">
            Summary of Multiple Papers on BEV Fusion
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Segmentation/CONVOLUTIONAL%20CRFS%20%20FOR%20SEMANTIC%20SEGMENTATION/" class="dropdown-item">
            Convolutional CRF
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Segmentation/Deep%20Multi-Sensor%20Lane%20Detection/" class="dropdown-item">
            Deep Multi-Sensor Lane Detection
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Segmentation/DeepSnake/" class="dropdown-item">
            Deep Snake
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Segmentation/FCN_panoptic_seg/" class="dropdown-item">
            Fully Convolutional Networks for Panoptic Segmentation (Panoptic FCN)
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Segmentation/LRNNET/" class="dropdown-item">
            LRNNet
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Segmentation/Lane%20Detection%20and%20Classification%20usingCascaded%20CNNs/" class="dropdown-item">
            Cascade Lane Detection
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Segmentation/PointRend/" class="dropdown-item">
            PointRend
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Segmentation/PolorMask/" class="dropdown-item">
            PolarMask
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Segmentation/RDSNet/" class="dropdown-item">
            RDSNet
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Segmentation/SAUNet/" class="dropdown-item">
            SAUNet
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Segmentation/SOLO/" class="dropdown-item">
            SOLO for instance Seg
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Segmentation/TPV/" class="dropdown-item">
            Tri-Perspective View for Vision-Based 3D Semantic Occupancy Prediction
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Segmentation/TensorMask%3A_A_Foundation_for_Dense_Object_Segmentation/" class="dropdown-item">
            TensorMask-Instance Seg
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Segmentation/Ultra_Fast_Structure-aware_Deep_Lane_Detection/" class="dropdown-item">
            Ultra Fast Structure-aware Deep Lane Detection
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Segmentation/YOLACT/" class="dropdown-item">
            YOLOACT
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Segmentation/blenderMask/" class="dropdown-item">
            BlendMask
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Segmentation/condInst/" class="dropdown-item">
            Conditional Convolutions for Instance Segmentation
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Segmentation/focus_on_local/" class="dropdown-item">
            Focus on Local: Detecting Lane Marker from Bottom Up via Key Point
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Segmentation/freeSOLO/" class="dropdown-item">
            FreeSOLO
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Segmentation/hdmapnet/" class="dropdown-item">
            HDMapNet: An Online HD Map Construction and Evaluation Framework
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Segmentation/lift_splat_shoot/" class="dropdown-item">
            Lift, Splat, Shoot: Encoding Images From Arbitrary Camera Rigs by Implicitly Unprojecting to 3D
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Segmentation/mmsegmentation/" class="dropdown-item">
            MMSegmentation
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Segmentation/nvidia-multi-scale-seg/" class="dropdown-item">
            Hierarchical Multi-scale Attention for Semantic Segmentation
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Segmentation/openOccupancy/" class="dropdown-item">
            OpenOccupancy: A Large Scale Benchmark for Surrounding Semantic Occupancy Perception
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Segmentation/panopticBEV/" class="dropdown-item">
            PanopticBEV
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Segmentation/pyorcc/" class="dropdown-item">
            PyrOccNet for BEV Segmentation
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Segmentation/skyeye/" class="dropdown-item">
            SkyEye: Self-Supervised Bird’s-Eye-View Semantic Mapping Using Monocular Frontal View Images
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Segmentation/uniocc/" class="dropdown-item">
            UniOcc: Unifying Vision-Centric 3D Occupancy Prediction with Geometric and Semantic Rendering
        </a>
    </li>
          
      </ul>
    </li>
                                    
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-item">
          SLAM
      </a>
      <ul class="dropdown-menu">
              
    <li>
        <a href="../../other_categories/SLAM/%20interval_based_Visual-LiDAR_Sensor-Fusion/" class="dropdown-item">
            Interval-Based Visual-LiDAR Sensor Fusion
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/SLAM/BAD-SLAM/" class="dropdown-item">
            BAD SLAM: Bundle Adjusted Direct RGB-D SLAM
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/SLAM/CubeSLAM/" class="dropdown-item">
            CubeSLAM
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/SLAM/DISK/" class="dropdown-item">
            DISK: Learning local features with policy gradient
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/SLAM/DeepICP%3A_An_End-to-End_Deep_Neural_Network_for_3D_Point_Cloud_Registration/" class="dropdown-item">
            DeepICP
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/SLAM/Joint_Unsupervised_Learning_of_Optical_Flow_and_Depth_by_Watching_Stereo_Videos/" class="dropdown-item">
            UnDepthFlow
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/SLAM/LO-Net%3A%20Deep%20Real-time%20Lidar%20Odometry/" class="dropdown-item">
            LO-Net
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/SLAM/PWC-Net_CNNs_for_Optical_Flow_Using_Pyramid_Warping_and_Cost_Volume/" class="dropdown-item">
            PWC-Net
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/SLAM/SuperPoint%3ASelf-Supervised_Interest_Point_Detection_and_Description/" class="dropdown-item">
            SuperPoint
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/SLAM/Unsupervised_Learning_of_Depth_and_Ego-Motion_from_Video/" class="dropdown-item">
            Unsupervised Learning of Depth and Ego-Motion from Video
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/SLAM/VOLDOR/" class="dropdown-item">
            VOLDOR: Visual Odometry from Log-logistic Dense Optical flow Residuals
        </a>
    </li>
          
      </ul>
    </li>
                                    
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-item">
          Summaries
      </a>
      <ul class="dropdown-menu">
              
    <li>
        <a href="../../other_categories/Summaries/Collections_StereoMatching_KITTI/" class="dropdown-item">
            Collections of Stereo Matching from KITTI
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Summaries/MachineLearningForRobotPlanningAndContrlGeorgiaTech/" class="dropdown-item">
            Robotics_DL Lecture from georgia Tech
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Summaries/SelfAttentionandCNN/" class="dropdown-item">
            Self-Attention & CNN
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Summaries/SummaryOfMono3DDetection_in2019/" class="dropdown-item">
            Summary of Mono 3D Detection in 2019
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Summaries/SummaryOfSingleStageInstanceSeg/" class="dropdown-item">
            Summary of Single Stage Instance Segmentation
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Summaries/SummaryOfTemperalBEV/" class="dropdown-item">
            Summary of Temperal BEV
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Summaries/Summary_CVPR_2021/" class="dropdown-item">
            CVPR 2021 clips
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Summaries/Summary_ICCV_2021/" class="dropdown-item">
            ICCV 2021 clips
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Summaries/Summary_ICLR_2021/" class="dropdown-item">
            ICLR 2021 clips
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Summaries/Summary_ICML_2021/" class="dropdown-item">
            ICML 2021 clips
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Summaries/Summary_MapExtraction/" class="dropdown-item">
            Summary of Several Map Extraction Papers
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Summaries/Summary_NIPS_2020_app/" class="dropdown-item">
            Summary of NIPS 2020 for application
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Summaries/Summary_NIPS_2021/" class="dropdown-item">
            NeurIPS 2021 clips
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Summaries/Summary_of_ICRA_2020/" class="dropdown-item">
            ICRA 2020 clips
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Summaries/Summary_of_SegLoss/" class="dropdown-item">
            Segmentation Loss Odyssey
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Summaries/Summary_of_serveral_cvpr2020/" class="dropdown-item">
            CVPR 2020 clips
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Summaries/Summary_of_serveral_eccv2020/" class="dropdown-item">
            ECCV 2020 clips
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/Summaries/Summary_of_several_iccv2019/" class="dropdown-item">
            ICCV 2019 Clips
        </a>
    </li>
          
      </ul>
    </li>
                                    
                                    
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-item">
          Daily
      </a>
      <ul class="dropdown-menu">
              
    <li>
        <a href="../../other_categories/daily/arxiv_cv_report_2025-08-27/" class="dropdown-item">
            Arxiv Computer Vision Papers - 2025-08-27
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/daily/arxiv_cv_report_2025-08-28/" class="dropdown-item">
            Arxiv Computer Vision Papers - 2025-08-28
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/daily/arxiv_cv_report_2025-08-29/" class="dropdown-item">
            Arxiv Computer Vision Papers - 2025-08-29
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/daily/arxiv_cv_report_2025-09-01/" class="dropdown-item">
            Arxiv Computer Vision Papers - 2025-09-01
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/daily/arxiv_cv_report_2025-09-02/" class="dropdown-item">
            Arxiv Computer Vision Papers - 2025-09-02
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/daily/arxiv_cv_report_2025-09-03/" class="dropdown-item">
            Arxiv Computer Vision Papers - 2025-09-03
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/daily/arxiv_cv_report_2025-09-04/" class="dropdown-item">
            Arxiv Computer Vision Papers - 2025-09-04
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/daily/arxiv_cv_report_2025-09-05/" class="dropdown-item">
            Arxiv Computer Vision Papers - 2025-09-05
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/daily/arxiv_cv_report_2025-09-07/" class="dropdown-item">
            Arxiv Computer Vision Papers - 2025-09-07
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/daily/arxiv_cv_report_2025-09-08/" class="dropdown-item">
            Arxiv Computer Vision Papers - 2025-09-08
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/daily/arxiv_cv_report_2025-09-09/" class="dropdown-item">
            Arxiv Computer Vision Papers - 2025-09-09
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/daily/arxiv_cv_report_2025-09-10/" class="dropdown-item">
            Arxiv Computer Vision Papers - 2025-09-10
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/daily/arxiv_cv_report_2025-09-11/" class="dropdown-item">
            Arxiv Computer Vision Papers - 2025-09-11
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/daily/arxiv_cv_report_2025-09-12/" class="dropdown-item">
            Arxiv Computer Vision Papers - 2025-09-12
        </a>
    </li>
          
      </ul>
    </li>
                                    
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-item">
          Depth Completion & Depth Prediction
      </a>
      <ul class="dropdown-menu">
              
    <li>
        <a href="../../other_categories/depth_completion/DNet/" class="dropdown-item">
            DNet for Depth Prediction
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/depth_completion/DeepLineEncode/" class="dropdown-item">
            Deep Line Encoding for Monocular 3D Object Detection and Depth Prediction
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/depth_completion/Deterministic_Guided_LiDAR_Depth_Map_Completion/" class="dropdown-item">
            Deterministic Guided LiDAR Depth Map Completion
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/depth_completion/OrdinalRegression/" class="dropdown-item">
            Soft Labels for Ordinal Regression
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/depth_completion/Sparse_and_noisy_LiDAR_completion/" class="dropdown-item">
            LiDAR completion with RGB uncertainty
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/depth_completion/advancing_monodepth_splidar/" class="dropdown-item">
            Advancing Self-supervised Monocular Depth Learning with Sparse LiDAR
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/depth_completion/depth_pred_before/" class="dropdown-item">
            Depth Prediction before DL
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/depth_completion/dorn/" class="dropdown-item">
            DORN Depth Prediction
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/depth_completion/guideNet/" class="dropdown-item">
            GuideNet
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/depth_completion/image_synthesis_loss/" class="dropdown-item">
            On the Sins of Image Synthesis Loss for Self-supervised Depth Estimation
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/depth_completion/manydepth/" class="dropdown-item">
            ManyDepth
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/depth_completion/mono_uncer/" class="dropdown-item">
            MonoUncertainty
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/depth_completion/monorec/" class="dropdown-item">
            MonoRec: Semi-Supervised Dense Reconstruction in Dynamic Environments from a Single Moving Camera
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/depth_completion/movedepth/" class="dropdown-item">
            Crafting Monocular Cues and Velocity Guidance for Self-Supervised Multi-Frame Depth Learning
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/depth_completion/multi_view_depth_estimation_epipolar_spatio_temporal/" class="dropdown-item">
            Multi-view Depth Estimation using Epipolar Spatio-Temporal Networks
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/depth_completion/pRGB-D_SLAM/" class="dropdown-item">
            Pseudo RGB-D for Self-Improving Monocular SLAM and Depth Prediction
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/depth_completion/steering_kernels/" class="dropdown-item">
            Learning Steering Kernels for Guided Depth Completion
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/depth_completion/sub_depth/" class="dropdown-item">
            SUB-Depth: Self-distillation and Uncertainty Boosting Self-supervised Monocular Depth Estimation
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/depth_completion/sungoesdown/" class="dropdown-item">
            When the Sun Goes Down: Repairing Photometric Losses for All-Day Depth Estimation
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/depth_completion/variational_monodepth/" class="dropdown-item">
            Variational Monocular Depth Estimation for Reliability Prediction
        </a>
    </li>
          
      </ul>
    </li>
                                    
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-item">
          Others
      </a>
      <ul class="dropdown-menu">
              
    <li>
        <a href="../../other_categories/others/Adaptive_Unimodal_Cost_Volume_Filtering_for_Deep_Stereo_Matching/" class="dropdown-item">
            AcfNet
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/Attacking_Optical_Flow/" class="dropdown-item">
            Attacking Optical Flow
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/CAM/" class="dropdown-item">
            CAM: Class Activation Map
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/Continuous-time_Intensity_Estimation_Using_Event_Cameras/" class="dropdown-item">
            Intensity Estimation With Event Cameras
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/FADNet/" class="dropdown-item">
            FADNet
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/GPLVM/" class="dropdown-item">
            GPLVM
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/Gated2Depth%3A_Real-Time_Dense_Lidar_From_Gated_Images/" class="dropdown-item">
            Gated2Depth
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/GaussianProcessVAE/" class="dropdown-item">
            Gaussian Process and Variantional Autoencoder
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/Hyperparameter_tuning/" class="dropdown-item">
            Hyperparameter Tuning
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/In_Defense_of_Classical_Image_Processing_Fast_Depth_Completion_on_the_CPU/" class="dropdown-item">
            Depth Completion on CPU
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/Jointly_derain_dehaze/" class="dropdown-item">
            Joint Deraining and Dehazing
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/OptNet_Differentiable_Optimization_as_a_Layer_in_Neural_Networks/" class="dropdown-item">
            OptNet, Optimization as Layer
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/PHOTOREALISTIC%20IMAGE%20RECONSTRUCTION%20FROM_HYBRID_INTENSITY_AND_EVENT_BASED_SENSOR/" class="dropdown-item">
            Image Reconstruction with Event Camera
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/PSMNet/" class="dropdown-item">
            PSMNet
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/PointFlow%20%3A%203D%20Point%20Cloud%20Generation%20with%20Continuous%20Normalizing%20Flows/" class="dropdown-item">
            PointFlow
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/R2D2/" class="dropdown-item">
            R2D2
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/SPM_SPR/" class="dropdown-item">
            SPM - SPR
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/SomePapersOnDifferentiableCvxOpt/" class="dropdown-item">
            More on Differentiable Convex Optimization
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/TRPO/" class="dropdown-item">
            Trust Region Policy Optimization
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/Unsupervised_depth_prediction/" class="dropdown-item">
            Unsupervised Mono Depth from stereo
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/adversarialPatch/" class="dropdown-item">
            Adversarial Patch
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/detic/" class="dropdown-item">
            Detecting Twenty-thousand Classes using Image-level Supervision
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/flownet/" class="dropdown-item">
            FlowNet & More
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/gaussian_splatting/" class="dropdown-item">
            Gaussian Splatting
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/generate_model_score_matching/" class="dropdown-item">
            Generative Modeling by Estimating Gradients of the Data Distribution
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/meta_updater_tracking/" class="dropdown-item">
            High-Performance Long-Term Tracking with Meta-Updater
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/mixmatch/" class="dropdown-item">
            MixMatch: A Holistic Approach to Semi-Supervised Learning
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/monodepth_collections/" class="dropdown-item">
            Collections on Monodepth (unsupervised)
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/monolayout/" class="dropdown-item">
            MonoLayout
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/objectvivit/" class="dropdown-item">
            How can objects help action recognition?
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/octsqueeze/" class="dropdown-item">
            OctSqueeze: Octree-Structured Entropy Model for LiDAR Compression
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/openpose_part_afinity_fileds/" class="dropdown-item">
            OpenPose: Part Affinity Fields
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/patchmatchnet/" class="dropdown-item">
            PatchmatchNet: Learned Multi-View Patchmatch Stereo
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/pruning/" class="dropdown-item">
            Why is the State of Neural Network Pruning so Confusing? On the Fairness, Comparison Setup, and Trainability in Network Pruning
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/self_supervised_stereo/" class="dropdown-item">
            SsSMnet
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/socialgan/" class="dropdown-item">
            Social GAN: Socially Acceptable Trajectories with Generative Adversarial Networks
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/space_sweep/" class="dropdown-item">
            Plane sweeping for multi-image matching
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/surround_depth/" class="dropdown-item">
            About Surround Monodepth
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/track2detection_and_seg/" class="dropdown-item">
            TraDeS
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/vectornet/" class="dropdown-item">
            VectorNet: Encoding HD Maps and Agent Dynamics from Vectorized Representation
        </a>
    </li>
              
    <li>
        <a href="../../other_categories/others/vip_deeplab/" class="dropdown-item">
            ViP-DeepLab: Learning Visual Perception with Depth-aware Video Panoptic Segmentation
        </a>
    </li>
          
      </ul>
    </li>
                                </ul>
                            </li>
                            <!-- <li class="navitem">
                                <a href="../.." class="nav-link">论文阅读</a>
                            </li> -->
                            <li class="dropdown active">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">3dDetection <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
    <li>
        <a href="../AFDet/" class="dropdown-item">
            CenterNet for Point cloud
        </a>
    </li>
                                    
    <li>
        <a href="../AM3D/" class="dropdown-item">
            Color-Embedded 3D Reconstructio Mono3D
        </a>
    </li>
                                    
    <li>
        <a href="../CDN/" class="dropdown-item">
            Wasserstein Distances for Stereo Disparity Estimation
        </a>
    </li>
                                    
    <li>
        <a href="../CameraDistanceAware/" class="dropdown-item">
            camera distance-aware Mono 3D pose estimation
        </a>
    </li>
                                    
    <li>
        <a href="../DSGN/" class="dropdown-item">
            DSGN
        </a>
    </li>
                                    
    <li>
        <a href="../Disentangling_Monocular_3D_Object_Detection/" class="dropdown-item">
            MonoDIS
        </a>
    </li>
                                    
    <li>
        <a href="../EGFN/" class="dropdown-item">
            EGFN: Efficient Geometry Feature Network for Fast Stereo 3D Object Detection
        </a>
    </li>
                                    
    <li>
        <a href="../End-to-end%20Learning%20of%20Multi-sensor%203D%20Tracking%20by%20Detection/" class="dropdown-item">
            End-to-end Learning of Multi-sensor 3D Tracking by Detection
        </a>
    </li>
                                    
    <li>
        <a href="../FCOS3D_mono/" class="dropdown-item">
            FCOS3D: Fully Convolutional One-Stage Monocular 3D Object Detection
        </a>
    </li>
                                    
    <li>
        <a href="../Fast%20and%20Furious%20Real%20Time%20End-to-End%203D%20Detection%2C%20Tracking%20and%20MotionForecasting%20with%20a%20Single%20Convolutional%20Net/" class="dropdown-item">
            Fast and Furious
        </a>
    </li>
                                    
    <li>
        <a href="../Frustum_PointNets_for_3D_Object_Detection_from_RGB-D_Data/" class="dropdown-item">
            Frustum PointNets
        </a>
    </li>
                                    
    <li>
        <a href="../Generalize3DDet/" class="dropdown-item">
            Generalization for 3D Detection
        </a>
    </li>
                                    
    <li>
        <a href="../GeneralizedIoU/" class="dropdown-item">
            Genearlized IoU 2D and 3D
        </a>
    </li>
                                    
    <li>
        <a href="../GroundAwareConvultion/" class="dropdown-item">
            Ground-aware Monocular 3D Object Detection for Autonomous Driving
        </a>
    </li>
                                    
    <li>
        <a href="../H23D_RCNN/" class="dropdown-item">
            From Multi-View to Hollow-3D: Hallucinated Hollow-3D R-CNN for 3D Object Detection: (H23D-RCNN)
        </a>
    </li>
                                    
    <li>
        <a href="../Improving%203D%20Object%20Detection%20for%20Pedestrians%20with%20Virtual%20Multi-View%20Synthesis%20Orientation%20Estimation/" class="dropdown-item">
            Multi-View Synthesis for Orientation Estimation
        </a>
    </li>
                                    
    <li>
        <a href="../IoU%20Loss%20for%202D/" class="dropdown-item">
            IoU Loss for 2D/3D Object Detection
        </a>
    </li>
                                    
    <li>
        <a href="../Kinematic_video3d/" class="dropdown-item">
            Kinematic 3D Object Detection in Monocular Video
        </a>
    </li>
                                    
    <li>
        <a href="../LaserNet/" class="dropdown-item">
            LaserNet
        </a>
    </li>
                                    
    <li>
        <a href="../M3D-RPN_Monocular_3D_Region_Proposal_Network_for_Object_Detection/" class="dropdown-item">
            M3D-RPN
        </a>
    </li>
                                    
    <li>
        <a href="../Metric_3d/" class="dropdown-item">
            3D detection evaluation metric
        </a>
    </li>
                                    
    <li>
        <a href="../Mono3D_virtualcam/" class="dropdown-item">
            Mono3d with virtual cameras
        </a>
    </li>
                                    
    <li>
        <a href="../MonoGRNet%3A%20A%20Geometric%20Reasoning%20Network%20for%20Monocular%203D%20Object%20Localization/" class="dropdown-item">
            MonoGRNet
        </a>
    </li>
                                    
    <li>
        <a href="../Monocular_3D_Object_Detection_and_Box_Fitting_Trained_End-to-End_Using_Intersection-over-Union_Loss/" class="dropdown-item">
            Single Shot Mono 3D(SS3D)
        </a>
    </li>
                                    
    <li>
        <a href="../Multi-View_3D_Detection_Network_for_autonomous_Driving/" class="dropdown-item">
            MV3D
        </a>
    </li>
                                    
    <li>
        <a href="../Orthographic_Feature_Transform_3D_detection/" class="dropdown-item">
            OftNet
        </a>
    </li>
                                    
    <li>
        <a href="../Pseudo-Lidar/" class="dropdown-item">
            Pseudo-Lidar with Instance Segmentation
        </a>
    </li>
                                    
    <li>
        <a href="./" class="dropdown-item active">
            Recent Collections for Mono3D
        </a>
    </li>
                                    
    <li>
        <a href="../RecentCollectionForStereo3D/" class="dropdown-item">
            Recent Collections for Stereo 3D
        </a>
    </li>
                                    
    <li>
        <a href="../RefinedMPL/" class="dropdown-item">
            RefinedMPL
        </a>
    </li>
                                    
    <li>
        <a href="../SHIFT%20R-CNN%3A%20DEEP%20MONOCULAR%203D%20OBJECT%20DETECTION%20WITH%20CLOSED-FORM%20GEOMETRIC%20CONSTRAINTS/" class="dropdown-item">
            Shift RCNN
        </a>
    </li>
                                    
    <li>
        <a href="../SSL_RTM3D/" class="dropdown-item">
            SSL-RTM3D
        </a>
    </li>
                                    
    <li>
        <a href="../SingleStage3DPoseEstimation/" class="dropdown-item">
            single-stage 3D Pose Estimation
        </a>
    </li>
                                    
    <li>
        <a href="../Triangulation%20Learning%20Network%3A%20from%20Monocular%20to%20Stereo%203D%20Object%20Detection/" class="dropdown-item">
            TLNet
        </a>
    </li>
                                    
    <li>
        <a href="../VoteNetImVote/" class="dropdown-item">
            VoteNet & ImVoteNet
        </a>
    </li>
                                    
    <li>
        <a href="../YOLOStereo3D/" class="dropdown-item">
            YOLOStereo3D: A Step Back to 2D for Efficient Stereo 3D Detection
        </a>
    </li>
                                    
    <li>
        <a href="../caddn/" class="dropdown-item">
            CaDDN
        </a>
    </li>
                                    
    <li>
        <a href="../digmono3d/" class="dropdown-item">
            Digging Into Output Representation For Monocular 3D Object Detection
        </a>
    </li>
                                    
    <li>
        <a href="../is_plidar_needed/" class="dropdown-item">
            Is Pseudo-Lidar needed for Monocular 3D Object detection? (DD3D)
        </a>
    </li>
                                    
    <li>
        <a href="../mono_differentiable_rendering/" class="dropdown-item">
            Monocular Differentiable Rendering for Self-Supervised 3D Object Detection
        </a>
    </li>
                                    
    <li>
        <a href="../monorun/" class="dropdown-item">
            MonoRUn: Monocular 3D Object Detection by Reconstruction and Uncertainty Propagation
        </a>
    </li>
                                    
    <li>
        <a href="../multisensor_refinement/" class="dropdown-item">
            Multi-Sensor Refinement - Li Peiliang
        </a>
    </li>
                                    
    <li>
        <a href="../my_cookbook/" class="dropdown-item">
            Synthetic Cookbook for Using/Testing/Demonstrating VisualDet3D in ROS
        </a>
    </li>
                                    
    <li>
        <a href="../pointnet_related/" class="dropdown-item">
            Collections on PointNet and follow-ups
        </a>
    </li>
                                    
    <li>
        <a href="../pvnet/" class="dropdown-item">
            PVNet
        </a>
    </li>
                                    
    <li>
        <a href="../pyramid-rcnn/" class="dropdown-item">
            Pyramid R-CNN: Towards Better Performance and Adaptability for 3D Object Detection
        </a>
    </li>
                                    
    <li>
        <a href="../renderocc/" class="dropdown-item">
            RenderOcc
        </a>
    </li>
                                    
    <li>
        <a href="../siaNMS/" class="dropdown-item">
            siaNMS
        </a>
    </li>
                                    
    <li>
        <a href="../voxelNet/" class="dropdown-item">
            VoxelNet
        </a>
    </li>
                                    
    <li>
        <a href="../weakly_super/" class="dropdown-item">
            Weakly Supervised 3D Object Detection from Point Clouds
        </a>
    </li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Building Blocks <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
    <li>
        <a href="../../Building_Blocks/4D%20Spatio-Temporal%20ConvNets%3A%20Minkowski%20Convolutional%20Neural%20Networks/" class="dropdown-item">
            Minkowski Convolutional Neural Networks
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/ASL_loss/" class="dropdown-item">
            Asymmetric Loss For Multi-Label Classification (ASL Loss)
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/AUGMIX/" class="dropdown-item">
            AugMix
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/AdaIN/" class="dropdown-item">
            AdaIn Style Transfer
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/Attention_Augmented_Conv/" class="dropdown-item">
            Attention Augmented Convolution
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/Attention_is_all_you_need/" class="dropdown-item">
            Self-Attention Mechanism
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/Bpnp/" class="dropdown-item">
            backprob through PnP Optimization
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/CBAM%3AConvolutional_Block_Attention_Module/" class="dropdown-item">
            CBAM: Convolutional Block Attention Module
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/Can%20GCNs%20Go%20as%20Deep%20as%20CNNs/" class="dropdown-item">
            Deep GCN
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/Container_context_aggregation_network/" class="dropdown-item">
            Container: Context Aggregation Network
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/DGCNN/" class="dropdown-item">
            DGCNN and edgeConv
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/DO-Conv/" class="dropdown-item">
            DO-Conv
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/DiCENet/" class="dropdown-item">
            DiCENet
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/Discovery_of_Latent_3D_Keypoints_via_End-to-end_Geometric_Reasoning/" class="dropdown-item">
            keypointNet
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/DynamicFilteringNetwork_Fewshot/" class="dropdown-item">
            Dynamic Conditional Networks for Few-Shot Learning
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/DynanicFilteringNetwork/" class="dropdown-item">
            Dynamic Filtering Network
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/ELASTIC/" class="dropdown-item">
            Elastic: Dynamic Scaling CNNs
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/EfficientNet%3A_Rethinking_Model_Scaling_for_Convolutional_Neural_Network/" class="dropdown-item">
            EfficientNet
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/GhostNet/" class="dropdown-item">
            Ghost Net
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/GumbelSoftmax/" class="dropdown-item">
            Gumbel_softmax; Differentiable Indexing
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/HRNet/" class="dropdown-item">
            HRNet
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/Lookahead%20Optimizer%20ksteps%20forward%2C%201%20step%20back/" class="dropdown-item">
            New Optimizers
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/MDEQ/" class="dropdown-item">
            MDEQ
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/MLP_image_classification/" class="dropdown-item">
            MLP in Image Classification
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/NRI/" class="dropdown-item">
            Neural Relational Inference Model (NRI)
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/Non-local_Neural_Networks/" class="dropdown-item">
            Non-local Neural Networks
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/On_Multiplicative_Integration_with_Recurrent_Neural_Networks/" class="dropdown-item">
            On Multiplicative Integration with Recurrent Neural Networks
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/PointAtrousNet/" class="dropdown-item">
            PointAtrousNet
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/PositionalNorm/" class="dropdown-item">
            Positional Normalization
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/RepVGG/" class="dropdown-item">
            RepVGG
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/SPN_CSPN/" class="dropdown-item">
            SPN, CSPN and CSPN ++
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/SQUEEZENET_ALEXNET-LEVEL_ACCURACY_WITH_50X_FEWER_PARAMETERS_AND_0.5MB_MODEL_SIZE/" class="dropdown-item">
            SqueezeNet
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/Songtao_Liu_Receptive_Field_Block_ECCV_2018_paper/" class="dropdown-item">
            Receptive Field Block
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/Squeeze-and-Excitation_Networks/" class="dropdown-item">
            Squeeze-and-Excitation Networks
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/Stacked_Hourglass_Networks_for_Human_Pose_Estimation/" class="dropdown-item">
            Stacked Hourglass Networks
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/convNext/" class="dropdown-item">
            A ConvNet for the 2020s (ConvNeXt)
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/crossBatchNormalization/" class="dropdown-item">
            Cross-iteration BatchNormalization
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/deepPruner/" class="dropdown-item">
            Deep Pruner & Differentiable Patch Match
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/deformable_convnet_v2/" class="dropdown-item">
            Deformable ConvNet V2
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/fcanet/" class="dropdown-item">
            FcaNet: Frequency Channel Attention Networks
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/gabor_layer/" class="dropdown-item">
            Gabor Layers
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/involution/" class="dropdown-item">
            Involution: Inverting the Inherence of Convolution for Visual Recognition
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/mpvit/" class="dropdown-item">
            MonoViT
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/mutualNet/" class="dropdown-item">
            MutualNet
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/omnivore/" class="dropdown-item">
            OMNIVORE: A Single Model for Many Visual Modalities
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/pyramid_vit/" class="dropdown-item">
            Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/replknet/" class="dropdown-item">
            RepLKNet
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/shape_adaptor/" class="dropdown-item">
            Shape Adaptor
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/swinV2/" class="dropdown-item">
            Swin Transformer V2: Scaling Up Capacity and Resolution
        </a>
    </li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Planning Control DL <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
    <li>
        <a href="../../Planning_Control_DL/Aggressive_Driving_with_Model_Predictive_Path_Integral_Control/" class="dropdown-item">
            Model Predicvtive Path Integral Control
        </a>
    </li>
                                    
    <li>
        <a href="../../Planning_Control_DL/Backprop%20KF%20Learning%20Discriminative%20DeterministicState%20Estimators/" class="dropdown-item">
            BackProp Kalman Filter
        </a>
    </li>
                                    
    <li>
        <a href="../../Planning_Control_DL/Cognitive%20Mapping%20and%20Planning%20for%20Visual%20Navigation/" class="dropdown-item">
            Cognitive Mapping and Planning
        </a>
    </li>
                                    
    <li>
        <a href="../../Planning_Control_DL/Composable_Action-Conditioned_Predictors_Flexible_Off-Policy_Learning_for_Robot_Navigation/" class="dropdown-item">
            Composable Action-Conditioned Predictors
        </a>
    </li>
                                    
    <li>
        <a href="../../Planning_Control_DL/DESPOT-%CE%B1%3A%20Online%20POMDP%20Planning%20With%20Large%20State%20And%20Observation%20Spaces/" class="dropdown-item">
            DESPOT-α
        </a>
    </li>
                                    
    <li>
        <a href="../../Planning_Control_DL/Differentiable%20Algorithm%20Networks%20forComposable%20Robot%20Learning/" class="dropdown-item">
            DAN for Composable Robot Learning
        </a>
    </li>
                                    
    <li>
        <a href="../../Planning_Control_DL/Differentiable%20MPC%20for%20End-to-end%20Planning%20and%20Control/" class="dropdown-item">
            Differentiable MPC
        </a>
    </li>
                                    
    <li>
        <a href="../../Planning_Control_DL/Diffusion_planner/" class="dropdown-item">
            Diffusion Planner
        </a>
    </li>
                                    
    <li>
        <a href="../../Planning_Control_DL/EUDM/" class="dropdown-item">
            EUDM Planning
        </a>
    </li>
                                    
    <li>
        <a href="../../Planning_Control_DL/Hierarchical_Imitation_and_Reinforcement_Learning/" class="dropdown-item">
            Hierarchical Imitation and Reinforcement Learning
        </a>
    </li>
                                    
    <li>
        <a href="../../Planning_Control_DL/Intention-Net%20Integrating%20Planning%20and%20DeepLearning%20for%20Goal-Directed%20Autonomous%20Navigation/" class="dropdown-item">
            Intention-Net
        </a>
    </li>
                                    
    <li>
        <a href="../../Planning_Control_DL/Learning-based_MPC/" class="dropdown-item">
            LMPC_GP
        </a>
    </li>
                                    
    <li>
        <a href="../../Planning_Control_DL/PMPNet/" class="dropdown-item">
            PMPNet
        </a>
    </li>
                                    
    <li>
        <a href="../../Planning_Control_DL/Path%20Integral%20Networks_End-to-End%20Differentiable%20Optimal%20Control/" class="dropdown-item">
            Path Integral Networks
        </a>
    </li>
                                    
    <li>
        <a href="../../Planning_Control_DL/QMDP-Net_%20Deep%20Learning%20for%20Planning%20underPartial%20Observability/" class="dropdown-item">
            QMDP-Net
        </a>
    </li>
                                    
    <li>
        <a href="../../Planning_Control_DL/SUNRISE_for_Ensemble_RL/" class="dropdown-item">
            SUNRISE
        </a>
    </li>
                                    
    <li>
        <a href="../../Planning_Control_DL/Universal%20Planning%20Networks/" class="dropdown-item">
            Universal Planning Networks
        </a>
    </li>
                                    
    <li>
        <a href="../../Planning_Control_DL/diff_MPC_ARE/" class="dropdown-item">
            differentiable pre-stablized MPC
        </a>
    </li>
                                    
    <li>
        <a href="../../Planning_Control_DL/end2end_challenge/" class="dropdown-item">
            End-to-end Autonomous Driving: Challenges and Frontiers
        </a>
    </li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Theorotical DL <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
    <li>
        <a href="../../The_theory/CMA_ES/" class="dropdown-item">
            Covariance matrix adaptation evolution strategy: CMA-ES
        </a>
    </li>
                                    
    <li>
        <a href="../../The_theory/CNN_position_information/" class="dropdown-item">
            Position Information in CNN
        </a>
    </li>
                                    
    <li>
        <a href="../../The_theory/Channel_Pruning_for_Accelerating_Very_Deep_Neural_Networks/" class="dropdown-item">
            Channel Pruning for Accelerating Very Deep Neural Networks
        </a>
    </li>
                                    
    <li>
        <a href="../../The_theory/CheckerBoardDeconv/" class="dropdown-item">
            Deconvolution and Checkerboard Artifacts
        </a>
    </li>
                                    
    <li>
        <a href="../../The_theory/ClosingGap/" class="dropdown-item">
            Train longer, generalize better: closing the generalization gap in large batch training of neural networks
        </a>
    </li>
                                    
    <li>
        <a href="../../The_theory/Continuous_learning/" class="dropdown-item">
            Continuous Learning
        </a>
    </li>
                                    
    <li>
        <a href="../../The_theory/ConvexOptimization/" class="dropdown-item">
            Convex Optimization
        </a>
    </li>
                                    
    <li>
        <a href="../../The_theory/Designing_Network_Design_Spaces/" class="dropdown-item">
            Designing Network Design Spaces
        </a>
    </li>
                                    
    <li>
        <a href="../../The_theory/DirectLossMinimization/" class="dropdown-item">
            Direct Loss Minimization
        </a>
    </li>
                                    
    <li>
        <a href="../../The_theory/Do%20Better%20ImageNet%20Models%20Transfer%20Better/" class="dropdown-item">
            Do Better ImageNet Models Transfer Better?
        </a>
    </li>
                                    
    <li>
        <a href="../../The_theory/First_order_methods_review_and_updates/" class="dropdown-item">
            First Order Optimizers
        </a>
    </li>
                                    
    <li>
        <a href="../../The_theory/Framework_Uncertainty_Propagation/" class="dropdown-item">
            Uncertainty Propagation in Neural Network
        </a>
    </li>
                                    
    <li>
        <a href="../../The_theory/FreeAnchor_Learning_to_Match_Anchors_for_Visual_Object_Detection/" class="dropdown-item">
            FreeAnchor
        </a>
    </li>
                                    
    <li>
        <a href="../../The_theory/LQF/" class="dropdown-item">
            LQF: Linear Quadratic Fine-Tuning
        </a>
    </li>
                                    
    <li>
        <a href="../../The_theory/Localization-aware%20Channel%20Pruning%20for%20Object%20Detection/" class="dropdown-item">
            Localization-aware Channel Pruning
        </a>
    </li>
                                    
    <li>
        <a href="../../The_theory/NIPS2020_networks/" class="dropdown-item">
            NIPS 2020 for Experimental NN
        </a>
    </li>
                                    
    <li>
        <a href="../../The_theory/NTK/" class="dropdown-item">
            Neural Tangent Kernel: Convergence and Generalization in Neural Networks
        </a>
    </li>
                                    
    <li>
        <a href="../../The_theory/Rethinking%20ImageNet%20Pre-training/" class="dropdown-item">
            Rethinking ImageNet Pre-training
        </a>
    </li>
                                    
    <li>
        <a href="../../The_theory/ShuffleNet_V2%3A_Practical_Guidelines_for_Efficient_CNN_Architecture_Design/" class="dropdown-item">
            ShuffleNet V2
        </a>
    </li>
                                    
    <li>
        <a href="../../The_theory/Style_and_normalization/" class="dropdown-item">
            Style and Normalization
        </a>
    </li>
                                    
    <li>
        <a href="../../The_theory/TranslationInvarianceinCNN/" class="dropdown-item">
            Translation invariance in CNN
        </a>
    </li>
                                    
    <li>
        <a href="../../The_theory/Understanding_Deep_Learning_Requires_Rethinking_Generalization/" class="dropdown-item">
            Understanding Deep Learning Requires Rethinking Generalization
        </a>
    </li>
                                    
    <li>
        <a href="../../The_theory/VAE/" class="dropdown-item">
            Auto-Encoding Variational Bayes
        </a>
    </li>
                                    
    <li>
        <a href="../../The_theory/VovNet/" class="dropdown-item">
            VovNet
        </a>
    </li>
                                    
    <li>
        <a href="../../The_theory/Why_gradien_clip_norm/" class="dropdown-item">
            WHY GRADIENT CLIPPING ACCELERATES TRAINING: A THEORETICAL JUSTIFICATION FOR ADAPTIVITY
        </a>
    </li>
                                    
    <li>
        <a href="../../The_theory/bayesianNetwork/" class="dropdown-item">
            Bayesian Neural Network
        </a>
    </li>
                                    
    <li>
        <a href="../../The_theory/compondingTechforCNN/" class="dropdown-item">
            Assembled Techniques for CNN
        </a>
    </li>
                                    
    <li>
        <a href="../../The_theory/ddn/" class="dropdown-item">
            Deep Declarative Networks
        </a>
    </li>
                                    
    <li>
        <a href="../../The_theory/deeplearning_foundation/" class="dropdown-item">
            Deep Learning "Foundations"
        </a>
    </li>
                                    
    <li>
        <a href="../../The_theory/diffussion_model/" class="dropdown-item">
            Denoising Diffusion Probabilistic Models
        </a>
    </li>
                                    
    <li>
        <a href="../../The_theory/dino/" class="dropdown-item">
            Emerging Properties in Self-Supervised Vision Transformers
        </a>
    </li>
                                    
    <li>
        <a href="../../The_theory/lle/" class="dropdown-item">
            An Introduction to Locally Linear Embedding
        </a>
    </li>
                                    
    <li>
        <a href="../../The_theory/mean_field_theory/" class="dropdown-item">
            Mean Field Theory in Deep Learning
        </a>
    </li>
                                    
    <li>
        <a href="../../The_theory/mindthepad/" class="dropdown-item">
            Mind The Pad - CNNs Can Develop Blind Spots
        </a>
    </li>
                                    
    <li>
        <a href="../../The_theory/momentum_BN/" class="dropdown-item">
            Momentum Batch Normalization
        </a>
    </li>
                                    
    <li>
        <a href="../../The_theory/understandingKD/" class="dropdown-item">
            Towards Understanding Ensemble, Knowledge Distillation and Self-Distillation in Deep Learning
        </a>
    </li>
                                    
    <li>
        <a href="../../The_theory/visualizing_landscape/" class="dropdown-item">
            Visualizing the Loss Landscape of Neural Nets
        </a>
    </li>
                                </ul>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" href="../Pseudo-Lidar/" class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" href="../RecentCollectionForStereo3D/" class="nav-link">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            
                <div   class=row >
                            <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>
    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        
        <ul class="nav flex-column bs-sidenav">
        

        
            <li class="nav-item main"><a href="#recent-collections-for-mono-3d-detection">Recent Collections for Mono 3D detection</a></li>
                <li class="nav-item">
                    <a href="#lpcg" class="nav-link">LPCG</a>
                </li>
                <li class="nav-item">
                    <a href="#pseudo-stereo" class="nav-link">Pseudo-Stereo</a>
                </li>
                <li class="nav-item">
                    <a href="#did-m3d" class="nav-link">DiD-M3D</a>
                </li>
                <li class="nav-item">
                    <a href="#monodetr" class="nav-link">MonoDETR</a>
                </li>
                <li class="nav-item">
                    <a href="#monodtr" class="nav-link">MonoDTR</a>
                </li>
                <li class="nav-item">
                    <a href="#gupnet" class="nav-link">GUPNet</a>
                </li>
                <li class="nav-item">
                    <a href="#monoflex" class="nav-link">MonoFlex</a>
                </li>
                <li class="nav-item">
                    <a href="#monoef" class="nav-link">MonoEF</a>
                </li>
                <li class="nav-item">
                    <a href="#monorcnn" class="nav-link">MonoRCNN</a>
                </li>
                <li class="nav-item">
                    <a href="#aug3drpn" class="nav-link">Aug3DRPN</a>
                </li>
                <li class="nav-item">
                    <a href="#d4lcn" class="nav-link">D4LCN</a>
                </li>
                <li class="nav-item">
                    <a href="#m3dssd" class="nav-link">M3DSSD</a>
                </li>
                <li class="nav-item">
                    <a href="#rtm3d" class="nav-link">RTM3D</a>
                </li>
                <li class="nav-item">
                    <a href="#monopair" class="nav-link">MonoPair</a>
                </li>
                <li class="nav-item">
                    <a href="#smoke" class="nav-link">SMOKE</a>
                </li>
                <li class="nav-item">
                    <a href="#yolomono3d" class="nav-link">YOLOMono3D</a>
                </li>
        </ul>
    </div>
</div></div>
                            <div class="col-md-9" role="main"><span>
    


</span>
<h1 id="recent-collections-for-mono-3d-detection">Recent Collections for Mono 3D detection</h1>
<p>在IROS2020投稿前后积攒了一系列单目3D检测paper的阅读。这里一次过进行记录,开源在前，未开源在后.</p>
<p>这里列出目前有文章可寻的KITTI排行榜(2022.07.23)</p>
<p>Update(2020.04.02):Update scores for YOLOMono3D</p>
<p>Update(2020.07.24): Update Kinematic 3D</p>
<p>Update(2020.09.08): Update SSL-RTM3D</p>
<p>Update(2021.02.01): Update Ground Aware 3D</p>
<p>Update(2021.03.17): Update CaDDN</p>
<p>Update(2021.04.10): Update MonoFlex, MonoRun, MonoRCNN</p>
<p>Update(2021.06.26): Update MonoEF</p>
<table>
<thead>
<tr>
<th>Methods</th>
<th style="text-align: center;">Moderate</th>
<th style="text-align: center;">Easy</th>
<th style="text-align: center;">Hard</th>
<th style="text-align: center;">Time</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#lpcg">LPCG</a></td>
<td style="text-align: center;">17.80</td>
<td style="text-align: center;">25.56</td>
<td style="text-align: center;">15.38</td>
<td style="text-align: center;">0.03</td>
</tr>
<tr>
<td><a href="#pseudo-stereo">PS-fld</a></td>
<td style="text-align: center;">17.74</td>
<td style="text-align: center;">23.74</td>
<td style="text-align: center;">15.14</td>
<td style="text-align: center;">0.25</td>
</tr>
<tr>
<td><a href="../is_plidar_needed/">dd3d</a></td>
<td style="text-align: center;">16.34</td>
<td style="text-align: center;">23.22</td>
<td style="text-align: center;">14.20</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td><a href="#did-m3d">DID-M3D</a></td>
<td style="text-align: center;">16.29</td>
<td style="text-align: center;">22.50</td>
<td style="text-align: center;">13.95</td>
<td style="text-align: center;">0.02</td>
</tr>
<tr>
<td><a href="#monodetr">MonoDETR</a></td>
<td style="text-align: center;">16.26</td>
<td style="text-align: center;">24.52</td>
<td style="text-align: center;">13.93</td>
<td style="text-align: center;">0.04</td>
</tr>
<tr>
<td><a href="#monodtr">MonoDTR</a></td>
<td style="text-align: center;">15.39</td>
<td style="text-align: center;">21.99</td>
<td style="text-align: center;">12.73</td>
<td style="text-align: center;">0.04</td>
</tr>
<tr>
<td><a href="#gupnet">GUPNet</a></td>
<td style="text-align: center;">15.02</td>
<td style="text-align: center;">22.26</td>
<td style="text-align: center;">13.12</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td><a href="https://github.com/abhi1kumar/DEVIANT">DEVIANT</a></td>
<td style="text-align: center;">14.46</td>
<td style="text-align: center;">21.88</td>
<td style="text-align: center;">11.89</td>
<td style="text-align: center;">0.04</td>
</tr>
<tr>
<td><a href="../../other_categories/depth_completion/DeepLineEncode/">DLE</a></td>
<td style="text-align: center;">14.33</td>
<td style="text-align: center;">24.23</td>
<td style="text-align: center;">10.30</td>
<td style="text-align: center;">0.06</td>
</tr>
<tr>
<td><a href="../../other_categories/Summaries/Summary_ICCV_2021/">AutoShape</a></td>
<td style="text-align: center;">14.17</td>
<td style="text-align: center;">22.47</td>
<td style="text-align: center;">11.36</td>
<td style="text-align: center;">0.05</td>
</tr>
<tr>
<td><a href="#monoflex">MonoFlex</a></td>
<td style="text-align: center;">13.89</td>
<td style="text-align: center;">19.94</td>
<td style="text-align: center;">12.07</td>
<td style="text-align: center;">0.03</td>
</tr>
<tr>
<td><a href="#monoef">MonoEF</a></td>
<td style="text-align: center;">13.87</td>
<td style="text-align: center;">21.29</td>
<td style="text-align: center;">11.74</td>
<td style="text-align: center;">0.03</td>
</tr>
<tr>
<td><a href="../caddn/">CaDDN</a></td>
<td style="text-align: center;">13.41</td>
<td style="text-align: center;">19.17</td>
<td style="text-align: center;">11.46</td>
<td style="text-align: center;">0.64</td>
</tr>
<tr>
<td><a href="../GroundAwareConvultion/">GroundAware3D</a></td>
<td style="text-align: center;">13.17</td>
<td style="text-align: center;">21.60</td>
<td style="text-align: center;">9.94</td>
<td style="text-align: center;">0.05</td>
</tr>
<tr>
<td><a href="#aug3drpn">Aug3DRPN</a></td>
<td style="text-align: center;">12.99</td>
<td style="text-align: center;">17.82</td>
<td style="text-align: center;">9.78</td>
<td style="text-align: center;">0.08</td>
</tr>
<tr>
<td><a href="../Kinematic_video3d/">Kinematic3D</a></td>
<td style="text-align: center;">12.72</td>
<td style="text-align: center;">19.07</td>
<td style="text-align: center;">9.17</td>
<td style="text-align: center;">0.12</td>
</tr>
<tr>
<td><a href="#monorcnn">MonoRCNN</a></td>
<td style="text-align: center;">12.65</td>
<td style="text-align: center;">18.36</td>
<td style="text-align: center;">10.03</td>
<td style="text-align: center;">0.07</td>
</tr>
<tr>
<td><a href="../monorun/">MonoRun</a></td>
<td style="text-align: center;">12.30</td>
<td style="text-align: center;">19.65</td>
<td style="text-align: center;">10.58</td>
<td style="text-align: center;">0.07</td>
</tr>
<tr>
<td><a href="#yolomono3d">YOLOMono3D</a></td>
<td style="text-align: center;">12.06</td>
<td style="text-align: center;">18.28</td>
<td style="text-align: center;">8.42</td>
<td style="text-align: center;">0.05</td>
</tr>
<tr>
<td><a href="#d4lc">D4LCN</a></td>
<td style="text-align: center;">11.72</td>
<td style="text-align: center;">16.65</td>
<td style="text-align: center;">9.51</td>
<td style="text-align: center;">0.2</td>
</tr>
<tr>
<td><a href="#m3dssd">M3DSSD</a></td>
<td style="text-align: center;">11.46</td>
<td style="text-align: center;">17.51</td>
<td style="text-align: center;">8.98</td>
<td style="text-align: center;">*</td>
</tr>
<tr>
<td><a href="../SSL_RTM3D/">SSL-RTM3D</a></td>
<td style="text-align: center;">11.45</td>
<td style="text-align: center;">16.73</td>
<td style="text-align: center;">9.92</td>
<td style="text-align: center;">0.04</td>
</tr>
<tr>
<td><a href="../RefinedMPL/">Refined-MPL</a></td>
<td style="text-align: center;">11.14</td>
<td style="text-align: center;">18.09</td>
<td style="text-align: center;">8.94</td>
<td style="text-align: center;">0.15</td>
</tr>
<tr>
<td><a href="../AM3D/">AM3D</a></td>
<td style="text-align: center;">10.74</td>
<td style="text-align: center;">16.50</td>
<td style="text-align: center;">9.52</td>
<td style="text-align: center;">0.4</td>
</tr>
<tr>
<td><a href="#rtm3d">RTM3D</a></td>
<td style="text-align: center;">10.34</td>
<td style="text-align: center;">14.41</td>
<td style="text-align: center;">8.77</td>
<td style="text-align: center;">0.05</td>
</tr>
<tr>
<td><a href="#monopair">MonoPair</a></td>
<td style="text-align: center;">9.99</td>
<td style="text-align: center;">13.04</td>
<td style="text-align: center;">8.65</td>
<td style="text-align: center;">0.06</td>
</tr>
<tr>
<td><a href="#smoke">SMOKE</a></td>
<td style="text-align: center;">9.76</td>
<td style="text-align: center;">14.03</td>
<td style="text-align: center;">7.84</td>
<td style="text-align: center;">0.03</td>
</tr>
<tr>
<td><a href="../M3D-RPN_Monocular_3D_Region_Proposal_Network_for_Object_Detection/">M3D-RPN</a></td>
<td style="text-align: center;">9.71</td>
<td style="text-align: center;">14.76</td>
<td style="text-align: center;">7.42</td>
<td style="text-align: center;">0.16</td>
</tr>
</tbody>
</table>
<p>目录:</p>
<ul>
<li><a href="#recent-collections-for-mono-3d-detection">Recent Collections for Mono 3D detection</a></li>
<li><a href="#lpcg">LPCG</a></li>
<li><a href="#pseudo-stereo">Pseudo-Stereo</a></li>
<li><a href="#did-m3d">DiD-M3D</a></li>
<li><a href="#monodetr">MonoDETR</a></li>
<li><a href="#monodtr">MonoDTR</a></li>
<li><a href="#gupnet">GUPNet</a></li>
<li><a href="#monoflex">MonoFlex</a></li>
<li><a href="#monoef">MonoEF</a></li>
<li><a href="#monorcnn">MonoRCNN</a></li>
<li><a href="#aug3drpn">Aug3DRPN</a></li>
<li><a href="#d4lcn">D4LCN</a></li>
<li><a href="#m3dssd">M3DSSD</a></li>
<li><a href="#rtm3d">RTM3D</a></li>
<li><a href="#monopair">MonoPair</a></li>
<li><a href="#smoke">SMOKE</a></li>
<li><a href="#yolomono3d">YOLOMono3D</a></li>
</ul>
<h2 id="lpcg">LPCG</h2>
<p><a href="https://arxiv.org/pdf/2104.09035.pdf">pdf</a> <a href="https://github.com/SPengLiang/LPCG">code</a></p>
<p><img alt="image" src="../res/LPCG_arch.png" /></p>
<p>这篇paper带来了很强的实用性。利用雷达，利用自监督，利用上大量kitti raw中没有被标记的数据。</p>
<ul>
<li>Step 1， 训练一个雷达的detector, 并且准备一个基于雷达的 unsupervised detector.</li>
<li>Step 2. 训练图片的时候，利用雷达的detector以及unsupervised detector, 在没有被标记的数据上生成 pseudo label. 扩大训练数据量。得到很好的性能。</li>
</ul>
<h2 id="pseudo-stereo">Pseudo-Stereo</h2>
<p><a href="https://arxiv.org/abs/2203.02112">pdf</a> <a href="https://github.com/revisitq/Pseudo-Stereo-3D">code</a>
<img alt="image" src="../res/pseudo_stereo.png" /></p>
<p>这篇paper做了很神奇的操作，就是采用单目伪装双目，然后使用双目的detector (<a href="../RecentCollectionForStereo3D/">LIGA</a>, <a href="../YOLOStereo3D/">YOLOStereo3D</a>)出结果，得到相当不错的性能。</p>
<p>作者尝试了几种方案，</p>
<ul>
<li>图像级别的生成：单目预测一个disparity map,完全直接构建双目图像。  性能一般</li>
<li>特征级别的生成：使用上述的Disparity map直接构建一个特征图，和右图的特征图输入双目匹配部分。效果最好</li>
<li>克隆，直接复制原来的单目特征，进入双目匹配部分。效果还不错</li>
</ul>
<h2 id="did-m3d">DiD-M3D</h2>
<p><a href="https://arxiv.org/pdf/2207.08531.pdf">pdf</a> <a href="https://github.com/SPengLiang/DID-M3D">code</a></p>
<p><img alt="image" src="../res/didm3d_idea.png" /></p>
<p>这篇paper整体方案上与<a href="#gupnet">GUPNet</a>是一致的，是一个二阶段的算法。它第一个引入并强调了 visual depth / attribute depth的概念。</p>
<p>visual depth也就是物体表面的深度，可以理解为该像素实际物体点的深度，attribute depth则是该点到物体中心的深度距离。作者强调认为，我们不应该直接预测中心的深度距离，而应该把这两个深度解耦。并且这个算法现在可以对内参完全不敏感了。</p>
<ul>
<li>Visual Depth 是物体像素到相机的距离，如果我们把图片裁剪/放大，那么对应的，我们预测的深度像素应该会随着焦距改变，这部分的深度是affine-sensitive的。</li>
<li>attribute depth是物体表面到三维目标中心点的距离，这部分深度是由车子的姿态和车子的大小决定的，因而可以认为这部分深度是 affine-insensitive, 与我们放大缩小图片无关。</li>
<li>GT和<a href="../multisensor_refinement/">MultiSensor Refinement</a>那篇的做法比较接近，利用3D框内的点云点构造一个稀疏的visual depth label.然后用gt 减去它就可以得到 attribute loss. 后续做数据增强的时候 visual depth随着scale改变，但是attribute loss则不改变。</li>
<li>使用L1 Loss, 都预测Laplacian uncertainty, 融合也一样。</li>
</ul>
<h2 id="monodetr">MonoDETR</h2>
<p><a href="https://arxiv.org/pdf/2203.13310.pdf">pdf</a> <a href="https://github.com/ZrrSkywalker/MonoDETR">code</a></p>
<p>这篇paper则完全引入了DETR, 似乎是第一篇把DETR的输出头完全地引入Mono3D这个任务。
<img alt="image" src="../res/monodetr_pipeline.jpg" /></p>
<ul>
<li>特征上分开visual encoder和有独立深度信息补充的depth encoder;</li>
<li>depth predictor预测一个多分类深度估计，由object depth进行监督，2d框内的所有点深度gt为物体的深度，相交部分取深度最小值，框外分类为独立的背景类。</li>
<li>在depth cross-attention中，利用深度的预测值构建深度positional embedding；把对应坐标的深度预测分布，引入作为positional embedding.</li>
<li>DETR深度的最终输出，由<script type="math/tex">d_{geo}=f\frac{h_{3D}}{t+b}</script>，(<script type="math/tex">t,b</script>分别是上下边到3D投影中心的距离，网络也以此作为prediction attribute)
，<script type="math/tex">d_reg</script>直接预测以及<script type="math/tex">d_{map}(x_{3D}, y_{3D})</script>预测的深度图在对应点的插值组成。</li>
</ul>
<h2 id="monodtr">MonoDTR</h2>
<p><a href="https://arxiv.org/pdf/2203.10981.pdf">pdf</a> <a href="https://github.com/KuanchihHuang/MonoDTR">code</a></p>
<p><img alt="image" src="../res/monodtr_arch.png" /></p>
<p>整体来说这篇paper采用了卷积backbone加transformer head的整体方案来构造网络，输出的形态与<a href="#yolomono3d">YOLOMono3D</a>是一样的。</p>
<p>也通过DFE引入了深度监督。</p>
<p><img alt="image" src="../res/monodtr_dfe.png" /></p>
<h2 id="gupnet">GUPNet</h2>
<p><a href="https://arxiv.org/pdf/2107.13774.pdf">pdf</a> <a href="https://github.com/SuperMHP/GUPNet">code</a></p>
<p><img alt="image" src="../res/GUPNet_arch.png" /></p>
<p>这篇paper是目前少有的使用二阶段检测网络实现高性能的结果.使用centerNet完成2D检测，然后使用RoIAlign提取特征.3D的输出与<a href="#monoflex">MonoFlex</a>有点相似，输出的是带有不确定的深度，采用的是2D的简要推理加上网络的一个学习值:</p>
<p>
<script type="math/tex; mode=display">\begin{aligned}
d_{p} &=\frac{f \cdot h_{3 d}}{h_{2 d}}=\frac{f \cdot\left(\lambda_{h} \cdot X+\mu_{h}\right)}{h_{2 d}} \\
&=\frac{f \cdot \lambda_{h}}{h_{2 d}} \cdot X+\frac{f \cdot \mu_{h}}{h_{2 d}}
\end{aligned}</script>
</p>
<p>
<script type="math/tex; mode=display">\begin{array}{c}
d=L a\left(\mu_{p}, \sigma_{p}\right)+L a\left(\mu_{b}, \sigma_{b}\right) \\
\mu_{d}=\mu_{p}+\mu_{b}, \quad \sigma_{d}=\sqrt{\left(\sigma_{p}\right)^{2}+\left(\sigma_{b}\right)^{2}}
\end{array}</script>
</p>
<p>
<script type="math/tex; mode=display">\mathcal{L}_{\text {depth }}=\frac{\sqrt{2}}{\sigma_{d}}\left|\mu_{d}-d^{g t}\right|+\log \left(\sigma_{d}\right)</script>
</p>
<p>本文还提出了一个hierarchical task learning.指优先把2D检测训练好，再把WHL训练好，最后再训练depth。"训练好"的评判标准是epochs之间的mean loss相差不大。</p>
<pre class="codehilite"><code class="language-python">self.loss_graph = {'seg_loss':[],
                   'size2d_loss':[], 
                   'offset2d_loss':[],
                   'offset3d_loss':['size2d_loss','offset2d_loss'], 
                   'size3d_loss':['size2d_loss','offset2d_loss'], 
                   'heading_loss':['size2d_loss','offset2d_loss'], 
                   'depth_loss':['size2d_loss','size3d_loss','offset2d_loss']}  
def compute_weight(self,current_loss,epoch):
    T=140
    #compute initial weights
    loss_weights = {}
    eval_loss_input = torch.cat([_.unsqueeze(0) for _ in current_loss.values()]).unsqueeze(0)
    for term in self.loss_graph:
        if len(self.loss_graph[term])==0:
            loss_weights[term] = torch.tensor(1.0).to(current_loss[term].device)
        else:
            loss_weights[term] = torch.tensor(0.0).to(current_loss[term].device) 
    #update losses list
    if len(self.past_losses)==self.stat_epoch_nums:
        past_loss = torch.cat(self.past_losses)
        mean_diff = (past_loss[:-2]-past_loss[2:]).mean(0)
        if not hasattr(self, 'init_diff'):
            self.init_diff = mean_diff
        c_weights = 1-(mean_diff/self.init_diff).relu().unsqueeze(0)

        time_value = min(((epoch-5)/(T-5)),1.0)
        for current_topic in self.loss_graph:
            if len(self.loss_graph[current_topic])!=0:
                control_weight = 1.0
                for pre_topic in self.loss_graph[current_topic]:
                    control_weight *= c_weights[0][self.term2index[pre_topic]]      
                loss_weights[current_topic] = time_value**(1-control_weight)
        #pop first list
        self.past_losses.pop(0)
    self.past_losses.append(eval_loss_input)   
    return loss_weights
</code></pre>

<h2 id="monoflex">MonoFlex</h2>
<p><a href="https://arxiv.org/pdf/2104.02323.pdf">pdf</a> <a href="https://github.com/zhangyp15/MonoFlex">code</a></p>
<p><img alt="image" src="../res/monoflex_arch.png" /></p>
<p>这篇paper在计算深度的时候和MonoRCNN不谋而合，觉得尽管同时找出多个角点很有诱惑力，但是一点点的误差就会造成3D回归很大的错误，所以主要依靠计算角点在图像上的高度来推理深度。</p>
<p><img alt="image" src="../res/monoflex_depth.png" /></p>
<h2 id="monoef">MonoEF</h2>
<p><a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_Monocular_3D_Object_Detection_An_Extrinsic_Parameter_Free_Approach_CVPR_2021_paper.pdf">pdf</a> <a href="https://github.com/ZhouYunsong-SJTU/MonoEF">code</a></p>
<p><img alt="image" src="../res/monoef_example.png" /></p>
<p>这篇paper关注外参的变动以及外参变动最相机感知效果的影响。同时会主动地通过序列图片预判车辆的运动.</p>
<p><img alt="image" src="../res/monofe_system.png" /></p>
<h2 id="monorcnn">MonoRCNN</h2>
<p><a href="https://arxiv.org/pdf/2104.03775.pdf">pdf</a> <a href="https://github.com/MagicRock100/MonoRCNN">code</a></p>
<p>这篇paper与MonoFlex有相似的思路，都是用projected visual height来计算深度。这篇文章则是基于two-stage的算法。文章直接指出了keypoints的问题。</p>
<p><img alt="image" src="../res/monorcnn_arch.png" /></p>
<h2 id="aug3drpn">Aug3DRPN</h2>
<p><a href="https://arxiv.org/pdf/2107.13269.pdf">pdf</a> </p>
<p><img alt="image" src="../res/aug3drpn_arch.png" /></p>
<p><img alt="image" src="../res/aug3drpn_synthetic.png" /></p>
<p>这篇paper基于<a href="../M3D-RPN_Monocular_3D_Region_Proposal_Network_for_Object_Detection/">M3D-RPN</a>的做法</p>
<ul>
<li>额外的深度预测</li>
<li>利用深度预测，渲染虚拟相机结果,增强训练结果.</li>
</ul>
<h2 id="d4lcn">D4LCN</h2>
<p><a href="https://arxiv.org/pdf/1912.04799.pdf">pdf</a>  <a href="https://github.com/dingmyu/D4LCN">code</a></p>
<p>这篇paper完全继承了<a href="../M3D-RPN_Monocular_3D_Region_Proposal_Network_for_Object_Detection/">M3D-RPN</a>的衣钵，它不同的地方在于，摒弃了M3D-RPN处理缓慢的height-wise convolution,而是使用单目估计深度，然后使用深度作为卷积核的guide, 这个guide类似于这几篇文章的操作:<a href="../../other_categories/depth_completion/guideNet/">guidenet</a>;<a href="../../Building_Blocks/DynanicFilteringNetwork/">DFN</a></p>
<p><img alt="image" src="../res/D4LCN.png" /></p>
<h2 id="m3dssd">M3DSSD</h2>
<p><a href="https://arxiv.org/pdf/2103.13164.pdf">pdf</a> <a href="https://github.com/mumianyuxin/M3DSSD">code</a></p>
<p><img alt="image" src="../res/M3DSSD_arch.png" /></p>
<p>这篇paper采用了大backbone,用deformable convolution的方法，重点解决2D detection中感受野与anchor不匹配问题以及3D中心与2D中心不匹配的问题. Shape alignment 与 center alignment 对应基于2D与3D的两种deformable base shift的产生方式。</p>
<p>另外本文又提出了 Asymmetric Non-Local Attention Block (ANAB)模块, 用于增强感受野.</p>
<h2 id="rtm3d">RTM3D</h2>
<p><a href="https://arxiv.org/pdf/2001.03343.pdf">pdf</a> <a href="https://github.com/Banconxuan/RTM3D">code</a></p>
<p>这篇文章还没有正式开源，但是github就先开着了。这篇文章在技术上有一定的新意，它使用<a href="../../other_categories/object_detection_2D/Object_as_points/#object-as-point">CenterNet</a>的架构估计大量的keypoints以及冗余的3D信息，最后通过最优化融合。使用大量冗余信息它不是第一个,前者比如有<a href="../Monocular_3D_Object_Detection_and_Box_Fitting_Trained_End-to-End_Using_Intersection-over-Union_Loss/">SS3D</a>,但是它绕过了anchor使用CenterNet有一定的新意。
<img alt="image" src="../res/RTM3D_0.png" />
<img alt="image" src="../res/RTM3D_2.png" /></p>
<h2 id="monopair">MonoPair</h2>
<p><a href="https://arxiv.org/pdf/2003.00504.pdf">pdf</a></p>
<p>这篇文章是实验室大师兄邰磊在阿里的CVPR2020 paper。有<a href="https://sites.google.com/view/chen3dmonopair">官方网站</a></p>
<p>文章的核心创新是第一个使用场景中不同物体之间的相互约束进行优化的paper。</p>
<p><img alt="image" src="../res/MonoPair.png" /></p>
<h2 id="smoke">SMOKE</h2>
<p><a href="https://arxiv.org/pdf/2002.10111v1.pdf">pdf</a></p>
<p>这篇paper的创新点不算特别多。
1. 使用了<a href="../../other_categories/object_detection_2D/Object_as_points/#object-as-point">CenterNet</a>的架构进行中心点的估计。
2. 使用了distangling loss, 这个来自于<a href="../Disentangling_Monocular_3D_Object_Detection/">MonoDIS</a>
3. 数据增强上使用了shifting等方法，但是只是用来train keypoint热图等结构。属于specialized augmentation for specialized cost.可谓深度调参</p>
<p><img alt="image" src="../res/SMOKE.png" /></p>
<h2 id="yolomono3d">YOLOMono3D</h2>
<p>不多说了，快上车</p>
<iframe src="//player.bilibili.com/player.html?aid=91364947&cid=156014191&page=1" scrolling="no" frameborder="no" framespacing="0" allowfullscreen="true" height=270 width=480> </iframe>

</div>
                    
                </div>

            <script src="https://utteranc.es/client.js"
                repo="Owen-Liuyuxuan/papers_reading_sharing.github.io"
                issue-term="Recent Collections for Mono 3D detection comments"
                theme="github-light"
                crossorigin="anonymous"
                async>
            </script>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "../..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../../js/base.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML" defer></script>
        <script src="../../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form>
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
