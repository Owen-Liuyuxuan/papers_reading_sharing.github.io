<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../../img/favicon.ico">
        <title>LO-Net: Deep Real-time Lidar Odometry - Reading Collections</title>
        <link href="../../css/bootstrap.min.css" rel="stylesheet">
        <link href="../../css/font-awesome.min.css" rel="stylesheet">
        <link href="../../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">

        <script src="../../js/jquery-1.10.2.min.js" defer></script>
        <script src="../../js/bootstrap.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script> 
    </head>

    <body>

        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">

                <!-- Collapsed navigation -->
                <div class="navbar-header">
                    <!-- Expander button -->
                    <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                        <span class="navbar-toggler-icon"></span>
                    </button>
                    <a class="navbar-brand" href="../..">Reading Collections</a>
                </div>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <!-- <li class="navitem">
                                <a href="../.." class="nav-link">论文阅读</a>
                            </li> -->
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">3dDetection <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
    <li>
        <a href="../../3dDetection/Accurate Monocular Object Detection via Color-Embedded 3D Reconstruction for Autonomous Driving/" class="dropdown-item">
            Color-Embedded 3D Reconstructio Mono3D
        </a>
    </li>
                                    
    <li>
        <a href="../../3dDetection/Disentangling_Monocular_3D_Object_Detection/" class="dropdown-item">
            Disentangling Monocular 3D Object Detection
        </a>
    </li>
                                    
    <li>
        <a href="../../3dDetection/End-to-end Learning of Multi-sensor 3D Tracking by Detection/" class="dropdown-item">
            End-to-end Learning of Multi-sensor 3D Tracking by Detection
        </a>
    </li>
                                    
    <li>
        <a href="../../3dDetection/Frustum_PointNets_for_3D_Object_Detection_from_RGB-D_Data/" class="dropdown-item">
            Frustum PointNets
        </a>
    </li>
                                    
    <li>
        <a href="../../3dDetection/IoU Loss for 2D/" class="dropdown-item">
            IoU Loss for 2D/3D Object Detection
        </a>
    </li>
                                    
    <li>
        <a href="../../3dDetection/M3D-RPN: Monocular 3D Region Proposal Network for Object Detection/" class="dropdown-item">
            M3D-RPN
        </a>
    </li>
                                    
    <li>
        <a href="../../3dDetection/MonoGRNet: A Geometric Reasoning Network for Monocular 3D Object Localization/" class="dropdown-item">
            MonoGRNet
        </a>
    </li>
                                    
    <li>
        <a href="../../3dDetection/Multi-Sensor 3D Object Box Refinement for Autonomous Driving/" class="dropdown-item">
            Multi-Sensor Refinement - Li Peiliang
        </a>
    </li>
                                    
    <li>
        <a href="../../3dDetection/Multi-View_3D_Detection_Network_for_autonomous_Driving/" class="dropdown-item">
            MV3D
        </a>
    </li>
                                    
    <li>
        <a href="../../3dDetection/Orthographic_Feature_Transform_3D_detection/" class="dropdown-item">
            OftNet
        </a>
    </li>
                                    
    <li>
        <a href="../../3dDetection/Pseudo-Lidar/" class="dropdown-item">
            Pseudo-Lidar with Instance Segmentation
        </a>
    </li>
                                    
    <li>
        <a href="../../3dDetection/SHIFT R-CNN: DEEP MONOCULAR 3D OBJECT DETECTION WITH CLOSED-FORM GEOMETRIC CONSTRAINTS/" class="dropdown-item">
            Shift RCNN
        </a>
    </li>
                                    
    <li>
        <a href="../../3dDetection/Triangulation Learning Network: from Monocular to Stereo 3D Object Detection/" class="dropdown-item">
            TLNet
        </a>
    </li>
                                    
    <li>
        <a href="../../3dDetection/voxelNet/" class="dropdown-item">
            VoxelNet
        </a>
    </li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Building Blocks <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
    <li>
        <a href="../../Building_Blocks/Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization/" class="dropdown-item">
            AdaIn Style Transfer
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/CBAM:Convolutional_Block_Attention_Module/" class="dropdown-item">
            CBAM: Convolutional Block Attention Module
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/Can GCNs Go as Deep as CNNs/" class="dropdown-item">
            Deep GCN
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/CornerNet_Detecting_Objects_as_Paired_Keypoints/" class="dropdown-item">
            CornetNet
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/ELASTIC/" class="dropdown-item">
            Elastic: Dynamic Scaling CNNs
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/Lookahead Optimizer ksteps forward, 1 step back/" class="dropdown-item">
            Lookahead Optimizer
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/Non-local Neural Networks/" class="dropdown-item">
            Non-local Neural Networks
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/On_Multiplicative_Integration_with_Recurrent_Neural_Networks/" class="dropdown-item">
            On Multiplicative Integration with Recurrent Neural Networks
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/SQUEEZENET_ALEXNET-LEVEL_ACCURACY_WITH_50X_FEWER_PARAMETERS_AND_0.5MB_MODEL_SIZE/" class="dropdown-item">
            SqueezeNet
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/Squeeze-and-Excitation Networks/" class="dropdown-item">
            Squeeze-and-Excitation Networks
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/Stacked_Hourglass_Networks_for_Human_Pose_Estimation/" class="dropdown-item">
            Stacked Hourglass Networks
        </a>
    </li>
                                    
    <li>
        <a href="../../Building_Blocks/deformable_convnet_v2/" class="dropdown-item">
            Deformable ConvNet V2
        </a>
    </li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Robotics with DL <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
    <li>
        <a href="../../Robotics_with_DL/Aggressive_Driving_with_Model_Predictive_Path_Integral_Control/" class="dropdown-item">
            Model Predicvtive Path Integral Control
        </a>
    </li>
                                    
    <li>
        <a href="../../Robotics_with_DL/Backprop KF Learning Discriminative DeterministicState Estimators/" class="dropdown-item">
            BackProp Kalman Filter
        </a>
    </li>
                                    
    <li>
        <a href="../../Robotics_with_DL/ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst/" class="dropdown-item">
            ChauffeurNet
        </a>
    </li>
                                    
    <li>
        <a href="../../Robotics_with_DL/Cognitive Mapping and Planning for Visual Navigation/" class="dropdown-item">
            Cognitive Mapping and Planning
        </a>
    </li>
                                    
    <li>
        <a href="../../Robotics_with_DL/Composable_Action-Conditioned_Predictors_Flexible_Off-Policy_Learning_for_Robot_Navigation/" class="dropdown-item">
            Composable Action-Conditioned Predictors
        </a>
    </li>
                                    
    <li>
        <a href="../../Robotics_with_DL/Differentiable Algorithm Networks forComposable Robot Learning/" class="dropdown-item">
            DAN for Composable Robot Learning
        </a>
    </li>
                                    
    <li>
        <a href="../../Robotics_with_DL/Differentiable MPC for End-to-end Planning and Control/" class="dropdown-item">
            Differentiable MPC
        </a>
    </li>
                                    
    <li>
        <a href="../../Robotics_with_DL/Intention-Net Integrating Planning and DeepLearning for Goal-Directed Autonomous Navigation/" class="dropdown-item">
            Intention-Net
        </a>
    </li>
                                    
    <li>
        <a href="../../Robotics_with_DL/MachineLearningForRobotPlanningAndContrlGeorgiaTech/" class="dropdown-item">
            Robotics_DL Lecture from georgia Tech
        </a>
    </li>
                                    
    <li>
        <a href="../../Robotics_with_DL/OptNet_Differentiable_Optimization_as_a_Layer_in_Neural_Networks/" class="dropdown-item">
            OptNet, Optimization as Layer
        </a>
    </li>
                                    
    <li>
        <a href="../../Robotics_with_DL/PHOTOREALISTIC IMAGE RECONSTRUCTION FROM_HYBRID_INTENSITY_AND_EVENT_BASED_SENSOR/" class="dropdown-item">
            Image Reconstruction with Event Camera
        </a>
    </li>
                                    
    <li>
        <a href="../../Robotics_with_DL/Path Integral Networks_End-to-End Differentiable Optimal Control/" class="dropdown-item">
            Path Integral Networks
        </a>
    </li>
                                    
    <li>
        <a href="../../Robotics_with_DL/QMDP-Net_ Deep Learning for Planning underPartial Observability/" class="dropdown-item">
            QMDP-Net
        </a>
    </li>
                                    
    <li>
        <a href="../../Robotics_with_DL/Robustness_to_Out-of-Distribution_Inputs_via_Task-Aware_Generative_Uncertainty/" class="dropdown-item">
            Task-Aware Generative Uncertainty
        </a>
    </li>
                                    
    <li>
        <a href="../../Robotics_with_DL/SuperPoint:Self-Supervised_Interest_Point_Detection_and_Description/" class="dropdown-item">
            SuperPoint
        </a>
    </li>
                                    
    <li>
        <a href="../../Robotics_with_DL/Universal Planning Networks/" class="dropdown-item">
            Universal Planning Networks
        </a>
    </li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">The Theory <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
    <li>
        <a href="../../The Theory/Do Better ImageNet Models Transfer Better/" class="dropdown-item">
            Do Better ImageNet Models Transfer Better?
        </a>
    </li>
                                    
    <li>
        <a href="../../The Theory/FreeAnchor_Learning_to_Match_Anchors_for_Visual_Object_Detection/" class="dropdown-item">
            FreeAnchor
        </a>
    </li>
                                    
    <li>
        <a href="../../The Theory/Rethinking ImageNet Pre-training/" class="dropdown-item">
            Rethinking ImageNet Pre-training
        </a>
    </li>
                                    
    <li>
        <a href="../../The Theory/ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design/" class="dropdown-item">
            ShuffleNet V2
        </a>
    </li>
                                    
    <li>
        <a href="../../The Theory/UNDERSTANDING DEEP LEARNING REQUIRES RETHINKING GENERALIZATION/" class="dropdown-item">
            Understanding Deep Learning Requires Rethinking Generalization
        </a>
    </li>
                                </ul>
                            </li>
                            <li class="dropdown active">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Papers <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
    <li>
        <a href="../4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks/" class="dropdown-item">
            Minkowski Convolutional Neural Networks
        </a>
    </li>
                                    
    <li>
        <a href="../Actor-Critic Instance Segmentation/" class="dropdown-item">
            Actor-Critic Instance Segmentation
        </a>
    </li>
                                    
    <li>
        <a href="../Associative_Embedding:End-to-End_Learning_for_Joint_Detection_and_Grouping/" class="dropdown-item">
            Associative Embedding
        </a>
    </li>
                                    
    <li>
        <a href="../CONVOLUTIONAL CRFS  FOR SEMANTIC SEGMENTATION/" class="dropdown-item">
            Convolutional CRF
        </a>
    </li>
                                    
    <li>
        <a href="../CenterNet:_Keypoint_Triplets_for_Object_Detection/" class="dropdown-item">
            CenterNet
        </a>
    </li>
                                    
    <li>
        <a href="../Continuous-time_Intensity_Estimation_Using_Event_Cameras/" class="dropdown-item">
            Intensity Estimation With Event Cameras
        </a>
    </li>
                                    
    <li>
        <a href="../CornerNet-Lite_Efficient_Keypoint_Based_Object_Detection/" class="dropdown-item">
            CornetNet-Lite
        </a>
    </li>
                                    
    <li>
        <a href="../DESPOT-α: Online POMDP Planning With Large State And Observation Spaces/" class="dropdown-item">
            DESPOT-α
        </a>
    </li>
                                    
    <li>
        <a href="../Deep High-Resolution Representation Learning for Human Pose Estimation/" class="dropdown-item">
            HRNet
        </a>
    </li>
                                    
    <li>
        <a href="../Deep Multi-Sensor Lane Detection/" class="dropdown-item">
            Deep Multi-Sensor Lane Detection
        </a>
    </li>
                                    
    <li>
        <a href="../DeepICP: An End-to-End Deep Neural Network for 3D Point Cloud Registration/" class="dropdown-item">
            DeepICP
        </a>
    </li>
                                    
    <li>
        <a href="../DroNet Learning to Fly by Driving/" class="dropdown-item">
            DroNet
        </a>
    </li>
                                    
    <li>
        <a href="../End-to-end Driving Deploying through Uncertainty-Aware ImitationLearning and Stochastic Visual Domain Adaptation/" class="dropdown-item">
            Domain Transfer Imitation - Tai Lei
        </a>
    </li>
                                    
    <li>
        <a href="../Fast and Furious Real Time End-to-End 3D Detection, Tracking and MotionForecasting with a Single Convolutional Net/" class="dropdown-item">
            Fast and Furious
        </a>
    </li>
                                    
    <li>
        <a href="../Gaze  Training  by  Modulated  Dropout  Improves  Imitation  Learning/" class="dropdown-item">
            Gaze Training - Chen Yuying
        </a>
    </li>
                                    
    <li>
        <a href="../Joint_Unsupervised_Learning_of_Optical_Flow_and_Depth_by_Watching_Stereo_Videos/" class="dropdown-item">
            UnDepthFlow
        </a>
    </li>
                                    
    <li>
        <a href="./" class="dropdown-item active">
            LO-Net
        </a>
    </li>
                                    
    <li>
        <a href="../Lane Detection and Classification usingCascaded CNNs/" class="dropdown-item">
            Cascade Lane Detection
        </a>
    </li>
                                    
    <li>
        <a href="../PWC-Net_CNNs_for_Optical_Flow_Using_Pyramid_Warping_and_Cost_Volume/" class="dropdown-item">
            PWC-Net
        </a>
    </li>
                                    
    <li>
        <a href="../PointFlow : 3D Point Cloud Generation with Continuous Normalizing Flows/" class="dropdown-item">
            PointFlow
        </a>
    </li>
                                    
    <li>
        <a href="../SSD Single Shot MultiBox Detector/" class="dropdown-item">
            SSD
        </a>
    </li>
                                    
    <li>
        <a href="../Unsupervised_Learning_of_Depth_and_Ego-Motion_from_Video/" class="dropdown-item">
            Unsupervised Learning of Depth and Ego-Motion from Video
        </a>
    </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">
        Undone
    </a>
    <ul class="dropdown-menu">
            
    <li>
        <a href="../undone/ApplicationofHDRalgorithmstosolvedirectsunlightproblemswhenautonomousvehiclesusingmachinevisionsystemsaredrivingintosun/" class="dropdown-item">
            Application of HDR algorithms to solve direct sunlight problems when autonomous vehicles using machine vision systems are driving into sun
        </a>
    </li>
            
    <li>
        <a href="../undone/Autonomous  Racing  using  Learning  Model  Predictive  Control/" class="dropdown-item">
            Autonomous  Racing  using  Learning  Model  Predictive  Control
        </a>
    </li>
            
    <li>
        <a href="../undone/Beyond Pixels Leveraging Geometry and Shape Cues for OnlineMulti-Object Tracking/" class="dropdown-item">
            Beyond Pixels: Leveraging Geometry and Shape Cues for OnlineMulti-Object Tracking
        </a>
    </li>
            
    <li>
        <a href="../undone/Data-Driven Modeling and Control of an Autonomous Race Car/" class="dropdown-item">
            Data-Driven Modeling and Control of an Autonomous Race Car
        </a>
    </li>
            
    <li>
        <a href="../undone/Deep Hough Voting for 3D Object Detection in Point Clouds/" class="dropdown-item">
            Deep Hough Voting for 3D Object Detection in Point Clouds
        </a>
    </li>
            
    <li>
        <a href="../undone/Deep Imitative Models for Flexible Inference,Planning, and Control/" class="dropdown-item">
            Deep Imitative Models for Flexible Inference,Planning, and Control
        </a>
    </li>
            
    <li>
        <a href="../undone/END-TO-END LEARNABLE HISTOGRAM FILTERS/" class="dropdown-item">
            END-TO-END LEARNABLE HISTOGRAM FILTERS
        </a>
    </li>
            
    <li>
        <a href="../undone/End-To-End Multi-Modal Sensors Fusion System ForUrban Automated Driving/" class="dropdown-item">
            End-To-End Multi-Modal Sensors Fusion System For Urban Automated Driving
        </a>
    </li>
            
    <li>
        <a href="../undone/Enhanced  free  space  detection  in  multiple  lanes  based  on  single  CNNwith  scene  identification/" class="dropdown-item">
            Enhanced  free  space  detection  in  multiple  lanes  based  on  single  CNN with  scene  identification
        </a>
    </li>
            
    <li>
        <a href="../undone/Exploring the structure of a real-time, arbitrary neuralartistic stylization network/" class="dropdown-item">
            Exploring the structure of a real-time, arbitrary neuralartistic stylization network
        </a>
    </li>
            
    <li>
        <a href="../undone/From Perception to Decision A Data-driven Approach to End-to-endMotion Planning for Autonomous Ground Robots/" class="dropdown-item">
            From Perception to Decision: A Data-driven Approach to End-to-end Motion Planning for Autonomous Ground Robots
        </a>
    </li>
            
    <li>
        <a href="../undone/IMAGENET-TRAINEDCNNS   ARE   BIASED   TOWARDSTEXTURE;INCREASING SHAPE BIAS IMPROVESACCURACY AND ROBUSTNESS/" class="dropdown-item">
            IMAGENET-TRAINEDCNNS   ARE   BIASED   TOWARDS TEXTURE;INCREASING SHAPE BIAS IMPROVES ACCURACY AND ROBUSTNESS
        </a>
    </li>
            
    <li>
        <a href="../undone/InfoGAN Interpretable Representation Learning byInformation Maximizing Generative Adversarial Nets/" class="dropdown-item">
            InfoGAN: Interpretable Representation Learning byInformation Maximizing Generative Adversarial Nets
        </a>
    </li>
            
    <li>
        <a href="../undone/LP-3DCNN Unveiling Local Phase in 3D Convolutional Neural Networks/" class="dropdown-item">
            LP-3DCNN: Unveiling Local Phase in 3D Convolutional Neural Networks
        </a>
    </li>
            
    <li>
        <a href="../undone/LiDAR Sensor modeling and Data augmentationwith GANs for Autonomous driving/" class="dropdown-item">
            LiDAR Sensor modeling and Data augmentationwith GANs for Autonomous driving
        </a>
    </li>
            
    <li>
        <a href="../undone/Libra R-CNN Towards Balanced Learning for Object Detection/" class="dropdown-item">
            Libra R-CNN: Towards Balanced Learning for Object Detection
        </a>
    </li>
            
    <li>
        <a href="../undone/MPC-Inspired Neural Network Policies for Sequential Decision Making/" class="dropdown-item">
            MPC-Inspired Neural Network Policies for Sequential Decision Making
        </a>
    </li>
            
    <li>
        <a href="../undone/MULTI-SCALEDENSENETWORKSFORRESOURCEEFFICIENTIMAGECLASSIFICATION/" class="dropdown-item">
            MULTI-SCALE DENSE NETWORKS FOR RESOURCE EFFICIENT IMAGE CLASSIFICATION
        </a>
    </li>
            
    <li>
        <a href="../undone/Motion Planning for Autonomous Driving with a Conformal Spatiotemporal Lattice/" class="dropdown-item">
            Motion Planning for Autonomous Driving with a Conformal Spatiotemporal Lattice
        </a>
    </li>
            
    <li>
        <a href="../undone/Optimization Beyond the Convolution Generalizing Spatial Relationswith End-to-End Metric Learning/" class="dropdown-item">
            Optimization Beyond the Convolution: Generalizing Spatial Relationswith End-to-End Metric Learning
        </a>
    </li>
            
    <li>
        <a href="../undone/POI Multiple Object Tracking with HighPerformance Detection and Appearance Feature/" class="dropdown-item">
            POI: Multiple Object Tracking with HighPerformance Detection and Appearance Feature
        </a>
    </li>
            
    <li>
        <a href="../undone/Probabilistic Decision-Making under Uncertainty for AutonomousDriving using Continuous POMDPs/" class="dropdown-item">
            Probabilistic Decision-Making under Uncertainty for AutonomousDriving using Continuous POMDPs
        </a>
    </li>
            
    <li>
        <a href="../undone/RETHINKINGSELF-DRIVING  MULTI-TASKKNOWL-EDGE  FORBETTERGENERALIZATION  ANDACCIDENTEXPLANATIONABILITY/" class="dropdown-item">
            RETHINKING SELF-DRIVING:   MULTI-TASK KNOWLEDGE  FOR BETTER GENERALIZATION  AND ACCIDENT EXPLANATIONABILITY
        </a>
    </li>
            
    <li>
        <a href="../undone/Real-Time Freespace Segmentation on AutonomousRobots for Detection of Obstacles and Drop-Offs/" class="dropdown-item">
            Real-Time Freespace Segmentation on AutonomousRobots for Detection of Obstacles and Drop-Offs
        </a>
    </li>
            
    <li>
        <a href="../undone/Restricted Deformable Convolution basedRoad Scene Semantic SegmentationUsing Surround View Cameras/" class="dropdown-item">
            Restricted Deformable Convolution based Road Scene Semantic Segmentation Using Surround View Cameras
        </a>
    </li>
            
    <li>
        <a href="../undone/Semantic Image Synthesis with Spatially-Adaptive Normalization/" class="dropdown-item">
            Semantic Image Synthesis with Spatially-Adaptive Normalization
        </a>
    </li>
            
    <li>
        <a href="../undone/Style Augmentation Data Augmentation via StyleRandomization/" class="dropdown-item">
            Style Augmentation: Data Augmentation via StyleRandomization
        </a>
    </li>
            
    <li>
        <a href="../undone/TossingBot Learning to Throw Arbitrary Objectswith Residual Physics/" class="dropdown-item">
            TossingBot: Learning to Throw Arbitrary Objectswith Residual Physics
        </a>
    </li>
            
    <li>
        <a href="../undone/Toward Driving Scene Understanding A Dataset for Learning Driver Behavior and Causal Reasoning/" class="dropdown-item">
            Toward Driving Scene Understanding:A Dataset for Learning Driver Behavior and Causal Reasoning
        </a>
    </li>
            
    <li>
        <a href="../undone/Towards Practical Hierarchical ReinforcementLearning for Multi-lane Autonomous Driving/" class="dropdown-item">
            Towards Practical Hierarchical ReinforcementLearning for Multi-lane Autonomous Driving
        </a>
    </li>
            
    <li>
        <a href="../undone/Unsupervised Learning of Depth and Ego-Motion from Monocular VideoUsing 3D Geometric Constraints/" class="dropdown-item">
            Unsupervised Learning of Depth and Ego-Motion from Monocular VideoUsing 3D Geometric Constraints
        </a>
    </li>
            
    <li>
        <a href="../undone/Virtual-to-real  Deep  Reinforcement  Learning Continuous  Control  of  Mobile  Robots  for  Mapless  Navigation/" class="dropdown-item">
            Virtual-to-real  Deep  Reinforcement  Learning:Continuous  Control  of  Mobile  Robots  for  Mapless  Navigation
        </a>
    </li>
            
    <li>
        <a href="../undone/Visual-based Autonomous Driving Deployment from a Stochastic andUncertainty-aware Perspective/" class="dropdown-item">
            Visual-based Autonomous Driving Deployment from a Stochastic andUncertainty-aware Perspective
        </a>
    </li>
            
    <li>
        <a href="../undone/aaaaa/" class="dropdown-item">
            Aaaaa
        </a>
    </li>
    </ul>
  </li>
                                </ul>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" href="../Joint_Unsupervised_Learning_of_Optical_Flow_and_Depth_by_Watching_Stereo_Videos/" class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" href="../Lane Detection and Classification usingCascaded CNNs/" class="nav-link">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            
                <div   class=row >
                            <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>
    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        
        <ul class="nav flex-column bs-sidenav">
        
        <a href=https://arxiv.org/pdf/1904.08242.pdf>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<i class="fa fa-file-pdf-o"> pdf</i>
        </a>
        

        
        <a href=https://github.com/PythonLidar/pytorch-LONet>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<i class="fa fa-github"> code</i>
        </a>

        
            <li class="nav-item main"><a href="#lo-net-deep-real-time-lidar-odometry">LO-Net: Deep Real-time Lidar Odometry</a></li>
                <li class="nav-item">
                    <a href="#_1" class="nav-link">网络主要结构</a>
                </li>
                <li class="nav-item">
                    <a href="#_2" class="nav-link">输入编码</a>
                </li>
                <li class="nav-item">
                    <a href="#_3" class="nav-link">几何约束</a>
                </li>
                <li class="nav-item">
                    <a href="#_5" class="nav-link">里程回归</a>
                </li>
                <li class="nav-item">
                    <a href="#mask" class="nav-link">Mask估计</a>
                </li>
                <li class="nav-item">
                    <a href="#mapping-refinement" class="nav-link">Mapping refinement</a>
                </li>
        </ul>
    </div>
</div></div>
                            <div class="col-md-9" role="main">
<h1 id="lo-net-deep-real-time-lidar-odometry">LO-Net: Deep Real-time Lidar Odometry</h1>
<p>这篇文章主要有三个贡献，第一提出了scan-to-scan lidar odometry网络，同时估计面的法向以及mask for dynamic regions。第二融合相邻两帧网络进行估计，第三，融合一个mapping module. 注意Github 链接代码尚未公布。</p>
<h2 id="_1">网络主要结构</h2>
<p><img alt="image" src="../res/LONet.png" /></p>
<p>整体来说，网络由三个网络构成，分别是法向估计网络(point wise)，mask 估计网络以及一个共用参数的双生姿态回归主网路。它以两个相邻的lidar点作为输入，估计出6自由度的相对运动、点云各点的面法向以及动态区域mask。odometry的输出会通过mapping模块进一步提高，最终的输出会是相对于初始位置的偏移</p>
<h2 id="_2">输入编码</h2>
<p>为了让网络的数据编排变得紧凑，这里使用圆柱坐标系</p>
<p>
<script type="math/tex; mode=display">\alpha = arctan(y/x)/\Delta \alpha</script>
<script type="math/tex; mode=display">\beta = arcsin(z/\sqrt{x^2+y^2 + z^2} / Δβ)</script>
</p>
<p>如果同一个<script type="math/tex">\alpha, \beta</script>坐标有不止一个点，则以最近的点为准，每一个点的特征包括强度值以及距离值。</p>
<p><img alt="image" src="../res/LOnet_encoding_and_normal.png" /></p>
<h2 id="_3">几何约束</h2>
<h3 id="_4">法向估计</h3>
<p>严谨来说，以上图为例子，点云的法向应该由点<script type="math/tex">X^i</script>以及其<script type="math/tex">k</script>个相邻的点，由下式定义</p>
<p>
<script type="math/tex; mode=display">\argmin_{\mathcal{N}(X^i)} ||[w_{i1}(X^{i_1}-X^i),...]^T\mathcal{N}(X^i)||_2</script>
</p>
<p>也就是寻找一个矢量，使得这个矢量与k个相邻点矢量的点乘的加权求和值(或者是加权范数)最小.一般来说距离越近权重越大，距离越远权重越小。</p>
<p>本文为了简化这一计算，使用以下方程</p>
<p>
<script type="math/tex; mode=display">\mathcal{N}(X^i) = \sum_{X^{i_k}, X^{i_j} in \mathcal{P}} (w_{ik}(X^{i_k} - X^i) \times w_{ij}(X^{i_j} - X^i))</script>
</p>
<p>其中<script type="math/tex">\mathcal{P}</script>为当前点的临近点。</p>
<p>相邻两簇点云之间有一定的对应关系，令<script type="math/tex">P</script>为投影过程而<script type="math/tex">T_t</script>为相对位移，可以找到点<script type="math/tex">X^{\alpha \beta}_{t-1}</script>的对应点</p>
<p>
<script type="math/tex; mode=display">\hat X^{\alpha \beta}_t = P T_t P^{-1} X^{\alpha\beta}_{t-1}</script>
</p>
<p>由于相对应的点法向估计理应比较相似，所以一个约束是</p>
<p>
<script type="math/tex; mode=display">\mathcal{L}_n = \sum_{\alpha \beta}||\mathcal{N}(\hat X^{\alpha\beta}_t) - \mathcal{N}(X^{\alpha\beta}_t) ||_1 \dot e^{|\nabla_r(\hat X^{\alpha \beta}_t)|}</script>
</p>
<p>其中 <script type="math/tex">\nabla_r(\hat X^{\alpha \beta}_t)</script>是距离关于<script type="math/tex">\alpha \beta</script>的微分，意思是变化越剧烈的地方越重要</p>
<h2 id="_5">里程回归</h2>
<p>这里让网络在完全连接层输出7个数值，前三个是平移向量，后面四个是四元数。大部分网络层使用的是<a href="../../Building_Blocks/SQUEEZENET_ALEXNET-LEVEL_ACCURACY_WITH_50X_FEWER_PARAMETERS_AND_0.5MB_MODEL_SIZE/">fireConv</a></p>
<p>由于点云的特性，feature map的高度远小于宽度(360°点云)，所以在下采样的时候只对宽度进行max pooling</p>
<p>在学习时由于旋转与平移的单位不同，同时为了避免调节超参，使用自动学习的参数(个人注解:尽管公式不同，引用的文章也不一致，但是基本可以确认理论本质来自于<a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Kendall_Multi-Task_Learning_Using_CVPR_2018_paper.pdf">multi-loss</a>)</p>
<p>
<script type="math/tex; mode=display">
\begin{aligned} \mathcal{L}_{o} &=\mathcal{L}_{x}\left(S_{t-1} ; S_{t}\right) \exp \left(-s_{x}\right)+s_{x} \\ &+\mathcal{L}_{q}\left(S_{t-1} ; S_{t}\right) \exp \left(-s_{q}\right)+s_{q} \end{aligned}
</script>
</p>
<h2 id="mask">Mask估计</h2>
<p>输出的mask会影响到几何约束的cost function，被改造为</p>
<p>
<script type="math/tex; mode=display">
\mathcal{L}_{n}=\sum_{\alpha \beta} \mathcal{M}\left(X_{t}^{\alpha \beta}\right)\left\|\mathcal{N}\left(\hat{X}_{t}^{\alpha \beta}\right)-\mathcal{N}\left(X_{t}^{\alpha \beta}\right)\right\|_{1} \cdot e^{\left|\nabla r\left(\hat{X}_{t}^{\alpha \beta}\right)\right|}
</script>
</p>
<p>注意到由于mask prediction没有ground truth 所以将所有mask设置为0可以让cost变得最小，所以附加以下的cost，目标是让网络能够权衡。
<script type="math/tex; mode=display">
\mathcal{L}_{r}=-\sum_{\alpha \beta} \log P\left(\mathcal{M}\left(X_{t}^{\alpha \beta}\right)=1\right)
</script>
</p>
<h2 id="mapping-refinement">Mapping refinement</h2>
<p><img alt="image" src="../res/LONet_Mapping.png" /></p>
<p>
<script type="math/tex">*</script>表示的是对法向估计的一个预设的<script type="math/tex">3\times 5</script>卷积，中央为-14.其他值为1，是一个高通滤波器。feature map上值最小的<script type="math/tex">n_c</script>个mask外的点选出来，认为是平面区域。</p>
<p>
<script type="math/tex">\mathbf{\Pi}</script>指的是计算lidar pose的先验计算(假设上一时刻转换矩阵不变) <script type="math/tex">M_{init} = M_{t-1}M^{-1}_{t-2}M_{t-1}</script>
</p>
<p>
<script type="math/tex">\mathbf{\Psi}</script> 首先利用网络预测的两帧间位移线性插值补偿运动畸变，然后用<script type="math/tex">M_{init}</script>将新的点云转移到世界坐标系下。</p>
<p>假设<script type="math/tex">p_i</script>是当前scan的点，<script type="math/tex">m_i</script>是对应点，而<script type="math/tex">n_i</script>是对应点的法向。全局mapping的目标就是要找到一个最优的<script type="math/tex">M</script>使得
<script type="math/tex; mode=display">
\hat{\mathbf{M}}_{o p t}=\underset{\hat{\mathbf{M}}}{\arg \min } \sum_{i}\left(\left(\hat{\mathbf{M}} \cdot \boldsymbol{p}_{i}-\boldsymbol{m}_{i}\right) \cdot \boldsymbol{n}_{i}\right)^{2}
</script>
</p>
<p>
<script type="math/tex">\Theta</script>:迭代地求解上文提到的方程，
<script type="math/tex; mode=display">
\mathbf{M}_{t}=\prod_{k=1}^{n_{i t e r}} \hat{\mathbf{M}}_{k} \mathbf{M}_{i n i t}
</script>
</p>
<p>
<script type="math/tex">\Phi</script>根据优化后的位移结果生成最终的点云结果。</p>
<p>
<script type="math/tex">\sum,N</script>将新的点云加到地图中，然后清除最旧的点云，只保存最旧的<script type="math/tex">n_m</script>个点云</p></div>
                    
                </div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "../..",
                shortcuts = {"next": 78, "help": 191, "previous": 80, "search": 83};
        </script>
        <script src="../../js/base.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML" defer></script>
        <script src="../../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form>
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
