{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-\\.]+$"},"docs":[{"location":"","text":"\u8bba\u6587\u9605\u8bfb \u5bf9\u8fdb\u884c\u7684\u8bba\u6587\u9605\u8bfb\u8fdb\u884c\u8bb0\u5f55\u3002 \u6ce8\u610f\u7531\u4e8e\u76ee\u524d\u5b58\u50a8\u7684\u8bba\u6587\u6570\u91cf\u8d8a\u6765\u8d8a\u591a\uff0c\u5982\u679c\u60f3\u8981\u67e5\u627e\u67d0\u4e9b\u7279\u5b9a\u7684\u8bba\u6587\u5efa\u8bae\u6309's'\u952e\u6216\u8005\u70b9\u51fb\u53f3\u4e0a\u65b9\u7684\"search\"\u6309\u94ae\uff0c\u8f93\u5165\u5bf9\u5e94\u82f1\u6587\u9898\u76ee\u8fdb\u884c\u641c\u7d22\u3002 \u6587\u7ae0\u5404\u81ea\u7684\u76ee\u5f55\u4e2d\u4f1a\u8868\u660epdf\u4ee5\u53ca\u5f00\u6e90\u4ee3\u7801(\u5982\u6709)\u7684\u5916\u94fe\u3002 This volume will be basically written in Chinese. The target is to provide fast reference. Papers are now sorted in Several categories 3D object detection. mainly on monocular detection and also many papers in sensor fusion. Building Blocks for neural networks that boost performance Robotics with DL: using deep learning related technology to boost robotics algorithms The Theory: General advices for understanding and boosting the performance of deep learning other interesting or useful papers including 1. 2D object detection 2. Advanced SLAM 3. Segmentation 4. End to end navigation \u63a8\u8350\u7684\u7efc\u8ff0\u578b\u9605\u8bfb Monocular 3D Object Detection-KITTI Stereo 3D Object Detection-KITTI Stereo Matching - KITTI Yolov4 & Review of Structure and Tricks for Object Detection Github Github \u7f51\u9875 \u6b22\u8fce\u5171\u540c\u8bb0\u5f55\u8bba\u6587\u9605\u8bfb,\u5bf9\u6587\u7ae0\u7684\u89e3\u8bfb\u6709\u8d28\u7591\u548c\u8865\u5145\u7684\u5efa\u8bae\u63d0\u4ea4github issue.","title":"\u8bba\u6587\u9605\u8bfb"},{"location":"#_1","text":"\u5bf9\u8fdb\u884c\u7684\u8bba\u6587\u9605\u8bfb\u8fdb\u884c\u8bb0\u5f55\u3002 \u6ce8\u610f\u7531\u4e8e\u76ee\u524d\u5b58\u50a8\u7684\u8bba\u6587\u6570\u91cf\u8d8a\u6765\u8d8a\u591a\uff0c\u5982\u679c\u60f3\u8981\u67e5\u627e\u67d0\u4e9b\u7279\u5b9a\u7684\u8bba\u6587\u5efa\u8bae\u6309's'\u952e\u6216\u8005\u70b9\u51fb\u53f3\u4e0a\u65b9\u7684\"search\"\u6309\u94ae\uff0c\u8f93\u5165\u5bf9\u5e94\u82f1\u6587\u9898\u76ee\u8fdb\u884c\u641c\u7d22\u3002 \u6587\u7ae0\u5404\u81ea\u7684\u76ee\u5f55\u4e2d\u4f1a\u8868\u660epdf\u4ee5\u53ca\u5f00\u6e90\u4ee3\u7801(\u5982\u6709)\u7684\u5916\u94fe\u3002 This volume will be basically written in Chinese. The target is to provide fast reference. Papers are now sorted in Several categories 3D object detection. mainly on monocular detection and also many papers in sensor fusion. Building Blocks for neural networks that boost performance Robotics with DL: using deep learning related technology to boost robotics algorithms The Theory: General advices for understanding and boosting the performance of deep learning other interesting or useful papers including 1. 2D object detection 2. Advanced SLAM 3. Segmentation 4. End to end navigation","title":"\u8bba\u6587\u9605\u8bfb"},{"location":"#_2","text":"","title":"\u63a8\u8350\u7684\u7efc\u8ff0\u578b\u9605\u8bfb"},{"location":"#monocular-3d-object-detection-kitti","text":"","title":"Monocular 3D Object Detection-KITTI"},{"location":"#stereo-3d-object-detection-kitti","text":"","title":"Stereo 3D Object Detection-KITTI"},{"location":"#stereo-matching-kitti","text":"","title":"Stereo Matching - KITTI"},{"location":"#yolov4-review-of-structure-and-tricks-for-object-detection","text":"","title":"Yolov4 &amp; Review of Structure and Tricks for Object Detection"},{"location":"#github","text":"Github \u7f51\u9875 \u6b22\u8fce\u5171\u540c\u8bb0\u5f55\u8bba\u6587\u9605\u8bfb,\u5bf9\u6587\u7ae0\u7684\u89e3\u8bfb\u6709\u8d28\u7591\u548c\u8865\u5145\u7684\u5efa\u8bae\u63d0\u4ea4github issue.","title":"Github"},{"location":"3dDetection/AFDet/","text":"CenterNet for Point cloud \u8fd9\u91cc\u5f15\u5165\u4e24\u7bc7paper\uff0c\u90fd\u4f7f\u7528 object as point \u4f5c\u4e3a\u57fa\u7840\u8fdb\u884cobject 3D detection. Center-based 3D Object Detection and Tracking pdf code \u8fd9\u7bc7\u662fXingyi Zhou\u7ec4\u7684\u5b98\u65b9\u5ef6\u7eed\u4ee3\u7801\uff0c\u4e3b\u8981\u4fee\u6539\uff0cHeat Map\u8c03\u6574\u4e86 \u6b63\u6837\u672c\u7684\u8986\u76d6\u9762\u79ef\u3002Detection head\u589e\u52a0\u4e86\u53ef\u53d8\u5f62\u5377\u79ef\u3002\u4f7f\u7528\u57fa\u4e8e\u534a\u5f84\u7684NMS\u53d6\u4ee3\u57fa\u4e8eIOU\u7684NMS\uff1b\u4e24\u8f74\u7ffb\u8f6c\u7684\u6570\u636e\u589e\u5f3a AFDet: Anchor Free One Stage 3D Object Detection pdf","title":"CenterNet for Point cloud"},{"location":"3dDetection/AFDet/#centernet-for-point-cloud","text":"\u8fd9\u91cc\u5f15\u5165\u4e24\u7bc7paper\uff0c\u90fd\u4f7f\u7528 object as point \u4f5c\u4e3a\u57fa\u7840\u8fdb\u884cobject 3D detection.","title":"CenterNet for Point cloud"},{"location":"3dDetection/AFDet/#center-based-3d-object-detection-and-tracking","text":"pdf code \u8fd9\u7bc7\u662fXingyi Zhou\u7ec4\u7684\u5b98\u65b9\u5ef6\u7eed\u4ee3\u7801\uff0c\u4e3b\u8981\u4fee\u6539\uff0cHeat Map\u8c03\u6574\u4e86 \u6b63\u6837\u672c\u7684\u8986\u76d6\u9762\u79ef\u3002Detection head\u589e\u52a0\u4e86\u53ef\u53d8\u5f62\u5377\u79ef\u3002\u4f7f\u7528\u57fa\u4e8e\u534a\u5f84\u7684NMS\u53d6\u4ee3\u57fa\u4e8eIOU\u7684NMS\uff1b\u4e24\u8f74\u7ffb\u8f6c\u7684\u6570\u636e\u589e\u5f3a","title":"Center-based 3D Object Detection and Tracking"},{"location":"3dDetection/AFDet/#afdet-anchor-free-one-stage-3d-object-detection","text":"pdf","title":"AFDet: Anchor Free One Stage 3D Object Detection"},{"location":"3dDetection/AM3D/","text":"Accurate Monocular Object Detection via Color-Embedded 3D Reconstruction for Autonomous Driving \u8fd9\u7bc7\u6587\u7ae0\u5229\u7528\u4e86depth estimation\u4ee5\u53caPseudo lidar\u7684\u601d\u8def\uff0c\u662f\u76ee\u524d\u5355\u76ee\u89c6\u89c93D\u68c0\u6d4b\u7684SOTA,\u4f46\u662f\u989d\u5916\u51fa\u5f69\u7684\u5730\u65b9\u5728\u4e8e\u5176\u5bf9RGB\u4fe1\u606f\u4ee5\u53ca\u6df1\u5ea6\u4fe1\u606f\u878d\u5408\u65f6\u7684\u505a\u6cd5\u3002 \u4e3b\u8981\u7ed3\u6784\u4e0e\u6d41\u7a0b\u56fe \u5bf9\u5355\u4e00\u56fe\u50cf\u5206\u522b\u4f7f\u7528RPN\u63d0\u53d6RoI\u4ee5\u53ca\u4f7f\u7528\u6df1\u5ea6\u7f51\u7edc\u751f\u6210\u6df1\u5ea6\u4fe1\u606f\uff0c\u7136\u540e\u5bf9\u63d0\u53d6\u51fa\u6765\u7684\u533a\u57df\uff0c\u8fdb\u884c\u7b80\u5355\u7684\u6570\u636e\u8f6c\u6362\u3001\u5206\u5272\u3001\u878d\u5408\u68c0\u6d4b\u56de\u5f52 \u5c40\u90e8\u8be6\u89e3 \u6570\u636e\u8f6c\u6362 \u5df2\u77e5\u6df1\u5ea6d\uff0c\u4f7f\u7528 \\left\\{\\begin{array}{l}{z=d} \\\\ {x=\\left(u-C_{x}\\right) * z / f} \\\\ {y=\\left(v-C_{y}\\right) * z / f}\\end{array}\\right. \u5c06RoI\u533a\u57df\u8f6c\u6362\u4e3a\u76ee\u6807\u70b9\u4e91(\u5bc6\u96c6\u8868\u8fbe)\u3002 \u70b9\u4e91\u5206\u5272 \u65b9\u6cd5\u7b80\u5355\uff0c\u5728RoI\u533a\u57df\u5185\uff0c\u6c42\u51fa\u6df1\u5ea6\u5e73\u5747\u503c\uff0c\u6bd4\u5747\u503c\u9ad8\u51fa\u4e00\u4e2a\u9608\u503c\u4ee5\u4e0a\u7684\u5224\u65ad\u4e3a\u80cc\u666f\u70b9 S^{\\prime}=\\left\\{p | p_{v} \\leq \\frac{\\sum_{p \\in S} p_{v}}{|S|}+r, p \\in S\\right\\} \u5e76\u4ece\u4e2d\u968f\u673a\u9009\u53d6\u4e00\u5b9a\u91cf\u7684\u70b9\u4f5c\u4e3a\u8f93\u51fa\u70b9\uff0c\u5927\u5c0f\u4e00\u81f4\u4fbf\u4e8e\u540e\u671f\u5904\u7406 \u5750\u6807\u8f6c\u6362 \u7528\u4e00\u4e2a\u7ecf\u5178 \u6587\u7ae0 \u7684\u65b9\u6cd5\uff0c\u5229\u7528\u4e00\u4e2a\u5c0f\u7f51\u7edc\u4f30\u8ba1\u51faRoI\u7684\u4e2d\u5fc3\uff0c\u7136\u540e\u5c06\u6240\u6709\u70b9\u8f6c\u5230\u76f8\u5bf9\u5750\u6807\u7cfb\u4e2d S^{\\prime \\prime}=\\left\\{p | p-\\delta, p \\in S^{\\prime}\\right\\} \u7136\u540e\u7528pointnet\u9884\u6d4b \u878d\u5408 \u7528\u5982\u56fe\u65b9\u5f0f\u878d\u5408\u70b9\u4e91\u4ee5\u53ca\u5f69\u8272\u70b9\u3002 G \u662f\u4e00\u4e2a\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u5f97\u5230\u5b83\u7684\u516c\u5f0f\u662f G = \\sigma(f([F^{xyz}_{max}, F^{xyz}_{avg}])) ,\u6709\u4e00\u70b9 CBAM \u7684\u6548\u679c\uff0c \u540e\u9762\u7684\u70b9\u4e58\u4e0e\u76f8\u52a0\u53ef\u4ee5\u5199\u6210 \\mathbf{F}^{x y z} \\leftarrow \\mathbf{F}^{x y z}+\\mathbf{G} \\odot \\mathbf{F}^{r g b} \u53e6\u4e00\u65b9\u9762\uff0c\u4ece\u56fe\u4e2d\u76842D RoI\u4e2d\uff0c\u4f7f\u7528RoIAlign\u8c03\u5230 128\\times 128 \uff0c\u7528CNN\u63d0\u53d6\u4e00\u4e2a\u7279\u5f81\u5411\u91cf\uff0c\u5e76\u8054 \u8bad\u7ec3\u7ec6\u8282 \u4e24\u9636\u6bb5\u8bad\u7ec3\uff0c\u5148\u8bad\u7ec3\u4e24\u4e2a\u4e2d\u95f4\u7f51\u7edc\uff0c\u7136\u540e\u53ea\u75283D\u4fe1\u606f\u8bad\u7ec3\u6574\u4e2a\u7f51\u7edc \u635f\u5931\u51fd\u6570\u5305\u62ec\uff0c\u4e2d\u95f4\u8f7b\u91cf\u7ea7\u7684\u5bf9center\u7684\u4f30\u8ba1\uff0c\u9884\u6d4b\u8f93\u51fa\u7684corner loss(8\u4e2a\u89d2)","title":"Accurate Monocular Object Detection via Color-Embedded 3D Reconstruction for Autonomous Driving"},{"location":"3dDetection/AM3D/#accurate-monocular-object-detection-via-color-embedded-3d-reconstruction-for-autonomous-driving","text":"\u8fd9\u7bc7\u6587\u7ae0\u5229\u7528\u4e86depth estimation\u4ee5\u53caPseudo lidar\u7684\u601d\u8def\uff0c\u662f\u76ee\u524d\u5355\u76ee\u89c6\u89c93D\u68c0\u6d4b\u7684SOTA,\u4f46\u662f\u989d\u5916\u51fa\u5f69\u7684\u5730\u65b9\u5728\u4e8e\u5176\u5bf9RGB\u4fe1\u606f\u4ee5\u53ca\u6df1\u5ea6\u4fe1\u606f\u878d\u5408\u65f6\u7684\u505a\u6cd5\u3002","title":"Accurate Monocular Object Detection via Color-Embedded 3D Reconstruction for Autonomous Driving"},{"location":"3dDetection/AM3D/#_1","text":"\u5bf9\u5355\u4e00\u56fe\u50cf\u5206\u522b\u4f7f\u7528RPN\u63d0\u53d6RoI\u4ee5\u53ca\u4f7f\u7528\u6df1\u5ea6\u7f51\u7edc\u751f\u6210\u6df1\u5ea6\u4fe1\u606f\uff0c\u7136\u540e\u5bf9\u63d0\u53d6\u51fa\u6765\u7684\u533a\u57df\uff0c\u8fdb\u884c\u7b80\u5355\u7684\u6570\u636e\u8f6c\u6362\u3001\u5206\u5272\u3001\u878d\u5408\u68c0\u6d4b\u56de\u5f52","title":"\u4e3b\u8981\u7ed3\u6784\u4e0e\u6d41\u7a0b\u56fe"},{"location":"3dDetection/AM3D/#_2","text":"","title":"\u5c40\u90e8\u8be6\u89e3"},{"location":"3dDetection/AM3D/#_3","text":"\u5df2\u77e5\u6df1\u5ea6d\uff0c\u4f7f\u7528 \\left\\{\\begin{array}{l}{z=d} \\\\ {x=\\left(u-C_{x}\\right) * z / f} \\\\ {y=\\left(v-C_{y}\\right) * z / f}\\end{array}\\right. \u5c06RoI\u533a\u57df\u8f6c\u6362\u4e3a\u76ee\u6807\u70b9\u4e91(\u5bc6\u96c6\u8868\u8fbe)\u3002","title":"\u6570\u636e\u8f6c\u6362"},{"location":"3dDetection/AM3D/#_4","text":"\u65b9\u6cd5\u7b80\u5355\uff0c\u5728RoI\u533a\u57df\u5185\uff0c\u6c42\u51fa\u6df1\u5ea6\u5e73\u5747\u503c\uff0c\u6bd4\u5747\u503c\u9ad8\u51fa\u4e00\u4e2a\u9608\u503c\u4ee5\u4e0a\u7684\u5224\u65ad\u4e3a\u80cc\u666f\u70b9 S^{\\prime}=\\left\\{p | p_{v} \\leq \\frac{\\sum_{p \\in S} p_{v}}{|S|}+r, p \\in S\\right\\} \u5e76\u4ece\u4e2d\u968f\u673a\u9009\u53d6\u4e00\u5b9a\u91cf\u7684\u70b9\u4f5c\u4e3a\u8f93\u51fa\u70b9\uff0c\u5927\u5c0f\u4e00\u81f4\u4fbf\u4e8e\u540e\u671f\u5904\u7406","title":"\u70b9\u4e91\u5206\u5272"},{"location":"3dDetection/AM3D/#_6","text":"\u7528\u4e00\u4e2a\u7ecf\u5178 \u6587\u7ae0 \u7684\u65b9\u6cd5\uff0c\u5229\u7528\u4e00\u4e2a\u5c0f\u7f51\u7edc\u4f30\u8ba1\u51faRoI\u7684\u4e2d\u5fc3\uff0c\u7136\u540e\u5c06\u6240\u6709\u70b9\u8f6c\u5230\u76f8\u5bf9\u5750\u6807\u7cfb\u4e2d S^{\\prime \\prime}=\\left\\{p | p-\\delta, p \\in S^{\\prime}\\right\\} \u7136\u540e\u7528pointnet\u9884\u6d4b","title":"\u5750\u6807\u8f6c\u6362"},{"location":"3dDetection/AM3D/#_7","text":"\u7528\u5982\u56fe\u65b9\u5f0f\u878d\u5408\u70b9\u4e91\u4ee5\u53ca\u5f69\u8272\u70b9\u3002 G \u662f\u4e00\u4e2a\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u5f97\u5230\u5b83\u7684\u516c\u5f0f\u662f G = \\sigma(f([F^{xyz}_{max}, F^{xyz}_{avg}])) ,\u6709\u4e00\u70b9 CBAM \u7684\u6548\u679c\uff0c \u540e\u9762\u7684\u70b9\u4e58\u4e0e\u76f8\u52a0\u53ef\u4ee5\u5199\u6210 \\mathbf{F}^{x y z} \\leftarrow \\mathbf{F}^{x y z}+\\mathbf{G} \\odot \\mathbf{F}^{r g b} \u53e6\u4e00\u65b9\u9762\uff0c\u4ece\u56fe\u4e2d\u76842D RoI\u4e2d\uff0c\u4f7f\u7528RoIAlign\u8c03\u5230 128\\times 128 \uff0c\u7528CNN\u63d0\u53d6\u4e00\u4e2a\u7279\u5f81\u5411\u91cf\uff0c\u5e76\u8054","title":"\u878d\u5408"},{"location":"3dDetection/AM3D/#_8","text":"\u4e24\u9636\u6bb5\u8bad\u7ec3\uff0c\u5148\u8bad\u7ec3\u4e24\u4e2a\u4e2d\u95f4\u7f51\u7edc\uff0c\u7136\u540e\u53ea\u75283D\u4fe1\u606f\u8bad\u7ec3\u6574\u4e2a\u7f51\u7edc \u635f\u5931\u51fd\u6570\u5305\u62ec\uff0c\u4e2d\u95f4\u8f7b\u91cf\u7ea7\u7684\u5bf9center\u7684\u4f30\u8ba1\uff0c\u9884\u6d4b\u8f93\u51fa\u7684corner loss(8\u4e2a\u89d2)","title":"\u8bad\u7ec3\u7ec6\u8282"},{"location":"3dDetection/CDN/","text":"Wasserstein Distances for Stereo Disparity Estimation \u8fd9\u7bc7paper\u63d0\u51fa\u4e86\u53cc\u76ee\u5339\u914d\u7684\u4e00\u4e2a\u65b0\u7684\u8f93\u51fa\u65b9\u5f0f\u4e0e\u8bad\u7ec3\u65b9\u5f0f\uff0c\u4f5c\u8005\u5c06\u5176\u66ff\u6362\u5230\u4e0d\u540c\u7684\u53cc\u76ee\u5339\u914d\u4ee5\u53ca\u53cc\u76ee\u68c0\u6d4b\u7684\u65b9\u6848\u4e2d\uff0c\u90fd\u5f97\u5230\u4e86\u76f4\u63a5\u7684\u6027\u80fd\u63d0\u5347\u3002 \u8f93\u51fa\u65b9\u5f0f \u6b64\u524d\u7684\u53cc\u76ee\u5339\u914d\u662f\u5efa\u7acb\u5728\u5355\u6a21\u9884\u6d4b\u7684\u5047\u8bbe\u4e0a\u7684\uff0c\u6bcf\u4e00\u4e2a\u70b9\u9884\u6d4b\u4e00\u4e2a\u6982\u7387\uff0c\u7136\u540e\u671f\u671b\u5c06\u7ed3\u679c\u8bad\u7ec3\u6210\u4e3a\u4e00\u4e2a\u5355\u5cf0\u7684\u9ad8\u65af\u5206\u5e03\u3002 \u4f46\u662f\u4f5c\u8005\u6307\u51fa\uff0c\u5728\u7269\u4f53\u8fb9\u754c\u4e0a\u7684\u70b9\uff0c\u5927\u6982\u7387\u5f97\u5230\u7684disparity\u662f\u4e00\u4e2a\u53cc\u6a21\u7684\u5206\u5e03(disparity\u53ef\u80fd\u5bf9\u5e94\u524d\u666f\u4e5f\u53ef\u80fd\u5bf9\u5e94\u540e\u666f)\uff0c\u5982\u679c\u76f4\u63a5\u5bf9\u7ed3\u679c\u8fdb\u884c\u52a0\u6743\u5e73\u5747\uff0c\u5c31\u4f1a\u89c2\u5bdf\u5230\u50cf P-lidar \u6587\u7ae0\u56fe\u7247\u4e2d\u770b\u5230\u7684\u60c5\u51b5\uff0c\u4e5f\u5c31\u662f\u8fb9\u7f18\u70b9\u6d12\u843d\u5728\u7269\u4f53\u524d\u666f\u4e0e\u540e\u666f\u4e4b\u95f4\u3002 \u4f5c\u8005\u7ed9\u51fa\u7684\u65b9\u6848\u662f\u8ba9\u6bcf\u4e00\u4e2abase disparity\u72ec\u7acb\u5730\u8ba1\u7b97ground truth\u4e0e\u81ea\u5df1\u7684offset\u4ee5\u53ca\u6982\u7387\uff0c\u7f51\u7edc\u7684\u8f93\u51fa\u5219\u662f\u76f4\u63a5\u8f93\u51fa\u5176\u4e2d\u6982\u7387\u6700\u9ad8\u7684\u6a21\u6001\u3002 \u8bad\u7ec3\u65b9\u5f0f \u5bf9\u4e8e\u5355\u6a21\u6001\u8bad\u7ec3\uff0c\u4f5c\u8005\u63d0\u51fa\u4f7f\u7528wasserstein\u8ddd\u79bb\u8fdb\u884c\u8bad\u7ec3: \\begin{aligned} W_{p}\\left(\\tilde{p}, p^{\\star}\\right)=\\left(\\mathbb{E}_{\\tilde{p}}\\left\\|d^{\\prime}-d^{*}\\right\\|^{p}\\right)^{1 / p} &=\\left(\\sum_{d \\in \\mathcal{D}} p(d \\mid u, v)\\left\\|d+b(u, v, d)-d^{\\star}\\right\\|^{p}\\right)^{1 / p} \\\\ &=\\left(\\sum_{d \\in \\mathcal{D}} \\operatorname{softmax}\\left(-S_{\\text {disp }}(u, v, d)\\right)\\left\\|d+b(u, v, d)-d^{\\star}\\right\\|^{p}\\right)^{1 / p} \\end{aligned}","title":"Wasserstein Distances for Stereo Disparity Estimation"},{"location":"3dDetection/CDN/#wasserstein-distances-for-stereo-disparity-estimation","text":"\u8fd9\u7bc7paper\u63d0\u51fa\u4e86\u53cc\u76ee\u5339\u914d\u7684\u4e00\u4e2a\u65b0\u7684\u8f93\u51fa\u65b9\u5f0f\u4e0e\u8bad\u7ec3\u65b9\u5f0f\uff0c\u4f5c\u8005\u5c06\u5176\u66ff\u6362\u5230\u4e0d\u540c\u7684\u53cc\u76ee\u5339\u914d\u4ee5\u53ca\u53cc\u76ee\u68c0\u6d4b\u7684\u65b9\u6848\u4e2d\uff0c\u90fd\u5f97\u5230\u4e86\u76f4\u63a5\u7684\u6027\u80fd\u63d0\u5347\u3002","title":"Wasserstein Distances for Stereo Disparity Estimation"},{"location":"3dDetection/CDN/#_1","text":"\u6b64\u524d\u7684\u53cc\u76ee\u5339\u914d\u662f\u5efa\u7acb\u5728\u5355\u6a21\u9884\u6d4b\u7684\u5047\u8bbe\u4e0a\u7684\uff0c\u6bcf\u4e00\u4e2a\u70b9\u9884\u6d4b\u4e00\u4e2a\u6982\u7387\uff0c\u7136\u540e\u671f\u671b\u5c06\u7ed3\u679c\u8bad\u7ec3\u6210\u4e3a\u4e00\u4e2a\u5355\u5cf0\u7684\u9ad8\u65af\u5206\u5e03\u3002 \u4f46\u662f\u4f5c\u8005\u6307\u51fa\uff0c\u5728\u7269\u4f53\u8fb9\u754c\u4e0a\u7684\u70b9\uff0c\u5927\u6982\u7387\u5f97\u5230\u7684disparity\u662f\u4e00\u4e2a\u53cc\u6a21\u7684\u5206\u5e03(disparity\u53ef\u80fd\u5bf9\u5e94\u524d\u666f\u4e5f\u53ef\u80fd\u5bf9\u5e94\u540e\u666f)\uff0c\u5982\u679c\u76f4\u63a5\u5bf9\u7ed3\u679c\u8fdb\u884c\u52a0\u6743\u5e73\u5747\uff0c\u5c31\u4f1a\u89c2\u5bdf\u5230\u50cf P-lidar \u6587\u7ae0\u56fe\u7247\u4e2d\u770b\u5230\u7684\u60c5\u51b5\uff0c\u4e5f\u5c31\u662f\u8fb9\u7f18\u70b9\u6d12\u843d\u5728\u7269\u4f53\u524d\u666f\u4e0e\u540e\u666f\u4e4b\u95f4\u3002 \u4f5c\u8005\u7ed9\u51fa\u7684\u65b9\u6848\u662f\u8ba9\u6bcf\u4e00\u4e2abase disparity\u72ec\u7acb\u5730\u8ba1\u7b97ground truth\u4e0e\u81ea\u5df1\u7684offset\u4ee5\u53ca\u6982\u7387\uff0c\u7f51\u7edc\u7684\u8f93\u51fa\u5219\u662f\u76f4\u63a5\u8f93\u51fa\u5176\u4e2d\u6982\u7387\u6700\u9ad8\u7684\u6a21\u6001\u3002","title":"\u8f93\u51fa\u65b9\u5f0f"},{"location":"3dDetection/CDN/#_2","text":"\u5bf9\u4e8e\u5355\u6a21\u6001\u8bad\u7ec3\uff0c\u4f5c\u8005\u63d0\u51fa\u4f7f\u7528wasserstein\u8ddd\u79bb\u8fdb\u884c\u8bad\u7ec3: \\begin{aligned} W_{p}\\left(\\tilde{p}, p^{\\star}\\right)=\\left(\\mathbb{E}_{\\tilde{p}}\\left\\|d^{\\prime}-d^{*}\\right\\|^{p}\\right)^{1 / p} &=\\left(\\sum_{d \\in \\mathcal{D}} p(d \\mid u, v)\\left\\|d+b(u, v, d)-d^{\\star}\\right\\|^{p}\\right)^{1 / p} \\\\ &=\\left(\\sum_{d \\in \\mathcal{D}} \\operatorname{softmax}\\left(-S_{\\text {disp }}(u, v, d)\\right)\\left\\|d+b(u, v, d)-d^{\\star}\\right\\|^{p}\\right)^{1 / p} \\end{aligned}","title":"\u8bad\u7ec3\u65b9\u5f0f"},{"location":"3dDetection/CameraDistanceAware/","text":"Camera Distance-aware Top-down Approach for 3D Multi-person Pose Estimation from a Single RGB Image \u8fd9\u7bc7\u8bba\u6587\u91c7\u7528\u4e86\u57fa\u4e8e\u51e0\u4f55\u4e0e\u76f8\u673a\u7684\u7279\u6027\u7684\u65b9\u5f0f\u5bf9\u4eba\u7684\u80a2\u4f53\u8fdb\u884c3D detection\uff0cpose estimation\u7684\u8f93\u51fa\u662f\u5173\u8282\u5750\u6807\uff0c\u672c\u6587\u8fdb\u4e00\u6b65\u9700\u8981\u8ba1\u7b97\u4eba\u4e0e\u76f8\u673a\u7684\u8ddd\u79bb\u3002\u4ee3\u7801\u5206\u4e24\u90e8\u5206\u5f00\u6e90 \u5206\u522b\u662f rootnet \u4e0e posenet . \u603b\u4f53\u6d41\u7a0b \u6d41\u7a0b\u5206\u4e3a\u4e09\u4e2a\u7f51\u7edc\uff0c\u7b2c\u4e00\u4e2a\u7f51\u7edc\u4e3aDetectNet,\u7b80\u5355\u6765\u8bf4\u5c31\u662ftwo-stage object detection\u7684proposal\u9636\u6bb5\uff0c\u91c7\u7528\u7684res\u7f51\u7edc\u4ee5\u53caroialign\u64cd\u4f5c\u7686\u4e3a\u5e38\u89c4\u3002 \u7b2c\u4e8c\u4e2a\u7f51\u7edc\u4e3arootNet\u4e3b\u8981\u8d1f\u8d23\u9884\u6d4b\u4eba\u4f53\u57283\u7ef4\u7a7a\u95f4\u4e2d\u7684\u4f4d\u7f6e\uff0c\u5728\u4e0b\u6587\u8bb2\u89e3\u3002 \u7b2c\u4e09\u4e2a\u7f51\u7edc\u4e3aPoseNet\uff0c\u91c7\u7528\u7684\u7c7b\u4f3c\u4e8e\u5e38\u89c4\u7684pose-estimation\u7f51\u7edc\uff0c\u8f93\u51fa\u7684\u662f\u5c0f\u56fe\u7247\u4e2d\u4eba\u4f53\u5404\u4e2a\u5173\u8282\u7684heatmap\u3002 RootNet rootnet\u4e3b\u8981\u89c2\u6d4b\u7684\u662f\u56fe\u7247\u4e2d2D\u6846\u5927\u5c0f\u4e0e\u6df1\u5ea6\u7684\u4e00\u4e2a\u76f8\u5173\u6027 \u7f51\u7edc\u7ed3\u6784\u5982\u4e0b\uff0c k=\\sqrt{\\alpha_{x} \\alpha_{y} \\frac{A_{r e a l}}{A_{i m g}}} \u5176\u4e2d \\alpha_{x} \u4e3a\u76f8\u673a\u5185\u53c2\u7684 f_x , A \u5206\u522b\u4e3a\u5b9e\u9645\u9762\u79ef\u5927\u5c0f\u4e0e\u56fe\u7247\u4e2d\u7684\u5927\u5c0f\u3002 A_{real} \u4e3a\u4e00\u4e2a\u4f30\u8ba1\u503c\uff0c\u7f51\u7edc\u7684\u8d23\u4efb\u5728\u4e8e\u4f30\u8ba1\u8fd9\u4e2ak\u503c.","title":"Camera Distance-aware Top-down Approach for 3D Multi-person Pose Estimation from a Single RGB Image"},{"location":"3dDetection/CameraDistanceAware/#camera-distance-aware-top-down-approach-for-3d-multi-person-pose-estimation-from-a-single-rgb-image","text":"\u8fd9\u7bc7\u8bba\u6587\u91c7\u7528\u4e86\u57fa\u4e8e\u51e0\u4f55\u4e0e\u76f8\u673a\u7684\u7279\u6027\u7684\u65b9\u5f0f\u5bf9\u4eba\u7684\u80a2\u4f53\u8fdb\u884c3D detection\uff0cpose estimation\u7684\u8f93\u51fa\u662f\u5173\u8282\u5750\u6807\uff0c\u672c\u6587\u8fdb\u4e00\u6b65\u9700\u8981\u8ba1\u7b97\u4eba\u4e0e\u76f8\u673a\u7684\u8ddd\u79bb\u3002\u4ee3\u7801\u5206\u4e24\u90e8\u5206\u5f00\u6e90 \u5206\u522b\u662f rootnet \u4e0e posenet .","title":"Camera Distance-aware Top-down Approach for 3D Multi-person Pose Estimation from a Single RGB Image"},{"location":"3dDetection/CameraDistanceAware/#_1","text":"\u6d41\u7a0b\u5206\u4e3a\u4e09\u4e2a\u7f51\u7edc\uff0c\u7b2c\u4e00\u4e2a\u7f51\u7edc\u4e3aDetectNet,\u7b80\u5355\u6765\u8bf4\u5c31\u662ftwo-stage object detection\u7684proposal\u9636\u6bb5\uff0c\u91c7\u7528\u7684res\u7f51\u7edc\u4ee5\u53caroialign\u64cd\u4f5c\u7686\u4e3a\u5e38\u89c4\u3002 \u7b2c\u4e8c\u4e2a\u7f51\u7edc\u4e3arootNet\u4e3b\u8981\u8d1f\u8d23\u9884\u6d4b\u4eba\u4f53\u57283\u7ef4\u7a7a\u95f4\u4e2d\u7684\u4f4d\u7f6e\uff0c\u5728\u4e0b\u6587\u8bb2\u89e3\u3002 \u7b2c\u4e09\u4e2a\u7f51\u7edc\u4e3aPoseNet\uff0c\u91c7\u7528\u7684\u7c7b\u4f3c\u4e8e\u5e38\u89c4\u7684pose-estimation\u7f51\u7edc\uff0c\u8f93\u51fa\u7684\u662f\u5c0f\u56fe\u7247\u4e2d\u4eba\u4f53\u5404\u4e2a\u5173\u8282\u7684heatmap\u3002","title":"\u603b\u4f53\u6d41\u7a0b"},{"location":"3dDetection/CameraDistanceAware/#rootnet","text":"rootnet\u4e3b\u8981\u89c2\u6d4b\u7684\u662f\u56fe\u7247\u4e2d2D\u6846\u5927\u5c0f\u4e0e\u6df1\u5ea6\u7684\u4e00\u4e2a\u76f8\u5173\u6027 \u7f51\u7edc\u7ed3\u6784\u5982\u4e0b\uff0c k=\\sqrt{\\alpha_{x} \\alpha_{y} \\frac{A_{r e a l}}{A_{i m g}}} \u5176\u4e2d \\alpha_{x} \u4e3a\u76f8\u673a\u5185\u53c2\u7684 f_x , A \u5206\u522b\u4e3a\u5b9e\u9645\u9762\u79ef\u5927\u5c0f\u4e0e\u56fe\u7247\u4e2d\u7684\u5927\u5c0f\u3002 A_{real} \u4e3a\u4e00\u4e2a\u4f30\u8ba1\u503c\uff0c\u7f51\u7edc\u7684\u8d23\u4efb\u5728\u4e8e\u4f30\u8ba1\u8fd9\u4e2ak\u503c.","title":"RootNet"},{"location":"3dDetection/DSGN/","text":"DSGN: Deep Stereo Geometry Network for 3D Object Detection \u8fd9\u7bc7\u8bba\u6587\u4e0d\u540c\u4e8e\u6b64\u524d\u7684\u4f7f\u7528Pseudo-lidar\u7684\u65b9\u5f0f\uff0c\u91c7\u7528\u4e86\u7c7b\u4f3c\u4e8eplane-sweeping \u7684\u601d\u8def\u3002\u5c06\u53cc\u76ee\u56fe\u50cf\u8f6c\u6362\u4e3a\u4e09\u7ef4\u5750\u6807\u4e0b\u7684\u4fe1\u606f\u3002 \u5728\u603b\u4f53\u4e0a\u6765\u8bf4\u8ba1\u7b97\u786e\u5b9e\u5f88\u66b4\u529b\uff0cinference\u4e5f\u5f88\u6162\uff0c\u4f46\u662f\u5b83\u7684\u7ed3\u6784\u80fd\u8ba9\u5b83\u540c\u65f6\u8fdb\u884c\u53cc\u76ee\u6df1\u5ea6\u4f30\u8ba1\uff0c\u4e5f\u53ef\u4ee5\u8bfb\u53d6\u70b9\u4e91\u4f5c\u4e3a\u8f85\u52a9\u7684\u76d1\u7763\u4fe1\u606f\uff0c\u5e76\u7ecf\u8fc7\u6d4b\u8bd5\u80fd\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002 Update: 20200409: \u4f5c\u8005\u5df2\u7ecf\u5f00\u6e90\uff0c\u91cc\u9762\u6709CostVolume\u7684cuda\u5b9e\u73b0\uff0c\u503c\u5f97\u5173\u6ce8\u5b66\u4e60 Pipeline \u4ee5\u53cc\u76ee\u4e3a\u4f8b\u5b50\uff0c\u5982\u56fe\uff0c\u4e24\u5e27\u56fe\u50cf\u540c\u65f6\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c Plane Sweep Volumn PSV\u6a21\u5757\u91cc\u9762\u6bcf\u4e00\u4e2aindex (u,v,d) \u662f\u5728\u6240\u8c13\u7684\u56fe\u7247\u5750\u6807\u4e2d\u8868\u8fbe\u7684,\u6240\u4ee5\u8fd9\u91cc\u7684\u505a\u6cd5\u662f\uff0c\u5bf9\u6bcf\u4e00\u4e2a\u5e73\u9762 d_{i} ,\u5c06\u53f3\u76ee\u7684\u7279\u5f81\u5728\u8fd9\u4e2a\u5e73\u9762\u5185\u627e\u5230\u4e0e\u5de6\u76ee\u5bf9\u5e94\u7684\u5750\u6807\uff0c\u5c06\u7279\u5f81concat\u8d77\u6765\u3002\u7136\u540e\u75283D\u5377\u79ef\u7684 hourglass \u6a21\u578b\u8fdb\u884c\u5904\u7406. 3D Geometry Volumn \u4e0b\u4e00\u6b65\u8981\u505a\u7684\u5c31\u662f\u5c06\u5efa\u7acb\u5728image-depth space\u7684PSV\u7279\u5f81\u6295\u5f71\u5230\u4e16\u754c\u5750\u6807\u4e2d\uff0c\u8fd9\u91cc\u7684\u505a\u6cd5\u662f\uff0c\u5bf9\u4e8e\u6bcf\u4e00\u4e2aworld space\u70b9\uff0c\u627e\u5230\u5b83\u5728 image-depth space\u4e2d\u7684\u4f4d\u7f6e\uff0c\u4f7f\u7528\u4e09\u5411\u63d2\u503c\u5f97\u5230\u5176\u503c\u3002(differential warping) \u68c0\u6d4b\u5206\u652f \u4e4b\u540e\u4f7f\u75283D \u5377\u79ef\u4e0e2D hourglass\uff0c\u7c7b\u4f3c OFT \u6216\u8005 MV3D \u7684\u6a21\u5f0f\u538b\u7f29\u5904\u7406BEV\u56fe\u7247,\u7269\u4f53\u68c0\u6d4b\u7684\u6a21\u5f0f\u662f\u6309\u7167 FCOS \u7684\u7b97\u6cd5\u8fdb\u884c\u7684\uff0c\u8fd9\u662f\u4e00\u79cdanchor-less\u7684\u7b97\u6cd5\u3002 \u6df1\u5ea6\u4f30\u8ba1\u5206\u652f\uff0c\u7ecf\u8fc7\u51e0\u4e2aConv3D\u4ee5\u53ca\u4e0a\u91c7\u6837\u5904\u7406\uff0c\u5f97\u5230 (H_1,W_1,D_1,1) \u7684\u77e9\u9635\u3002\u5bf9 D \u7ef4\u5ea6\u53d6softmin\u5e76\u52a0\u6743\u6c42\u548c\uff0c\u5f97\u5230\u5bf9\u6df1\u5ea6\u7684\u4f30\u8ba1\u3002 \u540e\u9762\u7684\u5b9e\u9a8c\u4e2d\uff0c\u4f5c\u8005\u7684implementation\u662f\u540c\u65f6\u7528\u70b9\u4e91\u4e0e\u7269\u4f53\u5728\u4e24\u4e2a\u5206\u652f\u4e0a\u540c\u65f6\u8fdb\u884c\u76d1\u7763\uff0c\u5f97\u5230\u7684\u6027\u80fd\u662f\u6700\u597d\u7684\u3002\u53e6\u5916\u672c\u6587\u91cc\u9762\u6240\u6709\u7684\u6a21\u578b\u90fd\u6ca1\u6709pretrain\uff0c\u90fd\u662ftrain from scratch\u3002","title":"DSGN: Deep Stereo Geometry Network for 3D Object Detection"},{"location":"3dDetection/DSGN/#dsgn-deep-stereo-geometry-network-for-3d-object-detection","text":"\u8fd9\u7bc7\u8bba\u6587\u4e0d\u540c\u4e8e\u6b64\u524d\u7684\u4f7f\u7528Pseudo-lidar\u7684\u65b9\u5f0f\uff0c\u91c7\u7528\u4e86\u7c7b\u4f3c\u4e8eplane-sweeping \u7684\u601d\u8def\u3002\u5c06\u53cc\u76ee\u56fe\u50cf\u8f6c\u6362\u4e3a\u4e09\u7ef4\u5750\u6807\u4e0b\u7684\u4fe1\u606f\u3002 \u5728\u603b\u4f53\u4e0a\u6765\u8bf4\u8ba1\u7b97\u786e\u5b9e\u5f88\u66b4\u529b\uff0cinference\u4e5f\u5f88\u6162\uff0c\u4f46\u662f\u5b83\u7684\u7ed3\u6784\u80fd\u8ba9\u5b83\u540c\u65f6\u8fdb\u884c\u53cc\u76ee\u6df1\u5ea6\u4f30\u8ba1\uff0c\u4e5f\u53ef\u4ee5\u8bfb\u53d6\u70b9\u4e91\u4f5c\u4e3a\u8f85\u52a9\u7684\u76d1\u7763\u4fe1\u606f\uff0c\u5e76\u7ecf\u8fc7\u6d4b\u8bd5\u80fd\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002 Update: 20200409: \u4f5c\u8005\u5df2\u7ecf\u5f00\u6e90\uff0c\u91cc\u9762\u6709CostVolume\u7684cuda\u5b9e\u73b0\uff0c\u503c\u5f97\u5173\u6ce8\u5b66\u4e60","title":"DSGN: Deep Stereo Geometry Network for 3D Object Detection"},{"location":"3dDetection/DSGN/#pipeline","text":"\u4ee5\u53cc\u76ee\u4e3a\u4f8b\u5b50\uff0c\u5982\u56fe\uff0c\u4e24\u5e27\u56fe\u50cf\u540c\u65f6\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c","title":"Pipeline"},{"location":"3dDetection/DSGN/#plane-sweep-volumn","text":"PSV\u6a21\u5757\u91cc\u9762\u6bcf\u4e00\u4e2aindex (u,v,d) \u662f\u5728\u6240\u8c13\u7684\u56fe\u7247\u5750\u6807\u4e2d\u8868\u8fbe\u7684,\u6240\u4ee5\u8fd9\u91cc\u7684\u505a\u6cd5\u662f\uff0c\u5bf9\u6bcf\u4e00\u4e2a\u5e73\u9762 d_{i} ,\u5c06\u53f3\u76ee\u7684\u7279\u5f81\u5728\u8fd9\u4e2a\u5e73\u9762\u5185\u627e\u5230\u4e0e\u5de6\u76ee\u5bf9\u5e94\u7684\u5750\u6807\uff0c\u5c06\u7279\u5f81concat\u8d77\u6765\u3002\u7136\u540e\u75283D\u5377\u79ef\u7684 hourglass \u6a21\u578b\u8fdb\u884c\u5904\u7406.","title":"Plane Sweep Volumn"},{"location":"3dDetection/DSGN/#3d-geometry-volumn","text":"\u4e0b\u4e00\u6b65\u8981\u505a\u7684\u5c31\u662f\u5c06\u5efa\u7acb\u5728image-depth space\u7684PSV\u7279\u5f81\u6295\u5f71\u5230\u4e16\u754c\u5750\u6807\u4e2d\uff0c\u8fd9\u91cc\u7684\u505a\u6cd5\u662f\uff0c\u5bf9\u4e8e\u6bcf\u4e00\u4e2aworld space\u70b9\uff0c\u627e\u5230\u5b83\u5728 image-depth space\u4e2d\u7684\u4f4d\u7f6e\uff0c\u4f7f\u7528\u4e09\u5411\u63d2\u503c\u5f97\u5230\u5176\u503c\u3002(differential warping)","title":"3D Geometry Volumn"},{"location":"3dDetection/DSGN/#_1","text":"\u4e4b\u540e\u4f7f\u75283D \u5377\u79ef\u4e0e2D hourglass\uff0c\u7c7b\u4f3c OFT \u6216\u8005 MV3D \u7684\u6a21\u5f0f\u538b\u7f29\u5904\u7406BEV\u56fe\u7247,\u7269\u4f53\u68c0\u6d4b\u7684\u6a21\u5f0f\u662f\u6309\u7167 FCOS \u7684\u7b97\u6cd5\u8fdb\u884c\u7684\uff0c\u8fd9\u662f\u4e00\u79cdanchor-less\u7684\u7b97\u6cd5\u3002 \u6df1\u5ea6\u4f30\u8ba1\u5206\u652f\uff0c\u7ecf\u8fc7\u51e0\u4e2aConv3D\u4ee5\u53ca\u4e0a\u91c7\u6837\u5904\u7406\uff0c\u5f97\u5230 (H_1,W_1,D_1,1) \u7684\u77e9\u9635\u3002\u5bf9 D \u7ef4\u5ea6\u53d6softmin\u5e76\u52a0\u6743\u6c42\u548c\uff0c\u5f97\u5230\u5bf9\u6df1\u5ea6\u7684\u4f30\u8ba1\u3002 \u540e\u9762\u7684\u5b9e\u9a8c\u4e2d\uff0c\u4f5c\u8005\u7684implementation\u662f\u540c\u65f6\u7528\u70b9\u4e91\u4e0e\u7269\u4f53\u5728\u4e24\u4e2a\u5206\u652f\u4e0a\u540c\u65f6\u8fdb\u884c\u76d1\u7763\uff0c\u5f97\u5230\u7684\u6027\u80fd\u662f\u6700\u597d\u7684\u3002\u53e6\u5916\u672c\u6587\u91cc\u9762\u6240\u6709\u7684\u6a21\u578b\u90fd\u6ca1\u6709pretrain\uff0c\u90fd\u662ftrain from scratch\u3002","title":"\u68c0\u6d4b\u5206\u652f"},{"location":"3dDetection/Disentangling_Monocular_3D_Object_Detection/","text":"Disentangling Monocular 3D Object Detection \u8fd9\u7bc7\u8bba\u6587\u76ee\u524d\u5728nuScene\u4ee5\u53caKitti\u4e0a\u5b9e\u73b0\u4e86\u5355\u76ee\u89c6\u89c9\u4e09\u7ef4\u68c0\u6d4b\u7684SOTA\u7684\u6027\u80fd\u3002 \u4f7f\u7528Two Stage\u7684\u68c0\u6d4b\u65b9\u5f0f\uff0c\u4e0eM3D-RPN\u7c7b\u4f3c\uff0c\u5229\u7528\u4e86\u591a\u5c3a\u5ea6\u7279\u5f81\uff0c\u589e\u52a0\u4e86\u591a\u4e2a\u7279\u6b8a\u8bbe\u8ba1\u7684Loss function \u6574\u4f53\u7ed3\u6784 \u7f51\u7edc\u5206\u4e3abackbone, 2D head, 3d head\u4e09\u4e2a\u90e8\u5206\uff0c\u7ed3\u6784\u5206\u522b\u4e3a \u76f4\u89c9\u4e0a\u6765\u8bf4\uff0c\u5c31\u662f\u4f7f\u7528Res34\u4ee5\u53cafeature pyramid network(FPN)\u63d0\u53d6\u591a\u5c3a\u5ea6\u7279\u5f81\uff0c\u8f93\u51fa\u591a\u4e2afeature map\uff0c\u6bcf\u4e00\u4e2afeature map\u8f93\u51fa2D detection Output.\u5bf9\u6bcf\u4e00\u4e2aProposal\uff0c\u4f7f\u7528ROIAlign\u5c42\u5c06\u5bf9\u5e94\u6846resize\u4e3a14*14\uff0c\u63d0\u53d6\u51fa\u7279\u5f81\u540e\u4e0e2D\u8f93\u51fa\u8fde\u63a5\u518d\u8f93\u5165\u5230\u5168\u8fde\u63a5\u5c42\uff0c\u6700\u7ec8\u8f93\u51fa3D output. \u6ce8\u610f\u5176\u4e2d\u7684iABN\u4e3aIn-Place Activated BatchNorm,\u662f\u4e00\u4e2a\u53ef\u4ee5\u8f83\u5c11training time memory cost\u7684\u6a21\u5757\uff0c\u5176pytorch\u5b9e\u73b0\u53ef\u4ee5\u5728 \u6b64\u5904 \u627e\u5230 \u5176\u8f93\u51fa\u5b9a\u4e49: \u6ce8\u610f\u65cb\u8f6c\u8f93\u51fa\u7684\u662f\u56db\u5143\u6570 \u635f\u5931\u51fd\u6570 2D Loss Focal loss \u6e90\u81ea\u4e0e \u8fd9\u7bc7\u6587\u7ae0 L_{2 \\mathrm{D}}^{\\mathrm{conf}}\\left(p_{2 \\mathrm{D}}, y\\right)=-\\alpha y\\left(1-p_{2 \\mathrm{D}}\\right)^{\\gamma} \\log p_{2 \\mathrm{D}}-\\overline{\\alpha} \\overline{y} p_{2 \\mathrm{D}}^{\\gamma} \\log \\left(1-p_{2 \\mathrm{D}}\\right) function focal_loss_y(x, gamma){ return - Math.pow(1-x, gamma) * Math.log(x) } function get_focal_loss_list(p, gamma){ focal = [] for (j = 0; j < 100;j++){ focal.push(focal_loss_y(p[j], gamma)) } return focal } focalLoss = document.getElementById('focalLoss'); var p = []; for (i = 0; i < 100;i++){ p.push(i * 0.01); } var focal = get_focal_loss_list(p, 0.2) slider_steps = [] for (i = 0.2; i < 4; i += 0.2){ slider_steps.push( { method: 'animate', label: Math.floor(i * 100) /100, args: [ { data: [{ x:p, y: get_focal_loss_list(p, i)}], }, { transition: {duration: 20}, frame: {duration: 20, redraw: false}, } ] } ) } Plotly.plot(focalLoss, [{ x: p, y: focal, }], { title: 'Focal Loss for positive samples', xaxis: { title: 'p' }, yaxis: { title: 'loss' }, sliders: [{ pad: {t: 30}, currentvalue: { xanchor: 'right', prefix: 'gamma: ', font: { color: '#888', size: 20 } }, steps: slider_steps }] }); Loss based on sIoU L_{2 \\mathrm{D}}^{\\mathrm{bb}}(\\boldsymbol{b}, \\hat{\\boldsymbol{b}})=1-\\operatorname{sIoU}(\\boldsymbol{b}, \\hat{\\boldsymbol{b}}) sIoU\u7684\u8ba1\u7b97\u516c\u5f0f\u4e3a\uff1a \u5b9e\u9645\u4e0a\u6709\u4ee5\u4e0b\u4e94\u79cd\u60c5\u51b5\uff0csIoU\u4f1a\u5728[-1, 1]\u4e4b\u95f4\uff0c 3D Loss Regression \u7f51\u7edc\u8f93\u51fa10\u4e2a\u53c2\u6570x,y,z,w,h,l,quarternion,\u4f7f\u7528lifting transformation \u5c06\u8fd9\u7ec4\u53c2\u6570\u8f6c\u6362\u4e3a\u76ee\u6807\u53c2\u65708\u4e2a\uff0c\u5bf98\u4e2a\u53c2\u6570\u8fdb\u884c\u56de\u5f52 Classification Focal loss lifting transform \u5b9e\u9645\u4e0a\u5c31\u662f\u5c06\u9884\u6d4b\u70b9\u63d0\u5347\u4e3a8\u4e2a\u89d2\u70b9 \u4ee4 z, c = (u_c, v_c), s = (W,H,D), q \u4e3a\u9884\u6d4b\u7684\u4e2d\u5fc3\u70b9\u6df1\u5ea6\u3001\u5728\u56fe\u4e2d\u6295\u5f71\u7684\u5750\u6807\uff0c\u8f66\u8f86\u4e09\u7ef4\u4ee5\u53ca\u56db\u5143\u6570\u3002K\u4e3a\u76f8\u673a\u5185\u53c2 K=\\left[\\begin{array}{ccc}{f_{x}} & {0} & {c_{x}} \\\\ {0} & {f_{y}} & {c_{y}} \\\\ {0} & {0} & {1}\\end{array}\\right] \u4ee4 C=\\left(\\begin{array}{cc}{\\frac{u_{c}-c_{x}}{f_{x}} z,} & {\\left.\\frac{v_{c}-c_{y}}{f_{y}} z, \\quad z\\right)^{\\top}=\\left(C_{x}, C_{y}, C_{z}\\right)^{\\top}}\\end{array}\\right. \u8fd9\u4e2a\u662f\u4e2d\u5fc3\u70b9\u662f\u5b9e\u9645\u5750\u6807 lifting transform \\mathcal{F} \u4e3a \\mathcal{F}(\\boldsymbol{\\theta})=\\frac{1}{2} R_{\\boldsymbol{q}_{\\mathrm{c}}} S B_{0}+\\boldsymbol{C} Disentangling 2D and 3D Detection Losses \u76f4\u89c9\u6765\u8bf4\uff0c\u4e8c\u7ef4Regression loss\u4e0e\u4e09\u7ef4Regression loss,\u76f4\u63a5\u53e0\u52a0\u7684\u597d\u5904\u662f\u4e24\u8005\u4e0d\u4f1a\u76f8\u4e92\u5f71\u54cd\uff0c\u4f46\u662f\u5b83\u4eec\u4f1a\u4ea7\u751f\u4e0d\u5e73\u8861\uff0c\u5f71\u54cd\u4f18\u5316\u7684\u8fc7\u7a0b \u6bd4\u5982\u5bf9\u4e8e\u672c\u6587\u7684\u4e09\u7ef4\u56de\u5f52\u6765\u8bf4\uff0c\u539f\u59cb\u53c2\u6570\u5206\u4e3a\u56db\u7ec4\uff0c\u4e5f\u5c31\u662f\u6df1\u5ea6\u3001\u76f8\u673a\u5750\u6807\u3001\u4e09\u7ef4\u4ee5\u53ca\u89d2\u5ea6\uff0c\u56de\u5f52\u65f6\u9700\u8981\u8ba1\u7b97\u7684\u53c2\u6570\u662f\u516b\u4e2a\u89d2\u70b9\u7684\u5750\u6807\uff0c\u5176\u4e2d\u9700\u8981\u4e00\u4e2a\u8f6c\u6362\u3002 \u5728\u8ba1\u7b97loss\u65f6\uff0c\u5206\u6210\u56db\u7ec4\u3002\u5176\u4e2d\u7b2c i \u7ec4\u8ba1\u7b97loss\u65f6\uff0c\u7b2c i \u7ec4\u53c2\u6570\u7528\u9884\u6d4b\u503c\uff0c\u5176\u4f59\u7528ground_truth\uff0c\u5982\u6b64\u6bcf\u4e00\u7ec4\u90fd\u4f1a\u5206\u5f00\u4f18\u5316\u3002 \u5177\u4f53\u76f4\u89c9\u770b\u539f\u6587","title":"Disentangling Monocular 3D Object Detection"},{"location":"3dDetection/Disentangling_Monocular_3D_Object_Detection/#disentangling-monocular-3d-object-detection","text":"\u8fd9\u7bc7\u8bba\u6587\u76ee\u524d\u5728nuScene\u4ee5\u53caKitti\u4e0a\u5b9e\u73b0\u4e86\u5355\u76ee\u89c6\u89c9\u4e09\u7ef4\u68c0\u6d4b\u7684SOTA\u7684\u6027\u80fd\u3002 \u4f7f\u7528Two Stage\u7684\u68c0\u6d4b\u65b9\u5f0f\uff0c\u4e0eM3D-RPN\u7c7b\u4f3c\uff0c\u5229\u7528\u4e86\u591a\u5c3a\u5ea6\u7279\u5f81\uff0c\u589e\u52a0\u4e86\u591a\u4e2a\u7279\u6b8a\u8bbe\u8ba1\u7684Loss function","title":"Disentangling Monocular 3D Object Detection"},{"location":"3dDetection/Disentangling_Monocular_3D_Object_Detection/#_1","text":"\u7f51\u7edc\u5206\u4e3abackbone, 2D head, 3d head\u4e09\u4e2a\u90e8\u5206\uff0c\u7ed3\u6784\u5206\u522b\u4e3a \u76f4\u89c9\u4e0a\u6765\u8bf4\uff0c\u5c31\u662f\u4f7f\u7528Res34\u4ee5\u53cafeature pyramid network(FPN)\u63d0\u53d6\u591a\u5c3a\u5ea6\u7279\u5f81\uff0c\u8f93\u51fa\u591a\u4e2afeature map\uff0c\u6bcf\u4e00\u4e2afeature map\u8f93\u51fa2D detection Output.\u5bf9\u6bcf\u4e00\u4e2aProposal\uff0c\u4f7f\u7528ROIAlign\u5c42\u5c06\u5bf9\u5e94\u6846resize\u4e3a14*14\uff0c\u63d0\u53d6\u51fa\u7279\u5f81\u540e\u4e0e2D\u8f93\u51fa\u8fde\u63a5\u518d\u8f93\u5165\u5230\u5168\u8fde\u63a5\u5c42\uff0c\u6700\u7ec8\u8f93\u51fa3D output. \u6ce8\u610f\u5176\u4e2d\u7684iABN\u4e3aIn-Place Activated BatchNorm,\u662f\u4e00\u4e2a\u53ef\u4ee5\u8f83\u5c11training time memory cost\u7684\u6a21\u5757\uff0c\u5176pytorch\u5b9e\u73b0\u53ef\u4ee5\u5728 \u6b64\u5904 \u627e\u5230 \u5176\u8f93\u51fa\u5b9a\u4e49: \u6ce8\u610f\u65cb\u8f6c\u8f93\u51fa\u7684\u662f\u56db\u5143\u6570","title":"\u6574\u4f53\u7ed3\u6784"},{"location":"3dDetection/Disentangling_Monocular_3D_Object_Detection/#_2","text":"","title":"\u635f\u5931\u51fd\u6570"},{"location":"3dDetection/Disentangling_Monocular_3D_Object_Detection/#2d-loss","text":"Focal loss \u6e90\u81ea\u4e0e \u8fd9\u7bc7\u6587\u7ae0 L_{2 \\mathrm{D}}^{\\mathrm{conf}}\\left(p_{2 \\mathrm{D}}, y\\right)=-\\alpha y\\left(1-p_{2 \\mathrm{D}}\\right)^{\\gamma} \\log p_{2 \\mathrm{D}}-\\overline{\\alpha} \\overline{y} p_{2 \\mathrm{D}}^{\\gamma} \\log \\left(1-p_{2 \\mathrm{D}}\\right) function focal_loss_y(x, gamma){ return - Math.pow(1-x, gamma) * Math.log(x) } function get_focal_loss_list(p, gamma){ focal = [] for (j = 0; j < 100;j++){ focal.push(focal_loss_y(p[j], gamma)) } return focal } focalLoss = document.getElementById('focalLoss'); var p = []; for (i = 0; i < 100;i++){ p.push(i * 0.01); } var focal = get_focal_loss_list(p, 0.2) slider_steps = [] for (i = 0.2; i < 4; i += 0.2){ slider_steps.push( { method: 'animate', label: Math.floor(i * 100) /100, args: [ { data: [{ x:p, y: get_focal_loss_list(p, i)}], }, { transition: {duration: 20}, frame: {duration: 20, redraw: false}, } ] } ) } Plotly.plot(focalLoss, [{ x: p, y: focal, }], { title: 'Focal Loss for positive samples', xaxis: { title: 'p' }, yaxis: { title: 'loss' }, sliders: [{ pad: {t: 30}, currentvalue: { xanchor: 'right', prefix: 'gamma: ', font: { color: '#888', size: 20 } }, steps: slider_steps }] }); Loss based on sIoU L_{2 \\mathrm{D}}^{\\mathrm{bb}}(\\boldsymbol{b}, \\hat{\\boldsymbol{b}})=1-\\operatorname{sIoU}(\\boldsymbol{b}, \\hat{\\boldsymbol{b}}) sIoU\u7684\u8ba1\u7b97\u516c\u5f0f\u4e3a\uff1a \u5b9e\u9645\u4e0a\u6709\u4ee5\u4e0b\u4e94\u79cd\u60c5\u51b5\uff0csIoU\u4f1a\u5728[-1, 1]\u4e4b\u95f4\uff0c","title":"2D Loss"},{"location":"3dDetection/Disentangling_Monocular_3D_Object_Detection/#3d-loss","text":"Regression \u7f51\u7edc\u8f93\u51fa10\u4e2a\u53c2\u6570x,y,z,w,h,l,quarternion,\u4f7f\u7528lifting transformation \u5c06\u8fd9\u7ec4\u53c2\u6570\u8f6c\u6362\u4e3a\u76ee\u6807\u53c2\u65708\u4e2a\uff0c\u5bf98\u4e2a\u53c2\u6570\u8fdb\u884c\u56de\u5f52 Classification Focal loss","title":"3D Loss"},{"location":"3dDetection/Disentangling_Monocular_3D_Object_Detection/#lifting-transform","text":"\u5b9e\u9645\u4e0a\u5c31\u662f\u5c06\u9884\u6d4b\u70b9\u63d0\u5347\u4e3a8\u4e2a\u89d2\u70b9 \u4ee4 z, c = (u_c, v_c), s = (W,H,D), q \u4e3a\u9884\u6d4b\u7684\u4e2d\u5fc3\u70b9\u6df1\u5ea6\u3001\u5728\u56fe\u4e2d\u6295\u5f71\u7684\u5750\u6807\uff0c\u8f66\u8f86\u4e09\u7ef4\u4ee5\u53ca\u56db\u5143\u6570\u3002K\u4e3a\u76f8\u673a\u5185\u53c2 K=\\left[\\begin{array}{ccc}{f_{x}} & {0} & {c_{x}} \\\\ {0} & {f_{y}} & {c_{y}} \\\\ {0} & {0} & {1}\\end{array}\\right] \u4ee4 C=\\left(\\begin{array}{cc}{\\frac{u_{c}-c_{x}}{f_{x}} z,} & {\\left.\\frac{v_{c}-c_{y}}{f_{y}} z, \\quad z\\right)^{\\top}=\\left(C_{x}, C_{y}, C_{z}\\right)^{\\top}}\\end{array}\\right. \u8fd9\u4e2a\u662f\u4e2d\u5fc3\u70b9\u662f\u5b9e\u9645\u5750\u6807 lifting transform \\mathcal{F} \u4e3a \\mathcal{F}(\\boldsymbol{\\theta})=\\frac{1}{2} R_{\\boldsymbol{q}_{\\mathrm{c}}} S B_{0}+\\boldsymbol{C}","title":"lifting transform"},{"location":"3dDetection/Disentangling_Monocular_3D_Object_Detection/#disentangling-2d-and-3d-detection-losses","text":"\u76f4\u89c9\u6765\u8bf4\uff0c\u4e8c\u7ef4Regression loss\u4e0e\u4e09\u7ef4Regression loss,\u76f4\u63a5\u53e0\u52a0\u7684\u597d\u5904\u662f\u4e24\u8005\u4e0d\u4f1a\u76f8\u4e92\u5f71\u54cd\uff0c\u4f46\u662f\u5b83\u4eec\u4f1a\u4ea7\u751f\u4e0d\u5e73\u8861\uff0c\u5f71\u54cd\u4f18\u5316\u7684\u8fc7\u7a0b \u6bd4\u5982\u5bf9\u4e8e\u672c\u6587\u7684\u4e09\u7ef4\u56de\u5f52\u6765\u8bf4\uff0c\u539f\u59cb\u53c2\u6570\u5206\u4e3a\u56db\u7ec4\uff0c\u4e5f\u5c31\u662f\u6df1\u5ea6\u3001\u76f8\u673a\u5750\u6807\u3001\u4e09\u7ef4\u4ee5\u53ca\u89d2\u5ea6\uff0c\u56de\u5f52\u65f6\u9700\u8981\u8ba1\u7b97\u7684\u53c2\u6570\u662f\u516b\u4e2a\u89d2\u70b9\u7684\u5750\u6807\uff0c\u5176\u4e2d\u9700\u8981\u4e00\u4e2a\u8f6c\u6362\u3002 \u5728\u8ba1\u7b97loss\u65f6\uff0c\u5206\u6210\u56db\u7ec4\u3002\u5176\u4e2d\u7b2c i \u7ec4\u8ba1\u7b97loss\u65f6\uff0c\u7b2c i \u7ec4\u53c2\u6570\u7528\u9884\u6d4b\u503c\uff0c\u5176\u4f59\u7528ground_truth\uff0c\u5982\u6b64\u6bcf\u4e00\u7ec4\u90fd\u4f1a\u5206\u5f00\u4f18\u5316\u3002 \u5177\u4f53\u76f4\u89c9\u770b\u539f\u6587","title":"Disentangling 2D and 3D Detection Losses"},{"location":"3dDetection/End-to-end Learning of Multi-sensor 3D Tracking by Detection/","text":"End-to-end Learning of Multi-sensor 3D Tracking by Detection \u8fd9\u7bc7\u8bba\u6587\u4e3b\u8981\u8ba8\u8bba\u7684\u662f\u4e00\u4e2atracking\u95ee\u9898\uff0c\u7a81\u51fa\u8d21\u732e\u662f\u4f7f\u7528\u4e86\u79bb\u6563\u4f18\u5316\u7684\u6982\u5ff5(\u5728\u6c42\u89e3\u65f6\u8f6c\u6362\u4e3a\u4e86\u7ebf\u6027\u4f18\u5316\u95ee\u9898)\uff0c\u5e76\u89e3\u51b3\u4e86\u5982\u4f55\u8bad\u7ec3\u8fd9\u4e2a\u95ee\u9898\uff0c\u8fc7\u7a0b\u4e2d\u6709\u8f83\u591a\u7684\u6570\u5b66\u5de7\u5408\uff0c\u4f46\u662f\u5176\u5b9e\u8fd9\u662f\u4e00\u7c7b\u95ee\u9898\u7684\u89e3\u51b3\u65b9\u6cd5,\u8fd9\u4e2a\u95ee\u9898\u79f0\u4e3ageneral matching problem,\u53ef\u4ee5 \u53c2\u8003\u5f15\u65876 \u7684\u95ee\u9898\u9610\u8ff0\u4ee5\u53ca\u9644\u5f551\u3002 \u63a8\u65ad\u7ed3\u6784 \u9010\u4e2a\u5206\u6790\uff1a Detection Net\u7528\u7684\u662f MV3D Scoring Net\uff0c\u5c06\u6bcf\u4e00\u4e2a3D\u6846\u6295\u5f71\u56de\u56fe\u7247\u4e2d\uff0c\u7528VGG\u603b\u7ed3\uff0c\u7ed9\u51fa\u8fd9\u4e2a\u56fe\u7247\u662ftrue positive\u7684cost Matching Net\uff0c\u5206\u4e24\u652f\uff0c\u4e00\u4e2a\u662fSiamese Network\uff0c\u5c06\u4e24\u4e2a3D\u6846\u5bf9\u5e94\u7684\u56fe\u7247\u9001\u5230network\u4e2d\u63d0\u53d6\u5171\u540c\u4fe1\u606f\uff0c\u7b2c\u4e8c\u4e2a\u662f\u8fd0\u52a8\u77eb\u6b63\u540e\u76843D\u6295\u5f71\u56fe\uff0c\u9001\u5230network\u4e2d\u63d0\u53d6\u4fe1\u606f\u3002\u7136\u540e\u6700\u540e\u7531FC Net\u5f97\u5230\u9884\u6d4b\u3002\u8fd9\u4e2anetwork\u9700\u8981\u5bf9\u6bcf\u4e00\u5bf9\u53ef\u80fd\u7684\u5339\u914d\u8ba1\u7b97\u3002 new cost and end cost:\u5bf9\u4e00\u4e2adetection\u662f\u65b0\u7684\u6216\u662f\u6700\u7ec8\u51fa\u73b0\u7684\u9884\u6d4b\uff0c\u662f\u4e00\u4e2a\u5e38\u91cf\uff0c\u53ef\u5b66\u4e60\u3002 \u8fc7\u7a0b\u7b80\u4ecb \u4e24\u4e2aLinear\u3001Integer Programming\u7684\u5b9a\u4e49 \u7ea6\u675f\u77e9\u9635 y_j^{new} + \\sum_{k of last frame}y^{link}_{j,k} = y^{end}_{j} + \\sum_{k of next frame} y_{j,k}^{link} = y_j^{det} \u7b80\u5355\u5730\u8bf4\u5c31\u662f\u65b0\u751f\u7684or\u4ece\u4e0a\u4e00\u5e27\u6765\u7684object = \u7ed3\u675f\u7684or\u53bb\u5f80\u4e0b\u4e00\u5e27\u7684object = \u8fd9\u4e00\u5e27\u8fd9\u4e2aobject\u662f\u5426\u662ftrue positive \u5728\u7eaf\u7cb9inference\u7684\u65f6\u5019\uff0c\u4f18\u5316\u76ee\u6807\u5c31\u662f \\theta_{\\bold w}(\\bold x) y ,\u6bcf\u4e00\u4e2a\u5e03\u5c14\u51b3\u7b56y\u524d\u7684cost\u7531\u524d\u6587\u7684Matching Net\uff0c scoring net\uff0c\u4ee5\u53ca\u53ef\u5b66\u4e60\u5e38\u91cf\u7ed9\u51fa\u3002\u76f4\u63a5\u7528OR-tools\u6c42\u89e3,\u76f8\u5f53\u4e8e\u5df2\u77e5reward\u53c2\u6570\u627e\u51fa\u6700\u597d\u7684\u89e3 \u5728\u9700\u8981train\u7684\u65f6\u5019\uff0c\u4f18\u5316\u76ee\u6807\u5c31\u662f L(x, y, W) = \\sum_x[\\max_{y}(\\Delta(y, \\hat y) + \\theta_{\\bold w}(\\bold x) (y-\\hat y)))] \u91cc\u9762\u7684 \\max_{y}(\\Delta(y, \\hat y) + \\theta_{\\bold w}(\\bold x) (y-\\hat y)) \u4f5c\u4e3ainference\u65f6\u5019\u9700\u8981\u6c42\u89e3\u7684LP\u51fd\u6570\u3002\u601d\u8def\u7c7b\u4f3c\u4e8eSVM\u4e2d\u7684\u5bf9\u5076\u4f18\u5316\u95ee\u9898\uff0c\u5728\u8bad\u7ec3\u7684\u65f6\u5019\uff0c\u6211\u4eec\u9700\u8981\u627e\u5230 w \uff0c\u4f7f\u5f97,worst case\u7684\u4e00\u4e2a\"\u9519\u5224loss\"\u6700\u5c0f\uff0c\u800c\u8fd9\u4e2aworst case\u7684\u9519\u5224loss\uff0c\u9996\u5148\u8981\u5b9a\u4e49\u9519\u5224loss\uff0c\u5176\u6b21\u662f\u7528max\u627e\u51faworst case(\u7b80\u5355).\u800c\u9519\u5224loss\u8fd9\u91cc\u7528\u6c49\u660e\u8ddd\u79bb+reward difference,\u7406\u60f3\u60c5\u51b5\u4e0b\uff0c\u6c49\u660e\u8ddd\u79bb\u8d8a\u5927\uff0creward difference\u5c31\u5e94\u8be5\u8d8a\u5c0f,\u53cd\u4e4b\u4ea6\u7136\uff0c\u5e76\u6700\u597d\u4fdd\u6301\u4e3a\u4e00\u4e2a\u5e38\u6570 \u5bf9\u4e8e\u9519\u5224loss\uff0c\u9996\u5148\u6c49\u660e\u8ddd\u79bb\u5c0f\u65f6reward difference\u81ea\u7136\u4e5f\u4f1a\u5c0f\uff0c\u800c\u6c49\u660e\u8ddd\u79bb\u5927\u65f6reward difference\u4e5f\u5e94\u8be5\u4e3a\u4e00\u4e2a\u5927\u7684\u8d1f\u6570\u4ee5\u62b5\u6d88\uff0c\u5982\u679c\u51fa\u73b0\u6c49\u660e\u8ddd\u79bb\u5927\u800creward difference\u4e0d\u591f\u5c0f\uff0c\u5219\u8fd9\u4e2aworst case\u9700\u8981\u88ab\u4fee\u6b63\uff0c\u4e5f\u5c31\u662f\u8fd9\u4e2a\u73a9\u610f\u513f\u7684intuition\u3002 \u5173\u4e8e\u5176\u68af\u5ea6\uff0c\u5efa\u8bae\u53c2\u8003 \u8fd9\u7bc7 \u3002\u5f97\u5230\u7684\u7ed3\u679c\u662f \u5173\u952e\u662f\u6839\u636e\u5f15\u65876\uff0c\u8fd9\u4e2a\u7ea6\u675f\u77e9\u9635A\u662f\u4e00\u4e2a\u5355\u6a21\u77e9\u9635\uff0c\u6240\u4ee5\u5176\u9006\u77e9\u9635\u7684\u89e3\u90fd\u662f\u6574\u6570\uff0c\u6240\u4ee5Integer programming\u88ab\u8f6c\u6362\u4e3aLinear Programming\u5e76\u540c\u65f6\u4fdd\u8bc1\u4e86\u6700\u4f18\u89e3\u4e00\u5b9a\u662f\u6574\u6570\u3002","title":"End-to-end Learning of Multi-sensor 3D Tracking by Detection"},{"location":"3dDetection/End-to-end Learning of Multi-sensor 3D Tracking by Detection/#end-to-end-learning-of-multi-sensor-3d-tracking-by-detection","text":"\u8fd9\u7bc7\u8bba\u6587\u4e3b\u8981\u8ba8\u8bba\u7684\u662f\u4e00\u4e2atracking\u95ee\u9898\uff0c\u7a81\u51fa\u8d21\u732e\u662f\u4f7f\u7528\u4e86\u79bb\u6563\u4f18\u5316\u7684\u6982\u5ff5(\u5728\u6c42\u89e3\u65f6\u8f6c\u6362\u4e3a\u4e86\u7ebf\u6027\u4f18\u5316\u95ee\u9898)\uff0c\u5e76\u89e3\u51b3\u4e86\u5982\u4f55\u8bad\u7ec3\u8fd9\u4e2a\u95ee\u9898\uff0c\u8fc7\u7a0b\u4e2d\u6709\u8f83\u591a\u7684\u6570\u5b66\u5de7\u5408\uff0c\u4f46\u662f\u5176\u5b9e\u8fd9\u662f\u4e00\u7c7b\u95ee\u9898\u7684\u89e3\u51b3\u65b9\u6cd5,\u8fd9\u4e2a\u95ee\u9898\u79f0\u4e3ageneral matching problem,\u53ef\u4ee5 \u53c2\u8003\u5f15\u65876 \u7684\u95ee\u9898\u9610\u8ff0\u4ee5\u53ca\u9644\u5f551\u3002","title":"End-to-end Learning of Multi-sensor 3D Tracking by Detection"},{"location":"3dDetection/End-to-end Learning of Multi-sensor 3D Tracking by Detection/#_1","text":"\u9010\u4e2a\u5206\u6790\uff1a Detection Net\u7528\u7684\u662f MV3D Scoring Net\uff0c\u5c06\u6bcf\u4e00\u4e2a3D\u6846\u6295\u5f71\u56de\u56fe\u7247\u4e2d\uff0c\u7528VGG\u603b\u7ed3\uff0c\u7ed9\u51fa\u8fd9\u4e2a\u56fe\u7247\u662ftrue positive\u7684cost Matching Net\uff0c\u5206\u4e24\u652f\uff0c\u4e00\u4e2a\u662fSiamese Network\uff0c\u5c06\u4e24\u4e2a3D\u6846\u5bf9\u5e94\u7684\u56fe\u7247\u9001\u5230network\u4e2d\u63d0\u53d6\u5171\u540c\u4fe1\u606f\uff0c\u7b2c\u4e8c\u4e2a\u662f\u8fd0\u52a8\u77eb\u6b63\u540e\u76843D\u6295\u5f71\u56fe\uff0c\u9001\u5230network\u4e2d\u63d0\u53d6\u4fe1\u606f\u3002\u7136\u540e\u6700\u540e\u7531FC Net\u5f97\u5230\u9884\u6d4b\u3002\u8fd9\u4e2anetwork\u9700\u8981\u5bf9\u6bcf\u4e00\u5bf9\u53ef\u80fd\u7684\u5339\u914d\u8ba1\u7b97\u3002 new cost and end cost:\u5bf9\u4e00\u4e2adetection\u662f\u65b0\u7684\u6216\u662f\u6700\u7ec8\u51fa\u73b0\u7684\u9884\u6d4b\uff0c\u662f\u4e00\u4e2a\u5e38\u91cf\uff0c\u53ef\u5b66\u4e60\u3002","title":"\u63a8\u65ad\u7ed3\u6784"},{"location":"3dDetection/End-to-end Learning of Multi-sensor 3D Tracking by Detection/#_2","text":"","title":"\u8fc7\u7a0b\u7b80\u4ecb"},{"location":"3dDetection/End-to-end Learning of Multi-sensor 3D Tracking by Detection/#linearinteger-programming","text":"\u7ea6\u675f\u77e9\u9635 y_j^{new} + \\sum_{k of last frame}y^{link}_{j,k} = y^{end}_{j} + \\sum_{k of next frame} y_{j,k}^{link} = y_j^{det} \u7b80\u5355\u5730\u8bf4\u5c31\u662f\u65b0\u751f\u7684or\u4ece\u4e0a\u4e00\u5e27\u6765\u7684object = \u7ed3\u675f\u7684or\u53bb\u5f80\u4e0b\u4e00\u5e27\u7684object = \u8fd9\u4e00\u5e27\u8fd9\u4e2aobject\u662f\u5426\u662ftrue positive \u5728\u7eaf\u7cb9inference\u7684\u65f6\u5019\uff0c\u4f18\u5316\u76ee\u6807\u5c31\u662f \\theta_{\\bold w}(\\bold x) y ,\u6bcf\u4e00\u4e2a\u5e03\u5c14\u51b3\u7b56y\u524d\u7684cost\u7531\u524d\u6587\u7684Matching Net\uff0c scoring net\uff0c\u4ee5\u53ca\u53ef\u5b66\u4e60\u5e38\u91cf\u7ed9\u51fa\u3002\u76f4\u63a5\u7528OR-tools\u6c42\u89e3,\u76f8\u5f53\u4e8e\u5df2\u77e5reward\u53c2\u6570\u627e\u51fa\u6700\u597d\u7684\u89e3 \u5728\u9700\u8981train\u7684\u65f6\u5019\uff0c\u4f18\u5316\u76ee\u6807\u5c31\u662f L(x, y, W) = \\sum_x[\\max_{y}(\\Delta(y, \\hat y) + \\theta_{\\bold w}(\\bold x) (y-\\hat y)))] \u91cc\u9762\u7684 \\max_{y}(\\Delta(y, \\hat y) + \\theta_{\\bold w}(\\bold x) (y-\\hat y)) \u4f5c\u4e3ainference\u65f6\u5019\u9700\u8981\u6c42\u89e3\u7684LP\u51fd\u6570\u3002\u601d\u8def\u7c7b\u4f3c\u4e8eSVM\u4e2d\u7684\u5bf9\u5076\u4f18\u5316\u95ee\u9898\uff0c\u5728\u8bad\u7ec3\u7684\u65f6\u5019\uff0c\u6211\u4eec\u9700\u8981\u627e\u5230 w \uff0c\u4f7f\u5f97,worst case\u7684\u4e00\u4e2a\"\u9519\u5224loss\"\u6700\u5c0f\uff0c\u800c\u8fd9\u4e2aworst case\u7684\u9519\u5224loss\uff0c\u9996\u5148\u8981\u5b9a\u4e49\u9519\u5224loss\uff0c\u5176\u6b21\u662f\u7528max\u627e\u51faworst case(\u7b80\u5355).\u800c\u9519\u5224loss\u8fd9\u91cc\u7528\u6c49\u660e\u8ddd\u79bb+reward difference,\u7406\u60f3\u60c5\u51b5\u4e0b\uff0c\u6c49\u660e\u8ddd\u79bb\u8d8a\u5927\uff0creward difference\u5c31\u5e94\u8be5\u8d8a\u5c0f,\u53cd\u4e4b\u4ea6\u7136\uff0c\u5e76\u6700\u597d\u4fdd\u6301\u4e3a\u4e00\u4e2a\u5e38\u6570 \u5bf9\u4e8e\u9519\u5224loss\uff0c\u9996\u5148\u6c49\u660e\u8ddd\u79bb\u5c0f\u65f6reward difference\u81ea\u7136\u4e5f\u4f1a\u5c0f\uff0c\u800c\u6c49\u660e\u8ddd\u79bb\u5927\u65f6reward difference\u4e5f\u5e94\u8be5\u4e3a\u4e00\u4e2a\u5927\u7684\u8d1f\u6570\u4ee5\u62b5\u6d88\uff0c\u5982\u679c\u51fa\u73b0\u6c49\u660e\u8ddd\u79bb\u5927\u800creward difference\u4e0d\u591f\u5c0f\uff0c\u5219\u8fd9\u4e2aworst case\u9700\u8981\u88ab\u4fee\u6b63\uff0c\u4e5f\u5c31\u662f\u8fd9\u4e2a\u73a9\u610f\u513f\u7684intuition\u3002 \u5173\u4e8e\u5176\u68af\u5ea6\uff0c\u5efa\u8bae\u53c2\u8003 \u8fd9\u7bc7 \u3002\u5f97\u5230\u7684\u7ed3\u679c\u662f \u5173\u952e\u662f\u6839\u636e\u5f15\u65876\uff0c\u8fd9\u4e2a\u7ea6\u675f\u77e9\u9635A\u662f\u4e00\u4e2a\u5355\u6a21\u77e9\u9635\uff0c\u6240\u4ee5\u5176\u9006\u77e9\u9635\u7684\u89e3\u90fd\u662f\u6574\u6570\uff0c\u6240\u4ee5Integer programming\u88ab\u8f6c\u6362\u4e3aLinear Programming\u5e76\u540c\u65f6\u4fdd\u8bc1\u4e86\u6700\u4f18\u89e3\u4e00\u5b9a\u662f\u6574\u6570\u3002","title":"\u4e24\u4e2aLinear\u3001Integer Programming\u7684\u5b9a\u4e49"},{"location":"3dDetection/Fast and Furious Real Time End-to-End 3D Detection, Tracking and MotionForecasting with a Single Convolutional Net/","text":"Fast and Furious: Real Time End-to-End 3D Detection, Tracking and MotionForecasting with a Single Convolutional Net \u8fd9\u7bc7\u8bba\u6587\u7684\u5173\u952e\u662f\u7ed3\u5408\u65f6\u5e8f\u4fe1\u606f\uff0c\u8981\u540c\u65f6\u5b9e\u73b03D detection\u4ee5\u53catracking\u751a\u81f3forecasting,\u4f7f\u7528\u5355\u4e00\u7684Lidar\u6570\u636e \u70b9\u4e91\u4fe1\u606f\u7684\u5904\u7406\u529e\u6cd5 \u5c06\u5355\u5e27\u70b9\u4e91\u8f6c\u6362\u4e3a2Dcostmap\uff0c\u70b9\u7684\u9ad8\u5ea6\u4f5c\u4e3a\u8f93\u5165\u7684\u4e00\u4e2afeature\u3002 \u5c06\u591a\u5e27\u70b9\u4e91\u8f6c\u6362\u5230\u540c\u4e00\u4e2a\u5750\u6807\u7cfb\u4e2d\uff0c\u6bcf\u4e00\u5e27\u53ef\u4ee5\u5355\u72ec\u5f62\u6210\u4e00\u4e2a3D Tensor\uff0c\u7ed3\u5408\u8d77\u6765\u6210\u4e3a\u4e00\u4e2a4D Tensor \u878d\u5408\u65f6\u5e8f\u4fe1\u606f\u7684\u65b9\u6cd5 \u7b2c\u4e00\u79cd\u65b9\u6cd5\u662fEarly Fusion,\u5728\u4e00\u5f00\u59cb\u5c31\u4f7f\u75281D Conv\u5c06\u591a\u4e2aCostmap\u7ed3\u5408\u6210\u4e00\u4e2aCostmap \u7b2c\u4e8c\u79cd\u65b9\u6cd5\u662fLate Fusion,\u4f7f\u75283D Conv\u5206\u4e24\u6b65\u7ed3\u5408\u3002 \u8f93\u51fabounding box \u4ee5\u53ca\u9884\u6d4b \u76f4\u63a5\u8f93\u51fa\u4e00\u7cfb\u5217\u7684bounding box\u548c\u79cd\u7c7b\u4fe1\u606f","title":"Fast and Furious: Real Time End-to-End 3D Detection, Tracking and MotionForecasting with a Single Convolutional Net"},{"location":"3dDetection/Fast and Furious Real Time End-to-End 3D Detection, Tracking and MotionForecasting with a Single Convolutional Net/#fast-and-furious-real-time-end-to-end-3d-detection-tracking-and-motionforecasting-with-a-single-convolutional-net","text":"\u8fd9\u7bc7\u8bba\u6587\u7684\u5173\u952e\u662f\u7ed3\u5408\u65f6\u5e8f\u4fe1\u606f\uff0c\u8981\u540c\u65f6\u5b9e\u73b03D detection\u4ee5\u53catracking\u751a\u81f3forecasting,\u4f7f\u7528\u5355\u4e00\u7684Lidar\u6570\u636e","title":"Fast and Furious: Real Time End-to-End 3D Detection, Tracking and MotionForecasting with a Single Convolutional Net"},{"location":"3dDetection/Fast and Furious Real Time End-to-End 3D Detection, Tracking and MotionForecasting with a Single Convolutional Net/#_1","text":"\u5c06\u5355\u5e27\u70b9\u4e91\u8f6c\u6362\u4e3a2Dcostmap\uff0c\u70b9\u7684\u9ad8\u5ea6\u4f5c\u4e3a\u8f93\u5165\u7684\u4e00\u4e2afeature\u3002 \u5c06\u591a\u5e27\u70b9\u4e91\u8f6c\u6362\u5230\u540c\u4e00\u4e2a\u5750\u6807\u7cfb\u4e2d\uff0c\u6bcf\u4e00\u5e27\u53ef\u4ee5\u5355\u72ec\u5f62\u6210\u4e00\u4e2a3D Tensor\uff0c\u7ed3\u5408\u8d77\u6765\u6210\u4e3a\u4e00\u4e2a4D Tensor","title":"\u70b9\u4e91\u4fe1\u606f\u7684\u5904\u7406\u529e\u6cd5"},{"location":"3dDetection/Fast and Furious Real Time End-to-End 3D Detection, Tracking and MotionForecasting with a Single Convolutional Net/#_2","text":"\u7b2c\u4e00\u79cd\u65b9\u6cd5\u662fEarly Fusion,\u5728\u4e00\u5f00\u59cb\u5c31\u4f7f\u75281D Conv\u5c06\u591a\u4e2aCostmap\u7ed3\u5408\u6210\u4e00\u4e2aCostmap \u7b2c\u4e8c\u79cd\u65b9\u6cd5\u662fLate Fusion,\u4f7f\u75283D Conv\u5206\u4e24\u6b65\u7ed3\u5408\u3002","title":"\u878d\u5408\u65f6\u5e8f\u4fe1\u606f\u7684\u65b9\u6cd5"},{"location":"3dDetection/Fast and Furious Real Time End-to-End 3D Detection, Tracking and MotionForecasting with a Single Convolutional Net/#bounding-box","text":"\u76f4\u63a5\u8f93\u51fa\u4e00\u7cfb\u5217\u7684bounding box\u548c\u79cd\u7c7b\u4fe1\u606f","title":"\u8f93\u51fabounding box \u4ee5\u53ca\u9884\u6d4b"},{"location":"3dDetection/Frustum_PointNets_for_3D_Object_Detection_from_RGB-D_Data/","text":"Frustum PointNets for 3D Object Detection from RGB-D Data \u8fd9\u7bc7\u8bba\u6587\u7ed9\u51fa\u4e86\u4f7f\u7528RGB-D\u6570\u636e\u8fdb\u884c3D\u68c0\u6d4b\u7684baseline pipeline. \u7f51\u7edc\u7ed3\u6784 \u5bf9RGB\u56fe\u7247\u6267\u884c2D detection\uff0c\u7ed9\u51fa2D proposal\u4ee5\u53ca\u5206\u7c7bone-hot\u77e2\u91cf,\u4eceproposal\u4e2d\u91c7\u6837\u51fan\u4e2a\u70b9\uff0c\u4f7f\u7528pointnet\u8fdb\u884cInstance Segmentation\u533a\u5206\u80cc\u666f\u4ee5\u53caforeground,\u6267\u884cmasking\u518d\u91c7\u6837m\u4e2a\u70b9\uff0c\u4f7f\u7528T-Net\u7b49\u56de\u5f52\u4f30\u8ba1\u4e09\u7ef4\u6846\u7ed3\u679c \u4ee3\u7801\u4e2d\u4f7f\u7528\u7684\u5750\u6807\u7cfb\u793a\u610f\u56fe PointNet\u4f7f\u7528\u7684\u7ed3\u6784 \u70b9\u4e91\u8bed\u4e49\u5206\u5272\u4e2d\uff0c\u9664\u4e86\u4f7f\u7528pointnet\u4e4b\u5916\uff0c\u5728\u8f93\u5165\u7279\u5f81\u4e2d\u8fd8concat\u4e86\u8bed\u4e49\u5206\u7c7b\u7684category\u3002 \u5728\u70b9\u4e91\u56de\u5f52\u65f6\uff0c\u5148\u7528T-Net\u6c42\u51fa\u4e2d\u5fc3\u70b9\u5750\u6807\uff0c\u5c06\u5269\u4f59\u70b9\u8f6c\u6362\u4e3a\u4ee5\u4e2d\u5fc3\u70b9\u4e3a\u4e2d\u5fc3\u7684\u4f4d\u7f6e\u4e0a\u5728\u4f30\u8ba1box size Loss Multitask Loss Corner Loss","title":"Frustum PointNets for 3D Object Detection from RGB-D Data"},{"location":"3dDetection/Frustum_PointNets_for_3D_Object_Detection_from_RGB-D_Data/#frustum-pointnets-for-3d-object-detection-from-rgb-d-data","text":"\u8fd9\u7bc7\u8bba\u6587\u7ed9\u51fa\u4e86\u4f7f\u7528RGB-D\u6570\u636e\u8fdb\u884c3D\u68c0\u6d4b\u7684baseline pipeline.","title":"Frustum PointNets for 3D Object Detection from RGB-D Data"},{"location":"3dDetection/Frustum_PointNets_for_3D_Object_Detection_from_RGB-D_Data/#_1","text":"\u5bf9RGB\u56fe\u7247\u6267\u884c2D detection\uff0c\u7ed9\u51fa2D proposal\u4ee5\u53ca\u5206\u7c7bone-hot\u77e2\u91cf,\u4eceproposal\u4e2d\u91c7\u6837\u51fan\u4e2a\u70b9\uff0c\u4f7f\u7528pointnet\u8fdb\u884cInstance Segmentation\u533a\u5206\u80cc\u666f\u4ee5\u53caforeground,\u6267\u884cmasking\u518d\u91c7\u6837m\u4e2a\u70b9\uff0c\u4f7f\u7528T-Net\u7b49\u56de\u5f52\u4f30\u8ba1\u4e09\u7ef4\u6846\u7ed3\u679c \u4ee3\u7801\u4e2d\u4f7f\u7528\u7684\u5750\u6807\u7cfb\u793a\u610f\u56fe PointNet\u4f7f\u7528\u7684\u7ed3\u6784 \u70b9\u4e91\u8bed\u4e49\u5206\u5272\u4e2d\uff0c\u9664\u4e86\u4f7f\u7528pointnet\u4e4b\u5916\uff0c\u5728\u8f93\u5165\u7279\u5f81\u4e2d\u8fd8concat\u4e86\u8bed\u4e49\u5206\u7c7b\u7684category\u3002 \u5728\u70b9\u4e91\u56de\u5f52\u65f6\uff0c\u5148\u7528T-Net\u6c42\u51fa\u4e2d\u5fc3\u70b9\u5750\u6807\uff0c\u5c06\u5269\u4f59\u70b9\u8f6c\u6362\u4e3a\u4ee5\u4e2d\u5fc3\u70b9\u4e3a\u4e2d\u5fc3\u7684\u4f4d\u7f6e\u4e0a\u5728\u4f30\u8ba1box size","title":"\u7f51\u7edc\u7ed3\u6784"},{"location":"3dDetection/Frustum_PointNets_for_3D_Object_Detection_from_RGB-D_Data/#loss","text":"Multitask Loss Corner Loss","title":"Loss"},{"location":"3dDetection/Generalize3DDet/","text":"Train in Germany, Test in The USA: Making 3D Object Detectors Generalize \u8fd9\u7bc7paper\u8ba8\u8bba\u7684\u662f\u70b9\u4e913D\u68c0\u6d4b\u5668\u7684\u9c81\u68d2\u6027\u95ee\u9898\u3002\u5e76\u63d0\u51fadoman transfer\u7684\u95ee\u9898 Biased in Datasets \u4f5c\u8005\u5206\u6790\u7814\u7a76\u4e86\u4e94\u4e2a\u6570\u636e\u96c6\u7684\u7279\u70b9\uff0c\u5206\u522b\u662f KITTI , Argoverse , nuScenes , Lyft , Waymo . (\u6ce8\uff0cArgoverse\u4e0eKITTI\u90fd\u6709\u53cc\u76ee) \u5148\u4f7f\u7528\u4e00\u4e2a PointRCNN ,\u5728\u5404\u4e2a\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\uff0c\u770b\u770b\u76f4\u63a5\u8de8\u6570\u636e\u96c6test\u7684\u7ed3\u679c\u3002 \u4f5c\u8005\u6307\u51fanuScenes\u4e0eArgoverse\u4f5c\u4e3atarget\u7684\u65f6\u5019\u6027\u80fd\u4e0b\u964d\u7279\u522b\u5389\u5bb3\uff0c\u8fd9\u53ef\u80fd\u662f\u4e0eLidar\u70b9\u6570\u7684\u8f93\u5165\u6709\u5173\u7684\u3002nuScenes\u53ea\u6709\u4e00\u4e2a32\u7ebf\u7684\u96f7\u8fbe\uff0c\u800cArgoverse\u662f\u7528\u4e24\u4e2a32\u7ebf\u7684\u96f7\u8fbe\u76f4\u63a5\u4e0a\u4e0b\u5806\u53e0\u5f62\u6210\u4e00\u4e2a64\u7ebf\u7684\u7ed3\u679c\u3002 \u540c\u65f6\u7531\u4e8e\u5730\u70b9\u4ee5\u53ca\u6807\u6ce8\u504f\u5dee\u7684\u539f\u56e0\uff0c\u4e0d\u540c\u6570\u636e\u96c6\u8f66\u8f86\u957f\u5bbd\u9ad8\u7684\u5206\u5e03\u5dee\u8ddd\u5f88\u5927\uff0c\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u662f\u56e0\u4e3a\u8f66\u5b50\u7684\u5730\u533a\u5dee\u5f02\u3002 (\u6ce8\uff1a\u4e2a\u4eba\u89c2\u5bdf\u4e0d\u540c\u6570\u636e\u96c6\u65f6\uff0c\u5f97\u5230\u7684\u7ed3\u8bba\u5176\u5b9e\u662f\u53ea\u6709KITTI\u76843D\u6846\u662f\u4e25\u683c\u4e0e\u7269\u4f53\u7d27\u8d34\u7684\uff0c\u5176\u4ed6\u6570\u636e\u96c6\u7684\u6846\u6295\u5f71\u5230\u76f8\u673a\u4e0a\u80fd\u770b\u5230\u663e\u7136\u662f\u4e0d\u7d27\u8d34\u7684) \u4f5c\u8005\u505a\u4e86\u4e00\u4e2a\u5b9e\u9a8c\uff0c\u5bf9\u6240\u6709IoU > 0.2\u4e3a\u754c\u9650\u5339\u914d\u7684prediction\uff0c\u4fdd\u6301\u5176\u4e2d\u5fc3\u4f4d\u7f6e\u4e0e\u89d2\u5ea6\u4e0d\u53d8\uff0c\u5c06whl\u6539\u4e3a\u6b63\u786e\u503c\uff0ccross domain\u6027\u80fd\u663e\u8457\u63d0\u5347\u3002\u4f5c\u8005\u4e0b\u7684\u7ed3\u8bba\u5c31\u662f\u7f51\u7edc\u9884\u6d4b\u4e0d\u6b63\u786e\u7684\u539f\u56e0\u5355\u7eaf\u5730\u5c31\u662f\u56e0\u4e3awhl\u4e0d\u6b63\u786e\u3002 Generalize to differet datasets \u505a\u6cd5\u4e0e\u7ed3\u8bba\u5982\u4e0b: fine tuning\u6709\u7528\uff0c\u4ec5\u572820\u4e2ascene\u4e0a\u5fae\u8c03\u7684\u7ed3\u679c\u80fd\u591f\u6bd4\u5f97\u4e0a\u5728\u539f\u6765500\u4e2ascene\u4e0a\u76f4\u63a5\u8bad\u7ec3\u7684\u6027\u80fd\u3002 \u4e0a\u56fe\u4f7f\u7528\u7684Statistical Normalization\u8fdb\u884c\u5fae\u8c03\uff08\u6ca1\u6709\u4f7f\u7528\u65b0domain\u7684\u6807\u6ce8\u6570\u636e\uff09\uff0c\u6027\u80fd\u4e5f\u80fd\u5f88\u597d\u3002 \u4e0dfinetune,\u5728\u70b9\u4e91\u7ed3\u679c\u76f4\u63a5\u9644\u52a0\u4e00\u4e2a\u6570\u636e\u96c6\u7684mean\u504f\u79fb\uff0c\u6027\u80fd\u6709\u90e8\u5206\u63d0\u5347\uff0c\u4f46\u662f\u53ef\u80fd\u4f1aover-react(\u56e0\u4e3a\u7f51\u7edc\u672c\u8eab\u5c31\u4f1aadjust\u4e00\u90e8\u5206\uff0c\u518d\u52a0\u504f\u79fb\u4f1aover-react)","title":"Train in Germany, Test in The USA: Making 3D Object Detectors Generalize"},{"location":"3dDetection/Generalize3DDet/#train-in-germany-test-in-the-usa-making-3d-object-detectors-generalize","text":"\u8fd9\u7bc7paper\u8ba8\u8bba\u7684\u662f\u70b9\u4e913D\u68c0\u6d4b\u5668\u7684\u9c81\u68d2\u6027\u95ee\u9898\u3002\u5e76\u63d0\u51fadoman transfer\u7684\u95ee\u9898","title":"Train in Germany, Test in The USA: Making 3D Object Detectors Generalize"},{"location":"3dDetection/Generalize3DDet/#biased-in-datasets","text":"\u4f5c\u8005\u5206\u6790\u7814\u7a76\u4e86\u4e94\u4e2a\u6570\u636e\u96c6\u7684\u7279\u70b9\uff0c\u5206\u522b\u662f KITTI , Argoverse , nuScenes , Lyft , Waymo . (\u6ce8\uff0cArgoverse\u4e0eKITTI\u90fd\u6709\u53cc\u76ee) \u5148\u4f7f\u7528\u4e00\u4e2a PointRCNN ,\u5728\u5404\u4e2a\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\uff0c\u770b\u770b\u76f4\u63a5\u8de8\u6570\u636e\u96c6test\u7684\u7ed3\u679c\u3002 \u4f5c\u8005\u6307\u51fanuScenes\u4e0eArgoverse\u4f5c\u4e3atarget\u7684\u65f6\u5019\u6027\u80fd\u4e0b\u964d\u7279\u522b\u5389\u5bb3\uff0c\u8fd9\u53ef\u80fd\u662f\u4e0eLidar\u70b9\u6570\u7684\u8f93\u5165\u6709\u5173\u7684\u3002nuScenes\u53ea\u6709\u4e00\u4e2a32\u7ebf\u7684\u96f7\u8fbe\uff0c\u800cArgoverse\u662f\u7528\u4e24\u4e2a32\u7ebf\u7684\u96f7\u8fbe\u76f4\u63a5\u4e0a\u4e0b\u5806\u53e0\u5f62\u6210\u4e00\u4e2a64\u7ebf\u7684\u7ed3\u679c\u3002 \u540c\u65f6\u7531\u4e8e\u5730\u70b9\u4ee5\u53ca\u6807\u6ce8\u504f\u5dee\u7684\u539f\u56e0\uff0c\u4e0d\u540c\u6570\u636e\u96c6\u8f66\u8f86\u957f\u5bbd\u9ad8\u7684\u5206\u5e03\u5dee\u8ddd\u5f88\u5927\uff0c\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u662f\u56e0\u4e3a\u8f66\u5b50\u7684\u5730\u533a\u5dee\u5f02\u3002 (\u6ce8\uff1a\u4e2a\u4eba\u89c2\u5bdf\u4e0d\u540c\u6570\u636e\u96c6\u65f6\uff0c\u5f97\u5230\u7684\u7ed3\u8bba\u5176\u5b9e\u662f\u53ea\u6709KITTI\u76843D\u6846\u662f\u4e25\u683c\u4e0e\u7269\u4f53\u7d27\u8d34\u7684\uff0c\u5176\u4ed6\u6570\u636e\u96c6\u7684\u6846\u6295\u5f71\u5230\u76f8\u673a\u4e0a\u80fd\u770b\u5230\u663e\u7136\u662f\u4e0d\u7d27\u8d34\u7684) \u4f5c\u8005\u505a\u4e86\u4e00\u4e2a\u5b9e\u9a8c\uff0c\u5bf9\u6240\u6709IoU > 0.2\u4e3a\u754c\u9650\u5339\u914d\u7684prediction\uff0c\u4fdd\u6301\u5176\u4e2d\u5fc3\u4f4d\u7f6e\u4e0e\u89d2\u5ea6\u4e0d\u53d8\uff0c\u5c06whl\u6539\u4e3a\u6b63\u786e\u503c\uff0ccross domain\u6027\u80fd\u663e\u8457\u63d0\u5347\u3002\u4f5c\u8005\u4e0b\u7684\u7ed3\u8bba\u5c31\u662f\u7f51\u7edc\u9884\u6d4b\u4e0d\u6b63\u786e\u7684\u539f\u56e0\u5355\u7eaf\u5730\u5c31\u662f\u56e0\u4e3awhl\u4e0d\u6b63\u786e\u3002","title":"Biased in Datasets"},{"location":"3dDetection/Generalize3DDet/#generalize-to-differet-datasets","text":"\u505a\u6cd5\u4e0e\u7ed3\u8bba\u5982\u4e0b: fine tuning\u6709\u7528\uff0c\u4ec5\u572820\u4e2ascene\u4e0a\u5fae\u8c03\u7684\u7ed3\u679c\u80fd\u591f\u6bd4\u5f97\u4e0a\u5728\u539f\u6765500\u4e2ascene\u4e0a\u76f4\u63a5\u8bad\u7ec3\u7684\u6027\u80fd\u3002 \u4e0a\u56fe\u4f7f\u7528\u7684Statistical Normalization\u8fdb\u884c\u5fae\u8c03\uff08\u6ca1\u6709\u4f7f\u7528\u65b0domain\u7684\u6807\u6ce8\u6570\u636e\uff09\uff0c\u6027\u80fd\u4e5f\u80fd\u5f88\u597d\u3002 \u4e0dfinetune,\u5728\u70b9\u4e91\u7ed3\u679c\u76f4\u63a5\u9644\u52a0\u4e00\u4e2a\u6570\u636e\u96c6\u7684mean\u504f\u79fb\uff0c\u6027\u80fd\u6709\u90e8\u5206\u63d0\u5347\uff0c\u4f46\u662f\u53ef\u80fd\u4f1aover-react(\u56e0\u4e3a\u7f51\u7edc\u672c\u8eab\u5c31\u4f1aadjust\u4e00\u90e8\u5206\uff0c\u518d\u52a0\u504f\u79fb\u4f1aover-react)","title":"Generalize to differet datasets"},{"location":"3dDetection/GeneralizedIoU/","text":"Generalized IoU for 2D and 3D \u8fd9\u91cc\u5c1d\u8bd5\u540c\u65f6\u8bb0\u5f55\u4e24\u7bc7\u76f8\u5173\u7684\u8bba\u6587\uff0c\u5206\u522b\u63cf\u8ff0\u7684Generalized 2D IoU \u4e0eGeneralized 3D IoU\uff0c\u6700\u7ec8\u89e3\u51b3\u7684\u90fd\u662f\u5728\u6ca1\u6709intersection\u7684\u60c5\u51b5\u4e0b\u5f97\u5230\u4e00\u4e2a\u5bf9IoU\u7684\u4f30\u8ba1 Generalized Intersection over Union: A Metric and A Loss for Bounding Box Regression \u8fd9\u7bc7\u662fCVPR\u4f7f\u7528Generalized 2D IoU\u7684\u539f\u6587\uff0c\u81f3\u4e8e\u662f\u8fd9\u4e2a\u7b97\u6cd5\u597d\uff0c\u8fd8\u662f signed_iou \u6548\u679c\u597d\uff0c\u6709\u5f85\u6d4b\u8bd5 3D-GIoU: 3D Generalized Intersection over Union for Object Detection in Point Cloud 3D IoU\u7684\u7b97\u6cd5\u5728 \u8fd9\u7bc7\u6587\u7ae0 \u6709\u8be6\u7ec6\u63cf\u8ff0 \u7b97\u6cd5","title":"Generalized IoU for 2D and 3D"},{"location":"3dDetection/GeneralizedIoU/#generalized-iou-for-2d-and-3d","text":"\u8fd9\u91cc\u5c1d\u8bd5\u540c\u65f6\u8bb0\u5f55\u4e24\u7bc7\u76f8\u5173\u7684\u8bba\u6587\uff0c\u5206\u522b\u63cf\u8ff0\u7684Generalized 2D IoU \u4e0eGeneralized 3D IoU\uff0c\u6700\u7ec8\u89e3\u51b3\u7684\u90fd\u662f\u5728\u6ca1\u6709intersection\u7684\u60c5\u51b5\u4e0b\u5f97\u5230\u4e00\u4e2a\u5bf9IoU\u7684\u4f30\u8ba1","title":"Generalized IoU for 2D and 3D"},{"location":"3dDetection/GeneralizedIoU/#generalized-intersection-over-union-a-metric-and-a-loss-for-bounding-box-regression","text":"\u8fd9\u7bc7\u662fCVPR\u4f7f\u7528Generalized 2D IoU\u7684\u539f\u6587\uff0c\u81f3\u4e8e\u662f\u8fd9\u4e2a\u7b97\u6cd5\u597d\uff0c\u8fd8\u662f signed_iou \u6548\u679c\u597d\uff0c\u6709\u5f85\u6d4b\u8bd5","title":"Generalized Intersection over Union: A Metric and A Loss for Bounding Box Regression"},{"location":"3dDetection/GeneralizedIoU/#3d-giou-3d-generalized-intersection-over-union-for-object-detection-in-point-cloud","text":"3D IoU\u7684\u7b97\u6cd5\u5728 \u8fd9\u7bc7\u6587\u7ae0 \u6709\u8be6\u7ec6\u63cf\u8ff0 \u7b97\u6cd5","title":"3D-GIoU: 3D Generalized Intersection over Union for Object Detection in Point Cloud"},{"location":"3dDetection/Improving 3D Object Detection for Pedestrians with Virtual Multi-View Synthesis Orientation Estimation/","text":"Improving 3D Object Detection for Pedestrians with Virtual Multi-View Synthesis Orientation Estimation \u8fd9\u7bc7\u8bba\u6587\u8ba8\u8bba\u7684\u95ee\u9898\u662f\u63d0\u53473D\u884c\u4eba\u68c0\u6d4b\u8fc7\u7a0b\u4e2d\u5bf9\u884c\u4eba\u671d\u5411\u89d2\u5ea6\u7684\u9884\u6d4b\u7cbe\u5ea6\u95ee\u9898\u3002\u91c7\u7528\u7684\u601d\u8def\u662f\u4f7f\u7528\u51e0\u4e2a\u4eba\u5de5\u89d2\u5ea6\u5408\u6210\u76f8\u7247\u5b9e\u73b0\u5f88\u5de7\u5999\u7684pooling.\u8f93\u5165\u662fRGB + Lidar Update: 2019.12.21: Code has been open-sourced \u603b\u4f53\u601d\u8def \u603b\u4f53\u601d\u8def: \u4f7f\u7528RGB\u56fe\u50cf\u4e0eLidar\u6570\u636e\uff0c\u8fdb\u884cDepth Completion and colorization \u5f62\u6210\u5f69\u8272\u7684\u66f4\u5bc6\u96c6\u7684\u70b9\u4e91\u573a\u666f \u8fdb\u884c3D\u7269\u4f53\u68c0\u6d4b,\u6c42\u51fa3D box\u53c2\u6570\u4ee5\u53ca\u7269\u4f53\u4e2d\u5fc3\u3002 \u6839\u636e\u7269\u4f53\u4e2d\u5fc3\uff0c\u5728\u8bbe\u8ba1\u7684\u7269\u4f53\u653e\u7f6e\u6570\u4e2a\u4e2a\u865a\u62df\u7684\u76f8\u673a\uff0c\u5c06\u5f69\u8272\u70b9\u4e91\u6295\u5f71\u5230\u8fd9\u51e0\u4e2a\u76f8\u673a\u5185\uff0c\u5f97\u5230\u51e0\u5f20\u5408\u6210\u7684\u56fe\u7247 \u5c06\u8fd9\u4e2a\u5408\u6210\u7684\u56fe\u7247\u8f93\u5165\u5230CNN\u4e2d\u8fdb\u4e00\u6b65\u8f93\u51fa\u89d2\u5ea6\u9884\u6d4b\u3002 \u5408\u6210\u76f8\u673a\u5e03\u7f6e \u76f8\u673a\u653e\u7f6e\u65b9\u5f0f,\u4e0e\u539f\u6765\u76f8\u5bf9\u5c04\u7ebf\u76f8\u5bf9\u00b125\u00b0\u4e4b\u95f4\u8fde\u7eed\u653e\u7f6e\uff0c\u672c\u6587\u91c7\u7528\u7684\u662f11\u4e2a\u865a\u62df\u76f8\u673a\u7684\u6392\u5217\u3002 \u6df1\u5ea6\u8865\u5168\u4e0a\u8272 \u539f\u6765\u7684\u70b9\u4e91\u53ea\u80fd\u63d0\u4f9b\u4e00\u4e2a\u7a00\u758f\u7684\u6df1\u5ea6\u4f30\u8ba1\uff0c\u672c\u6587\u5229\u7528\u4e86\u4f5c\u8005\u7684 \u53e6\u4e00\u7bc7\u6df1\u5ea6\u8865\u5168\u7b97\u6cd5.pdf , \u7b80\u4ecb ,\u5c06\u7a00\u758f\u7684\u70b9\u4e91\u53d8\u6210\u5bc6\u96c6\u7684\u6df1\u5ea6\u56fe\uff0c\u4e5f\u5c31\u53ef\u4ee5\u5bf9\u5e94\u50cf\u7d20\u4e0a\u8272\u3002 \u5176\u4ed6\u8bad\u7ec3\u7ec6\u8282 \u57fa\u7840\u76843D\u68c0\u6d4b\u4f7f\u7528\u7684\u662f AVOD.pdf ,\u89d2\u5ea6\u4f30\u8ba1\u4f7f\u7528\u7684\u662f\u5728kitti 2D\u68c0\u6d4b\u95ee\u9898\u4e2d\u9884\u8bad\u7ec3\u7684Res101(\u4e2a\u4eba\u7406\u89e3\u8fd9\u662f\u4e00\u4e2a\u76f8\u5f53\u5927\u7684\u7f51\u7edc) \u672c\u6587\u7684\u6210\u679c\u662f\u5c06\u884c\u4eba\u4e09\u7ef4\u68c0\u6d4b\u7684\u89d2\u5ea6\u4f30\u8ba1\u7cbe\u5ea6\u5927\u5e45\u5ea6\u63d0\u5347\u3002","title":"Improving 3D Object Detection for Pedestrians with Virtual Multi-View Synthesis Orientation Estimation"},{"location":"3dDetection/Improving 3D Object Detection for Pedestrians with Virtual Multi-View Synthesis Orientation Estimation/#improving-3d-object-detection-for-pedestrians-with-virtual-multi-view-synthesis-orientation-estimation","text":"\u8fd9\u7bc7\u8bba\u6587\u8ba8\u8bba\u7684\u95ee\u9898\u662f\u63d0\u53473D\u884c\u4eba\u68c0\u6d4b\u8fc7\u7a0b\u4e2d\u5bf9\u884c\u4eba\u671d\u5411\u89d2\u5ea6\u7684\u9884\u6d4b\u7cbe\u5ea6\u95ee\u9898\u3002\u91c7\u7528\u7684\u601d\u8def\u662f\u4f7f\u7528\u51e0\u4e2a\u4eba\u5de5\u89d2\u5ea6\u5408\u6210\u76f8\u7247\u5b9e\u73b0\u5f88\u5de7\u5999\u7684pooling.\u8f93\u5165\u662fRGB + Lidar Update: 2019.12.21: Code has been open-sourced","title":"Improving 3D Object Detection for Pedestrians with Virtual Multi-View Synthesis Orientation Estimation"},{"location":"3dDetection/Improving 3D Object Detection for Pedestrians with Virtual Multi-View Synthesis Orientation Estimation/#_1","text":"\u603b\u4f53\u601d\u8def: \u4f7f\u7528RGB\u56fe\u50cf\u4e0eLidar\u6570\u636e\uff0c\u8fdb\u884cDepth Completion and colorization \u5f62\u6210\u5f69\u8272\u7684\u66f4\u5bc6\u96c6\u7684\u70b9\u4e91\u573a\u666f \u8fdb\u884c3D\u7269\u4f53\u68c0\u6d4b,\u6c42\u51fa3D box\u53c2\u6570\u4ee5\u53ca\u7269\u4f53\u4e2d\u5fc3\u3002 \u6839\u636e\u7269\u4f53\u4e2d\u5fc3\uff0c\u5728\u8bbe\u8ba1\u7684\u7269\u4f53\u653e\u7f6e\u6570\u4e2a\u4e2a\u865a\u62df\u7684\u76f8\u673a\uff0c\u5c06\u5f69\u8272\u70b9\u4e91\u6295\u5f71\u5230\u8fd9\u51e0\u4e2a\u76f8\u673a\u5185\uff0c\u5f97\u5230\u51e0\u5f20\u5408\u6210\u7684\u56fe\u7247 \u5c06\u8fd9\u4e2a\u5408\u6210\u7684\u56fe\u7247\u8f93\u5165\u5230CNN\u4e2d\u8fdb\u4e00\u6b65\u8f93\u51fa\u89d2\u5ea6\u9884\u6d4b\u3002","title":"\u603b\u4f53\u601d\u8def"},{"location":"3dDetection/Improving 3D Object Detection for Pedestrians with Virtual Multi-View Synthesis Orientation Estimation/#_2","text":"\u76f8\u673a\u653e\u7f6e\u65b9\u5f0f,\u4e0e\u539f\u6765\u76f8\u5bf9\u5c04\u7ebf\u76f8\u5bf9\u00b125\u00b0\u4e4b\u95f4\u8fde\u7eed\u653e\u7f6e\uff0c\u672c\u6587\u91c7\u7528\u7684\u662f11\u4e2a\u865a\u62df\u76f8\u673a\u7684\u6392\u5217\u3002","title":"\u5408\u6210\u76f8\u673a\u5e03\u7f6e"},{"location":"3dDetection/Improving 3D Object Detection for Pedestrians with Virtual Multi-View Synthesis Orientation Estimation/#_3","text":"\u539f\u6765\u7684\u70b9\u4e91\u53ea\u80fd\u63d0\u4f9b\u4e00\u4e2a\u7a00\u758f\u7684\u6df1\u5ea6\u4f30\u8ba1\uff0c\u672c\u6587\u5229\u7528\u4e86\u4f5c\u8005\u7684 \u53e6\u4e00\u7bc7\u6df1\u5ea6\u8865\u5168\u7b97\u6cd5.pdf , \u7b80\u4ecb ,\u5c06\u7a00\u758f\u7684\u70b9\u4e91\u53d8\u6210\u5bc6\u96c6\u7684\u6df1\u5ea6\u56fe\uff0c\u4e5f\u5c31\u53ef\u4ee5\u5bf9\u5e94\u50cf\u7d20\u4e0a\u8272\u3002","title":"\u6df1\u5ea6\u8865\u5168\u4e0a\u8272"},{"location":"3dDetection/Improving 3D Object Detection for Pedestrians with Virtual Multi-View Synthesis Orientation Estimation/#_4","text":"\u57fa\u7840\u76843D\u68c0\u6d4b\u4f7f\u7528\u7684\u662f AVOD.pdf ,\u89d2\u5ea6\u4f30\u8ba1\u4f7f\u7528\u7684\u662f\u5728kitti 2D\u68c0\u6d4b\u95ee\u9898\u4e2d\u9884\u8bad\u7ec3\u7684Res101(\u4e2a\u4eba\u7406\u89e3\u8fd9\u662f\u4e00\u4e2a\u76f8\u5f53\u5927\u7684\u7f51\u7edc) \u672c\u6587\u7684\u6210\u679c\u662f\u5c06\u884c\u4eba\u4e09\u7ef4\u68c0\u6d4b\u7684\u89d2\u5ea6\u4f30\u8ba1\u7cbe\u5ea6\u5927\u5e45\u5ea6\u63d0\u5347\u3002","title":"\u5176\u4ed6\u8bad\u7ec3\u7ec6\u8282"},{"location":"3dDetection/IoU Loss for 2D/","text":"IoU Loss for 2D/3D Object Detection \u8fd9\u7bc7\u8bba\u6587\u7684\u6838\u5fc3\u8d21\u732e\u662f\u7ed9\u51fa\u4e86\u6240\u8c13\u7684IoU Loss,\u56e0\u4e3a\u62fc\u70b9\u7684\u8fc7\u7a0b\u4e2d\u5173\u952e\u70b9\u5728\u4e8e\u63d0\u5347IoU\u7684\u503c\uff0c\u4f46\u662f\u6211\u4eec\u76ee\u524d\u6ca1\u6709\u76f4\u63a5\u68af\u5ea6\u4f18\u5316IoU\u7684\u65b9\u6cd5\uff0c\u8fd9\u7bc7\u6587\u7ae0\u7ed9\u51fa\u7684IoU Loss\u5c31\u662f\u7ed9\u51fa\u4e00\u4e2a\u53ef\u5fae\u5206\u7684\u635f\u5931\u51fd\u6570\uff0c\u901a\u8fc7\u76f4\u63a5\u4f18\u5316IoU\u63d0\u9ad8\u5206\u6570 \u4e00\u822c\u5e26\u6709\u65cb\u8f6c\u76842D IoU\u7b97\u6cd5 \u8ba1\u7b97\u4e24\u4e2a\u5e73\u9762\u533a\u57df\u7684\u9762\u79ef \u627e\u51fa\u4e24\u4e2a\u533a\u57df\u76f8\u4ea4\u5f97\u5230\u7684\u51f8\u591a\u8fb9\u5f62\u7684\u70b9\uff0c\u8fd9\u4e9b\u70b9\u6709\u4e24\u79cd\u6765\u6e90\u53ef\u80fd\uff0c\u4e00\u4e2a\u662f\u4e24\u4e2abox\u8fb9\u7f18\u7684\u4ea4\u70b9\uff0c\u4e00\u4e2a\u662f\u51fa\u73b0\u5728\u53e6\u4e00\u4e2abbox\u533a\u57df\u4e2d\u7684\u539f\u6765box\u7684\u70b9 \u5c06\u8fd9\u4e9b\u51f8\u591a\u8fb9\u5f62\u7684\u8fb9\u7f18\u70b9\u9006\u65f6\u9488\u6216\u8005\u987a\u65f6\u9488\u6392\u5e8f\uff0c\u7b97\u6cd5\u662f\uff1a\u5148\u6c42\u51fa\u51f8\u591a\u8fb9\u5f62\u7684\u4e2d\u5fc3\u70b9\uff0c\u7136\u540e\u9010\u4e2a\u6c42\u51fa\u65cb\u8f6c\u89d2\u5ea6\uff0c\u7136\u540e\u5c06\u8fd9\u4e2a\u65cb\u8f6c\u89d2\u5ea6\u6392\u5e8f \u5c06\u51f8\u591a\u8fb9\u5f62\u5206\u89e3\u4e3a\u591a\u4e2a\u5c0f\u4e09\u89d2\u5f62\uff0c\u5e76\u6c42\u51fa\u603b\u5408\u9762\u79ef \u5f97\u5230overlap\u9762\u79ef\u540e\u6c42\u51faIoU 3D IoU \u53ea\u9700\u8981\u5728\u6c42\u51faover lap\u7684\u57fa\u7840\u4e0a\uff0c\u5728\u9ad8\u5ea6\u4e0a\u8865\u5145\u4e00\u4e9b\u53c2\u6570\u5373\u53ef\uff1a IoU_{3D} = \\frac{Area_{overlap} \\times h_{overlap}} {Area_g \\times h_g + Area_d \\times h_d - Area_{overlap} \\times h_{overlap}}","title":"IoU Loss for 2D/3D Object Detection"},{"location":"3dDetection/IoU Loss for 2D/#iou-loss-for-2d3d-object-detection","text":"\u8fd9\u7bc7\u8bba\u6587\u7684\u6838\u5fc3\u8d21\u732e\u662f\u7ed9\u51fa\u4e86\u6240\u8c13\u7684IoU Loss,\u56e0\u4e3a\u62fc\u70b9\u7684\u8fc7\u7a0b\u4e2d\u5173\u952e\u70b9\u5728\u4e8e\u63d0\u5347IoU\u7684\u503c\uff0c\u4f46\u662f\u6211\u4eec\u76ee\u524d\u6ca1\u6709\u76f4\u63a5\u68af\u5ea6\u4f18\u5316IoU\u7684\u65b9\u6cd5\uff0c\u8fd9\u7bc7\u6587\u7ae0\u7ed9\u51fa\u7684IoU Loss\u5c31\u662f\u7ed9\u51fa\u4e00\u4e2a\u53ef\u5fae\u5206\u7684\u635f\u5931\u51fd\u6570\uff0c\u901a\u8fc7\u76f4\u63a5\u4f18\u5316IoU\u63d0\u9ad8\u5206\u6570","title":"IoU Loss for 2D/3D Object Detection"},{"location":"3dDetection/IoU Loss for 2D/#2d-iou","text":"\u8ba1\u7b97\u4e24\u4e2a\u5e73\u9762\u533a\u57df\u7684\u9762\u79ef \u627e\u51fa\u4e24\u4e2a\u533a\u57df\u76f8\u4ea4\u5f97\u5230\u7684\u51f8\u591a\u8fb9\u5f62\u7684\u70b9\uff0c\u8fd9\u4e9b\u70b9\u6709\u4e24\u79cd\u6765\u6e90\u53ef\u80fd\uff0c\u4e00\u4e2a\u662f\u4e24\u4e2abox\u8fb9\u7f18\u7684\u4ea4\u70b9\uff0c\u4e00\u4e2a\u662f\u51fa\u73b0\u5728\u53e6\u4e00\u4e2abbox\u533a\u57df\u4e2d\u7684\u539f\u6765box\u7684\u70b9 \u5c06\u8fd9\u4e9b\u51f8\u591a\u8fb9\u5f62\u7684\u8fb9\u7f18\u70b9\u9006\u65f6\u9488\u6216\u8005\u987a\u65f6\u9488\u6392\u5e8f\uff0c\u7b97\u6cd5\u662f\uff1a\u5148\u6c42\u51fa\u51f8\u591a\u8fb9\u5f62\u7684\u4e2d\u5fc3\u70b9\uff0c\u7136\u540e\u9010\u4e2a\u6c42\u51fa\u65cb\u8f6c\u89d2\u5ea6\uff0c\u7136\u540e\u5c06\u8fd9\u4e2a\u65cb\u8f6c\u89d2\u5ea6\u6392\u5e8f \u5c06\u51f8\u591a\u8fb9\u5f62\u5206\u89e3\u4e3a\u591a\u4e2a\u5c0f\u4e09\u89d2\u5f62\uff0c\u5e76\u6c42\u51fa\u603b\u5408\u9762\u79ef \u5f97\u5230overlap\u9762\u79ef\u540e\u6c42\u51faIoU","title":"\u4e00\u822c\u5e26\u6709\u65cb\u8f6c\u76842D IoU\u7b97\u6cd5"},{"location":"3dDetection/IoU Loss for 2D/#3d-iou","text":"\u53ea\u9700\u8981\u5728\u6c42\u51faover lap\u7684\u57fa\u7840\u4e0a\uff0c\u5728\u9ad8\u5ea6\u4e0a\u8865\u5145\u4e00\u4e9b\u53c2\u6570\u5373\u53ef\uff1a IoU_{3D} = \\frac{Area_{overlap} \\times h_{overlap}} {Area_g \\times h_g + Area_d \\times h_d - Area_{overlap} \\times h_{overlap}}","title":"3D IoU"},{"location":"3dDetection/Kinematic_video3d/","text":"Kinematic 3D Object Detection in Monocular Video \u8fd9\u7bc7paper\u662f\u57fa\u4e8e M3D-RPN \u7684\u5355\u76ee\u65f6\u5e8f\u878d\u5408\u3002 \u6574\u4f53\u63a8\u7406\u7ed3\u6784 Modified M3D-RPN \u4fee\u6539\u7684\u7248\u672c\u4e3b\u8981\u662f\u4e24\u4e2a\uff0c\u4e00\u4e2a\u662f\u89d2\u5ea6\u7684\u9884\u6d4b\uff0c\u4e00\u4e2a\u662f\u81ea\u5e73\u8861\u635f\u5931\u51fd\u6570\u3002 \u89d2\u5ea6\u7684\u9884\u6d4b\u88ab\u5206\u4e3a\u4e24\u4e2a\u5206\u7c7b\u4ee5\u53ca\u4e00\u4e2a\u56de\u5f52 \u81ea\u5e73\u8861\u635f\u5931\u6709\u4e24\u4e2a\u4f5c\u7528\uff0c\u4e00\u65b9\u9762\u662f\u8ba9\u7f51\u7edc\u51b3\u5b9a\u4e0d\u786e\u5b9a\u6027\uff0c\u7528\u4e8e\u5361\u5c14\u66fc\u6ee4\u6ce2\uff0c\u53e6\u4e00\u65b9\u9762\u51cf\u5c11\u5bf9\u8fc7\u4e8e\u56f0\u96be\u7684instance\u7684\u8fc7\u62df\u5408\u3002 L=L_{2 \\mathrm{D}}+\\omega \\cdot L_{3 \\mathrm{D}}+\\lambda_{L} \\cdot(1-\\omega) \u5176\u4e2d \\lambda{L} \u4e3a\u8fc7\u53bb n_L \u4e2a\u6700\u8fd1\u7684 L_{3D} \u7684\u5747\u503c\u3002 \u5728\u63a8\u7406\u7684\u65f6\u5019\uff0c\u6700\u7ec8\u7684\u4e0d\u786e\u5b9a\u6027\u5c31\u662f \\mu = c \\cdot \\omega Ego-Motion \u4f5c\u8005\u4f7f\u7528raw data\u91cc\u9762\u7684devkit\u5728training set\u4e0a\u751f\u6210\u4e86odometry ground truth, \u7136\u540e\u7528\u7f51\u7edcDensely predict 6DOF\u7684ego motion.\u6700\u540e\u76f8\u5f53\u4e8e\u6c42\u5168\u5c40\u7684\u5747\u503c\u4f5c\u4e3a\u9884\u6d4b\u3002 \u56e0\u800c\u4e5f\u5c31\u53ef\u4ee5\u7528\u5728test\u65f6\u5c06\u5176\u4ed6\u8f66\u8f86\u7684\u8fd0\u52a8\u9650\u5236\u5728\u81ea\u5df1\u7684orientation\u4e0a\u3002 3D Kalman Filter \u72b6\u6001\u7a7a\u95f4\u7684\u8bbe\u7f6e\u4e3a \\tau = [\\tau_x, \\tau_y, \\tau_z, \\tau_w, \\tau_h, \\tau_l, \\tau_\\theta, \\tau_{\\theta_h}, \\tau_v] 3D\u4e2d\u5fc3\u70b9\uff0c3D\u5927\u5c0f\uff0c\u65b9\u5411\u4ee5\u53ca\u901f\u5ea6 \u7ebf\u6027\u7cfb\u7edf\u77e9\u9635 \\mathbf{F}=\\left[\\mathbf{I}^{9 \\times 8} \\begin{array}{cc} \\cos \\left(\\tau_{\\theta}+\\pi\\left\\lfloor\\tau_{\\theta_{h}}\\right\\rceil\\right) \\\\ 0 \\\\ -\\sin \\left(\\tau_{\\theta}+\\pi\\left\\lfloor\\tau_{\\theta_{h}}\\right\\rceil\\right) \\\\ 0 \\\\ \\vdots \\\\ 1 \\end{array}\\right] \u9884\u6d4b\u65f6\u6ce8\u610f\u9700\u8981\u5904\u7406ego-motion,\u72b6\u6001\u65b9\u7a0b\u662f\u5728\u4e16\u754c\u5750\u6807\u7cfb\u4e0a\u7684\uff0c\u800c\u7f51\u7edc\u7684\u9884\u6d4b\u662f\u5728\u76f8\u673a\u7684\u5750\u6807\u7cfb\u4e0b\u7684\u3002 \\mathbf{P}_{t}^{\\prime}=\\mathbf{F}_{t-1} \\cdot \\mathbf{P}_{t-1} \\cdot \\mathbf{F}_{t-1}^{T}+\\mathbf{I}^{9 \\times 9} \\cdot\\left(1-\\mu_{t-1}\\right) Association \u5c06\u5361\u5c14\u66fc\u6ee4\u6ce2\u7684\u8f93\u51fa\u4e0e\u65b0\u4e00\u5e27\u7684\u9884\u6d4b\u8fdb\u884c\u7ec4\u5408\uff0c\u8fd9\u8fb9\u9009\u62e9\u7684\u65b9\u6848\u662f\u8d2a\u5fc3\u7684\u6700\u4f4e\u8ddd\u79bb+2D IoU\u5339\u914d\u3002 \u89c2\u6d4b\u66f4\u65b0 \\mathbf{K}=\\mathbf{P}^{\\prime} \\mathbf{H}^{T}\\left(\\mathbf{H} \\mathbf{P}^{\\prime} \\mathbf{H}^{T}+\\mathbf{I}^{8 \\times 8}(1-\\mu) \\cdot \\lambda_{o}\\right)^{-1} \\tau_{t}=\\tau_{t}^{\\prime}+\\mathbf{K}\\left(b-\\mathbf{H} \\tau_{t}^{\\prime}\\right), \\quad \\mathbf{P}_{t}=\\left(\\mathbf{I}^{9 \\times 9}-\\mathbf{K} \\mathbf{H}\\right) \\mathbf{P}_{t}^{\\prime}","title":"Kinematic 3D Object Detection in Monocular Video"},{"location":"3dDetection/Kinematic_video3d/#kinematic-3d-object-detection-in-monocular-video","text":"\u8fd9\u7bc7paper\u662f\u57fa\u4e8e M3D-RPN \u7684\u5355\u76ee\u65f6\u5e8f\u878d\u5408\u3002","title":"Kinematic 3D Object Detection in Monocular Video"},{"location":"3dDetection/Kinematic_video3d/#_1","text":"","title":"\u6574\u4f53\u63a8\u7406\u7ed3\u6784"},{"location":"3dDetection/Kinematic_video3d/#modified-m3d-rpn","text":"\u4fee\u6539\u7684\u7248\u672c\u4e3b\u8981\u662f\u4e24\u4e2a\uff0c\u4e00\u4e2a\u662f\u89d2\u5ea6\u7684\u9884\u6d4b\uff0c\u4e00\u4e2a\u662f\u81ea\u5e73\u8861\u635f\u5931\u51fd\u6570\u3002 \u89d2\u5ea6\u7684\u9884\u6d4b\u88ab\u5206\u4e3a\u4e24\u4e2a\u5206\u7c7b\u4ee5\u53ca\u4e00\u4e2a\u56de\u5f52 \u81ea\u5e73\u8861\u635f\u5931\u6709\u4e24\u4e2a\u4f5c\u7528\uff0c\u4e00\u65b9\u9762\u662f\u8ba9\u7f51\u7edc\u51b3\u5b9a\u4e0d\u786e\u5b9a\u6027\uff0c\u7528\u4e8e\u5361\u5c14\u66fc\u6ee4\u6ce2\uff0c\u53e6\u4e00\u65b9\u9762\u51cf\u5c11\u5bf9\u8fc7\u4e8e\u56f0\u96be\u7684instance\u7684\u8fc7\u62df\u5408\u3002 L=L_{2 \\mathrm{D}}+\\omega \\cdot L_{3 \\mathrm{D}}+\\lambda_{L} \\cdot(1-\\omega) \u5176\u4e2d \\lambda{L} \u4e3a\u8fc7\u53bb n_L \u4e2a\u6700\u8fd1\u7684 L_{3D} \u7684\u5747\u503c\u3002 \u5728\u63a8\u7406\u7684\u65f6\u5019\uff0c\u6700\u7ec8\u7684\u4e0d\u786e\u5b9a\u6027\u5c31\u662f \\mu = c \\cdot \\omega","title":"Modified M3D-RPN"},{"location":"3dDetection/Kinematic_video3d/#ego-motion","text":"\u4f5c\u8005\u4f7f\u7528raw data\u91cc\u9762\u7684devkit\u5728training set\u4e0a\u751f\u6210\u4e86odometry ground truth, \u7136\u540e\u7528\u7f51\u7edcDensely predict 6DOF\u7684ego motion.\u6700\u540e\u76f8\u5f53\u4e8e\u6c42\u5168\u5c40\u7684\u5747\u503c\u4f5c\u4e3a\u9884\u6d4b\u3002 \u56e0\u800c\u4e5f\u5c31\u53ef\u4ee5\u7528\u5728test\u65f6\u5c06\u5176\u4ed6\u8f66\u8f86\u7684\u8fd0\u52a8\u9650\u5236\u5728\u81ea\u5df1\u7684orientation\u4e0a\u3002","title":"Ego-Motion"},{"location":"3dDetection/Kinematic_video3d/#3d-kalman-filter","text":"\u72b6\u6001\u7a7a\u95f4\u7684\u8bbe\u7f6e\u4e3a \\tau = [\\tau_x, \\tau_y, \\tau_z, \\tau_w, \\tau_h, \\tau_l, \\tau_\\theta, \\tau_{\\theta_h}, \\tau_v] 3D\u4e2d\u5fc3\u70b9\uff0c3D\u5927\u5c0f\uff0c\u65b9\u5411\u4ee5\u53ca\u901f\u5ea6 \u7ebf\u6027\u7cfb\u7edf\u77e9\u9635 \\mathbf{F}=\\left[\\mathbf{I}^{9 \\times 8} \\begin{array}{cc} \\cos \\left(\\tau_{\\theta}+\\pi\\left\\lfloor\\tau_{\\theta_{h}}\\right\\rceil\\right) \\\\ 0 \\\\ -\\sin \\left(\\tau_{\\theta}+\\pi\\left\\lfloor\\tau_{\\theta_{h}}\\right\\rceil\\right) \\\\ 0 \\\\ \\vdots \\\\ 1 \\end{array}\\right] \u9884\u6d4b\u65f6\u6ce8\u610f\u9700\u8981\u5904\u7406ego-motion,\u72b6\u6001\u65b9\u7a0b\u662f\u5728\u4e16\u754c\u5750\u6807\u7cfb\u4e0a\u7684\uff0c\u800c\u7f51\u7edc\u7684\u9884\u6d4b\u662f\u5728\u76f8\u673a\u7684\u5750\u6807\u7cfb\u4e0b\u7684\u3002 \\mathbf{P}_{t}^{\\prime}=\\mathbf{F}_{t-1} \\cdot \\mathbf{P}_{t-1} \\cdot \\mathbf{F}_{t-1}^{T}+\\mathbf{I}^{9 \\times 9} \\cdot\\left(1-\\mu_{t-1}\\right)","title":"3D Kalman Filter"},{"location":"3dDetection/Kinematic_video3d/#association","text":"\u5c06\u5361\u5c14\u66fc\u6ee4\u6ce2\u7684\u8f93\u51fa\u4e0e\u65b0\u4e00\u5e27\u7684\u9884\u6d4b\u8fdb\u884c\u7ec4\u5408\uff0c\u8fd9\u8fb9\u9009\u62e9\u7684\u65b9\u6848\u662f\u8d2a\u5fc3\u7684\u6700\u4f4e\u8ddd\u79bb+2D IoU\u5339\u914d\u3002 \u89c2\u6d4b\u66f4\u65b0 \\mathbf{K}=\\mathbf{P}^{\\prime} \\mathbf{H}^{T}\\left(\\mathbf{H} \\mathbf{P}^{\\prime} \\mathbf{H}^{T}+\\mathbf{I}^{8 \\times 8}(1-\\mu) \\cdot \\lambda_{o}\\right)^{-1} \\tau_{t}=\\tau_{t}^{\\prime}+\\mathbf{K}\\left(b-\\mathbf{H} \\tau_{t}^{\\prime}\\right), \\quad \\mathbf{P}_{t}=\\left(\\mathbf{I}^{9 \\times 9}-\\mathbf{K} \\mathbf{H}\\right) \\mathbf{P}_{t}^{\\prime}","title":"Association"},{"location":"3dDetection/LaserNet/","text":"LaserNet: An Efficient Probabilistic 3D Object Detector for Autonomous Driving \u8fd9\u7bc7\u8bba\u6587\u5b9e\u73b03D object detection\u5229\u7528\u7684\u6570\u636e\u7c7b\u578b\u4e3b\u8981\u662f\u70b9\u4e91\u7684Range view\u56fe\u50cf\u3002\u76ee\u7684\u662f\u907f\u514dBEV\u8fc7\u4e8e\u7a00\u758f\u7684\u95ee\u9898\u3002 \u603b\u4f53pipeline \u6570\u636e\u7ec4\u7ec7\u65b9\u5f0f Lidar\u4f1a\u968f\u7740\u65cb\u8f6c\u751f\u6210\u4e00\u4e2a\u5706\u67f1\u72b6\u7684range image,\u6570\u636e\u96c6\u4e2d\u4f7f\u7528\u7684\u6fc0\u5149\u96f7\u8fbevelodyne 64\u7ebf\uff0c\u5782\u76f4\u65b9\u5411\u89d2\u5ea6\u5206\u8fa8\u7387\u7ea6\u4e3a0.4\u00b0\uff0c\u6c34\u5e73\u65b9\u5411\u7684\u89d2\u5ea6\u5206\u8fa8\u7387\u7ea6\u4e3a0.2\u00b0,\u76f4\u63a5\u5c06\u5706\u67f1\u5750\u6807\u7684lidar\u8f6c\u6362\u4e3a\"\u56fe\u50cf\",\u8fd9\u4e2a\u7a0d\u5fae\u7c7b\u4f3c\u4e8e MV3D \u8ddd\u79bb\u3001\u9ad8\u5ea6\u3001\u53cd\u5c04\u5f3a\u5ea6\u3001\u662f\u5426\u5b58\u5728\u70b9\u7684flag\u5206\u522b\u6210\u4e3a\u4e94\u4e2arange view image\u7684channel \u7f51\u7edc\u7ed3\u6784 \u672c\u6587\u91c7\u7528\u4e00\u4e2a\u5168\u5377\u79ef\u7684\u7ed3\u6784\uff0c\u8f93\u51fa\u7684\u662f\u6bcf\u4e00\u4e2aRange view image\u5bf9\u5e94\u4e00\u4e2apixel\u5bf9\u5e94\u4e00\u4e2aprediction\u3002 \u9884\u6d4b\u8f93\u51fa \u7531\u4e8e\u4e0d\u540c\u7684\u70b9\u6709\u4e0d\u540c\u7684\u89c2\u6d4b\uff0c\u800c\u70b9\u4e91\u89c2\u6d4b\u6709\u4e0d\u786e\u5b9a\u6027\uff0c\u8fd9\u91cc\u5c31\u5c06\u4e0d\u786e\u5b9a\u6027\u5177\u4f53\u7684\u8003\u8651\uff0c(\u591a\u9884\u6d4bvariance)\u3002 \u540c\u65f6\u5047\u8bbe\u6240\u6709\u7269\u4f53\u90fd\u5728\u540c\u4e00\u4e2aground plane\u4e0a\uff0c\u56e0\u6b64\u4e00\u4e2abounding box\u7531\u4e00\u4e2a\u56db\u4e2a\u89d2\u843d\u786e\u5b9a(BEV\u4e2d)\uff0c\u5e76\u4e14\u9ad8\u5ea6\u56fa\u5b9a\u3002 \u8fd9\u91cc\u5177\u4f53\u7684\u8f93\u51fa\u662frelative center (d_x, d_y) \uff0c\u76f8\u5bf9\u8f6c\u89d2 (\\omega_x, \\omega_y) = (cos\\omega, sin\\omega) \u4ee5\u53cadimensions= (l,w) \u3002\u8fd9\u4e2a \\omega \u662f\u89c2\u6d4b\u89d2(\u89c6\u89c9\u63a2\u6d4b\u91cc\u9762\u5e38\u7528\u7684)\u3002\u6700\u7ec8\u8f93\u51fa\u77e2\u91cf ={d_{x,k}, d_{y,k}, \\omega_{x,k}, \\omega_{y,k},l_k, w_k}^K_{k=1} + {s_k}_{k=1}^K + {\\alpha_k}^K_{k=1} .\u5176\u4e2d \\alpha \u4e3amixture weights, K \u4e3amixture model\u7684\u6570\u91cf\u5b50\u6a21\u578b\u3002 \u5747\u503c\u504f\u79fb\u805a\u7c7b(Mean Shift Clustering) \u8fd9\u91cc\u7684\u8003\u8651\u662f\uff0c\u7531\u4e8e\u9884\u6d4b\u662f\u5bc6\u96c6\u7684\uff0c\u4f46\u662f\u76f8\u540c\u70b9\u9644\u8fd1\u7684\u9884\u6d4b\u5f88\u6709\u53ef\u80fd\u4f1a\u6709\u5f88\u5927\u7684\u76f8\u4f3c(\u5411\u540c\u4e00\u4e2a\u7269\u4f53\u9760\u62e2)\uff0c\u800c\u5355\u4e2a\u9884\u6d4b\u4f1a\u6709\u566a\u58f0\uff0c\u8fd9\u91cc\u8003\u8651\u7684\u662f\u8ba9\u9644\u8fd1\u591a\u4e2a\u70b9\u7684prediction\u5bf9\u540c\u4e00\u4e2aobject\u8fdb\u884c\u8d21\u732e\u3002 \u8fd9\u91cc\u5bf9\u4e2d\u5fc3\u70b9\u7684xy\u70b9\u8fd9\u4e24\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u805a\u7c7b\u3002\u5173\u4e8emean shift clustering \u53ef\u4ee5\u53c2\u89c1 wiki . \u672c\u6587\u7b97\u6cd5\uff1a \u5c06\u4fef\u89c6\u56fe\u4f7f\u7528 \\Delta x \\Delta y \u79bb\u6563\u5316\uff0c\u521d\u59cb\u5316\u6876(bin) m_i \uff0c \u5bf9\u4e8e\u62e5\u6709\u591a\u4e8e\u4e00\u4e2abox center\u7684\u6876 m_i ,\u7528\u5747\u503c\u8ba1\u7b97\uff0c\u5f97\u5230\u6876\u5bf9\u4e2d\u5fc3\u5750\u6807\u7684\u521d\u59cb\u4f30\u8ba1\uff0c\u7528 S_i \u8bb0\u5f55\u6876\u5185\u7684\u70b9\u96c6 \u66f4\u65b0\u65b0\u7684\u4e2d\u5fc3 m_i = \\frac{\\sum_{j \\in i \\bigcup N(i)} K_{i,j}(m_j * |S_j|)}{\\sum_{j \\in i \\bigcup N(i)} K_{i,j}|S_j|} \u5176\u4e2d, K = exp(-\\frac{||m_i-m_j||^2}{\\Delta x^2 + \\Delta y^2}) \u4e3a\u6838\u51fd\u6570\uff0c N(i) \u4e3a\u7b2c i \u4e2a\u6876\u9644\u8fd1\u76848\u4e2a\u6876.\u5176\u4e2d\u5bf9\u96c6\u5408\u7684 || \u64cd\u4f5c\u4e3a\u53d6\u96c6\u5408\u4e2d\u70b9\u7684\u6570\u91cf\u3002 \u5982\u679c\u7b2c i \u4e2a\u6876\u7684\u4e2d\u5fc3\u5728 j \u4e2a\u6876\u7684\u5185\u90e8\uff0c\u90a3\u4e48\u5c06 i,j \u52a0\u6743\u878d\u5408\uff0c\u7b2c i \u4e2a\u6876\u7684\u4e2d\u5fc3\u548c S_i \u5f520 \u4f5c\u8005\u8868\u793a\u8fd9\u4e9b\u5185\u5bb9\u90fd\u662f\u53ef\u4ee5\u7528GPU\u52a0\u901f\u7684\u3002\u5bf9\u7b2c3,4\u6b65\u8fed\u4ee3\u53ef\u5f97\u5230\u878d\u5408\u70b9\u3002 \u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u96c6\u5408\uff0c\u53ef\u4ee5\u7528\u5982\u4e0b\u516c\u5f0f\u5c06\u6876\u5185\u7684\u9884\u6d4b\u503c\u8fdb\u884c\u6c42\u548c\uff0c\u65b9\u5dee\u91cd\u7b97 \\hat b_i = \\frac{\\sum_{j \\in S_i} w_j b_j}{\\sum_{j \\in S_i} w_j} \\hat \\sigma^2 = (\\sum_{j\\in S_i}\\frac{1}{\\sigma_j^2})^{-1} \u672c\u6587\u5efa\u8bae \\Delta x = \\Delta y = 0.5 \u8bad\u7ec3\u635f\u5931 \u6700\u7ec8\u53ef\u4ee5\u5e26\u7740\u4e0d\u786e\u5b9a\u6027\u8f93\u51fa\u3002 \u9996\u5148 \\mathcal{L}_{cls} \u4e3afocal loss\uff0c\u8fd9\u91cc\u53ef\u4ee5\u53c2\u8003 \u8fd9\u7bc7 \\mathcal{L}_{box} = \\sum_n \\frac{1}{\\hat\\sigma_{k*}} |\\hat b_{n, k*} - b^{gt}_n| + log\\hat\\sigma_k \u81ea\u9002\u5e94NMS \u7ecf\u8fc7\u672c\u56fe\u7684\u5206\u6790 \u5f97\u5230\u53ef\u5bb9\u5fcd\u7684\u6700\u5927IoU\u4e3a t = max(\\frac{\\sigma_1 + \\sigma_2}{0.5 * w_1 + 0.5 * w_2 - \\sigma_1 - \\sigma2} ,0) \u5176\u4e2d w_1, w_2 \u4e3a\u5bbd\u5ea6\u3002","title":"LaserNet: An Efficient Probabilistic 3D Object Detector for Autonomous Driving"},{"location":"3dDetection/LaserNet/#lasernet-an-efficient-probabilistic-3d-object-detector-for-autonomous-driving","text":"\u8fd9\u7bc7\u8bba\u6587\u5b9e\u73b03D object detection\u5229\u7528\u7684\u6570\u636e\u7c7b\u578b\u4e3b\u8981\u662f\u70b9\u4e91\u7684Range view\u56fe\u50cf\u3002\u76ee\u7684\u662f\u907f\u514dBEV\u8fc7\u4e8e\u7a00\u758f\u7684\u95ee\u9898\u3002","title":"LaserNet: An Efficient Probabilistic 3D Object Detector for Autonomous Driving"},{"location":"3dDetection/LaserNet/#pipeline","text":"","title":"\u603b\u4f53pipeline"},{"location":"3dDetection/LaserNet/#_1","text":"Lidar\u4f1a\u968f\u7740\u65cb\u8f6c\u751f\u6210\u4e00\u4e2a\u5706\u67f1\u72b6\u7684range image,\u6570\u636e\u96c6\u4e2d\u4f7f\u7528\u7684\u6fc0\u5149\u96f7\u8fbevelodyne 64\u7ebf\uff0c\u5782\u76f4\u65b9\u5411\u89d2\u5ea6\u5206\u8fa8\u7387\u7ea6\u4e3a0.4\u00b0\uff0c\u6c34\u5e73\u65b9\u5411\u7684\u89d2\u5ea6\u5206\u8fa8\u7387\u7ea6\u4e3a0.2\u00b0,\u76f4\u63a5\u5c06\u5706\u67f1\u5750\u6807\u7684lidar\u8f6c\u6362\u4e3a\"\u56fe\u50cf\",\u8fd9\u4e2a\u7a0d\u5fae\u7c7b\u4f3c\u4e8e MV3D \u8ddd\u79bb\u3001\u9ad8\u5ea6\u3001\u53cd\u5c04\u5f3a\u5ea6\u3001\u662f\u5426\u5b58\u5728\u70b9\u7684flag\u5206\u522b\u6210\u4e3a\u4e94\u4e2arange view image\u7684channel","title":"\u6570\u636e\u7ec4\u7ec7\u65b9\u5f0f"},{"location":"3dDetection/LaserNet/#_2","text":"\u672c\u6587\u91c7\u7528\u4e00\u4e2a\u5168\u5377\u79ef\u7684\u7ed3\u6784\uff0c\u8f93\u51fa\u7684\u662f\u6bcf\u4e00\u4e2aRange view image\u5bf9\u5e94\u4e00\u4e2apixel\u5bf9\u5e94\u4e00\u4e2aprediction\u3002","title":"\u7f51\u7edc\u7ed3\u6784"},{"location":"3dDetection/LaserNet/#_3","text":"\u7531\u4e8e\u4e0d\u540c\u7684\u70b9\u6709\u4e0d\u540c\u7684\u89c2\u6d4b\uff0c\u800c\u70b9\u4e91\u89c2\u6d4b\u6709\u4e0d\u786e\u5b9a\u6027\uff0c\u8fd9\u91cc\u5c31\u5c06\u4e0d\u786e\u5b9a\u6027\u5177\u4f53\u7684\u8003\u8651\uff0c(\u591a\u9884\u6d4bvariance)\u3002 \u540c\u65f6\u5047\u8bbe\u6240\u6709\u7269\u4f53\u90fd\u5728\u540c\u4e00\u4e2aground plane\u4e0a\uff0c\u56e0\u6b64\u4e00\u4e2abounding box\u7531\u4e00\u4e2a\u56db\u4e2a\u89d2\u843d\u786e\u5b9a(BEV\u4e2d)\uff0c\u5e76\u4e14\u9ad8\u5ea6\u56fa\u5b9a\u3002 \u8fd9\u91cc\u5177\u4f53\u7684\u8f93\u51fa\u662frelative center (d_x, d_y) \uff0c\u76f8\u5bf9\u8f6c\u89d2 (\\omega_x, \\omega_y) = (cos\\omega, sin\\omega) \u4ee5\u53cadimensions= (l,w) \u3002\u8fd9\u4e2a \\omega \u662f\u89c2\u6d4b\u89d2(\u89c6\u89c9\u63a2\u6d4b\u91cc\u9762\u5e38\u7528\u7684)\u3002\u6700\u7ec8\u8f93\u51fa\u77e2\u91cf ={d_{x,k}, d_{y,k}, \\omega_{x,k}, \\omega_{y,k},l_k, w_k}^K_{k=1} + {s_k}_{k=1}^K + {\\alpha_k}^K_{k=1} .\u5176\u4e2d \\alpha \u4e3amixture weights, K \u4e3amixture model\u7684\u6570\u91cf\u5b50\u6a21\u578b\u3002","title":"\u9884\u6d4b\u8f93\u51fa"},{"location":"3dDetection/LaserNet/#mean-shift-clustering","text":"\u8fd9\u91cc\u7684\u8003\u8651\u662f\uff0c\u7531\u4e8e\u9884\u6d4b\u662f\u5bc6\u96c6\u7684\uff0c\u4f46\u662f\u76f8\u540c\u70b9\u9644\u8fd1\u7684\u9884\u6d4b\u5f88\u6709\u53ef\u80fd\u4f1a\u6709\u5f88\u5927\u7684\u76f8\u4f3c(\u5411\u540c\u4e00\u4e2a\u7269\u4f53\u9760\u62e2)\uff0c\u800c\u5355\u4e2a\u9884\u6d4b\u4f1a\u6709\u566a\u58f0\uff0c\u8fd9\u91cc\u8003\u8651\u7684\u662f\u8ba9\u9644\u8fd1\u591a\u4e2a\u70b9\u7684prediction\u5bf9\u540c\u4e00\u4e2aobject\u8fdb\u884c\u8d21\u732e\u3002 \u8fd9\u91cc\u5bf9\u4e2d\u5fc3\u70b9\u7684xy\u70b9\u8fd9\u4e24\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u805a\u7c7b\u3002\u5173\u4e8emean shift clustering \u53ef\u4ee5\u53c2\u89c1 wiki . \u672c\u6587\u7b97\u6cd5\uff1a \u5c06\u4fef\u89c6\u56fe\u4f7f\u7528 \\Delta x \\Delta y \u79bb\u6563\u5316\uff0c\u521d\u59cb\u5316\u6876(bin) m_i \uff0c \u5bf9\u4e8e\u62e5\u6709\u591a\u4e8e\u4e00\u4e2abox center\u7684\u6876 m_i ,\u7528\u5747\u503c\u8ba1\u7b97\uff0c\u5f97\u5230\u6876\u5bf9\u4e2d\u5fc3\u5750\u6807\u7684\u521d\u59cb\u4f30\u8ba1\uff0c\u7528 S_i \u8bb0\u5f55\u6876\u5185\u7684\u70b9\u96c6 \u66f4\u65b0\u65b0\u7684\u4e2d\u5fc3 m_i = \\frac{\\sum_{j \\in i \\bigcup N(i)} K_{i,j}(m_j * |S_j|)}{\\sum_{j \\in i \\bigcup N(i)} K_{i,j}|S_j|} \u5176\u4e2d, K = exp(-\\frac{||m_i-m_j||^2}{\\Delta x^2 + \\Delta y^2}) \u4e3a\u6838\u51fd\u6570\uff0c N(i) \u4e3a\u7b2c i \u4e2a\u6876\u9644\u8fd1\u76848\u4e2a\u6876.\u5176\u4e2d\u5bf9\u96c6\u5408\u7684 || \u64cd\u4f5c\u4e3a\u53d6\u96c6\u5408\u4e2d\u70b9\u7684\u6570\u91cf\u3002 \u5982\u679c\u7b2c i \u4e2a\u6876\u7684\u4e2d\u5fc3\u5728 j \u4e2a\u6876\u7684\u5185\u90e8\uff0c\u90a3\u4e48\u5c06 i,j \u52a0\u6743\u878d\u5408\uff0c\u7b2c i \u4e2a\u6876\u7684\u4e2d\u5fc3\u548c S_i \u5f520 \u4f5c\u8005\u8868\u793a\u8fd9\u4e9b\u5185\u5bb9\u90fd\u662f\u53ef\u4ee5\u7528GPU\u52a0\u901f\u7684\u3002\u5bf9\u7b2c3,4\u6b65\u8fed\u4ee3\u53ef\u5f97\u5230\u878d\u5408\u70b9\u3002 \u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u96c6\u5408\uff0c\u53ef\u4ee5\u7528\u5982\u4e0b\u516c\u5f0f\u5c06\u6876\u5185\u7684\u9884\u6d4b\u503c\u8fdb\u884c\u6c42\u548c\uff0c\u65b9\u5dee\u91cd\u7b97 \\hat b_i = \\frac{\\sum_{j \\in S_i} w_j b_j}{\\sum_{j \\in S_i} w_j} \\hat \\sigma^2 = (\\sum_{j\\in S_i}\\frac{1}{\\sigma_j^2})^{-1} \u672c\u6587\u5efa\u8bae \\Delta x = \\Delta y = 0.5","title":"\u5747\u503c\u504f\u79fb\u805a\u7c7b(Mean Shift Clustering)"},{"location":"3dDetection/LaserNet/#_4","text":"\u6700\u7ec8\u53ef\u4ee5\u5e26\u7740\u4e0d\u786e\u5b9a\u6027\u8f93\u51fa\u3002 \u9996\u5148 \\mathcal{L}_{cls} \u4e3afocal loss\uff0c\u8fd9\u91cc\u53ef\u4ee5\u53c2\u8003 \u8fd9\u7bc7 \\mathcal{L}_{box} = \\sum_n \\frac{1}{\\hat\\sigma_{k*}} |\\hat b_{n, k*} - b^{gt}_n| + log\\hat\\sigma_k","title":"\u8bad\u7ec3\u635f\u5931"},{"location":"3dDetection/LaserNet/#nms","text":"\u7ecf\u8fc7\u672c\u56fe\u7684\u5206\u6790 \u5f97\u5230\u53ef\u5bb9\u5fcd\u7684\u6700\u5927IoU\u4e3a t = max(\\frac{\\sigma_1 + \\sigma_2}{0.5 * w_1 + 0.5 * w_2 - \\sigma_1 - \\sigma2} ,0) \u5176\u4e2d w_1, w_2 \u4e3a\u5bbd\u5ea6\u3002","title":"\u81ea\u9002\u5e94NMS"},{"location":"3dDetection/M3D-RPN_Monocular_3D_Region_Proposal_Network_for_Object_Detection/","text":"M3D-RPN: Monocular 3D Region Proposal Network for Object Detection \u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u4f7f\u7528\u5355\u76ee\u76f8\u673a\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528\u4e86\u878d\u54082D-3D proposal\u7684\u65b9\u5f0f\uff0cuse depth-aware convolution,\u540e\u7aef\u4f18\u5316\u7ed3\u5408\u5404\u79cd\u4fe1\u606f\uff0c\u63d0\u5347\u5bf9 \\theta \u7684\u9884\u6d4b\u6027\u80fd \u603b\u4f53\u601d\u8def \u8fd9\u4e2a\u7f51\u7edc\u88ab\u8981\u6c42\u540c\u65f6\u8f93\u51fa2D\u4e0e3D\u9884\u6d4b\uff0ccost function\u540c\u65f6\u67093D\u6846\u4ee5\u53ca2D\u6846 depth-aware convolution\u5982\u56fe\uff0c\u5c31\u662f\u5728\u4e0d\u540c\u7684\u9ad8\u5ea6\u4e0a\u4f7f\u7528\u4e0d\u540c\u7684\u5377\u79ef\u6838\uff0c\u4e3a\u4e86\u4f7f\u5f97\u8fd0\u7b97\u5feb\uff0cpytorch implementation\u4e0a\u4f5c\u8005\u5c06\u5176reshape\uff0c\u7136\u540e\u4f7f\u7528depth-wise convolution(channel\u7ef4\u5ea6\u5206\u7ec4convolution) \u5176\u540e\u4f7f\u7528\u7684\u662f\u9010\u6b65\u4fee\u6539 \\theta \u4f7f\u5f97\u4e09\u7ef4\u5750\u6807\u4e0e\u4e8c\u7ef4\u6846\u5bf9\u9f50\uff0c\u7c7b\u4f3c\u4e8e\u6a21\u62df\u9000\u706b \u5177\u4f53\u7b97\u4e0a\u6765\u8bf4\u5c31\u662f\u6bcf\u4e00\u6b65\u8ba1\u7b973D\u5bf9\u5e942D\u6846\u4e0e\u9884\u6d4b2D\u6846\u7684L1-loss\uff0c\u4ece\u800c\u6765\u7ed9\u9884\u6d4b\u7684 \\theta \u6253\u5206","title":"M3D-RPN: Monocular 3D Region Proposal Network for Object Detection"},{"location":"3dDetection/M3D-RPN_Monocular_3D_Region_Proposal_Network_for_Object_Detection/#m3d-rpn-monocular-3d-region-proposal-network-for-object-detection","text":"\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u4f7f\u7528\u5355\u76ee\u76f8\u673a\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528\u4e86\u878d\u54082D-3D proposal\u7684\u65b9\u5f0f\uff0cuse depth-aware convolution,\u540e\u7aef\u4f18\u5316\u7ed3\u5408\u5404\u79cd\u4fe1\u606f\uff0c\u63d0\u5347\u5bf9 \\theta \u7684\u9884\u6d4b\u6027\u80fd","title":"M3D-RPN: Monocular 3D Region Proposal Network for Object Detection"},{"location":"3dDetection/M3D-RPN_Monocular_3D_Region_Proposal_Network_for_Object_Detection/#_1","text":"\u8fd9\u4e2a\u7f51\u7edc\u88ab\u8981\u6c42\u540c\u65f6\u8f93\u51fa2D\u4e0e3D\u9884\u6d4b\uff0ccost function\u540c\u65f6\u67093D\u6846\u4ee5\u53ca2D\u6846 depth-aware convolution\u5982\u56fe\uff0c\u5c31\u662f\u5728\u4e0d\u540c\u7684\u9ad8\u5ea6\u4e0a\u4f7f\u7528\u4e0d\u540c\u7684\u5377\u79ef\u6838\uff0c\u4e3a\u4e86\u4f7f\u5f97\u8fd0\u7b97\u5feb\uff0cpytorch implementation\u4e0a\u4f5c\u8005\u5c06\u5176reshape\uff0c\u7136\u540e\u4f7f\u7528depth-wise convolution(channel\u7ef4\u5ea6\u5206\u7ec4convolution) \u5176\u540e\u4f7f\u7528\u7684\u662f\u9010\u6b65\u4fee\u6539 \\theta \u4f7f\u5f97\u4e09\u7ef4\u5750\u6807\u4e0e\u4e8c\u7ef4\u6846\u5bf9\u9f50\uff0c\u7c7b\u4f3c\u4e8e\u6a21\u62df\u9000\u706b \u5177\u4f53\u7b97\u4e0a\u6765\u8bf4\u5c31\u662f\u6bcf\u4e00\u6b65\u8ba1\u7b973D\u5bf9\u5e942D\u6846\u4e0e\u9884\u6d4b2D\u6846\u7684L1-loss\uff0c\u4ece\u800c\u6765\u7ed9\u9884\u6d4b\u7684 \\theta \u6253\u5206","title":"\u603b\u4f53\u601d\u8def"},{"location":"3dDetection/Metric_3d/","text":"3D detection evaluation metric \u672c\u6587\u4e3b\u8981\u5c1d\u8bd5\u7efc\u8ff03D\u68c0\u6d4b\u7684\u8bc4\u4ef7\u65b9\u6cd5\u4ee5\u53ca\u5bf9\u5e94\u7684\u4e00\u4e9bcode\u7684\u5206\u6790\uff0c\u76ee\u6807\u662f\u6bd4\u8f83\u7ec6\u81f4\u7684\u5206\u6790\uff0c\u5728\u6709\u65b0metric\u63d0\u51fa\u7684\u8fc7\u7a0b\u4e2d\u4f1a\u6301\u7eed\u66f4\u65b0\uff0c\u5148\u7efc\u8ff0\u7684\u662fKITTI\u4e0eNuscene\u4e24\u5927benchmark\u7684\u8bc4\u4ef7\u5206\u6570\u3002 Average Precisiong - Kitti Official cpp code fast numba code \u6574\u4f53\u601d\u8def\u4e0a\u6765\u8bf4\uff0cKITTI\u7684\u6d4b\u8bd5\u662f\u5c062D\uff0cBEV\u4ee5\u53ca3D\u68c0\u6d4b\u7684\u8bc4\u4ef7\u8fc7\u7a0b\u5b8c\u5168\u5206\u5f00\u3002\u56e0\u800c\u4e09\u79cdevaluation\u4e2d\u95f4\u9700\u8981\u7684matching\u662f\u4e0d\u76f8\u5173\u7684\uff0c\u4f46\u662f\u7531\u4e8e\u6709\u76f8\u4f3c\u7684\u641c\u7d22\u601d\u8def\uff0c\u56e0\u800c\u4ee3\u7801\u5b9e\u73b0\u4e0a\u6709\u4e00\u5b9a\u7684\u590d\u7528\u3002 \u5339\u914d(true positive\u5224\u5b9a) KITTI\u7684matching\u662f\u4eceground truth boxes\u51fa\u53d1\uff0c\u7b80\u5355\u5730\u5faa\u73af\uff0c\u8d2a\u5a6a\u5730\u5bfb\u627e\u4e0e\u5176IoU(\u4f7f\u7528\u4ec0\u4e48IoU\u7531\u5f53\u524d\u4efb\u52a1\u51b3\u5b9a)\u6700\u5927\u7684prediction.\u4f46\u662f\u8981\u6ce8\u610f\u7684\u662f\uff0c\u8981\u8ba1\u7b97AP,\u8fd8\u662f\u8981\u8003\u8651score\u7684\u9ad8\u4f4e\u7684\u3002\u5b98\u65b9\u7684\u5b9e\u73b0\u4e0e\u52a0\u901f\u5b9e\u73b0\u7684\u601d\u8def\u662f\u4e00\u81f4\u7684\u3002 \u5148\u8003\u8651\u6240\u6709prediction,\u8ba1\u7b97\u4e00\u904dmatching\uff0c\u5e76\u8bb0\u5f55\u6bcf\u4e00\u4e2amatching\u7684score\uff0c\u7136\u540e\u5728PR\u66f2\u7ebf\u4e0a\u91c7\u683741\u4e2a\u70b9\uff0c\u5f97\u523041\u4e2aconfidence\u9608\u503c,\u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u9608\u503c\uff0c\u6ee4\u6389\u6bd4\u8fd9\u4e2a\u9608\u503c\u66f4\u4f4e\u7684boxes\uff0c\u7136\u540e\u91cd\u65b0match\uff0c\u8ba1\u7b97\u8fd9\u4e2a\u70b9\u4e0a\u7684recall\uff08\u8fd9\u4e2a\u4f1a\u4e0e\u91c7\u6837\u70b9\u4e00\u81f4\uff09 precision.\u4ee5\u6b64\u523b\u753bpr\u66f2\u7ebf\u3002 Easy, Medium, Hard KITTI\u4e00\u4e2a\u5f88\u7279\u6b8a\u7684\u673a\u5236\u5728\u4e8e\u5206\u8fa8\u4e86 easy, medium\u4e0ehard\u7684\u7ed3\u679c\u3002\u4ece\u4ee3\u7801\u5b9e\u73b0\u4e0a\uff0c\u53ef\u4ee5\u53d1\u73b0\u8fd9\u662f\u4e00\u4e2a\u4ee52D\u4ee5\u53ca\u906e\u6321\u4e3a\u4e3b\u8981\u6839\u636e\u7684\u5206\u522b\u3002Easy\u5305\u542b2D\u6846\u9ad8\u5ea6\u5927\u4e8e40 pixs\uff0c\u906e\u6321\u7b49\u7ea7\u6700\u4f4e\u7684objects\uff1bMedium\u5305\u542b2D\u6846\u9ad8\u4e8e25 pixs\uff0c\u906e\u6321\u7b49\u7ea7 0,1\u7684\u7269\u4f53\uff1bHard\u5305\u542b2D\u6846\u9ad8\u4e8e25 pixs\uff0c\u906e\u6321\u7b49\u7ea70-2\u7684\u7269\u4f53(\u4e5f\u5305\u542b\u524d\u9762\u63d0\u53ca\u7684\u6240\u6709\u7269\u4f53)\u3002 \u5173\u4e8e\u52a0\u901f \u524d\u9762\u63d0\u53ca\u7684Fast numba code\u76f8\u5bf9\u4e8e\u539f\u6765\u7684cpp\u4ee3\u7801\u5728\u4ee3\u7801\u6838\u5fc3\u903b\u8f91\u4e0a\u5dee\u8ddd\u4e0d\u5927\u3002\u6838\u5fc3\u53d8\u5316\u4e3b\u8981\u6709\u4e24\u4e2a\uff0c\u7b2c\u4e00\u4e2a\u662f\u4f7f\u7528numba.cudaGPU\u52a0\u901f\u4e863D IoU\u7684\u8ba1\u7b97,\u672c\u8d28\u4e0a\u662f\u7b80\u5355\u7684\u5e76\u884c\u8fd0\u7b97(\u5355\u4e2a\u7269\u4f53\u7684\u7b97\u6cd5\u5e76\u6ca1\u6709\u6539\u53d8)\u3002\u7b2c\u4e8c\u4e2a\u662f\u5229\u7528\u4e86numpy\u4ee5\u53canumba.jit\u7684CPU\u5e76\u884c\u4f18\u5316\uff0c\u4ee3\u7801\u4e2d\u6709\u4e00\u4e2a\u51fd\u6570\u7684\u4f5c\u7528\u662fcalculate_iou_partly,\u5c3d\u7ba1\u5b9e\u9645\u8fd0\u7b97\u91cf\u63d0\u5347\u4e86\uff0c\u4f46\u662f\u51cf\u5c11python\u5faa\u73af\u7684\u6b21\u6570\uff0c\u4e14\u5145\u5206\u5229\u7528numpy\u4ee5\u53canumba.jit\u7684\u5e76\u884c\u4f18\u5316\u3002 nuScenes detection score(NDS) - nuScenes pdf code nuscene \u7684\u8bc4\u4ef7metric\u662f\u76f8\u5f53\u72ec\u7279\u7684\uff0c\u4f5c\u8005\u7684\u539f\u610f\u662f\u5e0c\u671b\u6709metric\u5206\u522b\u8868\u8fbe\u5bf9\u4e2d\u5fc3\u8ddd\u79bb\u3001\u671d\u5411\u3001\u5927\u5c0f\u751a\u81f3\u901f\u5ea6\u7b49\u7ec6\u9879\u7684\u8ba1\u7b97\u7ed3\u679c\u3002\u6700\u540e\u7684NDS\u5355\u4e00\u6570\u503c\u4f1a\u662f\u591a\u4e2ametric\u7684\u5747\u503c\u3002 \u5339\u914d(true positive\u5224\u5b9a) nuscene\u7684matching\u662f\u4ecesorted predicted boxes\u51fa\u53d1\uff0c\u6309confidence\u5927\u5c0f\u5faa\u73af(\u6ce8\u610f\u8fd9\u91cc\u7684\u6392\u5e8f\u4ee5\u53ca\u5faa\u73af\u662f\u4ee5\u6240\u6709\u5e27\u7684\u9884\u6d4bbounding box\u4e3a\u51c6\uff0c\u800c\u5339\u914d\u7684\u65f6\u5019\u6839\u636esample_token\u53ea\u5728\u540c\u4e00\u5e27\u7684gt\u4e2d\u8fdb\u884c\u5339\u914d\uff0c sample_token\u4e5f\u662f\u8fd9\u4e2a\u65b9\u6cd5\u80fd\u65b9\u4fbf\u5730\u5b9e\u73b0\u7684\u539f\u56e0\uff0c\u5982\u679c\u5bf9KITTI\u7ed3\u679c\u8981\u7528\u540c\u6837\u7684\u7b97\u6cd5\uff0c\u5219\u9700\u8981\u5bf9\u6bcf\u4e00\u4e2abox\u90fd\u8bb0\u5f55\u81ea\u5df1\u5728\u54ea\u4e00\u5e27)\uff0c\u8d2a\u5a6a\u5730\u5bfb\u627e\u5c1a\u672a\u88ab\u5339\u914d\u7684\u4e14\u4e0e\u5176\u5e73\u9762\u8ddd\u79bb\u6700\u8fd1\u7684ground truth\uff0c\u5982\u679c\u6700\u8fd1\u7684\u8ddd\u79bb\u5728\u9608\u503c\u5185\uff0c\u5219\u8ba4\u4e3a\u662f\u4e00\u5bf9true positive\u3002\u7531\u4e8e\u8fd9\u4e2amatch\u5df2\u7ecf\u662f\u4ece\u9ad8confidence\u5230\u4f4econfidence\u4e86\uff0c\u6240\u4ee5\u53ef\u4ee5\u76f4\u63a5\u8ba1\u7b97precisions\u8ddfrecall\u66f2\u7ebf\u3002 Thresholds\u5206\u56db\u6b21\uff0c\u5206\u522b\u53d6 [0.5, 1, 2, 4] ,\u5f97\u5230\u7684mAP\u53d6\u5747\u503c\u3002\u6b64\u5916\u4ee5 threshold=2 \u65f6\u7684\u5339\u914d\u4e3a\u51c6\uff0c\u8ba1\u7b97\u5176\u4ed6 True positive metrics(TP metrics) \"\"\" tp: List[Union[0, 1]], len(tp) = num_prediction fp: List[Union[1, 0]], len(fp) = num_prediction fp[i] = 1 - tp[i],\u76f8\u5f53\u4e8e conf: List[float], len(conf) = num_prediction (sorted) They recorded whether each predicted object is true positive or false positive, and also its score. npos: number of positive ground truth \"\"\" tp_array = np . cumsum ( tp ) . astype ( np . float ) fp_array = np . cumsum ( fp ) . astype ( np . float ) conf_array = np . array ( conf ) prec = tp_array / ( fp_array + tp_array ) rec = tp_array / float ( npos ) rec_interp = np . linspace ( 0 , 1 , 101 ) # sample 0,0.01,0.02,..0.99,1;totally 101 samples prec = np . interp ( rec_interp , rec , prec , right = 0 ) # 1d-interpolate conf = np . interp ( rec_interp , rec , conf , right = 0 ) # np.interp(x_coordinate, x_data, y_data) -> interpolated_y rec = rec_interp TP Metrics \u8bba\u6587\u4e2d\u7ed9\u51fa\u4e86\u4e94\u4e2ametrics\uff0c\u5206\u522b\u662f \u4e2d\u5fc3\u70b9\u5e73\u9762\u76f4\u7ebf\u8ddd\u79bb scaled IoU (\u5047\u8bbe\u4f4d\u7f6e\u4e0e\u65b9\u5411\u6b63\u786e\uff0cpredicted whl\u957f\u65b9\u4f53\u4e0egt whl\u957f\u65b9\u4f53\u7684iou) yaw\u89d2\u5dee\u503c(radian) 2D\u901f\u5ea6\u5dee\u503c(m/s) \u7ec6\u5206\u7c7b\u5206\u7c7b\u51c6\u786e\u5ea6(nuscene\u5bf9\u90e8\u5206\u7c7b\u522b\u4f1a\u7ee7\u7eed\u7ec6\u5206) \u5404\u4e2aTP\u503c\u4e3a\u8bef\u5dee\u503c\u7684\u5728\u5404\u4e2arecall\u70b9\u4e0a\u7684\u7d2f\u79ef\u5747\u503c\u7684\u5747\u503c\u3002 \\mathrm{NDS}=\\frac{1}{10}\\left[5 \\mathrm{mAP}+\\sum_{\\mathrm{mTP} \\in \\mathrm{TP}}(1-\\min (1, \\mathrm{mTP}))\\right] Average Precision Weighted by Heading(APH) - Waymo \u9875\u9762 waymo\u7684\u7b97\u6cd5\u4e0eKITTI\u7684\u6781\u5ea6\u76f8\u4f3c\uff0c\u533a\u522b\u5728\u4e8e: Easy/Difficult\u5206\u8fa8\u65b9\u6cd5\u4e3b\u8981\u662f\u906e\u6321\u7a0b\u5ea6\u4ee5\u53cabox\u5185\u90e8\u70b9\u4e91\u7684\u6570\u91cf\u3002\u56e0\u800c\u662f\u4e00\u4e2a\u5b8c\u5168\u76843D-oriented\u7684\u5206\u7c7b\u6807\u51c6. \u6bcf\u5f53\u53d1\u73b0\u4e00\u4e2atrue-positive matching, tp = \\frac{\\Delta\\theta}{\\pi} ,\u76f8\u5f53\u4e8e\u53ea\u6709\u89d2\u5ea6\u662f\u51c6\u786e\u7684\u624d\u80fd\u5f97\u5230\u5b8c\u6574\u7684\u4e00\u4e2atrue-positive,\u5426\u5219\u4f1a\u52a0\u4e0a\u4e00\u4e2a\u60e9\u7f5a\u6743\u91cd\u3002\u800cFalse positive\u548cFalse negative\u6ca1\u6709\u53d8\u5316\u3002","title":"3D detection evaluation metric"},{"location":"3dDetection/Metric_3d/#3d-detection-evaluation-metric","text":"\u672c\u6587\u4e3b\u8981\u5c1d\u8bd5\u7efc\u8ff03D\u68c0\u6d4b\u7684\u8bc4\u4ef7\u65b9\u6cd5\u4ee5\u53ca\u5bf9\u5e94\u7684\u4e00\u4e9bcode\u7684\u5206\u6790\uff0c\u76ee\u6807\u662f\u6bd4\u8f83\u7ec6\u81f4\u7684\u5206\u6790\uff0c\u5728\u6709\u65b0metric\u63d0\u51fa\u7684\u8fc7\u7a0b\u4e2d\u4f1a\u6301\u7eed\u66f4\u65b0\uff0c\u5148\u7efc\u8ff0\u7684\u662fKITTI\u4e0eNuscene\u4e24\u5927benchmark\u7684\u8bc4\u4ef7\u5206\u6570\u3002","title":"3D detection evaluation metric"},{"location":"3dDetection/Metric_3d/#average-precisiong-kitti","text":"Official cpp code fast numba code \u6574\u4f53\u601d\u8def\u4e0a\u6765\u8bf4\uff0cKITTI\u7684\u6d4b\u8bd5\u662f\u5c062D\uff0cBEV\u4ee5\u53ca3D\u68c0\u6d4b\u7684\u8bc4\u4ef7\u8fc7\u7a0b\u5b8c\u5168\u5206\u5f00\u3002\u56e0\u800c\u4e09\u79cdevaluation\u4e2d\u95f4\u9700\u8981\u7684matching\u662f\u4e0d\u76f8\u5173\u7684\uff0c\u4f46\u662f\u7531\u4e8e\u6709\u76f8\u4f3c\u7684\u641c\u7d22\u601d\u8def\uff0c\u56e0\u800c\u4ee3\u7801\u5b9e\u73b0\u4e0a\u6709\u4e00\u5b9a\u7684\u590d\u7528\u3002","title":"Average Precisiong - Kitti"},{"location":"3dDetection/Metric_3d/#true-positive","text":"KITTI\u7684matching\u662f\u4eceground truth boxes\u51fa\u53d1\uff0c\u7b80\u5355\u5730\u5faa\u73af\uff0c\u8d2a\u5a6a\u5730\u5bfb\u627e\u4e0e\u5176IoU(\u4f7f\u7528\u4ec0\u4e48IoU\u7531\u5f53\u524d\u4efb\u52a1\u51b3\u5b9a)\u6700\u5927\u7684prediction.\u4f46\u662f\u8981\u6ce8\u610f\u7684\u662f\uff0c\u8981\u8ba1\u7b97AP,\u8fd8\u662f\u8981\u8003\u8651score\u7684\u9ad8\u4f4e\u7684\u3002\u5b98\u65b9\u7684\u5b9e\u73b0\u4e0e\u52a0\u901f\u5b9e\u73b0\u7684\u601d\u8def\u662f\u4e00\u81f4\u7684\u3002 \u5148\u8003\u8651\u6240\u6709prediction,\u8ba1\u7b97\u4e00\u904dmatching\uff0c\u5e76\u8bb0\u5f55\u6bcf\u4e00\u4e2amatching\u7684score\uff0c\u7136\u540e\u5728PR\u66f2\u7ebf\u4e0a\u91c7\u683741\u4e2a\u70b9\uff0c\u5f97\u523041\u4e2aconfidence\u9608\u503c,\u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u9608\u503c\uff0c\u6ee4\u6389\u6bd4\u8fd9\u4e2a\u9608\u503c\u66f4\u4f4e\u7684boxes\uff0c\u7136\u540e\u91cd\u65b0match\uff0c\u8ba1\u7b97\u8fd9\u4e2a\u70b9\u4e0a\u7684recall\uff08\u8fd9\u4e2a\u4f1a\u4e0e\u91c7\u6837\u70b9\u4e00\u81f4\uff09 precision.\u4ee5\u6b64\u523b\u753bpr\u66f2\u7ebf\u3002","title":"\u5339\u914d(true positive\u5224\u5b9a)"},{"location":"3dDetection/Metric_3d/#easy-medium-hard","text":"KITTI\u4e00\u4e2a\u5f88\u7279\u6b8a\u7684\u673a\u5236\u5728\u4e8e\u5206\u8fa8\u4e86 easy, medium\u4e0ehard\u7684\u7ed3\u679c\u3002\u4ece\u4ee3\u7801\u5b9e\u73b0\u4e0a\uff0c\u53ef\u4ee5\u53d1\u73b0\u8fd9\u662f\u4e00\u4e2a\u4ee52D\u4ee5\u53ca\u906e\u6321\u4e3a\u4e3b\u8981\u6839\u636e\u7684\u5206\u522b\u3002Easy\u5305\u542b2D\u6846\u9ad8\u5ea6\u5927\u4e8e40 pixs\uff0c\u906e\u6321\u7b49\u7ea7\u6700\u4f4e\u7684objects\uff1bMedium\u5305\u542b2D\u6846\u9ad8\u4e8e25 pixs\uff0c\u906e\u6321\u7b49\u7ea7 0,1\u7684\u7269\u4f53\uff1bHard\u5305\u542b2D\u6846\u9ad8\u4e8e25 pixs\uff0c\u906e\u6321\u7b49\u7ea70-2\u7684\u7269\u4f53(\u4e5f\u5305\u542b\u524d\u9762\u63d0\u53ca\u7684\u6240\u6709\u7269\u4f53)\u3002","title":"Easy, Medium, Hard"},{"location":"3dDetection/Metric_3d/#_1","text":"\u524d\u9762\u63d0\u53ca\u7684Fast numba code\u76f8\u5bf9\u4e8e\u539f\u6765\u7684cpp\u4ee3\u7801\u5728\u4ee3\u7801\u6838\u5fc3\u903b\u8f91\u4e0a\u5dee\u8ddd\u4e0d\u5927\u3002\u6838\u5fc3\u53d8\u5316\u4e3b\u8981\u6709\u4e24\u4e2a\uff0c\u7b2c\u4e00\u4e2a\u662f\u4f7f\u7528numba.cudaGPU\u52a0\u901f\u4e863D IoU\u7684\u8ba1\u7b97,\u672c\u8d28\u4e0a\u662f\u7b80\u5355\u7684\u5e76\u884c\u8fd0\u7b97(\u5355\u4e2a\u7269\u4f53\u7684\u7b97\u6cd5\u5e76\u6ca1\u6709\u6539\u53d8)\u3002\u7b2c\u4e8c\u4e2a\u662f\u5229\u7528\u4e86numpy\u4ee5\u53canumba.jit\u7684CPU\u5e76\u884c\u4f18\u5316\uff0c\u4ee3\u7801\u4e2d\u6709\u4e00\u4e2a\u51fd\u6570\u7684\u4f5c\u7528\u662fcalculate_iou_partly,\u5c3d\u7ba1\u5b9e\u9645\u8fd0\u7b97\u91cf\u63d0\u5347\u4e86\uff0c\u4f46\u662f\u51cf\u5c11python\u5faa\u73af\u7684\u6b21\u6570\uff0c\u4e14\u5145\u5206\u5229\u7528numpy\u4ee5\u53canumba.jit\u7684\u5e76\u884c\u4f18\u5316\u3002","title":"\u5173\u4e8e\u52a0\u901f"},{"location":"3dDetection/Metric_3d/#nuscenes-detection-scorends-nuscenes","text":"pdf code nuscene \u7684\u8bc4\u4ef7metric\u662f\u76f8\u5f53\u72ec\u7279\u7684\uff0c\u4f5c\u8005\u7684\u539f\u610f\u662f\u5e0c\u671b\u6709metric\u5206\u522b\u8868\u8fbe\u5bf9\u4e2d\u5fc3\u8ddd\u79bb\u3001\u671d\u5411\u3001\u5927\u5c0f\u751a\u81f3\u901f\u5ea6\u7b49\u7ec6\u9879\u7684\u8ba1\u7b97\u7ed3\u679c\u3002\u6700\u540e\u7684NDS\u5355\u4e00\u6570\u503c\u4f1a\u662f\u591a\u4e2ametric\u7684\u5747\u503c\u3002","title":"nuScenes detection score(NDS) - nuScenes"},{"location":"3dDetection/Metric_3d/#true-positive_1","text":"nuscene\u7684matching\u662f\u4ecesorted predicted boxes\u51fa\u53d1\uff0c\u6309confidence\u5927\u5c0f\u5faa\u73af(\u6ce8\u610f\u8fd9\u91cc\u7684\u6392\u5e8f\u4ee5\u53ca\u5faa\u73af\u662f\u4ee5\u6240\u6709\u5e27\u7684\u9884\u6d4bbounding box\u4e3a\u51c6\uff0c\u800c\u5339\u914d\u7684\u65f6\u5019\u6839\u636esample_token\u53ea\u5728\u540c\u4e00\u5e27\u7684gt\u4e2d\u8fdb\u884c\u5339\u914d\uff0c sample_token\u4e5f\u662f\u8fd9\u4e2a\u65b9\u6cd5\u80fd\u65b9\u4fbf\u5730\u5b9e\u73b0\u7684\u539f\u56e0\uff0c\u5982\u679c\u5bf9KITTI\u7ed3\u679c\u8981\u7528\u540c\u6837\u7684\u7b97\u6cd5\uff0c\u5219\u9700\u8981\u5bf9\u6bcf\u4e00\u4e2abox\u90fd\u8bb0\u5f55\u81ea\u5df1\u5728\u54ea\u4e00\u5e27)\uff0c\u8d2a\u5a6a\u5730\u5bfb\u627e\u5c1a\u672a\u88ab\u5339\u914d\u7684\u4e14\u4e0e\u5176\u5e73\u9762\u8ddd\u79bb\u6700\u8fd1\u7684ground truth\uff0c\u5982\u679c\u6700\u8fd1\u7684\u8ddd\u79bb\u5728\u9608\u503c\u5185\uff0c\u5219\u8ba4\u4e3a\u662f\u4e00\u5bf9true positive\u3002\u7531\u4e8e\u8fd9\u4e2amatch\u5df2\u7ecf\u662f\u4ece\u9ad8confidence\u5230\u4f4econfidence\u4e86\uff0c\u6240\u4ee5\u53ef\u4ee5\u76f4\u63a5\u8ba1\u7b97precisions\u8ddfrecall\u66f2\u7ebf\u3002 Thresholds\u5206\u56db\u6b21\uff0c\u5206\u522b\u53d6 [0.5, 1, 2, 4] ,\u5f97\u5230\u7684mAP\u53d6\u5747\u503c\u3002\u6b64\u5916\u4ee5 threshold=2 \u65f6\u7684\u5339\u914d\u4e3a\u51c6\uff0c\u8ba1\u7b97\u5176\u4ed6 True positive metrics(TP metrics) \"\"\" tp: List[Union[0, 1]], len(tp) = num_prediction fp: List[Union[1, 0]], len(fp) = num_prediction fp[i] = 1 - tp[i],\u76f8\u5f53\u4e8e conf: List[float], len(conf) = num_prediction (sorted) They recorded whether each predicted object is true positive or false positive, and also its score. npos: number of positive ground truth \"\"\" tp_array = np . cumsum ( tp ) . astype ( np . float ) fp_array = np . cumsum ( fp ) . astype ( np . float ) conf_array = np . array ( conf ) prec = tp_array / ( fp_array + tp_array ) rec = tp_array / float ( npos ) rec_interp = np . linspace ( 0 , 1 , 101 ) # sample 0,0.01,0.02,..0.99,1;totally 101 samples prec = np . interp ( rec_interp , rec , prec , right = 0 ) # 1d-interpolate conf = np . interp ( rec_interp , rec , conf , right = 0 ) # np.interp(x_coordinate, x_data, y_data) -> interpolated_y rec = rec_interp","title":"\u5339\u914d(true positive\u5224\u5b9a)"},{"location":"3dDetection/Metric_3d/#tp-metrics","text":"\u8bba\u6587\u4e2d\u7ed9\u51fa\u4e86\u4e94\u4e2ametrics\uff0c\u5206\u522b\u662f \u4e2d\u5fc3\u70b9\u5e73\u9762\u76f4\u7ebf\u8ddd\u79bb scaled IoU (\u5047\u8bbe\u4f4d\u7f6e\u4e0e\u65b9\u5411\u6b63\u786e\uff0cpredicted whl\u957f\u65b9\u4f53\u4e0egt whl\u957f\u65b9\u4f53\u7684iou) yaw\u89d2\u5dee\u503c(radian) 2D\u901f\u5ea6\u5dee\u503c(m/s) \u7ec6\u5206\u7c7b\u5206\u7c7b\u51c6\u786e\u5ea6(nuscene\u5bf9\u90e8\u5206\u7c7b\u522b\u4f1a\u7ee7\u7eed\u7ec6\u5206) \u5404\u4e2aTP\u503c\u4e3a\u8bef\u5dee\u503c\u7684\u5728\u5404\u4e2arecall\u70b9\u4e0a\u7684\u7d2f\u79ef\u5747\u503c\u7684\u5747\u503c\u3002 \\mathrm{NDS}=\\frac{1}{10}\\left[5 \\mathrm{mAP}+\\sum_{\\mathrm{mTP} \\in \\mathrm{TP}}(1-\\min (1, \\mathrm{mTP}))\\right]","title":"TP Metrics"},{"location":"3dDetection/Metric_3d/#average-precision-weighted-by-headingaph-waymo","text":"\u9875\u9762 waymo\u7684\u7b97\u6cd5\u4e0eKITTI\u7684\u6781\u5ea6\u76f8\u4f3c\uff0c\u533a\u522b\u5728\u4e8e: Easy/Difficult\u5206\u8fa8\u65b9\u6cd5\u4e3b\u8981\u662f\u906e\u6321\u7a0b\u5ea6\u4ee5\u53cabox\u5185\u90e8\u70b9\u4e91\u7684\u6570\u91cf\u3002\u56e0\u800c\u662f\u4e00\u4e2a\u5b8c\u5168\u76843D-oriented\u7684\u5206\u7c7b\u6807\u51c6. \u6bcf\u5f53\u53d1\u73b0\u4e00\u4e2atrue-positive matching, tp = \\frac{\\Delta\\theta}{\\pi} ,\u76f8\u5f53\u4e8e\u53ea\u6709\u89d2\u5ea6\u662f\u51c6\u786e\u7684\u624d\u80fd\u5f97\u5230\u5b8c\u6574\u7684\u4e00\u4e2atrue-positive,\u5426\u5219\u4f1a\u52a0\u4e0a\u4e00\u4e2a\u60e9\u7f5a\u6743\u91cd\u3002\u800cFalse positive\u548cFalse negative\u6ca1\u6709\u53d8\u5316\u3002","title":"Average Precision Weighted by Heading(APH) - Waymo"},{"location":"3dDetection/Mono3D_virtualcam/","text":"Single-Stage Monocular 3D Object Detection with Virtual Cameras \u8fd9\u7bc7\u6587\u7ae0\u6765\u81ea\u4e8e MonoDIS \u7684\u4f5c\u8005\u7ec4\uff0c\u91c7\u7528\u7684\u662fvirtual camera\u7684\u65b9\u6cd5\uff0c\u5f97\u5230\u4e86\u76f8\u5bf9\u4e0d\u9519\u7684\u7ed3\u679c virtual camera \u6838\u5fc3\u601d\u8def\uff0c\u5728\u56fe\u4e2d\u6838\u5fc3\u533a\u57dfcrop\u51fa\u591a\u4e2a\u6709\u6548\u533a\u57df\uff0c\u7136\u540e\u5728\u91cc\u9762\u8fdb\u884c3D detection\uff0c\u91cd\u8981\u7684\u6709\u51e0\u4e2ainsight. \u601d\u8def\u4e0e\u4f20\u7edf\u7684RCNN\u6709\u76f8\u4f3c\u4e4b\u5904\uff0c\u4e5f\u5c31\u662f\u4f7f\u7528\u4f20\u7edf\u65b9\u6cd5(\u6839\u636e3D\u7a7a\u95f4\u904d\u5386\u6216\u8005\u5176\u4ed6\u63d0\u793a)\uff0c\u4ece\u539f\u56fe\u4e2dcrop\u51fa\u6709\u6548\u6846\u518d\u8fdb\u884c\u5206\u6790\uff0c\u533a\u522b\u5728\u4e8ecrop\u51fa\u6765\u7684\u6bcf\u4e00\u5f20\u5b50\u90fd\u8fd8\u53ef\u80fd\u6709\u591a\u4e2atarget \u6bcf\u4e00\u4e2a3Ddetection\u9884\u6d4b\u7684\u6df1\u5ea6\u662f\u76f8\u5bf9\u4e8e\u865a\u62df\u76f8\u673a\u4f4d\u7f6e\u7684\u6df1\u5ea6\uff0c\u7a81\u51fa\u4e00\u4e2ascale invariance. virtual camera\u5177\u4f53\u7684\u5b9e\u73b0trick\u8f83\u591a\uff0c\u8d85\u53c2\u6570\u5f88\u591a\uff0c\u82e5\u60f3\u8981\u590d\u73b0\uff0c\u8fd9\u91cc\u5efa\u8bae\u56de\u770b\u8bba\u6587\u7684\u7b2c4\u7ae0\u8282\u4ee5\u53ca\u7b2c6.2\u7ae0\u8282\u3002\u7531\u4e8e\u6b20\u7f3a\u4ee3\u7801\uff0c\u8fd9\u4e2a\u7ed3\u679c\u6bd4\u8f83\u96be\u4ee5\u786e\u8ba4\u3002 DL structure \u7f51\u7edc\u7684\u8f93\u5165\u8f93\u51fa\u4e0e MonoDIS \u662f\u4e00\u6837\u7684\u3002","title":"Single-Stage Monocular 3D Object Detection with Virtual Cameras"},{"location":"3dDetection/Mono3D_virtualcam/#single-stage-monocular-3d-object-detection-with-virtual-cameras","text":"\u8fd9\u7bc7\u6587\u7ae0\u6765\u81ea\u4e8e MonoDIS \u7684\u4f5c\u8005\u7ec4\uff0c\u91c7\u7528\u7684\u662fvirtual camera\u7684\u65b9\u6cd5\uff0c\u5f97\u5230\u4e86\u76f8\u5bf9\u4e0d\u9519\u7684\u7ed3\u679c","title":"Single-Stage Monocular 3D Object Detection with Virtual Cameras"},{"location":"3dDetection/Mono3D_virtualcam/#virtual-camera","text":"\u6838\u5fc3\u601d\u8def\uff0c\u5728\u56fe\u4e2d\u6838\u5fc3\u533a\u57dfcrop\u51fa\u591a\u4e2a\u6709\u6548\u533a\u57df\uff0c\u7136\u540e\u5728\u91cc\u9762\u8fdb\u884c3D detection\uff0c\u91cd\u8981\u7684\u6709\u51e0\u4e2ainsight. \u601d\u8def\u4e0e\u4f20\u7edf\u7684RCNN\u6709\u76f8\u4f3c\u4e4b\u5904\uff0c\u4e5f\u5c31\u662f\u4f7f\u7528\u4f20\u7edf\u65b9\u6cd5(\u6839\u636e3D\u7a7a\u95f4\u904d\u5386\u6216\u8005\u5176\u4ed6\u63d0\u793a)\uff0c\u4ece\u539f\u56fe\u4e2dcrop\u51fa\u6709\u6548\u6846\u518d\u8fdb\u884c\u5206\u6790\uff0c\u533a\u522b\u5728\u4e8ecrop\u51fa\u6765\u7684\u6bcf\u4e00\u5f20\u5b50\u90fd\u8fd8\u53ef\u80fd\u6709\u591a\u4e2atarget \u6bcf\u4e00\u4e2a3Ddetection\u9884\u6d4b\u7684\u6df1\u5ea6\u662f\u76f8\u5bf9\u4e8e\u865a\u62df\u76f8\u673a\u4f4d\u7f6e\u7684\u6df1\u5ea6\uff0c\u7a81\u51fa\u4e00\u4e2ascale invariance. virtual camera\u5177\u4f53\u7684\u5b9e\u73b0trick\u8f83\u591a\uff0c\u8d85\u53c2\u6570\u5f88\u591a\uff0c\u82e5\u60f3\u8981\u590d\u73b0\uff0c\u8fd9\u91cc\u5efa\u8bae\u56de\u770b\u8bba\u6587\u7684\u7b2c4\u7ae0\u8282\u4ee5\u53ca\u7b2c6.2\u7ae0\u8282\u3002\u7531\u4e8e\u6b20\u7f3a\u4ee3\u7801\uff0c\u8fd9\u4e2a\u7ed3\u679c\u6bd4\u8f83\u96be\u4ee5\u786e\u8ba4\u3002","title":"virtual camera"},{"location":"3dDetection/Mono3D_virtualcam/#dl-structure","text":"\u7f51\u7edc\u7684\u8f93\u5165\u8f93\u51fa\u4e0e MonoDIS \u662f\u4e00\u6837\u7684\u3002","title":"DL structure"},{"location":"3dDetection/MonoGRNet: A Geometric Reasoning Network for Monocular 3D Object Localization/","text":"MonoGRNet: A Geometric Reasoning Network for Monocular 3D Object Localization \u672c\u6587\u63d0\u51fa\u7684\u7f51\u7edc\u7ed3\u6784\u53ef\u4ee5\u57280.06s\u79d2\u5185\u5b8c\u6210\u4e00\u5f20\u56fe\u7247\u7684inference","title":"MonoGRNet: A Geometric Reasoning Network for Monocular 3D Object Localization"},{"location":"3dDetection/MonoGRNet: A Geometric Reasoning Network for Monocular 3D Object Localization/#monogrnet-a-geometric-reasoning-network-for-monocular-3d-object-localization","text":"\u672c\u6587\u63d0\u51fa\u7684\u7f51\u7edc\u7ed3\u6784\u53ef\u4ee5\u57280.06s\u79d2\u5185\u5b8c\u6210\u4e00\u5f20\u56fe\u7247\u7684inference","title":"MonoGRNet: A Geometric Reasoning Network for Monocular 3D Object Localization"},{"location":"3dDetection/Monocular_3D_Object_Detection_and_Box_Fitting_Trained_End-to-End_Using_Intersection-over-Union_Loss/","text":"Monocular 3D Object Detection and Box Fitting Trained End-to-End Using Intersection-over-Union Loss \u672c\u6587\u63d0\u51fa\u4e86\u5728\u5355\u76ee3D\u68c0\u6d4b\u4e2d\u8003\u8651\u5f02\u8d28\u566a\u58f0\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2abackprop through optimization\u7684\u65b9\u6cd5\u3002 \u6d41\u7a0b\u603b\u89c8 \u9996\u5148\u4e00\u4e2aCNN\u8fdb\u884cobject detection\uff0c\u8f93\u51fa\u7c7b\u522bscore\u4ee5\u53ca2D bounding box\uff0c\u6267\u884cNMS\u5220\u9664\u90e8\u5206\u5197\u4f59\uff0c\u6700\u540e\u4f7f\u7528\u4e00\u4e2a\u975e\u7ebf\u6027\u4f18\u5316\u3002 \u7f51\u7edc\u8f93\u51fa \u7f51\u7edc\u8f93\u51fa\u7ed3\u679c\u9664\u4e86\u5206\u7c7b\u7ed3\u679c\u4e4b\u5916\u8fd8\u670926\u7ef4\u3002 2D bounding box\u5bf9\u5e94\u4e24\u4e2a\u89d2\u70b94\u4e2a\u503c\u3002 \u7269\u4f53\u4e2d\u5fc3\u4e0e\u76f8\u673a\u7684\u8ddd\u79bb(\u4e5f\u53ef\u4ee5\u7528Z\u8f74\u8ddd\u79bb\uff0c\u6027\u80fd\u5dee\u8ddd\u4e0d\u5927)\uff0c\u4e00\u4e2a\u503c \u89c2\u5bdf\u89d2 \\alpha \u9884\u6d4b\u5176sin\u4e0ecos\u503c\uff0c\u51712\u4e2a\u503c \u7269\u4f53\u5c3a\u5ea6\u957f\u5bbd\u9ad8\uff0c\u7528log\u503c\u4ee3\u8868\uff0c\u51713\u4e2a\u503c\u3002 3D bounding box\u76848\u4e2a\u70b9\u5728\u76f8\u673a\u5750\u6807\u7cfb\u7684\u6295\u5f71\uff0c\u517116\u4e2a\u503c\u3002 \u5bf93Dbox\u7684\u521d\u59cb\u89e3,\u4ee52D\u6846\u7684\u4e2d\u5fc3\u4f5c\u4e3a\u7269\u4f533D\u4e2d\u5fc3\u5728\u56fe\u7247\u7684\u6295\u5f71,\u5c31\u53ef\u4ee5\u5f97\u5230\u5bf93Dbox\u7684\u521d\u59cb\u4f30\u8ba1. taskNet\u4f7f\u5f97\u6bcf\u4e00\u4e2a\u8f93\u51fa\u4f1a\u540c\u65f6\u5e26\u4e0a\u4e86\u5bf9\u4e0d\u786e\u5b9a\u6027\u7684\u4f30\u8ba1 \u4e09\u79cdLoss\u8bad\u7ec3\u65b9\u6cd5 \u7b2c\u4e00\u79cd\u4f20\u7edf\u5b9a\u4e49\u662f\u5e73\u7a33\u566a\u58f0 Loss\u51fd\u6570\u5b9a\u4e49\u5982\u4e0b: \\begin{aligned} \\mathcal{L}_{1} &=\\mathcal{L}_{c l s} \\\\ &+\\frac{1}{N} \\sum_{j=1}^{N} \\sum_{k=1}^{26}\\left(\\frac{\\left\\|\\mathbf{y}_{k}^{(j)}-f_{k}\\left(\\mathbf{b}^{(j)}\\right)\\right\\|^{2}}{2 \\sigma_{k}^{2}}+\\log \\sigma_{k}\\right) \\end{aligned} \u672c\u8d28\u4e0a\u5c31\u662f Multi Task Learning \uff0c \u4e5f\u5c31\u662f\u8bf4\u6bcf\u4e00\u4e2aloss\u7c7b\u522b\u4f1a\u6709\u4e00\u4e2a\u5355\u72ec\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1. \u7b2c\u4e8c\u79cd\u5b9a\u4e49\u662f\u5f02\u65b9\u5dee\u566a\u58f0 \\begin{aligned} \\mathcal{L}_{2} &=\\mathcal{L}_{c l s} \\\\ &+\\frac{1}{N} \\sum_{i}\\left(\\frac{\\left(y_{i}-f_{i}\\left(\\mathbf{b}_{i}\\right)^{2}\\right)}{2 \\sigma_{i}^{2}}+\\log \\sigma_{i}-\\log P_{\\text {prior }}\\left(\\sigma_{i}^{-2}\\right)\\right) \\end{aligned} \u4e5f\u5c31\u662f\u9700\u8981tasknet\u8ddf\u968f\u6bcf\u4e00\u4e2a\u8f93\u51fa\u8f93\u51fa\u4e00\u4e2a\u8bef\u5dee\u503c \u5176\u4e2d P_{prior} \u5728\u8fd9\u91cc\u88ab\u5b9a\u4e49\u4e3a (\\alpha, \\beta) = (1, 0.5) \u7684 \u4f3d\u9a6c\u5206\u5e03 \u4ee5\u4e0a\u4e24\u79cd\u65b9\u5f0f\u5f97\u5230\u7684variance\u90fd\u53ef\u4ee5\u5728inference\u7684\u65f6\u5019\u4f5c\u4e3a\u5bf9\u4e0d\u786e\u5b9a\u6027\u7684\u4f30\u8ba1\uff0c\u4e5f\u5c31\u4fbf\u4e8e\u5bf9\u540e\u7aef\u4f18\u5316 \u7b2c\u4e09\u79cd\u8bad\u7ec3\u65b9\u5f0f\u662fbackprop through optimization \u9996\u5148\u4f18\u5316\u95ee\u9898\u7684\u5b9a\u4e49\u6765\u81ea\u4e8e E(\\mathbf{b} ; \\mathbf{y})=\\sum_{i=1}^{26} r_{i}(\\mathbf{b} ; \\mathbf{y})^{2}=\\sum_{i=1}^{26}\\left(w_{i}\\left(y_{i}-f_{i}(\\mathbf{b})\\right)\\right)^{2} \u524d\u4e24\u79cd\u65b9\u5f0f\u7684\u903b\u8f91\u5c31\u662f\u5728\u8bad\u7ec3\u7684\u65f6\u5019\u901a\u8fc7loss\u5b66\u4e60variance\uff0c\u7136\u540e\u76f4\u63a5\u7528\u4e8einference\u3002\u800c\u7b2c\u4e09\u79cd\u8bad\u7ec3\u65b9\u5f0f\u5c31\u662f\u628aoptimization\u653e\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u4e5f\u5c31\u80fd\u76f4\u63a5\u8bad\u7ec3\u8bef\u5deevariance. \u8fd9\u91cc\u5b83\u5728\u8bad\u7ec3\u7684\u65f6\u5019\u4f7f\u75283D IoU\u635f\u5931\u3002\u5728\u53cd\u4f20\u7684\u65f6\u5019\uff0c\u6839\u636e \\hat b = argmin_bE(b,y,\\sigma) \u4ee5\u53ca \\nabla_bE(b, y, \\sigma) = 0 \u4f7f\u7528 \u9690\u51fd\u6570\u5b9a\u7406 (\u4e2a\u4eba\u6682\u65f6\u672a\u80fd\u7406\u89e3) \u5f97\u5230 \\frac{\\partial \\hat{\\mathbf{b}}}{\\partial \\mathbf{y}}=-\\left[\\frac{\\partial^{2} E}{\\partial \\hat{\\mathbf{b}}^{2}}\\right]^{-1}\\left[\\frac{\\partial^{2} E}{\\partial \\mathbf{y} \\partial \\hat{\\mathbf{b}}}\\right] \\approx-\\left[\\frac{\\partial \\mathbf{r}}{\\partial \\hat{\\mathbf{b}}}\\right]^{+}\\left[\\frac{\\partial \\mathbf{r}}{\\partial \\mathbf{y}}\\right]","title":"Monocular 3D Object Detection and Box Fitting Trained End-to-End Using Intersection-over-Union Loss"},{"location":"3dDetection/Monocular_3D_Object_Detection_and_Box_Fitting_Trained_End-to-End_Using_Intersection-over-Union_Loss/#monocular-3d-object-detection-and-box-fitting-trained-end-to-end-using-intersection-over-union-loss","text":"\u672c\u6587\u63d0\u51fa\u4e86\u5728\u5355\u76ee3D\u68c0\u6d4b\u4e2d\u8003\u8651\u5f02\u8d28\u566a\u58f0\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2abackprop through optimization\u7684\u65b9\u6cd5\u3002","title":"Monocular 3D Object Detection and Box Fitting Trained End-to-End Using Intersection-over-Union Loss"},{"location":"3dDetection/Monocular_3D_Object_Detection_and_Box_Fitting_Trained_End-to-End_Using_Intersection-over-Union_Loss/#_1","text":"\u9996\u5148\u4e00\u4e2aCNN\u8fdb\u884cobject detection\uff0c\u8f93\u51fa\u7c7b\u522bscore\u4ee5\u53ca2D bounding box\uff0c\u6267\u884cNMS\u5220\u9664\u90e8\u5206\u5197\u4f59\uff0c\u6700\u540e\u4f7f\u7528\u4e00\u4e2a\u975e\u7ebf\u6027\u4f18\u5316\u3002","title":"\u6d41\u7a0b\u603b\u89c8"},{"location":"3dDetection/Monocular_3D_Object_Detection_and_Box_Fitting_Trained_End-to-End_Using_Intersection-over-Union_Loss/#_2","text":"\u7f51\u7edc\u8f93\u51fa\u7ed3\u679c\u9664\u4e86\u5206\u7c7b\u7ed3\u679c\u4e4b\u5916\u8fd8\u670926\u7ef4\u3002 2D bounding box\u5bf9\u5e94\u4e24\u4e2a\u89d2\u70b94\u4e2a\u503c\u3002 \u7269\u4f53\u4e2d\u5fc3\u4e0e\u76f8\u673a\u7684\u8ddd\u79bb(\u4e5f\u53ef\u4ee5\u7528Z\u8f74\u8ddd\u79bb\uff0c\u6027\u80fd\u5dee\u8ddd\u4e0d\u5927)\uff0c\u4e00\u4e2a\u503c \u89c2\u5bdf\u89d2 \\alpha \u9884\u6d4b\u5176sin\u4e0ecos\u503c\uff0c\u51712\u4e2a\u503c \u7269\u4f53\u5c3a\u5ea6\u957f\u5bbd\u9ad8\uff0c\u7528log\u503c\u4ee3\u8868\uff0c\u51713\u4e2a\u503c\u3002 3D bounding box\u76848\u4e2a\u70b9\u5728\u76f8\u673a\u5750\u6807\u7cfb\u7684\u6295\u5f71\uff0c\u517116\u4e2a\u503c\u3002 \u5bf93Dbox\u7684\u521d\u59cb\u89e3,\u4ee52D\u6846\u7684\u4e2d\u5fc3\u4f5c\u4e3a\u7269\u4f533D\u4e2d\u5fc3\u5728\u56fe\u7247\u7684\u6295\u5f71,\u5c31\u53ef\u4ee5\u5f97\u5230\u5bf93Dbox\u7684\u521d\u59cb\u4f30\u8ba1. taskNet\u4f7f\u5f97\u6bcf\u4e00\u4e2a\u8f93\u51fa\u4f1a\u540c\u65f6\u5e26\u4e0a\u4e86\u5bf9\u4e0d\u786e\u5b9a\u6027\u7684\u4f30\u8ba1","title":"\u7f51\u7edc\u8f93\u51fa"},{"location":"3dDetection/Monocular_3D_Object_Detection_and_Box_Fitting_Trained_End-to-End_Using_Intersection-over-Union_Loss/#loss","text":"\u7b2c\u4e00\u79cd\u4f20\u7edf\u5b9a\u4e49\u662f\u5e73\u7a33\u566a\u58f0 Loss\u51fd\u6570\u5b9a\u4e49\u5982\u4e0b: \\begin{aligned} \\mathcal{L}_{1} &=\\mathcal{L}_{c l s} \\\\ &+\\frac{1}{N} \\sum_{j=1}^{N} \\sum_{k=1}^{26}\\left(\\frac{\\left\\|\\mathbf{y}_{k}^{(j)}-f_{k}\\left(\\mathbf{b}^{(j)}\\right)\\right\\|^{2}}{2 \\sigma_{k}^{2}}+\\log \\sigma_{k}\\right) \\end{aligned} \u672c\u8d28\u4e0a\u5c31\u662f Multi Task Learning \uff0c \u4e5f\u5c31\u662f\u8bf4\u6bcf\u4e00\u4e2aloss\u7c7b\u522b\u4f1a\u6709\u4e00\u4e2a\u5355\u72ec\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1. \u7b2c\u4e8c\u79cd\u5b9a\u4e49\u662f\u5f02\u65b9\u5dee\u566a\u58f0 \\begin{aligned} \\mathcal{L}_{2} &=\\mathcal{L}_{c l s} \\\\ &+\\frac{1}{N} \\sum_{i}\\left(\\frac{\\left(y_{i}-f_{i}\\left(\\mathbf{b}_{i}\\right)^{2}\\right)}{2 \\sigma_{i}^{2}}+\\log \\sigma_{i}-\\log P_{\\text {prior }}\\left(\\sigma_{i}^{-2}\\right)\\right) \\end{aligned} \u4e5f\u5c31\u662f\u9700\u8981tasknet\u8ddf\u968f\u6bcf\u4e00\u4e2a\u8f93\u51fa\u8f93\u51fa\u4e00\u4e2a\u8bef\u5dee\u503c \u5176\u4e2d P_{prior} \u5728\u8fd9\u91cc\u88ab\u5b9a\u4e49\u4e3a (\\alpha, \\beta) = (1, 0.5) \u7684 \u4f3d\u9a6c\u5206\u5e03 \u4ee5\u4e0a\u4e24\u79cd\u65b9\u5f0f\u5f97\u5230\u7684variance\u90fd\u53ef\u4ee5\u5728inference\u7684\u65f6\u5019\u4f5c\u4e3a\u5bf9\u4e0d\u786e\u5b9a\u6027\u7684\u4f30\u8ba1\uff0c\u4e5f\u5c31\u4fbf\u4e8e\u5bf9\u540e\u7aef\u4f18\u5316 \u7b2c\u4e09\u79cd\u8bad\u7ec3\u65b9\u5f0f\u662fbackprop through optimization \u9996\u5148\u4f18\u5316\u95ee\u9898\u7684\u5b9a\u4e49\u6765\u81ea\u4e8e E(\\mathbf{b} ; \\mathbf{y})=\\sum_{i=1}^{26} r_{i}(\\mathbf{b} ; \\mathbf{y})^{2}=\\sum_{i=1}^{26}\\left(w_{i}\\left(y_{i}-f_{i}(\\mathbf{b})\\right)\\right)^{2} \u524d\u4e24\u79cd\u65b9\u5f0f\u7684\u903b\u8f91\u5c31\u662f\u5728\u8bad\u7ec3\u7684\u65f6\u5019\u901a\u8fc7loss\u5b66\u4e60variance\uff0c\u7136\u540e\u76f4\u63a5\u7528\u4e8einference\u3002\u800c\u7b2c\u4e09\u79cd\u8bad\u7ec3\u65b9\u5f0f\u5c31\u662f\u628aoptimization\u653e\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u4e5f\u5c31\u80fd\u76f4\u63a5\u8bad\u7ec3\u8bef\u5deevariance. \u8fd9\u91cc\u5b83\u5728\u8bad\u7ec3\u7684\u65f6\u5019\u4f7f\u75283D IoU\u635f\u5931\u3002\u5728\u53cd\u4f20\u7684\u65f6\u5019\uff0c\u6839\u636e \\hat b = argmin_bE(b,y,\\sigma) \u4ee5\u53ca \\nabla_bE(b, y, \\sigma) = 0 \u4f7f\u7528 \u9690\u51fd\u6570\u5b9a\u7406 (\u4e2a\u4eba\u6682\u65f6\u672a\u80fd\u7406\u89e3) \u5f97\u5230 \\frac{\\partial \\hat{\\mathbf{b}}}{\\partial \\mathbf{y}}=-\\left[\\frac{\\partial^{2} E}{\\partial \\hat{\\mathbf{b}}^{2}}\\right]^{-1}\\left[\\frac{\\partial^{2} E}{\\partial \\mathbf{y} \\partial \\hat{\\mathbf{b}}}\\right] \\approx-\\left[\\frac{\\partial \\mathbf{r}}{\\partial \\hat{\\mathbf{b}}}\\right]^{+}\\left[\\frac{\\partial \\mathbf{r}}{\\partial \\mathbf{y}}\\right]","title":"\u4e09\u79cdLoss\u8bad\u7ec3\u65b9\u6cd5"},{"location":"3dDetection/Multi-Sensor 3D Object Box Refinement for Autonomous Driving/","text":"Multi-Sensor 3D Object Box Refinement for Autonomous Driving \u8fd9\u7bc7\u8bba\u6587\u6e90\u81ea\u4e8e\u6c88\u5c11\u6770\u5b9e\u9a8c\u5ba4\u7684\u5b66\u957f\uff0c\u975e\u5e38\u503c\u5f97\u6ce8\u610f\u7684\u662f\u8fd9\u7bc7\u8bba\u6587\u4ece\u5355\u76ee\u89c6\u89c93D\u68c0\u6d4b\u51fa\u53d1\uff0c\u901a\u8fc7\u4e0d\u540c\u7684trick\u878d\u5408\u53cc\u76ee\u4ee5\u53ca\u70b9\u4e91\u4fe1\u606f(\u4e5f\u5c31\u662f\u8bf4\u5728\u6dfb\u52a0\u53cc\u76ee\u4ee5\u53ca\u6dfb\u52a0\u70b9\u4e91\u7684\u65f6\u5019\u4e0d\u9700\u8981\u91cd\u65b0train\u5168\u65b0\u7684\u7f51\u7edc\uff0c\u53ea\u9700\u8981train\u5c0f\u7f51\u7edc\u6216\u8005\u66f4\u6539post-opimization),\u662f\u4e00\u5957\u975e\u5e38\u79d1\u5b66\u53ef\u7528\u7684\u65b9\u6848\u3002 \u7ed3\u679c\u6765\u770b\uff0c\u5728\u5355\u76ee\u4e0a\u521b\u65b0\u6709\u9650\uff0c\u5728\u5355\u76ee-\u53cc\u76ee\u8054\u5408\u4e0a\u7528\u5904\u5f88\u5927\uff0c\u4e5f\u8fbe\u5230\u4e86\u53cc\u76ee\u7684SOTA(\u4ec5\u6b21\u4e8e\u8fd0\u7b97\u91cf\u66f4\u591a\u7684pseudo lidar)\uff0c\u53ef\u60dc\u5728lidar\u878d\u5408\u4e0a\u6570\u636e\u7ed3\u679c\u5e76\u6ca1\u6709\u663e\u8457\u9ad8\u4e8e\u7eafLidar\u7684SOTA\u65b9\u6848\u3002 \u6574\u4f53\u7ed3\u6784 \u4ece\u4e2d\u53ef\u77e5\u4e2d\u95f4\u4e00\u6761pipeline\u662f\u5b8c\u6574\u7684\u5355\u76ee\u9884\u6d4b\u8fc7\u7a0b\uff0c\u53cc\u76ee\u4ee5\u53ca\u70b9\u4e91\u5728\u8fd9\u91cc\u4e3b\u8981\u4f5c\u4e3a\u8f85\u52a9 \u5355\u76ee\u68c0\u6d4b\u505a\u6cd5 \u7b97\u662f\u6bd4\u8f83\u5e38\u89c1\u7684\u7ed3\u6784\uff0cFaster RCNN->RoI Align->residual prediction \u5bf9\u4e8e\u6df1\u5ea6\uff0c\u7f51\u7edc\u8f93\u51fa\u7684\u4e5f\u662f\u6b8b\u5dee\uff0c\u5bf9\u9ad8\u5ea6\u5176\u6b8b\u5dee\u7684base\u4f30\u8ba1\u4e3a z_{roi}=f_y\\frac{h}{h_{roio}} \u5176\u4e2d h \u4e3a3D\u7269\u4f53\u7684\u9ad8\u5ea6\uff0c h_{roi} \u4e3a2D RoI\u9ad8\u5ea6,\u7f51\u7edc\u8f93\u51fa\u7684\u6df1\u5ea6\u6b8b\u5dee\u4e3a log\\frac{z_{gt}}{z_{roi}} \uff0c\u5b9a\u4e49\u7684\u7f51\u7edc\u8f93\u51fa\u7684\u957f\u5bbd\u9ad8\u6b8b\u5dee \\Delta d = \\frac{d-p_d}{\\sigma_d} d \uff0c\u5176\u4e2d d \u4e3a (w,h,l) \u6700\u7ec8\u7684\u8f93\u51fa\u4e3a\u4e2d\u5fc3\u5728\u76f8\u673a\u4e2d\u7684\u6295\u5f71,\u6df1\u5ea6,\u957f\u5bbd\u9ad8\u7684\u6b8b\u5dee\uff0c\u4ee5\u53ca\u76f8\u5bf9\u89c2\u5bdf\u89d2\u7684sin,cos\u503c(\u89c2\u5bdf\u89d2\u7528multi-bin\u56de\u5f52) \u53cc\u76eeRefinement \u7a0d\u5fae\u6709\u70b9\u50cf Stereo RCNN \u7684\u60f3\u6cd5,\u901a\u8fc7\u5728\u5c40\u90e8\u56fe\u50cf\u4ece\u53f3\u76eewarp\u5230\u5de6\u76ee\u4e0aminimizing\u4e00\u4e2a\u5339\u914derror\u6765\u4f30\u8ba1\u6df1\u5ea6\u3002 \u8fd9\u91cc\u7684\u7b97\u6cd5\uff1a \u5728RoI\u4e2d\u7c7b\u4f3cSegmentation\u8f93\u51fa28*28 * 4 * classs\u7684sigmoid\u7ed3\u679c\uff0c\u5305\u542b\u4e00\u4e2a\u5206\u7c7b\u5668+\u4e09\u4e2a\u56de\u5f52\u5668,\u56de\u5f52\u90e8\u5206\u8868\u660e\u56fe\u50cf\u8fd9\u4e2a\u70b9\u5bf9\u5e94\u5750\u6807(normalized to [0,1] for each dimensions) \u6839\u636e\u5de6\u56fe\u8fd9\u4e2a\u533a\u57df\u6bcf\u4e00\u4e2a\u70b9\u9884\u6d4b\u7684normalized\u5750\u6807\u4ee5\u53ca\u9884\u6d4b\u7684\u5c3a\u5bf8\uff0c\u5c06\u8be5\u70b9\u5728\u56fe\u4e2d\u7684\u4f4d\u7f6e\u8f6c\u6362\u5230\u4e16\u754c\u5750\u6807\uff0c\u518d\u6295\u5f71\u5230\u7b2c\u4e8c\u5f20\u56fe\u4e2d\u3002 \u6211\u4eec\u9700\u8981\u51cf\u5c11\u5bf9\u5e94\u70b9\u4e4b\u95f4\u7684\u539f\u56fe\u5dee\u503c \u4f18\u5316\u6df1\u5ea6\u503c \u5b50\u7f51\u7edc\u7684label\u6765\u6e90\uff1a\u501f\u52a9\u70b9\u4e91\uff0c\u5148\u5f97\u5230\u8be5\u70b9\u4e91\u7684\u5b9e\u9645 instance vector\u503c\uff0c\u7136\u540e\u6295\u5f71\u56de\u56fe\u7247\u4e2d\u5f97\u5230\u50cf\u7d20\u7ea7label \u70b9\u4e91Refinement \u4f7f\u75282D detection\u7ed3\u679c\u7684 RoI\u63d0\u53d6\u51fa\u90e8\u5206\u70b9\u4e91\uff0c \u91cd\u91c7\u6837\u56fa\u5b9an\u4e2a\u70b9 point-wise instance seg\u7528\u4e8e\u533a\u5206foreground \u6839\u636eforeground\u7684probability,\u91cd\u91c7\u6837m\u4e2a\u70b9 T-Net\u7528\u4e8e\u4f30\u8ba1\u7269\u4f53\u4e2d\u5fc3\u4e0e\u51e0\u4f55\u3001\u65b9\u5411\u4fe1\u606f\uff0c\u8fd8\u8981\u505a\u4e00\u4e2ainstance vector\u7684\u4f30\u8ba1(\u7c7b\u4f3c\u4e8e\u53cc\u76ee\u7684\u7ed3\u679c) \u4f18\u5316\u8fd9\u4e2a\u51fd\u6570,\u5176\u4e2d ^cp_i \u4e3alidar\u70b9\u7684\u5750\u6807\uff0c ^c\\hat p_i \u4e3a\u6839\u636e\u4e2d\u5fc3\u70b9\u3001pose\u3001\u5f62\u72b6\u3001instsance vector\u4f30\u8ba1\u7684\u5750\u6807\u503c\uff0c\u7531\u4e8e\u53ea\u9700\u8981\u4f18\u5316\u6df1\u5ea6\u503c\uff0c\u6240\u4ee5\u53ef\u4ee5\u7ebf\u6027\u6c42\u89e3 \\mathbf{E}_{p} :=\\sum_{i=0}^{m}\\left\\|^{c} \\mathbf{p}_{i}-^{c} \\hat{\\mathbf{p}}_{i}\\right\\|, \\text { with } \\quad^{c} \\hat{\\mathbf{p}}_{i}=\\hat{\\mathbf{p}}_{o}+\\mathbf{R}(\\theta)^{o} \\mathbf{p}_{i} \u66f4\u591a\u4f20\u611f\u5668\u7684\u878d\u5408 \\begin{aligned} \\mathbf{p}_{o}=\\underset{\\mathbf{p}_{o}}{\\arg \\min } & \\sum_{i=0}^{n}\\left\\|I_{l}\\left(\\mathbf{u}_{i}\\right)-I_{r}\\left(\\pi\\left(^{c} \\hat{\\mathbf{p}}_{i}-\\mathbf{b}\\right)\\right)\\right\\|_{\\sum_{s}}+\\\\ & \\sum_{j=0}^{m}\\left\\|^{c} \\mathbf{p}_{j}-^{c} \\hat{\\mathbf{p}}_{j}\\right\\|_{\\Sigma_{p}} \\end{aligned} \u4e24\u9879\u5206\u522b\u5904\u7406\u76f8\u673a\u4ee5\u53ca\u70b9\u4e91\u6570\u636e\u3002 \u5176\u4ed6\u8bad\u7ec3\u7ec6\u8282 \u635f\u5931\u51fd\u6570\u5305\u62ecRPN, 2D\u68c0\u6d4b\uff0c\u89d2\u5ea6\uff0c\u4f4d\u7f6e\uff0c\u7ef4\u5ea6\u3002\u7528 multi-loss \u7ed3\u5408 \u4e3a\u4e86\u7ed9\u56fe\u7247\u7f51\u8def\u63d0\u4f9b\u4f4d\u7f6e\uff0c\u5728\u8f93\u51fa\u7aef\u52a0\u5165u,v\u5750\u6807(grid channels),\u7b2c\u4e00\u4e2aConv\u7684\u6743\u91cd\u88ab\u590d\u5236\u91cd\u7528\u7ed9\u8fd9\u65b0\u7684channel.","title":"Multi-Sensor 3D Object Box Refinement for Autonomous Driving"},{"location":"3dDetection/Multi-Sensor 3D Object Box Refinement for Autonomous Driving/#multi-sensor-3d-object-box-refinement-for-autonomous-driving","text":"\u8fd9\u7bc7\u8bba\u6587\u6e90\u81ea\u4e8e\u6c88\u5c11\u6770\u5b9e\u9a8c\u5ba4\u7684\u5b66\u957f\uff0c\u975e\u5e38\u503c\u5f97\u6ce8\u610f\u7684\u662f\u8fd9\u7bc7\u8bba\u6587\u4ece\u5355\u76ee\u89c6\u89c93D\u68c0\u6d4b\u51fa\u53d1\uff0c\u901a\u8fc7\u4e0d\u540c\u7684trick\u878d\u5408\u53cc\u76ee\u4ee5\u53ca\u70b9\u4e91\u4fe1\u606f(\u4e5f\u5c31\u662f\u8bf4\u5728\u6dfb\u52a0\u53cc\u76ee\u4ee5\u53ca\u6dfb\u52a0\u70b9\u4e91\u7684\u65f6\u5019\u4e0d\u9700\u8981\u91cd\u65b0train\u5168\u65b0\u7684\u7f51\u7edc\uff0c\u53ea\u9700\u8981train\u5c0f\u7f51\u7edc\u6216\u8005\u66f4\u6539post-opimization),\u662f\u4e00\u5957\u975e\u5e38\u79d1\u5b66\u53ef\u7528\u7684\u65b9\u6848\u3002 \u7ed3\u679c\u6765\u770b\uff0c\u5728\u5355\u76ee\u4e0a\u521b\u65b0\u6709\u9650\uff0c\u5728\u5355\u76ee-\u53cc\u76ee\u8054\u5408\u4e0a\u7528\u5904\u5f88\u5927\uff0c\u4e5f\u8fbe\u5230\u4e86\u53cc\u76ee\u7684SOTA(\u4ec5\u6b21\u4e8e\u8fd0\u7b97\u91cf\u66f4\u591a\u7684pseudo lidar)\uff0c\u53ef\u60dc\u5728lidar\u878d\u5408\u4e0a\u6570\u636e\u7ed3\u679c\u5e76\u6ca1\u6709\u663e\u8457\u9ad8\u4e8e\u7eafLidar\u7684SOTA\u65b9\u6848\u3002","title":"Multi-Sensor 3D Object Box Refinement for Autonomous Driving"},{"location":"3dDetection/Multi-Sensor 3D Object Box Refinement for Autonomous Driving/#_1","text":"\u4ece\u4e2d\u53ef\u77e5\u4e2d\u95f4\u4e00\u6761pipeline\u662f\u5b8c\u6574\u7684\u5355\u76ee\u9884\u6d4b\u8fc7\u7a0b\uff0c\u53cc\u76ee\u4ee5\u53ca\u70b9\u4e91\u5728\u8fd9\u91cc\u4e3b\u8981\u4f5c\u4e3a\u8f85\u52a9","title":"\u6574\u4f53\u7ed3\u6784"},{"location":"3dDetection/Multi-Sensor 3D Object Box Refinement for Autonomous Driving/#_2","text":"\u7b97\u662f\u6bd4\u8f83\u5e38\u89c1\u7684\u7ed3\u6784\uff0cFaster RCNN->RoI Align->residual prediction \u5bf9\u4e8e\u6df1\u5ea6\uff0c\u7f51\u7edc\u8f93\u51fa\u7684\u4e5f\u662f\u6b8b\u5dee\uff0c\u5bf9\u9ad8\u5ea6\u5176\u6b8b\u5dee\u7684base\u4f30\u8ba1\u4e3a z_{roi}=f_y\\frac{h}{h_{roio}} \u5176\u4e2d h \u4e3a3D\u7269\u4f53\u7684\u9ad8\u5ea6\uff0c h_{roi} \u4e3a2D RoI\u9ad8\u5ea6,\u7f51\u7edc\u8f93\u51fa\u7684\u6df1\u5ea6\u6b8b\u5dee\u4e3a log\\frac{z_{gt}}{z_{roi}} \uff0c\u5b9a\u4e49\u7684\u7f51\u7edc\u8f93\u51fa\u7684\u957f\u5bbd\u9ad8\u6b8b\u5dee \\Delta d = \\frac{d-p_d}{\\sigma_d} d \uff0c\u5176\u4e2d d \u4e3a (w,h,l) \u6700\u7ec8\u7684\u8f93\u51fa\u4e3a\u4e2d\u5fc3\u5728\u76f8\u673a\u4e2d\u7684\u6295\u5f71,\u6df1\u5ea6,\u957f\u5bbd\u9ad8\u7684\u6b8b\u5dee\uff0c\u4ee5\u53ca\u76f8\u5bf9\u89c2\u5bdf\u89d2\u7684sin,cos\u503c(\u89c2\u5bdf\u89d2\u7528multi-bin\u56de\u5f52)","title":"\u5355\u76ee\u68c0\u6d4b\u505a\u6cd5"},{"location":"3dDetection/Multi-Sensor 3D Object Box Refinement for Autonomous Driving/#refinement","text":"\u7a0d\u5fae\u6709\u70b9\u50cf Stereo RCNN \u7684\u60f3\u6cd5,\u901a\u8fc7\u5728\u5c40\u90e8\u56fe\u50cf\u4ece\u53f3\u76eewarp\u5230\u5de6\u76ee\u4e0aminimizing\u4e00\u4e2a\u5339\u914derror\u6765\u4f30\u8ba1\u6df1\u5ea6\u3002 \u8fd9\u91cc\u7684\u7b97\u6cd5\uff1a \u5728RoI\u4e2d\u7c7b\u4f3cSegmentation\u8f93\u51fa28*28 * 4 * classs\u7684sigmoid\u7ed3\u679c\uff0c\u5305\u542b\u4e00\u4e2a\u5206\u7c7b\u5668+\u4e09\u4e2a\u56de\u5f52\u5668,\u56de\u5f52\u90e8\u5206\u8868\u660e\u56fe\u50cf\u8fd9\u4e2a\u70b9\u5bf9\u5e94\u5750\u6807(normalized to [0,1] for each dimensions) \u6839\u636e\u5de6\u56fe\u8fd9\u4e2a\u533a\u57df\u6bcf\u4e00\u4e2a\u70b9\u9884\u6d4b\u7684normalized\u5750\u6807\u4ee5\u53ca\u9884\u6d4b\u7684\u5c3a\u5bf8\uff0c\u5c06\u8be5\u70b9\u5728\u56fe\u4e2d\u7684\u4f4d\u7f6e\u8f6c\u6362\u5230\u4e16\u754c\u5750\u6807\uff0c\u518d\u6295\u5f71\u5230\u7b2c\u4e8c\u5f20\u56fe\u4e2d\u3002 \u6211\u4eec\u9700\u8981\u51cf\u5c11\u5bf9\u5e94\u70b9\u4e4b\u95f4\u7684\u539f\u56fe\u5dee\u503c \u4f18\u5316\u6df1\u5ea6\u503c \u5b50\u7f51\u7edc\u7684label\u6765\u6e90\uff1a\u501f\u52a9\u70b9\u4e91\uff0c\u5148\u5f97\u5230\u8be5\u70b9\u4e91\u7684\u5b9e\u9645 instance vector\u503c\uff0c\u7136\u540e\u6295\u5f71\u56de\u56fe\u7247\u4e2d\u5f97\u5230\u50cf\u7d20\u7ea7label","title":"\u53cc\u76eeRefinement"},{"location":"3dDetection/Multi-Sensor 3D Object Box Refinement for Autonomous Driving/#refinement_1","text":"\u4f7f\u75282D detection\u7ed3\u679c\u7684 RoI\u63d0\u53d6\u51fa\u90e8\u5206\u70b9\u4e91\uff0c \u91cd\u91c7\u6837\u56fa\u5b9an\u4e2a\u70b9 point-wise instance seg\u7528\u4e8e\u533a\u5206foreground \u6839\u636eforeground\u7684probability,\u91cd\u91c7\u6837m\u4e2a\u70b9 T-Net\u7528\u4e8e\u4f30\u8ba1\u7269\u4f53\u4e2d\u5fc3\u4e0e\u51e0\u4f55\u3001\u65b9\u5411\u4fe1\u606f\uff0c\u8fd8\u8981\u505a\u4e00\u4e2ainstance vector\u7684\u4f30\u8ba1(\u7c7b\u4f3c\u4e8e\u53cc\u76ee\u7684\u7ed3\u679c) \u4f18\u5316\u8fd9\u4e2a\u51fd\u6570,\u5176\u4e2d ^cp_i \u4e3alidar\u70b9\u7684\u5750\u6807\uff0c ^c\\hat p_i \u4e3a\u6839\u636e\u4e2d\u5fc3\u70b9\u3001pose\u3001\u5f62\u72b6\u3001instsance vector\u4f30\u8ba1\u7684\u5750\u6807\u503c\uff0c\u7531\u4e8e\u53ea\u9700\u8981\u4f18\u5316\u6df1\u5ea6\u503c\uff0c\u6240\u4ee5\u53ef\u4ee5\u7ebf\u6027\u6c42\u89e3 \\mathbf{E}_{p} :=\\sum_{i=0}^{m}\\left\\|^{c} \\mathbf{p}_{i}-^{c} \\hat{\\mathbf{p}}_{i}\\right\\|, \\text { with } \\quad^{c} \\hat{\\mathbf{p}}_{i}=\\hat{\\mathbf{p}}_{o}+\\mathbf{R}(\\theta)^{o} \\mathbf{p}_{i}","title":"\u70b9\u4e91Refinement"},{"location":"3dDetection/Multi-Sensor 3D Object Box Refinement for Autonomous Driving/#_3","text":"\\begin{aligned} \\mathbf{p}_{o}=\\underset{\\mathbf{p}_{o}}{\\arg \\min } & \\sum_{i=0}^{n}\\left\\|I_{l}\\left(\\mathbf{u}_{i}\\right)-I_{r}\\left(\\pi\\left(^{c} \\hat{\\mathbf{p}}_{i}-\\mathbf{b}\\right)\\right)\\right\\|_{\\sum_{s}}+\\\\ & \\sum_{j=0}^{m}\\left\\|^{c} \\mathbf{p}_{j}-^{c} \\hat{\\mathbf{p}}_{j}\\right\\|_{\\Sigma_{p}} \\end{aligned} \u4e24\u9879\u5206\u522b\u5904\u7406\u76f8\u673a\u4ee5\u53ca\u70b9\u4e91\u6570\u636e\u3002","title":"\u66f4\u591a\u4f20\u611f\u5668\u7684\u878d\u5408"},{"location":"3dDetection/Multi-Sensor 3D Object Box Refinement for Autonomous Driving/#_4","text":"\u635f\u5931\u51fd\u6570\u5305\u62ecRPN, 2D\u68c0\u6d4b\uff0c\u89d2\u5ea6\uff0c\u4f4d\u7f6e\uff0c\u7ef4\u5ea6\u3002\u7528 multi-loss \u7ed3\u5408 \u4e3a\u4e86\u7ed9\u56fe\u7247\u7f51\u8def\u63d0\u4f9b\u4f4d\u7f6e\uff0c\u5728\u8f93\u51fa\u7aef\u52a0\u5165u,v\u5750\u6807(grid channels),\u7b2c\u4e00\u4e2aConv\u7684\u6743\u91cd\u88ab\u590d\u5236\u91cd\u7528\u7ed9\u8fd9\u65b0\u7684channel.","title":"\u5176\u4ed6\u8bad\u7ec3\u7ec6\u8282"},{"location":"3dDetection/Multi-View_3D_Detection_Network_for_autonomous_Driving/","text":"Multi-View 3D Detection Network for autonomous Driving \u8fd9\u7bc7\u8bba\u6587\u7ed3\u5408\u4e86\u591a\u89c6\u89d2\uff0c\u878d\u5408Lidar\u548ccamera\u8fdb\u884c\u4e09\u7ef4\u68c0\u6d4b\u3002 \u7f51\u7edc\u7ed3\u6784 \u6570\u636e\u51c6\u5907 \u6fc0\u5149\u96f7\u8fbe\u9e1f\u77b0\u56fe\uff1a \u9e1f\u77b0\u56fe\u5206\u4e3a\u9ad8\u5ea6\u56fe\u3001\u5f3a\u5ea6\u56fe\u4ee5\u53ca\u5bc6\u5ea6\u56fe\u3002\u90fd\u5148\u5c06\u9e1f\u77b0\u56fe\u5206\u62102D\u7f51\u683c \u9ad8\u5ea6\u56fe\uff1a\u5c06\u70b9\u4e91\u968f\u673a\u5206\u6210M\u4efd\uff0c\u6bcf\u4e00\u4efd\u4e2d\uff0c2D\u7f51\u683c\u4e2d\u7684\u6bcf\u4e00\u4e2a\u7f51\u683c\u53d6\u8be5\u5904\u7684\u6700\u9ad8\u70b9\u7684\u9ad8\u5ea6\uff0c\u6700\u7ec8\u5f97\u5230M-channel\u7684\u9ad8\u5ea6\u56fe \u5f3a\u5ea6\u56fe\uff1a\u4e0d\u5206\u62c6\uff0c\u6bcf\u4e00\u7f51\u683c\u53d6\u8be5\u5904\u6700\u9ad8\u70b9\u7684\u53cd\u5c04\u5f3a\u5ea6 \u5bc6\u5ea6\u56fe\uff1a\u4e0d\u5206\u62c6\uff0c\u6bcf\u4e00\u4e2a\u7f51\u683c\u53d6\u8be5\u5904\u70b9\u7684\u5bc6\u5ea6\uff0c\u7528\u4e00\u4e2alog\u51fd\u6570\u89c4\u8303\u5316 \u6fc0\u5149\u96f7\u8fbe\u524d\u89c6\u56fe\uff1a \u524d\u89c6\u56fe\u4e0d\u5206\u62c6\uff0c\u5c06\u70b9\u4e91\u6295\u5f71\u5230\u5706\u67f1\u9762\u4e0a\uff0c\u7528\u6781\u5750\u6807 (r, c) \u8868\u793a\u6295\u5f71\u56fe\u7684 (x, y) \uff0c\u5e76\u540c\u6837\u7ed9\u51fa\u9ad8\u5ea6\u56fe\uff0c\u5f3a\u5ea6\u56fe\uff0c\u5bc6\u5ea6\u56fe RGB\u56fe\u7247\uff1a\u6b63\u5e38\u4f7f\u7528 \u6570\u636e\u878d\u5408\u64cd\u4f5c \u56fe\u4e2d\u9009\u62e9\u7684M\u4e3aelemental\u2014\u2014mean\u64cd\u4f5c \u5b9e\u9a8c\u4e2d\u91cd\u70b9\u8fd8\u662f\u8981\u641e\u597dablation study","title":"Multi-View 3D Detection Network for autonomous Driving"},{"location":"3dDetection/Multi-View_3D_Detection_Network_for_autonomous_Driving/#multi-view-3d-detection-network-for-autonomous-driving","text":"\u8fd9\u7bc7\u8bba\u6587\u7ed3\u5408\u4e86\u591a\u89c6\u89d2\uff0c\u878d\u5408Lidar\u548ccamera\u8fdb\u884c\u4e09\u7ef4\u68c0\u6d4b\u3002","title":"Multi-View 3D Detection Network for autonomous Driving"},{"location":"3dDetection/Multi-View_3D_Detection_Network_for_autonomous_Driving/#_1","text":"","title":"\u7f51\u7edc\u7ed3\u6784"},{"location":"3dDetection/Multi-View_3D_Detection_Network_for_autonomous_Driving/#_2","text":"\u6fc0\u5149\u96f7\u8fbe\u9e1f\u77b0\u56fe\uff1a \u9e1f\u77b0\u56fe\u5206\u4e3a\u9ad8\u5ea6\u56fe\u3001\u5f3a\u5ea6\u56fe\u4ee5\u53ca\u5bc6\u5ea6\u56fe\u3002\u90fd\u5148\u5c06\u9e1f\u77b0\u56fe\u5206\u62102D\u7f51\u683c \u9ad8\u5ea6\u56fe\uff1a\u5c06\u70b9\u4e91\u968f\u673a\u5206\u6210M\u4efd\uff0c\u6bcf\u4e00\u4efd\u4e2d\uff0c2D\u7f51\u683c\u4e2d\u7684\u6bcf\u4e00\u4e2a\u7f51\u683c\u53d6\u8be5\u5904\u7684\u6700\u9ad8\u70b9\u7684\u9ad8\u5ea6\uff0c\u6700\u7ec8\u5f97\u5230M-channel\u7684\u9ad8\u5ea6\u56fe \u5f3a\u5ea6\u56fe\uff1a\u4e0d\u5206\u62c6\uff0c\u6bcf\u4e00\u7f51\u683c\u53d6\u8be5\u5904\u6700\u9ad8\u70b9\u7684\u53cd\u5c04\u5f3a\u5ea6 \u5bc6\u5ea6\u56fe\uff1a\u4e0d\u5206\u62c6\uff0c\u6bcf\u4e00\u4e2a\u7f51\u683c\u53d6\u8be5\u5904\u70b9\u7684\u5bc6\u5ea6\uff0c\u7528\u4e00\u4e2alog\u51fd\u6570\u89c4\u8303\u5316 \u6fc0\u5149\u96f7\u8fbe\u524d\u89c6\u56fe\uff1a \u524d\u89c6\u56fe\u4e0d\u5206\u62c6\uff0c\u5c06\u70b9\u4e91\u6295\u5f71\u5230\u5706\u67f1\u9762\u4e0a\uff0c\u7528\u6781\u5750\u6807 (r, c) \u8868\u793a\u6295\u5f71\u56fe\u7684 (x, y) \uff0c\u5e76\u540c\u6837\u7ed9\u51fa\u9ad8\u5ea6\u56fe\uff0c\u5f3a\u5ea6\u56fe\uff0c\u5bc6\u5ea6\u56fe RGB\u56fe\u7247\uff1a\u6b63\u5e38\u4f7f\u7528","title":"\u6570\u636e\u51c6\u5907"},{"location":"3dDetection/Multi-View_3D_Detection_Network_for_autonomous_Driving/#_3","text":"\u56fe\u4e2d\u9009\u62e9\u7684M\u4e3aelemental\u2014\u2014mean\u64cd\u4f5c \u5b9e\u9a8c\u4e2d\u91cd\u70b9\u8fd8\u662f\u8981\u641e\u597dablation study","title":"\u6570\u636e\u878d\u5408\u64cd\u4f5c"},{"location":"3dDetection/Orthographic_Feature_Transform_3D_detection/","text":"Orthographic Feature Transform for Monocular 3D Object Detection \u8fd9\u7bc7\u8bba\u6587\u8ba4\u4e3a\u5bf9\u5355\u4e2a\u6444\u50cf\u5934\u5f97\u5230\u7684\u6444\u50cf\u5934\u8fdb\u884c3D detection\u7684\u65f6\u5019\uff0c\u8fd8\u662f\u9700\u8981\u8003\u8651\u6574\u4e2a\u573a\u666f\u7684\u4e09\u7ef4\u7ed3\u6784\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u5728\u56fe\u50cf\u5750\u6807\u7cfb\u8fdb\u884c\u7814\u7a76\u3002 \u5728\u65e0\u4eba\u8f66\u7684\u4f20\u7edf\u89c6\u89c9\u7b97\u6cd5\u4e2d\uff0c\u5728\u5355\u76ee\u89c6\u89c9\u6761\u4ef6\u4e0b\uff0c\u5982\u679c\u8981\u6d4b\u5f97\u8ddd\u79bb\uff0c\u9700\u8981\u77e5\u9053\u6444\u50cf\u5934\u7684pitch\u89d2\u5ea6\u4ee5\u53ca\u6240\u63cf\u8ff0\u7684\u70b9\u5230\u6444\u50cf\u5934\u7684Z\u8f74\u8ddd\u79bb(\u7ecf\u5e38\u662f\u6444\u50cf\u5934\u76f8\u5bf9\u5730\u9762\u7684\u9ad8\u5ea6)\u3002\u56e0\u6b64\u8fd9\u4e2a\u76f4\u89c9\u5c31\u662f3d detection\u9700\u8981\u6444\u50cf\u5934\u7684\u5916\u53c2 \u4e3b\u8981\u7b97\u6cd5\u8d21\u732e \u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u5982\u4e0a\u56fe\u3002\u4ee5\u4e0b\u4e3a\u5177\u4f53\u4ecb\u7ecd\uff1a 1. \u524d\u7279\u5f81\u63d0\u53d6 \u8fd9\u4e2a\u7ed3\u6784\u91c7\u7528\u7684\u662fResNet18 \u4f5c\u4e3a\u524d\u7aef\u7684\u7279\u5f81\u63d0\u53d6\uff0c\u540c\u65f6\u5c06\u4e0d\u540cscale\u7684feature maps\u540c\u65f6\u4f20\u7ed9\u4e0b\u4e00\u6b65\u7684\u6b63\u4ea4\u53d8\u6362\u3002\u8fd9\u4e2a\u8f83\u4e3a\u5e38\u89c4\u3002 2. \u6b63\u4ea4\u53d8\u6362 \u8fd9\u4e2a\u662f\u672c\u6587\u7684\u7b2c\u4e00\u4e2a\u4e3b\u8981\u8d21\u732e\uff0c\u7528\u5982\u56fe\u7684\u65b9\u5f0f\u5c06\u56fe\u50cf\u5750\u6807\u7cfb\u7684feature map\u8f6c\u6362\u4e3abird eye view\u89c6\u89d2\u7684feature map \u8ba1\u7b97\u8fc7\u7a0b\uff1a 1. \u9884\u5b9a\u4e49\u4e09\u7ef4\u7684\u65b9\u5757\u7a7a\u95f4\uff0c\u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u5927\u5c0f\u4e3ar\u7684\u683c\u5b50\uff0c\u6839\u636e\u5176\u4e2d\u5fc3\u70b9\u7684\u5750\u6807\u9006\u6295\u5f71\u5230\u56fe\u50cf\u7a7a\u95f4\u4e2d\uff0c\u6295\u5f71\u7ed3\u679c\u518d\u8fd1\u4f3c\u4e3a\u4e00\u4e2a\u77e9\u5f62\uff0c\u56fe\u7247\u5750\u6807\u7684\u5de6\u4e0a\u89d2\u4e0e\u53f3\u4e0a\u89d2\u5750\u6807\u7531\u4ee5\u4e0b\u516c\u5f0f\u51b3\u5b9a 2. \u5bf9\u4e8e\u70b9 (x, y, z) \u5bf9\u5e94\u7684\u7ed3\u679c g(x, y, z) \u4e3a\u9006\u6295\u5f71\u4e0a\u7684\u77e9\u5f62\u6846\u5185\u7684\u6240\u6709feature map\u7684\u6570\u503c\u5747\u503c\u3002 3. \u5bf9\u4e8e\u4fef\u77b0\u56fe(\u6ca1\u6709Z)\u4e0a\u6bcf\u4e00\u4e2a\u70b9\u7684\u8f93\u51fa\u7ed3\u679c\u4e3a\u5bf9\u5e94 (x, y) \u7ad6\u76f4\u65b9\u5411\u4e0a\u6240\u6709 g(x, y, z) \u7684\u52a0\u6743\u6c42\u548c\uff0c\u5176\u6743\u91cd\u4e3a\u53ef\u5b66\u4e60\u7684\u53c2\u6570\u3002 3. Topdown network \u7528\u4e00\u822c\u7684\u4e8c\u7ef4\u5377\u79ef\u4ee5\u53caResNet\u98ce\u683c\u7684skip-connection\u8fdb\u884c\u5904\u7406\uff0c\u5f97\u5230\u8f93\u51fa 4. output \u7f6e\u4fe1\u5ea6map(\u6982\u7387\u56fe)\uff0c\u8bad\u7ec3\u65f6\u5176\u771f\u503c\u7531\u771f\u5b9eobject\u4e3a\u4e2d\u5fc3\u7684\u9ad8\u65af\u51fd\u6570\u5f97\u5230( \\sigma \u672a\u7ed9\u51fa\uff0c\u591a\u4e2a\u969c\u788d\u7269\u7684\u8bdd\u53d6\u5404\u4e2a\u9ad8\u65af\u51fd\u6570\u7684\u6700\u5927\u503c) position offset \u548cdimension offset\uff0c\u672c\u6765\u6bcf\u4e00\u4e2a\u65b9\u5757\u7684\u7f6e\u4fe1\u5ea6map\u5df2\u7ecf\u9884\u6d4b\u4e86\u5728resolution\u4e3ar\u7684\u5730\u56fe\u4e2d\u6bcf\u4e00\u4e2a\u70b9\u662f\u969c\u788d\u7684\u6982\u7387\uff0c\u8fd9\u91cc\u518d\u8865\u5145\u4e86\u76f8\u5bf9\u4e8e\u65b9\u5757\u4e2d\u5fc3\u7684\u504f\u79fb\u9884\u6d4b\u3002 \u89d2\u5ea6vector map \u6709\u7528\u7684\u5b9e\u8df5\u7ec6\u8282 Integral Feature Map \u5728\u8fdb\u884c\u6b63\u4ea4\u53d8\u6362\u7684\u65f6\u5019\uff0c\u7531\u4e8e\u9700\u8981\u591a\u6b21\u6c42\u56fe\u50cf\u4e2d\u4e00\u4e2a\u4e2a\u77e9\u5f62\u6846\u5185\u6570\u503c\u7684\u548c\uff0c\u8fd9\u91cc\u4f7f\u7528\u52a8\u6001\u89c4\u5212\u7684\u7b97\u6cd5\uff0c\u5148\u6c42\u51faintegral feature map\uff0c F \u3002\u5176\u4e2d F(u,v) \u4e3a (u,v) \u70b9\u5de6\u4e0a\u89d2\u6574\u4e2a\u77e9\u5f62\u7684\u6570\u503c\u6c42\u548c\u3002\u4e4b\u540e\u6bcf\u4e00\u6b21\u6c42 g(x, y, z) \u65f6\u9700\u8981\u505a\u6c42\u548c\u7684\u65f6\u5019\uff0c\u53ea\u9700\u8981\u505a\u4e00\u4e2a\u5229\u7528 F \u505a\u4e00\u4e2aO(1)\u7684\u8fd0\u7b97\u5373\u53ef\u3002 Skew Loss Function \u5728\u505aobject detection\u65f6\u7531\u4e8e\u6b63\u8d1f\u6837\u672c\u7684\u95ee\u9898\uff0c\u4e00\u822c\u90fd\u9700\u8981\u5bf9\u8d1f\u6837\u672c\u7ed9\u4e88\u6bd4\u8f83\u5c11\u7684\u60e9\u7f5a\uff0c\u6587\u4e2d\u5728\u8bad\u7ec3confidence map prediction\u65f6\uff0c\u5bf9\u8bad\u7ec3\u76ee\u6807 S<0.05 \u7684\u4f4d\u7f6e\uff0c\u7ed9\u4e88\u4e00\u4e2a0.01\u7684\u56e0\u5b50\u3002 Normalizing Dimension and Angle Prediction \u5bf9\u4e8e\u4e00\u4e2a\u7279\u5b9a\u7684class\uff0c\u5df2\u77e5\u5b83\u7684\u5e73\u5747\u957f\u5bbd\u9ad8\uff0c\u5219\u9700\u8981\u9884\u6d4b\u7684\u957f\u5bbd\u9ad8\u53d8\u5316\u4e3a \\Delta_{dim}(x, z) = [log \\frac{w_i}{w},log \\frac{h_i}{h} ,log \\frac{l_i}{l}] \u89d2\u5ea6\u8f93\u51fa\u7528 sin\uff0ccos \u3002 \\Delta_{ang}(x,z) = [sin\\theta_i, cos\\theta_i] \u53e6\u5916\u672c\u6587\u7684regression\u90fd\u662f\u7528 l_1 loss. NMS(non max suppression) \u5148\u5c06\u7f6e\u4fe1\u5ea6map\u505a\u4e00\u4e2a\u9ad8\u65af\u5e73\u6ed1\uff0c\u7136\u540e\u627e\u5176\u4e2d\u5c40\u90e8\u6700\u5927\u503c\u70b9\u4f5c\u4e3a\u8f93\u51fa","title":"Orthographic Feature Transform for Monocular 3D Object Detection"},{"location":"3dDetection/Orthographic_Feature_Transform_3D_detection/#orthographic-feature-transform-for-monocular-3d-object-detection","text":"\u8fd9\u7bc7\u8bba\u6587\u8ba4\u4e3a\u5bf9\u5355\u4e2a\u6444\u50cf\u5934\u5f97\u5230\u7684\u6444\u50cf\u5934\u8fdb\u884c3D detection\u7684\u65f6\u5019\uff0c\u8fd8\u662f\u9700\u8981\u8003\u8651\u6574\u4e2a\u573a\u666f\u7684\u4e09\u7ef4\u7ed3\u6784\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u5728\u56fe\u50cf\u5750\u6807\u7cfb\u8fdb\u884c\u7814\u7a76\u3002 \u5728\u65e0\u4eba\u8f66\u7684\u4f20\u7edf\u89c6\u89c9\u7b97\u6cd5\u4e2d\uff0c\u5728\u5355\u76ee\u89c6\u89c9\u6761\u4ef6\u4e0b\uff0c\u5982\u679c\u8981\u6d4b\u5f97\u8ddd\u79bb\uff0c\u9700\u8981\u77e5\u9053\u6444\u50cf\u5934\u7684pitch\u89d2\u5ea6\u4ee5\u53ca\u6240\u63cf\u8ff0\u7684\u70b9\u5230\u6444\u50cf\u5934\u7684Z\u8f74\u8ddd\u79bb(\u7ecf\u5e38\u662f\u6444\u50cf\u5934\u76f8\u5bf9\u5730\u9762\u7684\u9ad8\u5ea6)\u3002\u56e0\u6b64\u8fd9\u4e2a\u76f4\u89c9\u5c31\u662f3d detection\u9700\u8981\u6444\u50cf\u5934\u7684\u5916\u53c2","title":"Orthographic Feature Transform for Monocular 3D Object Detection"},{"location":"3dDetection/Orthographic_Feature_Transform_3D_detection/#_1","text":"\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u5982\u4e0a\u56fe\u3002\u4ee5\u4e0b\u4e3a\u5177\u4f53\u4ecb\u7ecd\uff1a","title":"\u4e3b\u8981\u7b97\u6cd5\u8d21\u732e"},{"location":"3dDetection/Orthographic_Feature_Transform_3D_detection/#1","text":"\u8fd9\u4e2a\u7ed3\u6784\u91c7\u7528\u7684\u662fResNet18 \u4f5c\u4e3a\u524d\u7aef\u7684\u7279\u5f81\u63d0\u53d6\uff0c\u540c\u65f6\u5c06\u4e0d\u540cscale\u7684feature maps\u540c\u65f6\u4f20\u7ed9\u4e0b\u4e00\u6b65\u7684\u6b63\u4ea4\u53d8\u6362\u3002\u8fd9\u4e2a\u8f83\u4e3a\u5e38\u89c4\u3002","title":"1. \u524d\u7279\u5f81\u63d0\u53d6"},{"location":"3dDetection/Orthographic_Feature_Transform_3D_detection/#2","text":"\u8fd9\u4e2a\u662f\u672c\u6587\u7684\u7b2c\u4e00\u4e2a\u4e3b\u8981\u8d21\u732e\uff0c\u7528\u5982\u56fe\u7684\u65b9\u5f0f\u5c06\u56fe\u50cf\u5750\u6807\u7cfb\u7684feature map\u8f6c\u6362\u4e3abird eye view\u89c6\u89d2\u7684feature map \u8ba1\u7b97\u8fc7\u7a0b\uff1a 1. \u9884\u5b9a\u4e49\u4e09\u7ef4\u7684\u65b9\u5757\u7a7a\u95f4\uff0c\u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u5927\u5c0f\u4e3ar\u7684\u683c\u5b50\uff0c\u6839\u636e\u5176\u4e2d\u5fc3\u70b9\u7684\u5750\u6807\u9006\u6295\u5f71\u5230\u56fe\u50cf\u7a7a\u95f4\u4e2d\uff0c\u6295\u5f71\u7ed3\u679c\u518d\u8fd1\u4f3c\u4e3a\u4e00\u4e2a\u77e9\u5f62\uff0c\u56fe\u7247\u5750\u6807\u7684\u5de6\u4e0a\u89d2\u4e0e\u53f3\u4e0a\u89d2\u5750\u6807\u7531\u4ee5\u4e0b\u516c\u5f0f\u51b3\u5b9a 2. \u5bf9\u4e8e\u70b9 (x, y, z) \u5bf9\u5e94\u7684\u7ed3\u679c g(x, y, z) \u4e3a\u9006\u6295\u5f71\u4e0a\u7684\u77e9\u5f62\u6846\u5185\u7684\u6240\u6709feature map\u7684\u6570\u503c\u5747\u503c\u3002 3. \u5bf9\u4e8e\u4fef\u77b0\u56fe(\u6ca1\u6709Z)\u4e0a\u6bcf\u4e00\u4e2a\u70b9\u7684\u8f93\u51fa\u7ed3\u679c\u4e3a\u5bf9\u5e94 (x, y) \u7ad6\u76f4\u65b9\u5411\u4e0a\u6240\u6709 g(x, y, z) \u7684\u52a0\u6743\u6c42\u548c\uff0c\u5176\u6743\u91cd\u4e3a\u53ef\u5b66\u4e60\u7684\u53c2\u6570\u3002","title":"2. \u6b63\u4ea4\u53d8\u6362"},{"location":"3dDetection/Orthographic_Feature_Transform_3D_detection/#3-topdown-network","text":"\u7528\u4e00\u822c\u7684\u4e8c\u7ef4\u5377\u79ef\u4ee5\u53caResNet\u98ce\u683c\u7684skip-connection\u8fdb\u884c\u5904\u7406\uff0c\u5f97\u5230\u8f93\u51fa","title":"3. Topdown network"},{"location":"3dDetection/Orthographic_Feature_Transform_3D_detection/#4-output","text":"\u7f6e\u4fe1\u5ea6map(\u6982\u7387\u56fe)\uff0c\u8bad\u7ec3\u65f6\u5176\u771f\u503c\u7531\u771f\u5b9eobject\u4e3a\u4e2d\u5fc3\u7684\u9ad8\u65af\u51fd\u6570\u5f97\u5230( \\sigma \u672a\u7ed9\u51fa\uff0c\u591a\u4e2a\u969c\u788d\u7269\u7684\u8bdd\u53d6\u5404\u4e2a\u9ad8\u65af\u51fd\u6570\u7684\u6700\u5927\u503c) position offset \u548cdimension offset\uff0c\u672c\u6765\u6bcf\u4e00\u4e2a\u65b9\u5757\u7684\u7f6e\u4fe1\u5ea6map\u5df2\u7ecf\u9884\u6d4b\u4e86\u5728resolution\u4e3ar\u7684\u5730\u56fe\u4e2d\u6bcf\u4e00\u4e2a\u70b9\u662f\u969c\u788d\u7684\u6982\u7387\uff0c\u8fd9\u91cc\u518d\u8865\u5145\u4e86\u76f8\u5bf9\u4e8e\u65b9\u5757\u4e2d\u5fc3\u7684\u504f\u79fb\u9884\u6d4b\u3002 \u89d2\u5ea6vector map","title":"4. output"},{"location":"3dDetection/Orthographic_Feature_Transform_3D_detection/#_2","text":"","title":"\u6709\u7528\u7684\u5b9e\u8df5\u7ec6\u8282"},{"location":"3dDetection/Orthographic_Feature_Transform_3D_detection/#integral-feature-map","text":"\u5728\u8fdb\u884c\u6b63\u4ea4\u53d8\u6362\u7684\u65f6\u5019\uff0c\u7531\u4e8e\u9700\u8981\u591a\u6b21\u6c42\u56fe\u50cf\u4e2d\u4e00\u4e2a\u4e2a\u77e9\u5f62\u6846\u5185\u6570\u503c\u7684\u548c\uff0c\u8fd9\u91cc\u4f7f\u7528\u52a8\u6001\u89c4\u5212\u7684\u7b97\u6cd5\uff0c\u5148\u6c42\u51faintegral feature map\uff0c F \u3002\u5176\u4e2d F(u,v) \u4e3a (u,v) \u70b9\u5de6\u4e0a\u89d2\u6574\u4e2a\u77e9\u5f62\u7684\u6570\u503c\u6c42\u548c\u3002\u4e4b\u540e\u6bcf\u4e00\u6b21\u6c42 g(x, y, z) \u65f6\u9700\u8981\u505a\u6c42\u548c\u7684\u65f6\u5019\uff0c\u53ea\u9700\u8981\u505a\u4e00\u4e2a\u5229\u7528 F \u505a\u4e00\u4e2aO(1)\u7684\u8fd0\u7b97\u5373\u53ef\u3002","title":"Integral Feature Map"},{"location":"3dDetection/Orthographic_Feature_Transform_3D_detection/#skew-loss-function","text":"\u5728\u505aobject detection\u65f6\u7531\u4e8e\u6b63\u8d1f\u6837\u672c\u7684\u95ee\u9898\uff0c\u4e00\u822c\u90fd\u9700\u8981\u5bf9\u8d1f\u6837\u672c\u7ed9\u4e88\u6bd4\u8f83\u5c11\u7684\u60e9\u7f5a\uff0c\u6587\u4e2d\u5728\u8bad\u7ec3confidence map prediction\u65f6\uff0c\u5bf9\u8bad\u7ec3\u76ee\u6807 S<0.05 \u7684\u4f4d\u7f6e\uff0c\u7ed9\u4e88\u4e00\u4e2a0.01\u7684\u56e0\u5b50\u3002","title":"Skew Loss Function"},{"location":"3dDetection/Orthographic_Feature_Transform_3D_detection/#normalizing-dimension-and-angle-prediction","text":"\u5bf9\u4e8e\u4e00\u4e2a\u7279\u5b9a\u7684class\uff0c\u5df2\u77e5\u5b83\u7684\u5e73\u5747\u957f\u5bbd\u9ad8\uff0c\u5219\u9700\u8981\u9884\u6d4b\u7684\u957f\u5bbd\u9ad8\u53d8\u5316\u4e3a \\Delta_{dim}(x, z) = [log \\frac{w_i}{w},log \\frac{h_i}{h} ,log \\frac{l_i}{l}] \u89d2\u5ea6\u8f93\u51fa\u7528 sin\uff0ccos \u3002 \\Delta_{ang}(x,z) = [sin\\theta_i, cos\\theta_i] \u53e6\u5916\u672c\u6587\u7684regression\u90fd\u662f\u7528 l_1 loss.","title":"Normalizing Dimension and Angle Prediction"},{"location":"3dDetection/Orthographic_Feature_Transform_3D_detection/#nmsnon-max-suppression","text":"\u5148\u5c06\u7f6e\u4fe1\u5ea6map\u505a\u4e00\u4e2a\u9ad8\u65af\u5e73\u6ed1\uff0c\u7136\u540e\u627e\u5176\u4e2d\u5c40\u90e8\u6700\u5927\u503c\u70b9\u4f5c\u4e3a\u8f93\u51fa","title":"NMS(non max suppression)"},{"location":"3dDetection/Pseudo-Lidar/","text":"Monocular 3D Object Detection with Pseudo-LiDAR Point Cloud \u8fd9\u7bc7\u8bba\u6587\u6709\u591a\u4e2a\u91cd\u8981\u8d21\u732e\uff0c\u4e00\u662f\u4f7f\u7528\u5355\u76ee\u9884\u6d4b\u6df1\u5ea6\u56fe\uff0c\u5f62\u6210\u5047Lidar\u6570\u636e\uff0c\u5e76\u5f97\u5230\u4eba\u5de5\u7535\u4e91\uff0c\u7136\u540e\u4f7f\u7528 Frustum Pointnet \u3002\u5bf9\u5f97\u5230\u4e00\u4e2a\u53ef\u9760\u7684\u521d\u59cb\u89e3\u3002 \u7b2c\u4e8c\u7531\u4e8e\u5047Lidar\u6709\u5f88\u591a\u566a\u70b9\uff0c\u566a\u97f3\u4f53\u73b0\u5728\u4e24\u4e2a\u65b9\u9762\uff0c\u4e00\u4e2a\u662f\u6709\u504f\u79fb\uff0c\u5f71\u54cd\u5bf9\u8ddd\u79bb\u7684\u4f30\u8ba1\uff0c\u4e00\u4e2a\u662f\u6709\u957f\u5c3e\u2014\u2014\u7269\u4f53\u8fb9\u7f18\u7684\u4e00\u4e9b\u70b9\u4e91\u4f1a\u62c9\u5f97\u5f88\u957f\uff0c\u539f\u56e0\u662f\u7269\u4f53\u8fb9\u7f18\u5904\u7684\u6df1\u5ea6\u4f30\u8ba1\u4e0d\u51c6\u786e\u3002 \u4e3a\u4e86\u7f13\u89e3\u7b2c\u4e00\u4e2a\u95ee\u9898\uff0c\u4f7f\u75282D-3D box\u7ea6\u675f\u8c03\u65743D box\u7684\u4f4d\u7f6e\uff0c\u8fd9\u91cc\u5f15\u5165\u4e86\u4e00\u4e2aloss\u51fd\u6570\u5728training\u8fc7\u7a0b\u4e2d\u5904\u7406\u8fd9\u4e2a\u95ee\u9898\uff0c\u5728inference\u7684\u65f6\u5019\u5c06\u95ee\u9898\u8f6c\u4e3a\u4f18\u5316\u518d\u63d0\u9ad8\u6027\u80fd\u3002 \u4e3a\u4e86\u7f13\u89e3\u7b2c\u4e8c\u4e2a\u95ee\u9898\uff0c\u4f7f\u7528instance mask\u6765\u4ee3\u88682D proposal\u800c\u4e0d\u662fbounding box\u3002\u76f8\u5f53\u4e8e\u7528segmentation\u7684\u50cf\u7d20\u70b9\u7ea7\u7684\u7ed3\u679c\u8f93\u51fa 2D 3D\u7ea6\u675f \u5c063D\u6846\u8f6c\u6362\u4e3a8\u4e2a\u5750\u6807\u70b9\uff0c\u7136\u540e\u8f6c\u6362\u4e3a\u56fe\u7247\u5750\u6807\uff0c\u6c42\u51fa\u6700\u5c0fbounding rectangle\u5bf9\u5e94\u7684\u56db\u4e2a\u5750\u6807\u3002BBCL\u5c31\u662f\u8fd9\u56db\u4e2a\u5750\u6807\u4e0e2Dbounding box\u7684L1\u8ddd\u79bb\u3002BBCO\u5219\u662f\u5728inference\u7684\u65f6\u5019\u4f7f\u7528global search\u7684\u65b9\u5f0f(\u591a\u534a\u662f\u6a21\u62df\u9000\u706b)\u6709\u8d27\u5bf9\u5e94\u7684L1\u8ddd\u79bb\u3002 \u8fd9\u662f\u4e00\u5e74\u524d\u7684SOTA","title":"Monocular 3D Object Detection with Pseudo-LiDAR Point Cloud"},{"location":"3dDetection/Pseudo-Lidar/#monocular-3d-object-detection-with-pseudo-lidar-point-cloud","text":"\u8fd9\u7bc7\u8bba\u6587\u6709\u591a\u4e2a\u91cd\u8981\u8d21\u732e\uff0c\u4e00\u662f\u4f7f\u7528\u5355\u76ee\u9884\u6d4b\u6df1\u5ea6\u56fe\uff0c\u5f62\u6210\u5047Lidar\u6570\u636e\uff0c\u5e76\u5f97\u5230\u4eba\u5de5\u7535\u4e91\uff0c\u7136\u540e\u4f7f\u7528 Frustum Pointnet \u3002\u5bf9\u5f97\u5230\u4e00\u4e2a\u53ef\u9760\u7684\u521d\u59cb\u89e3\u3002 \u7b2c\u4e8c\u7531\u4e8e\u5047Lidar\u6709\u5f88\u591a\u566a\u70b9\uff0c\u566a\u97f3\u4f53\u73b0\u5728\u4e24\u4e2a\u65b9\u9762\uff0c\u4e00\u4e2a\u662f\u6709\u504f\u79fb\uff0c\u5f71\u54cd\u5bf9\u8ddd\u79bb\u7684\u4f30\u8ba1\uff0c\u4e00\u4e2a\u662f\u6709\u957f\u5c3e\u2014\u2014\u7269\u4f53\u8fb9\u7f18\u7684\u4e00\u4e9b\u70b9\u4e91\u4f1a\u62c9\u5f97\u5f88\u957f\uff0c\u539f\u56e0\u662f\u7269\u4f53\u8fb9\u7f18\u5904\u7684\u6df1\u5ea6\u4f30\u8ba1\u4e0d\u51c6\u786e\u3002 \u4e3a\u4e86\u7f13\u89e3\u7b2c\u4e00\u4e2a\u95ee\u9898\uff0c\u4f7f\u75282D-3D box\u7ea6\u675f\u8c03\u65743D box\u7684\u4f4d\u7f6e\uff0c\u8fd9\u91cc\u5f15\u5165\u4e86\u4e00\u4e2aloss\u51fd\u6570\u5728training\u8fc7\u7a0b\u4e2d\u5904\u7406\u8fd9\u4e2a\u95ee\u9898\uff0c\u5728inference\u7684\u65f6\u5019\u5c06\u95ee\u9898\u8f6c\u4e3a\u4f18\u5316\u518d\u63d0\u9ad8\u6027\u80fd\u3002 \u4e3a\u4e86\u7f13\u89e3\u7b2c\u4e8c\u4e2a\u95ee\u9898\uff0c\u4f7f\u7528instance mask\u6765\u4ee3\u88682D proposal\u800c\u4e0d\u662fbounding box\u3002\u76f8\u5f53\u4e8e\u7528segmentation\u7684\u50cf\u7d20\u70b9\u7ea7\u7684\u7ed3\u679c\u8f93\u51fa","title":"Monocular 3D Object Detection with Pseudo-LiDAR Point Cloud"},{"location":"3dDetection/Pseudo-Lidar/#2d-3d","text":"\u5c063D\u6846\u8f6c\u6362\u4e3a8\u4e2a\u5750\u6807\u70b9\uff0c\u7136\u540e\u8f6c\u6362\u4e3a\u56fe\u7247\u5750\u6807\uff0c\u6c42\u51fa\u6700\u5c0fbounding rectangle\u5bf9\u5e94\u7684\u56db\u4e2a\u5750\u6807\u3002BBCL\u5c31\u662f\u8fd9\u56db\u4e2a\u5750\u6807\u4e0e2Dbounding box\u7684L1\u8ddd\u79bb\u3002BBCO\u5219\u662f\u5728inference\u7684\u65f6\u5019\u4f7f\u7528global search\u7684\u65b9\u5f0f(\u591a\u534a\u662f\u6a21\u62df\u9000\u706b)\u6709\u8d27\u5bf9\u5e94\u7684L1\u8ddd\u79bb\u3002 \u8fd9\u662f\u4e00\u5e74\u524d\u7684SOTA","title":"2D 3D\u7ea6\u675f"},{"location":"3dDetection/RecentCollectionForMono3D/","text":"Recent Collections for Mono 3D detection \u5728IROS2020\u6295\u7a3f\u524d\u540e\u79ef\u6512\u4e86\u4e00\u7cfb\u5217\u5355\u76ee3D\u68c0\u6d4bpaper\u7684\u9605\u8bfb\u3002\u8fd9\u91cc\u4e00\u6b21\u8fc7\u8fdb\u884c\u8bb0\u5f55,\u5f00\u6e90\u5728\u524d\uff0c\u672a\u5f00\u6e90\u5728\u540e. \u8fd9\u91cc\u5217\u51fa\u76ee\u524d\u6709\u6587\u7ae0\u53ef\u5bfb\u7684KITTI\u6392\u884c\u699c(2020.02.27) Update(2020.04.02):Update scores for YOLOMono3D Update(2020.07.24): Update Kinematic 3D Methods Moderate Easy Hard Time Kinematic3D 12.72 19.07 9.17 0.12 YOLOMono3D 12.06 18.28 8.42 0.05 D4LCN 11.72 16.65 9.51 0.2 Refined-MPL 11.14 18.09 8.94 0.15 AM3D 10.74 16.50 9.52 0.4 RTM3D 10.34 14.41 8.77 0.05 MonoPair 9.99 13.04 8.65 0.06 SMOKE 9.76 14.03 7.84 0.03 M3D-RPN 9.71 14.76 7.42 0.16 D4LCN pdf code \u8fd9\u7bc7paper\u5b8c\u5168\u7ee7\u627f\u4e86 M3D-RPN \u7684\u8863\u94b5\uff0c\u5b83\u4e0d\u540c\u7684\u5730\u65b9\u5728\u4e8e\uff0c\u6452\u5f03\u4e86M3D-RPN\u5904\u7406\u7f13\u6162\u7684height-wise convolution,\u800c\u662f\u4f7f\u7528\u5355\u76ee\u4f30\u8ba1\u6df1\u5ea6\uff0c\u7136\u540e\u4f7f\u7528\u6df1\u5ea6\u4f5c\u4e3a\u5377\u79ef\u6838\u7684guide, \u8fd9\u4e2aguide\u7c7b\u4f3c\u4e8e\u8fd9\u51e0\u7bc7\u6587\u7ae0\u7684\u64cd\u4f5c: guidenet ; DFN RTM3D pdf code \u8fd9\u7bc7\u6587\u7ae0\u8fd8\u6ca1\u6709\u6b63\u5f0f\u5f00\u6e90\uff0c\u4f46\u662fgithub\u5c31\u5148\u5f00\u7740\u4e86\u3002\u8fd9\u7bc7\u6587\u7ae0\u5728\u6280\u672f\u4e0a\u6709\u4e00\u5b9a\u7684\u65b0\u610f\uff0c\u5b83\u4f7f\u7528 CenterNet \u7684\u67b6\u6784\u4f30\u8ba1\u5927\u91cf\u7684keypoints\u4ee5\u53ca\u5197\u4f59\u76843D\u4fe1\u606f\uff0c\u6700\u540e\u901a\u8fc7\u6700\u4f18\u5316\u878d\u5408\u3002\u4f7f\u7528\u5927\u91cf\u5197\u4f59\u4fe1\u606f\u5b83\u4e0d\u662f\u7b2c\u4e00\u4e2a,\u524d\u8005\u6bd4\u5982\u6709 SS3D ,\u4f46\u662f\u5b83\u7ed5\u8fc7\u4e86anchor\u4f7f\u7528CenterNet\u6709\u4e00\u5b9a\u7684\u65b0\u610f\u3002 MonoPair pdf \u8fd9\u7bc7\u6587\u7ae0\u662f\u5b9e\u9a8c\u5ba4\u5927\u5e08\u5144\u90b0\u78ca\u5728\u963f\u91cc\u7684CVPR2020 paper\u3002\u6709 \u5b98\u65b9\u7f51\u7ad9 \u6587\u7ae0\u7684\u6838\u5fc3\u521b\u65b0\u662f\u7b2c\u4e00\u4e2a\u4f7f\u7528\u573a\u666f\u4e2d\u4e0d\u540c\u7269\u4f53\u4e4b\u95f4\u7684\u76f8\u4e92\u7ea6\u675f\u8fdb\u884c\u4f18\u5316\u7684paper\u3002 SMOKE pdf \u8fd9\u7bc7paper\u7684\u521b\u65b0\u70b9\u4e0d\u7b97\u7279\u522b\u591a\u3002 1. \u4f7f\u7528\u4e86 CenterNet \u7684\u67b6\u6784\u8fdb\u884c\u4e2d\u5fc3\u70b9\u7684\u4f30\u8ba1\u3002 2. \u4f7f\u7528\u4e86distangling loss, \u8fd9\u4e2a\u6765\u81ea\u4e8e MonoDIS 3. \u6570\u636e\u589e\u5f3a\u4e0a\u4f7f\u7528\u4e86shifting\u7b49\u65b9\u6cd5\uff0c\u4f46\u662f\u53ea\u662f\u7528\u6765train keypoint\u70ed\u56fe\u7b49\u7ed3\u6784\u3002\u5c5e\u4e8especialized augmentation for specialized cost.\u53ef\u8c13\u6df1\u5ea6\u8c03\u53c2 YOLOMono3D \u4e0d\u591a\u8bf4\u4e86\uff0c\u5feb\u4e0a\u8f66","title":"Recent Collections for Mono 3D detection"},{"location":"3dDetection/RecentCollectionForMono3D/#recent-collections-for-mono-3d-detection","text":"\u5728IROS2020\u6295\u7a3f\u524d\u540e\u79ef\u6512\u4e86\u4e00\u7cfb\u5217\u5355\u76ee3D\u68c0\u6d4bpaper\u7684\u9605\u8bfb\u3002\u8fd9\u91cc\u4e00\u6b21\u8fc7\u8fdb\u884c\u8bb0\u5f55,\u5f00\u6e90\u5728\u524d\uff0c\u672a\u5f00\u6e90\u5728\u540e. \u8fd9\u91cc\u5217\u51fa\u76ee\u524d\u6709\u6587\u7ae0\u53ef\u5bfb\u7684KITTI\u6392\u884c\u699c(2020.02.27) Update(2020.04.02):Update scores for YOLOMono3D Update(2020.07.24): Update Kinematic 3D Methods Moderate Easy Hard Time Kinematic3D 12.72 19.07 9.17 0.12 YOLOMono3D 12.06 18.28 8.42 0.05 D4LCN 11.72 16.65 9.51 0.2 Refined-MPL 11.14 18.09 8.94 0.15 AM3D 10.74 16.50 9.52 0.4 RTM3D 10.34 14.41 8.77 0.05 MonoPair 9.99 13.04 8.65 0.06 SMOKE 9.76 14.03 7.84 0.03 M3D-RPN 9.71 14.76 7.42 0.16","title":"Recent Collections for Mono 3D detection"},{"location":"3dDetection/RecentCollectionForMono3D/#d4lcn","text":"pdf code \u8fd9\u7bc7paper\u5b8c\u5168\u7ee7\u627f\u4e86 M3D-RPN \u7684\u8863\u94b5\uff0c\u5b83\u4e0d\u540c\u7684\u5730\u65b9\u5728\u4e8e\uff0c\u6452\u5f03\u4e86M3D-RPN\u5904\u7406\u7f13\u6162\u7684height-wise convolution,\u800c\u662f\u4f7f\u7528\u5355\u76ee\u4f30\u8ba1\u6df1\u5ea6\uff0c\u7136\u540e\u4f7f\u7528\u6df1\u5ea6\u4f5c\u4e3a\u5377\u79ef\u6838\u7684guide, \u8fd9\u4e2aguide\u7c7b\u4f3c\u4e8e\u8fd9\u51e0\u7bc7\u6587\u7ae0\u7684\u64cd\u4f5c: guidenet ; DFN","title":"D4LCN"},{"location":"3dDetection/RecentCollectionForMono3D/#rtm3d","text":"pdf code \u8fd9\u7bc7\u6587\u7ae0\u8fd8\u6ca1\u6709\u6b63\u5f0f\u5f00\u6e90\uff0c\u4f46\u662fgithub\u5c31\u5148\u5f00\u7740\u4e86\u3002\u8fd9\u7bc7\u6587\u7ae0\u5728\u6280\u672f\u4e0a\u6709\u4e00\u5b9a\u7684\u65b0\u610f\uff0c\u5b83\u4f7f\u7528 CenterNet \u7684\u67b6\u6784\u4f30\u8ba1\u5927\u91cf\u7684keypoints\u4ee5\u53ca\u5197\u4f59\u76843D\u4fe1\u606f\uff0c\u6700\u540e\u901a\u8fc7\u6700\u4f18\u5316\u878d\u5408\u3002\u4f7f\u7528\u5927\u91cf\u5197\u4f59\u4fe1\u606f\u5b83\u4e0d\u662f\u7b2c\u4e00\u4e2a,\u524d\u8005\u6bd4\u5982\u6709 SS3D ,\u4f46\u662f\u5b83\u7ed5\u8fc7\u4e86anchor\u4f7f\u7528CenterNet\u6709\u4e00\u5b9a\u7684\u65b0\u610f\u3002","title":"RTM3D"},{"location":"3dDetection/RecentCollectionForMono3D/#monopair","text":"pdf \u8fd9\u7bc7\u6587\u7ae0\u662f\u5b9e\u9a8c\u5ba4\u5927\u5e08\u5144\u90b0\u78ca\u5728\u963f\u91cc\u7684CVPR2020 paper\u3002\u6709 \u5b98\u65b9\u7f51\u7ad9 \u6587\u7ae0\u7684\u6838\u5fc3\u521b\u65b0\u662f\u7b2c\u4e00\u4e2a\u4f7f\u7528\u573a\u666f\u4e2d\u4e0d\u540c\u7269\u4f53\u4e4b\u95f4\u7684\u76f8\u4e92\u7ea6\u675f\u8fdb\u884c\u4f18\u5316\u7684paper\u3002","title":"MonoPair"},{"location":"3dDetection/RecentCollectionForMono3D/#smoke","text":"pdf \u8fd9\u7bc7paper\u7684\u521b\u65b0\u70b9\u4e0d\u7b97\u7279\u522b\u591a\u3002 1. \u4f7f\u7528\u4e86 CenterNet \u7684\u67b6\u6784\u8fdb\u884c\u4e2d\u5fc3\u70b9\u7684\u4f30\u8ba1\u3002 2. \u4f7f\u7528\u4e86distangling loss, \u8fd9\u4e2a\u6765\u81ea\u4e8e MonoDIS 3. \u6570\u636e\u589e\u5f3a\u4e0a\u4f7f\u7528\u4e86shifting\u7b49\u65b9\u6cd5\uff0c\u4f46\u662f\u53ea\u662f\u7528\u6765train keypoint\u70ed\u56fe\u7b49\u7ed3\u6784\u3002\u5c5e\u4e8especialized augmentation for specialized cost.\u53ef\u8c13\u6df1\u5ea6\u8c03\u53c2","title":"SMOKE"},{"location":"3dDetection/RecentCollectionForMono3D/#yolomono3d","text":"\u4e0d\u591a\u8bf4\u4e86\uff0c\u5feb\u4e0a\u8f66","title":"YOLOMono3D"},{"location":"3dDetection/RecentCollectionForStereo3D/","text":"Recent Collections for Stereo 3D detection \u8fd1\u671f\u79ef\u6512\u4e86\u4e00\u7cfb\u5217\u53cc\u76ee3D\u68c0\u6d4bpaper\u7684\u9605\u8bfb\u3002\u8fd9\u91cc\u4e00\u6b21\u8fc7\u8fdb\u884c\u8bb0\u5f55,\u4ee5\u7ed3\u679c\u6392\u5217\u4e3a\u987a\u5e8f\u3002 \u8fd9\u91cc\u5217\u51fa\u76ee\u524d\u6709\u6587\u7ae0\u53ef\u5bfb\u7684KITTI\u6392\u884c\u699c(2020.04.09) Update: 2020.0409: Add Disp-RCNN and PL E2E. 2020.0714: Add CDN Methods Moderate Easy Hard Time CDN 54.22 % 74.52 % 46.36 % 0.6 s CG-Stereo 53.58 % 74.39 % 46.50 % 0.57 s DSGN 52.18 % 73.50 % 45.14 % 0.67 s CDN P-LiDAR++ 44.86 % 64.31 % 38.11 % 0.4 s Pseudo-LiDAR E2E 43.92 % 64.75 % 38.14 % 0.4 s Pseudo-LiDAR++ 42.43 % 61.11 % 36.99 % 0.4 s Disp R-CNN (velo) 39.34 % 59.58 % 31.99 % 0.42 s ZoomNet 38.64 % 55.98 % 30.97 % 0.3 s OC Stereo 37.60 % 55.15 % 30.25 % 0.35 s Pseudo-Lidar 34.05 % 54.53 % 28.25 % 0.4 s Stereo R-CNN 30.23 % 47.58 % 23.72 % 0.3 s RT3DStereo 23.28 % 29.90 % 18.96 % 0.08 s CG-stereo pdf \u8fd9\u7bc7paper\u6765\u81ea\u4e8e Jason Ku\u90a3\u4e00\u7ec4\uff0c\u662f\u76ee\u524d(2020.03.15)Stereo\u7684SOTA\uff0c\u7ed9pseudo-lidar\u7cfb\u5217\u63d0\u4f9b\u4e86\u4e24\u4e2a\u5f88\u6709\u6548\u7684idea\u3002 \u9996\u5148\u662f\u53cc\u76ee\u4f30\u8ba1\u4e2d\uff0cforground\u4e0ebackground\u7684\u7279\u6027\u5dee\u8ddd\u662f\u5f88\u5927\u7684\uff0c\u4f5c\u8005\u8ba4\u4e3a\u5e94\u5f53\u4f7f\u7528\u4e24\u4e2a\u5206\u522b\u7684decoder\u5904\u7406\u524d\u666f\u4e0e\u80cc\u666f\u7684\u7269\u4f53\uff0c\u5206\u53c9\u7684\u4f9d\u636e\u662f\u8bed\u4e49\u5206\u5272\u7684\u7ed3\u679c\u3002 \u5176\u6b21\u662f\u53cc\u76ee\u4f30\u8ba1\u5f97\u5230\u7684\u70b9\u4e4b\u4e2d\u6709\u5f88\u591a\u7684\u566a\u97f3\uff0c\u4e0d\u540c\u70b9\u7684confidence\u4e0d\u540c\uff0c\u5bf9\u540e\u7aef\u70b9\u4e91\u7684\u5f71\u54cd\u5f88\u5927\uff0c\u4f5c\u8005\u8fd9\u91cc\u6839\u636estereo matching\u7684\u4e00\u4e2aconfidence map\u4f5c\u4e3a\u4e00\u4e2aattention \u5c42\u8f93\u5165\u5230\u70b9\u4e91\u540e\u7aef\u5904\u7406\u4e2d\u3002 Pseudo-LiDAR E2E pdf code \u8fd9\u7bc7paper\u7684\u8d21\u732e\u975e\u5e38\u6709\u610f\u4e49\uff0c\u63d0\u5230\u7684\u662f\u8fc7\u53bb\u7684Pseudo-lidar\u7b97\u6cd5\u57fa\u672c\u90fd\u662f\u5b8c\u5168\u7684\u4e8c\u9636\u6bb5\u7b97\u6cd5\uff0c\u4e5f\u5c31\u662f\u53cc\u76ee\u751f\u6210\u70b9\u4e91\u4e0e\u70b9\u4e913D\u68c0\u6d4b\u4e4b\u95f4\u662f\u65e0\u6cd5End2End\u8bad\u7ec3\u7684\uff0c\u4e2d\u95f4\u7684\u8f6c\u6362\u8fc7\u7a0b\u662f\u4e0d\u53ef\u5bfc\u7684\uff0c\u56e0\u800c\u5c3d\u7ba1\u53ef\u4ee5fine-tune,\u4f46\u662f\u68af\u5ea6\u7684\u6d41\u52a8\u4f1a\u4e2d\u65ad,\u8fd9\u7bc7paper\u7684\u6700\u5927\u8d21\u732e\u5728\u4e8e\u63d0\u51fa\u4e00\u4e2aCoR\u6a21\u5757\u4f7f\u5f97\u540c\u65f6\u53ef\u4ee5\u8bad\u7ec3\u70b9\u4e91\u751f\u6210\u4ee5\u53ca\u57fa\u4e8e\u70b9\u4e91\u7684\u7269\u4f53\u68c0\u6d4b\u3002 \\boldsymbol{T}\\left(m, m^{\\prime}\\right)=\\left\\{\\begin{array}{cc} 0 & \\text { if }\\left|P_{m^{\\prime}}\\right|=0 \\\\ \\frac{1}{\\left|\\boldsymbol{P}_{m^{\\prime}}\\right|} \\sum_{\\boldsymbol{p} \\in \\boldsymbol{P}_{m^{\\prime}}} e^{-\\frac{\\left\\|\\boldsymbol{p}-\\hat{p}_{m}\\right\\|^{2}}{\\sigma^{2}}} & \\text { if }\\left|P_{m^{\\prime}}\\right|>0 \\end{array}\\right. \\boldsymbol{T}(m)=\\boldsymbol{T}(m, m)+\\frac{1}{\\left|\\mathcal{N}_{m}\\right|} \\sum_{m^{\\prime} \\in \\mathcal{N}_{m}} \\boldsymbol{T}\\left(m, m^{\\prime}\\right) voxel\u91cc\u9762\u6bcf\u4e00\u4e2abin\u90fd\u5bf9\u5e94\u4e00\u4e2a\u57fa\u7c7b\uff0c\u6bcf\u4e00\u4e2abin\u662f\u81ea\u5df1\u4e0e\u5468\u56f4\u7684\u52a0\u6743\u6c42\u548c\u3002\u4ece\u800cvoxel\u53ef\u5bfc Pseudo-Lidar++ pdf code \u8fd9\u7bc7paper\u7684\u4e3b\u8981\u65b0\u610f\u6709\u4e24\u70b9 \u5728\u6df1\u5ea6\u4f30\u8ba1\u4e0a\uff0c\u4f5c\u8005\u7ed9\u51fa\u4e00\u4e2a\u65b0\u7684insight\uff0c\u5c31\u662f\u5747\u5300\u76843D\u5377\u79ef\u5f88\u53ef\u80fd\u662fdisparity-based cost volome\u7684\u4e00\u4e2aerror source\uff0c\u6bd4\u5982\u8bf4\u5bf9\u4e8edisparity\u6bd4\u8f83\u9ad8\u7684\u70b9\uff0c\u53ef\u4ee5smooth out\uff0c\u4f46\u662f\u5bf9\u4e8edisparity\u6bd4\u8f83\u5c0f\u7684\u70b9\u5219\u4e0d\u5e94\u8be5\u540c\u7b49\u7ea7\u522b\u7684smooth out(\u4f1a\u4ea7\u751f\u5f88\u5927\u8bef\u5dee)\u3002\u6240\u4ee5\u4f5c\u8005\u5c06disparity cost volume\u7684\u6df1\u5ea6\u65b9\u5411\u6c42\u5012\u6570\uff0c\u5e76\u7ebf\u6027\u63d2\u503c\u5f97\u5230depth cost volume,\u7136\u540e\u5728depth cost volume\u4e0a\u9762\u505a3D\u5377\u79ef\u3002 \u5728\u540e\u5904\u7406\u4e0a\uff0c\u4f5c\u8005\u878d\u5408\u4e86\u6df1\u5ea6\u8865\u5168(depth completion)\u7684\u601d\u60f3\uff0c\u7531\u4e8edisparity\u662f\u79bb\u6563\u7684\uff0c\u6240\u4ee5\u4f1a\u5f15\u8d77\u5f88\u591a\u4e0d\u5e94\u8be5\u7684\u8bef\u5dee\uff0c\u8fdb\u800c\u4f5c\u8005\u8003\u8651\u4f7f\u7528\u4f4e\u7ebf\u6570\u7684lidar(\u5f00\u6e90\u7684\u4e00\u4e2a\u65b9\u6848\u7ebf\u6570\u662f4)\u4f5c\u4e3a\u4e00\u4e2aground truth\u7684\u8865\u507f\u3002\u8fd9\u91cc\u4e0d\u8fdb\u4e00\u6b65\u5c55\u5f00\u3002 \u4f5c\u8005\u5728KITTI\u4e0a\u63d0\u4ea4\u4e86\u4e24\u4e2a\u6210\u7ee9(PL++),\u6807\u9898\u4e0b\u9762\u7ed9\u51fa\u7684\u662f\u6625\u53cc\u76ee\u800c\u6ca1\u6709GDC\u7684\u6210\u7ee9\uff0c\u6709GDC\u7684\u6210\u7ee9\u4f1a\u66f4\u9ad8\u4e00\u4e9b\u3002 Disp-RCNN pdf code \u8fd9\u7bc7paper\u7684\u4e3b\u8981\u4e0d\u540c\u70b9\u5728\u4e8e\u4f7f\u7528RoIPooling\u4ece\u539f\u56fe(\u4f5c\u8005\u6307\u51fa\u4e0d\u5e94\u8be5\u4ecefeature\u4e2d\u91c7\u6837\uff0c\u56e0\u4e3aDisparity\u8981\u6c42\u90bb\u8fd1\u50cf\u7d20\u7ed3\u679c\u4e0d\u540c\uff0c\u4f46\u662fInstance Segmentation\u4f1a\u8981\u6c42\u90bb\u8fd1\u50cf\u7d20\u7ed3\u679c\u76f8\u540c)\u4e2d\u91c7\u6837,\u7136\u540e\u4ecePooling\u540e\u7684\u7ed3\u679c\u91cd\u5efaDisparity\u4ee5\u53ca\u5c40\u90e8\u70b9\u4e91(\u8fd9\u4e2a\u6a21\u5757\u5728\u6570\u5b66\u5904\u7406\u4e0a\u8981\u5c0f\u5fc3)\uff0c\u7136\u540e\u4f7f\u7528\u70b9\u4e91\u68c0\u6d4b\u8f93\u51fa\u7ed3\u679c\u3002 \u8fd9\u7bc7paper\u8fd8\u6709\u4f7f\u7528pretrained\u7684\u53cc\u76ee\u91cd\u5efa\u7f51\u7edc\uff0c\u5f97\u5230\u5bc6\u96c6\u7684pseudo Ground Truth Disparity. Loss\u7684\u6784\u6210\u6bd4\u8f83\u590d\u6742\uff0c\u5177\u4f53\u770bpaper ZoomNet pdf code \u4f7f\u75282D\u68c0\u6d4b\u5148\u5f97\u5230\u4e24\u4e2a\u8f66\u5b50\u548b\u56fe\u7247\u7684\u4f4d\u7f6e\uff0c\u7136\u540e\u5206\u522bresize,\u5e76\u4e14\u8c03\u8282\u540d\u4e49\u76f8\u673a\u53c2\u6570(zooming)\u3002 \u4e2d\u4ecb\u8f85\u52a9\u9884\u6d4b\u7684\u5185\u5bb9\u5305\u62ecdisparity, instance segmentation, part location(\u6bcf\u4e00\u4e2a\u50cf\u7d20\u76f8\u5bf9\u4e8e\u8f66\u5b50\u4e2d\u5fc3x, y, z\u8f74\u7684\u4f4d\u7f6e\uff0c\u8fd9\u4e2a\u4e00\u822c\u4f7f\u7528\u70b9\u4e91\u548c\u7a20\u5bc6\u6df1\u5ea6\u56fe\u8fdb\u884c\u6807\u6ce8)\u3002\u5f97\u5230\u70b9\u4e91\u540e\u5c06feature \u94fe\u63a5\uff0c\u7136\u540e\u7528\u7c7b\u4f3c\u4e8epoint net\u7684\u65b9\u5f0f\u9884\u6d4b\u6700\u7ec8\u7ed3\u679c\u3002 OC Stereo pdf \u8fd9\u7bc7paper\u7684\u60f3\u6cd5\u662f\u4f7f\u7528RoIAlign\u5c06\u5de6\u53f3\u76ee\u4e24\u4e2a\u533a\u57df\u7684feature \u63d0\u51fa\u6765\uff0c\u7136\u540e\u4f7f\u7528instance seg\u4e0eCost volumn\u8ba1\u7b97\u5bf9\u5e94pixel\u5904\u7684disparity\u3002 \u4f5c\u8005\u5bf9\u4e8eRoIAlign\u524d\u540e\u7684segmentation pixel\u7684\u4f4d\u7f6e\u5173\u7cfb\u505a\u4e86\u5f88\u7ec6\u81f4\u7684\u89e3\u91ca\u3002 \u5728\u5f97\u5230\u5c40\u90e8RGB\u70b9\u4e91\u4e4b\u540e\u4f5c\u8005\u4f7f\u7528 AVOD \u8fdb\u884c3D\u68c0\u6d4b\u3002 Pseudo-Lidar pdf code \u8fd9\u7bc7paper\u7406\u8bba\u4e0a\u6765\u8bf4\u662fpseudo-lidar\u7684\u7b2c\u4e00\u7bc7\u6587\u7ae0 \u601d\u8def\u76ee\u524d\u56de\u770b\u6bd4\u8f83\u5730\u76f4\u63a5\uff0c\u53cc\u76ee\u6df1\u5ea6\u4f30\u8ba1\u65b9\u9762\uff0c\u4f5c\u8005\u4f7f\u7528pretrain PSMNet .\u6ce8\u610f\u8fd9\u4e2aPSMNet\u662f\u5728sceneflow\u6570\u636e\u96c6\uff0c\u4ee5\u53catraining set\u7684\u70b9\u4e91\u6570\u636e\u4f5c\u4e3a\u76d1\u7763\u7684\u3002lidar 3D\u68c0\u6d4b\u65b9\u9762\uff0c\u4f5c\u8005\u4f7f\u7528 AVOD Stereo R-CNN pdf code \u51e0\u4e2a\u8bad\u7ec3\u7ec6\u8282: positive anchors \u7684threshold\u63d0\u9ad8\u4e86\u3002 \u591a\u9884\u6d4b\u4e00\u4e2aKeypoint\u7684\u4f4d\u7f6e\uff0c\u5982\u4e0b\u56fe SSIM\uff0c\u5229\u7528\u53cc\u76ee\u7684disparity\uff0c\u540e\u5904\u7406\u4f18\u5316\u6df1\u5ea6\u503c\u3002 RT3D Stereo pdf \u8bad\u7ec3\u7ec6\u8282: \u4f7f\u7528\u5355\u4e00\u4e00\u4e2aResNet\u89e3\u51b32D \u68c0\u6d4b\u4ee5\u53ca\u8bed\u4e49\u5206\u5272\u7684encoding.\u7528\u7684\u662f \u4e8c\u4f5c\u4f5c\u8005\u7684\u540c\u65f6\u68c0\u6d4b\u4e0e\u8bed\u4e49\u5206\u5272\u7f51\u7edc.pdf Disparity\u4f7f\u7528\u7684\u662fblock matching\u7684\u4f20\u7edf\u65b9\u6cd5\uff0c \u4f5c\u8005\u6839\u636e\u8bed\u4e49\u5206\u5272\u4ee5\u53cadetector\u7ed3\u679c\u5206\u5272\u51fa\u76f8\u5173\u50cf\u7d20\uff0c\u7136\u540e\u805a\u7c7b\uff0c\u7136\u540e\u4ee5\u4f18\u5316\u51f8\u5305\u7684\u65b9\u5f0f\u5f97\u51fa\u7ed3\u679c\u3002\u7531\u4e8e\u4f5c\u8005\u6ca1\u6709\u5f00\u6e90\uff0c\u5f88\u591a\u5185\u5bb9\u6709\u5f85\u5546\u69b7\u3002","title":"Recent Collections for Stereo 3D detection"},{"location":"3dDetection/RecentCollectionForStereo3D/#recent-collections-for-stereo-3d-detection","text":"\u8fd1\u671f\u79ef\u6512\u4e86\u4e00\u7cfb\u5217\u53cc\u76ee3D\u68c0\u6d4bpaper\u7684\u9605\u8bfb\u3002\u8fd9\u91cc\u4e00\u6b21\u8fc7\u8fdb\u884c\u8bb0\u5f55,\u4ee5\u7ed3\u679c\u6392\u5217\u4e3a\u987a\u5e8f\u3002 \u8fd9\u91cc\u5217\u51fa\u76ee\u524d\u6709\u6587\u7ae0\u53ef\u5bfb\u7684KITTI\u6392\u884c\u699c(2020.04.09) Update: 2020.0409: Add Disp-RCNN and PL E2E. 2020.0714: Add CDN Methods Moderate Easy Hard Time CDN 54.22 % 74.52 % 46.36 % 0.6 s CG-Stereo 53.58 % 74.39 % 46.50 % 0.57 s DSGN 52.18 % 73.50 % 45.14 % 0.67 s CDN P-LiDAR++ 44.86 % 64.31 % 38.11 % 0.4 s Pseudo-LiDAR E2E 43.92 % 64.75 % 38.14 % 0.4 s Pseudo-LiDAR++ 42.43 % 61.11 % 36.99 % 0.4 s Disp R-CNN (velo) 39.34 % 59.58 % 31.99 % 0.42 s ZoomNet 38.64 % 55.98 % 30.97 % 0.3 s OC Stereo 37.60 % 55.15 % 30.25 % 0.35 s Pseudo-Lidar 34.05 % 54.53 % 28.25 % 0.4 s Stereo R-CNN 30.23 % 47.58 % 23.72 % 0.3 s RT3DStereo 23.28 % 29.90 % 18.96 % 0.08 s","title":"Recent Collections for Stereo 3D detection"},{"location":"3dDetection/RecentCollectionForStereo3D/#cg-stereo","text":"pdf \u8fd9\u7bc7paper\u6765\u81ea\u4e8e Jason Ku\u90a3\u4e00\u7ec4\uff0c\u662f\u76ee\u524d(2020.03.15)Stereo\u7684SOTA\uff0c\u7ed9pseudo-lidar\u7cfb\u5217\u63d0\u4f9b\u4e86\u4e24\u4e2a\u5f88\u6709\u6548\u7684idea\u3002 \u9996\u5148\u662f\u53cc\u76ee\u4f30\u8ba1\u4e2d\uff0cforground\u4e0ebackground\u7684\u7279\u6027\u5dee\u8ddd\u662f\u5f88\u5927\u7684\uff0c\u4f5c\u8005\u8ba4\u4e3a\u5e94\u5f53\u4f7f\u7528\u4e24\u4e2a\u5206\u522b\u7684decoder\u5904\u7406\u524d\u666f\u4e0e\u80cc\u666f\u7684\u7269\u4f53\uff0c\u5206\u53c9\u7684\u4f9d\u636e\u662f\u8bed\u4e49\u5206\u5272\u7684\u7ed3\u679c\u3002 \u5176\u6b21\u662f\u53cc\u76ee\u4f30\u8ba1\u5f97\u5230\u7684\u70b9\u4e4b\u4e2d\u6709\u5f88\u591a\u7684\u566a\u97f3\uff0c\u4e0d\u540c\u70b9\u7684confidence\u4e0d\u540c\uff0c\u5bf9\u540e\u7aef\u70b9\u4e91\u7684\u5f71\u54cd\u5f88\u5927\uff0c\u4f5c\u8005\u8fd9\u91cc\u6839\u636estereo matching\u7684\u4e00\u4e2aconfidence map\u4f5c\u4e3a\u4e00\u4e2aattention \u5c42\u8f93\u5165\u5230\u70b9\u4e91\u540e\u7aef\u5904\u7406\u4e2d\u3002","title":"CG-stereo"},{"location":"3dDetection/RecentCollectionForStereo3D/#pseudo-lidar-e2e","text":"pdf code \u8fd9\u7bc7paper\u7684\u8d21\u732e\u975e\u5e38\u6709\u610f\u4e49\uff0c\u63d0\u5230\u7684\u662f\u8fc7\u53bb\u7684Pseudo-lidar\u7b97\u6cd5\u57fa\u672c\u90fd\u662f\u5b8c\u5168\u7684\u4e8c\u9636\u6bb5\u7b97\u6cd5\uff0c\u4e5f\u5c31\u662f\u53cc\u76ee\u751f\u6210\u70b9\u4e91\u4e0e\u70b9\u4e913D\u68c0\u6d4b\u4e4b\u95f4\u662f\u65e0\u6cd5End2End\u8bad\u7ec3\u7684\uff0c\u4e2d\u95f4\u7684\u8f6c\u6362\u8fc7\u7a0b\u662f\u4e0d\u53ef\u5bfc\u7684\uff0c\u56e0\u800c\u5c3d\u7ba1\u53ef\u4ee5fine-tune,\u4f46\u662f\u68af\u5ea6\u7684\u6d41\u52a8\u4f1a\u4e2d\u65ad,\u8fd9\u7bc7paper\u7684\u6700\u5927\u8d21\u732e\u5728\u4e8e\u63d0\u51fa\u4e00\u4e2aCoR\u6a21\u5757\u4f7f\u5f97\u540c\u65f6\u53ef\u4ee5\u8bad\u7ec3\u70b9\u4e91\u751f\u6210\u4ee5\u53ca\u57fa\u4e8e\u70b9\u4e91\u7684\u7269\u4f53\u68c0\u6d4b\u3002 \\boldsymbol{T}\\left(m, m^{\\prime}\\right)=\\left\\{\\begin{array}{cc} 0 & \\text { if }\\left|P_{m^{\\prime}}\\right|=0 \\\\ \\frac{1}{\\left|\\boldsymbol{P}_{m^{\\prime}}\\right|} \\sum_{\\boldsymbol{p} \\in \\boldsymbol{P}_{m^{\\prime}}} e^{-\\frac{\\left\\|\\boldsymbol{p}-\\hat{p}_{m}\\right\\|^{2}}{\\sigma^{2}}} & \\text { if }\\left|P_{m^{\\prime}}\\right|>0 \\end{array}\\right. \\boldsymbol{T}(m)=\\boldsymbol{T}(m, m)+\\frac{1}{\\left|\\mathcal{N}_{m}\\right|} \\sum_{m^{\\prime} \\in \\mathcal{N}_{m}} \\boldsymbol{T}\\left(m, m^{\\prime}\\right) voxel\u91cc\u9762\u6bcf\u4e00\u4e2abin\u90fd\u5bf9\u5e94\u4e00\u4e2a\u57fa\u7c7b\uff0c\u6bcf\u4e00\u4e2abin\u662f\u81ea\u5df1\u4e0e\u5468\u56f4\u7684\u52a0\u6743\u6c42\u548c\u3002\u4ece\u800cvoxel\u53ef\u5bfc","title":"Pseudo-LiDAR E2E"},{"location":"3dDetection/RecentCollectionForStereo3D/#pseudo-lidar","text":"pdf code \u8fd9\u7bc7paper\u7684\u4e3b\u8981\u65b0\u610f\u6709\u4e24\u70b9 \u5728\u6df1\u5ea6\u4f30\u8ba1\u4e0a\uff0c\u4f5c\u8005\u7ed9\u51fa\u4e00\u4e2a\u65b0\u7684insight\uff0c\u5c31\u662f\u5747\u5300\u76843D\u5377\u79ef\u5f88\u53ef\u80fd\u662fdisparity-based cost volome\u7684\u4e00\u4e2aerror source\uff0c\u6bd4\u5982\u8bf4\u5bf9\u4e8edisparity\u6bd4\u8f83\u9ad8\u7684\u70b9\uff0c\u53ef\u4ee5smooth out\uff0c\u4f46\u662f\u5bf9\u4e8edisparity\u6bd4\u8f83\u5c0f\u7684\u70b9\u5219\u4e0d\u5e94\u8be5\u540c\u7b49\u7ea7\u522b\u7684smooth out(\u4f1a\u4ea7\u751f\u5f88\u5927\u8bef\u5dee)\u3002\u6240\u4ee5\u4f5c\u8005\u5c06disparity cost volume\u7684\u6df1\u5ea6\u65b9\u5411\u6c42\u5012\u6570\uff0c\u5e76\u7ebf\u6027\u63d2\u503c\u5f97\u5230depth cost volume,\u7136\u540e\u5728depth cost volume\u4e0a\u9762\u505a3D\u5377\u79ef\u3002 \u5728\u540e\u5904\u7406\u4e0a\uff0c\u4f5c\u8005\u878d\u5408\u4e86\u6df1\u5ea6\u8865\u5168(depth completion)\u7684\u601d\u60f3\uff0c\u7531\u4e8edisparity\u662f\u79bb\u6563\u7684\uff0c\u6240\u4ee5\u4f1a\u5f15\u8d77\u5f88\u591a\u4e0d\u5e94\u8be5\u7684\u8bef\u5dee\uff0c\u8fdb\u800c\u4f5c\u8005\u8003\u8651\u4f7f\u7528\u4f4e\u7ebf\u6570\u7684lidar(\u5f00\u6e90\u7684\u4e00\u4e2a\u65b9\u6848\u7ebf\u6570\u662f4)\u4f5c\u4e3a\u4e00\u4e2aground truth\u7684\u8865\u507f\u3002\u8fd9\u91cc\u4e0d\u8fdb\u4e00\u6b65\u5c55\u5f00\u3002 \u4f5c\u8005\u5728KITTI\u4e0a\u63d0\u4ea4\u4e86\u4e24\u4e2a\u6210\u7ee9(PL++),\u6807\u9898\u4e0b\u9762\u7ed9\u51fa\u7684\u662f\u6625\u53cc\u76ee\u800c\u6ca1\u6709GDC\u7684\u6210\u7ee9\uff0c\u6709GDC\u7684\u6210\u7ee9\u4f1a\u66f4\u9ad8\u4e00\u4e9b\u3002","title":"Pseudo-Lidar++"},{"location":"3dDetection/RecentCollectionForStereo3D/#disp-rcnn","text":"pdf code \u8fd9\u7bc7paper\u7684\u4e3b\u8981\u4e0d\u540c\u70b9\u5728\u4e8e\u4f7f\u7528RoIPooling\u4ece\u539f\u56fe(\u4f5c\u8005\u6307\u51fa\u4e0d\u5e94\u8be5\u4ecefeature\u4e2d\u91c7\u6837\uff0c\u56e0\u4e3aDisparity\u8981\u6c42\u90bb\u8fd1\u50cf\u7d20\u7ed3\u679c\u4e0d\u540c\uff0c\u4f46\u662fInstance Segmentation\u4f1a\u8981\u6c42\u90bb\u8fd1\u50cf\u7d20\u7ed3\u679c\u76f8\u540c)\u4e2d\u91c7\u6837,\u7136\u540e\u4ecePooling\u540e\u7684\u7ed3\u679c\u91cd\u5efaDisparity\u4ee5\u53ca\u5c40\u90e8\u70b9\u4e91(\u8fd9\u4e2a\u6a21\u5757\u5728\u6570\u5b66\u5904\u7406\u4e0a\u8981\u5c0f\u5fc3)\uff0c\u7136\u540e\u4f7f\u7528\u70b9\u4e91\u68c0\u6d4b\u8f93\u51fa\u7ed3\u679c\u3002 \u8fd9\u7bc7paper\u8fd8\u6709\u4f7f\u7528pretrained\u7684\u53cc\u76ee\u91cd\u5efa\u7f51\u7edc\uff0c\u5f97\u5230\u5bc6\u96c6\u7684pseudo Ground Truth Disparity. Loss\u7684\u6784\u6210\u6bd4\u8f83\u590d\u6742\uff0c\u5177\u4f53\u770bpaper","title":"Disp-RCNN"},{"location":"3dDetection/RecentCollectionForStereo3D/#zoomnet","text":"pdf code \u4f7f\u75282D\u68c0\u6d4b\u5148\u5f97\u5230\u4e24\u4e2a\u8f66\u5b50\u548b\u56fe\u7247\u7684\u4f4d\u7f6e\uff0c\u7136\u540e\u5206\u522bresize,\u5e76\u4e14\u8c03\u8282\u540d\u4e49\u76f8\u673a\u53c2\u6570(zooming)\u3002 \u4e2d\u4ecb\u8f85\u52a9\u9884\u6d4b\u7684\u5185\u5bb9\u5305\u62ecdisparity, instance segmentation, part location(\u6bcf\u4e00\u4e2a\u50cf\u7d20\u76f8\u5bf9\u4e8e\u8f66\u5b50\u4e2d\u5fc3x, y, z\u8f74\u7684\u4f4d\u7f6e\uff0c\u8fd9\u4e2a\u4e00\u822c\u4f7f\u7528\u70b9\u4e91\u548c\u7a20\u5bc6\u6df1\u5ea6\u56fe\u8fdb\u884c\u6807\u6ce8)\u3002\u5f97\u5230\u70b9\u4e91\u540e\u5c06feature \u94fe\u63a5\uff0c\u7136\u540e\u7528\u7c7b\u4f3c\u4e8epoint net\u7684\u65b9\u5f0f\u9884\u6d4b\u6700\u7ec8\u7ed3\u679c\u3002","title":"ZoomNet"},{"location":"3dDetection/RecentCollectionForStereo3D/#oc-stereo","text":"pdf \u8fd9\u7bc7paper\u7684\u60f3\u6cd5\u662f\u4f7f\u7528RoIAlign\u5c06\u5de6\u53f3\u76ee\u4e24\u4e2a\u533a\u57df\u7684feature \u63d0\u51fa\u6765\uff0c\u7136\u540e\u4f7f\u7528instance seg\u4e0eCost volumn\u8ba1\u7b97\u5bf9\u5e94pixel\u5904\u7684disparity\u3002 \u4f5c\u8005\u5bf9\u4e8eRoIAlign\u524d\u540e\u7684segmentation pixel\u7684\u4f4d\u7f6e\u5173\u7cfb\u505a\u4e86\u5f88\u7ec6\u81f4\u7684\u89e3\u91ca\u3002 \u5728\u5f97\u5230\u5c40\u90e8RGB\u70b9\u4e91\u4e4b\u540e\u4f5c\u8005\u4f7f\u7528 AVOD \u8fdb\u884c3D\u68c0\u6d4b\u3002","title":"OC Stereo"},{"location":"3dDetection/RecentCollectionForStereo3D/#pseudo-lidar_1","text":"pdf code \u8fd9\u7bc7paper\u7406\u8bba\u4e0a\u6765\u8bf4\u662fpseudo-lidar\u7684\u7b2c\u4e00\u7bc7\u6587\u7ae0 \u601d\u8def\u76ee\u524d\u56de\u770b\u6bd4\u8f83\u5730\u76f4\u63a5\uff0c\u53cc\u76ee\u6df1\u5ea6\u4f30\u8ba1\u65b9\u9762\uff0c\u4f5c\u8005\u4f7f\u7528pretrain PSMNet .\u6ce8\u610f\u8fd9\u4e2aPSMNet\u662f\u5728sceneflow\u6570\u636e\u96c6\uff0c\u4ee5\u53catraining set\u7684\u70b9\u4e91\u6570\u636e\u4f5c\u4e3a\u76d1\u7763\u7684\u3002lidar 3D\u68c0\u6d4b\u65b9\u9762\uff0c\u4f5c\u8005\u4f7f\u7528 AVOD","title":"Pseudo-Lidar"},{"location":"3dDetection/RecentCollectionForStereo3D/#stereo-r-cnn","text":"pdf code \u51e0\u4e2a\u8bad\u7ec3\u7ec6\u8282: positive anchors \u7684threshold\u63d0\u9ad8\u4e86\u3002 \u591a\u9884\u6d4b\u4e00\u4e2aKeypoint\u7684\u4f4d\u7f6e\uff0c\u5982\u4e0b\u56fe SSIM\uff0c\u5229\u7528\u53cc\u76ee\u7684disparity\uff0c\u540e\u5904\u7406\u4f18\u5316\u6df1\u5ea6\u503c\u3002","title":"Stereo R-CNN"},{"location":"3dDetection/RecentCollectionForStereo3D/#rt3d-stereo","text":"pdf \u8bad\u7ec3\u7ec6\u8282: \u4f7f\u7528\u5355\u4e00\u4e00\u4e2aResNet\u89e3\u51b32D \u68c0\u6d4b\u4ee5\u53ca\u8bed\u4e49\u5206\u5272\u7684encoding.\u7528\u7684\u662f \u4e8c\u4f5c\u4f5c\u8005\u7684\u540c\u65f6\u68c0\u6d4b\u4e0e\u8bed\u4e49\u5206\u5272\u7f51\u7edc.pdf Disparity\u4f7f\u7528\u7684\u662fblock matching\u7684\u4f20\u7edf\u65b9\u6cd5\uff0c \u4f5c\u8005\u6839\u636e\u8bed\u4e49\u5206\u5272\u4ee5\u53cadetector\u7ed3\u679c\u5206\u5272\u51fa\u76f8\u5173\u50cf\u7d20\uff0c\u7136\u540e\u805a\u7c7b\uff0c\u7136\u540e\u4ee5\u4f18\u5316\u51f8\u5305\u7684\u65b9\u5f0f\u5f97\u51fa\u7ed3\u679c\u3002\u7531\u4e8e\u4f5c\u8005\u6ca1\u6709\u5f00\u6e90\uff0c\u5f88\u591a\u5185\u5bb9\u6709\u5f85\u5546\u69b7\u3002","title":"RT3D Stereo"},{"location":"3dDetection/RefinedMPL/","text":"RefinedMPL: Refined Monocular PseudoLiDAR for 3D Object Detection in Autonomous Driving \u8fd9\u7bc7\u8bba\u6587\u7684\u76ee\u6807\u5728\u4e8e\u4f18\u5316pseudolidar\u7684\u524d\u7aef\u90e8\u5206(\u70b9\u7684\u751f\u6210\u4e0e\u6570\u91cf\u7cbe\u7b80)\u3002\u4f5c\u8005\u5199\u4e86\u8f83\u957f\u7684introduction\u8bf4\u660e\u4e86\u672c\u6587\u7684\u52a8\u673a\u3002\u5728\u76ee\u524d\u7684pseudo-lidar\u6846\u67b6\u4e0b\uff0c\u6211\u4eec\u9700\u8981\u6839\u636eRGB\u56fe\u7247\u751f\u6210\u4e00\u4e2a\u5bc6\u96c6\u7684\u70b9\u4e91\u6df1\u5ea6\u4f30\u8ba1\uff0c\u4f46\u662f\u7b80\u5355\u8ba1\u7b97\u53ef\u4ee5\u53d1\u73b0\uff0c\u8fd9\u79cd\u65b9\u6cd5\u751f\u6210\u7684\u5bc6\u96c6\u70b9\u4e91\u6bd464\u7ebf\u751a\u81f3128\u7ebflidar\u751f\u6210\u7684\u70b9\u4e91\u66f4\u52a0\u5bc6\u96c6\uff0c\u5c24\u5176\u662f\u5bf9\u8ddd\u79bb\u8f83\u4e3a\u8fd1\u7684\u7269\u4f53\uff0c\u53ef\u77e5pseudo-lidar\u7684\u5bc6\u96c6\u70b9\u4e91\u5176\u5b9e\u5bf9\u68c0\u6d4b\u7cbe\u5ea6\u6ca1\u6709\u4ec0\u4e48\u663e\u8457\u7684\u63d0\u5347\uff0c\u56e0\u800c\u7cbe\u7b80\u70b9\u4e91\u5bf9\u8ba1\u7b97\u901f\u5ea6\u4ee5\u53ca\u6027\u80fd\u90fd\u6709\u5e2e\u52a9. \u5728\u4e0d\u8003\u8651\u76ee\u6807\u68c0\u6d4b\u7684\u60c5\u51b5\u4e0b\uff0c\u672c\u6587\u63d0\u4f9b\u4e86\u4e0b\u91c7\u6837\u70b9\u4e91\u7684\u65b9\u5f0f.(\u672a\u5f00\u6e90) \u6d41\u7a0b\u603b\u89c8 \u672c\u6587\u63d0\u4f9b\u4e86\u4e24\u79cd\u65b9\u5f0f\uff0c\u4e00\u79cd\u662f\u6709\u76d1\u7763\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u70b9\u4e91\u9884\u5904\u7406\uff0c\u4e00\u79cd\u65b9\u5f0f\u662f\u65e0\u76d1\u7763\u5730\u4f7f\u7528\u70b9\u4e91\u9884\u5904\u7406\u3002\u672c\u6587\u8fd9\u91cc\u7528\u7684\u662fSparsification,\u56e0\u4e3a\u4e3b\u8981\u76ee\u6807\u662f\u6ee4\u6389\u4e0d\u9700\u8981\u7684\u8fc7\u591a\u7684\u70b9 \u76d1\u7763\u7684\u65b9\u5f0f\uff1a * \u8bed\u4e49\u5206\u5272\u7f51\u7edc\u540c\u65f6\u8f93\u51fa\u6df1\u5ea6\u4f30\u8ba1\u4ee5\u53ca2D\u76ee\u6807\u68c0\u6d4b\u6846 * \u4ece2D\u76ee\u6807\u68c0\u6d4b\u6846\u4e2d\u9009\u51fa\u6846\u5185\u7684\u70b9 * DSD\u91c7\u6837 \u975e\u76d1\u7763\u65b9\u5f0f\uff1a * \u5355\u76ee\u8f93\u51fa\u6df1\u5ea6\u4f30\u8ba1 * \u4ece\u539f\u56fe\u8f93\u51fa2D\u5173\u952e\u70b9(LoG maximum) * \u6295\u5f71\u5173\u952e\u70b9 * \u80cc\u666f\u70b9\u5206\u79bb * DSD\u91c7\u6837 DSD\u91c7\u6837 \u968f\u673a\u4e0b\u91c7\u6837\u7684\u95ee\u9898\u5728\u4e0e\u8fd9\u6837\u5bb9\u6613\u5927\u5e45\u5ea6\u5730\u51cf\u5c11\u8f83\u8fdc\u5904\u8f83\u5c0f\u7684(\u540c\u65f6\u8f83\u4e3a\u96be\u7684)\u7269\u4f53\u7684\u70b9\uff0c\u8fd9\u6837\u4f1a\u4f7f\u5f97detection\u7ed3\u679c\u53d8\u5dee\uff0c\u4f5c\u8005\u7684\u601d\u8def\u662f\u6839\u636e\u70b9\u5230\u76f8\u673a\u7684\u8ddd\u79bb\u8fdb\u884c\u91c7\u6837(\u4e2a\u4eba\u611f\u89c9\u63cf\u8ff0\u4e0d\u6e05) \u672c\u6587\u540e\u7eed\u76843D\u68c0\u6d4b\u4f7f\u7528\u7684\u662fpointRCNN\uff0c\u6700\u7ec8\u5b9e\u73b0\u4e86\u76ee\u524d(2019-12-24\u67e5\u770b)\u7684SOTA\u7b2c\u4e8c\u540d","title":"RefinedMPL: Refined Monocular PseudoLiDAR for 3D Object Detection in Autonomous Driving"},{"location":"3dDetection/RefinedMPL/#refinedmpl-refined-monocular-pseudolidar-for-3d-object-detection-in-autonomous-driving","text":"\u8fd9\u7bc7\u8bba\u6587\u7684\u76ee\u6807\u5728\u4e8e\u4f18\u5316pseudolidar\u7684\u524d\u7aef\u90e8\u5206(\u70b9\u7684\u751f\u6210\u4e0e\u6570\u91cf\u7cbe\u7b80)\u3002\u4f5c\u8005\u5199\u4e86\u8f83\u957f\u7684introduction\u8bf4\u660e\u4e86\u672c\u6587\u7684\u52a8\u673a\u3002\u5728\u76ee\u524d\u7684pseudo-lidar\u6846\u67b6\u4e0b\uff0c\u6211\u4eec\u9700\u8981\u6839\u636eRGB\u56fe\u7247\u751f\u6210\u4e00\u4e2a\u5bc6\u96c6\u7684\u70b9\u4e91\u6df1\u5ea6\u4f30\u8ba1\uff0c\u4f46\u662f\u7b80\u5355\u8ba1\u7b97\u53ef\u4ee5\u53d1\u73b0\uff0c\u8fd9\u79cd\u65b9\u6cd5\u751f\u6210\u7684\u5bc6\u96c6\u70b9\u4e91\u6bd464\u7ebf\u751a\u81f3128\u7ebflidar\u751f\u6210\u7684\u70b9\u4e91\u66f4\u52a0\u5bc6\u96c6\uff0c\u5c24\u5176\u662f\u5bf9\u8ddd\u79bb\u8f83\u4e3a\u8fd1\u7684\u7269\u4f53\uff0c\u53ef\u77e5pseudo-lidar\u7684\u5bc6\u96c6\u70b9\u4e91\u5176\u5b9e\u5bf9\u68c0\u6d4b\u7cbe\u5ea6\u6ca1\u6709\u4ec0\u4e48\u663e\u8457\u7684\u63d0\u5347\uff0c\u56e0\u800c\u7cbe\u7b80\u70b9\u4e91\u5bf9\u8ba1\u7b97\u901f\u5ea6\u4ee5\u53ca\u6027\u80fd\u90fd\u6709\u5e2e\u52a9. \u5728\u4e0d\u8003\u8651\u76ee\u6807\u68c0\u6d4b\u7684\u60c5\u51b5\u4e0b\uff0c\u672c\u6587\u63d0\u4f9b\u4e86\u4e0b\u91c7\u6837\u70b9\u4e91\u7684\u65b9\u5f0f.(\u672a\u5f00\u6e90)","title":"RefinedMPL: Refined Monocular PseudoLiDAR for 3D Object Detection in Autonomous Driving"},{"location":"3dDetection/RefinedMPL/#_1","text":"\u672c\u6587\u63d0\u4f9b\u4e86\u4e24\u79cd\u65b9\u5f0f\uff0c\u4e00\u79cd\u662f\u6709\u76d1\u7763\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u70b9\u4e91\u9884\u5904\u7406\uff0c\u4e00\u79cd\u65b9\u5f0f\u662f\u65e0\u76d1\u7763\u5730\u4f7f\u7528\u70b9\u4e91\u9884\u5904\u7406\u3002\u672c\u6587\u8fd9\u91cc\u7528\u7684\u662fSparsification,\u56e0\u4e3a\u4e3b\u8981\u76ee\u6807\u662f\u6ee4\u6389\u4e0d\u9700\u8981\u7684\u8fc7\u591a\u7684\u70b9 \u76d1\u7763\u7684\u65b9\u5f0f\uff1a * \u8bed\u4e49\u5206\u5272\u7f51\u7edc\u540c\u65f6\u8f93\u51fa\u6df1\u5ea6\u4f30\u8ba1\u4ee5\u53ca2D\u76ee\u6807\u68c0\u6d4b\u6846 * \u4ece2D\u76ee\u6807\u68c0\u6d4b\u6846\u4e2d\u9009\u51fa\u6846\u5185\u7684\u70b9 * DSD\u91c7\u6837 \u975e\u76d1\u7763\u65b9\u5f0f\uff1a * \u5355\u76ee\u8f93\u51fa\u6df1\u5ea6\u4f30\u8ba1 * \u4ece\u539f\u56fe\u8f93\u51fa2D\u5173\u952e\u70b9(LoG maximum) * \u6295\u5f71\u5173\u952e\u70b9 * \u80cc\u666f\u70b9\u5206\u79bb * DSD\u91c7\u6837","title":"\u6d41\u7a0b\u603b\u89c8"},{"location":"3dDetection/RefinedMPL/#dsd","text":"\u968f\u673a\u4e0b\u91c7\u6837\u7684\u95ee\u9898\u5728\u4e0e\u8fd9\u6837\u5bb9\u6613\u5927\u5e45\u5ea6\u5730\u51cf\u5c11\u8f83\u8fdc\u5904\u8f83\u5c0f\u7684(\u540c\u65f6\u8f83\u4e3a\u96be\u7684)\u7269\u4f53\u7684\u70b9\uff0c\u8fd9\u6837\u4f1a\u4f7f\u5f97detection\u7ed3\u679c\u53d8\u5dee\uff0c\u4f5c\u8005\u7684\u601d\u8def\u662f\u6839\u636e\u70b9\u5230\u76f8\u673a\u7684\u8ddd\u79bb\u8fdb\u884c\u91c7\u6837(\u4e2a\u4eba\u611f\u89c9\u63cf\u8ff0\u4e0d\u6e05) \u672c\u6587\u540e\u7eed\u76843D\u68c0\u6d4b\u4f7f\u7528\u7684\u662fpointRCNN\uff0c\u6700\u7ec8\u5b9e\u73b0\u4e86\u76ee\u524d(2019-12-24\u67e5\u770b)\u7684SOTA\u7b2c\u4e8c\u540d","title":"DSD\u91c7\u6837"},{"location":"3dDetection/SHIFT R-CNN: DEEP MONOCULAR 3D OBJECT DETECTION WITH CLOSED-FORM GEOMETRIC CONSTRAINTS/","text":"SHIFT R-CNN: DEEP MONOCULAR 3D OBJECT DETECTION WITH CLOSED-FORM GEOMETRIC CONSTRAINTS \u8fd9\u7bc7\u8bba\u6587\u7684\u5728\u7406\u8bba\u4e0a\u4e3b\u8981\u662f\u4e09\u5927\u8d21\u732e\uff0c\u7b2c\u4e00\u662f\u4e09\u6b65\u8d70\u7684\u57fa\u4e8eFaster-RCNN\u7684 Shift R-CNN\uff0c\u7b2c\u4e8c\u662fVolume Displacement Loss (VDL)\u7528\u4e8e\u8bad\u7ec3\u7f51\u7edc\u3002 \u5de5\u4f5c\u6d41\u7a0b 2D \u68c0\u6d4b\u4e0e3D\u7ed3\u6784\u53c2\u6570\u4f30\u8ba1 \u4f7f\u7528Faster-RCNN\u7684RPN\u8f93\u51faProposal\u4ee5\u53ca2D\u6846\u9884\u6d4b\uff0c\u540e\u7eed\u5168\u8fde\u63a5\u5c42\u8f93\u51fa\u5206\u7c7b\u3001\u7269\u4f53\u5927\u5c0f\u4ee5\u53ca\u7269\u4f53\u65b9\u5411\u3002 \u7269\u4f53\u65b9\u5411\u56de\u5f52\u540c\u6837\u5f97\u9009\u62e9\u56de\u5f52 sin , cos \u503c\uff0c\u540c\u65f6\u591a\u4e00\u4e2a L_1 cost\u8981\u6c42 sin^2 + cos^2 = 1 \uff0c\u8fd9\u91cc\u53ea\u8981\u6c42\u8f93\u51fa\u89c2\u6d4b\u89d2\\alpht_L \u4e5f\u5c31\u662f \\alpha_G - \\theta_{ray}$ \u7269\u4f53\u5927\u5c0f\u56de\u5f52\u540c\u6837\u9009\u62e9\u56de\u5f52 log \u503c\uff0c \u6700\u7ec8\u52a0\u6743\u8f93\u51fa\u603b\u548c \u95ed\u73af\u7ea6\u675f\u6c42\u51fa\u76f8\u5bf9\u4f4d\u7f6e \u8fd9\u4e2a\u95ee\u9898\u6700\u7ec8\u80fd\u8f6c\u6362\u4e3a\u4e00\u4e2a\u6700\u5c0f\u4e8c\u4e58\u7684\u95ee\u9898 ShiftNet\u8fdb\u4e00\u6b65\u4f18\u5316 \u628a\u4e0a\u4e00\u90e8\u5206\u4ee5\u53ca\u7b2c\u4e00\u90e8\u5206\u7684\u4fe1\u606f\uff0c\u5305\u62ec t, \\bold b_{2D}\uff0c \\bold d, (sin(\\alpha_L), cos(\\alpha_L)), (sin(\\alpha_G), cos(\\alpha_G)) ,\u8f93\u5165\u5230\u4e24\u5c42\u5168\u8fde\u63a5\u5c42\u4e2d\u7136\u540e\u8f93\u51fa\u6700\u7ec8\u76ee\u6807\u3002 Volume Displacement Loss \u76ee\u7684\u662f\u6b63\u786e\u5730\u63d0\u53473D IOU,\u4f46\u662f3D IOU\u76f4\u63a5\u641e\u5e76\u4e0d\u53ef\u5bfc\u3002\u8fd9\u91cc\u7ed9\u51fa\u65b0\u7684\u601d\u8def, \\Delta t \u4e3a\u4e16\u754c\u5750\u6807\u4e2d\u7684 x, y, z \u5dee\u503c \\Delta t_{\\alpha G} = R_y(\\alpha G) \\Delta t L = w \\times h \\times |\\Delta x_{\\alpha G}| + w \\times l \\times |\\Delta y_{\\alpha G}| + h \\times l \\times |\\Delta z_{\\alpha G}|","title":"SHIFT R-CNN: DEEP MONOCULAR 3D OBJECT DETECTION WITH CLOSED-FORM GEOMETRIC CONSTRAINTS"},{"location":"3dDetection/SHIFT R-CNN: DEEP MONOCULAR 3D OBJECT DETECTION WITH CLOSED-FORM GEOMETRIC CONSTRAINTS/#shift-r-cnn-deep-monocular-3d-object-detection-with-closed-form-geometric-constraints","text":"\u8fd9\u7bc7\u8bba\u6587\u7684\u5728\u7406\u8bba\u4e0a\u4e3b\u8981\u662f\u4e09\u5927\u8d21\u732e\uff0c\u7b2c\u4e00\u662f\u4e09\u6b65\u8d70\u7684\u57fa\u4e8eFaster-RCNN\u7684 Shift R-CNN\uff0c\u7b2c\u4e8c\u662fVolume Displacement Loss (VDL)\u7528\u4e8e\u8bad\u7ec3\u7f51\u7edc\u3002","title":"SHIFT R-CNN: DEEP MONOCULAR 3D OBJECT DETECTION WITH CLOSED-FORM GEOMETRIC CONSTRAINTS"},{"location":"3dDetection/SHIFT R-CNN: DEEP MONOCULAR 3D OBJECT DETECTION WITH CLOSED-FORM GEOMETRIC CONSTRAINTS/#_1","text":"","title":"\u5de5\u4f5c\u6d41\u7a0b"},{"location":"3dDetection/SHIFT R-CNN: DEEP MONOCULAR 3D OBJECT DETECTION WITH CLOSED-FORM GEOMETRIC CONSTRAINTS/#2d-3d","text":"\u4f7f\u7528Faster-RCNN\u7684RPN\u8f93\u51faProposal\u4ee5\u53ca2D\u6846\u9884\u6d4b\uff0c\u540e\u7eed\u5168\u8fde\u63a5\u5c42\u8f93\u51fa\u5206\u7c7b\u3001\u7269\u4f53\u5927\u5c0f\u4ee5\u53ca\u7269\u4f53\u65b9\u5411\u3002 \u7269\u4f53\u65b9\u5411\u56de\u5f52\u540c\u6837\u5f97\u9009\u62e9\u56de\u5f52 sin , cos \u503c\uff0c\u540c\u65f6\u591a\u4e00\u4e2a L_1 cost\u8981\u6c42 sin^2 + cos^2 = 1 \uff0c\u8fd9\u91cc\u53ea\u8981\u6c42\u8f93\u51fa\u89c2\u6d4b\u89d2\\alpht_L \u4e5f\u5c31\u662f \\alpha_G - \\theta_{ray}$ \u7269\u4f53\u5927\u5c0f\u56de\u5f52\u540c\u6837\u9009\u62e9\u56de\u5f52 log \u503c\uff0c \u6700\u7ec8\u52a0\u6743\u8f93\u51fa\u603b\u548c","title":"2D \u68c0\u6d4b\u4e0e3D\u7ed3\u6784\u53c2\u6570\u4f30\u8ba1"},{"location":"3dDetection/SHIFT R-CNN: DEEP MONOCULAR 3D OBJECT DETECTION WITH CLOSED-FORM GEOMETRIC CONSTRAINTS/#_2","text":"\u8fd9\u4e2a\u95ee\u9898\u6700\u7ec8\u80fd\u8f6c\u6362\u4e3a\u4e00\u4e2a\u6700\u5c0f\u4e8c\u4e58\u7684\u95ee\u9898","title":"\u95ed\u73af\u7ea6\u675f\u6c42\u51fa\u76f8\u5bf9\u4f4d\u7f6e"},{"location":"3dDetection/SHIFT R-CNN: DEEP MONOCULAR 3D OBJECT DETECTION WITH CLOSED-FORM GEOMETRIC CONSTRAINTS/#shiftnet","text":"\u628a\u4e0a\u4e00\u90e8\u5206\u4ee5\u53ca\u7b2c\u4e00\u90e8\u5206\u7684\u4fe1\u606f\uff0c\u5305\u62ec t, \\bold b_{2D}\uff0c \\bold d, (sin(\\alpha_L), cos(\\alpha_L)), (sin(\\alpha_G), cos(\\alpha_G)) ,\u8f93\u5165\u5230\u4e24\u5c42\u5168\u8fde\u63a5\u5c42\u4e2d\u7136\u540e\u8f93\u51fa\u6700\u7ec8\u76ee\u6807\u3002","title":"ShiftNet\u8fdb\u4e00\u6b65\u4f18\u5316"},{"location":"3dDetection/SHIFT R-CNN: DEEP MONOCULAR 3D OBJECT DETECTION WITH CLOSED-FORM GEOMETRIC CONSTRAINTS/#volume-displacement-loss","text":"\u76ee\u7684\u662f\u6b63\u786e\u5730\u63d0\u53473D IOU,\u4f46\u662f3D IOU\u76f4\u63a5\u641e\u5e76\u4e0d\u53ef\u5bfc\u3002\u8fd9\u91cc\u7ed9\u51fa\u65b0\u7684\u601d\u8def, \\Delta t \u4e3a\u4e16\u754c\u5750\u6807\u4e2d\u7684 x, y, z \u5dee\u503c \\Delta t_{\\alpha G} = R_y(\\alpha G) \\Delta t L = w \\times h \\times |\\Delta x_{\\alpha G}| + w \\times l \\times |\\Delta y_{\\alpha G}| + h \\times l \\times |\\Delta z_{\\alpha G}|","title":"Volume Displacement Loss"},{"location":"3dDetection/SingleStage3DPoseEstimation/","text":"Real-Time Seamless Single Shot 6D Object Pose Prediction \u8fd9\u7bc7\u8bba\u6587\u662f\u4e00\u7bc7\u8f83\u4e3a\u57fa\u7840\u76843D\u7269\u4f53\u68c0\u6d4b\u6587\u7ae0\uff0c\u8fdb\u884c\u7684\u662f\u5728\u57fa\u672c\u5df2\u77e5\u7269\u4f53scale\u7684\u60c5\u51b5\u4e0b,\u4ece\u5355\u4e00RGB\u56fe\u7247\u4e2d\u8fd8\u539f\u7269\u4f53\u7684\u4f4d\u7f6e\u4e0e\u59ff\u6001\u7684\u4efb\u52a1\u3002 \u8fd9\u7bc7\u6587\u7ae0\u6709\u5f00\u6e90\u7684\u4ee3\u7801\uff0c\u540c\u65f6\u5bf9\u4e8e\u672c\u6587\u800c\u8a00\u662f \u8fd9\u7bc7\u6587\u7ae0 \u7684\u76f8\u5173\u524d\u7f6e. \u603b\u4f53\u67b6\u6784 \u8fd9\u7bc7\u6587\u7ae0\u501f\u7528YOLO\u7684\u67b6\u6784,\u8f93\u5165\u4e3a\u4e00\u5f20\u56fe\uff0c\u7528dense anchor box\u9884\u6d4b\u5404\u4e2a\u4f4d\u7f6e\u4e0a\u4e0d\u540c\u7269\u4f53\u7684\u5927\u81f4\u4f4d\u7f6e\uff0c\u540c\u65f6\u8fd9\u4e2aanchor box\u8fd8\u4f1a\u8f93\u51fa\u7269\u4f53\u76849\u4e2a\u63a7\u5236\u70b9\u5728\u56fe\u4e2d\u7684\u76f8\u5f53\u5750\u6807\uff0c\u5305\u542b\u4e00\u4e2a\u4e2d\u5fc3\u70b9\u4ee5\u53ca8\u4e2a\u957f\u65b9\u4f53\u6846\u7684\u89d2\u70b9\u3002\u53e6\u5916\u8f93\u51fa C \u4e2a\u5206\u7c7b\u6307\u6807\u4ee5\u53ca 1 \u4e2aobjectness\u6307\u6807\uff0c\u8fd9\u4e2a\u6307\u6807\u7684\u76ee\u6807\uff0c\u7531\u4e00\u4e2a\u6307\u6570\u51fd\u6570\u51b3\u5b9a \u5df2\u77e59\u4e2a\u70b9\u4e4b\u540e\uff0c\u4f7f\u7528opencv\u7684 solvePnP \u51fd\u6570\u76f4\u63a5\u6c42\u5f97\u7269\u4f53\u7684\u76f8\u5bf9\u4f4d\u79fb\u4e0e\u76f8\u5bf9\u59ff\u6001\u3002","title":"Real-Time Seamless Single Shot 6D Object Pose Prediction"},{"location":"3dDetection/SingleStage3DPoseEstimation/#real-time-seamless-single-shot-6d-object-pose-prediction","text":"\u8fd9\u7bc7\u8bba\u6587\u662f\u4e00\u7bc7\u8f83\u4e3a\u57fa\u7840\u76843D\u7269\u4f53\u68c0\u6d4b\u6587\u7ae0\uff0c\u8fdb\u884c\u7684\u662f\u5728\u57fa\u672c\u5df2\u77e5\u7269\u4f53scale\u7684\u60c5\u51b5\u4e0b,\u4ece\u5355\u4e00RGB\u56fe\u7247\u4e2d\u8fd8\u539f\u7269\u4f53\u7684\u4f4d\u7f6e\u4e0e\u59ff\u6001\u7684\u4efb\u52a1\u3002 \u8fd9\u7bc7\u6587\u7ae0\u6709\u5f00\u6e90\u7684\u4ee3\u7801\uff0c\u540c\u65f6\u5bf9\u4e8e\u672c\u6587\u800c\u8a00\u662f \u8fd9\u7bc7\u6587\u7ae0 \u7684\u76f8\u5173\u524d\u7f6e.","title":"Real-Time Seamless Single Shot 6D Object Pose Prediction"},{"location":"3dDetection/SingleStage3DPoseEstimation/#_1","text":"\u8fd9\u7bc7\u6587\u7ae0\u501f\u7528YOLO\u7684\u67b6\u6784,\u8f93\u5165\u4e3a\u4e00\u5f20\u56fe\uff0c\u7528dense anchor box\u9884\u6d4b\u5404\u4e2a\u4f4d\u7f6e\u4e0a\u4e0d\u540c\u7269\u4f53\u7684\u5927\u81f4\u4f4d\u7f6e\uff0c\u540c\u65f6\u8fd9\u4e2aanchor box\u8fd8\u4f1a\u8f93\u51fa\u7269\u4f53\u76849\u4e2a\u63a7\u5236\u70b9\u5728\u56fe\u4e2d\u7684\u76f8\u5f53\u5750\u6807\uff0c\u5305\u542b\u4e00\u4e2a\u4e2d\u5fc3\u70b9\u4ee5\u53ca8\u4e2a\u957f\u65b9\u4f53\u6846\u7684\u89d2\u70b9\u3002\u53e6\u5916\u8f93\u51fa C \u4e2a\u5206\u7c7b\u6307\u6807\u4ee5\u53ca 1 \u4e2aobjectness\u6307\u6807\uff0c\u8fd9\u4e2a\u6307\u6807\u7684\u76ee\u6807\uff0c\u7531\u4e00\u4e2a\u6307\u6570\u51fd\u6570\u51b3\u5b9a \u5df2\u77e59\u4e2a\u70b9\u4e4b\u540e\uff0c\u4f7f\u7528opencv\u7684 solvePnP \u51fd\u6570\u76f4\u63a5\u6c42\u5f97\u7269\u4f53\u7684\u76f8\u5bf9\u4f4d\u79fb\u4e0e\u76f8\u5bf9\u59ff\u6001\u3002","title":"\u603b\u4f53\u67b6\u6784"},{"location":"3dDetection/Triangulation Learning Network: from Monocular to Stereo 3D Object Detection/","text":"Triangulation Learning Network: from Monocular to Stereo 3D Object Detection \u8fd9\u7bc7\u8bba\u6587\u7684\u4e3b\u8981contribution\u662f\u4e09\u90e8\u5206\uff0c\u7b2c\u4e00\u90e8\u5206\u662f\u4e00\u4e2a\u53ef\u9760\u7684\u5355\u76ee3D detector baseline\uff1b\u7b2c\u4e8c\u90e8\u5206\u662fTriangulation Learning\uff1b\u7b2c\u4e09\u90e8\u5206\u662ffeature reweighting strategy\u3002 Baseline Monocular Network\u5355\u76eebaseline \u6b63\u9762\u89c6\u89d2 Anchor Generation \u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u4e0b\u91c7\u6837\uff0c\u5f97\u5230\u4e00\u4e2a G_x \\times G_y \u7684\u7f51\u683c,\u6bcf\u4e00\u4e2a\u7f51\u683c\u91cc\u9762\u7684\u503c\u4ee3\u8868\u8fd9\u4e2a\u7f51\u683c\u6709\u76ee\u6807\u7684\u6982\u7387\uff0c\u4ece\u8fd9\u4e9bpotential cells\u51fa\u53d1\u5c04\u51fa\u4e00\u4e2a\u5706\u53f0\uff0c\u5728\u53f0\u4f53\u4e2d\u5747\u5300\u53d6\u6837\u5f62\u62103D anchors proposals\u3002 3D \u76d2\u4f53proposal\u4ee5\u53carefinement \u4f7f\u7528 RoIAlign\uff0c\u4e5f\u5c31\u662f\u4f20\u7edf\u7684RCNN\u65b9\u5f0f\u505a Triangulation Learning Network TL-Net:Object level triangulation \u8f93\u5165\u662f\u4e00\u5bf9ROI\uff0c\u4e00\u81f4\u6027\u8bc4\u5206 Pairwise Coherence Score\u662f\u4e00\u4e2a 1 \\times 1 \\times C_{roi} \u7684\u6743\u91cd\u5f20\u91cf\uff0c\u7136\u540e\u5206\u522b\u6539\u53d8\u4e24\u4e2a\u56fe\u4e2d\u5404\u4e2a\u7279\u5f81\u901a\u9053\u7684\u6743\u91cd\uff0c\u7136\u540e\u76f8\u52a0\uff0c\u518d\u5168\u8fde\u63a5\u8f93\u51fa\u3002 \u8fd9\u4e2aCoherence Score\u662f\u4e24\u4e2a\u7279\u5f81feature map\u7684\u4f59\u5f26\u8ddd\u79bb\uff0c\u4f5c\u8005\u7684\u8bba\u70b9\u662f\u5982\u679c3D\u4f4d\u7f6e\u6b63\u786e\uff0c\u90a3\u4e48anchor box\u6295\u5f71\u5230\u5de6\u53f3\u76f8\u673a\u4e2d\u7684\u7279\u5f81\u4f1a\u76f8\u4f3c\uff0c\u4e5f\u90fd\u662f\u7269\u4f53\u7684feature\uff0c \u82e5\u504f\u4e86\u5219\u5dee\u8ddd\u4f1a\u5f88\u5927\uff0c\u968f\u673a\u3001\u5b8c\u5168\u65e0\u5173\u7684\u6761\u4ef6\u4e0breweight \u6743\u91cd\u4f1a\u4e3a0\uff0c\u6700\u7ec8\u8f93\u51fa\u7684confidence\u4e5f\u4f1a\u6709\u6240\u5f71\u54cd\u3002","title":"Triangulation Learning Network: from Monocular to Stereo 3D Object Detection"},{"location":"3dDetection/Triangulation Learning Network: from Monocular to Stereo 3D Object Detection/#triangulation-learning-network-from-monocular-to-stereo-3d-object-detection","text":"\u8fd9\u7bc7\u8bba\u6587\u7684\u4e3b\u8981contribution\u662f\u4e09\u90e8\u5206\uff0c\u7b2c\u4e00\u90e8\u5206\u662f\u4e00\u4e2a\u53ef\u9760\u7684\u5355\u76ee3D detector baseline\uff1b\u7b2c\u4e8c\u90e8\u5206\u662fTriangulation Learning\uff1b\u7b2c\u4e09\u90e8\u5206\u662ffeature reweighting strategy\u3002","title":"Triangulation Learning Network: from Monocular to Stereo 3D Object Detection"},{"location":"3dDetection/Triangulation Learning Network: from Monocular to Stereo 3D Object Detection/#baseline-monocular-networkbaseline","text":"","title":"Baseline Monocular Network\u5355\u76eebaseline"},{"location":"3dDetection/Triangulation Learning Network: from Monocular to Stereo 3D Object Detection/#anchor-generation","text":"\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u4e0b\u91c7\u6837\uff0c\u5f97\u5230\u4e00\u4e2a G_x \\times G_y \u7684\u7f51\u683c,\u6bcf\u4e00\u4e2a\u7f51\u683c\u91cc\u9762\u7684\u503c\u4ee3\u8868\u8fd9\u4e2a\u7f51\u683c\u6709\u76ee\u6807\u7684\u6982\u7387\uff0c\u4ece\u8fd9\u4e9bpotential cells\u51fa\u53d1\u5c04\u51fa\u4e00\u4e2a\u5706\u53f0\uff0c\u5728\u53f0\u4f53\u4e2d\u5747\u5300\u53d6\u6837\u5f62\u62103D anchors proposals\u3002","title":"\u6b63\u9762\u89c6\u89d2 Anchor Generation"},{"location":"3dDetection/Triangulation Learning Network: from Monocular to Stereo 3D Object Detection/#3d-proposalrefinement","text":"\u4f7f\u7528 RoIAlign\uff0c\u4e5f\u5c31\u662f\u4f20\u7edf\u7684RCNN\u65b9\u5f0f\u505a","title":"3D \u76d2\u4f53proposal\u4ee5\u53carefinement"},{"location":"3dDetection/Triangulation Learning Network: from Monocular to Stereo 3D Object Detection/#triangulation-learning-network","text":"","title":"Triangulation Learning Network"},{"location":"3dDetection/Triangulation Learning Network: from Monocular to Stereo 3D Object Detection/#tl-netobject-level-triangulation","text":"\u8f93\u5165\u662f\u4e00\u5bf9ROI\uff0c\u4e00\u81f4\u6027\u8bc4\u5206 Pairwise Coherence Score\u662f\u4e00\u4e2a 1 \\times 1 \\times C_{roi} \u7684\u6743\u91cd\u5f20\u91cf\uff0c\u7136\u540e\u5206\u522b\u6539\u53d8\u4e24\u4e2a\u56fe\u4e2d\u5404\u4e2a\u7279\u5f81\u901a\u9053\u7684\u6743\u91cd\uff0c\u7136\u540e\u76f8\u52a0\uff0c\u518d\u5168\u8fde\u63a5\u8f93\u51fa\u3002 \u8fd9\u4e2aCoherence Score\u662f\u4e24\u4e2a\u7279\u5f81feature map\u7684\u4f59\u5f26\u8ddd\u79bb\uff0c\u4f5c\u8005\u7684\u8bba\u70b9\u662f\u5982\u679c3D\u4f4d\u7f6e\u6b63\u786e\uff0c\u90a3\u4e48anchor box\u6295\u5f71\u5230\u5de6\u53f3\u76f8\u673a\u4e2d\u7684\u7279\u5f81\u4f1a\u76f8\u4f3c\uff0c\u4e5f\u90fd\u662f\u7269\u4f53\u7684feature\uff0c \u82e5\u504f\u4e86\u5219\u5dee\u8ddd\u4f1a\u5f88\u5927\uff0c\u968f\u673a\u3001\u5b8c\u5168\u65e0\u5173\u7684\u6761\u4ef6\u4e0breweight \u6743\u91cd\u4f1a\u4e3a0\uff0c\u6700\u7ec8\u8f93\u51fa\u7684confidence\u4e5f\u4f1a\u6709\u6240\u5f71\u54cd\u3002","title":"TL-Net:Object level triangulation"},{"location":"3dDetection/VoteNetImVote/","text":"VoteNet & ImVoteNet \u53e6\u5916ImVoteNet\u7684pdf: pdf \u8fd9\u4e24\u7bc7paper\u662f\u76f8\u5173\u4e14\u8fde\u7eed\u7684idea\uff0c\u8fd9\u91cc\u8fde\u7eed\u9605\u8bfb VoteNet \u4f5c\u8005\u7684\u7406\u89e3\u662f\uff0c\u7531\u4e8e\u70b9\u4e91\u4e0e\u5b9e\u9645\u70b9\u7684\u4f4d\u7f6e\u6709\u4e00\u5b9a\u7684\u8ddd\u79bb\uff0c\u56e0\u800cinference \u7269\u4f53\u7684\u4e2d\u5fc3\u6709\u96be\u5ea6\uff0c\u8fd9\u91cc\u501f\u52a9hough-voting\u7684\u601d\u8def. \u7b97\u6cd5pipeline: \u4f7f\u7528PointNet++ \u63d0\u53d6\u7279\u5f81\uff0c\u4f7f\u7528\u6700\u8fdc\u70b9\u53d6\u6837\uff0c\u4e0b\u91c7\u6837\u7684\u5230M\u4e2aseed point. \u6bcf\u4e00\u4e2aseedpoint \u7ecf\u8fc7MLP\uff0c\u5f97\u5230object \u4e2d\u5fc3\u4e0eseed point\u7684 dx, dy, dz \u4ee5\u53ca\u7279\u5f81\u6b8b\u5dee df . \u6839\u636e\u6700\u8fdc\u70b9\u91c7\u6837\u4ee5\u53ca\u57fa\u7840\u7684threshold\u8ddd\u79bb\u8fdb\u884c\u805a\u7c7b\u3002 \u6bcf\u4e00\u4e2a\u805a\u7c7b\u91cc\u9762\u7684\u70b9\u7528\u7ebf\u6027\u5c42\u8fdb\u884c\u878d\u5408\uff0c \u5176\u4e2d z_i' \u4e3a\u5f52\u4e00\u5316\u7684\u8ddd\u79bb\u503c\uff0c h_i \u4e3a\u6bcf\u4e00\u4e2a\u70b9\u7684\u7279\u5f81 p(\\mathcal{C})=\\operatorname{MLP}_{2}\\left\\{\\max _{i=1, \\ldots, n}\\left\\{\\operatorname{MLP}_{1}\\left(\\left[z_{i}^{\\prime} ; h_{i}\\right]\\right)\\right\\}\\right\\} ImVoteNet \u8fd9\u7bc7\u8bba\u6587\u5728votenet\u7684\u57fa\u7840\u4e0a\u89e3\u51b3\u4e24\u4e2a\u95ee\u9898\uff0c\u7b2c\u4e00\u4e2a\u662f\u5982\u4f55\u4f7f\u7528image detector\u8f85\u52a9seed points\u8fdb\u884cvoting\uff0c\u7b2c\u4e8c\u4e2a\u662f\u5982\u4f55\u878d\u5408\u4e24\u8005\u7684feature \u5bf9\u6700\u540e\u76843D\u4fe1\u606f\u8fdb\u884c\u56de\u5f52\u3002 \u5728\u7b2c\u4e00\u4e2a\u95ee\u9898\u4e0a\uff0cImVoteNet\u7684\u8bbe\u5b9a\u662f2D detector\u7684\u4e2d\u5fc3\u4e0e\u7269\u4f53\u76843D\u4e2d\u5fc3\u5728\u540c\u4e00\u4e2a\u6295\u5f71\u7ebf\u4e0a\u3002\u5982\u4e0b\u56fe \u5047\u8bbe p \u662f\u7269\u4f53\u4e0a\u7684\u70b9\uff0c\u4e5f\u5c31\u662f\u70b9\u4e91\u7684\u4e00\u4e2a\u70b9\uff0c\u70b9P\u4ea7\u751fvote\u65f6\u9700\u8981\u9884\u6d4b\u4e00\u4e2a \\vec{PC} .\u73b0\u6709\u7684\u6570\u636e\u4e3a\u70b9 P \u7684\u4e09\u7ef4\u5750\u6807\u3001\u5728\u56fe\u7247\u4e0a\u7684\u6295\u5f71 p , \u4ee5\u53ca C \u5728\u56fe\u7247\u4e2d\u7684\u6295\u5f71 c . \\begin{aligned} \\vec{p} \\vec{c} &=\\left(u_{2}-u_{1}, v_{2}-v_{1}\\right)=(\\Delta u, \\Delta v) \\\\ &=\\left(f\\left(\\frac{x_{2}}{z_{2}}-\\frac{x_{1}}{z_{1}}\\right), f\\left(\\frac{y_{2}}{z_{2}}-\\frac{y_{1}}{z_{1}}\\right)\\right) \\end{aligned} \\overrightarrow{P C^{\\prime}}=\\left(\\frac{\\Delta u}{f} z_{1}, \\frac{\\Delta v}{f} z_{1}, 0\\right) 3D voting\u65f6\u53ea\u9700\u8981\u518d\u9884\u6d4b \\Delta z = z' - z \uff0c\u964d\u4f4e\u4e86\u641c\u7d22\u7a7a\u95f4\u3002 \u5173\u4e8e\u7b2c\u4e8c\u4e2a\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u4f7f\u7528\u4e09\u4e2a\u4e0e2D detector\u65e0\u5173\u7684feature Geometric Cues for each seed point: \\left(\\frac{\\Delta u}{f} z_{1}, \\frac{\\Delta v}{f} z_{1}, \\frac{\\overrightarrow{O C^{\\prime}}}{\\|\\overrightarrow{O C^{\\prime}}\\|}\\right) Semantic Cues for each seed point: \u5bf9\u5e942D detector\u8f93\u51fa\u65f6\u7684\u5206\u7c7b\u77e2\u91cf(\u4e0d\u4f7f\u7528RoI Align\u5904\u7406\u540e\u7684\u77e2\u91cf\uff0c\u4e3a\u4e86\u8ba9\u8fd9\u4e2a\u7f51\u7edc\u4e0e detector \u65e0\u5173) Texture Cues for each seed point: \u5c06seed point\u6295\u5f71\u5230\u539f\u6765\u7684RGB\u56fe\u4e0a\uff0c\u5c06\u8fd9\u4e2aRGB vector \u4f5c\u4e3a texture cues\u8d4b\u4e88\u7ed9\u8fd9\u4e2a\u70b9\u3002 Fusion: \u4f5c\u8005\u8ba9\u70b9\u4e91\u3001\u56fe\u7247\u5206\u522b\u5404\u81ea\u8fdb\u884cdetection\uff0ctraining\u65f6\u76f4\u63a5\u878d\u5408\u3002\u4f7f\u7528\u4e86 gradient blending.pdf \u8fd9\u4e2atrick.","title":"VoteNet & ImVoteNet"},{"location":"3dDetection/VoteNetImVote/#votenet-imvotenet","text":"\u53e6\u5916ImVoteNet\u7684pdf: pdf \u8fd9\u4e24\u7bc7paper\u662f\u76f8\u5173\u4e14\u8fde\u7eed\u7684idea\uff0c\u8fd9\u91cc\u8fde\u7eed\u9605\u8bfb","title":"VoteNet &amp; ImVoteNet"},{"location":"3dDetection/VoteNetImVote/#votenet","text":"\u4f5c\u8005\u7684\u7406\u89e3\u662f\uff0c\u7531\u4e8e\u70b9\u4e91\u4e0e\u5b9e\u9645\u70b9\u7684\u4f4d\u7f6e\u6709\u4e00\u5b9a\u7684\u8ddd\u79bb\uff0c\u56e0\u800cinference \u7269\u4f53\u7684\u4e2d\u5fc3\u6709\u96be\u5ea6\uff0c\u8fd9\u91cc\u501f\u52a9hough-voting\u7684\u601d\u8def. \u7b97\u6cd5pipeline: \u4f7f\u7528PointNet++ \u63d0\u53d6\u7279\u5f81\uff0c\u4f7f\u7528\u6700\u8fdc\u70b9\u53d6\u6837\uff0c\u4e0b\u91c7\u6837\u7684\u5230M\u4e2aseed point. \u6bcf\u4e00\u4e2aseedpoint \u7ecf\u8fc7MLP\uff0c\u5f97\u5230object \u4e2d\u5fc3\u4e0eseed point\u7684 dx, dy, dz \u4ee5\u53ca\u7279\u5f81\u6b8b\u5dee df . \u6839\u636e\u6700\u8fdc\u70b9\u91c7\u6837\u4ee5\u53ca\u57fa\u7840\u7684threshold\u8ddd\u79bb\u8fdb\u884c\u805a\u7c7b\u3002 \u6bcf\u4e00\u4e2a\u805a\u7c7b\u91cc\u9762\u7684\u70b9\u7528\u7ebf\u6027\u5c42\u8fdb\u884c\u878d\u5408\uff0c \u5176\u4e2d z_i' \u4e3a\u5f52\u4e00\u5316\u7684\u8ddd\u79bb\u503c\uff0c h_i \u4e3a\u6bcf\u4e00\u4e2a\u70b9\u7684\u7279\u5f81 p(\\mathcal{C})=\\operatorname{MLP}_{2}\\left\\{\\max _{i=1, \\ldots, n}\\left\\{\\operatorname{MLP}_{1}\\left(\\left[z_{i}^{\\prime} ; h_{i}\\right]\\right)\\right\\}\\right\\}","title":"VoteNet"},{"location":"3dDetection/VoteNetImVote/#imvotenet","text":"\u8fd9\u7bc7\u8bba\u6587\u5728votenet\u7684\u57fa\u7840\u4e0a\u89e3\u51b3\u4e24\u4e2a\u95ee\u9898\uff0c\u7b2c\u4e00\u4e2a\u662f\u5982\u4f55\u4f7f\u7528image detector\u8f85\u52a9seed points\u8fdb\u884cvoting\uff0c\u7b2c\u4e8c\u4e2a\u662f\u5982\u4f55\u878d\u5408\u4e24\u8005\u7684feature \u5bf9\u6700\u540e\u76843D\u4fe1\u606f\u8fdb\u884c\u56de\u5f52\u3002 \u5728\u7b2c\u4e00\u4e2a\u95ee\u9898\u4e0a\uff0cImVoteNet\u7684\u8bbe\u5b9a\u662f2D detector\u7684\u4e2d\u5fc3\u4e0e\u7269\u4f53\u76843D\u4e2d\u5fc3\u5728\u540c\u4e00\u4e2a\u6295\u5f71\u7ebf\u4e0a\u3002\u5982\u4e0b\u56fe \u5047\u8bbe p \u662f\u7269\u4f53\u4e0a\u7684\u70b9\uff0c\u4e5f\u5c31\u662f\u70b9\u4e91\u7684\u4e00\u4e2a\u70b9\uff0c\u70b9P\u4ea7\u751fvote\u65f6\u9700\u8981\u9884\u6d4b\u4e00\u4e2a \\vec{PC} .\u73b0\u6709\u7684\u6570\u636e\u4e3a\u70b9 P \u7684\u4e09\u7ef4\u5750\u6807\u3001\u5728\u56fe\u7247\u4e0a\u7684\u6295\u5f71 p , \u4ee5\u53ca C \u5728\u56fe\u7247\u4e2d\u7684\u6295\u5f71 c . \\begin{aligned} \\vec{p} \\vec{c} &=\\left(u_{2}-u_{1}, v_{2}-v_{1}\\right)=(\\Delta u, \\Delta v) \\\\ &=\\left(f\\left(\\frac{x_{2}}{z_{2}}-\\frac{x_{1}}{z_{1}}\\right), f\\left(\\frac{y_{2}}{z_{2}}-\\frac{y_{1}}{z_{1}}\\right)\\right) \\end{aligned} \\overrightarrow{P C^{\\prime}}=\\left(\\frac{\\Delta u}{f} z_{1}, \\frac{\\Delta v}{f} z_{1}, 0\\right) 3D voting\u65f6\u53ea\u9700\u8981\u518d\u9884\u6d4b \\Delta z = z' - z \uff0c\u964d\u4f4e\u4e86\u641c\u7d22\u7a7a\u95f4\u3002 \u5173\u4e8e\u7b2c\u4e8c\u4e2a\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u4f7f\u7528\u4e09\u4e2a\u4e0e2D detector\u65e0\u5173\u7684feature Geometric Cues for each seed point: \\left(\\frac{\\Delta u}{f} z_{1}, \\frac{\\Delta v}{f} z_{1}, \\frac{\\overrightarrow{O C^{\\prime}}}{\\|\\overrightarrow{O C^{\\prime}}\\|}\\right) Semantic Cues for each seed point: \u5bf9\u5e942D detector\u8f93\u51fa\u65f6\u7684\u5206\u7c7b\u77e2\u91cf(\u4e0d\u4f7f\u7528RoI Align\u5904\u7406\u540e\u7684\u77e2\u91cf\uff0c\u4e3a\u4e86\u8ba9\u8fd9\u4e2a\u7f51\u7edc\u4e0e detector \u65e0\u5173) Texture Cues for each seed point: \u5c06seed point\u6295\u5f71\u5230\u539f\u6765\u7684RGB\u56fe\u4e0a\uff0c\u5c06\u8fd9\u4e2aRGB vector \u4f5c\u4e3a texture cues\u8d4b\u4e88\u7ed9\u8fd9\u4e2a\u70b9\u3002 Fusion: \u4f5c\u8005\u8ba9\u70b9\u4e91\u3001\u56fe\u7247\u5206\u522b\u5404\u81ea\u8fdb\u884cdetection\uff0ctraining\u65f6\u76f4\u63a5\u878d\u5408\u3002\u4f7f\u7528\u4e86 gradient blending.pdf \u8fd9\u4e2atrick.","title":"ImVoteNet"},{"location":"3dDetection/pointnet_related/","text":"Collections on PointNet and follow-ups PointNet\u662f\u76ee\u524d\u70b9\u4e91\u5904\u7406\u4e2d\u76f8\u5f53\u91cd\u8981\u7684\u4e00\u4e2a\u90e8\u5206\uff0c\u4e0eVoxel\u603b\u4f53\u5e76\u884c\u3002 Related paper: Frustum Pointnet PointNet pdf code PointNet\u6709\u4e00\u4e2a\u5f88\u597d\u7684CSDN\u4ecb\u7ecd \u535a\u5ba2 . \u6838\u5fc3\u601d\u60f3: \u8fd0\u7b97\u5e94\u5f53\u662f\u8f6e\u6362\u4e0d\u53d8\u7684\uff0c\u9002\u5e94\u65e0\u5e8f\u7684\u70b9\u4e91\u3002 \u7406\u89e3\u70b9\u4e91\u7684\u5173\u952e\u70b9\u5728\u4e8e\u627e\u5230\u5408\u9002\u7684\u6295\u5f71\uff0c\u8fb9\u754c/\u9762\u4e0a\u7684\u5173\u952e\u70b9\u51b3\u5b9a\u4e86\u5bf9\u70b9\u4e91\u7684\u7406\u89e3\u3002 \u7b2c\u4e00\u70b9\u7ed9\u51fa\u7684\u542f\u53d1\u662f\u4ee5\u5168\u8fde\u63a5\u5c42\u3001\u5750\u6807\u8f6c\u6362\u5c42\u4ee5\u53camax-pooling\u4e3a\u4e3b\u8981\u8fd0\u7b97\u65b9\u5f0f\u3002 \u5750\u6807\u8f6c\u6362\u5c42\u4e0e\u5168\u8fde\u63a5\u5c42\u4e0d\u540c\u7684\u5730\u65b9\u5728\u4e8e\u8f6c\u6362\u6743\u91cd\u77e9\u9635\u7684\u884c\u5217\u5f0f\u5e94\u4e0e\u65cb\u8f6c\u77e9\u9635\u6027\u8d28\u7c7b\u4f3c\uff0c\u4f5c\u8005\u7ed9\u51fa\u4e86\u8fd9\u6837Regularization Loss \u4f5c\u4e3a\u7ea6\u675f: L_{r e g}=\\left\\|I-A A^{T}\\right\\|_{F}^{2} \u7b2c\u4e8c\u70b9\u5f15\u5165\u4e86Critical Points\u7684\u6982\u5ff5\uff0c\u7b80\u5355\u800c\u8a00\u5c31\u662f\u6700\u540eMaxpooling\u4e2d\uff0c\u5982\u679c\u70b9 p \u6709\u81f3\u5c11\u4e00\u4e2achannel\u662fMaxpooling\u64cd\u4f5c\u5bf9\u5e94\u7684 argmax ,\u90a3\u4e48\u70b9 p \u5c31\u662f\u4e00\u4e2acritical point.\u663e\u7136\uff0cCritical Point\u7684\u6570\u91cf\u4e0d\u80fd\u8d85\u8fc7\u8fd9\u4e2a\u77e2\u91cf\u7684channel\u6570\uff0c\u56fe\u4e2d\u4e3a1024. \u4f5c\u8005\u901a\u8fc7\u53ef\u89c6\u5316\u8868\u660e\u4e86\u8fd9\u91cc\u7684Critical Point\u5728\u5b9e\u9645\u4e2d\u4e5f\u57fa\u672c\u5bf9\u5e94\u7a00\u758f\u7684\u3001\u4e00\u7ec4\u6700\u6709\u8868\u8fbe\u529b\u7684\u70b9\u3002 \u8bed\u4e49\u5206\u5272\u7f51\u7edc\u4e2d\uff0c\u4f5c\u8005\u5c06\u5168\u5c40\u77e2\u91cfconcat\u5230\u6bcf\u4e2a\u70b9\u81ea\u5df1\u7684feature\u4e2d\uff0c\u7136\u540e\u5168\u8fde\u63a5\u8f93\u51fa\u5206\u7c7b\u3002 PointNet++ pdf code Faster Pytorch \u4ece\u5e94\u7528\u573a\u666f\u53ef\u77e5\uff0cPointNet\u9762\u5bf9\u7684\u662f\u7b80\u5355\u7269\u4f53\u7684mesh/point cloud\u7ec4\u6210\uff0c\u4f46\u662f\u5728\u9762\u5bf9\u5927\u573a\u666f\u65f6\u6709\u4e24\u4e2a\u95ee\u9898\u3002\u7b2c\u4e00\u4e2a\u662f\u65e0\u6cd5\u5904\u7406\u6570\u91cf\u5de8\u5927\u7684\u70b9\u4e91\uff0c\u7b2c\u4e8c\u4e2a\u662f\u7531\u4e8e\u53ca\u5176\u5f3a\u8c03\u65e0\u5e8f\u6027\u4ee5\u53ca\u4f9d\u8d56\u4e8e\u5168\u5c40feature\uff0c\u5e26\u6765\u7684\u6838\u5fc3\u95ee\u9898\u662f\u65e0\u6cd5\u5bf9\u5c40\u90e8\u70b9\u4e91\u7ed3\u6784\u8fdb\u884c\u63a8\u7406\uff0c\u6ca1\u6709\u5229\u7528\u5927\u573a\u666f\u4e2d\u70b9\u4e91\u591a\u5904\u5c0f\u89c4\u6a21\u805a\u7c7b\u7684\u7279\u70b9\u3002 Set Abstraction Layer = sampling + grouping + pointnet; Sampling\u4f7f\u7528\u6700\u8fdc\u70b9\u91c7\u6837(FPS), code .\u5faa\u73af\u91c7\u6837\uff0c\u6bcf\u4e00\u4e2a\u65b0\u91c7\u6837\u7684\u70b9\u8ddd\u79bb\u73b0\u6709\u70b9\u7684\u8ddd\u79bb\u3002 Grouping\u4f7f\u7528Ball query\u5bfb\u627ekeypoint\u9644\u8fd1K\u4e2a\u6700\u8fd1\u7684\u70b9\uff0c\u8f93\u5165\u4e3a N\\times (d+C) \u4e2a\u70b9\uff0c\u4e2d\u5fc3\u70b9 N'\\times d ,\u8f93\u51fa\u4e3a N'\\times K\\times (d+C) , code PointNet Layer,\u5c06K\u4e2a\u6700\u8fd1\u7684\u70b9\u8f93\u5165\u5230pointNet\u4e2d\u3002\u5f97\u5230\u8fd9\u4e2a\u805a\u7c7b\u7684\u65b0features Point Feature Propagation for Set Segmentation \u8fd9\u5bf9\u5e94\u7684\u662fskip connection \u4ee5\u53ca\u4e0a\u91c7\u6837\u7684\u6b65\u9aa4\uff0c\u4f5c\u8005\u91c7\u7528\u7684\u662f\u4e0e\u73b0\u6709\u70b9\u8ddd\u79bb\u6210\u53cd\u6bd4\u76843D interpolation, code . f^{(j)}(x)=\\frac{\\sum_{i=1}^{k} w_{i}(x) f_{i}^{(j)}}{\\sum_{i=1}^{k} w_{i}(x)} \\quad \\text { where } \\quad w_{i}(x)=\\frac{1}{d\\left(x, x_{i}\\right)^{p}}, j=1, \\ldots, C \u5c06\u7f51\u7edc\u524d\u9762\u7684features \u7ecf\u8fc7 1\\times 1 \u5377\u79efconcat\u5230\u63d2\u503c\u7ed3\u679c\u4e2d\u3002 PointRCNN: 3D Object Proposal Generation and Detection from Point Cloud pdf code \u8fd9\u662f\u4e00\u4e2atwo-stage\u7684model, \u4f7f\u7528segmentation pointcloud\u7f51\u7edc\uff0c\u5f97\u5230\u6bcf\u4e00\u4e2a\u70b9\u7684features\uff0c\u751f\u6210\u4e00\u4e2aanchor 3D box\uff0c\u4ee5\u53ca\u524d\u540e\u666f\u5206\u5272\u3002\u4f5c\u8005\u5bf9anchor 3D box\u7528\u7684\u662fbin-based generation,\u4f7f\u5f97\u8fd9\u91cc\u7684\u6bcf\u4e00\u4e2a\u8f93\u51fa\u90fd\u4f1a\u662f\u5206\u7c7b\u8f93\u51fa\u3002","title":"Collections on PointNet and follow-ups"},{"location":"3dDetection/pointnet_related/#collections-on-pointnet-and-follow-ups","text":"PointNet\u662f\u76ee\u524d\u70b9\u4e91\u5904\u7406\u4e2d\u76f8\u5f53\u91cd\u8981\u7684\u4e00\u4e2a\u90e8\u5206\uff0c\u4e0eVoxel\u603b\u4f53\u5e76\u884c\u3002 Related paper: Frustum Pointnet","title":"Collections on PointNet and follow-ups"},{"location":"3dDetection/pointnet_related/#pointnet","text":"pdf code PointNet\u6709\u4e00\u4e2a\u5f88\u597d\u7684CSDN\u4ecb\u7ecd \u535a\u5ba2 . \u6838\u5fc3\u601d\u60f3: \u8fd0\u7b97\u5e94\u5f53\u662f\u8f6e\u6362\u4e0d\u53d8\u7684\uff0c\u9002\u5e94\u65e0\u5e8f\u7684\u70b9\u4e91\u3002 \u7406\u89e3\u70b9\u4e91\u7684\u5173\u952e\u70b9\u5728\u4e8e\u627e\u5230\u5408\u9002\u7684\u6295\u5f71\uff0c\u8fb9\u754c/\u9762\u4e0a\u7684\u5173\u952e\u70b9\u51b3\u5b9a\u4e86\u5bf9\u70b9\u4e91\u7684\u7406\u89e3\u3002 \u7b2c\u4e00\u70b9\u7ed9\u51fa\u7684\u542f\u53d1\u662f\u4ee5\u5168\u8fde\u63a5\u5c42\u3001\u5750\u6807\u8f6c\u6362\u5c42\u4ee5\u53camax-pooling\u4e3a\u4e3b\u8981\u8fd0\u7b97\u65b9\u5f0f\u3002 \u5750\u6807\u8f6c\u6362\u5c42\u4e0e\u5168\u8fde\u63a5\u5c42\u4e0d\u540c\u7684\u5730\u65b9\u5728\u4e8e\u8f6c\u6362\u6743\u91cd\u77e9\u9635\u7684\u884c\u5217\u5f0f\u5e94\u4e0e\u65cb\u8f6c\u77e9\u9635\u6027\u8d28\u7c7b\u4f3c\uff0c\u4f5c\u8005\u7ed9\u51fa\u4e86\u8fd9\u6837Regularization Loss \u4f5c\u4e3a\u7ea6\u675f: L_{r e g}=\\left\\|I-A A^{T}\\right\\|_{F}^{2} \u7b2c\u4e8c\u70b9\u5f15\u5165\u4e86Critical Points\u7684\u6982\u5ff5\uff0c\u7b80\u5355\u800c\u8a00\u5c31\u662f\u6700\u540eMaxpooling\u4e2d\uff0c\u5982\u679c\u70b9 p \u6709\u81f3\u5c11\u4e00\u4e2achannel\u662fMaxpooling\u64cd\u4f5c\u5bf9\u5e94\u7684 argmax ,\u90a3\u4e48\u70b9 p \u5c31\u662f\u4e00\u4e2acritical point.\u663e\u7136\uff0cCritical Point\u7684\u6570\u91cf\u4e0d\u80fd\u8d85\u8fc7\u8fd9\u4e2a\u77e2\u91cf\u7684channel\u6570\uff0c\u56fe\u4e2d\u4e3a1024. \u4f5c\u8005\u901a\u8fc7\u53ef\u89c6\u5316\u8868\u660e\u4e86\u8fd9\u91cc\u7684Critical Point\u5728\u5b9e\u9645\u4e2d\u4e5f\u57fa\u672c\u5bf9\u5e94\u7a00\u758f\u7684\u3001\u4e00\u7ec4\u6700\u6709\u8868\u8fbe\u529b\u7684\u70b9\u3002 \u8bed\u4e49\u5206\u5272\u7f51\u7edc\u4e2d\uff0c\u4f5c\u8005\u5c06\u5168\u5c40\u77e2\u91cfconcat\u5230\u6bcf\u4e2a\u70b9\u81ea\u5df1\u7684feature\u4e2d\uff0c\u7136\u540e\u5168\u8fde\u63a5\u8f93\u51fa\u5206\u7c7b\u3002","title":"PointNet"},{"location":"3dDetection/pointnet_related/#pointnet_1","text":"pdf code Faster Pytorch \u4ece\u5e94\u7528\u573a\u666f\u53ef\u77e5\uff0cPointNet\u9762\u5bf9\u7684\u662f\u7b80\u5355\u7269\u4f53\u7684mesh/point cloud\u7ec4\u6210\uff0c\u4f46\u662f\u5728\u9762\u5bf9\u5927\u573a\u666f\u65f6\u6709\u4e24\u4e2a\u95ee\u9898\u3002\u7b2c\u4e00\u4e2a\u662f\u65e0\u6cd5\u5904\u7406\u6570\u91cf\u5de8\u5927\u7684\u70b9\u4e91\uff0c\u7b2c\u4e8c\u4e2a\u662f\u7531\u4e8e\u53ca\u5176\u5f3a\u8c03\u65e0\u5e8f\u6027\u4ee5\u53ca\u4f9d\u8d56\u4e8e\u5168\u5c40feature\uff0c\u5e26\u6765\u7684\u6838\u5fc3\u95ee\u9898\u662f\u65e0\u6cd5\u5bf9\u5c40\u90e8\u70b9\u4e91\u7ed3\u6784\u8fdb\u884c\u63a8\u7406\uff0c\u6ca1\u6709\u5229\u7528\u5927\u573a\u666f\u4e2d\u70b9\u4e91\u591a\u5904\u5c0f\u89c4\u6a21\u805a\u7c7b\u7684\u7279\u70b9\u3002","title":"PointNet++"},{"location":"3dDetection/pointnet_related/#set-abstraction-layer-sampling-grouping-pointnet","text":"Sampling\u4f7f\u7528\u6700\u8fdc\u70b9\u91c7\u6837(FPS), code .\u5faa\u73af\u91c7\u6837\uff0c\u6bcf\u4e00\u4e2a\u65b0\u91c7\u6837\u7684\u70b9\u8ddd\u79bb\u73b0\u6709\u70b9\u7684\u8ddd\u79bb\u3002 Grouping\u4f7f\u7528Ball query\u5bfb\u627ekeypoint\u9644\u8fd1K\u4e2a\u6700\u8fd1\u7684\u70b9\uff0c\u8f93\u5165\u4e3a N\\times (d+C) \u4e2a\u70b9\uff0c\u4e2d\u5fc3\u70b9 N'\\times d ,\u8f93\u51fa\u4e3a N'\\times K\\times (d+C) , code PointNet Layer,\u5c06K\u4e2a\u6700\u8fd1\u7684\u70b9\u8f93\u5165\u5230pointNet\u4e2d\u3002\u5f97\u5230\u8fd9\u4e2a\u805a\u7c7b\u7684\u65b0features","title":"Set Abstraction Layer = sampling + grouping + pointnet;"},{"location":"3dDetection/pointnet_related/#point-feature-propagation-for-set-segmentation","text":"\u8fd9\u5bf9\u5e94\u7684\u662fskip connection \u4ee5\u53ca\u4e0a\u91c7\u6837\u7684\u6b65\u9aa4\uff0c\u4f5c\u8005\u91c7\u7528\u7684\u662f\u4e0e\u73b0\u6709\u70b9\u8ddd\u79bb\u6210\u53cd\u6bd4\u76843D interpolation, code . f^{(j)}(x)=\\frac{\\sum_{i=1}^{k} w_{i}(x) f_{i}^{(j)}}{\\sum_{i=1}^{k} w_{i}(x)} \\quad \\text { where } \\quad w_{i}(x)=\\frac{1}{d\\left(x, x_{i}\\right)^{p}}, j=1, \\ldots, C \u5c06\u7f51\u7edc\u524d\u9762\u7684features \u7ecf\u8fc7 1\\times 1 \u5377\u79efconcat\u5230\u63d2\u503c\u7ed3\u679c\u4e2d\u3002","title":"Point Feature Propagation for Set Segmentation"},{"location":"3dDetection/pointnet_related/#pointrcnn-3d-object-proposal-generation-and-detection-from-point-cloud","text":"pdf code \u8fd9\u662f\u4e00\u4e2atwo-stage\u7684model, \u4f7f\u7528segmentation pointcloud\u7f51\u7edc\uff0c\u5f97\u5230\u6bcf\u4e00\u4e2a\u70b9\u7684features\uff0c\u751f\u6210\u4e00\u4e2aanchor 3D box\uff0c\u4ee5\u53ca\u524d\u540e\u666f\u5206\u5272\u3002\u4f5c\u8005\u5bf9anchor 3D box\u7528\u7684\u662fbin-based generation,\u4f7f\u5f97\u8fd9\u91cc\u7684\u6bcf\u4e00\u4e2a\u8f93\u51fa\u90fd\u4f1a\u662f\u5206\u7c7b\u8f93\u51fa\u3002","title":"PointRCNN: 3D Object Proposal Generation and Detection from Point Cloud"},{"location":"3dDetection/pvnet/","text":"PVNet: Pixel-wise Voting Network for 6DoF Pose Estimation \u8fd9\u7bc7\u6587\u7ae0\u89e3\u51b3\u7684\u4e5f\u662f\u5728\u57fa\u672c\u5df2\u77e5\u7269\u4f53scale\u751a\u81f3\u66f4\u591a\u4fe1\u606f\u7684\u60c5\u51b5\u4e0b,\u4ece\u5355\u4e00RGB\u56fe\u7247\u4e2d\u8fd8\u539f\u7269\u4f53\u7684\u4f4d\u7f6e\u4e0e\u59ff\u6001\u7684\u4efb\u52a1\u3002 Motivation \u5982 \u524d\u6587 \u7684\u505a\u6cd5\uff0c\u5728\u505akeypoint\u56de\u5f52\u65f6\u4f5c\u8005\u53d1\u73b0\u4e86\u4e24\u4e2a\u95ee\u9898. \u7b2c\u4e00\uff0c\u906e\u6321\u751a\u81f3\u7269\u4f53\u8d85\u51fa\u56fe\u7247\u8303\u56f4\u7684\u60c5\u51b5\u3002\u76f4\u63a5\u56de\u5f52\u7cbe\u5ea6\u6709\u9650\u800c\u4f7f\u7528heatmap( \u6bd4\u5982PAF )\u4f1a\u9762\u4e34\u7684\u95ee\u9898\u5219\u662f\u5b8c\u5168\u65e0\u5904\u7406\u7269\u4f53\u8d85\u51fa\u56fe\u7247\u8303\u56f4\u7684\u60c5\u51b5\u3002 \u7b2c\u4e8c, \u76f4\u63a5\u4f7f\u7528PnP\u6c42\u89e3\u59ff\u6001\u7684\u95ee\u9898\u5728\u4e8e\u6ca1\u6709\u8003\u8651\u4e0d\u540ckeypoint\u6709\u4e0d\u540c\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5982\u4f55\u6c42\u5f97\u8fd9\u4e2a\u4e0d\u786e\u5b9a\u6027(\u672c\u6587\u63d0\u4f9b\u4e86\u66f4\u6709\u8da3\u7684\u601d\u8def)\u4e5f\u662f\u4e00\u5927\u95ee\u9898\u3002 \u7b2c\u4e09\uff0c \u524d\u6587 \u8bbe\u5b9a\u5176PnP\u95ee\u9898\u7684\u63a7\u5236\u70b9\u4e3a\u957f\u65b9\u4f53\u76848\u4e2a\u89d2\u70b9\u4ee5\u53ca\u4e2d\u5fc3\u70b9\uff0c\u7136\u800c\u4f5c\u8005\u53d1\u73b0\u7531\u4e8e\u89d2\u70b9\u5bb9\u6613\u504f\u79bb\u7269\u4f53\u8868\u9762\uff0c\u56e0\u800c\u7f51\u7edc\u6839\u636e\u56fe\u7247\u50cf\u7d20\u7279\u5f81\u8fdb\u884c\u7684\u56de\u5f52\u7ed3\u679c\u6548\u679c\u4e00\u822c\uff0c\u4f5c\u8005\u6307\u51fa\u5e94\u5f53\u5c3d\u53ef\u80fd\u8ba9\u63a7\u5236\u70b9\u5728\u7269\u4f53\u8868\u9762 \u7ed3\u6784 \u603b\u4f53pipeline \u5982\u56fe: \u8f93\u5165\u56fe\u7247\uff0c\u795e\u7ecf\u7f51\u7edc\u8f93\u51fa\u8bed\u4e49\u5206\u5272\u7ed3\u679c\uff0c\u4ee5\u53cakeypoints\u77e2\u91cf\u573a\u3002\u7136\u540e\u4f7f\u7528voting\u786e\u5b9a\u5404\u4e2a\u7269\u4f53\u7684keypoints\u7684\u671f\u671b\u503c\u4e0e\u65b9\u5dee\uff0c\u6700\u540e\u4f7f\u7528PnP\u6c42\u89e3\u7269\u4f53\u7684\u4f4d\u59ff Keypoints as Intersections \u7f51\u7edc\u5728keypoints\u77e2\u91cf\u573a\u8fd9\u91cc\u9700\u8981\u8f93\u51fa\u7684\u662f\u8fd9\u4e2a\u70b9\u5230\u5bf9\u5e94\u7269\u4f53\u5404\u4e2akeypoints\u7684\u5355\u4f4d\u65b9\u5411\u77e2\u91cf\u3002\u5219\u5bf9\u5e94keypoints\u7531\u672cobject\u6240\u6709\u50cf\u7d20\u7684\u65b9\u5411\u77e2\u91cf\u51b3\u5b9a\u3002\u672c\u6587\u4f7f\u7528\u57fa\u4e8eransac\u7684voting\u65b9\u5f0f\u51b3\u5b9akeypoints\u7684\u6700\u7ec8\u6982\u7387\u5206\u5e03\u3002 \u7b97\u6cd5\uff1a 1. \u4f7f\u7528\u8bed\u4e49\u5206\u5272label\u8fc7\u6ee4\u76ee\u6807\u50cf\u7d20 2. \u968f\u673a\u9009\u62e9\u4e24\u4e2a\u77e2\u91cf\uff0c\u6c42\u51fa\u5b83\u4eec\u7684\u89d2\u70b9\uff0c\u91cd\u590d N \u6b21\uff0c\u5f97\u5230 N \u4e2ahypothesis h_i 3. \u6240\u6709\u50cf\u7d20\u5bf9\u8fd9 N \u4e2aprior\u8fdb\u884c\u6295\u7968,\u6bcf\u4e2ahypothesis\u7684\u6743\u91cd\u4e3a w_{k, i}=\\sum_{\\mathbf{p} \\in O} \\mathbb{I}\\left(\\frac{\\left(\\mathbf{h}_{k, i}-\\mathbf{p}\\right)^{T}}{\\left\\|\\mathbf{h}_{k, i}-\\mathbf{p}\\right\\|_{2}} \\mathbf{v}_{k}(\\mathbf{p}) \\geq \\theta\\right) \u5176\u4e2d \\theta \u4e3a\u70b9\u4e58\u7ed3\u679c\u7684threshold\uff0c\u8fd9\u91cc\u8bbe\u5b9a\u4e3a0.99 4. \u6c42\u5f97\u8fd9\u4e2akeypoint\u7684\u5747\u503c\u4e0e\u65b9\u5dee \\begin{aligned} &\\boldsymbol{\\mu}_{k}=\\frac{\\sum_{i=1}^{N} w_{k, i} \\mathbf{h}_{k, i}}{\\sum_{i=1}^{N} w_{k, i}}\\\\ &\\boldsymbol{\\Sigma}_{k}=\\frac{\\sum_{i=1}^{N} w_{k, i}\\left(\\mathbf{h}_{k, i}-\\boldsymbol{\\mu}_{k}\\right)\\left(\\mathbf{h}_{k, i}-\\boldsymbol{\\mu}_{k}\\right)^{T}}{\\sum_{i=1}^{N} w_{k, i}} \\end{aligned} Groud Truth Keypoints Selection \u4f5c\u8005\u8fd9\u91cc\u9009\u62e9\u4e86\u66f4\u5168\u9762\u7684\u5efa\u6a21\u6548\u679c\uff0c\u662f\u4e00\u4e2a\u57fa\u4e8eFPS(farthest point sampling)\u7684\u7b97\u6cd5,\u4f7f\u5f97\u70b9\u5c3d\u53ef\u80fd\u5728\u7269\u4f53\u8868\u9762\uff0c\u540c\u65f6\u9694\u5f97\u8db3\u591f\u8fdc\uff0c\u4f46\u662f\u9700\u8981\u7269\u4f53\u7684\u5b8c\u6574\u5efa\u6a21\uff0c\u8fd9\u91cc\u6682\u4e14\u7565\u8fc7\u3002 Uncertainty-driven PnP \u7531\u4e8e\u524d\u9762\u5f97\u5230\u7684Keypoints\u5e26\u6709\u4e0d\u786e\u5b9a\u6027\u7684\u4f30\u8ba1\uff0c\u8fd9\u91cc\u5728\u8ba1\u7b97\u7684\u65f6\u5019\u5c31\u53ef\u4ee5\u5e26\u4e0a\u4e0d\u786e\u5b9a\u6027\u8fdb\u884cPnP\u4f18\u5316\uff0c\u4e5f\u5c31\u662f\u6c42\u89e3\u4e00\u4e2a\u975e\u7ebf\u6027\u4f18\u5316: \\begin{aligned} \\underset{R, \\mathbf{t}}{\\operatorname{minimize}} & \\sum_{k=1}^{K}\\left(\\tilde{\\mathbf{x}}_{k}-\\boldsymbol{\\mu}_{k}\\right)^{T} \\mathbf{\\Sigma}_{k}^{-1}\\left(\\tilde{\\mathbf{x}}_{k}-\\boldsymbol{\\mu}_{k}\\right) \\\\ & \\tilde{\\mathbf{x}}_{k}=\\pi\\left(R \\mathbf{X}_{k}+\\mathbf{t}\\right) \\end{aligned} \u5728\u672c\u6587\u7684\u5f00\u6e90\u5e93\u4e2d\uff0c\u4f5c\u8005\u4f7f\u7528CUDA\u52a0\u901f\u4e86 Ransac voting,\u7528opencv\u7684 solvePnP \u5f97\u5230\u4f4d\u59ff\u7684\u521d\u59cb\u89e3\uff0c\u7136\u540e\u4f7f\u7528Ceres\u5e93\u8003\u8651\u4e0d\u786e\u5b9a\u6027\u8fed\u4ee3\u5f97\u5230\u6700\u540e\u7ed3\u679c\u3002","title":"PVNet: Pixel-wise Voting Network for 6DoF Pose Estimation"},{"location":"3dDetection/pvnet/#pvnet-pixel-wise-voting-network-for-6dof-pose-estimation","text":"\u8fd9\u7bc7\u6587\u7ae0\u89e3\u51b3\u7684\u4e5f\u662f\u5728\u57fa\u672c\u5df2\u77e5\u7269\u4f53scale\u751a\u81f3\u66f4\u591a\u4fe1\u606f\u7684\u60c5\u51b5\u4e0b,\u4ece\u5355\u4e00RGB\u56fe\u7247\u4e2d\u8fd8\u539f\u7269\u4f53\u7684\u4f4d\u7f6e\u4e0e\u59ff\u6001\u7684\u4efb\u52a1\u3002","title":"PVNet: Pixel-wise Voting Network for 6DoF Pose Estimation"},{"location":"3dDetection/pvnet/#motivation","text":"\u5982 \u524d\u6587 \u7684\u505a\u6cd5\uff0c\u5728\u505akeypoint\u56de\u5f52\u65f6\u4f5c\u8005\u53d1\u73b0\u4e86\u4e24\u4e2a\u95ee\u9898. \u7b2c\u4e00\uff0c\u906e\u6321\u751a\u81f3\u7269\u4f53\u8d85\u51fa\u56fe\u7247\u8303\u56f4\u7684\u60c5\u51b5\u3002\u76f4\u63a5\u56de\u5f52\u7cbe\u5ea6\u6709\u9650\u800c\u4f7f\u7528heatmap( \u6bd4\u5982PAF )\u4f1a\u9762\u4e34\u7684\u95ee\u9898\u5219\u662f\u5b8c\u5168\u65e0\u5904\u7406\u7269\u4f53\u8d85\u51fa\u56fe\u7247\u8303\u56f4\u7684\u60c5\u51b5\u3002 \u7b2c\u4e8c, \u76f4\u63a5\u4f7f\u7528PnP\u6c42\u89e3\u59ff\u6001\u7684\u95ee\u9898\u5728\u4e8e\u6ca1\u6709\u8003\u8651\u4e0d\u540ckeypoint\u6709\u4e0d\u540c\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5982\u4f55\u6c42\u5f97\u8fd9\u4e2a\u4e0d\u786e\u5b9a\u6027(\u672c\u6587\u63d0\u4f9b\u4e86\u66f4\u6709\u8da3\u7684\u601d\u8def)\u4e5f\u662f\u4e00\u5927\u95ee\u9898\u3002 \u7b2c\u4e09\uff0c \u524d\u6587 \u8bbe\u5b9a\u5176PnP\u95ee\u9898\u7684\u63a7\u5236\u70b9\u4e3a\u957f\u65b9\u4f53\u76848\u4e2a\u89d2\u70b9\u4ee5\u53ca\u4e2d\u5fc3\u70b9\uff0c\u7136\u800c\u4f5c\u8005\u53d1\u73b0\u7531\u4e8e\u89d2\u70b9\u5bb9\u6613\u504f\u79bb\u7269\u4f53\u8868\u9762\uff0c\u56e0\u800c\u7f51\u7edc\u6839\u636e\u56fe\u7247\u50cf\u7d20\u7279\u5f81\u8fdb\u884c\u7684\u56de\u5f52\u7ed3\u679c\u6548\u679c\u4e00\u822c\uff0c\u4f5c\u8005\u6307\u51fa\u5e94\u5f53\u5c3d\u53ef\u80fd\u8ba9\u63a7\u5236\u70b9\u5728\u7269\u4f53\u8868\u9762","title":"Motivation"},{"location":"3dDetection/pvnet/#_1","text":"\u603b\u4f53pipeline \u5982\u56fe: \u8f93\u5165\u56fe\u7247\uff0c\u795e\u7ecf\u7f51\u7edc\u8f93\u51fa\u8bed\u4e49\u5206\u5272\u7ed3\u679c\uff0c\u4ee5\u53cakeypoints\u77e2\u91cf\u573a\u3002\u7136\u540e\u4f7f\u7528voting\u786e\u5b9a\u5404\u4e2a\u7269\u4f53\u7684keypoints\u7684\u671f\u671b\u503c\u4e0e\u65b9\u5dee\uff0c\u6700\u540e\u4f7f\u7528PnP\u6c42\u89e3\u7269\u4f53\u7684\u4f4d\u59ff","title":"\u7ed3\u6784"},{"location":"3dDetection/pvnet/#keypoints-as-intersections","text":"\u7f51\u7edc\u5728keypoints\u77e2\u91cf\u573a\u8fd9\u91cc\u9700\u8981\u8f93\u51fa\u7684\u662f\u8fd9\u4e2a\u70b9\u5230\u5bf9\u5e94\u7269\u4f53\u5404\u4e2akeypoints\u7684\u5355\u4f4d\u65b9\u5411\u77e2\u91cf\u3002\u5219\u5bf9\u5e94keypoints\u7531\u672cobject\u6240\u6709\u50cf\u7d20\u7684\u65b9\u5411\u77e2\u91cf\u51b3\u5b9a\u3002\u672c\u6587\u4f7f\u7528\u57fa\u4e8eransac\u7684voting\u65b9\u5f0f\u51b3\u5b9akeypoints\u7684\u6700\u7ec8\u6982\u7387\u5206\u5e03\u3002 \u7b97\u6cd5\uff1a 1. \u4f7f\u7528\u8bed\u4e49\u5206\u5272label\u8fc7\u6ee4\u76ee\u6807\u50cf\u7d20 2. \u968f\u673a\u9009\u62e9\u4e24\u4e2a\u77e2\u91cf\uff0c\u6c42\u51fa\u5b83\u4eec\u7684\u89d2\u70b9\uff0c\u91cd\u590d N \u6b21\uff0c\u5f97\u5230 N \u4e2ahypothesis h_i 3. \u6240\u6709\u50cf\u7d20\u5bf9\u8fd9 N \u4e2aprior\u8fdb\u884c\u6295\u7968,\u6bcf\u4e2ahypothesis\u7684\u6743\u91cd\u4e3a w_{k, i}=\\sum_{\\mathbf{p} \\in O} \\mathbb{I}\\left(\\frac{\\left(\\mathbf{h}_{k, i}-\\mathbf{p}\\right)^{T}}{\\left\\|\\mathbf{h}_{k, i}-\\mathbf{p}\\right\\|_{2}} \\mathbf{v}_{k}(\\mathbf{p}) \\geq \\theta\\right) \u5176\u4e2d \\theta \u4e3a\u70b9\u4e58\u7ed3\u679c\u7684threshold\uff0c\u8fd9\u91cc\u8bbe\u5b9a\u4e3a0.99 4. \u6c42\u5f97\u8fd9\u4e2akeypoint\u7684\u5747\u503c\u4e0e\u65b9\u5dee \\begin{aligned} &\\boldsymbol{\\mu}_{k}=\\frac{\\sum_{i=1}^{N} w_{k, i} \\mathbf{h}_{k, i}}{\\sum_{i=1}^{N} w_{k, i}}\\\\ &\\boldsymbol{\\Sigma}_{k}=\\frac{\\sum_{i=1}^{N} w_{k, i}\\left(\\mathbf{h}_{k, i}-\\boldsymbol{\\mu}_{k}\\right)\\left(\\mathbf{h}_{k, i}-\\boldsymbol{\\mu}_{k}\\right)^{T}}{\\sum_{i=1}^{N} w_{k, i}} \\end{aligned}","title":"Keypoints as Intersections"},{"location":"3dDetection/pvnet/#groud-truth-keypoints-selection","text":"\u4f5c\u8005\u8fd9\u91cc\u9009\u62e9\u4e86\u66f4\u5168\u9762\u7684\u5efa\u6a21\u6548\u679c\uff0c\u662f\u4e00\u4e2a\u57fa\u4e8eFPS(farthest point sampling)\u7684\u7b97\u6cd5,\u4f7f\u5f97\u70b9\u5c3d\u53ef\u80fd\u5728\u7269\u4f53\u8868\u9762\uff0c\u540c\u65f6\u9694\u5f97\u8db3\u591f\u8fdc\uff0c\u4f46\u662f\u9700\u8981\u7269\u4f53\u7684\u5b8c\u6574\u5efa\u6a21\uff0c\u8fd9\u91cc\u6682\u4e14\u7565\u8fc7\u3002","title":"Groud Truth Keypoints Selection"},{"location":"3dDetection/pvnet/#uncertainty-driven-pnp","text":"\u7531\u4e8e\u524d\u9762\u5f97\u5230\u7684Keypoints\u5e26\u6709\u4e0d\u786e\u5b9a\u6027\u7684\u4f30\u8ba1\uff0c\u8fd9\u91cc\u5728\u8ba1\u7b97\u7684\u65f6\u5019\u5c31\u53ef\u4ee5\u5e26\u4e0a\u4e0d\u786e\u5b9a\u6027\u8fdb\u884cPnP\u4f18\u5316\uff0c\u4e5f\u5c31\u662f\u6c42\u89e3\u4e00\u4e2a\u975e\u7ebf\u6027\u4f18\u5316: \\begin{aligned} \\underset{R, \\mathbf{t}}{\\operatorname{minimize}} & \\sum_{k=1}^{K}\\left(\\tilde{\\mathbf{x}}_{k}-\\boldsymbol{\\mu}_{k}\\right)^{T} \\mathbf{\\Sigma}_{k}^{-1}\\left(\\tilde{\\mathbf{x}}_{k}-\\boldsymbol{\\mu}_{k}\\right) \\\\ & \\tilde{\\mathbf{x}}_{k}=\\pi\\left(R \\mathbf{X}_{k}+\\mathbf{t}\\right) \\end{aligned} \u5728\u672c\u6587\u7684\u5f00\u6e90\u5e93\u4e2d\uff0c\u4f5c\u8005\u4f7f\u7528CUDA\u52a0\u901f\u4e86 Ransac voting,\u7528opencv\u7684 solvePnP \u5f97\u5230\u4f4d\u59ff\u7684\u521d\u59cb\u89e3\uff0c\u7136\u540e\u4f7f\u7528Ceres\u5e93\u8003\u8651\u4e0d\u786e\u5b9a\u6027\u8fed\u4ee3\u5f97\u5230\u6700\u540e\u7ed3\u679c\u3002","title":"Uncertainty-driven PnP"},{"location":"3dDetection/siaNMS/","text":"siaNMS: Non-Maximum Suppression with Siamese Networks for Multi-Camera 3D Object Detection \u8fd9\u7bc7paper\u5c1d\u8bd5\u89e3\u51b3\u7684\u95ee\u9898\u662f\u76f8\u673a\u4e0e\u70b9\u4e91\u878d\u5408\u573a\u666f\u4e2d\u7684\u4e00\u4e2a\u95ee\u9898\uff0c\u5c31\u662f\u8bf4\u4e00\u4e2a\u7269\u4f53\u540c\u65f6\u88ab\u4e24\u4e2a\u76f8\u673a\u62cd\u6444\u65f6\uff0c\u5982\u4f55\u5145\u5206\u5229\u7528\u4e24\u4e2a\u76f8\u673a\u7684\u4fe1\u606f\u8fdb\u884c\u878d\u5408\u3002 \u603b\u4f53\u7ed3\u6784 \u8fd9\u7bc7\u6587\u7ae0\u603b\u4f53\u67b6\u6784\u8ddf\u968f Frustum Network \u7684\u8bbe\u8ba1\u3002\u4f7f\u75282D \u7269\u4f53\u68c0\u6d4b\u7b97\u6cd5\u5f97\u5230\u7269\u4f53\u76842\u7ef4\u6846\uff0c\u5728\u4e8c\u7ef4\u6846\u5bf9\u5e94\u7684\u65b9\u5f62\u67f1\u53f0\u4e2d\u627e\u51fa\u70b9\u4e91\u5b50\u96c6\uff0c\u4f7f\u7528Point Net\u4f5c\u6700\u540e\u76843D\u524d\u540e\u666f\u5206\u5272\u5df2\u7ecf3D\u53c2\u6570\u56de\u5f52\u3002 siaNMS\u7684\u7406\u89e3\u4e0e\u8bad\u7ec3\u65b9\u6cd5 \u4f5c\u8005\u91c7\u53d6\u4e00\u4e2a\u6bd4\u8f83\u76f4\u89c2\u7684\u8bbe\u8ba1\u8003\u8651\uff0c\u5bf9\u4e8eRoIpooling\u5f97\u5230\u7684\u6bcf\u4e00\u4e2a\u8f66\u5b50\u7684Feature Map\uff0c\u5982\u679c\u5b83\u4eec\u5c5e\u4e8e\u540c\u4e00\u8f86\u8f66\uff0c\u90a3\u4e48\u8fd9\u4e24\u4e2afeature\u5c31\u4f1a\u6bd4\u8f83\u63a5\u8fd1\u3002 Inference\u8fc7\u7a0b \u5bf9\u4e8e\u4e24\u4e2a\u76f8\u673a\u91cc\u9762\u53d1\u73b0\u7684object\uff0c\u7ecf\u8fc7siaNMS\u5f97\u5230\u5b83\u4eec\u7684feature\uff0c\u8ba1\u7b97\u5b83\u4eec\u4e4b\u95f4\u7684\u8ddd\u79bb\u3002\u4f7f\u7528 \u5308\u7259\u5229\u7b97\u6cd5 \u5f97\u5230\u6700\u4f73\u4e24\u4e24\u5339\u914d\u7ed3\u679c\uff0c\u5982\u679c\u4e24\u4e2a\u5339\u914d\u6846\u5e76\u96c6(union)\u5185\u6709\u70b9\u4e91\uff0c\u5219\u8fd9\u4e9b\u70b9\u4e91\u90fd\u4f1a\u4f5c\u4e3a\u8fd9\u4e2a\u7269\u4f53Frustum\u5185\u7684\u70b9\u3002 \u7b80\u5355\u7684\u8868\u8ff0\u6765\u8bf4\u5c31\u662f\u88ab\u5339\u914d\u8ba4\u4e3a\u662f\u540c\u4e00\u4e2a\u7269\u4f53\u7684\u76f8\u673a\u6846\u5185\u7684\u70b9\uff0c\u5408\u5e76\u540e\u7684\u76f8\u673a\u4e3b\u8f74\u8bbe\u8ba1\u4e3a Training \u65b9\u6cd5 \u8fd9\u91cc\u4f7f\u7528 nuscene \u6570\u636e\u96c6\uff0c nuscene \u7684\u4e00\u4e2a\u7279\u5f81\u662f\u6807\u8bb0\u6bcf\u4e00\u4e2a\u573a\u666f\u91cc\u9762\u6bcf\u4e00\u8f86\u8f66\u7684instance ID\u3002\u4f5c\u8005\u5148\u4f7f\u75282D detector\u5f97\u5230\u6bcf\u4e00\u4e2a\u573a\u666f\u91cc\u9762\u6bcf\u4e00\u8f86\u8f66\u5728\u6bcf\u4e00\u4e2a\u6444\u50cf\u5934\u4e2dRoIAlign\u540e\u7684\u7279\u5f81\u56fe\u3002 \u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6bcf\u4e00\u4e2a\u6837\u672c\u7531\u4e00\u8f86\u540c\u65f6\u5728\u4e24\u4e2a\u6444\u50cf\u5934\u4e2d\u51fa\u73b0\u7684\u8f66\u7684\u7279\u5f81\u56fe\uff0c\u4e00\u4e2a\u4e3a\u53c2\u8003\u6837\u672c x^r , \u4e00\u4e2a\u4e3a\u6b63\u6837\u672c x^p \uff0c\u540c\u573a\u666f\u53e6\u4e00\u8f86\u968f\u673a\u8f66\u8f86\u4f5c\u4e3a\u8d1f\u6837\u672c x^n \u3002\u8bad\u7ec3\u4e00\u4e2asiaNMS\u7f51\u7edc\uff0c\u8f93\u5165\u662f2D aligned\u540e\u7684\u7279\u5f81\u56fe\uff0c\u8f93\u51fa\u662f\u4e00\u4e2a d \u7ef4\u7684\u77e2\u91cf\u3002 \u6211\u4eec\u5e0c\u671b\u6b63\u6837\u672c\u4e0e\u53c2\u8003\u6837\u672c\u7684\u77e2\u91cf\u63a5\u8fd1\u800c\u8d1f\u6837\u672c\u4e0e\u53c2\u8003\u6837\u672c\u7684\u77e2\u91cf\u8ddd\u79bb\u8fdc\u3002 \\begin{array}{l} \\left\\|f\\left(x_{i}^{r}\\right)-f\\left(x_{i}^{p}\\right)\\right\\|_{2}<\\alpha \\\\ \\left\\|f\\left(x_{i}^{r}\\right)-f\\left(x_{i}^{n}\\right)\\right\\|_{2}>\\beta \\end{array} \u56e0\u800c\u635f\u5931\u51fd\u6570\u4e3a\uff1a \\begin{aligned} \\mathcal{L}=& \\frac{1}{2} \\sum_{i}^{N}\\left[\\max \\left(\\left\\|f\\left(x_{i}^{r}\\right)-f\\left(x_{i}^{p}\\right)\\right\\|_{2}-\\alpha, 0\\right)^{2}+\\right.\\\\ &\\left.\\max \\left(\\beta-\\left\\|f\\left(x_{i}^{r}\\right)-f\\left(x_{i}^{n}\\right)\\right\\|_{2}, 0\\right)^{2}\\right] \\end{aligned} \u8bad\u7ec3\u5b8c\u4e4b\u540e\u8fd9\u4e2a\u6a21\u5757\u53ef\u4ee5\u4f5c\u4e3a\u4e00\u4e2aplug-and-play\u7684\u72ec\u7acb\u6a21\u5757\u52a0\u5165\u7f51\u7edc\u4e4b\u4e2d\uff0c\u7528\u4e8e\u878d\u5408\u4e0d\u540c\u76f8\u673a\u56fe\u7247\u7684\u56fe\u50cf\u4fe1\u606f\u3002 \u4ece\u8bba\u6587\u793a\u4f8b\u56fe\u53ef\u4ee5\u770b\u5230\u8fd9\u4e2a\u6a21\u5757\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u8fb9\u754c\u5904\u7684detection\u7ed3\u679c\u3002","title":"siaNMS: Non-Maximum Suppression with Siamese Networks for Multi-Camera 3D Object Detection"},{"location":"3dDetection/siaNMS/#sianms-non-maximum-suppression-with-siamese-networks-for-multi-camera-3d-object-detection","text":"\u8fd9\u7bc7paper\u5c1d\u8bd5\u89e3\u51b3\u7684\u95ee\u9898\u662f\u76f8\u673a\u4e0e\u70b9\u4e91\u878d\u5408\u573a\u666f\u4e2d\u7684\u4e00\u4e2a\u95ee\u9898\uff0c\u5c31\u662f\u8bf4\u4e00\u4e2a\u7269\u4f53\u540c\u65f6\u88ab\u4e24\u4e2a\u76f8\u673a\u62cd\u6444\u65f6\uff0c\u5982\u4f55\u5145\u5206\u5229\u7528\u4e24\u4e2a\u76f8\u673a\u7684\u4fe1\u606f\u8fdb\u884c\u878d\u5408\u3002","title":"siaNMS: Non-Maximum Suppression with Siamese Networks for Multi-Camera 3D Object Detection"},{"location":"3dDetection/siaNMS/#_1","text":"\u8fd9\u7bc7\u6587\u7ae0\u603b\u4f53\u67b6\u6784\u8ddf\u968f Frustum Network \u7684\u8bbe\u8ba1\u3002\u4f7f\u75282D \u7269\u4f53\u68c0\u6d4b\u7b97\u6cd5\u5f97\u5230\u7269\u4f53\u76842\u7ef4\u6846\uff0c\u5728\u4e8c\u7ef4\u6846\u5bf9\u5e94\u7684\u65b9\u5f62\u67f1\u53f0\u4e2d\u627e\u51fa\u70b9\u4e91\u5b50\u96c6\uff0c\u4f7f\u7528Point Net\u4f5c\u6700\u540e\u76843D\u524d\u540e\u666f\u5206\u5272\u5df2\u7ecf3D\u53c2\u6570\u56de\u5f52\u3002","title":"\u603b\u4f53\u7ed3\u6784"},{"location":"3dDetection/siaNMS/#sianms","text":"\u4f5c\u8005\u91c7\u53d6\u4e00\u4e2a\u6bd4\u8f83\u76f4\u89c2\u7684\u8bbe\u8ba1\u8003\u8651\uff0c\u5bf9\u4e8eRoIpooling\u5f97\u5230\u7684\u6bcf\u4e00\u4e2a\u8f66\u5b50\u7684Feature Map\uff0c\u5982\u679c\u5b83\u4eec\u5c5e\u4e8e\u540c\u4e00\u8f86\u8f66\uff0c\u90a3\u4e48\u8fd9\u4e24\u4e2afeature\u5c31\u4f1a\u6bd4\u8f83\u63a5\u8fd1\u3002","title":"siaNMS\u7684\u7406\u89e3\u4e0e\u8bad\u7ec3\u65b9\u6cd5"},{"location":"3dDetection/siaNMS/#inference","text":"\u5bf9\u4e8e\u4e24\u4e2a\u76f8\u673a\u91cc\u9762\u53d1\u73b0\u7684object\uff0c\u7ecf\u8fc7siaNMS\u5f97\u5230\u5b83\u4eec\u7684feature\uff0c\u8ba1\u7b97\u5b83\u4eec\u4e4b\u95f4\u7684\u8ddd\u79bb\u3002\u4f7f\u7528 \u5308\u7259\u5229\u7b97\u6cd5 \u5f97\u5230\u6700\u4f73\u4e24\u4e24\u5339\u914d\u7ed3\u679c\uff0c\u5982\u679c\u4e24\u4e2a\u5339\u914d\u6846\u5e76\u96c6(union)\u5185\u6709\u70b9\u4e91\uff0c\u5219\u8fd9\u4e9b\u70b9\u4e91\u90fd\u4f1a\u4f5c\u4e3a\u8fd9\u4e2a\u7269\u4f53Frustum\u5185\u7684\u70b9\u3002 \u7b80\u5355\u7684\u8868\u8ff0\u6765\u8bf4\u5c31\u662f\u88ab\u5339\u914d\u8ba4\u4e3a\u662f\u540c\u4e00\u4e2a\u7269\u4f53\u7684\u76f8\u673a\u6846\u5185\u7684\u70b9\uff0c\u5408\u5e76\u540e\u7684\u76f8\u673a\u4e3b\u8f74\u8bbe\u8ba1\u4e3a","title":"Inference\u8fc7\u7a0b"},{"location":"3dDetection/siaNMS/#training","text":"\u8fd9\u91cc\u4f7f\u7528 nuscene \u6570\u636e\u96c6\uff0c nuscene \u7684\u4e00\u4e2a\u7279\u5f81\u662f\u6807\u8bb0\u6bcf\u4e00\u4e2a\u573a\u666f\u91cc\u9762\u6bcf\u4e00\u8f86\u8f66\u7684instance ID\u3002\u4f5c\u8005\u5148\u4f7f\u75282D detector\u5f97\u5230\u6bcf\u4e00\u4e2a\u573a\u666f\u91cc\u9762\u6bcf\u4e00\u8f86\u8f66\u5728\u6bcf\u4e00\u4e2a\u6444\u50cf\u5934\u4e2dRoIAlign\u540e\u7684\u7279\u5f81\u56fe\u3002 \u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6bcf\u4e00\u4e2a\u6837\u672c\u7531\u4e00\u8f86\u540c\u65f6\u5728\u4e24\u4e2a\u6444\u50cf\u5934\u4e2d\u51fa\u73b0\u7684\u8f66\u7684\u7279\u5f81\u56fe\uff0c\u4e00\u4e2a\u4e3a\u53c2\u8003\u6837\u672c x^r , \u4e00\u4e2a\u4e3a\u6b63\u6837\u672c x^p \uff0c\u540c\u573a\u666f\u53e6\u4e00\u8f86\u968f\u673a\u8f66\u8f86\u4f5c\u4e3a\u8d1f\u6837\u672c x^n \u3002\u8bad\u7ec3\u4e00\u4e2asiaNMS\u7f51\u7edc\uff0c\u8f93\u5165\u662f2D aligned\u540e\u7684\u7279\u5f81\u56fe\uff0c\u8f93\u51fa\u662f\u4e00\u4e2a d \u7ef4\u7684\u77e2\u91cf\u3002 \u6211\u4eec\u5e0c\u671b\u6b63\u6837\u672c\u4e0e\u53c2\u8003\u6837\u672c\u7684\u77e2\u91cf\u63a5\u8fd1\u800c\u8d1f\u6837\u672c\u4e0e\u53c2\u8003\u6837\u672c\u7684\u77e2\u91cf\u8ddd\u79bb\u8fdc\u3002 \\begin{array}{l} \\left\\|f\\left(x_{i}^{r}\\right)-f\\left(x_{i}^{p}\\right)\\right\\|_{2}<\\alpha \\\\ \\left\\|f\\left(x_{i}^{r}\\right)-f\\left(x_{i}^{n}\\right)\\right\\|_{2}>\\beta \\end{array} \u56e0\u800c\u635f\u5931\u51fd\u6570\u4e3a\uff1a \\begin{aligned} \\mathcal{L}=& \\frac{1}{2} \\sum_{i}^{N}\\left[\\max \\left(\\left\\|f\\left(x_{i}^{r}\\right)-f\\left(x_{i}^{p}\\right)\\right\\|_{2}-\\alpha, 0\\right)^{2}+\\right.\\\\ &\\left.\\max \\left(\\beta-\\left\\|f\\left(x_{i}^{r}\\right)-f\\left(x_{i}^{n}\\right)\\right\\|_{2}, 0\\right)^{2}\\right] \\end{aligned} \u8bad\u7ec3\u5b8c\u4e4b\u540e\u8fd9\u4e2a\u6a21\u5757\u53ef\u4ee5\u4f5c\u4e3a\u4e00\u4e2aplug-and-play\u7684\u72ec\u7acb\u6a21\u5757\u52a0\u5165\u7f51\u7edc\u4e4b\u4e2d\uff0c\u7528\u4e8e\u878d\u5408\u4e0d\u540c\u76f8\u673a\u56fe\u7247\u7684\u56fe\u50cf\u4fe1\u606f\u3002 \u4ece\u8bba\u6587\u793a\u4f8b\u56fe\u53ef\u4ee5\u770b\u5230\u8fd9\u4e2a\u6a21\u5757\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u8fb9\u754c\u5904\u7684detection\u7ed3\u679c\u3002","title":"Training \u65b9\u6cd5"},{"location":"3dDetection/voxelNet/","text":"VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection \u70b9\u4e91\u6295\u5f71\u5230\u4e09\u7ef4\u7f51\u683c\uff0c\u6bcf\u4e00\u4e2a\u7f51\u683c\u5185\u901a\u8fc7\u968f\u673a\u53d6\u70b9\u52a0\u5168\u8fde\u63a5\u4f20\u64ad\uff0c\u5f97\u5230\u4e00\u4e2a\u5355\u4e00\u7684feature-vector\u3002\u5173\u952e\u662f\u5bf9\u4e8e\u8fd9\u6837\u4e00\u4e2a\u7a00\u758f\u76844D\u77e9\u9635\uff0c\u5728\u540e\u9762\u5982\u4f55\u5feb\u901f\u8fdb\u884c\u77e2\u91cf\u8fd0\u7b97\uff0c\u8fd9\u91cc\u4f7f\u7528\u7a00\u758f\u8868\u8fbe\uff0c\u7528hash table\u5efa\u7acb\u5feb\u901findex\u3002","title":"VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection"},{"location":"3dDetection/voxelNet/#voxelnet-end-to-end-learning-for-point-cloud-based-3d-object-detection","text":"\u70b9\u4e91\u6295\u5f71\u5230\u4e09\u7ef4\u7f51\u683c\uff0c\u6bcf\u4e00\u4e2a\u7f51\u683c\u5185\u901a\u8fc7\u968f\u673a\u53d6\u70b9\u52a0\u5168\u8fde\u63a5\u4f20\u64ad\uff0c\u5f97\u5230\u4e00\u4e2a\u5355\u4e00\u7684feature-vector\u3002\u5173\u952e\u662f\u5bf9\u4e8e\u8fd9\u6837\u4e00\u4e2a\u7a00\u758f\u76844D\u77e9\u9635\uff0c\u5728\u540e\u9762\u5982\u4f55\u5feb\u901f\u8fdb\u884c\u77e2\u91cf\u8fd0\u7b97\uff0c\u8fd9\u91cc\u4f7f\u7528\u7a00\u758f\u8868\u8fbe\uff0c\u7528hash table\u5efa\u7acb\u5feb\u901findex\u3002","title":"VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection"},{"location":"Building_Blocks/4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks/","text":"4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks \u8fd9\u7bc7\u8bba\u6587\u4f7f\u7528\u7a00\u758f\u77e2\u91cf\u3001\u5e7f\u4e49\u7a00\u758f\u5377\u79ef\uff0c\u62d3\u5c55\u4e863D\u30014D\u5377\u79ef\uff0c\u52a0\u901f\u4e86\u7a00\u758f\u7684\u70b9\u4e91\u7684\u9ad8\u7ef4\u5377\u79ef\u3002 \u76ee\u524d\u6ca1\u770b\u61c2\u539f\u7406\uff0c\u800c\u4e14\u6709\u5927\u91cf\u57fa\u4e8eGPU cuda\u7684\u5de5\u7a0b\u5de5\u4f5c\u3002","title":"4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks"},{"location":"Building_Blocks/4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks/#4d-spatio-temporal-convnets-minkowski-convolutional-neural-networks","text":"\u8fd9\u7bc7\u8bba\u6587\u4f7f\u7528\u7a00\u758f\u77e2\u91cf\u3001\u5e7f\u4e49\u7a00\u758f\u5377\u79ef\uff0c\u62d3\u5c55\u4e863D\u30014D\u5377\u79ef\uff0c\u52a0\u901f\u4e86\u7a00\u758f\u7684\u70b9\u4e91\u7684\u9ad8\u7ef4\u5377\u79ef\u3002 \u76ee\u524d\u6ca1\u770b\u61c2\u539f\u7406\uff0c\u800c\u4e14\u6709\u5927\u91cf\u57fa\u4e8eGPU cuda\u7684\u5de5\u7a0b\u5de5\u4f5c\u3002","title":"4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks"},{"location":"Building_Blocks/AUGMIX/","text":"AUGMIX: A SIMPLE DATA PROCESSING METHOD TO IMPROVE ROBUSTNESS AND UNCERTAINTY \u8fd9\u7bc7\u8c37\u6b4c\u7684\u6587\u7ae0\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5bf9\u4e8e\u5206\u7c7bmodel\u5bb9\u6613\u4f7f\u7528\u7684\u81ea\u52a8\u6570\u636e\u589e\u5f3a\u8303\u5f0f\u3002\u4e0e\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u7b49\u5176\u4ed6\u65b9\u6cd5\u4e0d\u540c\uff0c\u8c37\u6b4c\u63d0\u51fa\u7684\u7b97\u6cd5\u53ea\u5305\u542b\u968f\u673a\u91c7\u6837\u52a0\u4e0a\u4e00\u4e2a\u9644\u52a0\u7684\u635f\u5931\u51fd\u6570\u9879\u3002\u5f00\u6e90\u7684\u4ee3\u7801\u4e3a\u7b80\u5355\u7684numpy\u4e0epytorch\uff0c\u8f83\u4e3a\u6613\u61c2\u3002 \u4f2a\u4ee3\u7801 \u4f5c\u8005\u63d0\u51fa\u7684\u6570\u636e\u52a0\u5f3a\u7684\u91c7\u6837\u7ed3\u679c\u4e0d\u662f\u591a\u4e2a\u6570\u636e\u52a0\u5f3a\u7684\u7b80\u5355\u5c42\u53e0(\u6df1\u5ea6\u4e0a\u7684\u94fe\u63a5)\uff0c\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u79cd\u505a\u6cd5\u5f88\u5bb9\u6613\u4f7f\u5f97\u5f97\u5230\u7684\u6570\u636e\u504f\u79bb\u771f\u5b9e\u6570\u636e\u96c6\u592a\u8fdc\uff0c\u6240\u4ee5\u63d0\u51fa\u7684\u662f\u4e00\u4e2a\u7efc\u5408\u4e86\u5e7f\u5ea6\u548c\u6df1\u5ea6\u590d\u5408\u7ec4\u5408\u65b9\u5f0f\uff0c\u4e00\u4e2a\u4f8b\u5b50\u5982\u56fe \u635f\u5931\u51fd\u6570\u4e0a\u9700\u8981\u52a0\u4e0a Jensen-Shannon divergence . Jensen-Shannon divergence Jensen-Shannon divergence\u672c\u8d28\u4e0a\u662f KL divergence \u7684\u4e00\u4e2a\u6269\u5c55. \u672c\u6587\u7684\u4e09\u5143\u7684JS divergence\u5b9a\u4e49\u4e3a \\operatorname{JS}\\left(p_{\\text {orig }} ; p_{\\text {augmix } 1} ; p_{\\text {augmix } 2}\\right)=\\frac{1}{3}\\left(\\mathrm{KL}\\left[p_{\\text {orig }} \\| M\\right]+\\mathrm{KL}\\left[p_{\\text {augmix } 1} \\| M\\right]+\\mathrm{KL}\\left[p_{\\text {augmix } 2} \\| M\\right]\\right) \u6ce8\u610f Pytorch\u7684KL-divergence \u5728\u5b9e\u73b0\u4e0a\u7a0d\u7a0d\u6709\u5751\u3002\u672c\u6587\u4ee3\u7801\u6709\u5b8c\u6574\u7684\u5b9e\u73b0\u3002","title":"AUGMIX: A SIMPLE DATA PROCESSING METHOD TO IMPROVE ROBUSTNESS AND UNCERTAINTY"},{"location":"Building_Blocks/AUGMIX/#augmix-a-simple-data-processing-method-to-improve-robustness-and-uncertainty","text":"\u8fd9\u7bc7\u8c37\u6b4c\u7684\u6587\u7ae0\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5bf9\u4e8e\u5206\u7c7bmodel\u5bb9\u6613\u4f7f\u7528\u7684\u81ea\u52a8\u6570\u636e\u589e\u5f3a\u8303\u5f0f\u3002\u4e0e\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u7b49\u5176\u4ed6\u65b9\u6cd5\u4e0d\u540c\uff0c\u8c37\u6b4c\u63d0\u51fa\u7684\u7b97\u6cd5\u53ea\u5305\u542b\u968f\u673a\u91c7\u6837\u52a0\u4e0a\u4e00\u4e2a\u9644\u52a0\u7684\u635f\u5931\u51fd\u6570\u9879\u3002\u5f00\u6e90\u7684\u4ee3\u7801\u4e3a\u7b80\u5355\u7684numpy\u4e0epytorch\uff0c\u8f83\u4e3a\u6613\u61c2\u3002","title":"AUGMIX: A SIMPLE DATA PROCESSING METHOD TO IMPROVE ROBUSTNESS AND UNCERTAINTY"},{"location":"Building_Blocks/AUGMIX/#_1","text":"\u4f5c\u8005\u63d0\u51fa\u7684\u6570\u636e\u52a0\u5f3a\u7684\u91c7\u6837\u7ed3\u679c\u4e0d\u662f\u591a\u4e2a\u6570\u636e\u52a0\u5f3a\u7684\u7b80\u5355\u5c42\u53e0(\u6df1\u5ea6\u4e0a\u7684\u94fe\u63a5)\uff0c\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u79cd\u505a\u6cd5\u5f88\u5bb9\u6613\u4f7f\u5f97\u5f97\u5230\u7684\u6570\u636e\u504f\u79bb\u771f\u5b9e\u6570\u636e\u96c6\u592a\u8fdc\uff0c\u6240\u4ee5\u63d0\u51fa\u7684\u662f\u4e00\u4e2a\u7efc\u5408\u4e86\u5e7f\u5ea6\u548c\u6df1\u5ea6\u590d\u5408\u7ec4\u5408\u65b9\u5f0f\uff0c\u4e00\u4e2a\u4f8b\u5b50\u5982\u56fe \u635f\u5931\u51fd\u6570\u4e0a\u9700\u8981\u52a0\u4e0a Jensen-Shannon divergence .","title":"\u4f2a\u4ee3\u7801"},{"location":"Building_Blocks/AUGMIX/#jensen-shannon-divergence","text":"Jensen-Shannon divergence\u672c\u8d28\u4e0a\u662f KL divergence \u7684\u4e00\u4e2a\u6269\u5c55. \u672c\u6587\u7684\u4e09\u5143\u7684JS divergence\u5b9a\u4e49\u4e3a \\operatorname{JS}\\left(p_{\\text {orig }} ; p_{\\text {augmix } 1} ; p_{\\text {augmix } 2}\\right)=\\frac{1}{3}\\left(\\mathrm{KL}\\left[p_{\\text {orig }} \\| M\\right]+\\mathrm{KL}\\left[p_{\\text {augmix } 1} \\| M\\right]+\\mathrm{KL}\\left[p_{\\text {augmix } 2} \\| M\\right]\\right) \u6ce8\u610f Pytorch\u7684KL-divergence \u5728\u5b9e\u73b0\u4e0a\u7a0d\u7a0d\u6709\u5751\u3002\u672c\u6587\u4ee3\u7801\u6709\u5b8c\u6574\u7684\u5b9e\u73b0\u3002","title":"Jensen-Shannon divergence"},{"location":"Building_Blocks/Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization/","text":"Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization \u8fd9\u7bc7\u6587\u7ae0\u63d0\u51fa\u4e86Style Transfer\u76f8\u5f53\u957f\u4e00\u6bb5\u65f6\u95f4\u7684SOTA\u6216\u8005baseline\uff0c\u4e5f\u5c31\u662fAdaIN\u6a21\u5757\u3002 \u80cc\u666f\u77e5\u8bc6 Normalization \u56de\u987e \u672c\u6587\u9664\u4e86\u57fa\u7840\u7684BatchNorm(\u5b8c\u6574batch)\u4ee5\u53caInstanceNorm(\u4e0d\u8003\u8651batch)\u8fd8\u56de\u987e\u4e86Conditional Instance Normalization(CIN). CIN\u5c42\u4e3a\u6bcf\u4e00\u4e2astyle\u5b66\u4e60\u4e00\u5957InstanceNorm\u7684\u53c2\u6570 \\gamma^s, \\beta^s \\operatorname{CIN}(x ; s)=\\gamma^{s}\\left(\\frac{x-\\mu(x)}{\\sigma(x)}\\right)+\\beta^{s} \u5b9e\u9a8c\u53ef\u77e5\u5bf9CIN\u7f51\u7edc\u800c\u8a00\uff0cBN\u7684\u7ed3\u679c\u603b\u4f53\u4e0d\u5982IN\u7684\u7ed3\u679c Adaptive Instance Normalization AdaIN\u516c\u5f0f: \\operatorname{AdaIN}(x, y)=\\sigma(y)\\left(\\frac{x-\\mu(x)}{\\sigma(x)}\\right)+\\mu(y) \u5176\u4e2d x \u4e3acontent input\u800c y \u4e3astyle input.\u672c\u8d28\u4e0a\u6765\u8bf4\u5c31\u662f\u5bf9content instance\u4f7f\u7528instance normalization \u8f6c\u6362\u4e3astyle instance\u7684\u5747\u503c\u4e0e\u65b9\u5dee. \u7f51\u7edc\u7ed3\u6784\u4e0e\u8bad\u7ec3\u65b9\u6cd5 \u7f51\u7edc\u7ed3\u6784\u5982\u56fe \u5c06\u4e24\u5f20\u56fe\u540c\u65f6\u8f93\u5165\u5230VGG encoder\u4e2d\uff0c\u6267\u884cAdaIN\uff0c\u5bf9content\u7ed3\u679cdecode\u5f97\u5230\u8f93\u51fa\u56fe Content Loss \u5229\u7528VGG encode style-transfered picture, \\mathcal{L_c} = ||f(g(t)) - t||_2 \u5176\u4e2d f \u4e3aencoder, g \u4e3adecoder\uff0c t \u4e3aAdaIN\u5904\u7684\u8f93\u51fa\uff0c\u4e5f\u5c31\u662f\u5bf9\u7279\u5f81\u5411\u91cf\u53d6L2\u8bef\u5dee Style Loss \u4ee5\u524d\u6709\u4f7f\u7528 \u683c\u62c9\u59c6\u77e9\u9635\u7684\u76f8\u5173\u6027\u8bef\u5dee\u7684 ,\u8fd9\u91cc\u8d85\u94fe\u63a5\u7ed9\u7684\u4f8b\u5b50\u6765\u81ea\u4e8ekeras\u7684\u4f8b\u5b50\u3002\u672c\u6587\u8fd9\u91cc\u4f7f\u7528\u53e6\u4e00\u4e2a \u522b\u4eba \u63d0\u51fa\u7684\u8bef\u5dee \\begin{array}{c}{\\mathcal{L}_{s}=\\sum_{i=1}^{L}\\left\\|\\mu\\left(\\phi_{i}(g(t))\\right)-\\mu\\left(\\phi_{i}(s)\\right)\\right\\|_{2}+} \\\\ {\\sum_{i=1}^{L}\\left\\|\\sigma\\left(\\phi_{i}(g(t))\\right)-\\sigma\\left(\\phi_{i}(s)\\right)\\right\\|_{2}}\\end{array} \u5176\u4e2d \\mu, \\sigma \u6307\u6c42\u5747\u503c\u4e0e\u65b9\u5dee, \\phi_i \u6307VGG-19\u4e2d\u7684\u67d0\u4e00\u5c42\u7684\u8f93\u51fa\u3002","title":"Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization"},{"location":"Building_Blocks/Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization/#arbitrary-style-transfer-in-real-time-with-adaptive-instance-normalization","text":"\u8fd9\u7bc7\u6587\u7ae0\u63d0\u51fa\u4e86Style Transfer\u76f8\u5f53\u957f\u4e00\u6bb5\u65f6\u95f4\u7684SOTA\u6216\u8005baseline\uff0c\u4e5f\u5c31\u662fAdaIN\u6a21\u5757\u3002","title":"Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization"},{"location":"Building_Blocks/Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization/#normalization","text":"\u672c\u6587\u9664\u4e86\u57fa\u7840\u7684BatchNorm(\u5b8c\u6574batch)\u4ee5\u53caInstanceNorm(\u4e0d\u8003\u8651batch)\u8fd8\u56de\u987e\u4e86Conditional Instance Normalization(CIN). CIN\u5c42\u4e3a\u6bcf\u4e00\u4e2astyle\u5b66\u4e60\u4e00\u5957InstanceNorm\u7684\u53c2\u6570 \\gamma^s, \\beta^s \\operatorname{CIN}(x ; s)=\\gamma^{s}\\left(\\frac{x-\\mu(x)}{\\sigma(x)}\\right)+\\beta^{s} \u5b9e\u9a8c\u53ef\u77e5\u5bf9CIN\u7f51\u7edc\u800c\u8a00\uff0cBN\u7684\u7ed3\u679c\u603b\u4f53\u4e0d\u5982IN\u7684\u7ed3\u679c","title":"\u80cc\u666f\u77e5\u8bc6 Normalization \u56de\u987e"},{"location":"Building_Blocks/Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization/#adaptive-instance-normalization","text":"AdaIN\u516c\u5f0f: \\operatorname{AdaIN}(x, y)=\\sigma(y)\\left(\\frac{x-\\mu(x)}{\\sigma(x)}\\right)+\\mu(y) \u5176\u4e2d x \u4e3acontent input\u800c y \u4e3astyle input.\u672c\u8d28\u4e0a\u6765\u8bf4\u5c31\u662f\u5bf9content instance\u4f7f\u7528instance normalization \u8f6c\u6362\u4e3astyle instance\u7684\u5747\u503c\u4e0e\u65b9\u5dee.","title":"Adaptive Instance Normalization"},{"location":"Building_Blocks/Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization/#_1","text":"\u7f51\u7edc\u7ed3\u6784\u5982\u56fe \u5c06\u4e24\u5f20\u56fe\u540c\u65f6\u8f93\u5165\u5230VGG encoder\u4e2d\uff0c\u6267\u884cAdaIN\uff0c\u5bf9content\u7ed3\u679cdecode\u5f97\u5230\u8f93\u51fa\u56fe","title":"\u7f51\u7edc\u7ed3\u6784\u4e0e\u8bad\u7ec3\u65b9\u6cd5"},{"location":"Building_Blocks/Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization/#content-loss","text":"\u5229\u7528VGG encode style-transfered picture, \\mathcal{L_c} = ||f(g(t)) - t||_2 \u5176\u4e2d f \u4e3aencoder, g \u4e3adecoder\uff0c t \u4e3aAdaIN\u5904\u7684\u8f93\u51fa\uff0c\u4e5f\u5c31\u662f\u5bf9\u7279\u5f81\u5411\u91cf\u53d6L2\u8bef\u5dee","title":"Content Loss"},{"location":"Building_Blocks/Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization/#style-loss","text":"\u4ee5\u524d\u6709\u4f7f\u7528 \u683c\u62c9\u59c6\u77e9\u9635\u7684\u76f8\u5173\u6027\u8bef\u5dee\u7684 ,\u8fd9\u91cc\u8d85\u94fe\u63a5\u7ed9\u7684\u4f8b\u5b50\u6765\u81ea\u4e8ekeras\u7684\u4f8b\u5b50\u3002\u672c\u6587\u8fd9\u91cc\u4f7f\u7528\u53e6\u4e00\u4e2a \u522b\u4eba \u63d0\u51fa\u7684\u8bef\u5dee \\begin{array}{c}{\\mathcal{L}_{s}=\\sum_{i=1}^{L}\\left\\|\\mu\\left(\\phi_{i}(g(t))\\right)-\\mu\\left(\\phi_{i}(s)\\right)\\right\\|_{2}+} \\\\ {\\sum_{i=1}^{L}\\left\\|\\sigma\\left(\\phi_{i}(g(t))\\right)-\\sigma\\left(\\phi_{i}(s)\\right)\\right\\|_{2}}\\end{array} \u5176\u4e2d \\mu, \\sigma \u6307\u6c42\u5747\u503c\u4e0e\u65b9\u5dee, \\phi_i \u6307VGG-19\u4e2d\u7684\u67d0\u4e00\u5c42\u7684\u8f93\u51fa\u3002","title":"Style Loss"},{"location":"Building_Blocks/Attention_Augmented_Conv/","text":"Attention Augmented Convolutional Networks \u8fd9\u7bc7\u6587\u7ae0\u57fa\u4e8e transformer \uff0c\u5c06attention\u76f4\u63a5\u9644\u52a0\u5728\u5377\u79ef\u5c42\u4e2d,\u7406\u8bba\u4e0a\u6765\u8bf4\u53ef\u4ee5\u7528\u4e8e\u66ff\u4ee3\u5377\u79ef\u5c42. \u56fe\u7247\u4e0a\u7684self-attention \u8bbe\u8f93\u5165\u5f20\u91cf\u5f62\u72b6\u4e3a (H, W, F_{in}) \uff0c\u8fd9\u91cc\u5ffd\u7565Batch.\u9996\u5148\u644a\u5e73\u4e3a\u4e00\u7ef4\u53d8\u4e3a X \u77e2\u91cf\uff0c\u7136\u540e\u76f4\u63a5\u4f7f\u7528 transformer \u4e2d\u7684\u81ea\u6ce8\u610f\u529b\u5c42 O_h = Softmax(\\frac{(XW_q)(XW_k)^T}{\\sqrt{d_k^h}})(XW_v) \u5176\u4e2d W_q, W_k, W_v \u5206\u522b\u662f\u8f93\u51fa\u7ef4\u5ea6\u4e3a d_k, d_k, d_v \u7684\u5168\u8fde\u63a5\u5c42\u7684\u6743\u91cd\u77e9\u9635\u3002 \u8f93\u51fa\u518dConcat\u4e3aMHA MHA(X) = Concat[O_1,...,O_{N_h}]W^O \u6700\u540e\u4f1a\u88abreshape\u6210\u4e3a (H, W, d_v) \u7684\u5f62\u72b6. \u4e8c\u7ef4positional embedding \u540c transformer ,\u6211\u4eec\u9700\u8981\u4e00\u4e2a\u4f20\u9012\u76f8\u5bf9\u4f4d\u7f6e\u4fe1\u606f\u7684\u65b9\u5f0f\uff0c\u6211\u4eec\u8981\u6c42\u8fd9\u4e2aembedding\u80fd\u591f\u4f7f\u7f51\u7edc\u5bf9\u4f4d\u7f6e\u654f\u611f\uff0c\u4f46\u662f\u4e0d\u80fd\u8ba9\u7f51\u7edc\u5bf9\u5e73\u79fb\u654f\u611f,\u8fd9\u91cc\u6765\u6e90\u6765\u81ea\u4e8emusic transformer. \u50cf\u7d20 i=(i_x, i_y) \u5bf9\u50cf\u7d20 j=(j_x,j_y) \u7684attention logits\u4e3a l_{i,j} = \\frac{q_i^T}{\\sqrt(d^h_k)}(k_j + r^W_{j_x-i_x} + r^H_{j_y-i_y}) \u5176\u4e2d q_i \u662f\u50cf\u7d20 i \u5bf9\u5e94\u7684query vector, k_j \u662f\u50cf\u7d20 j \u7684key vector, \u4e0a\u6587\u7684self-Attention\u8ba1\u7b97\u53ef\u4ee5\u8f6c\u5316\u4e3a O_h = Softmax(\\frac{QK^T + S^{rel}_H + S^{rel}_W}{\\sqrt{d^h_k}})V \u4e5f\u5c31\u662fsoftmax\u5206\u5b50\u52a0\u4e86\u4e24\u9879,\u5176\u4e2d S^{rel}_H[i,j] = q_i^Tr^H_{j_y,i_y}, S^{rel}_W = q_i^Tr^W_{j_x-i_x} \u3002 \u8bba\u6587\u8bf4\u8fd9\u4e2a r \u7684\u4e00\u79cd\u505a\u6cd5\u662f\u76f4\u63a5\u5b58\u6210\u4e00\u4e2a (HW, HW, d_k^h) \u77e9\u9635\uff0c\u4f46\u662f\u8fd9\u6837\u4e0d\u592a\u597d\uff0c\u6240\u4ee5\u91c7\u53d6\u4e86Music Transform\u7684\u7b97\u6cd5\uff0c\u66f4\u7701\u5185\u5b58\uff0c\u5177\u4f53\u770b\u4ee3\u7801(\u539f\u6587\u5c31\u662f\u8fd9\u6837)\uff0c\u8fd9\u4e9b\u53c2\u6570\u53ef\u5b66\u4e60\u3002 Attention Augmented conv AAConv(X) = Concat[Conv(X), MHA(X)]","title":"Attention Augmented Convolutional Networks"},{"location":"Building_Blocks/Attention_Augmented_Conv/#attention-augmented-convolutional-networks","text":"\u8fd9\u7bc7\u6587\u7ae0\u57fa\u4e8e transformer \uff0c\u5c06attention\u76f4\u63a5\u9644\u52a0\u5728\u5377\u79ef\u5c42\u4e2d,\u7406\u8bba\u4e0a\u6765\u8bf4\u53ef\u4ee5\u7528\u4e8e\u66ff\u4ee3\u5377\u79ef\u5c42.","title":"Attention Augmented Convolutional Networks"},{"location":"Building_Blocks/Attention_Augmented_Conv/#self-attention","text":"\u8bbe\u8f93\u5165\u5f20\u91cf\u5f62\u72b6\u4e3a (H, W, F_{in}) \uff0c\u8fd9\u91cc\u5ffd\u7565Batch.\u9996\u5148\u644a\u5e73\u4e3a\u4e00\u7ef4\u53d8\u4e3a X \u77e2\u91cf\uff0c\u7136\u540e\u76f4\u63a5\u4f7f\u7528 transformer \u4e2d\u7684\u81ea\u6ce8\u610f\u529b\u5c42 O_h = Softmax(\\frac{(XW_q)(XW_k)^T}{\\sqrt{d_k^h}})(XW_v) \u5176\u4e2d W_q, W_k, W_v \u5206\u522b\u662f\u8f93\u51fa\u7ef4\u5ea6\u4e3a d_k, d_k, d_v \u7684\u5168\u8fde\u63a5\u5c42\u7684\u6743\u91cd\u77e9\u9635\u3002 \u8f93\u51fa\u518dConcat\u4e3aMHA MHA(X) = Concat[O_1,...,O_{N_h}]W^O \u6700\u540e\u4f1a\u88abreshape\u6210\u4e3a (H, W, d_v) \u7684\u5f62\u72b6.","title":"\u56fe\u7247\u4e0a\u7684self-attention"},{"location":"Building_Blocks/Attention_Augmented_Conv/#positional-embedding","text":"\u540c transformer ,\u6211\u4eec\u9700\u8981\u4e00\u4e2a\u4f20\u9012\u76f8\u5bf9\u4f4d\u7f6e\u4fe1\u606f\u7684\u65b9\u5f0f\uff0c\u6211\u4eec\u8981\u6c42\u8fd9\u4e2aembedding\u80fd\u591f\u4f7f\u7f51\u7edc\u5bf9\u4f4d\u7f6e\u654f\u611f\uff0c\u4f46\u662f\u4e0d\u80fd\u8ba9\u7f51\u7edc\u5bf9\u5e73\u79fb\u654f\u611f,\u8fd9\u91cc\u6765\u6e90\u6765\u81ea\u4e8emusic transformer. \u50cf\u7d20 i=(i_x, i_y) \u5bf9\u50cf\u7d20 j=(j_x,j_y) \u7684attention logits\u4e3a l_{i,j} = \\frac{q_i^T}{\\sqrt(d^h_k)}(k_j + r^W_{j_x-i_x} + r^H_{j_y-i_y}) \u5176\u4e2d q_i \u662f\u50cf\u7d20 i \u5bf9\u5e94\u7684query vector, k_j \u662f\u50cf\u7d20 j \u7684key vector, \u4e0a\u6587\u7684self-Attention\u8ba1\u7b97\u53ef\u4ee5\u8f6c\u5316\u4e3a O_h = Softmax(\\frac{QK^T + S^{rel}_H + S^{rel}_W}{\\sqrt{d^h_k}})V \u4e5f\u5c31\u662fsoftmax\u5206\u5b50\u52a0\u4e86\u4e24\u9879,\u5176\u4e2d S^{rel}_H[i,j] = q_i^Tr^H_{j_y,i_y}, S^{rel}_W = q_i^Tr^W_{j_x-i_x} \u3002 \u8bba\u6587\u8bf4\u8fd9\u4e2a r \u7684\u4e00\u79cd\u505a\u6cd5\u662f\u76f4\u63a5\u5b58\u6210\u4e00\u4e2a (HW, HW, d_k^h) \u77e9\u9635\uff0c\u4f46\u662f\u8fd9\u6837\u4e0d\u592a\u597d\uff0c\u6240\u4ee5\u91c7\u53d6\u4e86Music Transform\u7684\u7b97\u6cd5\uff0c\u66f4\u7701\u5185\u5b58\uff0c\u5177\u4f53\u770b\u4ee3\u7801(\u539f\u6587\u5c31\u662f\u8fd9\u6837)\uff0c\u8fd9\u4e9b\u53c2\u6570\u53ef\u5b66\u4e60\u3002","title":"\u4e8c\u7ef4positional embedding"},{"location":"Building_Blocks/Attention_Augmented_Conv/#attention-augmented-conv","text":"AAConv(X) = Concat[Conv(X), MHA(X)]","title":"Attention Augmented conv"},{"location":"Building_Blocks/Attention_is_all_you_need/","text":"Attention is all you need \u8fd9\u7bc7\u8bba\u6587\u662f\u81ea\u6ce8\u610f\u673a\u5236\u5728\u65f6\u5e8f\u6a21\u578b\u4e2d\u5e7f\u6cdb\u4f7f\u7528\u7684\u5f00\u59cb\u3002\u672c\u6587\u63d0\u5230\u7684Transformer\u4ee5\u53ca\u5bf9\u5e94\u7684\u5c42\u90fd\u5df2\u7ecf\u6210\u4e3a\u4e86Pytorch\u7684\u6807\u51c6\u5c42. attention \u57fa\u7840\u56de\u987e \u8fd9\u91cc\u5f15\u7528\u51e0\u5f20Udaicty\u7eb3\u7c73\u5b66\u4f4d\u7684\u8bfe\u7a0b\u622a\u56fe \u9996\u5148Attention network\u7684Embedding\u5c06\u65f6\u5e8f\u7684\u6bcf\u4e00\u4e2a\u8f93\u5165(\u5355\u8bcd)\uff0c\u7ffb\u8bd1\u6210\u4e00\u4e2a\u4e2a\u5bf9\u5e94\u7684key vector K . \u7528\u672c\u8bba\u6587\u4e2d\u7684\u7528\u8bcd\u6765\u63cf\u8ff0\uff0c\u5c31\u662f\u8bf4RNN\u7684\u9690\u85cf\u5c42\u662fQuery Q , RNN\u89e3\u7801\u8fc7\u7a0b\u4e2d\u7684\u8f93\u5165\u4e3a value vector V Transformer \u7cfb\u7edf\u603b\u89c8 \u5728\"RNN\"\u7684\u6bcf\u4e00\u5c42\u7684\u7ed3\u6784\u5982\u56fe,\u5728embedding\u4e4b\u540e,\u8f93\u5165\u4e0e\u8f93\u51fa\u5206\u522b\u8f93\u5165\u5230\u4e00\u4e2amulti-head self attention\u6a21\u5757\u91cc\u9762\uff0c\u76f8\u5f53\u4e8e\u5728\u8f93\u5165\u8f93\u51fa\u5185\u90e8\u81ea\u5df1\u5148\u505a\u4e00\u6b21attention,\u7136\u540e\u8f93\u5165\u7ecf\u8fc7\u4e00\u4e2a\u5168\u8fde\u63a5\u524d\u9988\u7f51\u7edc\u540e\uff0c\u6210\u4e3a\u4e0b\u4e00\u4e2aattention module\u7684 Q \u4e0e K ,\u8f93\u51fa\u90e8\u5206\u7684processed embedding\u76f4\u63a5\u4f5c\u4e3a\u8fd9\u4e2a\u6a21\u5757\u7684 V .\u6700\u540e\u8f93\u51fa\u7ecf\u8fc7\u524d\u9988\u7f51\u7edc\u5904\u7406\u8f93\u51fa\u3002 \u6ce8\u610f\u672c\u6587\u7cfb\u7edf\u5b9e\u9645\u4e0a\u6ca1\u6709\u4f7f\u7528RNN,\u53ea\u662f\u501f\u7528\u4e86\u4e0a\u6587\u7684notation. Multi-head Attention \u5de6\u4fa7attention\u7684\u516c\u5f0f Attention(Q,K,V) = softmax(\\frac{QK^T}{\\sqrt{d_k}})V \u53f3\u4fa7\u7684\u516c\u5f0f \\begin{aligned} MultiHead(Q,K,V)&=Concat(head1,..head_h) W^O \\\\ where head_i &= Attention(QW_i^Q, KW_i^k, VW_i^V) \\end{aligned} \u672c\u6587\u4ee5\u53capytorch\u7684\u5b9e\u73b0\u4e2d\u9009\u62e9\u7684 h=8 \u524d\u9988\u6a21\u5757 FFN(x) = ReLU(W_1x+b_1)W_2 + b_2 Positional Encoding \u7531\u4e8e\u672c\u6587\u6700\u7ec8\u5b8c\u5168\u629b\u5f03RNN, \u8fd9\u91cc\u9700\u8981\u7ed9\u6a21\u578b\u8f93\u5165\u4f4d\u7f6e\u4fe1\u606f\uff0c\u4ee5\u8ba9model\u8ba4\u8bc6\u5230\u8fd9\u662f\u4e00\u4e2a\u5e8f\u5217\u95ee\u9898\u3002 Positional encoding\u7684\u7ef4\u5ea6\u4e3a d_{model} \u4e0eembedding\u4e00\u81f4 \u8fd9\u91cc\u7528\u7684\u516c\u5f0f\u662f \\begin{aligned} PE_{(pos,2i)} &= sin(pos/10000^{2i/d_{model}}) \\\\ PE_{(pos,2i+1)}&=cos(pos/10000^{2i/d_{model}}) \\end{aligned} pos \u6307\u4f4d\u7f6e\uff0c\u800c i \u6307\u7ef4\u5ea6,\u6bcf\u4e00\u7ef4\u5bf9\u5e94\u4e00\u4e2a\u6b63\u5f26,\u8fd9\u4e2a\u77e2\u91cf\u548cembedding\u76f8\u52a0\u3002 Self attention Udacity supplyment","title":"Attention is all you need"},{"location":"Building_Blocks/Attention_is_all_you_need/#attention-is-all-you-need","text":"\u8fd9\u7bc7\u8bba\u6587\u662f\u81ea\u6ce8\u610f\u673a\u5236\u5728\u65f6\u5e8f\u6a21\u578b\u4e2d\u5e7f\u6cdb\u4f7f\u7528\u7684\u5f00\u59cb\u3002\u672c\u6587\u63d0\u5230\u7684Transformer\u4ee5\u53ca\u5bf9\u5e94\u7684\u5c42\u90fd\u5df2\u7ecf\u6210\u4e3a\u4e86Pytorch\u7684\u6807\u51c6\u5c42.","title":"Attention is all you need"},{"location":"Building_Blocks/Attention_is_all_you_need/#attention","text":"\u8fd9\u91cc\u5f15\u7528\u51e0\u5f20Udaicty\u7eb3\u7c73\u5b66\u4f4d\u7684\u8bfe\u7a0b\u622a\u56fe \u9996\u5148Attention network\u7684Embedding\u5c06\u65f6\u5e8f\u7684\u6bcf\u4e00\u4e2a\u8f93\u5165(\u5355\u8bcd)\uff0c\u7ffb\u8bd1\u6210\u4e00\u4e2a\u4e2a\u5bf9\u5e94\u7684key vector K . \u7528\u672c\u8bba\u6587\u4e2d\u7684\u7528\u8bcd\u6765\u63cf\u8ff0\uff0c\u5c31\u662f\u8bf4RNN\u7684\u9690\u85cf\u5c42\u662fQuery Q , RNN\u89e3\u7801\u8fc7\u7a0b\u4e2d\u7684\u8f93\u5165\u4e3a value vector V","title":"attention \u57fa\u7840\u56de\u987e"},{"location":"Building_Blocks/Attention_is_all_you_need/#transformer","text":"\u5728\"RNN\"\u7684\u6bcf\u4e00\u5c42\u7684\u7ed3\u6784\u5982\u56fe,\u5728embedding\u4e4b\u540e,\u8f93\u5165\u4e0e\u8f93\u51fa\u5206\u522b\u8f93\u5165\u5230\u4e00\u4e2amulti-head self attention\u6a21\u5757\u91cc\u9762\uff0c\u76f8\u5f53\u4e8e\u5728\u8f93\u5165\u8f93\u51fa\u5185\u90e8\u81ea\u5df1\u5148\u505a\u4e00\u6b21attention,\u7136\u540e\u8f93\u5165\u7ecf\u8fc7\u4e00\u4e2a\u5168\u8fde\u63a5\u524d\u9988\u7f51\u7edc\u540e\uff0c\u6210\u4e3a\u4e0b\u4e00\u4e2aattention module\u7684 Q \u4e0e K ,\u8f93\u51fa\u90e8\u5206\u7684processed embedding\u76f4\u63a5\u4f5c\u4e3a\u8fd9\u4e2a\u6a21\u5757\u7684 V .\u6700\u540e\u8f93\u51fa\u7ecf\u8fc7\u524d\u9988\u7f51\u7edc\u5904\u7406\u8f93\u51fa\u3002 \u6ce8\u610f\u672c\u6587\u7cfb\u7edf\u5b9e\u9645\u4e0a\u6ca1\u6709\u4f7f\u7528RNN,\u53ea\u662f\u501f\u7528\u4e86\u4e0a\u6587\u7684notation.","title":"Transformer \u7cfb\u7edf\u603b\u89c8"},{"location":"Building_Blocks/Attention_is_all_you_need/#multi-head-attention","text":"\u5de6\u4fa7attention\u7684\u516c\u5f0f Attention(Q,K,V) = softmax(\\frac{QK^T}{\\sqrt{d_k}})V \u53f3\u4fa7\u7684\u516c\u5f0f \\begin{aligned} MultiHead(Q,K,V)&=Concat(head1,..head_h) W^O \\\\ where head_i &= Attention(QW_i^Q, KW_i^k, VW_i^V) \\end{aligned} \u672c\u6587\u4ee5\u53capytorch\u7684\u5b9e\u73b0\u4e2d\u9009\u62e9\u7684 h=8","title":"Multi-head Attention"},{"location":"Building_Blocks/Attention_is_all_you_need/#_1","text":"FFN(x) = ReLU(W_1x+b_1)W_2 + b_2","title":"\u524d\u9988\u6a21\u5757"},{"location":"Building_Blocks/Attention_is_all_you_need/#positional-encoding","text":"\u7531\u4e8e\u672c\u6587\u6700\u7ec8\u5b8c\u5168\u629b\u5f03RNN, \u8fd9\u91cc\u9700\u8981\u7ed9\u6a21\u578b\u8f93\u5165\u4f4d\u7f6e\u4fe1\u606f\uff0c\u4ee5\u8ba9model\u8ba4\u8bc6\u5230\u8fd9\u662f\u4e00\u4e2a\u5e8f\u5217\u95ee\u9898\u3002 Positional encoding\u7684\u7ef4\u5ea6\u4e3a d_{model} \u4e0eembedding\u4e00\u81f4 \u8fd9\u91cc\u7528\u7684\u516c\u5f0f\u662f \\begin{aligned} PE_{(pos,2i)} &= sin(pos/10000^{2i/d_{model}}) \\\\ PE_{(pos,2i+1)}&=cos(pos/10000^{2i/d_{model}}) \\end{aligned} pos \u6307\u4f4d\u7f6e\uff0c\u800c i \u6307\u7ef4\u5ea6,\u6bcf\u4e00\u7ef4\u5bf9\u5e94\u4e00\u4e2a\u6b63\u5f26,\u8fd9\u4e2a\u77e2\u91cf\u548cembedding\u76f8\u52a0\u3002","title":"Positional Encoding"},{"location":"Building_Blocks/Attention_is_all_you_need/#self-attention-udacity-supplyment","text":"","title":"Self attention Udacity supplyment"},{"location":"Building_Blocks/Bpnp/","text":"End-to-End Learnable Geometric Vision by Backpropagating PnP Optimization \u8fd9\u7bc7\u8bba\u6587\u7684\u6838\u5fc3\u8d21\u732e\u662f\u5c06PnP \u4f18\u5316\u8fc7\u7a0b\u53d8\u4e3a\u4e00\u4e2a\u53ef\u5bfc\u7684\u90e8\u4ef6\u63d2\u5165\u5230\u7f51\u7edc\u4e4b\u4e2d\uff0c\u5bf9\u4e8e\u66f4\u591a\u7aef\u5230\u7aef\u7684\u6a21\u578b\u6709\u5f88\u597d\u7684\u5e2e\u52a9\u3002 \u9690\u51fd\u6570\u5b9a\u7406 Implicit function theorem \u5bf9\u4e8e f(a^*, b^*) = 0, \u4e14 b^* = g(a^*) \u82e5\u5176\u4e2d\u7684\u96c5\u514b\u6bd4\u77e9\u9635\u53ef\u5bfc\uff0c\u6709 \\frac{\\partial g}{\\partial x_{j}}(\\mathbf{x})=-\\left[J_{f, \\mathbf{y}}(\\mathbf{x}, g(\\mathbf{x}))\\right]_{m \\times m}^{-1}\\left[\\frac{\\partial f}{\\partial x_{j}}(\\mathbf{x}, g(\\mathbf{x}))\\right]_{m \\times 1} PnP\u95ee\u9898\uff0c\u4f5c\u8005\u9009\u62e9\u7684\u63cf\u8ff0\u662f\uff0c\u5bfb\u627e6 DoF\u4f4d\u59ff\uff0c\u4f7f\u5f973D\u70b9\u57282D\u5e73\u9762\u4e0a\u7684\u6295\u5f71\u7684\u5bf9\u5e94\u70b9\u4e2a\u70b9\u5728\u56fe\u7247\u4e2d\u7684\u8bef\u5dee\u5e73\u65b9\u548c\u6700\u5c0f\uff0c \u8fd9\u91cc\u4f5c\u8005\u9009\u62e9 f \u4e3a\u8bef\u5dee\u51fd\u6570\u5173\u4e8e\u8f93\u51fa\u7684\u5bfc\u6570 \\frac{\\partial f}{\\partial y} \uff0c\u5728pnp\u4f18\u5316\u597d\u540e\uff0c\u5176\u4e2d\u8fd9\u4e2a\u5bfc\u6570\u5e94\u4e3a\u96f6\u3002 \u5177\u4f53\u8ba1\u7b97\u89c1\u4ee3\u7801\u4e0e\u8bba\u6587 \u5176\u4e2dforward\u51fd\u6570opencv\u5b8c\u6210\uff0cbackward\u51fd\u6570\u8be6\u89c1\u4ee3\u7801\u3002\u6574\u4e2a\u51fd\u6570\u53ef\u4ee5\u4f5c\u4e3a\u4e00\u4e2a\u5373\u63d2\u5373\u7528\u7684\u90e8\u4ef6\u3002\u4e14\u4f5c\u8005\u6709\u8bad\u7ec3\u7684\u4e00\u4e2asample\u811a\u672c\u3002 \u4f5c\u8005\u5728paper\u7b2c\u4e94\u7ae0\u8282\u7ed9\u51fa\u4e86\u4e00\u4e2aobject pose estimation\u7684\u4f8b\u5b50\u3002","title":"End-to-End Learnable Geometric Vision by Backpropagating PnP Optimization"},{"location":"Building_Blocks/Bpnp/#end-to-end-learnable-geometric-vision-by-backpropagating-pnp-optimization","text":"\u8fd9\u7bc7\u8bba\u6587\u7684\u6838\u5fc3\u8d21\u732e\u662f\u5c06PnP \u4f18\u5316\u8fc7\u7a0b\u53d8\u4e3a\u4e00\u4e2a\u53ef\u5bfc\u7684\u90e8\u4ef6\u63d2\u5165\u5230\u7f51\u7edc\u4e4b\u4e2d\uff0c\u5bf9\u4e8e\u66f4\u591a\u7aef\u5230\u7aef\u7684\u6a21\u578b\u6709\u5f88\u597d\u7684\u5e2e\u52a9\u3002","title":"End-to-End Learnable Geometric Vision by Backpropagating PnP Optimization"},{"location":"Building_Blocks/Bpnp/#_1","text":"Implicit function theorem \u5bf9\u4e8e f(a^*, b^*) = 0, \u4e14 b^* = g(a^*) \u82e5\u5176\u4e2d\u7684\u96c5\u514b\u6bd4\u77e9\u9635\u53ef\u5bfc\uff0c\u6709 \\frac{\\partial g}{\\partial x_{j}}(\\mathbf{x})=-\\left[J_{f, \\mathbf{y}}(\\mathbf{x}, g(\\mathbf{x}))\\right]_{m \\times m}^{-1}\\left[\\frac{\\partial f}{\\partial x_{j}}(\\mathbf{x}, g(\\mathbf{x}))\\right]_{m \\times 1} PnP\u95ee\u9898\uff0c\u4f5c\u8005\u9009\u62e9\u7684\u63cf\u8ff0\u662f\uff0c\u5bfb\u627e6 DoF\u4f4d\u59ff\uff0c\u4f7f\u5f973D\u70b9\u57282D\u5e73\u9762\u4e0a\u7684\u6295\u5f71\u7684\u5bf9\u5e94\u70b9\u4e2a\u70b9\u5728\u56fe\u7247\u4e2d\u7684\u8bef\u5dee\u5e73\u65b9\u548c\u6700\u5c0f\uff0c \u8fd9\u91cc\u4f5c\u8005\u9009\u62e9 f \u4e3a\u8bef\u5dee\u51fd\u6570\u5173\u4e8e\u8f93\u51fa\u7684\u5bfc\u6570 \\frac{\\partial f}{\\partial y} \uff0c\u5728pnp\u4f18\u5316\u597d\u540e\uff0c\u5176\u4e2d\u8fd9\u4e2a\u5bfc\u6570\u5e94\u4e3a\u96f6\u3002 \u5177\u4f53\u8ba1\u7b97\u89c1\u4ee3\u7801\u4e0e\u8bba\u6587 \u5176\u4e2dforward\u51fd\u6570opencv\u5b8c\u6210\uff0cbackward\u51fd\u6570\u8be6\u89c1\u4ee3\u7801\u3002\u6574\u4e2a\u51fd\u6570\u53ef\u4ee5\u4f5c\u4e3a\u4e00\u4e2a\u5373\u63d2\u5373\u7528\u7684\u90e8\u4ef6\u3002\u4e14\u4f5c\u8005\u6709\u8bad\u7ec3\u7684\u4e00\u4e2asample\u811a\u672c\u3002 \u4f5c\u8005\u5728paper\u7b2c\u4e94\u7ae0\u8282\u7ed9\u51fa\u4e86\u4e00\u4e2aobject pose estimation\u7684\u4f8b\u5b50\u3002","title":"\u9690\u51fd\u6570\u5b9a\u7406"},{"location":"Building_Blocks/CBAM:Convolutional_Block_Attention_Module/","text":"CBAM: Convolutional Block Attention Module","title":"CBAM: Convolutional Block Attention Module"},{"location":"Building_Blocks/CBAM:Convolutional_Block_Attention_Module/#cbam-convolutional-block-attention-module","text":"","title":"CBAM: Convolutional Block Attention Module"},{"location":"Building_Blocks/Can GCNs Go as Deep as CNNs/","text":"Can GCNs Go as Deep as CNNs \u8fd9\u7bc7\u8bba\u6587\u662f\u8fd1\u671f\u56fe\u5377\u79ef\u7f51\u7edc\u7684\u91cd\u8981\u7a81\u7834\u4e4b\u4e00\u3002\u610f\u4e49\u5728\u4e8e\u5bf9\u57fa\u672c\u5377\u79ef\u7684\u4e00\u4e2a\u590d\u5236\uff0c\u5c06\u57fa\u7840\u5377\u79ef\u76f8\u5173\u7684\u8fde\u63a5\u7b97\u6cd5\u79fb\u690d\u5230\u56fe\u5377\u79ef\u4e2d\u3002 \u56fe\u5377\u79ef\u7f51\u7edc\u7684Res\u8fde\u63a5\u4ee5\u53caDense\u8fde\u63a5 \u4e0e\u57fa\u7840\u7684ResNet\u548cDenseNet\u4e00\u81f4\uff0cRes\u4ee3\u8868\u5c42\u8f93\u5165\u4e0e\u5c42\u8f93\u51fa\u76f8\u52a0\u3002Dense\u5219\u662f\u591a\u5c42\u8f93\u5165\u3001\u8f93\u51fa\u7684Concatenation\u3002 \u56fe\u5377\u79ef\u7f51\u7edc\u7684Dilated Convolution \u672c\u6587\u5377\u79ef\u91c7\u53d6\u7684\u65b9\u6848\u662fK-nearest-neighbor\u7684\u65b9\u6848\uff0c\u5bfb\u627e\u4e0e\u5f53\u524d\u70b9\u8ddd\u79bb\u6700\u8fd1\u7684k\u4e2a\u70b9\u8fdb\u884c\u5377\u79ef\uff0c\u82e5\u6269\u5c55\u4e3adilatedConv\uff0c\u5219\u8ddd\u79bb\u6700\u8fd1\u7684\u70b9\u8fdb\u884c\u6392\u5e8f\uff0c\u6bcf\u9694\u51e0\u4e2a\u70b9\u627e\u51fa\u4e00\u4e2a\u5377\u79ef\u70b9\u3002 \u4ece\u5b9e\u65f6\u8fd0\u7b97\u7684\u89d2\u5ea6\u6765\u770b\uff0c\u9700\u8981\u5efa\u7acb\u4e00\u4e2aKDtree\uff0c \u5bf9\u4e8e\u6bcf\u4e00\u5c42\u7684\u7f51\u7edc\u90fd\u8981\u5bf9\u6bcf\u4e00\u4e2a\u70b9\u8fdb\u884cKNN\u7684\u641c\u7d22\u3002\u5b9e\u65f6\u8fd0\u7b97\u901f\u7387\u4e00\u822c\uff0c\u4f46\u662f\u80fd\u5f97\u5230\u66f4\u597d\u7684\u7ed3\u679c\u3002","title":"Can GCNs Go as Deep as CNNs"},{"location":"Building_Blocks/Can GCNs Go as Deep as CNNs/#can-gcns-go-as-deep-as-cnns","text":"\u8fd9\u7bc7\u8bba\u6587\u662f\u8fd1\u671f\u56fe\u5377\u79ef\u7f51\u7edc\u7684\u91cd\u8981\u7a81\u7834\u4e4b\u4e00\u3002\u610f\u4e49\u5728\u4e8e\u5bf9\u57fa\u672c\u5377\u79ef\u7684\u4e00\u4e2a\u590d\u5236\uff0c\u5c06\u57fa\u7840\u5377\u79ef\u76f8\u5173\u7684\u8fde\u63a5\u7b97\u6cd5\u79fb\u690d\u5230\u56fe\u5377\u79ef\u4e2d\u3002","title":"Can GCNs Go as Deep as CNNs"},{"location":"Building_Blocks/Can GCNs Go as Deep as CNNs/#resdense","text":"\u4e0e\u57fa\u7840\u7684ResNet\u548cDenseNet\u4e00\u81f4\uff0cRes\u4ee3\u8868\u5c42\u8f93\u5165\u4e0e\u5c42\u8f93\u51fa\u76f8\u52a0\u3002Dense\u5219\u662f\u591a\u5c42\u8f93\u5165\u3001\u8f93\u51fa\u7684Concatenation\u3002","title":"\u56fe\u5377\u79ef\u7f51\u7edc\u7684Res\u8fde\u63a5\u4ee5\u53caDense\u8fde\u63a5"},{"location":"Building_Blocks/Can GCNs Go as Deep as CNNs/#dilated-convolution","text":"\u672c\u6587\u5377\u79ef\u91c7\u53d6\u7684\u65b9\u6848\u662fK-nearest-neighbor\u7684\u65b9\u6848\uff0c\u5bfb\u627e\u4e0e\u5f53\u524d\u70b9\u8ddd\u79bb\u6700\u8fd1\u7684k\u4e2a\u70b9\u8fdb\u884c\u5377\u79ef\uff0c\u82e5\u6269\u5c55\u4e3adilatedConv\uff0c\u5219\u8ddd\u79bb\u6700\u8fd1\u7684\u70b9\u8fdb\u884c\u6392\u5e8f\uff0c\u6bcf\u9694\u51e0\u4e2a\u70b9\u627e\u51fa\u4e00\u4e2a\u5377\u79ef\u70b9\u3002 \u4ece\u5b9e\u65f6\u8fd0\u7b97\u7684\u89d2\u5ea6\u6765\u770b\uff0c\u9700\u8981\u5efa\u7acb\u4e00\u4e2aKDtree\uff0c \u5bf9\u4e8e\u6bcf\u4e00\u5c42\u7684\u7f51\u7edc\u90fd\u8981\u5bf9\u6bcf\u4e00\u4e2a\u70b9\u8fdb\u884cKNN\u7684\u641c\u7d22\u3002\u5b9e\u65f6\u8fd0\u7b97\u901f\u7387\u4e00\u822c\uff0c\u4f46\u662f\u80fd\u5f97\u5230\u66f4\u597d\u7684\u7ed3\u679c\u3002","title":"\u56fe\u5377\u79ef\u7f51\u7edc\u7684Dilated Convolution"},{"location":"Building_Blocks/DGCNN/","text":"Dynamic Graph CNN for Learning on Point Clouds \u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86edgeConv\u4f5c\u4e3a\u65b0\u7684pointNet\u64cd\u4f5c\u7b26,\u5b83\u7684\u7279\u70b9\u5728\u4e8e\u8003\u8651\u4e86\u70b9\u7684\u5750\u6807\u4ee5\u53ca\u76f8\u90bb\u70b9\u7684\u8ddd\u79bb\u3002\u8fd9\u91cc\u63a8\u8350 \u4e2d\u6587\u8bba\u6587\u7b14\u8bb0 EdgeConv \u76f4\u89c9\u4ecb\u7ecd\uff0c\u7531\u4e8e\u6bcf\u4e00\u4e2a\u70b9\u7684\u7279\u5f81\u7ecf\u5e38\u5305\u542b\u5750\u6807\u3001\u989c\u8272\u7684\u4fe1\u606f\uff0c\u672c\u6587\u7684\u7b97\u6cd5\u662f\u663e\u5f0f\u5730\u8ba9\u76f8\u90bb\u7684\u70b9\u76f4\u63a5\u76f8\u4e92\u878d\u5408\u8fd0\u7b97\uff0c\u8fd9\u6837\u65b9\u4fbf\u5f97\u5230\u4e24\u8005\u7684\u5dee\u6216\u8005\u4e24\u8005\u7684\u5747\u503c\uff0c\u8fd9\u4e5f\u662f\u672c\u6587edgeConv\u7684\u540d\u5b57\u6765\u6e90\u3002 \u5b9a\u4e49\u8fb9\u7f18\u7279\u5f81 e_{ij} = h_{\\Theta}(x_i,x_j) \u5176\u4e2d h_{\\Theta} \u4e3a\u53ef\u5b66\u4e60\u7684\u975e\u7ebf\u6027\u51fd\u6570\uff0c\u8fd9\u4f1a\u8f93\u51fa F' \u4e2a\u7279\u5f81\uff0c\u5f53\u524d\u70b9\u7684\u8f93\u51fa\u4e3a\u9644\u8fd1\u591a\u4e2a\u76f8\u90bb\u8fb9\u7f18\u503c\u7684\u7efc\u5408\uff0c\u53ef\u4ee5\u662f\u6c42\u548c\u4e5f\u53ef\u4ee5\u662f\u6c42\u6700\u5927\u503c\u3002 \u5bf9 h_{\\Theta} \u7684\u5b9a\u4e49\u4e5f\u662f\u591a\u6837\u5316\u7684\uff0c1.\u5bf9\u5355\u4e2a\u5bf9\u65b9\u70b9\u7684\u52a0\u6743\u6c42\u548c;2.\u5bf9\u672c\u5730\u70b9\u7279\u5f81\u7684\u52a0\u6743\u6c42\u548c(\u4e0epointNet\u4e00\u81f4);3. h_{\\Theta}(x_i,x_j) = h_\\Theta(x_j - x_i) \u8fd9\u6837\u5c31\u53ea\u4f1a\u6709\u5c40\u90e8\u4fe1\u606f\u5dee\u503c\u800c\u7f3a\u5c11\u5168\u5c40\u4fe1\u606f(\u5f53\u524d\u70b9\u7684\u5168\u5c40\u4f4d\u7f6e);4. h_\\Theta(x_i,x_j) = h_\\Theta(x_i, x_j - x_i) \u4ece\u800c\u7efc\u5408\u5168\u5c40\u4e0e\u5c40\u90e8\u4fe1\u606f\uff0c\u4e5f\u662f\u4e3b\u6d41\u9009\u62e9\u3002(\u539f\u8bba\u6587\u8fd8\u63d0\u5230\u4e00\u79cd\u4f7f\u7528\u9ad8\u65af\u6838\u7684\u65b9\u6cd5\uff0c\u8fd9\u91cc\u7701\u7565) \u7efc\u5408\u4e0d\u540c\u8fb9\u7f18\u7684\u8fd0\u7b97\u7b26\u9009\u62e9\u7684\u662fmax\uff0c\u8fd9\u6837\u6574\u4e2a\u8ba1\u7b97\u53ef\u4ee5\u7528\u4e00\u4e2a\u5171\u4eab\u53c2\u6570\u7684MLP\u5b9e\u73b0\u3002 \u52a8\u6001\u91cd\u7ec4 \u4e00\u4e9b\u4f20\u7edf\u7684pointnet\u4f1a\u5c06\u70b9\u7684\u4f4d\u7f6e\u56fa\u5b9a\u4e0b\u6765\uff0c\u6bcf\u6b21\u7684\u5377\u79ef\u90fd\u53ea\u5728\u70b9\u539f\u6765\u7684\u76f8\u90bb\u8fb9\u4e2d\u6311\u9009\u3002\u672c\u6587\u7684\u601d\u8def\u662f\u6bcf\u5c42\u8fd0\u7b97\u540e\uff0c\u7528\u65b0\u7684\u7279\u5f81\u4f5c\u4e3afeature vector\uff0c\u5728\u6574\u4e2a\u70b9\u4e91\u4e2d\u91cd\u65b0\u8fdb\u884cKNN\u8fd0\u7b97\u627e\u5728\u65b0\u7279\u5f81\u6761\u4ef6\u4e0b\u6700\u9760\u8fd1\u7684\u70b9\u3002\u5982\u6b64\u4ee5\u6765\u6bcf\u4e00\u5c42\u8fd0\u7b97\u540e\u70b9\u7684\u90bb\u57df\u90fd\u4f1a\u88ab\u6d17\u4e71\u3002 \u7f51\u7edc\u603b\u4f53\u7ed3\u6784 \u4ee5PointNet\u4e3a\u57fa\u7840\u3002\u5177\u4f53\u53ef\u4ee5\u89c2\u5bdf\u4ee3\u7801\u4ee5\u53ca\u56fe\u7247\u89e3\u91ca\u3002","title":"Dynamic Graph CNN for Learning on Point Clouds"},{"location":"Building_Blocks/DGCNN/#dynamic-graph-cnn-for-learning-on-point-clouds","text":"\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86edgeConv\u4f5c\u4e3a\u65b0\u7684pointNet\u64cd\u4f5c\u7b26,\u5b83\u7684\u7279\u70b9\u5728\u4e8e\u8003\u8651\u4e86\u70b9\u7684\u5750\u6807\u4ee5\u53ca\u76f8\u90bb\u70b9\u7684\u8ddd\u79bb\u3002\u8fd9\u91cc\u63a8\u8350 \u4e2d\u6587\u8bba\u6587\u7b14\u8bb0","title":"Dynamic Graph CNN for Learning on Point Clouds"},{"location":"Building_Blocks/DGCNN/#edgeconv","text":"\u76f4\u89c9\u4ecb\u7ecd\uff0c\u7531\u4e8e\u6bcf\u4e00\u4e2a\u70b9\u7684\u7279\u5f81\u7ecf\u5e38\u5305\u542b\u5750\u6807\u3001\u989c\u8272\u7684\u4fe1\u606f\uff0c\u672c\u6587\u7684\u7b97\u6cd5\u662f\u663e\u5f0f\u5730\u8ba9\u76f8\u90bb\u7684\u70b9\u76f4\u63a5\u76f8\u4e92\u878d\u5408\u8fd0\u7b97\uff0c\u8fd9\u6837\u65b9\u4fbf\u5f97\u5230\u4e24\u8005\u7684\u5dee\u6216\u8005\u4e24\u8005\u7684\u5747\u503c\uff0c\u8fd9\u4e5f\u662f\u672c\u6587edgeConv\u7684\u540d\u5b57\u6765\u6e90\u3002 \u5b9a\u4e49\u8fb9\u7f18\u7279\u5f81 e_{ij} = h_{\\Theta}(x_i,x_j) \u5176\u4e2d h_{\\Theta} \u4e3a\u53ef\u5b66\u4e60\u7684\u975e\u7ebf\u6027\u51fd\u6570\uff0c\u8fd9\u4f1a\u8f93\u51fa F' \u4e2a\u7279\u5f81\uff0c\u5f53\u524d\u70b9\u7684\u8f93\u51fa\u4e3a\u9644\u8fd1\u591a\u4e2a\u76f8\u90bb\u8fb9\u7f18\u503c\u7684\u7efc\u5408\uff0c\u53ef\u4ee5\u662f\u6c42\u548c\u4e5f\u53ef\u4ee5\u662f\u6c42\u6700\u5927\u503c\u3002 \u5bf9 h_{\\Theta} \u7684\u5b9a\u4e49\u4e5f\u662f\u591a\u6837\u5316\u7684\uff0c1.\u5bf9\u5355\u4e2a\u5bf9\u65b9\u70b9\u7684\u52a0\u6743\u6c42\u548c;2.\u5bf9\u672c\u5730\u70b9\u7279\u5f81\u7684\u52a0\u6743\u6c42\u548c(\u4e0epointNet\u4e00\u81f4);3. h_{\\Theta}(x_i,x_j) = h_\\Theta(x_j - x_i) \u8fd9\u6837\u5c31\u53ea\u4f1a\u6709\u5c40\u90e8\u4fe1\u606f\u5dee\u503c\u800c\u7f3a\u5c11\u5168\u5c40\u4fe1\u606f(\u5f53\u524d\u70b9\u7684\u5168\u5c40\u4f4d\u7f6e);4. h_\\Theta(x_i,x_j) = h_\\Theta(x_i, x_j - x_i) \u4ece\u800c\u7efc\u5408\u5168\u5c40\u4e0e\u5c40\u90e8\u4fe1\u606f\uff0c\u4e5f\u662f\u4e3b\u6d41\u9009\u62e9\u3002(\u539f\u8bba\u6587\u8fd8\u63d0\u5230\u4e00\u79cd\u4f7f\u7528\u9ad8\u65af\u6838\u7684\u65b9\u6cd5\uff0c\u8fd9\u91cc\u7701\u7565) \u7efc\u5408\u4e0d\u540c\u8fb9\u7f18\u7684\u8fd0\u7b97\u7b26\u9009\u62e9\u7684\u662fmax\uff0c\u8fd9\u6837\u6574\u4e2a\u8ba1\u7b97\u53ef\u4ee5\u7528\u4e00\u4e2a\u5171\u4eab\u53c2\u6570\u7684MLP\u5b9e\u73b0\u3002","title":"EdgeConv"},{"location":"Building_Blocks/DGCNN/#_1","text":"\u4e00\u4e9b\u4f20\u7edf\u7684pointnet\u4f1a\u5c06\u70b9\u7684\u4f4d\u7f6e\u56fa\u5b9a\u4e0b\u6765\uff0c\u6bcf\u6b21\u7684\u5377\u79ef\u90fd\u53ea\u5728\u70b9\u539f\u6765\u7684\u76f8\u90bb\u8fb9\u4e2d\u6311\u9009\u3002\u672c\u6587\u7684\u601d\u8def\u662f\u6bcf\u5c42\u8fd0\u7b97\u540e\uff0c\u7528\u65b0\u7684\u7279\u5f81\u4f5c\u4e3afeature vector\uff0c\u5728\u6574\u4e2a\u70b9\u4e91\u4e2d\u91cd\u65b0\u8fdb\u884cKNN\u8fd0\u7b97\u627e\u5728\u65b0\u7279\u5f81\u6761\u4ef6\u4e0b\u6700\u9760\u8fd1\u7684\u70b9\u3002\u5982\u6b64\u4ee5\u6765\u6bcf\u4e00\u5c42\u8fd0\u7b97\u540e\u70b9\u7684\u90bb\u57df\u90fd\u4f1a\u88ab\u6d17\u4e71\u3002","title":"\u52a8\u6001\u91cd\u7ec4"},{"location":"Building_Blocks/DGCNN/#_2","text":"\u4ee5PointNet\u4e3a\u57fa\u7840\u3002\u5177\u4f53\u53ef\u4ee5\u89c2\u5bdf\u4ee3\u7801\u4ee5\u53ca\u56fe\u7247\u89e3\u91ca\u3002","title":"\u7f51\u7edc\u603b\u4f53\u7ed3\u6784"},{"location":"Building_Blocks/DO-Conv/","text":"DO-Conv: Depthwise Over-parameterized Convolutional Layer \u4f5c\u8005\u5f15\u5165\u4e86over-parameterized\u7684\u5377\u79ef\u5c42\uff0c\u8fd9\u79cd\u5377\u79ef\u5c42\u7684\u597d\u5904\u662f\u5728training\u7684\u65f6\u5019\u5bb9\u6613\u8bad\u7ec3\uff0c\u5728inference\u7684\u65f6\u5019\u53ef\u4ee5\u5c06\u5bbd\u53c2\u6570\u878d\u5408\uff0c\u5f97\u5230\u5355\u4e2a\u5377\u79ef\u5c42\u8fdb\u884c\u63a8\u7406\u3002 \\begin{aligned} \\mathbb{O} &=(\\mathbb{D}, \\mathbb{W}) \\otimes \\mathbb{P} \\\\ &=\\mathbb{W} *(\\mathbb{D} \\circ \\mathbb{P}) \\quad \\text { (Fig. 3-a, feature composition) } \\\\ &=\\left(\\mathbb{D}^{T} \\circ \\mathbb{W}\\right) * \\mathbb{P}, \\quad \\text { (Fig. 3-b, kernel composition) } \\end{aligned}","title":"DO-Conv: Depthwise Over-parameterized Convolutional Layer"},{"location":"Building_Blocks/DO-Conv/#do-conv-depthwise-over-parameterized-convolutional-layer","text":"\u4f5c\u8005\u5f15\u5165\u4e86over-parameterized\u7684\u5377\u79ef\u5c42\uff0c\u8fd9\u79cd\u5377\u79ef\u5c42\u7684\u597d\u5904\u662f\u5728training\u7684\u65f6\u5019\u5bb9\u6613\u8bad\u7ec3\uff0c\u5728inference\u7684\u65f6\u5019\u53ef\u4ee5\u5c06\u5bbd\u53c2\u6570\u878d\u5408\uff0c\u5f97\u5230\u5355\u4e2a\u5377\u79ef\u5c42\u8fdb\u884c\u63a8\u7406\u3002 \\begin{aligned} \\mathbb{O} &=(\\mathbb{D}, \\mathbb{W}) \\otimes \\mathbb{P} \\\\ &=\\mathbb{W} *(\\mathbb{D} \\circ \\mathbb{P}) \\quad \\text { (Fig. 3-a, feature composition) } \\\\ &=\\left(\\mathbb{D}^{T} \\circ \\mathbb{W}\\right) * \\mathbb{P}, \\quad \\text { (Fig. 3-b, kernel composition) } \\end{aligned}","title":"DO-Conv: Depthwise Over-parameterized Convolutional Layer"},{"location":"Building_Blocks/DiCENet/","text":"DiCENet: Dimension-wise Convolutions for Efficient Networks \u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86DiCE\u6a21\u5757\uff0cDiCE\u6a21\u5757\u662f\u53ef\u4ee5\u7406\u89e3\u4e3a\u662f\u5347\u7ea7\u7248\u7684pointwise convolusion(\u6bcf\u4e2aspatial location\u4e0d\u540c\u5377\u79ef\u6838)\u6216\u8005 depthwise convolution (\u672c\u6587\u4f5c\u8005\u5c06\u5176\u7406\u89e3\u4e3aHeight-wise convolution) \u76ee\u524d\u8fd9\u91cc\u9009\u8bfb\u8fd9\u4e00\u7bc7\u662f\u56e0\u4e3a\u770b\u597d\u5b83\u5728\u5355\u76ee3D\u68c0\u6d4b\u4e2d\u7684\u6f5c\u529b\u3002\u56e0\u4e3a\u5b83\u5728\u591a\u4e2a\u8f74\u4e0a\u5206\u7ec4\u5377\u79ef\uff0c\u4f1a\u5f7b\u5e95\u6253\u7834\u7cfb\u7edf\u7684\u5e73\u79fb\u4e0d\u53d8\u6027\u4ee5\u53ca\u5bf9\u79f0\u6027\u3002 DiCE unit depth-wise convolution\u6307\u4ee3\u7684\u662f\u57fa\u7840\u7684\u5206\u7ec4\u5377\u79ef width-wise convolution\u4e0eheight-wise\u7684\u7b97\u6cd5\u662f\u5c06\u5bf9\u5e94\u7ef4\u5ea6\u65cb\u8f6c\u5230dim=1\u5904(pytorch cnn\u9ed8\u8ba4\u7684\u7279\u5f81\u7ef4\u5ea6)\uff0c\u7136\u540e\u76f4\u63a5\u5206\u7ec4CNN \u518dtranspose\u56de\u53bb\uff0c\u4e09\u4e2a\u5206\u652f\u5f97\u5230\u4e09\u4e2a C H W \u7684\u77e9\u9635 \u5408\u5e76\u7684\u65b9\u6cd5\uff0c\u4f5c\u8005\u4ee3\u7801\u7684\u7b97\u6cd5\u662f\u5148torch.cat,\u7136\u540e\u6267\u884c channel shuffle .\u76f4\u63a5\u7cc5\u5408\u8d77\u6765\u7684\u4ee3\u7801\u662fstack(dim=2) -> reshape \u5408\u5e76\u4e4b\u540e\u4f7f\u7528\u5206\u7ec4\u5377\u79ef\u878d\u5408\u6765\u81ea\u4e0d\u540c\u5206\u652f\u7684\u7279\u5f81\uff0c\u6b64\u540e\u518d\u5206\u652f\uff0c\u6a21\u4eff\u7684\u662f Squeeze_and_excitation .\u5176\u4e2d\u4e00\u4e2a\u5206\u652f\u901a\u8fc7spatial\u5e73\u5747\u4e0eFC\u8fde\u63a5\u5f97\u5230channel wise\u7684\u6743\u91cd\uff0c\u7136\u540e\u505a\u4e00\u4e2a\u5206\u7ec4\u5377\u79ef\u5f97\u5230 Y_S \uff0c\u4e24\u8005\u76f8\u4e58\u8f93\u51fa\u3002 \u4e0d\u540c\u5f62\u72b6\u7684\u8f93\u5165 \u672c\u6587\u8fd9\u91cc\u4f7f\u7528\u7684\u662fpytorch\u7684\u81ea\u9002\u5e94avgpool\u6765\u5177\u4f53\u5b9e\u73b0\u3002","title":"DiCENet: Dimension-wise Convolutions for Efficient Networks"},{"location":"Building_Blocks/DiCENet/#dicenet-dimension-wise-convolutions-for-efficient-networks","text":"\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86DiCE\u6a21\u5757\uff0cDiCE\u6a21\u5757\u662f\u53ef\u4ee5\u7406\u89e3\u4e3a\u662f\u5347\u7ea7\u7248\u7684pointwise convolusion(\u6bcf\u4e2aspatial location\u4e0d\u540c\u5377\u79ef\u6838)\u6216\u8005 depthwise convolution (\u672c\u6587\u4f5c\u8005\u5c06\u5176\u7406\u89e3\u4e3aHeight-wise convolution) \u76ee\u524d\u8fd9\u91cc\u9009\u8bfb\u8fd9\u4e00\u7bc7\u662f\u56e0\u4e3a\u770b\u597d\u5b83\u5728\u5355\u76ee3D\u68c0\u6d4b\u4e2d\u7684\u6f5c\u529b\u3002\u56e0\u4e3a\u5b83\u5728\u591a\u4e2a\u8f74\u4e0a\u5206\u7ec4\u5377\u79ef\uff0c\u4f1a\u5f7b\u5e95\u6253\u7834\u7cfb\u7edf\u7684\u5e73\u79fb\u4e0d\u53d8\u6027\u4ee5\u53ca\u5bf9\u79f0\u6027\u3002","title":"DiCENet: Dimension-wise Convolutions for Efficient Networks"},{"location":"Building_Blocks/DiCENet/#dice-unit","text":"depth-wise convolution\u6307\u4ee3\u7684\u662f\u57fa\u7840\u7684\u5206\u7ec4\u5377\u79ef width-wise convolution\u4e0eheight-wise\u7684\u7b97\u6cd5\u662f\u5c06\u5bf9\u5e94\u7ef4\u5ea6\u65cb\u8f6c\u5230dim=1\u5904(pytorch cnn\u9ed8\u8ba4\u7684\u7279\u5f81\u7ef4\u5ea6)\uff0c\u7136\u540e\u76f4\u63a5\u5206\u7ec4CNN \u518dtranspose\u56de\u53bb\uff0c\u4e09\u4e2a\u5206\u652f\u5f97\u5230\u4e09\u4e2a C H W \u7684\u77e9\u9635 \u5408\u5e76\u7684\u65b9\u6cd5\uff0c\u4f5c\u8005\u4ee3\u7801\u7684\u7b97\u6cd5\u662f\u5148torch.cat,\u7136\u540e\u6267\u884c channel shuffle .\u76f4\u63a5\u7cc5\u5408\u8d77\u6765\u7684\u4ee3\u7801\u662fstack(dim=2) -> reshape \u5408\u5e76\u4e4b\u540e\u4f7f\u7528\u5206\u7ec4\u5377\u79ef\u878d\u5408\u6765\u81ea\u4e0d\u540c\u5206\u652f\u7684\u7279\u5f81\uff0c\u6b64\u540e\u518d\u5206\u652f\uff0c\u6a21\u4eff\u7684\u662f Squeeze_and_excitation .\u5176\u4e2d\u4e00\u4e2a\u5206\u652f\u901a\u8fc7spatial\u5e73\u5747\u4e0eFC\u8fde\u63a5\u5f97\u5230channel wise\u7684\u6743\u91cd\uff0c\u7136\u540e\u505a\u4e00\u4e2a\u5206\u7ec4\u5377\u79ef\u5f97\u5230 Y_S \uff0c\u4e24\u8005\u76f8\u4e58\u8f93\u51fa\u3002","title":"DiCE unit"},{"location":"Building_Blocks/DiCENet/#_1","text":"\u672c\u6587\u8fd9\u91cc\u4f7f\u7528\u7684\u662fpytorch\u7684\u81ea\u9002\u5e94avgpool\u6765\u5177\u4f53\u5b9e\u73b0\u3002","title":"\u4e0d\u540c\u5f62\u72b6\u7684\u8f93\u5165"},{"location":"Building_Blocks/Discovery_of_Latent_3D_Keypoints_via_End-to-end_Geometric_Reasoning/","text":"Discovery of Latent 3D Keypoints via End-to-end Geometric Reasoning \u8fd9\u7bc7\u8bba\u6587\u5b8c\u6210\u7684\u4efb\u52a1\u662f\uff0c\u5bf9\u5355\u5f20\u56fe\u7247\u8f93\u51fa\u4e00\u7cfb\u5217\u6709\u5e8f\u7684keypoints\uff0c\u8fd9\u4e9bkeypoints\u5728\u4e0d\u540c\u89c6\u89d2\u4e0b\u6709\u76f8\u540c\u7684\u8868\u8fbe\u3002\u8bad\u7ec3\u65f6\u5219\u901a\u8fc7\u540c\u4e00\u7269\u4f53\u4e0d\u540c\u89c6\u89d2\u7684\u4e00\u5bf9\u56fe\u7247\u8fdb\u884c\u8bad\u7ec3\u3002 \u4e3b\u4f53Pipeline \u5df2\u77e5\u7684\u76f8\u5bf9\u521a\u4f53\u8fd0\u52a8\u4f5c\u4e3a\u76d1\u7763\u4fe1\u53f7\u3002inference\u7684\u65f6\u5019\uff0cKeypointNet\u4ece\u5355\u4e2a\u8f93\u5165\u56fe\u4e2d\u8f93\u51fa3D\u5173\u952e\u70b9 \u5177\u4f53\u4ecb\u7ecd \u4e00\u4e2a3D keypoint\u88ab\u5b9a\u4e49\u4e3a\u50cf\u7d20\u5750\u6807\u52a0\u4e0a\u5bf9\u5e94\u7684\u6df1\u5ea6\u503c\u3002\u7f51\u7edc\u8f93\u51fa N\u4e2a\u5206\u652f\uff0c\u9884\u6d4bN\u4e2a\u5173\u952e\u70b9\u3002 \u76ee\u6807\u51fd\u6570\u7531\u4e24\u4e2a\u90e8\u5206\u7ec4\u6210 Multi-view Consistency \u63cf\u8ff0\u4e24\u7ec4\u70b9\u5728ground truth\u8f6c\u6362\u524d\u540e\u70b9\u7684\u8ddd\u79bb \\begin{aligned}[\\hat{u}, \\hat{v}, \\hat{z}, 1]^{\\top} & \\sim \\pi T \\pi^{-1}\\left([u, v, z, 1]^{\\top}\\right) \\\\\\left[\\hat{u}^{\\prime}, \\hat{v}^{\\prime}, \\hat{z}^{\\prime}, 1\\right]^{\\top} & \\sim \\pi T^{-1} \\pi^{-1}\\left(\\left[u^{\\prime}, v^{\\prime}, z^{\\prime}, 1\\right]^{\\top}\\right) \\end{aligned} \\pi\\left([x, y, z, 1]^{\\top}\\right)=\\left[\\frac{f x}{z}, \\frac{f y}{z}, z, 1\\right]^{\\top}=[u, v, z, 1]^{\\top} L_{\\mathrm{con}}=\\frac{1}{2 N} \\sum_{i=1}^{N}\\left\\|\\left[u_{i}, v_{i}, u_{i}^{\\prime}, v_{i}^{\\prime}\\right]^{\\top}-\\left[\\hat{u}_{i}^{\\prime}, \\hat{v}_{i}^{\\prime}, \\hat{u}_{i}, \\hat{v}_{i}\\right]^{\\top}\\right\\|^{2} \u672c\u8d28\u4e0a\u5c31\u662f\u5c06A\u56fe\u4e0a\u7684\u70b9\u8f6c\u6362\u5230B\u56fe\u4e0a\u6c42\u5dee\u503c\uff0c\u518d\u5c06B\u56fe\u4e0a\u7684\u70b9\u8f6c\u6362\u5230A\u56fe\u4e0a\u6c42\u5dee\u503c\uff0c\u6c42\u548c\u3002 \u76f8\u5bf9\u59ff\u6001\u4f30\u8ba1\u3002 \u8fd9\u91cc\u53ea\u8981\u6c42\u5bf9\u4f30\u8ba1\u7684\u65cb\u8f6c\u77e9\u9635\u8ba1\u7b97loss L_{\\mathrm{pose}}=2 \\arcsin \\left(\\frac{1}{2 \\sqrt{2}}\\|\\hat{R}-R\\|_{F}\\right) \u5176\u4e2d\u4f30\u8ba1 \\hat R ,\u4ee4 X \u548c X' \u6307\u4ee3\u4e24\u4e2a\u56fe\u8ba1\u7b97\u51fa\u6765\u7684keypoints\u7684 X \\equiv\\left[X_{1}, \\ldots, X_{N}\\right] and X_{i} \\equiv\\left(\\pi^{-1} p_{i}\\right)[: 3] \\hat{R}=V \\operatorname{diag}\\left(1,1, \\ldots, \\operatorname{det}\\left(V U^{\\top}\\right)\\right) U^{\\top} U, \\Sigma, V^{\\top}=\\operatorname{SVD}\\left(\\tilde{X} \\tilde{X}^{\\prime \\top}\\right) \u8fd9\u4e2a\u65b9\u6cd5\u88ab\u79f0\u4e3a Procrustes problem SVD\u662f\u53ef\u4ee5backprob\u7684\u5b9e\u73b0\u7684(\u540c\u6837\u4f7f\u7528\u53ef\u5fae\u5206SVD\u7684 \u8fd9\u7bc7\u6587\u7ae0 \u4e5f\u63d0\u5230tensorflow\u6709\u53ef\u5fae\u5206SVD) KeypointNet \u7ed3\u6784 \u672c\u6587\u4f7f\u7528\u7684KeypointNet,\u4e00\u4e2a\u91cd\u8981\u7684\u6027\u8d28\u5728\u4e8e\u5e73\u79fb\u7b49\u4ef7\uff0c\u4e5f\u5c31\u662f\u8bf4\u5e73\u79fb\u4e00\u4e2a\u50cf\u7d20\uff0c\u8f93\u51fa\u4f4d\u7f6e\u4e5f\u4f1a\u79fb\u52a8\u4e00\u4e2a\u5355\u4f4d\u3002\u8981\u6c42\u8f93\u51faheatmap g_i(u,v) \u4ee3\u8868\u7b2c i \u4e2akeypoint\u51fa\u73b0\u5728 (u,v) ,\u8981\u6c42 \\sum_{u,v}g_i(u,v)=1 \u4f7f\u7528spatial softmax\u53bb\u5b9e\u73b0\u3002 \u7528\u52a0\u6743\u5e73\u5747\u6c42\u51fa\u5bf9\u5e94keypoint\u7684\u4f4d\u7f6e\u4ee5\u53ca\u6df1\u5ea6 [u_i,v_i]^T = \\sum_{u,v}[u * g_i(u,v), v * g_i(u,v)]^T z_i = \\sum_{u,v}d_i(u,v)g_i(u,v) \u8f85\u52a9training \u5206\u79bbloss:\u5bf9\u8fc7\u4e8e\u9760\u8fd1\u7684keypoints\u7ed9\u4e00\u4e2aloss L_{\\mathrm{sep}}=\\frac{1}{N^{2}} \\sum_{i=1}^{N} \\sum_{j \\neq i}^{N} \\max \\left(0, \\delta^{2}-\\left\\|X_{i}-X_{j}\\right\\|^{2}\\right) \u8f6e\u5ed3\u4e00\u81f4\u6027:\u9f13\u52b1keypoints\u5728\u7269\u4f53\u5185\u90e8\uff0c\u539f\u56e0\u662ftraining\u7684\u65f6\u5019\u80fd\u5f97\u5230\u56fe\u7247\u6bcf\u4e00\u4e2a\u5750\u6807\u662f\u5426\u5bf9\u5e94\u4e00\u4e2aobject\uff0c\u8fd9\u4e2amask\u6807\u8bb0\u4e3a b(u,v)\\in{0,1} L_{obj} = \\frac{1}{N}\\sum^N_{i=1} - log\\sum_{u,v}b(u,v)g_i(u,v)","title":"Discovery of Latent 3D Keypoints via End-to-end Geometric Reasoning"},{"location":"Building_Blocks/Discovery_of_Latent_3D_Keypoints_via_End-to-end_Geometric_Reasoning/#discovery-of-latent-3d-keypoints-via-end-to-end-geometric-reasoning","text":"\u8fd9\u7bc7\u8bba\u6587\u5b8c\u6210\u7684\u4efb\u52a1\u662f\uff0c\u5bf9\u5355\u5f20\u56fe\u7247\u8f93\u51fa\u4e00\u7cfb\u5217\u6709\u5e8f\u7684keypoints\uff0c\u8fd9\u4e9bkeypoints\u5728\u4e0d\u540c\u89c6\u89d2\u4e0b\u6709\u76f8\u540c\u7684\u8868\u8fbe\u3002\u8bad\u7ec3\u65f6\u5219\u901a\u8fc7\u540c\u4e00\u7269\u4f53\u4e0d\u540c\u89c6\u89d2\u7684\u4e00\u5bf9\u56fe\u7247\u8fdb\u884c\u8bad\u7ec3\u3002","title":"Discovery of Latent 3D Keypoints via End-to-end Geometric Reasoning"},{"location":"Building_Blocks/Discovery_of_Latent_3D_Keypoints_via_End-to-end_Geometric_Reasoning/#pipeline","text":"\u5df2\u77e5\u7684\u76f8\u5bf9\u521a\u4f53\u8fd0\u52a8\u4f5c\u4e3a\u76d1\u7763\u4fe1\u53f7\u3002inference\u7684\u65f6\u5019\uff0cKeypointNet\u4ece\u5355\u4e2a\u8f93\u5165\u56fe\u4e2d\u8f93\u51fa3D\u5173\u952e\u70b9","title":"\u4e3b\u4f53Pipeline"},{"location":"Building_Blocks/Discovery_of_Latent_3D_Keypoints_via_End-to-end_Geometric_Reasoning/#_1","text":"\u4e00\u4e2a3D keypoint\u88ab\u5b9a\u4e49\u4e3a\u50cf\u7d20\u5750\u6807\u52a0\u4e0a\u5bf9\u5e94\u7684\u6df1\u5ea6\u503c\u3002\u7f51\u7edc\u8f93\u51fa N\u4e2a\u5206\u652f\uff0c\u9884\u6d4bN\u4e2a\u5173\u952e\u70b9\u3002 \u76ee\u6807\u51fd\u6570\u7531\u4e24\u4e2a\u90e8\u5206\u7ec4\u6210","title":"\u5177\u4f53\u4ecb\u7ecd"},{"location":"Building_Blocks/Discovery_of_Latent_3D_Keypoints_via_End-to-end_Geometric_Reasoning/#multi-view-consistency","text":"\u63cf\u8ff0\u4e24\u7ec4\u70b9\u5728ground truth\u8f6c\u6362\u524d\u540e\u70b9\u7684\u8ddd\u79bb \\begin{aligned}[\\hat{u}, \\hat{v}, \\hat{z}, 1]^{\\top} & \\sim \\pi T \\pi^{-1}\\left([u, v, z, 1]^{\\top}\\right) \\\\\\left[\\hat{u}^{\\prime}, \\hat{v}^{\\prime}, \\hat{z}^{\\prime}, 1\\right]^{\\top} & \\sim \\pi T^{-1} \\pi^{-1}\\left(\\left[u^{\\prime}, v^{\\prime}, z^{\\prime}, 1\\right]^{\\top}\\right) \\end{aligned} \\pi\\left([x, y, z, 1]^{\\top}\\right)=\\left[\\frac{f x}{z}, \\frac{f y}{z}, z, 1\\right]^{\\top}=[u, v, z, 1]^{\\top} L_{\\mathrm{con}}=\\frac{1}{2 N} \\sum_{i=1}^{N}\\left\\|\\left[u_{i}, v_{i}, u_{i}^{\\prime}, v_{i}^{\\prime}\\right]^{\\top}-\\left[\\hat{u}_{i}^{\\prime}, \\hat{v}_{i}^{\\prime}, \\hat{u}_{i}, \\hat{v}_{i}\\right]^{\\top}\\right\\|^{2} \u672c\u8d28\u4e0a\u5c31\u662f\u5c06A\u56fe\u4e0a\u7684\u70b9\u8f6c\u6362\u5230B\u56fe\u4e0a\u6c42\u5dee\u503c\uff0c\u518d\u5c06B\u56fe\u4e0a\u7684\u70b9\u8f6c\u6362\u5230A\u56fe\u4e0a\u6c42\u5dee\u503c\uff0c\u6c42\u548c\u3002","title":"Multi-view Consistency"},{"location":"Building_Blocks/Discovery_of_Latent_3D_Keypoints_via_End-to-end_Geometric_Reasoning/#_2","text":"\u8fd9\u91cc\u53ea\u8981\u6c42\u5bf9\u4f30\u8ba1\u7684\u65cb\u8f6c\u77e9\u9635\u8ba1\u7b97loss L_{\\mathrm{pose}}=2 \\arcsin \\left(\\frac{1}{2 \\sqrt{2}}\\|\\hat{R}-R\\|_{F}\\right) \u5176\u4e2d\u4f30\u8ba1 \\hat R ,\u4ee4 X \u548c X' \u6307\u4ee3\u4e24\u4e2a\u56fe\u8ba1\u7b97\u51fa\u6765\u7684keypoints\u7684 X \\equiv\\left[X_{1}, \\ldots, X_{N}\\right] and X_{i} \\equiv\\left(\\pi^{-1} p_{i}\\right)[: 3] \\hat{R}=V \\operatorname{diag}\\left(1,1, \\ldots, \\operatorname{det}\\left(V U^{\\top}\\right)\\right) U^{\\top} U, \\Sigma, V^{\\top}=\\operatorname{SVD}\\left(\\tilde{X} \\tilde{X}^{\\prime \\top}\\right) \u8fd9\u4e2a\u65b9\u6cd5\u88ab\u79f0\u4e3a Procrustes problem SVD\u662f\u53ef\u4ee5backprob\u7684\u5b9e\u73b0\u7684(\u540c\u6837\u4f7f\u7528\u53ef\u5fae\u5206SVD\u7684 \u8fd9\u7bc7\u6587\u7ae0 \u4e5f\u63d0\u5230tensorflow\u6709\u53ef\u5fae\u5206SVD)","title":"\u76f8\u5bf9\u59ff\u6001\u4f30\u8ba1\u3002"},{"location":"Building_Blocks/Discovery_of_Latent_3D_Keypoints_via_End-to-end_Geometric_Reasoning/#keypointnet","text":"\u672c\u6587\u4f7f\u7528\u7684KeypointNet,\u4e00\u4e2a\u91cd\u8981\u7684\u6027\u8d28\u5728\u4e8e\u5e73\u79fb\u7b49\u4ef7\uff0c\u4e5f\u5c31\u662f\u8bf4\u5e73\u79fb\u4e00\u4e2a\u50cf\u7d20\uff0c\u8f93\u51fa\u4f4d\u7f6e\u4e5f\u4f1a\u79fb\u52a8\u4e00\u4e2a\u5355\u4f4d\u3002\u8981\u6c42\u8f93\u51faheatmap g_i(u,v) \u4ee3\u8868\u7b2c i \u4e2akeypoint\u51fa\u73b0\u5728 (u,v) ,\u8981\u6c42 \\sum_{u,v}g_i(u,v)=1 \u4f7f\u7528spatial softmax\u53bb\u5b9e\u73b0\u3002 \u7528\u52a0\u6743\u5e73\u5747\u6c42\u51fa\u5bf9\u5e94keypoint\u7684\u4f4d\u7f6e\u4ee5\u53ca\u6df1\u5ea6 [u_i,v_i]^T = \\sum_{u,v}[u * g_i(u,v), v * g_i(u,v)]^T z_i = \\sum_{u,v}d_i(u,v)g_i(u,v)","title":"KeypointNet \u7ed3\u6784"},{"location":"Building_Blocks/Discovery_of_Latent_3D_Keypoints_via_End-to-end_Geometric_Reasoning/#training","text":"\u5206\u79bbloss:\u5bf9\u8fc7\u4e8e\u9760\u8fd1\u7684keypoints\u7ed9\u4e00\u4e2aloss L_{\\mathrm{sep}}=\\frac{1}{N^{2}} \\sum_{i=1}^{N} \\sum_{j \\neq i}^{N} \\max \\left(0, \\delta^{2}-\\left\\|X_{i}-X_{j}\\right\\|^{2}\\right) \u8f6e\u5ed3\u4e00\u81f4\u6027:\u9f13\u52b1keypoints\u5728\u7269\u4f53\u5185\u90e8\uff0c\u539f\u56e0\u662ftraining\u7684\u65f6\u5019\u80fd\u5f97\u5230\u56fe\u7247\u6bcf\u4e00\u4e2a\u5750\u6807\u662f\u5426\u5bf9\u5e94\u4e00\u4e2aobject\uff0c\u8fd9\u4e2amask\u6807\u8bb0\u4e3a b(u,v)\\in{0,1} L_{obj} = \\frac{1}{N}\\sum^N_{i=1} - log\\sum_{u,v}b(u,v)g_i(u,v)","title":"\u8f85\u52a9training"},{"location":"Building_Blocks/DynamicFilteringNetwork_Fewshot/","text":"Dynamic Conditional Networks for Few-Shot Learning \u672c\u6587\u4f7f\u7528class\u7684\u6587\u5b57 embedding \u4f5c\u4e3a convolution \u7684 guidance \u6765\u5b8c\u6210few-shot learning\u7684\u4efb\u52a1\u3002 \u8fd9\u91cc\u4ec5\u4ecb\u7ecd\u5176\u5f00\u6e90\u7684\u90e8\u5206,\u4e5f\u5c31\u662f dynamic filtering network\u90e8\u5206. Dynamic Filtering Network \u7b97\u6cd5\u4e0a\u4e3a\u521d\u59cb\u5316 N \u4e2a\u6743\u91cd\u7ec4\uff0cembedding\u8f93\u51fa\u4e00\u4e2a N \u7ef4\u7684\u5206\u7c7b\u77e2\u91cf\uff0c\u5c06 N \u4e2a\u6743\u91cd\u52a0\u6743\u6c42\u548c\uff0c\u4f5c\u4e3a\u4e3b\u7ebf\u4e0aConv2D\u7684\u6743\u91cd\u3002","title":"Dynamic Conditional Networks for Few-Shot Learning"},{"location":"Building_Blocks/DynamicFilteringNetwork_Fewshot/#dynamic-conditional-networks-for-few-shot-learning","text":"\u672c\u6587\u4f7f\u7528class\u7684\u6587\u5b57 embedding \u4f5c\u4e3a convolution \u7684 guidance \u6765\u5b8c\u6210few-shot learning\u7684\u4efb\u52a1\u3002 \u8fd9\u91cc\u4ec5\u4ecb\u7ecd\u5176\u5f00\u6e90\u7684\u90e8\u5206,\u4e5f\u5c31\u662f dynamic filtering network\u90e8\u5206.","title":"Dynamic Conditional Networks for Few-Shot Learning"},{"location":"Building_Blocks/DynamicFilteringNetwork_Fewshot/#dynamic-filtering-network","text":"\u7b97\u6cd5\u4e0a\u4e3a\u521d\u59cb\u5316 N \u4e2a\u6743\u91cd\u7ec4\uff0cembedding\u8f93\u51fa\u4e00\u4e2a N \u7ef4\u7684\u5206\u7c7b\u77e2\u91cf\uff0c\u5c06 N \u4e2a\u6743\u91cd\u52a0\u6743\u6c42\u548c\uff0c\u4f5c\u4e3a\u4e3b\u7ebf\u4e0aConv2D\u7684\u6743\u91cd\u3002","title":"Dynamic Filtering Network"},{"location":"Building_Blocks/DynanicFilteringNetwork/","text":"Dynamic Filter Networks \u8fd9\u7bc72016\u7684NIPS\u8bba\u6587\u63a2\u8ba8\u7684\u662f\u52a8\u6001\u5377\u79ef\u6838\u7684\u95ee\u9898.\u539f\u6587\u7684\u5b98\u65b9\u5e93\u662f\u57fa\u4e8eTheano\u7684\uff0c\u540e\u6765\u4e5f\u6709\u4e86 tensorflow implementation .\u6982\u5ff5\u4e0d\u7b97\u590d\u6742\u3002 \u7ed3\u6784\u4e0e\u6a21\u5757\u7ec4\u6210 \u7b80\u5355\u6765\u8bf4\u5c31\u662f\u8ba9\u8f93\u5165\u4e00\u65b9\u9762\u4f5c\u4e3a\u88ab\u5377\u79ef\u7684\u5e38\u89c4\u8f93\u5165\uff0c\u53e6\u4e00\u65b9\u9762\u53c8\u4f7f\u7528\u7f51\u7edc\u751f\u6210\u5377\u79ef\u6838\u3002 \u8fd9\u91cc\u6709\u4e24\u79cd\u5b9e\u73b0\u65b9\u5f0f\uff0c\u7b2c\u4e00\u79cd\u662f\u6574\u4e2aFeature map\u53ea\u8f93\u51fa\u4e00\u4e2asingle Convolution Kernel,\u7136\u540e\u5377\u79ef\u4e5f\u4f1a\u4e0e\u4e00\u822c\u7684\u5377\u79ef\u4e00\u81f4\u3002 \u7b2c\u4e8c\u79cd\u662f\u5728feature map\u6bcf\u4e00\u4e2a\u70b9\u4e0a\u7528\u5e38\u89c4\u5377\u79ef\u751f\u62109(3x3)\u4e2a\u7279\u5f81,\u7136\u540e\u6bcf\u4e00\u4e2a\u70b9\u4e0a\u7528\u5404\u81ea\u7684\u8ba1\u7b97\u5f97\u5230\u7684\u7279\u5f81\u518d\u8ba1\u7b97\u5377\u79ef\u3002 \u4f5c\u8005\u6307\u51fa\u8fd9\u4e2a\u7ed3\u6784\u4e0eResidual\u8fde\u63a5\u6709\u4e00\u5b9a\u76f8\u4f3c\u4e4b\u5904\u3002","title":"Dynamic Filter Networks"},{"location":"Building_Blocks/DynanicFilteringNetwork/#dynamic-filter-networks","text":"\u8fd9\u7bc72016\u7684NIPS\u8bba\u6587\u63a2\u8ba8\u7684\u662f\u52a8\u6001\u5377\u79ef\u6838\u7684\u95ee\u9898.\u539f\u6587\u7684\u5b98\u65b9\u5e93\u662f\u57fa\u4e8eTheano\u7684\uff0c\u540e\u6765\u4e5f\u6709\u4e86 tensorflow implementation .\u6982\u5ff5\u4e0d\u7b97\u590d\u6742\u3002","title":"Dynamic Filter Networks"},{"location":"Building_Blocks/DynanicFilteringNetwork/#_1","text":"\u7b80\u5355\u6765\u8bf4\u5c31\u662f\u8ba9\u8f93\u5165\u4e00\u65b9\u9762\u4f5c\u4e3a\u88ab\u5377\u79ef\u7684\u5e38\u89c4\u8f93\u5165\uff0c\u53e6\u4e00\u65b9\u9762\u53c8\u4f7f\u7528\u7f51\u7edc\u751f\u6210\u5377\u79ef\u6838\u3002 \u8fd9\u91cc\u6709\u4e24\u79cd\u5b9e\u73b0\u65b9\u5f0f\uff0c\u7b2c\u4e00\u79cd\u662f\u6574\u4e2aFeature map\u53ea\u8f93\u51fa\u4e00\u4e2asingle Convolution Kernel,\u7136\u540e\u5377\u79ef\u4e5f\u4f1a\u4e0e\u4e00\u822c\u7684\u5377\u79ef\u4e00\u81f4\u3002 \u7b2c\u4e8c\u79cd\u662f\u5728feature map\u6bcf\u4e00\u4e2a\u70b9\u4e0a\u7528\u5e38\u89c4\u5377\u79ef\u751f\u62109(3x3)\u4e2a\u7279\u5f81,\u7136\u540e\u6bcf\u4e00\u4e2a\u70b9\u4e0a\u7528\u5404\u81ea\u7684\u8ba1\u7b97\u5f97\u5230\u7684\u7279\u5f81\u518d\u8ba1\u7b97\u5377\u79ef\u3002 \u4f5c\u8005\u6307\u51fa\u8fd9\u4e2a\u7ed3\u6784\u4e0eResidual\u8fde\u63a5\u6709\u4e00\u5b9a\u76f8\u4f3c\u4e4b\u5904\u3002","title":"\u7ed3\u6784\u4e0e\u6a21\u5757\u7ec4\u6210"},{"location":"Building_Blocks/ELASTIC/","text":"ELASTIC Improving CNNs With Dynamic Scaling Policies \u8fd9\u7bc7\u8bba\u6587\u7684\u60f3\u6cd5\u975e\u5e38\u7b80\u5355\uff0c\u7b80\u5355\u6765\u8bf4\u5c31\u662f\u8981\u8ba9\u7f51\u7edc\u80fd\u591f\u81ea\u4e3b\u5b66\u4e60\u5728inference\u8fc7\u7a0b\u4e2d\u91c7\u53d6\u600e\u6837\u7684scale\uff0c\u505a\u6cd5\u662f\u5728Resnet\u7684\u4e00\u4e2a\u5206\u652f\u4e2d\uff0c\u5148downsample\uff0c\u505a\u5377\u79ef\uff0c\u518dupsample\u3002\u540c\u65f6\u4fdd\u7559\u539fscale\u7684\u901a\u8def\uff0c\u7531\u8bad\u7ec3\u8fc7\u7a0b\u6765\u8ba9\u7f51\u7edc\u51b3\u5b9a\u5e94\u8be5\u5982\u4f55\u914d\u7f6e\u4e24\u4e2a\u901a\u8def\u7684\u53c2\u6570\uff0c\u4ee5\u6b64\u51b3\u5b9ascale. \u672c\u6587\u8fdb\u4e00\u6b65\u8fd8\u7ed9\u51fa\u4e86\u76ee\u524d\u591a\u79cdmultiscale model\u7684\u7ed3\u6784\uff0c\u56fe\u975e\u5e38\u7684\u597d\u770b\u4e14inspiring","title":"ELASTIC Improving CNNs With Dynamic Scaling Policies"},{"location":"Building_Blocks/ELASTIC/#elastic-improving-cnns-with-dynamic-scaling-policies","text":"\u8fd9\u7bc7\u8bba\u6587\u7684\u60f3\u6cd5\u975e\u5e38\u7b80\u5355\uff0c\u7b80\u5355\u6765\u8bf4\u5c31\u662f\u8981\u8ba9\u7f51\u7edc\u80fd\u591f\u81ea\u4e3b\u5b66\u4e60\u5728inference\u8fc7\u7a0b\u4e2d\u91c7\u53d6\u600e\u6837\u7684scale\uff0c\u505a\u6cd5\u662f\u5728Resnet\u7684\u4e00\u4e2a\u5206\u652f\u4e2d\uff0c\u5148downsample\uff0c\u505a\u5377\u79ef\uff0c\u518dupsample\u3002\u540c\u65f6\u4fdd\u7559\u539fscale\u7684\u901a\u8def\uff0c\u7531\u8bad\u7ec3\u8fc7\u7a0b\u6765\u8ba9\u7f51\u7edc\u51b3\u5b9a\u5e94\u8be5\u5982\u4f55\u914d\u7f6e\u4e24\u4e2a\u901a\u8def\u7684\u53c2\u6570\uff0c\u4ee5\u6b64\u51b3\u5b9ascale. \u672c\u6587\u8fdb\u4e00\u6b65\u8fd8\u7ed9\u51fa\u4e86\u76ee\u524d\u591a\u79cdmultiscale model\u7684\u7ed3\u6784\uff0c\u56fe\u975e\u5e38\u7684\u597d\u770b\u4e14inspiring","title":"ELASTIC Improving CNNs With Dynamic Scaling Policies"},{"location":"Building_Blocks/EfficientNet:_Rethinking_Model_Scaling_for_Convolutional_Neural_Network/","text":"EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks \u8fd9\u7bc7\u6587\u7ae0\u5206\u6790\u4e86CNN Scale Up\u7684\u76f8\u5173\u539f\u7406\uff0c\u7136\u540e\u7ed9\u51faEfficientNet.\u80cc\u540e\u7684\u903b\u8f91\u662f\u8fd9\u6837\u7684\uff0c\u9996\u5148\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7Neural Architecture Search\u5f97\u5230\u4e00\u4e2a\u4f4e\u5206\u8fa8\u7387\u56fe\u7247\u7684\u9ad8\u6548\u7387\u6a21\u578b\uff0c\u7136\u540e\u4f9d\u636e\u5b83\u5bf9\u5e94\u7684Scale Up\u539f\u7406\u8fdb\u884c\u6269\u5c55\u3002\u672c\u6587\u7528\u5230\u7684baseline\u51fa\u81ea MnasNet(pdf) ,\u5c31\u662f\u901a\u8fc7NAS\u5f97\u5230\u7684\u3002\u672c\u6587\u7684 \u4ee3\u7801 \u63d0\u4f9b\u4e86keras\u4ee5\u53caTensorflow\u5b9e\u73b0\u3002\u8fd9\u4e2a repo\u63d0\u4f9b\u4e86pytorch\u5b9e\u73b0 \u8fd9\u91cc\u6dfb\u52a0\u4e00\u4e2a medium\u4e0a\u7684\u89e3\u8bfb . Model Scaling Observation \u4e0a\u56fe\u5c55\u793a\u7684\u662f\u4e0d\u540c\u7684scale up\u4e00\u4e2a\u6a21\u578b\u7684\u65b9\u5f0f\u3002\u672c\u6587\u7684\u7ed3\u8bba\u662f\u5e94\u8be5\u6839\u636e\u8f93\u5165\u56fe\u7247\u7684\u5206\u8fa8\u7387\u3001channel\u6570\u76ee\u4ee5\u53ca\u7f51\u7edc\u6df1\u5ea6\u7efc\u5408Scale Up\u5f97\u5230\u7684\u63d0\u5347\u624d\u662f\u6700\u660e\u663e\u7684\u3002 \u4e0a\u56fe\u5c55\u793a\u7684\u662f\u5206\u522b\u53eaScale Up\u7f51\u7edcchannel\u6570,\u7f51\u7edc\u6df1\u5ea6,\u4ee5\u53ca\u56fe\u7247\u5206\u8fa8\u7387\u5f97\u5230\u7684\u3002\u4f5c\u8005\u7684\u7ed3\u8bba\u662f\u53eaScale Up\u4e00\u4e2a\u56e0\u5b50\u5f88\u5bb9\u6613\u5f97\u5230Saturation\uff0c\u901a\u8fc7\u53e6\u4e00\u4e2a\u5b9e\u9a8c\u53d1\u73b0\u603b\u5408\u4e00\u8d77Scale Up\u80fd\u5f97\u5230\u66f4\u597d\u7684\u7ed3\u679c\u3002 Compound Scaling Method \\begin{aligned} \\text { depth: } d &=\\alpha^{\\phi} \\\\ \\text { width: } w &=\\beta^{\\phi} \\\\ \\text { resolution: } r &=\\gamma^{\\phi} \\\\ \\text { s.t. } \\alpha & \\cdot \\beta^{2} \\cdot \\gamma^{2} \\approx 2 \\\\ \\alpha & \\geq 1, \\beta \\geq 1, \\gamma \\geq 1 \\end{aligned} \u4f5c\u8005\u9009\u62e9\u8fd9\u4e2a\u7684\u539f\u56e0\u662f\u56e0\u4e3aFLOPS(\u6d6e\u70b9\u8fd0\u7b97\u6570)\u6b63\u6bd4\u4e8e\u6df1\u5ea6,\u9891\u9053\u6570\u7684\u5e73\u65b9\u4ee5\u53ca\u5206\u8fa8\u7387\u7684\u5e73\u65b9\u3002 Efficient Net EfficientNet\u7684\u57fa\u672c\u5355\u5143\u7531 Mobile Conv(pdf) \u7ec4\u6210\u3002 \u4ece\u8fd9\u4e2aBaseLine\u5f00\u59cb\uff0c\u901a\u8fc7\u5c0fgrid-search\u5f97\u5230 \\alpha, \\beta, \\gamma \u7684\u521d\u59cb\u503c,\u66f4\u6539 \\phi \u5f97\u5230\u4e0d\u540c\u7684channel\u6570,\u5206\u8fa8\u7387\u4ee5\u53ca\u7f51\u7edc\u5c42\u6570(\u7f51\u7edc\u5c42\u6570\u7684\u66f4\u6539\u662f\u901a\u8fc7\u66f4\u6539\u5806\u53e0MBConv\u7684\u4e00\u4e2afor\u5faa\u73af\u7684\u5faa\u73af\u6b21\u6570\u5b9e\u73b0\u7684) \u5b9e\u9a8c\u4e0e\u7ed3\u679c \u672c\u6587\u9996\u5148\u5c1d\u8bd5Scale Up\u4e86MobileNet\u4ee5\u53caResNet\u7684\u5230\u597d\u7684\u7ed3\u679c\uff0c\u7136\u540e\u5f00\u59cbScale Up EfficientNet, \u4ee5\u4e0b\u56fe\u4e2d\u5404\u4e2a\u7f51\u7edc\u7684\u51c6\u786e\u7387\u3001\u53c2\u6570\u4ee5\u53caFLOPS\u662f\u4e00\u4e2a\u5f88\u597d\u7684\u53c2\u8003.","title":"EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"},{"location":"Building_Blocks/EfficientNet:_Rethinking_Model_Scaling_for_Convolutional_Neural_Network/#efficientnet-rethinking-model-scaling-for-convolutional-neural-networks","text":"\u8fd9\u7bc7\u6587\u7ae0\u5206\u6790\u4e86CNN Scale Up\u7684\u76f8\u5173\u539f\u7406\uff0c\u7136\u540e\u7ed9\u51faEfficientNet.\u80cc\u540e\u7684\u903b\u8f91\u662f\u8fd9\u6837\u7684\uff0c\u9996\u5148\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7Neural Architecture Search\u5f97\u5230\u4e00\u4e2a\u4f4e\u5206\u8fa8\u7387\u56fe\u7247\u7684\u9ad8\u6548\u7387\u6a21\u578b\uff0c\u7136\u540e\u4f9d\u636e\u5b83\u5bf9\u5e94\u7684Scale Up\u539f\u7406\u8fdb\u884c\u6269\u5c55\u3002\u672c\u6587\u7528\u5230\u7684baseline\u51fa\u81ea MnasNet(pdf) ,\u5c31\u662f\u901a\u8fc7NAS\u5f97\u5230\u7684\u3002\u672c\u6587\u7684 \u4ee3\u7801 \u63d0\u4f9b\u4e86keras\u4ee5\u53caTensorflow\u5b9e\u73b0\u3002\u8fd9\u4e2a repo\u63d0\u4f9b\u4e86pytorch\u5b9e\u73b0 \u8fd9\u91cc\u6dfb\u52a0\u4e00\u4e2a medium\u4e0a\u7684\u89e3\u8bfb .","title":"EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"},{"location":"Building_Blocks/EfficientNet:_Rethinking_Model_Scaling_for_Convolutional_Neural_Network/#model-scaling-observation","text":"\u4e0a\u56fe\u5c55\u793a\u7684\u662f\u4e0d\u540c\u7684scale up\u4e00\u4e2a\u6a21\u578b\u7684\u65b9\u5f0f\u3002\u672c\u6587\u7684\u7ed3\u8bba\u662f\u5e94\u8be5\u6839\u636e\u8f93\u5165\u56fe\u7247\u7684\u5206\u8fa8\u7387\u3001channel\u6570\u76ee\u4ee5\u53ca\u7f51\u7edc\u6df1\u5ea6\u7efc\u5408Scale Up\u5f97\u5230\u7684\u63d0\u5347\u624d\u662f\u6700\u660e\u663e\u7684\u3002 \u4e0a\u56fe\u5c55\u793a\u7684\u662f\u5206\u522b\u53eaScale Up\u7f51\u7edcchannel\u6570,\u7f51\u7edc\u6df1\u5ea6,\u4ee5\u53ca\u56fe\u7247\u5206\u8fa8\u7387\u5f97\u5230\u7684\u3002\u4f5c\u8005\u7684\u7ed3\u8bba\u662f\u53eaScale Up\u4e00\u4e2a\u56e0\u5b50\u5f88\u5bb9\u6613\u5f97\u5230Saturation\uff0c\u901a\u8fc7\u53e6\u4e00\u4e2a\u5b9e\u9a8c\u53d1\u73b0\u603b\u5408\u4e00\u8d77Scale Up\u80fd\u5f97\u5230\u66f4\u597d\u7684\u7ed3\u679c\u3002","title":"Model Scaling Observation"},{"location":"Building_Blocks/EfficientNet:_Rethinking_Model_Scaling_for_Convolutional_Neural_Network/#compound-scaling-method","text":"\\begin{aligned} \\text { depth: } d &=\\alpha^{\\phi} \\\\ \\text { width: } w &=\\beta^{\\phi} \\\\ \\text { resolution: } r &=\\gamma^{\\phi} \\\\ \\text { s.t. } \\alpha & \\cdot \\beta^{2} \\cdot \\gamma^{2} \\approx 2 \\\\ \\alpha & \\geq 1, \\beta \\geq 1, \\gamma \\geq 1 \\end{aligned} \u4f5c\u8005\u9009\u62e9\u8fd9\u4e2a\u7684\u539f\u56e0\u662f\u56e0\u4e3aFLOPS(\u6d6e\u70b9\u8fd0\u7b97\u6570)\u6b63\u6bd4\u4e8e\u6df1\u5ea6,\u9891\u9053\u6570\u7684\u5e73\u65b9\u4ee5\u53ca\u5206\u8fa8\u7387\u7684\u5e73\u65b9\u3002","title":"Compound Scaling Method"},{"location":"Building_Blocks/EfficientNet:_Rethinking_Model_Scaling_for_Convolutional_Neural_Network/#efficient-net","text":"EfficientNet\u7684\u57fa\u672c\u5355\u5143\u7531 Mobile Conv(pdf) \u7ec4\u6210\u3002 \u4ece\u8fd9\u4e2aBaseLine\u5f00\u59cb\uff0c\u901a\u8fc7\u5c0fgrid-search\u5f97\u5230 \\alpha, \\beta, \\gamma \u7684\u521d\u59cb\u503c,\u66f4\u6539 \\phi \u5f97\u5230\u4e0d\u540c\u7684channel\u6570,\u5206\u8fa8\u7387\u4ee5\u53ca\u7f51\u7edc\u5c42\u6570(\u7f51\u7edc\u5c42\u6570\u7684\u66f4\u6539\u662f\u901a\u8fc7\u66f4\u6539\u5806\u53e0MBConv\u7684\u4e00\u4e2afor\u5faa\u73af\u7684\u5faa\u73af\u6b21\u6570\u5b9e\u73b0\u7684)","title":"Efficient Net"},{"location":"Building_Blocks/EfficientNet:_Rethinking_Model_Scaling_for_Convolutional_Neural_Network/#_1","text":"\u672c\u6587\u9996\u5148\u5c1d\u8bd5Scale Up\u4e86MobileNet\u4ee5\u53caResNet\u7684\u5230\u597d\u7684\u7ed3\u679c\uff0c\u7136\u540e\u5f00\u59cbScale Up EfficientNet, \u4ee5\u4e0b\u56fe\u4e2d\u5404\u4e2a\u7f51\u7edc\u7684\u51c6\u786e\u7387\u3001\u53c2\u6570\u4ee5\u53caFLOPS\u662f\u4e00\u4e2a\u5f88\u597d\u7684\u53c2\u8003.","title":"\u5b9e\u9a8c\u4e0e\u7ed3\u679c"},{"location":"Building_Blocks/GhostNet/","text":"GhostNet: More Features from Cheap Operations class GhostModule ( nn . Module ): def __init__ ( self , inp , oup , kernel_size = 1 , ratio = 2 , dw_size = 3 , stride = 1 , relu = True ): super ( GhostModule , self ) . __init__ () self . oup = oup init_channels = math . ceil ( oup / ratio ) new_channels = init_channels * ( ratio - 1 ) self . primary_conv = nn . Sequential ( nn . Conv2d ( inp , init_channels , kernel_size , stride , kernel_size // 2 , bias = False ), nn . BatchNorm2d ( init_channels ), nn . ReLU ( inplace = True ) if relu else nn . Sequential (), ) self . cheap_operation = nn . Sequential ( nn . Conv2d ( init_channels , new_channels , dw_size , 1 , dw_size // 2 , groups = init_channels , bias = False ), nn . BatchNorm2d ( new_channels ), nn . ReLU ( inplace = True ) if relu else nn . Sequential (), ) def forward ( self , x ): x1 = self . primary_conv ( x ) x2 = self . cheap_operation ( x1 ) out = torch . cat ([ x1 , x2 ], dim = 1 ) return out [:,: self . oup ,:,:] class GhostBottleneck ( nn . Module ): def __init__ ( self , inp , hidden_dim , oup , kernel_size , stride , use_se ): super ( GhostBottleneck , self ) . __init__ () assert stride in [ 1 , 2 ] self . conv = nn . Sequential ( # pw GhostModule ( inp , hidden_dim , kernel_size = 1 , relu = True ), # dw depthwise_conv ( hidden_dim , hidden_dim , kernel_size , stride , relu = False ) if stride == 2 else nn . Sequential (), # Squeeze-and-Excite SELayer ( hidden_dim ) if use_se else nn . Sequential (), # pw-linear GhostModule ( hidden_dim , oup , kernel_size = 1 , relu = False ), ) if stride == 1 and inp == oup : self . shortcut = nn . Sequential () else : self . shortcut = nn . Sequential ( depthwise_conv ( inp , inp , 3 , stride , relu = True ), nn . Conv2d ( inp , oup , 1 , 1 , 0 , bias = False ), nn . BatchNorm2d ( oup ), ) def forward ( self , x ): return self . conv ( x ) + self . shortcut ( x )","title":"GhostNet: More Features from Cheap Operations"},{"location":"Building_Blocks/GhostNet/#ghostnet-more-features-from-cheap-operations","text":"class GhostModule ( nn . Module ): def __init__ ( self , inp , oup , kernel_size = 1 , ratio = 2 , dw_size = 3 , stride = 1 , relu = True ): super ( GhostModule , self ) . __init__ () self . oup = oup init_channels = math . ceil ( oup / ratio ) new_channels = init_channels * ( ratio - 1 ) self . primary_conv = nn . Sequential ( nn . Conv2d ( inp , init_channels , kernel_size , stride , kernel_size // 2 , bias = False ), nn . BatchNorm2d ( init_channels ), nn . ReLU ( inplace = True ) if relu else nn . Sequential (), ) self . cheap_operation = nn . Sequential ( nn . Conv2d ( init_channels , new_channels , dw_size , 1 , dw_size // 2 , groups = init_channels , bias = False ), nn . BatchNorm2d ( new_channels ), nn . ReLU ( inplace = True ) if relu else nn . Sequential (), ) def forward ( self , x ): x1 = self . primary_conv ( x ) x2 = self . cheap_operation ( x1 ) out = torch . cat ([ x1 , x2 ], dim = 1 ) return out [:,: self . oup ,:,:] class GhostBottleneck ( nn . Module ): def __init__ ( self , inp , hidden_dim , oup , kernel_size , stride , use_se ): super ( GhostBottleneck , self ) . __init__ () assert stride in [ 1 , 2 ] self . conv = nn . Sequential ( # pw GhostModule ( inp , hidden_dim , kernel_size = 1 , relu = True ), # dw depthwise_conv ( hidden_dim , hidden_dim , kernel_size , stride , relu = False ) if stride == 2 else nn . Sequential (), # Squeeze-and-Excite SELayer ( hidden_dim ) if use_se else nn . Sequential (), # pw-linear GhostModule ( hidden_dim , oup , kernel_size = 1 , relu = False ), ) if stride == 1 and inp == oup : self . shortcut = nn . Sequential () else : self . shortcut = nn . Sequential ( depthwise_conv ( inp , inp , 3 , stride , relu = True ), nn . Conv2d ( inp , oup , 1 , 1 , 0 , bias = False ), nn . BatchNorm2d ( oup ), ) def forward ( self , x ): return self . conv ( x ) + self . shortcut ( x )","title":"GhostNet: More Features from Cheap Operations"},{"location":"Building_Blocks/GumbelSoftmax/","text":"Categorical Reparameterization with Gumbel-Softmax \u8fd9\u7bc7\u6587\u7ae0\u7684\u5185\u5bb9\u5df2\u7ecf\u56fa\u5316\u4e3a\u4e86pytorch\u7684\u4e00\u4e2a \u51fd\u6570 \u5176\u4f5c\u7528\u662f\u5141\u8bb8 Stochastic, Differentiable, Probabilistic Weighted, Indexing. \u5148\u7528\u4ee3\u7801\u89e3\u91ca gumbel\u91c7\u6837\u53ef\u4ee5\u5982\u4f55\u7528\u5747\u5300\u968f\u673a\u91c7\u6837\u8868\u8fbe\uff1a def gumbel ( * shape ): u = np . random . rand ( * shape ) return - np . log ( - np . log ( u )) def gumbelsoftmax ( weights , lmbda = 1 , N = 10000 ): d = len ( weights ) logits = np . log ( weights . reshape ( d , 1 )) gumbel_noise = gumbel ( d * N ) . reshape ( d , N ) return softmax (( logits + gumbel_noise ) / lmbda , axis = 0 ) \u901a\u8fc7\u91c7\u6837 gumbelsoftmax,\u5f97\u5230\u7684\u5206\u5e03\u8fd1\u4f3c\u4e8e \\frac{weights}{\\sum(weights)} \u5176\u4e2d lmbda \u53d8\u91cf\u7406\u89e3\u4e3a\u6e29\u5ea6\u8d85\u53c2\uff0c\u5176\u4f5c\u7528\u5728\u4e8e\u63a7\u5236\u91c7\u6837\u7cfb\u7edf\u7684\u968f\u673a\u6027. pytorch functional \u7684\u4ee3\u7801\u5982\u4e0b(\u4e0d\u5fc5\u590d\u5236\u4f7f\u7528\uff0c\u8fd9\u5185\u7f6e\u4e8epytorch\u4e2d): def gumbel_softmax ( logits , tau = 1 , hard = False , eps = 1e-10 , dim =- 1 ): # type: (Tensor, float, bool, float, int) -> Tensor r \"\"\" Examples:: >>> logits = torch.randn(20, 32) >>> # Sample soft categorical using reparametrization trick: >>> F.gumbel_softmax(logits, tau=1, hard=False) >>> # Sample hard categorical using \"Straight-through\" trick: >>> F.gumbel_softmax(logits, tau=1, hard=True) \"\"\" if eps != 1e-10 : warnings . warn ( \"`eps` parameter is deprecated and has no effect.\" ) gumbels = - torch . empty_like ( logits , memory_format = torch . legacy_contiguous_format ) . exponential_ () . log () # ~Gumbel(0,1) gumbels = ( logits + gumbels ) / tau # ~Gumbel(logits,tau) y_soft = gumbels . softmax ( dim ) if hard : # Straight through. index = y_soft . max ( dim , keepdim = True )[ 1 ] y_hard = torch . zeros_like ( logits , memory_format = torch . legacy_contiguous_format ) . scatter_ ( dim , index , 1.0 ) ret = y_hard - y_soft . detach () + y_soft else : # Reparametrization trick. ret = y_soft return ret \u503c\u5f97\u6ce8\u610f\u7684\u662f\u8fd9\u91cc\u4f7f\u7528\u4e86 ret = y_hard - y_soft . detach () + y_soft \u8fd9\u4e00\u4e2atrick\u4f7f\u5f97one-hot\u7684 y\\_hard \u5728forward\u65f6\u662findexing\u91cf\uff0c\u4f46\u662fbackward\u7684\u65f6\u5019\u7528\u7684\u662f y\\_soft \u7684\u68af\u5ea6\u3002 \u8fd9\u7bc7\u6587\u7ae0\u4e0e\u5f88\u591a\u5176\u4ed6\u5185\u5bb9\u76f8\u5173\uff0c\u6bd4\u5982\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u4f5c\u4e3a\u4e00\u4e2a\u53ef\u4ee5exploit\u53c8\u53ef\u4ee5explore\u7684hard indexing. \u5728\u7f51\u7edc\u526a\u679d\u4e2d\u53ef\u4ee5\u4f5c\u4e3a\u4e00\u4e2a\u53ef\u4ee5\u5b66\u4e60\u4f7f\u7528\u7684\u53c2\u91cf\u3002 \u6bd4\u8f83\u5947\u5999\u7684\u662f\u8fd9\u7bc7paper\u5728ICLR\u53d1\u5e03\u7684\u65f6\u5019\u53ea\u662fmarginally accepted,\u4e5f\u53ea\u662fposter,\u4e3b\u8981\u662f\u53ef\u80fd\u539f\u4f5c\u8005\u4ee5\u53caReviewer\u5f53\u65f6\u53ea\u662f\u5728\u8003\u8651\u4f7f\u7528\u5728Generative Model\u4e0a\uff0c\u63d0\u5347\u6ca1\u6709\u90a3\u4e48\u663e\u8457\uff0c\u800c\u6ca1\u6709\u9884\u77e5\u8fd9\u4e48\u591a\u540e\u6765\u7684\u5e94\u7528\u3002\u4e0d\u8fc7\u540e\u6765\u5927\u5bb6\u5bf9\u5b83\u7684\u5f15\u7528\u4ee5\u53ca\u53d1\u6325\u662f\u5f88\u5de8\u5927\u7684.","title":"Categorical Reparameterization with Gumbel-Softmax"},{"location":"Building_Blocks/GumbelSoftmax/#categorical-reparameterization-with-gumbel-softmax","text":"\u8fd9\u7bc7\u6587\u7ae0\u7684\u5185\u5bb9\u5df2\u7ecf\u56fa\u5316\u4e3a\u4e86pytorch\u7684\u4e00\u4e2a \u51fd\u6570 \u5176\u4f5c\u7528\u662f\u5141\u8bb8 Stochastic, Differentiable, Probabilistic Weighted, Indexing. \u5148\u7528\u4ee3\u7801\u89e3\u91ca gumbel\u91c7\u6837\u53ef\u4ee5\u5982\u4f55\u7528\u5747\u5300\u968f\u673a\u91c7\u6837\u8868\u8fbe\uff1a def gumbel ( * shape ): u = np . random . rand ( * shape ) return - np . log ( - np . log ( u )) def gumbelsoftmax ( weights , lmbda = 1 , N = 10000 ): d = len ( weights ) logits = np . log ( weights . reshape ( d , 1 )) gumbel_noise = gumbel ( d * N ) . reshape ( d , N ) return softmax (( logits + gumbel_noise ) / lmbda , axis = 0 ) \u901a\u8fc7\u91c7\u6837 gumbelsoftmax,\u5f97\u5230\u7684\u5206\u5e03\u8fd1\u4f3c\u4e8e \\frac{weights}{\\sum(weights)} \u5176\u4e2d lmbda \u53d8\u91cf\u7406\u89e3\u4e3a\u6e29\u5ea6\u8d85\u53c2\uff0c\u5176\u4f5c\u7528\u5728\u4e8e\u63a7\u5236\u91c7\u6837\u7cfb\u7edf\u7684\u968f\u673a\u6027. pytorch functional \u7684\u4ee3\u7801\u5982\u4e0b(\u4e0d\u5fc5\u590d\u5236\u4f7f\u7528\uff0c\u8fd9\u5185\u7f6e\u4e8epytorch\u4e2d): def gumbel_softmax ( logits , tau = 1 , hard = False , eps = 1e-10 , dim =- 1 ): # type: (Tensor, float, bool, float, int) -> Tensor r \"\"\" Examples:: >>> logits = torch.randn(20, 32) >>> # Sample soft categorical using reparametrization trick: >>> F.gumbel_softmax(logits, tau=1, hard=False) >>> # Sample hard categorical using \"Straight-through\" trick: >>> F.gumbel_softmax(logits, tau=1, hard=True) \"\"\" if eps != 1e-10 : warnings . warn ( \"`eps` parameter is deprecated and has no effect.\" ) gumbels = - torch . empty_like ( logits , memory_format = torch . legacy_contiguous_format ) . exponential_ () . log () # ~Gumbel(0,1) gumbels = ( logits + gumbels ) / tau # ~Gumbel(logits,tau) y_soft = gumbels . softmax ( dim ) if hard : # Straight through. index = y_soft . max ( dim , keepdim = True )[ 1 ] y_hard = torch . zeros_like ( logits , memory_format = torch . legacy_contiguous_format ) . scatter_ ( dim , index , 1.0 ) ret = y_hard - y_soft . detach () + y_soft else : # Reparametrization trick. ret = y_soft return ret \u503c\u5f97\u6ce8\u610f\u7684\u662f\u8fd9\u91cc\u4f7f\u7528\u4e86 ret = y_hard - y_soft . detach () + y_soft \u8fd9\u4e00\u4e2atrick\u4f7f\u5f97one-hot\u7684 y\\_hard \u5728forward\u65f6\u662findexing\u91cf\uff0c\u4f46\u662fbackward\u7684\u65f6\u5019\u7528\u7684\u662f y\\_soft \u7684\u68af\u5ea6\u3002 \u8fd9\u7bc7\u6587\u7ae0\u4e0e\u5f88\u591a\u5176\u4ed6\u5185\u5bb9\u76f8\u5173\uff0c\u6bd4\u5982\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u4f5c\u4e3a\u4e00\u4e2a\u53ef\u4ee5exploit\u53c8\u53ef\u4ee5explore\u7684hard indexing. \u5728\u7f51\u7edc\u526a\u679d\u4e2d\u53ef\u4ee5\u4f5c\u4e3a\u4e00\u4e2a\u53ef\u4ee5\u5b66\u4e60\u4f7f\u7528\u7684\u53c2\u91cf\u3002 \u6bd4\u8f83\u5947\u5999\u7684\u662f\u8fd9\u7bc7paper\u5728ICLR\u53d1\u5e03\u7684\u65f6\u5019\u53ea\u662fmarginally accepted,\u4e5f\u53ea\u662fposter,\u4e3b\u8981\u662f\u53ef\u80fd\u539f\u4f5c\u8005\u4ee5\u53caReviewer\u5f53\u65f6\u53ea\u662f\u5728\u8003\u8651\u4f7f\u7528\u5728Generative Model\u4e0a\uff0c\u63d0\u5347\u6ca1\u6709\u90a3\u4e48\u663e\u8457\uff0c\u800c\u6ca1\u6709\u9884\u77e5\u8fd9\u4e48\u591a\u540e\u6765\u7684\u5e94\u7528\u3002\u4e0d\u8fc7\u540e\u6765\u5927\u5bb6\u5bf9\u5b83\u7684\u5f15\u7528\u4ee5\u53ca\u53d1\u6325\u662f\u5f88\u5de8\u5927\u7684.","title":"Categorical Reparameterization with Gumbel-Softmax"},{"location":"Building_Blocks/HRNet/","text":"Deep High-Resolution Representation Learning for Human Pose Estimation \u8fd9\u7bc7\u8bba\u6587\u7ed9\u51faHRnet,\u601d\u8def\u5173\u952e\u662f\u4fdd\u7559\u4e0d\u540cscale\u7684feature map\uff0c\u5e76\u5728\u524d\u4f20\u8fc7\u7a0b\u4e2d\u8ba9\u4ed6\u4eec\u4ea4\u6362\u4fe1\u606f\u3002","title":"Deep High-Resolution Representation Learning for Human Pose Estimation"},{"location":"Building_Blocks/HRNet/#deep-high-resolution-representation-learning-for-human-pose-estimation","text":"\u8fd9\u7bc7\u8bba\u6587\u7ed9\u51faHRnet,\u601d\u8def\u5173\u952e\u662f\u4fdd\u7559\u4e0d\u540cscale\u7684feature map\uff0c\u5e76\u5728\u524d\u4f20\u8fc7\u7a0b\u4e2d\u8ba9\u4ed6\u4eec\u4ea4\u6362\u4fe1\u606f\u3002","title":"Deep High-Resolution Representation Learning for Human Pose Estimation"},{"location":"Building_Blocks/Lookahead Optimizer ksteps forward, 1 step back/","text":"New Optimizers \u76ee\u5f55\u4e2d\u7684\u4ee3\u7801\u4ed3\u5e93\u6307\u5411Ranger\u5e93\uff0c\u662f\u4e00\u4e2a\u878d\u5408\u4e86\u591a\u4e2aoptimizer\u7684\u5e93\u3002\u5404\u7bc7\u6587\u7ae0\u6709\u81ea\u5df1\u7684\u5b98\u65b9\u5f00\u6e90\u5e93\u3002 Lookahead Optimizer:ksteps forward, 1 step back pdf code \u672c\u8d28\u4e0a\u6765\u8bf4\u5c31\u662f\u4fdd\u5b58\u4e24\u5957\u53c2\u6570\u503c\uff0c\u7528\u4e00\u5957\u53c2\u6570\u503c\u6b63\u5e38\u66f4\u65b0N\u6b65(\u6bcf\u53d8\u4e00\u6b21\u9700\u8981\u4f7f\u7528\u65b0\u7684\u6743\u503c\u8ba1\u7b97\u66f4\u65b0\u65b9\u5411)\uff0c\u7136\u540e\u7528\u7b2c\u4e8c\u5957\u53c2\u6570\u5f80\u6700\u7ec8\u8fd9N\u6b65\u7684\u603b\u66f4\u65b0\u65b9\u5411\u8d70\u4e00\u6b65 Gradient Centralization: A New Optimization Technique for Deep Neural Networks pdf code \u8ba1\u7b97\u65b9\u5f0f\u5f88\u7b80\u5355\uff0c\u5c31\u662f\u8ba1\u7b97graident\u4e4b\u540e\uff0c\u5728update\u4e4b\u524dnormalize\u5168\u5c40gradient for p in group [ 'params' ]: d_p = p . grad . data d_p . add_ ( - d_p . mean ( dim = tuple ( range ( 1 , len ( list ( d_p . size ())))), keepdim = True )) \u8fd9\u79cd\u8bad\u7ec3\u65b9\u5f0f\u8981\u6c42\u7f51\u7edc\u7684\u6743\u91cd\u7684\u5747\u503c\u4e00\u76f4\u662f\u4e0d\u53d8\u7684\uff0c\u4e5f\u5c31\u662fregularize\u4e86\u6743\u91cd\u7684\u641c\u7d22\u7a7a\u95f4.\u4f5c\u8005\u4e5f\u8bc1\u660e\u8fd9\u79cd\u5199\u6cd5\u4f1aregularize feature output space.\u4f46\u662fkaiming init \u8fd8\u6709imagenet pretrained\u7684\u6743\u91cd\u503c\u90fd\u4e0d\u4f1a\u592a\u5927\uff0c\u6240\u4ee5\u8fd9\u4e2aregularization\u4e0d\u4f1a\u8f7b\u6613\u5d29\u3002","title":"New Optimizers"},{"location":"Building_Blocks/Lookahead Optimizer ksteps forward, 1 step back/#new-optimizers","text":"\u76ee\u5f55\u4e2d\u7684\u4ee3\u7801\u4ed3\u5e93\u6307\u5411Ranger\u5e93\uff0c\u662f\u4e00\u4e2a\u878d\u5408\u4e86\u591a\u4e2aoptimizer\u7684\u5e93\u3002\u5404\u7bc7\u6587\u7ae0\u6709\u81ea\u5df1\u7684\u5b98\u65b9\u5f00\u6e90\u5e93\u3002","title":"New Optimizers"},{"location":"Building_Blocks/Lookahead Optimizer ksteps forward, 1 step back/#lookahead-optimizerksteps-forward-1-step-back","text":"pdf code \u672c\u8d28\u4e0a\u6765\u8bf4\u5c31\u662f\u4fdd\u5b58\u4e24\u5957\u53c2\u6570\u503c\uff0c\u7528\u4e00\u5957\u53c2\u6570\u503c\u6b63\u5e38\u66f4\u65b0N\u6b65(\u6bcf\u53d8\u4e00\u6b21\u9700\u8981\u4f7f\u7528\u65b0\u7684\u6743\u503c\u8ba1\u7b97\u66f4\u65b0\u65b9\u5411)\uff0c\u7136\u540e\u7528\u7b2c\u4e8c\u5957\u53c2\u6570\u5f80\u6700\u7ec8\u8fd9N\u6b65\u7684\u603b\u66f4\u65b0\u65b9\u5411\u8d70\u4e00\u6b65","title":"Lookahead Optimizer:ksteps forward, 1 step back"},{"location":"Building_Blocks/Lookahead Optimizer ksteps forward, 1 step back/#gradient-centralization-a-new-optimization-technique-for-deep-neural-networks","text":"pdf code \u8ba1\u7b97\u65b9\u5f0f\u5f88\u7b80\u5355\uff0c\u5c31\u662f\u8ba1\u7b97graident\u4e4b\u540e\uff0c\u5728update\u4e4b\u524dnormalize\u5168\u5c40gradient for p in group [ 'params' ]: d_p = p . grad . data d_p . add_ ( - d_p . mean ( dim = tuple ( range ( 1 , len ( list ( d_p . size ())))), keepdim = True )) \u8fd9\u79cd\u8bad\u7ec3\u65b9\u5f0f\u8981\u6c42\u7f51\u7edc\u7684\u6743\u91cd\u7684\u5747\u503c\u4e00\u76f4\u662f\u4e0d\u53d8\u7684\uff0c\u4e5f\u5c31\u662fregularize\u4e86\u6743\u91cd\u7684\u641c\u7d22\u7a7a\u95f4.\u4f5c\u8005\u4e5f\u8bc1\u660e\u8fd9\u79cd\u5199\u6cd5\u4f1aregularize feature output space.\u4f46\u662fkaiming init \u8fd8\u6709imagenet pretrained\u7684\u6743\u91cd\u503c\u90fd\u4e0d\u4f1a\u592a\u5927\uff0c\u6240\u4ee5\u8fd9\u4e2aregularization\u4e0d\u4f1a\u8f7b\u6613\u5d29\u3002","title":"Gradient Centralization: A New Optimization Technique for Deep Neural Networks"},{"location":"Building_Blocks/MDEQ/","text":"Multiscale Deep Equilibrium Models \u6211\u5728\u8fd9\u7bc7paper\u91cc\u9762\u8bfb\u5230\u4e86\u4e00\u4e2a\u53eb\u505a Implicit Deep Learning \u7684\u6982\u5ff5\u3002\u76ee\u524d\u4e3b\u8981\u7684\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\uff0c\u5b83\u4eec\u7684forward pass\u662f\u9884\u8bbe\u5b9a\u597d\u7684\uff0c\u800cbackward pass\u5219\u662f\u4e00\u53e5forward\u7684\u8fd0\u7b97\u56fe\u53cd\u5411\u8ba1\u7b97\u3002\u800cImplicit Deep Learning\u7684\u7279\u70b9\u5728\u4e8eforward pass\u7684\u8fd0\u7b97\u5e76\u4e0d\u662f\u5b8c\u5168\u9884\u5148\u5b9a\u4e49\u597d\u7684\uff0c\u800c\u662f\u4f1a\u6709\u4e00\u4e2a\u7ec8\u6001\u6807\u51c6\uff0c\u7f51\u7edc\u5728\u5b9e\u73b0\u8fd9\u4e00\u7ec8\u6001\u6807\u51c6\u4e4b\u540e\u5b8c\u6210\u8fd9\u4e00\u5c42\u7684\u8fd0\u7b97\uff0c\u800c\u7f51\u7edc\u7684backward pass\u5219\u662f\u6839\u636e\u8fd9\u4e00\u7ec8\u6001\u6807\u51c6\u83b7\u53d6\u7684\uff0c\u4e0eforward pass\u7684\u8fc7\u7a0b\u65e0\u5173\u3002 Deep Equilibrium \u6df1\u5ea6\u5747\u8861 Motivation: \u5bf9\u4e8e\u4e00\u4e2a L \u5c42\u7684\u6743\u91cd\u5171\u4eab\u7684\u7f51\u7edc\u6765\u8bf4\uff0c\u5b83\u7684\u8fd0\u7b97\u53ef\u4ee5\u8868\u8fbe\u4e3a z^{[i+1]} = f_\\theta(z^{[i]};x) \u5982\u679c L \u6570\u91cf\u8d8b\u8fd1\u4e8e\u65e0\u7a77\uff0c\u5219\u6700\u7ec8\u7ed3\u679c\u4f1a\u8d8b\u5411\u4e8e\u4e00\u4e2a\u5747\u8861\u6001 z^* = f_\\theta(z^*;x) .\u8fd9\u4e2a\u8bbe\u5b9a\u7684\u597d\u5904\u6709\u4e8c\uff0c\u9996\u5148\u662fForward\u7ed3\u679c\u8ba1\u7b97\u53ef\u4ee5\u88ab\u7406\u89e3\u4e3a\u4e00\u4e2a\u4e0d\u52a8\u70b9\u7684\u5bfb\u627e z^* = Rootfind(f_\\theta(z;x) - z) ,\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u725b\u987f\u6cd5\u903c\u8fd1\u4e0d\u52a8\u70b9\u7684\u6839\u3002\u5176\u6b21\uff0c\u5728backward\u7684\u65f6\u5019\u53ef\u4ee5\u76f4\u63a5\u5bf9\u7a33\u5b9a\u6001\u8fdb\u884c\u53cd\u4f20 \\frac{\\partial \\ell}{\\partial \\theta}=\\frac{\\partial \\ell}{\\partial \\mathbf{z}^{\\star}}\\left(-\\left.J_{g_{\\theta}}^{-1}\\right|_{\\mathbf{z}^{\\star}}\\right) \\frac{\\partial f_{\\theta}\\left(\\mathbf{z}^{\\star} ; \\mathbf{x}\\right)}{\\partial \\theta} \\quad \\frac{\\partial \\ell}{\\partial \\mathbf{x}}=\\frac{\\partial \\ell}{\\partial \\mathbf{z}^{\\star}}\\left(-\\left.J_{g_{\\theta}}^{-1}\\right|_{\\mathbf{z}^{\\star}}\\right) \\frac{\\partial f_{\\theta}\\left(\\mathbf{z}^{\\star} ; \\mathbf{x}\\right)}{\\partial \\mathbf{x}} \u7531\u4e8e\u96c5\u514b\u6bd4\u77e9\u9635\u8ba1\u7b97\u7684\u590d\u6742\u6027\uff0c\u524d\u6587\u4ec5\u5728\u5e8f\u5217\u6a21\u578b\u4e2d\u5c1d\u8bd5\uff0c\u672c\u6587\u5c1d\u8bd5\u5c06\u5176\u6269\u5c55\u5230\u56fe\u7247\u4e2d \u7ed3\u6784 \u4ee3\u7801\u5448\u73b0\u7684\u903b\u8f91\u662f\u628amulti-scale resolution\u7406\u89e3\u4e3a\u4e00\u4e2a\u65e0\u9650\u6b21\u7684convolution block\uff0c\u6c42\u89e3\u5668\u9700\u8981\u505a\u7684\u662f\u5c31\u662f\u6c42\u51fa\u56fe\u4e2d f_\\theta \u7684\u4e0d\u52a8\u70b9,\u5bf9\u4e8epytorch\u51fd\u6570g\u7684\u6838\u5fc3\u4ee3\u7801\u5728 broyden.py ,\u4ee3\u7801\u5b8c\u5168\u4e3apython/pytorch\u8ba1\u7b97\u3002","title":"Multiscale Deep Equilibrium Models"},{"location":"Building_Blocks/MDEQ/#multiscale-deep-equilibrium-models","text":"\u6211\u5728\u8fd9\u7bc7paper\u91cc\u9762\u8bfb\u5230\u4e86\u4e00\u4e2a\u53eb\u505a Implicit Deep Learning \u7684\u6982\u5ff5\u3002\u76ee\u524d\u4e3b\u8981\u7684\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\uff0c\u5b83\u4eec\u7684forward pass\u662f\u9884\u8bbe\u5b9a\u597d\u7684\uff0c\u800cbackward pass\u5219\u662f\u4e00\u53e5forward\u7684\u8fd0\u7b97\u56fe\u53cd\u5411\u8ba1\u7b97\u3002\u800cImplicit Deep Learning\u7684\u7279\u70b9\u5728\u4e8eforward pass\u7684\u8fd0\u7b97\u5e76\u4e0d\u662f\u5b8c\u5168\u9884\u5148\u5b9a\u4e49\u597d\u7684\uff0c\u800c\u662f\u4f1a\u6709\u4e00\u4e2a\u7ec8\u6001\u6807\u51c6\uff0c\u7f51\u7edc\u5728\u5b9e\u73b0\u8fd9\u4e00\u7ec8\u6001\u6807\u51c6\u4e4b\u540e\u5b8c\u6210\u8fd9\u4e00\u5c42\u7684\u8fd0\u7b97\uff0c\u800c\u7f51\u7edc\u7684backward pass\u5219\u662f\u6839\u636e\u8fd9\u4e00\u7ec8\u6001\u6807\u51c6\u83b7\u53d6\u7684\uff0c\u4e0eforward pass\u7684\u8fc7\u7a0b\u65e0\u5173\u3002","title":"Multiscale Deep Equilibrium Models"},{"location":"Building_Blocks/MDEQ/#deep-equilibrium","text":"","title":"Deep Equilibrium \u6df1\u5ea6\u5747\u8861"},{"location":"Building_Blocks/MDEQ/#motivation","text":"\u5bf9\u4e8e\u4e00\u4e2a L \u5c42\u7684\u6743\u91cd\u5171\u4eab\u7684\u7f51\u7edc\u6765\u8bf4\uff0c\u5b83\u7684\u8fd0\u7b97\u53ef\u4ee5\u8868\u8fbe\u4e3a z^{[i+1]} = f_\\theta(z^{[i]};x) \u5982\u679c L \u6570\u91cf\u8d8b\u8fd1\u4e8e\u65e0\u7a77\uff0c\u5219\u6700\u7ec8\u7ed3\u679c\u4f1a\u8d8b\u5411\u4e8e\u4e00\u4e2a\u5747\u8861\u6001 z^* = f_\\theta(z^*;x) .\u8fd9\u4e2a\u8bbe\u5b9a\u7684\u597d\u5904\u6709\u4e8c\uff0c\u9996\u5148\u662fForward\u7ed3\u679c\u8ba1\u7b97\u53ef\u4ee5\u88ab\u7406\u89e3\u4e3a\u4e00\u4e2a\u4e0d\u52a8\u70b9\u7684\u5bfb\u627e z^* = Rootfind(f_\\theta(z;x) - z) ,\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u725b\u987f\u6cd5\u903c\u8fd1\u4e0d\u52a8\u70b9\u7684\u6839\u3002\u5176\u6b21\uff0c\u5728backward\u7684\u65f6\u5019\u53ef\u4ee5\u76f4\u63a5\u5bf9\u7a33\u5b9a\u6001\u8fdb\u884c\u53cd\u4f20 \\frac{\\partial \\ell}{\\partial \\theta}=\\frac{\\partial \\ell}{\\partial \\mathbf{z}^{\\star}}\\left(-\\left.J_{g_{\\theta}}^{-1}\\right|_{\\mathbf{z}^{\\star}}\\right) \\frac{\\partial f_{\\theta}\\left(\\mathbf{z}^{\\star} ; \\mathbf{x}\\right)}{\\partial \\theta} \\quad \\frac{\\partial \\ell}{\\partial \\mathbf{x}}=\\frac{\\partial \\ell}{\\partial \\mathbf{z}^{\\star}}\\left(-\\left.J_{g_{\\theta}}^{-1}\\right|_{\\mathbf{z}^{\\star}}\\right) \\frac{\\partial f_{\\theta}\\left(\\mathbf{z}^{\\star} ; \\mathbf{x}\\right)}{\\partial \\mathbf{x}} \u7531\u4e8e\u96c5\u514b\u6bd4\u77e9\u9635\u8ba1\u7b97\u7684\u590d\u6742\u6027\uff0c\u524d\u6587\u4ec5\u5728\u5e8f\u5217\u6a21\u578b\u4e2d\u5c1d\u8bd5\uff0c\u672c\u6587\u5c1d\u8bd5\u5c06\u5176\u6269\u5c55\u5230\u56fe\u7247\u4e2d","title":"Motivation:"},{"location":"Building_Blocks/MDEQ/#_1","text":"\u4ee3\u7801\u5448\u73b0\u7684\u903b\u8f91\u662f\u628amulti-scale resolution\u7406\u89e3\u4e3a\u4e00\u4e2a\u65e0\u9650\u6b21\u7684convolution block\uff0c\u6c42\u89e3\u5668\u9700\u8981\u505a\u7684\u662f\u5c31\u662f\u6c42\u51fa\u56fe\u4e2d f_\\theta \u7684\u4e0d\u52a8\u70b9,\u5bf9\u4e8epytorch\u51fd\u6570g\u7684\u6838\u5fc3\u4ee3\u7801\u5728 broyden.py ,\u4ee3\u7801\u5b8c\u5168\u4e3apython/pytorch\u8ba1\u7b97\u3002","title":"\u7ed3\u6784"},{"location":"Building_Blocks/Non-local_Neural_Networks/","text":"Non-local Neural Networks non-local\u5355\u5143\u662f\u53e6\u4e00\u4e2a\u53ef\u4ee5\u663e\u8457\u63d0\u9ad83D,2D\u5377\u79ef\u7f51\u7edc\u7684\u611f\u53d7\u91ce \u6a21\u5757\u7ed3\u6784 \u56fe\u4e2d\u7ed9\u51fa\u7684\u662f\u7b80\u6d01\u660e\u4e86\u7684non-local\u6a21\u5757\u7684\u5177\u4f53\u7b97\u6cd5\u3002\u6bcf\u4e00\u4e2a\u84dd\u8272\u7684[1x1x1]\u8868\u660e\u4e00\u6b21channel-wise Conv\u3002 \u4ee5\u4e0b\u4e3a\u51e0\u4e2a\u76f4\u89c9\u4ee5\u53ca\u5f15\u7533 1. \u5728\u56fe\u4e2d\u5220\u9664T\u7ef4\u5ea6\u4e0d\u5f71\u54cd\u5168\u56fe\u7ed3\u6784\u4e0e\u53ef\u884c\u6027\uff0c\u4e5f\u4e0d\u5f71\u54cd\u6548\u679c\uff0c\u56e0\u800cnon-local\u4e5f\u53ef\u4ee5\u7528\u4e8e\u56fe\u7247\u3002 2. non_local\u6838\u5fc3\u662f f(x_i,x_j) = e^{x_i^T x_j} ,\u76f4\u89c9\u4e0a\u6765\u8bf4\uff0c\u4f1a\u8ba9\u4e0d\u540c\u65f6\u7a7a\u4f4d\u7f6e\u4e0a\u76f8\u4f3c\u7684\u7279\u5f81\u5f97\u5230\u8f83\u9ad8\u7684\u6fc0\u6d3b\u503c\uff0c\u5728\u540e\u9762\u4e5f\u5c31\u4f7f\u5f97\u56fe\u50cf\u4e0a\u4e00\u4e2a\u70b9\u7684feature map\u53ef\u4ee5\u878d\u5408\u4e0e\u5b83\u76f8\u4f3c\u7684\u5730\u65b9\u7684\u4fe1\u606f\u3002\u5728\u89c6\u9891\u5904\u7406\u4e2d\u6709\u4e00\u4e2a\u8f85\u52a9\u7269\u4f53\u8ddf\u8e2a\u7684\u6548\u679c\u3002 3. \u5f53feature map\u957f\u5bbd\u6bd4\u8f83\u5c0f\u7684\u65f6\u5019\u6548\u679c\u597d\u4e14\u8fd0\u7b97\u901f\u5ea6\u5feb\uff0c\u4f46\u662f\u5f53\u957f\u5bbd\u5f88\u5927\u7684\u65f6\u5019\u8fd0\u7b97\u4f1a\u5f88\u6162\uff0c\u56e0\u4e3a\u4f1a\u6709\u6570\u4e07\u7ef4\u7684\u77e9\u9635\u76f8\u4e58\uff0c\u8fd0\u7b97\u56fe\u4e5f\u4f1a\u590d\u6742\u3002 4. \u53ef\u4ee5\u9002\u5f53\u5220\u6539\u91cc\u9762\u51e0\u4e2a\u5377\u79ef\u64cd\u4f5c\u4ee5\u53casoftmax\u64cd\u4f5c\u3002","title":"Non-local Neural Networks"},{"location":"Building_Blocks/Non-local_Neural_Networks/#non-local-neural-networks","text":"non-local\u5355\u5143\u662f\u53e6\u4e00\u4e2a\u53ef\u4ee5\u663e\u8457\u63d0\u9ad83D,2D\u5377\u79ef\u7f51\u7edc\u7684\u611f\u53d7\u91ce","title":"Non-local Neural Networks"},{"location":"Building_Blocks/Non-local_Neural_Networks/#_1","text":"\u56fe\u4e2d\u7ed9\u51fa\u7684\u662f\u7b80\u6d01\u660e\u4e86\u7684non-local\u6a21\u5757\u7684\u5177\u4f53\u7b97\u6cd5\u3002\u6bcf\u4e00\u4e2a\u84dd\u8272\u7684[1x1x1]\u8868\u660e\u4e00\u6b21channel-wise Conv\u3002 \u4ee5\u4e0b\u4e3a\u51e0\u4e2a\u76f4\u89c9\u4ee5\u53ca\u5f15\u7533 1. \u5728\u56fe\u4e2d\u5220\u9664T\u7ef4\u5ea6\u4e0d\u5f71\u54cd\u5168\u56fe\u7ed3\u6784\u4e0e\u53ef\u884c\u6027\uff0c\u4e5f\u4e0d\u5f71\u54cd\u6548\u679c\uff0c\u56e0\u800cnon-local\u4e5f\u53ef\u4ee5\u7528\u4e8e\u56fe\u7247\u3002 2. non_local\u6838\u5fc3\u662f f(x_i,x_j) = e^{x_i^T x_j} ,\u76f4\u89c9\u4e0a\u6765\u8bf4\uff0c\u4f1a\u8ba9\u4e0d\u540c\u65f6\u7a7a\u4f4d\u7f6e\u4e0a\u76f8\u4f3c\u7684\u7279\u5f81\u5f97\u5230\u8f83\u9ad8\u7684\u6fc0\u6d3b\u503c\uff0c\u5728\u540e\u9762\u4e5f\u5c31\u4f7f\u5f97\u56fe\u50cf\u4e0a\u4e00\u4e2a\u70b9\u7684feature map\u53ef\u4ee5\u878d\u5408\u4e0e\u5b83\u76f8\u4f3c\u7684\u5730\u65b9\u7684\u4fe1\u606f\u3002\u5728\u89c6\u9891\u5904\u7406\u4e2d\u6709\u4e00\u4e2a\u8f85\u52a9\u7269\u4f53\u8ddf\u8e2a\u7684\u6548\u679c\u3002 3. \u5f53feature map\u957f\u5bbd\u6bd4\u8f83\u5c0f\u7684\u65f6\u5019\u6548\u679c\u597d\u4e14\u8fd0\u7b97\u901f\u5ea6\u5feb\uff0c\u4f46\u662f\u5f53\u957f\u5bbd\u5f88\u5927\u7684\u65f6\u5019\u8fd0\u7b97\u4f1a\u5f88\u6162\uff0c\u56e0\u4e3a\u4f1a\u6709\u6570\u4e07\u7ef4\u7684\u77e9\u9635\u76f8\u4e58\uff0c\u8fd0\u7b97\u56fe\u4e5f\u4f1a\u590d\u6742\u3002 4. \u53ef\u4ee5\u9002\u5f53\u5220\u6539\u91cc\u9762\u51e0\u4e2a\u5377\u79ef\u64cd\u4f5c\u4ee5\u53casoftmax\u64cd\u4f5c\u3002","title":"\u6a21\u5757\u7ed3\u6784"},{"location":"Building_Blocks/On_Multiplicative_Integration_with_Recurrent_Neural_Networks/","text":"On Multiplicative Integration with Recurrent Neural Networks \u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e00\u4e2a\u5728CAPs\u6a21\u578b\u63d0\u51fa\u7684 \u6587\u7ae0 \u4e2d\u4f7f\u7528\u7684Multiplicative Integration RNN(LSTM, GRU) \u672c\u8d28\u516c\u5f0f\u5c31\u662f \\phi\\left(\\boldsymbol{\\alpha} \\odot \\mathbf{W} \\boldsymbol{x} \\odot \\mathbf{U} \\boldsymbol{z}+\\boldsymbol{\\beta}_{1} \\odot \\mathbf{U} \\boldsymbol{z}+\\boldsymbol{\\beta}_{2} \\odot \\mathbf{W} \\boldsymbol{x}+\\boldsymbol{b}\\right) \u5176\u4e2d \\odot \u8868\u793a\u7684\u662f\u76f8\u540c\u5f62\u72b6\u7684\u77e9\u9635\u4e4b\u95f4\u7684\u5143\u7d20\u5bf9\u5e94\u4e58\u79ef\uff0c\u79f0\u4e3aHadamard product\u3002 \u76f4\u89c9\u662f\u4fc3\u8fdb\u4e86\u4e24\u4e2a\u4fe1\u606f\u6e90 x, z \u7684\u4fe1\u606f\u4ea4\u6d41\uff0c\u540c\u65f6\u4f18\u5316 Uz \u7684\u68af\u5ea6\u6d41\u901a,\u8fd9\u4e2a\u5728\u65f6\u5e8f\u6a21\u578b\u4e2d\u8f83\u4e3a\u91cd\u8981\u3002 \u8fd9\u4e2a github repo\u63d0\u4f9b\u4e86keras\u7684\u6267\u884c\u3002 \u5177\u4f53\u516c\u5f0f\u7684\u66ff\u6362\u5982\u4e0b:","title":"On Multiplicative Integration with Recurrent Neural Networks"},{"location":"Building_Blocks/On_Multiplicative_Integration_with_Recurrent_Neural_Networks/#on-multiplicative-integration-with-recurrent-neural-networks","text":"\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e00\u4e2a\u5728CAPs\u6a21\u578b\u63d0\u51fa\u7684 \u6587\u7ae0 \u4e2d\u4f7f\u7528\u7684Multiplicative Integration RNN(LSTM, GRU) \u672c\u8d28\u516c\u5f0f\u5c31\u662f \\phi\\left(\\boldsymbol{\\alpha} \\odot \\mathbf{W} \\boldsymbol{x} \\odot \\mathbf{U} \\boldsymbol{z}+\\boldsymbol{\\beta}_{1} \\odot \\mathbf{U} \\boldsymbol{z}+\\boldsymbol{\\beta}_{2} \\odot \\mathbf{W} \\boldsymbol{x}+\\boldsymbol{b}\\right) \u5176\u4e2d \\odot \u8868\u793a\u7684\u662f\u76f8\u540c\u5f62\u72b6\u7684\u77e9\u9635\u4e4b\u95f4\u7684\u5143\u7d20\u5bf9\u5e94\u4e58\u79ef\uff0c\u79f0\u4e3aHadamard product\u3002 \u76f4\u89c9\u662f\u4fc3\u8fdb\u4e86\u4e24\u4e2a\u4fe1\u606f\u6e90 x, z \u7684\u4fe1\u606f\u4ea4\u6d41\uff0c\u540c\u65f6\u4f18\u5316 Uz \u7684\u68af\u5ea6\u6d41\u901a,\u8fd9\u4e2a\u5728\u65f6\u5e8f\u6a21\u578b\u4e2d\u8f83\u4e3a\u91cd\u8981\u3002 \u8fd9\u4e2a github repo\u63d0\u4f9b\u4e86keras\u7684\u6267\u884c\u3002 \u5177\u4f53\u516c\u5f0f\u7684\u66ff\u6362\u5982\u4e0b:","title":"On Multiplicative Integration with Recurrent Neural Networks"},{"location":"Building_Blocks/PointAtrousNet/","text":"PointAtrousNet: Point Atrous Convolution for Point Cloud Analysis \u8fd9\u7bc7\u8bba\u6587\u5c06\u70b9\u4e91\u7684\u7a7a\u6d1e\u5377\u79ef\u5f15\u5165\u70b9\u4e91\u5206\u6790\u4e2d\uff0c\u503c\u5f97\u7559\u610f\u7684\u662f\u7a7a\u6d1e\u5377\u79ef\u5728 \u8fd9\u7bc7\u6587\u7ae0 \u4e2d\u5df2\u7ecf\u6709\u63d0\u53ca\uff0c\u4e14\u672c\u6587\u5e76\u6ca1\u6709\u5f15\u7528\u5b83\uff0c\u8fd9\u91cc\u53ef\u80fd\u6d89\u53ca\u4e00\u4e9b\u65f6\u95f4\u4e0a\u7684\u5dee\u522b\uff0c\u4e24\u8005\u5728\u70b9\u4e91\u7a7a\u6d1e\u5377\u79ef\u4e0a\u7684\u8ba1\u7b97\u8f83\u4e3a\u76f8\u4f3c\uff0c\u4f46\u662f\u672c\u6587\u8fdb\u4e00\u6b65\u63d0\u51fa\u4e86\u70b9\u4e91\u4e2d\u7684\u7a7a\u6d1e\u6c60\u5316\uff0c\u53ef\u4ee5\u4e00\u770b\u3002 \u70b9\u4e91\u7a7a\u6d1e\u5377\u79ef \u4e0e \u8fd9\u7bc7\u6587\u7ae0 \u76f8\u4f3c\uff0c\u5728\u6bcf\u4e00\u4e2a\u70b9\u9644\u8fd1\u5bfb\u627e\u6700\u9760\u8fd1\u7684K\u4e2a\u70b9,\u8fd9\u91cc\u4e0e\u524d\u6587\u4e0d\u540c\u7684\u5730\u65b9\u5728\u4e8e\u8fd9\u91cc\u91c7\u7528\u7684\u662fedge convolution\u7684\u64cd\u4f5c\uff0c\u4e0e DGCNN.pdf \u7c7b\u4f3c\u7684\u8fd0\u7b97\uff0c \u7b80\u4ecb X_{p}^{\\prime}=g\\left(H_{\\Theta}\\left(X_{p}, X_{q_{r}}\\right), \\ldots, H_{\\Theta}\\left(X_{p}, X_{\\left.q_{(r, k)}\\right)}\\right)\\right. \u5176\u4e2d H_{\\Theta} = h_{\\theta}\\left(X_{p} \\oplus\\left(X_{p}-X_{q_{i}}\\right)\\right) \u5bfb\u627e\u4e34\u8fd1\u70b9\u7684\u65b9\u6cd5\u4e5f\u662f\u6784\u5efaKD\u6811. \u70b9\u4e91\u7a7a\u6d1e\u6c60\u5316 \\begin{aligned} X_{p}^{\\prime} &=X_{p 1}^{\\prime} \\oplus X_{p 2}^{\\prime} \\oplus X_{p 3}^{\\prime} \\oplus X_{p 4}^{\\prime} \\\\ X_{p i}^{\\prime}=& g\\left(H_{\\rho}\\left(X_{p}, X_{q_{r_{i}}}\\right), \\ldots, H_{\\Theta}\\left(X_{p}, X_{\\left.q_{\\left(r_{i}, k\\right)}\\right)}\\right)\\right.\\end{aligned} \u5b8c\u6574\u7f51\u7edc\u793a\u4f8b \u8ba1\u7b97\u7ec6\u8282\u5728\u56fe\u4e2d\u4ee5\u53ca\u4ee3\u7801\u4e2d\u3002","title":"PointAtrousNet: Point Atrous Convolution for Point Cloud Analysis"},{"location":"Building_Blocks/PointAtrousNet/#pointatrousnet-point-atrous-convolution-for-point-cloud-analysis","text":"\u8fd9\u7bc7\u8bba\u6587\u5c06\u70b9\u4e91\u7684\u7a7a\u6d1e\u5377\u79ef\u5f15\u5165\u70b9\u4e91\u5206\u6790\u4e2d\uff0c\u503c\u5f97\u7559\u610f\u7684\u662f\u7a7a\u6d1e\u5377\u79ef\u5728 \u8fd9\u7bc7\u6587\u7ae0 \u4e2d\u5df2\u7ecf\u6709\u63d0\u53ca\uff0c\u4e14\u672c\u6587\u5e76\u6ca1\u6709\u5f15\u7528\u5b83\uff0c\u8fd9\u91cc\u53ef\u80fd\u6d89\u53ca\u4e00\u4e9b\u65f6\u95f4\u4e0a\u7684\u5dee\u522b\uff0c\u4e24\u8005\u5728\u70b9\u4e91\u7a7a\u6d1e\u5377\u79ef\u4e0a\u7684\u8ba1\u7b97\u8f83\u4e3a\u76f8\u4f3c\uff0c\u4f46\u662f\u672c\u6587\u8fdb\u4e00\u6b65\u63d0\u51fa\u4e86\u70b9\u4e91\u4e2d\u7684\u7a7a\u6d1e\u6c60\u5316\uff0c\u53ef\u4ee5\u4e00\u770b\u3002","title":"PointAtrousNet: Point Atrous Convolution for Point Cloud Analysis"},{"location":"Building_Blocks/PointAtrousNet/#_1","text":"\u4e0e \u8fd9\u7bc7\u6587\u7ae0 \u76f8\u4f3c\uff0c\u5728\u6bcf\u4e00\u4e2a\u70b9\u9644\u8fd1\u5bfb\u627e\u6700\u9760\u8fd1\u7684K\u4e2a\u70b9,\u8fd9\u91cc\u4e0e\u524d\u6587\u4e0d\u540c\u7684\u5730\u65b9\u5728\u4e8e\u8fd9\u91cc\u91c7\u7528\u7684\u662fedge convolution\u7684\u64cd\u4f5c\uff0c\u4e0e DGCNN.pdf \u7c7b\u4f3c\u7684\u8fd0\u7b97\uff0c \u7b80\u4ecb X_{p}^{\\prime}=g\\left(H_{\\Theta}\\left(X_{p}, X_{q_{r}}\\right), \\ldots, H_{\\Theta}\\left(X_{p}, X_{\\left.q_{(r, k)}\\right)}\\right)\\right. \u5176\u4e2d H_{\\Theta} = h_{\\theta}\\left(X_{p} \\oplus\\left(X_{p}-X_{q_{i}}\\right)\\right) \u5bfb\u627e\u4e34\u8fd1\u70b9\u7684\u65b9\u6cd5\u4e5f\u662f\u6784\u5efaKD\u6811.","title":"\u70b9\u4e91\u7a7a\u6d1e\u5377\u79ef"},{"location":"Building_Blocks/PointAtrousNet/#_2","text":"\\begin{aligned} X_{p}^{\\prime} &=X_{p 1}^{\\prime} \\oplus X_{p 2}^{\\prime} \\oplus X_{p 3}^{\\prime} \\oplus X_{p 4}^{\\prime} \\\\ X_{p i}^{\\prime}=& g\\left(H_{\\rho}\\left(X_{p}, X_{q_{r_{i}}}\\right), \\ldots, H_{\\Theta}\\left(X_{p}, X_{\\left.q_{\\left(r_{i}, k\\right)}\\right)}\\right)\\right.\\end{aligned}","title":"\u70b9\u4e91\u7a7a\u6d1e\u6c60\u5316"},{"location":"Building_Blocks/PointAtrousNet/#_3","text":"\u8ba1\u7b97\u7ec6\u8282\u5728\u56fe\u4e2d\u4ee5\u53ca\u4ee3\u7801\u4e2d\u3002","title":"\u5b8c\u6574\u7f51\u7edc\u793a\u4f8b"},{"location":"Building_Blocks/PositionalNorm/","text":"Positional Normalization \u8fd9\u7bc7paper\u63d0\u4f9b\u4e86\u4e00\u4e2a\u968f\u7740\u4e0d\u540cposition\u4e0d\u540c\u7684normalization scheme Normalization Review and Positional Normalization \u4ee3\u7801 import torch # x is the features of shape [B, C, H, W] # In the Encoder def PONO ( x , epsilon = 1e-5 ): mean = x . mean ( dim = 1 , keepdim = True ) std = x . var ( dim = 1 , keepdim = True ) . add ( epsilon ) . sqrt () output = ( x - mean ) / std return output , mean , std # In the Decoder # one can call MS(x, mean, std) # with the mean and std are from a PONO in the encoder def MS ( x , beta , gamma ): return x * gamma + beta ShortCut in Generative Model \u7528\u4e8e\u5c06\u8f93\u5165\u4fe1\u606f\u4f20\u9012\u5230\u8f93\u51fablock\u4e2d\uff0c\u80fd\u63d0\u5347\u751f\u6210\u6a21\u578b\u6bd4\u5982GAN\u7684\u6027\u80fd\u3002","title":"Positional Normalization"},{"location":"Building_Blocks/PositionalNorm/#positional-normalization","text":"\u8fd9\u7bc7paper\u63d0\u4f9b\u4e86\u4e00\u4e2a\u968f\u7740\u4e0d\u540cposition\u4e0d\u540c\u7684normalization scheme","title":"Positional Normalization"},{"location":"Building_Blocks/PositionalNorm/#normalization-review-and-positional-normalization","text":"\u4ee3\u7801 import torch # x is the features of shape [B, C, H, W] # In the Encoder def PONO ( x , epsilon = 1e-5 ): mean = x . mean ( dim = 1 , keepdim = True ) std = x . var ( dim = 1 , keepdim = True ) . add ( epsilon ) . sqrt () output = ( x - mean ) / std return output , mean , std # In the Decoder # one can call MS(x, mean, std) # with the mean and std are from a PONO in the encoder def MS ( x , beta , gamma ): return x * gamma + beta","title":"Normalization Review and Positional Normalization"},{"location":"Building_Blocks/PositionalNorm/#shortcut-in-generative-model","text":"\u7528\u4e8e\u5c06\u8f93\u5165\u4fe1\u606f\u4f20\u9012\u5230\u8f93\u51fablock\u4e2d\uff0c\u80fd\u63d0\u5347\u751f\u6210\u6a21\u578b\u6bd4\u5982GAN\u7684\u6027\u80fd\u3002","title":"ShortCut in Generative Model"},{"location":"Building_Blocks/SPN_CSPN/","text":"Spatial Propagation Network, Convolutional SPN and More \u8fd9\u7bc7\u6587\u662fSPN\u4ee5\u53caCSPN\uff0cCSPN++\u4e09\u7bc7paper\u7684\u7efc\u8ff0\u3002\u5728\u4f20\u7edf\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\uff0c Diffusion \u662f\u4e00\u4e2a\u542f\u53d1\u4e8e\u81ea\u7136\u6269\u6563/\u6e17\u900f\u5b9a\u5f8b\u7684\u5904\u7406\u7b97\u6cd5\uff0c\u8fed\u4ee3\u5730\u4f7f\u7528\u4e0d\u540c\u4f4d\u7f6e\u4e0d\u540c\u7684kernel\u5c06\u67d0\u4e00\u70b9\u7684\u4fe1\u606f\u6269\u6563\u5230\u9644\u8fd1\u7684\u70b9\u4e0a\u3002 Spatial Propagation Network pdf code \u8fd9\u7bc7NIPS paper\uff0c\u662f\u7b2c\u4e00\u4e2a\u5c06Diffusion \u6df1\u5ea6\u5b66\u4e60\u5316\u7684paper\u3002 Spatial Propagation Basic \u5bf9\u4e8e\u6c34\u5e73\u65b9\u5411propagate\u7684\u4f8b\u5b50,\u8bbe x_t\uff0c h_t \u4e3a n\\times n \u7684\u7279\u5f81\u56fe\uff0c w_t \u662f n\\times n \u7684kernel\u77e9\u9635(\u53ef\u4ee5\u7406\u89e3\u4e3a\u4e00\u4e2a\u53c2\u6570\u77e9\u9635), d_t \u662f\u4e00\u4e2a\u5bf9\u89d2\u77e9\u9635\uff0c d_{t}(i, i)=\\sum_{j=1, j \\neq i}^{n} w_{t}(i, j) \u90a3\u4e48\u8fed\u4ee3\u516c\u5f0f\u5c31\u662f h_{t}=\\left(I-d_{t}\\right) x_{t}+w_{t} h_{t-1}, \\quad t \\in[2, n] \u5c06\u6240\u6709 t \u6b21\u8fed\u4ee3\u5199\u5728\u4e00\u4e2a t\\dot n \\times t\\dot n \u77e9\u9635\u91cc\u9762\uff0c H_{v}=\\left[\\begin{array}{ccccc} I & 0 & \\cdots & \\cdots & 0 \\\\ w_{2} & \\lambda_{2} & 0 & \\cdots & \\cdots \\\\ w_{3} w_{2} & w_{3} \\lambda_{2} & \\lambda_{3} & 0 & \\cdots \\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\vdots & \\vdots & \\cdots & \\cdots & \\lambda_{n} \\end{array}\\right] X_{v}=G X_{v} Learning based Implementation \u672c\u6587\u63d0\u51fa\"three-way connection\"\uff0c\u4e5f\u5c31\u662f\u6bcf\u6b21\u4f20\u64ad\u4f1a\u5411\u4e0a\u4e0b\u5de6\u53f33\u4e2apixel\uff0c\u5206\u4e3a\u56db\u4e2a\u5206\u652f\uff0c\u7136\u540e\u5206\u522b\u8fed\u4ee3\u6267\u884c\u3002 \u5f00\u6e90\u4ee3\u7801\u53ea\u80fd\u652f\u6301\u65b9\u5f62\u77e9\u9635(\u9884\u8bbeH==W, \u6bd4\u8f83\u7684\u50f5\u786c,\u8fd9\u4e5f\u5bfc\u81f4\u4e86\u4ee3\u7801\u7684\u6ce8\u91ca\u4e00\u81f4\u6027\u6bd4\u8f83\u5dee)\uff0c\u56e0\u800c\u5177\u4f53implementation \u6b64\u5904\u7565\u8fc7 Convolutional SPN pdf code \u8fd9\u7bc7paper\u5728\u53cc\u76ee\u4ee5\u53caStereo\u4e2d\u662f\u4e00\u4e2a\u5f88\u5bcc\u88d5\u7684\u6587\u7ae0\uff0c\u5176\u4e2d\u7406\u8bba\u6bd4\u8f83\u65b0\u9896\u7684\u5730\u65b9\u662f\u52a0\u5165\u4e86CSPN\u6a21\u5757\u4ee5\u53ca\u5b83\u76843D\u5f62\u5f0f\u3002 code","title":"Spatial Propagation Network, Convolutional SPN and More"},{"location":"Building_Blocks/SPN_CSPN/#spatial-propagation-network-convolutional-spn-and-more","text":"\u8fd9\u7bc7\u6587\u662fSPN\u4ee5\u53caCSPN\uff0cCSPN++\u4e09\u7bc7paper\u7684\u7efc\u8ff0\u3002\u5728\u4f20\u7edf\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\uff0c Diffusion \u662f\u4e00\u4e2a\u542f\u53d1\u4e8e\u81ea\u7136\u6269\u6563/\u6e17\u900f\u5b9a\u5f8b\u7684\u5904\u7406\u7b97\u6cd5\uff0c\u8fed\u4ee3\u5730\u4f7f\u7528\u4e0d\u540c\u4f4d\u7f6e\u4e0d\u540c\u7684kernel\u5c06\u67d0\u4e00\u70b9\u7684\u4fe1\u606f\u6269\u6563\u5230\u9644\u8fd1\u7684\u70b9\u4e0a\u3002","title":"Spatial Propagation Network, Convolutional SPN and More"},{"location":"Building_Blocks/SPN_CSPN/#spatial-propagation-network","text":"pdf code \u8fd9\u7bc7NIPS paper\uff0c\u662f\u7b2c\u4e00\u4e2a\u5c06Diffusion \u6df1\u5ea6\u5b66\u4e60\u5316\u7684paper\u3002","title":"Spatial Propagation Network"},{"location":"Building_Blocks/SPN_CSPN/#spatial-propagation-basic","text":"\u5bf9\u4e8e\u6c34\u5e73\u65b9\u5411propagate\u7684\u4f8b\u5b50,\u8bbe x_t\uff0c h_t \u4e3a n\\times n \u7684\u7279\u5f81\u56fe\uff0c w_t \u662f n\\times n \u7684kernel\u77e9\u9635(\u53ef\u4ee5\u7406\u89e3\u4e3a\u4e00\u4e2a\u53c2\u6570\u77e9\u9635), d_t \u662f\u4e00\u4e2a\u5bf9\u89d2\u77e9\u9635\uff0c d_{t}(i, i)=\\sum_{j=1, j \\neq i}^{n} w_{t}(i, j) \u90a3\u4e48\u8fed\u4ee3\u516c\u5f0f\u5c31\u662f h_{t}=\\left(I-d_{t}\\right) x_{t}+w_{t} h_{t-1}, \\quad t \\in[2, n] \u5c06\u6240\u6709 t \u6b21\u8fed\u4ee3\u5199\u5728\u4e00\u4e2a t\\dot n \\times t\\dot n \u77e9\u9635\u91cc\u9762\uff0c H_{v}=\\left[\\begin{array}{ccccc} I & 0 & \\cdots & \\cdots & 0 \\\\ w_{2} & \\lambda_{2} & 0 & \\cdots & \\cdots \\\\ w_{3} w_{2} & w_{3} \\lambda_{2} & \\lambda_{3} & 0 & \\cdots \\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\vdots & \\vdots & \\cdots & \\cdots & \\lambda_{n} \\end{array}\\right] X_{v}=G X_{v}","title":"Spatial Propagation Basic"},{"location":"Building_Blocks/SPN_CSPN/#learning-based-implementation","text":"\u672c\u6587\u63d0\u51fa\"three-way connection\"\uff0c\u4e5f\u5c31\u662f\u6bcf\u6b21\u4f20\u64ad\u4f1a\u5411\u4e0a\u4e0b\u5de6\u53f33\u4e2apixel\uff0c\u5206\u4e3a\u56db\u4e2a\u5206\u652f\uff0c\u7136\u540e\u5206\u522b\u8fed\u4ee3\u6267\u884c\u3002 \u5f00\u6e90\u4ee3\u7801\u53ea\u80fd\u652f\u6301\u65b9\u5f62\u77e9\u9635(\u9884\u8bbeH==W, \u6bd4\u8f83\u7684\u50f5\u786c,\u8fd9\u4e5f\u5bfc\u81f4\u4e86\u4ee3\u7801\u7684\u6ce8\u91ca\u4e00\u81f4\u6027\u6bd4\u8f83\u5dee)\uff0c\u56e0\u800c\u5177\u4f53implementation \u6b64\u5904\u7565\u8fc7","title":"Learning based Implementation"},{"location":"Building_Blocks/SPN_CSPN/#convolutional-spn","text":"pdf code \u8fd9\u7bc7paper\u5728\u53cc\u76ee\u4ee5\u53caStereo\u4e2d\u662f\u4e00\u4e2a\u5f88\u5bcc\u88d5\u7684\u6587\u7ae0\uff0c\u5176\u4e2d\u7406\u8bba\u6bd4\u8f83\u65b0\u9896\u7684\u5730\u65b9\u662f\u52a0\u5165\u4e86CSPN\u6a21\u5757\u4ee5\u53ca\u5b83\u76843D\u5f62\u5f0f\u3002 code","title":"Convolutional SPN"},{"location":"Building_Blocks/SQUEEZENET_ALEXNET-LEVEL_ACCURACY_WITH_50X_FEWER_PARAMETERS_AND_0.5MB_MODEL_SIZE/","text":"SQUEEZENET: ALEXNET-LEVEL ACCURACY WITH 50X FEWER PARAMETERS AND <0.5MB MODEL SIZE \u672c\u6587\u63d0\u51fa\u4e86\u4f53\u79ef\u5c0f\u7684\u7f51\u7edc\u6709\u4ec0\u4e48\u597d\u5904\uff0c\u5e76\u4e14\u7ed9\u51fa\u4e86SqueezeNet\u7684\u5177\u4f53\u7ed3\u6784\u4ee5\u53ca\u76f8\u5173\u8ba8\u8bba \u7f51\u7edc\u7ed3\u6784\u8bbe\u8ba1\u7b56\u7565 \u5c06 3\\times 3 \u5377\u79ef\u6838\u8f6c\u6362\u4e3a 1\\times 1 \u964d\u4f4e\u8f93\u5165\u5230 3\\times 3 \u5377\u79ef\u7684\u7f51\u7edc\u8f93\u5165channel\u6570 \u5728\u8f83\u540e\u7684\u4f4d\u7f6e\u518d\u8fdb\u884c\u4e0b\u91c7\u6837\uff0c\u4ee5\u6b64\u63d0\u5347\u5377\u79ef\u5c42\u7684FOV Fire Module \u4e00\u4e2afire module\u7531: 1. squeeze layer(\u4ec5\u6709 1\\times 1 \u5377\u79ef\u7ec4\u6210) 2. expand layer(\u6df7\u5408 1\\times 1 \u5377\u79ef\u4e0e 3\\times 3 \u5377\u79ef) \u7b80\u5355\u6765\u8bf4\u5c31\u662f\u5148\u7528 1\\times 1 \u5377\u79ef\u964d\u4f4e\u8f93\u5165\u7684channel\u6570\uff0c\u7136\u540e\u5c06\u4e3b\u8f93\u51fa\u7684\u5c42\u90e8\u5206\u7528 1\\times 1 \u66ff\u4ee3\u3002 SqueezeNet\u7ed3\u6784 \u672c\u6587\u7b2c5\u7ae0\u8fd8\u8fdb\u4e00\u6b65\u8ba8\u8bba\u4e86Fire Module\u8fd8\u6709\u5b8f\u89c2\u7ed3\u6784\u4e2d\u7684\u4e00\u7cfb\u5217\u5177\u4f53\u53c2\u6570\u3002","title":"SQUEEZENET: ALEXNET-LEVEL ACCURACY WITH 50X FEWER PARAMETERS AND <0.5MB MODEL SIZE"},{"location":"Building_Blocks/SQUEEZENET_ALEXNET-LEVEL_ACCURACY_WITH_50X_FEWER_PARAMETERS_AND_0.5MB_MODEL_SIZE/#squeezenet-alexnet-level-accuracy-with-50x-fewer-parameters-and-05mb-model-size","text":"\u672c\u6587\u63d0\u51fa\u4e86\u4f53\u79ef\u5c0f\u7684\u7f51\u7edc\u6709\u4ec0\u4e48\u597d\u5904\uff0c\u5e76\u4e14\u7ed9\u51fa\u4e86SqueezeNet\u7684\u5177\u4f53\u7ed3\u6784\u4ee5\u53ca\u76f8\u5173\u8ba8\u8bba","title":"SQUEEZENET: ALEXNET-LEVEL ACCURACY WITH 50X FEWER PARAMETERS AND &lt;0.5MB MODEL SIZE"},{"location":"Building_Blocks/SQUEEZENET_ALEXNET-LEVEL_ACCURACY_WITH_50X_FEWER_PARAMETERS_AND_0.5MB_MODEL_SIZE/#_1","text":"\u5c06 3\\times 3 \u5377\u79ef\u6838\u8f6c\u6362\u4e3a 1\\times 1 \u964d\u4f4e\u8f93\u5165\u5230 3\\times 3 \u5377\u79ef\u7684\u7f51\u7edc\u8f93\u5165channel\u6570 \u5728\u8f83\u540e\u7684\u4f4d\u7f6e\u518d\u8fdb\u884c\u4e0b\u91c7\u6837\uff0c\u4ee5\u6b64\u63d0\u5347\u5377\u79ef\u5c42\u7684FOV","title":"\u7f51\u7edc\u7ed3\u6784\u8bbe\u8ba1\u7b56\u7565"},{"location":"Building_Blocks/SQUEEZENET_ALEXNET-LEVEL_ACCURACY_WITH_50X_FEWER_PARAMETERS_AND_0.5MB_MODEL_SIZE/#fire-module","text":"\u4e00\u4e2afire module\u7531: 1. squeeze layer(\u4ec5\u6709 1\\times 1 \u5377\u79ef\u7ec4\u6210) 2. expand layer(\u6df7\u5408 1\\times 1 \u5377\u79ef\u4e0e 3\\times 3 \u5377\u79ef) \u7b80\u5355\u6765\u8bf4\u5c31\u662f\u5148\u7528 1\\times 1 \u5377\u79ef\u964d\u4f4e\u8f93\u5165\u7684channel\u6570\uff0c\u7136\u540e\u5c06\u4e3b\u8f93\u51fa\u7684\u5c42\u90e8\u5206\u7528 1\\times 1 \u66ff\u4ee3\u3002","title":"Fire Module"},{"location":"Building_Blocks/SQUEEZENET_ALEXNET-LEVEL_ACCURACY_WITH_50X_FEWER_PARAMETERS_AND_0.5MB_MODEL_SIZE/#squeezenet","text":"\u672c\u6587\u7b2c5\u7ae0\u8fd8\u8fdb\u4e00\u6b65\u8ba8\u8bba\u4e86Fire Module\u8fd8\u6709\u5b8f\u89c2\u7ed3\u6784\u4e2d\u7684\u4e00\u7cfb\u5217\u5177\u4f53\u53c2\u6570\u3002","title":"SqueezeNet\u7ed3\u6784"},{"location":"Building_Blocks/Songtao_Liu_Receptive_Field_Block_ECCV_2018_paper/","text":"Receptive Field Block Net for Accurate and Fast Object Detection \u8fd9\u7bc7\u6587\u7ae0\u7684\u4f5c\u8005\u57fa\u4e8e\u4eba\u773c\u5b9e\u9645\u7ec6\u80de\u7684\u611f\u53d7\u91ce,\u8bbe\u8ba1\u4e86RFB\u6a21\u5757\u7528\u4e8e\u5206\u7c7b\u4e0e\u68c0\u6d4b\u3002 RFB \u6a21\u5757\u611f\u53d7\u91ce\u53ef\u89c6\u5316 \u4e0b\u56fe\u8868\u793a\u4e86,RFB\u6a21\u5757\u7684\u611f\u53d7\u91ce\u4e0e\u4eba\u7c7bhV4\u773c\u7ec6\u80de\u3002 RFB \u6267\u884c\u7ed3\u6784 \u4e0b\u56fe\u8868\u8fbe\u4e24\u79cdRFB\u6a21\u5757\u7684\u5177\u4f53\u7ed3\u6784\uff0c\u5b83\u4eec\u5206\u522b\u8fd1\u4f3c\u4eba\u7c7b\u6df1\u5c42\u4e0e\u6d45\u5c42\u89c6\u89c9\u7ec6\u80de\u7684\u611f\u53d7\u91ce\u7279\u6027\u3002\u5177\u4f53\u5b9e\u73b0\u7684\u4f7f\u7528\u4f7f\u7528\u4e24\u4e2a\u4e32\u63a5\u7684 3\\times 3 \u5377\u79ef\u66ff\u4ee3 5\\times 5 \u5377\u79ef\u3002 RFB SSD RFB\u7ed3\u6784\u5728SSD\u4e2d\u4f7f\u7528\uff0c\u4f5c\u8005\u63d0\u5347\u4e86\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u7684\u6027\u80fd\u3002","title":"Receptive Field Block Net for Accurate and Fast Object Detection"},{"location":"Building_Blocks/Songtao_Liu_Receptive_Field_Block_ECCV_2018_paper/#receptive-field-block-net-for-accurate-and-fast-object-detection","text":"\u8fd9\u7bc7\u6587\u7ae0\u7684\u4f5c\u8005\u57fa\u4e8e\u4eba\u773c\u5b9e\u9645\u7ec6\u80de\u7684\u611f\u53d7\u91ce,\u8bbe\u8ba1\u4e86RFB\u6a21\u5757\u7528\u4e8e\u5206\u7c7b\u4e0e\u68c0\u6d4b\u3002","title":"Receptive Field Block Net for Accurate and Fast Object Detection"},{"location":"Building_Blocks/Songtao_Liu_Receptive_Field_Block_ECCV_2018_paper/#rfb","text":"\u4e0b\u56fe\u8868\u793a\u4e86,RFB\u6a21\u5757\u7684\u611f\u53d7\u91ce\u4e0e\u4eba\u7c7bhV4\u773c\u7ec6\u80de\u3002","title":"RFB \u6a21\u5757\u611f\u53d7\u91ce\u53ef\u89c6\u5316"},{"location":"Building_Blocks/Songtao_Liu_Receptive_Field_Block_ECCV_2018_paper/#rfb_1","text":"\u4e0b\u56fe\u8868\u8fbe\u4e24\u79cdRFB\u6a21\u5757\u7684\u5177\u4f53\u7ed3\u6784\uff0c\u5b83\u4eec\u5206\u522b\u8fd1\u4f3c\u4eba\u7c7b\u6df1\u5c42\u4e0e\u6d45\u5c42\u89c6\u89c9\u7ec6\u80de\u7684\u611f\u53d7\u91ce\u7279\u6027\u3002\u5177\u4f53\u5b9e\u73b0\u7684\u4f7f\u7528\u4f7f\u7528\u4e24\u4e2a\u4e32\u63a5\u7684 3\\times 3 \u5377\u79ef\u66ff\u4ee3 5\\times 5 \u5377\u79ef\u3002","title":"RFB \u6267\u884c\u7ed3\u6784"},{"location":"Building_Blocks/Songtao_Liu_Receptive_Field_Block_ECCV_2018_paper/#rfb-ssd","text":"RFB\u7ed3\u6784\u5728SSD\u4e2d\u4f7f\u7528\uff0c\u4f5c\u8005\u63d0\u5347\u4e86\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u7684\u6027\u80fd\u3002","title":"RFB SSD"},{"location":"Building_Blocks/Squeeze-and-Excitation_Networks/","text":"Squeeze-and-Excitation Networks \u8fd9\u7bc7\u8bba\u6587\u7ed9\u51fa\u4e86squeeze-and-excitation\u65b9\u6cd5\u6765\u63d0\u9ad8\u5377\u79ef\u7684\u611f\u53d7\u573a\u5927\u5c0f\u3002 \u8ba1\u7b97\u5355\u5143\u7ed3\u6784 F_{tr} \u4e3a\u57fa\u7840\u5377\u79ef\u64cd\u4f5c\uff0c F_{sq} \u4e3a\u4e00\u4e2a\u5168\u56fe(H*W)\u7684average pool. F_{ex} = \\sigma(W_2\\sigma(W_1z)) \uff0c\u5c31\u662f\u4e00\u4e2aencoder\u3001decoder\u7684\u7ed3\u6784\uff0c F_{scale} \u5219\u662f\u4e00\u4e2achannel-wise\u7684\u70b9\u4e58(scalar and a H\\times W feature map) \u4f5c\u8005\u8868\u793a\u8fd9\u53ef\u4ee5\u7406\u89e3\u4e3a\u4e00\u4e2a\u81ea\u6ce8\u610f\u529b\u51fd\u6570","title":"Squeeze-and-Excitation Networks"},{"location":"Building_Blocks/Squeeze-and-Excitation_Networks/#squeeze-and-excitation-networks","text":"\u8fd9\u7bc7\u8bba\u6587\u7ed9\u51fa\u4e86squeeze-and-excitation\u65b9\u6cd5\u6765\u63d0\u9ad8\u5377\u79ef\u7684\u611f\u53d7\u573a\u5927\u5c0f\u3002","title":"Squeeze-and-Excitation Networks"},{"location":"Building_Blocks/Squeeze-and-Excitation_Networks/#_1","text":"F_{tr} \u4e3a\u57fa\u7840\u5377\u79ef\u64cd\u4f5c\uff0c F_{sq} \u4e3a\u4e00\u4e2a\u5168\u56fe(H*W)\u7684average pool. F_{ex} = \\sigma(W_2\\sigma(W_1z)) \uff0c\u5c31\u662f\u4e00\u4e2aencoder\u3001decoder\u7684\u7ed3\u6784\uff0c F_{scale} \u5219\u662f\u4e00\u4e2achannel-wise\u7684\u70b9\u4e58(scalar and a H\\times W feature map) \u4f5c\u8005\u8868\u793a\u8fd9\u53ef\u4ee5\u7406\u89e3\u4e3a\u4e00\u4e2a\u81ea\u6ce8\u610f\u529b\u51fd\u6570","title":"\u8ba1\u7b97\u5355\u5143\u7ed3\u6784"},{"location":"Building_Blocks/Stacked_Hourglass_Networks_for_Human_Pose_Estimation/","text":"Stacked Hourglass Networks for Human Pose Estimation \u8fd9\u7bc7\u6587\u7ae0\u76ee\u524d\u5bf9\u4e8e\u672c\u4eba\u6765\u8bf4\u662f \u8fd9\u7bc7\u6587\u7ae0 \u7684\u524d\u7f6e. \u76ee\u524d(2019-10-13)\uff0c\u6211\u4eec\u4e3b\u8981\u8ba8\u8bba\u672c\u6587\u63d0\u5230\u7684HourGlass \u6a21\u5757 HourGlass \u8fd9\u4e2a\u6a21\u5757\u7684\u8bbe\u8ba1\u8d77\u6e90\u4e8e\u5bf9\u591ascale\u7279\u5f81\u8f93\u51fa\u63d0\u53d6\u7684\u9700\u6c42\u3002\u7b80\u5355\u800c\u8a00\u5c31\u662f\u5728\u6bcf\u4e00\u4e2ascale\uff0c\u8fdb\u884c\u5206\u652f\uff0c\u4e00\u90e8\u5206\u6267\u884c\u4e00\u6b21\u5377\u79ef\u7b49\u5f85\u8fdb\u4e00\u6b65\u4f7f\u7528\u3002\u53e6\u4e00\u90e8\u5206\u6267\u884cmax-pooling\u4e0b\u91c7\u6837\u3002\u53bb\u5230\u6700\u5c0ffeatrue maps\u540e\uff0c\u4f7f\u7528Neareast pooling\u4e0a\u91c7\u6837\uff0c\u4e0e\u540cscale\u7684\u5148\u524d\u7559\u4e0b\u7684\u6b8b\u5dee\u8fdb\u884celement-wise\u76f8\u52a0 \u672c\u6587\u540e\u9762\u63d0\u5230\u8fd9\u91cc\u7684\u5377\u79ef\u53ef\u4ee5\u4f7f\u7528\u4e0d\u540c\u7684\u65b9\u5f0f\u5b9e\u73b0\uff0c\u6bd4\u5982\u672c\u6587\u4f3c\u4e4e\u5c31\u662f\u4f7f\u7528\u4e00\u4e2a\u590d\u6742\u7684Res\u7ed3\u6784\u5b9e\u73b0\u7684\u3002\u5177\u4f53\u8fd8\u9700\u8981\u770b\u4ee3\u7801\u3002","title":"Stacked Hourglass Networks for Human Pose Estimation"},{"location":"Building_Blocks/Stacked_Hourglass_Networks_for_Human_Pose_Estimation/#stacked-hourglass-networks-for-human-pose-estimation","text":"\u8fd9\u7bc7\u6587\u7ae0\u76ee\u524d\u5bf9\u4e8e\u672c\u4eba\u6765\u8bf4\u662f \u8fd9\u7bc7\u6587\u7ae0 \u7684\u524d\u7f6e. \u76ee\u524d(2019-10-13)\uff0c\u6211\u4eec\u4e3b\u8981\u8ba8\u8bba\u672c\u6587\u63d0\u5230\u7684HourGlass \u6a21\u5757","title":"Stacked Hourglass Networks for Human Pose Estimation"},{"location":"Building_Blocks/Stacked_Hourglass_Networks_for_Human_Pose_Estimation/#hourglass","text":"\u8fd9\u4e2a\u6a21\u5757\u7684\u8bbe\u8ba1\u8d77\u6e90\u4e8e\u5bf9\u591ascale\u7279\u5f81\u8f93\u51fa\u63d0\u53d6\u7684\u9700\u6c42\u3002\u7b80\u5355\u800c\u8a00\u5c31\u662f\u5728\u6bcf\u4e00\u4e2ascale\uff0c\u8fdb\u884c\u5206\u652f\uff0c\u4e00\u90e8\u5206\u6267\u884c\u4e00\u6b21\u5377\u79ef\u7b49\u5f85\u8fdb\u4e00\u6b65\u4f7f\u7528\u3002\u53e6\u4e00\u90e8\u5206\u6267\u884cmax-pooling\u4e0b\u91c7\u6837\u3002\u53bb\u5230\u6700\u5c0ffeatrue maps\u540e\uff0c\u4f7f\u7528Neareast pooling\u4e0a\u91c7\u6837\uff0c\u4e0e\u540cscale\u7684\u5148\u524d\u7559\u4e0b\u7684\u6b8b\u5dee\u8fdb\u884celement-wise\u76f8\u52a0 \u672c\u6587\u540e\u9762\u63d0\u5230\u8fd9\u91cc\u7684\u5377\u79ef\u53ef\u4ee5\u4f7f\u7528\u4e0d\u540c\u7684\u65b9\u5f0f\u5b9e\u73b0\uff0c\u6bd4\u5982\u672c\u6587\u4f3c\u4e4e\u5c31\u662f\u4f7f\u7528\u4e00\u4e2a\u590d\u6742\u7684Res\u7ed3\u6784\u5b9e\u73b0\u7684\u3002\u5177\u4f53\u8fd8\u9700\u8981\u770b\u4ee3\u7801\u3002","title":"HourGlass"},{"location":"Building_Blocks/crossBatchNormalization/","text":"Cross-Iteration Batch Normalization \u8fd9\u7bc7\u6587\u7ae0\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u6a21\u5757\uff0c\u79f0\u4e3a\u8de8\u8fed\u4ee3\u7684batchnorm, \u8fd9\u4e2a\u6a21\u5757\u7684\u6e90\u7801\u5728\u5176github\u9879\u76ee\u7684 ./mmdet/models/utils/CBN.py \u627e\u5f97\u5230. Motivation BatchNormalization\u7684\u4e00\u4e2a\u95ee\u9898\u5c31\u662f\u5728batchsize\u6bd4\u8f83\u5c0f\u7684\u65f6\u5019\u6548\u679c\u6bd4\u8f83\u5dee. \u540e\u6765\u53d1\u660e\u4e86 SyncBatchnorm \u6765\u8fdb\u884c\u8de8GPU\u7684batchnorm\u8ba1\u7b97\u3002\u672c\u6587\u8fdb\u4e00\u6b65\u63d0\u51fa\uff0c\u4f7f\u7528\u591a\u6b21\u8fed\u4ee3\u7684\u7ed3\u679c\u5e2e\u52a9batchnorm\u3002 \u76f4\u89c9\u4e0a\u6765\u8bf4,\u5c3d\u7ba1\u7531\u4e8e\u7f51\u7edc\u6743\u91cd\u53d8\u5316\u901f\u5ea6\u4e0d\u5feb\uff0c\u4f46\u662f\u76f8\u90bb\u7684\u8fed\u4ee3\u8fc7\u7a0b\u4e2d\uff0cexpected mean and variance\u8fd8\u662f\u5728\u53d8\u5316\u7684\u3002\u672c\u6587\u501f\u52a9\u4e00\u4e9b\u4f4e\u9636\u8fd1\u4f3c\uff0c\u5bf9\u6743\u91cd\u53d8\u5316\u505a\u4e86\u7b80\u8981\u7684\u5206\u6790\uff0c\u7ed9\u51fa\u4e86CBN\u6a21\u5757\u3002 CBN Algorithm \u672c\u8d28\u4e0a\u6765\u8bf4\uff0cbatch response\u7684\u5747\u503c\uff0c\u5e73\u65b9\u548c\u4ee5\u53ca\u65b9\u5dee\u7b49\u6570\u636e\u503c\u662f\u5173\u4e8e\u6743\u91cd\u7684\u4e00\u4e2adeterministic\u51fd\u6570\uff0c \u5728\u5b9e\u9645\u8ba1\u7b97\u4e2d\u7531\u67d0\u6b21\u8fed\u4ee3\u5f97\u5230\u7684\u7ed3\u679c\u8fdb\u884cMonte-Carlo\u4eff\u771f\u5f97\u5230\u4e00\u4e2a\u53c2\u8003\u503c\u3002\u8fc7\u53bb\u5f97\u5230\u7684\u5747\u503c\u53c2\u8003\u503c\u4e0e\u5f53\u524d\u503c\u5dee\u503c\u5728\u8fd9\u91cc\u7528\u6cf0\u52d2\u516c\u5f0f\u8fd1\u4f3c\u5f97\u5230 \\begin{aligned} \\mu_{t-\\tau}\\left(\\theta_{t}\\right)=& \\mu_{t-\\tau}\\left(\\theta_{t-\\tau}\\right)+\\frac{\\partial \\mu_{t-\\tau}\\left(\\theta_{t-\\tau}\\right)}{\\partial \\theta_{t-\\tau}}\\left(\\theta_{t}-\\theta_{t-\\tau}\\right) \\\\ &+\\mathbf{O}\\left(\\left\\|\\theta_{t}-\\theta_{t-\\tau}\\right\\|^{2}\\right) \\\\ \\nu_{t-\\tau}\\left(\\theta_{t}\\right)=& \\nu_{t-\\tau}\\left(\\theta_{t-\\tau}\\right)+\\frac{\\partial \\nu_{t-\\tau}\\left(\\theta_{t-\\tau}\\right)}{\\partial \\theta_{t-\\tau}}\\left(\\theta_{t}-\\theta_{t-\\tau}\\right) \\\\ &+\\mathbf{O}\\left(\\left\\|\\theta_{t}-\\theta_{t-\\tau}\\right\\|^{2}\\right) \\end{aligned} \u7701\u7565\u9ad8\u9636\u9879\uff0c\u540c\u65f6\u4f5c\u8005\u6307\u51fa\uff0c\u4e0d\u540cnormalization\u5c42\u4e4b\u95f4\u56e0\u4e3a\u524d\u4e00\u5c42\u6743\u91cd\u53d8\u5316\u5f15\u8d77\u7684\u540e\u4e00\u5c42\u7684\u5747\u503c\u4e0e\u65b9\u5dee\u53d8\u5316\u662f\u6709\u9650\u7684\u3002\u8fd9\u4e2a\u539f\u56e0\u6765\u8bf4\uff0c\u4f5c\u8005\u7684\u7406\u89e3\u662f\u8fd9\u4e2aBatchnorm\u4e2d\u76f4\u63a5\u5b66\u4e60\u7684 scale and shift\u5bf9\u540e\u4e00\u5c42\u5747\u503c\u4e0e\u65b9\u5dee\u7684\u5f71\u54cd\u603b\u4f53\u6765\u8bf4\u662f\u66f4\u4e3a\u663e\u8457\u7684\u3002\u8fdb\u800c\u5f97\u5230\u8fd9\u4e2a\u516c\u5f0f \\begin{array}{l} {\\boldsymbol{\\mu}_{t-\\tau}^{l}\\left(\\theta_{t}\\right) \\approx \\mu_{t-\\tau}^{l}\\left(\\theta_{t-\\tau}\\right)+\\frac{\\partial \\mu_{t-\\tau}^{l}\\left(\\theta_{t-\\tau}\\right)}{\\partial \\theta_{t-\\tau}^{l}}\\left(\\theta_{t}^{l}-\\theta_{t-\\tau}^{l}\\right)} \\\\ {\\nu_{t-\\tau}^{l}\\left(\\theta_{t}\\right) \\approx \\nu_{t-\\tau}^{l}\\left(\\theta_{t-\\tau}\\right)+\\frac{\\partial \\nu_{t-\\tau}^{l}\\left(\\theta_{t-\\tau}\\right)}{\\partial \\theta_{t-\\tau}^{l}}\\left(\\theta_{t}^{l}-\\theta_{t-\\tau}^{l}\\right)} \\end{array} \u672c\u6587\u540e\u9762\u7ed9\u51fa\u4e86\u4e00\u4e2aefficient\u7684\u68af\u5ea6\u7b97\u6cd5\uff0c\u4f46\u662f\u4ee3\u7801\u91cc\u76f4\u63a5\u4f7f\u7528\u7684\u662ftorch.autograd.grad\u7684API\u3002","title":"Cross-Iteration Batch Normalization"},{"location":"Building_Blocks/crossBatchNormalization/#cross-iteration-batch-normalization","text":"\u8fd9\u7bc7\u6587\u7ae0\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u6a21\u5757\uff0c\u79f0\u4e3a\u8de8\u8fed\u4ee3\u7684batchnorm, \u8fd9\u4e2a\u6a21\u5757\u7684\u6e90\u7801\u5728\u5176github\u9879\u76ee\u7684 ./mmdet/models/utils/CBN.py \u627e\u5f97\u5230.","title":"Cross-Iteration Batch Normalization"},{"location":"Building_Blocks/crossBatchNormalization/#motivation","text":"BatchNormalization\u7684\u4e00\u4e2a\u95ee\u9898\u5c31\u662f\u5728batchsize\u6bd4\u8f83\u5c0f\u7684\u65f6\u5019\u6548\u679c\u6bd4\u8f83\u5dee. \u540e\u6765\u53d1\u660e\u4e86 SyncBatchnorm \u6765\u8fdb\u884c\u8de8GPU\u7684batchnorm\u8ba1\u7b97\u3002\u672c\u6587\u8fdb\u4e00\u6b65\u63d0\u51fa\uff0c\u4f7f\u7528\u591a\u6b21\u8fed\u4ee3\u7684\u7ed3\u679c\u5e2e\u52a9batchnorm\u3002 \u76f4\u89c9\u4e0a\u6765\u8bf4,\u5c3d\u7ba1\u7531\u4e8e\u7f51\u7edc\u6743\u91cd\u53d8\u5316\u901f\u5ea6\u4e0d\u5feb\uff0c\u4f46\u662f\u76f8\u90bb\u7684\u8fed\u4ee3\u8fc7\u7a0b\u4e2d\uff0cexpected mean and variance\u8fd8\u662f\u5728\u53d8\u5316\u7684\u3002\u672c\u6587\u501f\u52a9\u4e00\u4e9b\u4f4e\u9636\u8fd1\u4f3c\uff0c\u5bf9\u6743\u91cd\u53d8\u5316\u505a\u4e86\u7b80\u8981\u7684\u5206\u6790\uff0c\u7ed9\u51fa\u4e86CBN\u6a21\u5757\u3002","title":"Motivation"},{"location":"Building_Blocks/crossBatchNormalization/#cbn-algorithm","text":"\u672c\u8d28\u4e0a\u6765\u8bf4\uff0cbatch response\u7684\u5747\u503c\uff0c\u5e73\u65b9\u548c\u4ee5\u53ca\u65b9\u5dee\u7b49\u6570\u636e\u503c\u662f\u5173\u4e8e\u6743\u91cd\u7684\u4e00\u4e2adeterministic\u51fd\u6570\uff0c \u5728\u5b9e\u9645\u8ba1\u7b97\u4e2d\u7531\u67d0\u6b21\u8fed\u4ee3\u5f97\u5230\u7684\u7ed3\u679c\u8fdb\u884cMonte-Carlo\u4eff\u771f\u5f97\u5230\u4e00\u4e2a\u53c2\u8003\u503c\u3002\u8fc7\u53bb\u5f97\u5230\u7684\u5747\u503c\u53c2\u8003\u503c\u4e0e\u5f53\u524d\u503c\u5dee\u503c\u5728\u8fd9\u91cc\u7528\u6cf0\u52d2\u516c\u5f0f\u8fd1\u4f3c\u5f97\u5230 \\begin{aligned} \\mu_{t-\\tau}\\left(\\theta_{t}\\right)=& \\mu_{t-\\tau}\\left(\\theta_{t-\\tau}\\right)+\\frac{\\partial \\mu_{t-\\tau}\\left(\\theta_{t-\\tau}\\right)}{\\partial \\theta_{t-\\tau}}\\left(\\theta_{t}-\\theta_{t-\\tau}\\right) \\\\ &+\\mathbf{O}\\left(\\left\\|\\theta_{t}-\\theta_{t-\\tau}\\right\\|^{2}\\right) \\\\ \\nu_{t-\\tau}\\left(\\theta_{t}\\right)=& \\nu_{t-\\tau}\\left(\\theta_{t-\\tau}\\right)+\\frac{\\partial \\nu_{t-\\tau}\\left(\\theta_{t-\\tau}\\right)}{\\partial \\theta_{t-\\tau}}\\left(\\theta_{t}-\\theta_{t-\\tau}\\right) \\\\ &+\\mathbf{O}\\left(\\left\\|\\theta_{t}-\\theta_{t-\\tau}\\right\\|^{2}\\right) \\end{aligned} \u7701\u7565\u9ad8\u9636\u9879\uff0c\u540c\u65f6\u4f5c\u8005\u6307\u51fa\uff0c\u4e0d\u540cnormalization\u5c42\u4e4b\u95f4\u56e0\u4e3a\u524d\u4e00\u5c42\u6743\u91cd\u53d8\u5316\u5f15\u8d77\u7684\u540e\u4e00\u5c42\u7684\u5747\u503c\u4e0e\u65b9\u5dee\u53d8\u5316\u662f\u6709\u9650\u7684\u3002\u8fd9\u4e2a\u539f\u56e0\u6765\u8bf4\uff0c\u4f5c\u8005\u7684\u7406\u89e3\u662f\u8fd9\u4e2aBatchnorm\u4e2d\u76f4\u63a5\u5b66\u4e60\u7684 scale and shift\u5bf9\u540e\u4e00\u5c42\u5747\u503c\u4e0e\u65b9\u5dee\u7684\u5f71\u54cd\u603b\u4f53\u6765\u8bf4\u662f\u66f4\u4e3a\u663e\u8457\u7684\u3002\u8fdb\u800c\u5f97\u5230\u8fd9\u4e2a\u516c\u5f0f \\begin{array}{l} {\\boldsymbol{\\mu}_{t-\\tau}^{l}\\left(\\theta_{t}\\right) \\approx \\mu_{t-\\tau}^{l}\\left(\\theta_{t-\\tau}\\right)+\\frac{\\partial \\mu_{t-\\tau}^{l}\\left(\\theta_{t-\\tau}\\right)}{\\partial \\theta_{t-\\tau}^{l}}\\left(\\theta_{t}^{l}-\\theta_{t-\\tau}^{l}\\right)} \\\\ {\\nu_{t-\\tau}^{l}\\left(\\theta_{t}\\right) \\approx \\nu_{t-\\tau}^{l}\\left(\\theta_{t-\\tau}\\right)+\\frac{\\partial \\nu_{t-\\tau}^{l}\\left(\\theta_{t-\\tau}\\right)}{\\partial \\theta_{t-\\tau}^{l}}\\left(\\theta_{t}^{l}-\\theta_{t-\\tau}^{l}\\right)} \\end{array} \u672c\u6587\u540e\u9762\u7ed9\u51fa\u4e86\u4e00\u4e2aefficient\u7684\u68af\u5ea6\u7b97\u6cd5\uff0c\u4f46\u662f\u4ee3\u7801\u91cc\u76f4\u63a5\u4f7f\u7528\u7684\u662ftorch.autograd.grad\u7684API\u3002","title":"CBN Algorithm"},{"location":"Building_Blocks/deepPruner/","text":"DeepPruner: Learning Efficient Stereo Matching via Differentiable PatchMatch \u4e0d\u540c\u4e8e\u4f7f\u7528Cost Volomn\u5bc6\u96c6\u9884\u6d4bdisparity\uff0c\u8fd9\u7bc7\u8bba\u6587\u4f7f\u7528Differentiable Patch Match\u8fdb\u884c\u4e00\u4e2a\u7c97\u7565\u7684disparity\u4f30\u8ba1\uff0c\u6700\u7ec8\u4f7f\u5f97\u9700\u8981densely predict\u7684disparity\u503c\u8fdc\u8fdc\u6bd4\u4e4b\u524d\u5c11\u3002\u6240\u4ee5\u79f0\u4e4b\u4e3apruning\u3002\u4f5c\u8005\u79f0\u5b9e\u73b0\u4e86\u5b9e\u65f6\u7684Scencflow\u4f30\u8ba1 Architecture \u7279\u5f81\u63d0\u53d6\u90e8\u5206\u4f7f\u7528\u7c7b\u4f3c\u4e8e PSMNet \u7684\u7ed3\u6784 Patch Match\u5728 \u540e\u6587 Cost Aggregation\u4e0e PSMNet \u4e00\u81f4\uff0c\u4e0d\u8fc7\u7531\u4e8e\u7ecf\u8fc7\u4e86pruning, \u641c\u7d22\u8303\u56f4\u66f4\u5c0f Refinement, \u4f7f\u7528\u5de6\u56fe\u7684image-feature\u901a\u8fc7Conv2D\u540e\u4e0eCost Softmax\u6c42expectation\u540e\u7684\u56fe\u7247residual\u94fe\u63a5 Patch Match Patch Match\u5728\u672c\u6587\u7684\u5b98\u65b9\u5f00\u6e90\u4ed3\u5e93\u91cc\u9762\u53ef\u4ee5\u88ab\u7406\u89e3\u4e3a\u662f\u4e00\u4e2a\u5355\u72ec\u7684\u5927\u6a21\u5757\u3002 \u8bbe\u8ba1\u4e09\u4e2a\u4e3b\u8981\u7f51\u7edc\u5c42\uff1a Sampler Layer \u968f\u673a\u62bd\u6837\u5c42\uff0c\u5728\u56fe\u7247\u4e0a\u7684\u6bcf\u4e2a\u70b9\u91cc\u9762\uff0c \u5728\u5f53\u524d\u641c\u7d22\u7a97\u53e3\u5185\uff0c\u751f\u6210 k \u4e2ax\u65b9\u5411\u7684\u6270\u52a8\u503c\u4e0e k \u4e2ay\u65b9\u5411\u7684\u6270\u52a8\u503c\uff0c\u6700\u540e\u5f62\u6210\u5728\u56fe\u7247\u7684\u6bcf\u4e00\u4e2afeature\u4f4d\u7f6e\u4e0a\uff0c\u4ea7\u751f k*k \u4e2adisparity estimation\u3002 Propagation Layer \u4f20\u64ad\u5c42\uff0c\u8fd9\u91cc\u6709\u4e24\u4e2a\u7248\u672c\uff0c\u8fd4\u56de\u503c\u4e2d\uff0c\u6bcf\u4e00\u4e2afeature map\u4e0a\u70b9\u7684\u7279\u5f81\u5305\u542b\u4e86\u5f53\u524d\u4f4d\u7f6e\u7684disparity estimation\u4ee5\u53ca\u76f8\u90bb\u4f4d\u7f6e\u7684disparity estimation. \u4f7f\u7528\u57fa\u7840\u7248\u672c\u7684\u8bdd\uff0c\u4f5c\u8005\u4f7f\u7528\u4e86\u4e00\u4e2a\u9884\u8bbe\u7684Conv3D,\u53bb\u63d0\u53d6\u7d27\u90bb\u4e0a\u4e0b\u5de6\u53f3\u7684feature\u3002 \u4f7f\u7528\u5feb\u901f\u7248\u672c\u7684\u8bdd\u4f5c\u8005\u5206\u4e24\u6b21propagate & evaluate, \u5206\u522b\u5bf9\u6c34\u5e73\u65b9\u5411\u4e0e\u7ad6\u76f4\u65b9\u5411\u5206\u5f00\u5904\u7406\u3002 Evaluation Layer \u8bc4\u4ef7\u5c42\uff0c \u5c06\u53f3\u56fe\u7279\u5f81\u6839\u636erandomly select\u7684disparity estimation warp\u5230\u5de6\u56fe\u4e0a\u3002\u7136\u540e\u7531\u4e8e\u5728\u4f20\u64ad\u5c42\u7684\u65f6\u5019\u5c31\u5df2\u7ecf\u5c06\u76f8\u90bb\u7684\u7279\u5f81\u90fd\u805a\u96c6\u8d77\u6765\u4e86\uff0c\u5728\u8bc4\u4ef7\u5c42\u5bf9\u6bcf\u4e00\u4e2apixel\u8ba1\u7b97\u5de6\u53f3\u56fe\u76f8\u90bb\u7279\u5f81\u7684\u76f8\u4f3c\u5ea6\u3002\u6700\u540e\u4f7f\u7528Softmax \u6c42\u51fa\u5404\u4e2adisparity estimation\u7684\u6982\u7387\uff0c\u5e76\u8ba1\u7b97\u5176expectation. \u5168\u5c40\u7b97\u6cd5 \u8fed\u4ee3\u5904\u7406\uff0csampler layer-> propagation layer-> evaluation layer. \u4ece\u5168\u5c40\u5e73\u5747\u91c7\u6837\u5f00\u59cb\uff0c\u5728\u4e4b\u540e\u7684\u6bcf\u6b21\u8fed\u4ee3\u4e2d\uff0c\u4f7f\u7528evaluation layer\u4f30\u8ba1\u7684expectation\u9644\u8fd1\u4e00\u5b9a\u5927\u5c0f\u7684\u7a97\u53e3\u4f5c\u4e3a\u65b0\u7684\u91c7\u6837\u8303\u56f4\u3002\u6700\u7ec8\u6bcf\u4e00\u4e2a\u70b9\u7684\u91c7\u6837\u8303\u56f4\u5c31\u88ab\u8fdb\u4e00\u6b65\u5730\u7f29\u5c0f\u3002","title":"DeepPruner: Learning Efficient Stereo Matching via Differentiable PatchMatch"},{"location":"Building_Blocks/deepPruner/#deeppruner-learning-efficient-stereo-matching-via-differentiable-patchmatch","text":"\u4e0d\u540c\u4e8e\u4f7f\u7528Cost Volomn\u5bc6\u96c6\u9884\u6d4bdisparity\uff0c\u8fd9\u7bc7\u8bba\u6587\u4f7f\u7528Differentiable Patch Match\u8fdb\u884c\u4e00\u4e2a\u7c97\u7565\u7684disparity\u4f30\u8ba1\uff0c\u6700\u7ec8\u4f7f\u5f97\u9700\u8981densely predict\u7684disparity\u503c\u8fdc\u8fdc\u6bd4\u4e4b\u524d\u5c11\u3002\u6240\u4ee5\u79f0\u4e4b\u4e3apruning\u3002\u4f5c\u8005\u79f0\u5b9e\u73b0\u4e86\u5b9e\u65f6\u7684Scencflow\u4f30\u8ba1","title":"DeepPruner: Learning Efficient Stereo Matching via Differentiable PatchMatch"},{"location":"Building_Blocks/deepPruner/#architecture","text":"\u7279\u5f81\u63d0\u53d6\u90e8\u5206\u4f7f\u7528\u7c7b\u4f3c\u4e8e PSMNet \u7684\u7ed3\u6784 Patch Match\u5728 \u540e\u6587 Cost Aggregation\u4e0e PSMNet \u4e00\u81f4\uff0c\u4e0d\u8fc7\u7531\u4e8e\u7ecf\u8fc7\u4e86pruning, \u641c\u7d22\u8303\u56f4\u66f4\u5c0f Refinement, \u4f7f\u7528\u5de6\u56fe\u7684image-feature\u901a\u8fc7Conv2D\u540e\u4e0eCost Softmax\u6c42expectation\u540e\u7684\u56fe\u7247residual\u94fe\u63a5","title":"Architecture"},{"location":"Building_Blocks/deepPruner/#patch-match","text":"Patch Match\u5728\u672c\u6587\u7684\u5b98\u65b9\u5f00\u6e90\u4ed3\u5e93\u91cc\u9762\u53ef\u4ee5\u88ab\u7406\u89e3\u4e3a\u662f\u4e00\u4e2a\u5355\u72ec\u7684\u5927\u6a21\u5757\u3002 \u8bbe\u8ba1\u4e09\u4e2a\u4e3b\u8981\u7f51\u7edc\u5c42\uff1a","title":"Patch Match"},{"location":"Building_Blocks/deepPruner/#sampler-layer","text":"\u968f\u673a\u62bd\u6837\u5c42\uff0c\u5728\u56fe\u7247\u4e0a\u7684\u6bcf\u4e2a\u70b9\u91cc\u9762\uff0c \u5728\u5f53\u524d\u641c\u7d22\u7a97\u53e3\u5185\uff0c\u751f\u6210 k \u4e2ax\u65b9\u5411\u7684\u6270\u52a8\u503c\u4e0e k \u4e2ay\u65b9\u5411\u7684\u6270\u52a8\u503c\uff0c\u6700\u540e\u5f62\u6210\u5728\u56fe\u7247\u7684\u6bcf\u4e00\u4e2afeature\u4f4d\u7f6e\u4e0a\uff0c\u4ea7\u751f k*k \u4e2adisparity estimation\u3002","title":"Sampler Layer"},{"location":"Building_Blocks/deepPruner/#propagation-layer","text":"\u4f20\u64ad\u5c42\uff0c\u8fd9\u91cc\u6709\u4e24\u4e2a\u7248\u672c\uff0c\u8fd4\u56de\u503c\u4e2d\uff0c\u6bcf\u4e00\u4e2afeature map\u4e0a\u70b9\u7684\u7279\u5f81\u5305\u542b\u4e86\u5f53\u524d\u4f4d\u7f6e\u7684disparity estimation\u4ee5\u53ca\u76f8\u90bb\u4f4d\u7f6e\u7684disparity estimation. \u4f7f\u7528\u57fa\u7840\u7248\u672c\u7684\u8bdd\uff0c\u4f5c\u8005\u4f7f\u7528\u4e86\u4e00\u4e2a\u9884\u8bbe\u7684Conv3D,\u53bb\u63d0\u53d6\u7d27\u90bb\u4e0a\u4e0b\u5de6\u53f3\u7684feature\u3002 \u4f7f\u7528\u5feb\u901f\u7248\u672c\u7684\u8bdd\u4f5c\u8005\u5206\u4e24\u6b21propagate & evaluate, \u5206\u522b\u5bf9\u6c34\u5e73\u65b9\u5411\u4e0e\u7ad6\u76f4\u65b9\u5411\u5206\u5f00\u5904\u7406\u3002","title":"Propagation Layer"},{"location":"Building_Blocks/deepPruner/#evaluation-layer","text":"\u8bc4\u4ef7\u5c42\uff0c \u5c06\u53f3\u56fe\u7279\u5f81\u6839\u636erandomly select\u7684disparity estimation warp\u5230\u5de6\u56fe\u4e0a\u3002\u7136\u540e\u7531\u4e8e\u5728\u4f20\u64ad\u5c42\u7684\u65f6\u5019\u5c31\u5df2\u7ecf\u5c06\u76f8\u90bb\u7684\u7279\u5f81\u90fd\u805a\u96c6\u8d77\u6765\u4e86\uff0c\u5728\u8bc4\u4ef7\u5c42\u5bf9\u6bcf\u4e00\u4e2apixel\u8ba1\u7b97\u5de6\u53f3\u56fe\u76f8\u90bb\u7279\u5f81\u7684\u76f8\u4f3c\u5ea6\u3002\u6700\u540e\u4f7f\u7528Softmax \u6c42\u51fa\u5404\u4e2adisparity estimation\u7684\u6982\u7387\uff0c\u5e76\u8ba1\u7b97\u5176expectation.","title":"Evaluation Layer"},{"location":"Building_Blocks/deepPruner/#_1","text":"\u8fed\u4ee3\u5904\u7406\uff0csampler layer-> propagation layer-> evaluation layer. \u4ece\u5168\u5c40\u5e73\u5747\u91c7\u6837\u5f00\u59cb\uff0c\u5728\u4e4b\u540e\u7684\u6bcf\u6b21\u8fed\u4ee3\u4e2d\uff0c\u4f7f\u7528evaluation layer\u4f30\u8ba1\u7684expectation\u9644\u8fd1\u4e00\u5b9a\u5927\u5c0f\u7684\u7a97\u53e3\u4f5c\u4e3a\u65b0\u7684\u91c7\u6837\u8303\u56f4\u3002\u6700\u7ec8\u6bcf\u4e00\u4e2a\u70b9\u7684\u91c7\u6837\u8303\u56f4\u5c31\u88ab\u8fdb\u4e00\u6b65\u5730\u7f29\u5c0f\u3002","title":"\u5168\u5c40\u7b97\u6cd5"},{"location":"Building_Blocks/deformable_convnet_v2/","text":"Deformable ConvNets V2: More Deformable, Better Results \u8fd9\u7bc7\u8bba\u6587\u4e00\u65b9\u9762\u8ba8\u8bba\u4e86\u4e00\u4e9b\u8bc4\u4ef7deformable convolution\u6a21\u5757\u6027\u80fd\u7684metric,\u5e76\u7528\u4e00\u4e9b\u5b9e\u9a8c\u5f15\u5165\u3002\u5728\u6a21\u5757\u8bbe\u8ba1\u4e0a\u7ed9\u51fadeformable convolution\u7684\u7ec6\u8282. \u7ed3\u6784\u89e3\u8bfb \u672c\u6587\u7684\u5173\u952e\u60f3\u6cd5\u662f\u5141\u8bb8deformable conv\u6a21\u5757\u5728\u540c\u4e00\u5f20\u56fe\u7247\u540c\u4e00\u4e2achannel\u3001\u4e0d\u540c\u5730\u65b9\u6709\u4e0d\u540c\u7684behavior,\u800c\u539f\u6765\u7684conv\u4ee5\u53ca\u521d\u59cb\u7684deformable conv\u90fd\u662f\u5904\u5904\u76f8\u540c\u7684\u7279\u5f81\u3002\u8ba1\u7b97\u516c\u5f0f y(p) = \\sum^K_{k=1}w_k\\dot x(p + p_k + \\Delta p_k) \\dot \\Delta m_k \u5176\u4e2d p, x(p), y(p) \u8868\u793a\u4f4d\u7f6e p \u4ee5\u53ca\u5f53\u524d\u4f4d\u7f6e\u4e0a\u7684\u8f93\u5165\u3001\u8f93\u51fafeature map\u3002 K \u4e3a\u5377\u79ef\u6838\u7684\u6570\u91cf\uff0c p_k\uff0c w_k \u4e3a\u666e\u901a\u5377\u79ef\u5b66\u4e60\u5230\u7684offset\u4ee5\u53ca\u6743\u91cd(\u5728\u540c\u4e00\u56fe\u7247\u540c\u4e00channel\u5904\u5904\u76f8\u540c), \\Delta p_k, \\Delta m_k \u4e3a\u65b0\u7248\u589e\u52a0\u7684\uff0c\u4e0e\u5f53\u524d\u533a\u57df\u76f8\u5173\u7684offset\u4ee5\u53ca\u6743\u91cd (offset \u5f62\u72b6\u4e3a [B, kernel_size**2, H, W]) \u800c \\Delta p_k, \\Delta m_k \u7531\u5f53\u524d\u4f4d\u7f6e\u5377\u79ef\u4ea7\u751f\uff0c\u6bd4\u5982\u4f7f\u7528K=9\uff0c\u5bf9\u5f53\u524d\u4f4d\u7f6e\u4f7f\u7528\u6b63\u5e38\u5377\u79ef\uff0c\u5f97\u523027\u4e2achannel\uff0c\u524d18\u4e2achannel\u5206\u522b\u5bf9\u5e94 \\Delta p_k \u7684\u4e24\u4e2a\u5750\u6807,\u540e9\u4e2achannel\u7ecf\u8fc7sigmoid\u6fc0\u6d3b\u540e\u53d8\u4e3a \\Delta m_k \u7ec6\u8282 \u53ef\u4ee5\u5b66\u4e60\u672c\u6587github\u4e2d\u4f7f\u7528cuda\u8f85\u52a9\u5e2e\u5fd9\u5f00\u53d1pytorch\u5b50\u6a21\u5757\uff0c\u5982\u679c\u53ef\u80fd\u53ef\u4ee5\u9002\u5f53\u5b66\u4e60\u3002\u6709\u52a0\u901f\u4ee3\u7801\u8fd0\u884c\u7684\u6f5c\u80fd\u3002","title":"Deformable ConvNets V2: More Deformable, Better Results"},{"location":"Building_Blocks/deformable_convnet_v2/#deformable-convnets-v2-more-deformable-better-results","text":"\u8fd9\u7bc7\u8bba\u6587\u4e00\u65b9\u9762\u8ba8\u8bba\u4e86\u4e00\u4e9b\u8bc4\u4ef7deformable convolution\u6a21\u5757\u6027\u80fd\u7684metric,\u5e76\u7528\u4e00\u4e9b\u5b9e\u9a8c\u5f15\u5165\u3002\u5728\u6a21\u5757\u8bbe\u8ba1\u4e0a\u7ed9\u51fadeformable convolution\u7684\u7ec6\u8282.","title":"Deformable ConvNets V2: More Deformable, Better Results"},{"location":"Building_Blocks/deformable_convnet_v2/#_1","text":"\u672c\u6587\u7684\u5173\u952e\u60f3\u6cd5\u662f\u5141\u8bb8deformable conv\u6a21\u5757\u5728\u540c\u4e00\u5f20\u56fe\u7247\u540c\u4e00\u4e2achannel\u3001\u4e0d\u540c\u5730\u65b9\u6709\u4e0d\u540c\u7684behavior,\u800c\u539f\u6765\u7684conv\u4ee5\u53ca\u521d\u59cb\u7684deformable conv\u90fd\u662f\u5904\u5904\u76f8\u540c\u7684\u7279\u5f81\u3002\u8ba1\u7b97\u516c\u5f0f y(p) = \\sum^K_{k=1}w_k\\dot x(p + p_k + \\Delta p_k) \\dot \\Delta m_k \u5176\u4e2d p, x(p), y(p) \u8868\u793a\u4f4d\u7f6e p \u4ee5\u53ca\u5f53\u524d\u4f4d\u7f6e\u4e0a\u7684\u8f93\u5165\u3001\u8f93\u51fafeature map\u3002 K \u4e3a\u5377\u79ef\u6838\u7684\u6570\u91cf\uff0c p_k\uff0c w_k \u4e3a\u666e\u901a\u5377\u79ef\u5b66\u4e60\u5230\u7684offset\u4ee5\u53ca\u6743\u91cd(\u5728\u540c\u4e00\u56fe\u7247\u540c\u4e00channel\u5904\u5904\u76f8\u540c), \\Delta p_k, \\Delta m_k \u4e3a\u65b0\u7248\u589e\u52a0\u7684\uff0c\u4e0e\u5f53\u524d\u533a\u57df\u76f8\u5173\u7684offset\u4ee5\u53ca\u6743\u91cd (offset \u5f62\u72b6\u4e3a [B, kernel_size**2, H, W]) \u800c \\Delta p_k, \\Delta m_k \u7531\u5f53\u524d\u4f4d\u7f6e\u5377\u79ef\u4ea7\u751f\uff0c\u6bd4\u5982\u4f7f\u7528K=9\uff0c\u5bf9\u5f53\u524d\u4f4d\u7f6e\u4f7f\u7528\u6b63\u5e38\u5377\u79ef\uff0c\u5f97\u523027\u4e2achannel\uff0c\u524d18\u4e2achannel\u5206\u522b\u5bf9\u5e94 \\Delta p_k \u7684\u4e24\u4e2a\u5750\u6807,\u540e9\u4e2achannel\u7ecf\u8fc7sigmoid\u6fc0\u6d3b\u540e\u53d8\u4e3a \\Delta m_k","title":"\u7ed3\u6784\u89e3\u8bfb"},{"location":"Building_Blocks/deformable_convnet_v2/#_2","text":"\u53ef\u4ee5\u5b66\u4e60\u672c\u6587github\u4e2d\u4f7f\u7528cuda\u8f85\u52a9\u5e2e\u5fd9\u5f00\u53d1pytorch\u5b50\u6a21\u5757\uff0c\u5982\u679c\u53ef\u80fd\u53ef\u4ee5\u9002\u5f53\u5b66\u4e60\u3002\u6709\u52a0\u901f\u4ee3\u7801\u8fd0\u884c\u7684\u6f5c\u80fd\u3002","title":"\u7ec6\u8282"},{"location":"Building_Blocks/mutualNet/","text":"MutualNet: Adaptive ConvNet via Mutual Learning from Network Width and Resolution \u8fd9\u7bc7paper\u57fa\u4e8e EfficientNet \u7684\u601d\u8def\uff0c\u5728\u6b64\u4e4b\u4e0a\u7ee7\u7eed\u53d1\u6563\u3002EfficientNet\u63d0\u51fainput scale\u4e0e\u7f51\u7edc\u7684\u5927\u5c0f\u8981\u4e00\u540cScale up. Methods Sandwich Rule \u4e2d\u95f4\u4e24\u4e2a\u7f51\u7edc\u7684\u8f93\u5165\u9700\u8981\u662f\u5728 0.25 \\times, 1.0\\times \u4e4b\u95f4\u9009\u53d6\u8f93\u5165\u5927\u5c0f\u3002 Inplace Distillation \u4e2d\u95f4\u7684\u7f51\u7edc\u4f7f\u7528\u7684\u6743\u91cd\u90fd\u662f\u4e00\u81f4\u7684\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6700\u5927\u5c42\u4f5c\u4e3aTeacher network,\u4e2d\u95f4\u5c42\u4f5c\u4e3aStudent network,\u4f7f\u7528KL Divergence\u4f5c\u8bad\u7ec3\u3002 Post-statistics of BN \u5728\u8bad\u7ec3\u5e76\u786e\u5b9a\u4e86\u9009\u62e9\u7684\u8f93\u5165\u5c3a\u5ea6\u4e4b\u540e\uff0c\u9700\u8981\u91cd\u65b0\u4e3asubnetwork\u6536\u96c6BN\u6570\u636e\u3002 Mutual Learning of different resolution \u68af\u5ea6\u9610\u8ff0: \\begin{aligned} \\frac{\\partial L}{\\partial W} &=\\frac{\\partial l_{W_{0: 0.4}, I_{R=128}}}{\\partial W_{0: 0.4}}+\\frac{\\partial l_{W_{0: 0.8}, I_{R=192}}}{\\partial W_{0: 0.8}} \\\\ &=\\frac{\\partial l_{W_{0: 0.4}, I_{R=128}}}{\\partial W_{0: 0.4}}+\\left(\\frac{\\partial l_{W_{0: 0.8}, I_{R=192}}}{\\partial W_{0: 0.4}} \\oplus \\frac{\\partial l_{W_{0: 0.8}, I_{R=192}}}{\\partial W_{0.4: 0.8}}\\right) \\\\ &=\\frac{\\partial l_{W_{0: 0.4}, I_{R=128}+\\partial l_{W_{0: 0.8}, I_{R=192}}} \\oplus \\frac{\\partial l_{W_{0: 0.8}, I_{R=192}}}{\\partial W_{0: 0.4}}}{\\partial W_{0.4: 0.8}} \\end{aligned}","title":"MutualNet: Adaptive ConvNet via Mutual Learning from Network Width and Resolution"},{"location":"Building_Blocks/mutualNet/#mutualnet-adaptive-convnet-via-mutual-learning-from-network-width-and-resolution","text":"\u8fd9\u7bc7paper\u57fa\u4e8e EfficientNet \u7684\u601d\u8def\uff0c\u5728\u6b64\u4e4b\u4e0a\u7ee7\u7eed\u53d1\u6563\u3002EfficientNet\u63d0\u51fainput scale\u4e0e\u7f51\u7edc\u7684\u5927\u5c0f\u8981\u4e00\u540cScale up.","title":"MutualNet: Adaptive ConvNet via Mutual Learning from Network Width and Resolution"},{"location":"Building_Blocks/mutualNet/#methods","text":"","title":"Methods"},{"location":"Building_Blocks/mutualNet/#sandwich-rule","text":"\u4e2d\u95f4\u4e24\u4e2a\u7f51\u7edc\u7684\u8f93\u5165\u9700\u8981\u662f\u5728 0.25 \\times, 1.0\\times \u4e4b\u95f4\u9009\u53d6\u8f93\u5165\u5927\u5c0f\u3002","title":"Sandwich Rule"},{"location":"Building_Blocks/mutualNet/#inplace-distillation","text":"\u4e2d\u95f4\u7684\u7f51\u7edc\u4f7f\u7528\u7684\u6743\u91cd\u90fd\u662f\u4e00\u81f4\u7684\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6700\u5927\u5c42\u4f5c\u4e3aTeacher network,\u4e2d\u95f4\u5c42\u4f5c\u4e3aStudent network,\u4f7f\u7528KL Divergence\u4f5c\u8bad\u7ec3\u3002","title":"Inplace Distillation"},{"location":"Building_Blocks/mutualNet/#post-statistics-of-bn","text":"\u5728\u8bad\u7ec3\u5e76\u786e\u5b9a\u4e86\u9009\u62e9\u7684\u8f93\u5165\u5c3a\u5ea6\u4e4b\u540e\uff0c\u9700\u8981\u91cd\u65b0\u4e3asubnetwork\u6536\u96c6BN\u6570\u636e\u3002","title":"Post-statistics of BN"},{"location":"Building_Blocks/mutualNet/#mutual-learning-of-different-resolution","text":"\u68af\u5ea6\u9610\u8ff0: \\begin{aligned} \\frac{\\partial L}{\\partial W} &=\\frac{\\partial l_{W_{0: 0.4}, I_{R=128}}}{\\partial W_{0: 0.4}}+\\frac{\\partial l_{W_{0: 0.8}, I_{R=192}}}{\\partial W_{0: 0.8}} \\\\ &=\\frac{\\partial l_{W_{0: 0.4}, I_{R=128}}}{\\partial W_{0: 0.4}}+\\left(\\frac{\\partial l_{W_{0: 0.8}, I_{R=192}}}{\\partial W_{0: 0.4}} \\oplus \\frac{\\partial l_{W_{0: 0.8}, I_{R=192}}}{\\partial W_{0.4: 0.8}}\\right) \\\\ &=\\frac{\\partial l_{W_{0: 0.4}, I_{R=128}+\\partial l_{W_{0: 0.8}, I_{R=192}}} \\oplus \\frac{\\partial l_{W_{0: 0.8}, I_{R=192}}}{\\partial W_{0: 0.4}}}{\\partial W_{0.4: 0.8}} \\end{aligned}","title":"Mutual Learning of different resolution"},{"location":"Building_Blocks/shape_adaptor/","text":"Shape Adaptor: A Learnable Resizing Module def ShapeAdaptor ( input1 , input2 , alpha , residual = False , r1 = 0.5 , r2 = 1.0 ): # sigmoid_alpha = sigmoid(alpha) if having penalty, i.e. penalty = 1; # the penalty value will be defined/computed in the model_training file sigmoid_alpha = torch . sigmoid ( alpha ) * ShapeAdaptor . penalty + r1 / ( r2 - r1 ) * ( ShapeAdaptor . penalty - 1 ) s_alpha = ( r2 - r1 ) * sigmoid_alpha . item () + r1 # total no. of shape adaptors ShapeAdaptor . counter += 1 # the true current dim without any penalty (will be used for computing the correct penalty value) ShapeAdaptor . current_dim_true *= (( r2 - r1 ) * torch . sigmoid ( alpha ) . item () + r1 ) if ShapeAdaptor . type == 'local' : # a shape adaptor will drop at least 1 dimension (local structure), used in standard or AutoTL mode ShapeAdaptor . current_dim = int ( ShapeAdaptor . current_dim * s_alpha ) dim = 1 if ShapeAdaptor . current_dim < 1 else ShapeAdaptor . current_dim # output dim should be at least 1 elif ShapeAdaptor . type == 'global' : # a shape adaptor could maintain the same dimension (global structure), used in AutoSC mode ShapeAdaptor . current_dim = ShapeAdaptor . current_dim * s_alpha dim = 1 if ShapeAdaptor . current_dim < 1 else round ( ShapeAdaptor . current_dim ) # output dim should be at least 1 ''' input1 = resizing(x, scale=r1); input2 = resizing(x, scale=r2) It's important to debug/confirm your model design using these two different implementations. Implementation A: input2_rs = F.interpolate(input2, scale_factor=(1/r2)*s_alpha, mode='bilinear', align_corners=True) input1_rs = F.interpolate(input1, size=input2_rs.shape[-2:], mode='bilinear', align_corners=True) Implementation B: input1_rs = F.interpolate(input1, scale_factor=(1/r1)*s_alpha, mode='bilinear', align_corners=True) input2_rs = F.interpolate(input2, size=input1_rs.shape[-2:], mode='bilinear', align_corners=True) Those two implementations (along with an additional version below) should produce the same shape. Note: +- 1 dim change in intermediate layers is expected due to different rounding methods. ''' input1_rs = F . interpolate ( input1 , size = dim , mode = 'bilinear' , align_corners = True ) input2_rs = F . interpolate ( input2 , size = dim , mode = 'bilinear' , align_corners = True ) if residual : # to keep gradient magnitude consistent with standard residuals: f(x) + x return 2 * ( 1 - sigmoid_alpha ) * input1_rs + 2 * sigmoid_alpha * input2_rs else : return ( 1 - sigmoid_alpha ) * input1_rs + sigmoid_alpha * input2_rs","title":"Shape Adaptor: A Learnable Resizing Module"},{"location":"Building_Blocks/shape_adaptor/#shape-adaptor-a-learnable-resizing-module","text":"def ShapeAdaptor ( input1 , input2 , alpha , residual = False , r1 = 0.5 , r2 = 1.0 ): # sigmoid_alpha = sigmoid(alpha) if having penalty, i.e. penalty = 1; # the penalty value will be defined/computed in the model_training file sigmoid_alpha = torch . sigmoid ( alpha ) * ShapeAdaptor . penalty + r1 / ( r2 - r1 ) * ( ShapeAdaptor . penalty - 1 ) s_alpha = ( r2 - r1 ) * sigmoid_alpha . item () + r1 # total no. of shape adaptors ShapeAdaptor . counter += 1 # the true current dim without any penalty (will be used for computing the correct penalty value) ShapeAdaptor . current_dim_true *= (( r2 - r1 ) * torch . sigmoid ( alpha ) . item () + r1 ) if ShapeAdaptor . type == 'local' : # a shape adaptor will drop at least 1 dimension (local structure), used in standard or AutoTL mode ShapeAdaptor . current_dim = int ( ShapeAdaptor . current_dim * s_alpha ) dim = 1 if ShapeAdaptor . current_dim < 1 else ShapeAdaptor . current_dim # output dim should be at least 1 elif ShapeAdaptor . type == 'global' : # a shape adaptor could maintain the same dimension (global structure), used in AutoSC mode ShapeAdaptor . current_dim = ShapeAdaptor . current_dim * s_alpha dim = 1 if ShapeAdaptor . current_dim < 1 else round ( ShapeAdaptor . current_dim ) # output dim should be at least 1 ''' input1 = resizing(x, scale=r1); input2 = resizing(x, scale=r2) It's important to debug/confirm your model design using these two different implementations. Implementation A: input2_rs = F.interpolate(input2, scale_factor=(1/r2)*s_alpha, mode='bilinear', align_corners=True) input1_rs = F.interpolate(input1, size=input2_rs.shape[-2:], mode='bilinear', align_corners=True) Implementation B: input1_rs = F.interpolate(input1, scale_factor=(1/r1)*s_alpha, mode='bilinear', align_corners=True) input2_rs = F.interpolate(input2, size=input1_rs.shape[-2:], mode='bilinear', align_corners=True) Those two implementations (along with an additional version below) should produce the same shape. Note: +- 1 dim change in intermediate layers is expected due to different rounding methods. ''' input1_rs = F . interpolate ( input1 , size = dim , mode = 'bilinear' , align_corners = True ) input2_rs = F . interpolate ( input2 , size = dim , mode = 'bilinear' , align_corners = True ) if residual : # to keep gradient magnitude consistent with standard residuals: f(x) + x return 2 * ( 1 - sigmoid_alpha ) * input1_rs + 2 * sigmoid_alpha * input2_rs else : return ( 1 - sigmoid_alpha ) * input1_rs + sigmoid_alpha * input2_rs","title":"Shape Adaptor: A Learnable Resizing Module"},{"location":"Planning_Control_DL/Aggressive_Driving_with_Model_Predictive_Path_Integral_Control/","text":"Aggressive Driving with Model Predictive Path Integral Control \u672c\u7bc7\u8bba\u6587\u5c06Path integral Control\u4f7f\u7528\u5728\u81ea\u52a8\u9a7e\u9a76\u4e4b\u4e2d\uff0cPath integral Control\u5c5e\u4e8e\u968f\u673a\u6700\u4f18\u63a7\u5236\u7684\u7b97\u6cd5\uff0c\u6982\u5ff5\u5927\u6982\u662f\u8fd9\u6837\u7684\uff0c\u4f7f\u7528\u968f\u673a\u63a7\u5236\u503c\u8fdb\u884c\u63a2\u7d22\u4e0e\u9884\u6d4b\uff0c\u7136\u540e\u4e0e\u5176\u9009\u62e9\u5176\u4e2d\u6700\u4f18\u7684\uff0c\u7efc\u5408\u5404\u4e2a\u70b9\u7684\u6210\u672c\u4ee5\u53ca\u884c\u52a8\u8f68\u8ff9\uff0c\u5f97\u5230\u4e00\u4e2a\u7ecf\u9a8c\u4e0a\u7684\u6700\u4f18\u63a7\u5236\u7ed3\u679c\u3002 \u5728\u6bcf\u4e00\u4e2a\u65f6\u523b\uff1a \u786e\u5b9a\u53c2\u6570\uff0c\u968f\u673a\u91c7\u6837\u6570K\uff0c\u9884\u6d4b\u6b65\u957fN\uff0c\u521d\u59cb\u5316N\u4e2a\u521d\u59cb\u7684\u63a7\u5236\u5e8f\u5217\u3002 \u5bf9\u6bcf\u4e00\u4e2a\u91c7\u6837\u70b9(\u5e76\u884c\u8fdb\u884c)\uff0c\u52a0\u5165\u968f\u673a\u6270\u52a8\u5e8f\u5217\u5e76\u5f80\u524d\u9884\u6d4bN\u6b65\uff0c\u5f97\u5230\u5206\u522b\u7684\u603bcost \u8fd9\u91cc\u6ce8\u610f\u56fe\u4e2d\u7684 HG^{-1} = \\gamma \u662f\u4e00\u4e2a\u66f4\u65b0\u63a7\u5236\u53c2\u6570 \u4f7f\u7528\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u7684\u601d\u8def\uff0c\u53ea\u6267\u884c\u7b2c\u4e00\u4e2a\u63a7\u5236\u7ed3\u679c \u5b9e\u73b0\u7ec6\u8282\uff1a 1. \u6bcf\u4e00\u4e2a\u91c7\u6837\u70b9\u7684\u9884\u6d4b\u66f4\u65b0\u4ee5\u53ca\u6c42\u548c\u53ef\u4ee5\u7528GPU\u5e76\u884c\u5b8c\u6210(\u7528\u4e0a\u5343\u4e2a\u968f\u673a\u91c7\u6837\u6837\u672c) 2. \u5728\u5b9e\u65f6\u6267\u884c\u7684\u65f6\u5019\uff0c\u6bcf\u4e2a\u65f6\u523b\u53ea\u9700\u8981\u968f\u673a\u4f18\u5316\u6574\u4e2a\u5e8f\u5217\u4e00\u6b65\uff0c\u5e8f\u5217\u540e\u9762\u5730\u65b9\u53ef\u4ee5\u4f7f\u7528\u524d\u4e00\u4e2a\u65f6\u95f4\u6b65\u65f6\u7684\u4f18\u5316\u7ed3\u679c\u3002 3. \u672c\u6587\u63a7\u5236\u7684\u65f6\u5019\u8fd8\u662f\u5bf9\u63a7\u5236\u7ed3\u679c\u8fdb\u884c\u4e86\u5e73\u6ed1\u3002 \u7406\u8bba\u7ec6\u8282\uff1a 1. \u8981\u5b9e\u73b0\u4e0a\u6587\u56fe\u4e2d\u7684\u7b97\u6cd5\u8fd9\u4e00\u5316\u7b80\uff0c\u8981\u6c42\u7684\u662f\u968f\u673a\u566a\u58f0\u7684\u4f5c\u7528\u77e9\u9635 B \u7684\u4e0d\u53ef\u63a7\u5236\u4e0e\u53ef\u63a7\u5236\u90e8\u5206\uff0c\u4e0d\u53ef\u4ee5\u6709\u76f8\u5173\u9879 2. HG^{-1} = G_c^{-1} B_c \uff0c G_c \u5c31\u662f\u7cfb\u7edf\u52a8\u6001\u65b9\u7a0b\u4e2d\u7684\u53ef\u63a7\u90e8\u5206, B_c \u662f\u5e03\u6717\u6f02\u79fb\u5bf9\u5e94\u7684\u53ef\u63a7\u90e8\u5206\uff0c\u5728\u6211\u4eec\u4f18\u5316\u7684\u65f6\u5019\u5f80\u5f80\u4e24\u4e2a\u77e9\u9635\u662f\u76f8\u540c\u7684(\u5047\u8bbe\u63a7\u5236\u7ed3\u679c\u4ee5\u53ca\u6210\u672c\u4e0a\u662f\u4eff\u5c04\u7684)\uff0c\u90a3\u4e48\u8fd9\u4e2a \\gamma = 1 \u4e3a\u5e38\u6001 3. \\lambda \u662f\u6e29\u5ea6\uff0c\u4f1a\u63a7\u5236\u5141\u8bb8\u6ce2\u52a8\u7684\u81ea\u7531\u80fd\u7684\u5927\u5c0f,\u76f4\u89c9\u7ed3\u679c\u662f\u5f53 \\lambda \u8d8a\u5c0f\u7684\u65f6\u5019\uff0c\u7ed3\u679c\u66f4\u8d8b\u5411\u76f4\u63a5\u53d6\u6700\u4f18\uff0c\u5f53 \\lambda \u8d8a\u5927\u7684\u65f6\u5019\uff0c\u7ed3\u679c\u66f4\u8d8b\u5411\u4e8e\u968f\u673a\u9009\u62e9\u3002","title":"Aggressive Driving with Model Predictive Path Integral Control"},{"location":"Planning_Control_DL/Aggressive_Driving_with_Model_Predictive_Path_Integral_Control/#aggressive-driving-with-model-predictive-path-integral-control","text":"\u672c\u7bc7\u8bba\u6587\u5c06Path integral Control\u4f7f\u7528\u5728\u81ea\u52a8\u9a7e\u9a76\u4e4b\u4e2d\uff0cPath integral Control\u5c5e\u4e8e\u968f\u673a\u6700\u4f18\u63a7\u5236\u7684\u7b97\u6cd5\uff0c\u6982\u5ff5\u5927\u6982\u662f\u8fd9\u6837\u7684\uff0c\u4f7f\u7528\u968f\u673a\u63a7\u5236\u503c\u8fdb\u884c\u63a2\u7d22\u4e0e\u9884\u6d4b\uff0c\u7136\u540e\u4e0e\u5176\u9009\u62e9\u5176\u4e2d\u6700\u4f18\u7684\uff0c\u7efc\u5408\u5404\u4e2a\u70b9\u7684\u6210\u672c\u4ee5\u53ca\u884c\u52a8\u8f68\u8ff9\uff0c\u5f97\u5230\u4e00\u4e2a\u7ecf\u9a8c\u4e0a\u7684\u6700\u4f18\u63a7\u5236\u7ed3\u679c\u3002 \u5728\u6bcf\u4e00\u4e2a\u65f6\u523b\uff1a \u786e\u5b9a\u53c2\u6570\uff0c\u968f\u673a\u91c7\u6837\u6570K\uff0c\u9884\u6d4b\u6b65\u957fN\uff0c\u521d\u59cb\u5316N\u4e2a\u521d\u59cb\u7684\u63a7\u5236\u5e8f\u5217\u3002 \u5bf9\u6bcf\u4e00\u4e2a\u91c7\u6837\u70b9(\u5e76\u884c\u8fdb\u884c)\uff0c\u52a0\u5165\u968f\u673a\u6270\u52a8\u5e8f\u5217\u5e76\u5f80\u524d\u9884\u6d4bN\u6b65\uff0c\u5f97\u5230\u5206\u522b\u7684\u603bcost \u8fd9\u91cc\u6ce8\u610f\u56fe\u4e2d\u7684 HG^{-1} = \\gamma \u662f\u4e00\u4e2a\u66f4\u65b0\u63a7\u5236\u53c2\u6570 \u4f7f\u7528\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u7684\u601d\u8def\uff0c\u53ea\u6267\u884c\u7b2c\u4e00\u4e2a\u63a7\u5236\u7ed3\u679c \u5b9e\u73b0\u7ec6\u8282\uff1a 1. \u6bcf\u4e00\u4e2a\u91c7\u6837\u70b9\u7684\u9884\u6d4b\u66f4\u65b0\u4ee5\u53ca\u6c42\u548c\u53ef\u4ee5\u7528GPU\u5e76\u884c\u5b8c\u6210(\u7528\u4e0a\u5343\u4e2a\u968f\u673a\u91c7\u6837\u6837\u672c) 2. \u5728\u5b9e\u65f6\u6267\u884c\u7684\u65f6\u5019\uff0c\u6bcf\u4e2a\u65f6\u523b\u53ea\u9700\u8981\u968f\u673a\u4f18\u5316\u6574\u4e2a\u5e8f\u5217\u4e00\u6b65\uff0c\u5e8f\u5217\u540e\u9762\u5730\u65b9\u53ef\u4ee5\u4f7f\u7528\u524d\u4e00\u4e2a\u65f6\u95f4\u6b65\u65f6\u7684\u4f18\u5316\u7ed3\u679c\u3002 3. \u672c\u6587\u63a7\u5236\u7684\u65f6\u5019\u8fd8\u662f\u5bf9\u63a7\u5236\u7ed3\u679c\u8fdb\u884c\u4e86\u5e73\u6ed1\u3002 \u7406\u8bba\u7ec6\u8282\uff1a 1. \u8981\u5b9e\u73b0\u4e0a\u6587\u56fe\u4e2d\u7684\u7b97\u6cd5\u8fd9\u4e00\u5316\u7b80\uff0c\u8981\u6c42\u7684\u662f\u968f\u673a\u566a\u58f0\u7684\u4f5c\u7528\u77e9\u9635 B \u7684\u4e0d\u53ef\u63a7\u5236\u4e0e\u53ef\u63a7\u5236\u90e8\u5206\uff0c\u4e0d\u53ef\u4ee5\u6709\u76f8\u5173\u9879 2. HG^{-1} = G_c^{-1} B_c \uff0c G_c \u5c31\u662f\u7cfb\u7edf\u52a8\u6001\u65b9\u7a0b\u4e2d\u7684\u53ef\u63a7\u90e8\u5206, B_c \u662f\u5e03\u6717\u6f02\u79fb\u5bf9\u5e94\u7684\u53ef\u63a7\u90e8\u5206\uff0c\u5728\u6211\u4eec\u4f18\u5316\u7684\u65f6\u5019\u5f80\u5f80\u4e24\u4e2a\u77e9\u9635\u662f\u76f8\u540c\u7684(\u5047\u8bbe\u63a7\u5236\u7ed3\u679c\u4ee5\u53ca\u6210\u672c\u4e0a\u662f\u4eff\u5c04\u7684)\uff0c\u90a3\u4e48\u8fd9\u4e2a \\gamma = 1 \u4e3a\u5e38\u6001 3. \\lambda \u662f\u6e29\u5ea6\uff0c\u4f1a\u63a7\u5236\u5141\u8bb8\u6ce2\u52a8\u7684\u81ea\u7531\u80fd\u7684\u5927\u5c0f,\u76f4\u89c9\u7ed3\u679c\u662f\u5f53 \\lambda \u8d8a\u5c0f\u7684\u65f6\u5019\uff0c\u7ed3\u679c\u66f4\u8d8b\u5411\u76f4\u63a5\u53d6\u6700\u4f18\uff0c\u5f53 \\lambda \u8d8a\u5927\u7684\u65f6\u5019\uff0c\u7ed3\u679c\u66f4\u8d8b\u5411\u4e8e\u968f\u673a\u9009\u62e9\u3002","title":"Aggressive Driving with Model Predictive Path Integral Control"},{"location":"Planning_Control_DL/Backprop KF Learning Discriminative DeterministicState Estimators/","text":"Backprop KF: Learning Discriminative DeterministicState Estimators \u8fd9\u662f\u4e00\u7bc7\u6bd4\u8f83\u65e9\u671f\u7684\u8bba\u6587\uff0c\u4ecb\u7ecd\u7684\u662f\u53ef\u5fae\u5206\u5361\u5c14\u66fc\u6ee4\u6ce2\u3002 \u6838\u5fc3\u7ed3\u6784 \u7528CNN\u8f93\u51fa\u4e00\u7ef4\u7684\u89c2\u6d4b\u77e2\u91cf\uff0c\u4ee5\u53ca\u89c2\u6d4b\u7684covariance\u77e9\u9635\u3002 \u89c2\u6d4b\u7684covariance\u77e9\u9635\u7684\u751f\u6210\u65b9\u5f0f\uff1a Relu->diag->square \u5176\u4f59\u4e2d\u95f4\u516c\u5f0f\u4e0e\u5361\u5c14\u66fc\u6ee4\u6ce2\u4e00\u81f4\uff0c\u6a21\u578b\u52a8\u6001\u65b9\u7a0b\u4e0e\u89c2\u6d4b\u65b9\u7a0b\u7686(\u72b6\u6001\u7a7a\u95f4ABCD\uff0cQ\u77e9\u9635)\u7686\u4e3a\u53ef\u5b66\u4e60\u7684\u53c2\u6570","title":"Backprop KF: Learning Discriminative DeterministicState Estimators"},{"location":"Planning_Control_DL/Backprop KF Learning Discriminative DeterministicState Estimators/#backprop-kf-learning-discriminative-deterministicstate-estimators","text":"\u8fd9\u662f\u4e00\u7bc7\u6bd4\u8f83\u65e9\u671f\u7684\u8bba\u6587\uff0c\u4ecb\u7ecd\u7684\u662f\u53ef\u5fae\u5206\u5361\u5c14\u66fc\u6ee4\u6ce2\u3002","title":"Backprop KF: Learning Discriminative DeterministicState Estimators"},{"location":"Planning_Control_DL/Backprop KF Learning Discriminative DeterministicState Estimators/#_1","text":"\u7528CNN\u8f93\u51fa\u4e00\u7ef4\u7684\u89c2\u6d4b\u77e2\u91cf\uff0c\u4ee5\u53ca\u89c2\u6d4b\u7684covariance\u77e9\u9635\u3002 \u89c2\u6d4b\u7684covariance\u77e9\u9635\u7684\u751f\u6210\u65b9\u5f0f\uff1a Relu->diag->square \u5176\u4f59\u4e2d\u95f4\u516c\u5f0f\u4e0e\u5361\u5c14\u66fc\u6ee4\u6ce2\u4e00\u81f4\uff0c\u6a21\u578b\u52a8\u6001\u65b9\u7a0b\u4e0e\u89c2\u6d4b\u65b9\u7a0b\u7686(\u72b6\u6001\u7a7a\u95f4ABCD\uff0cQ\u77e9\u9635)\u7686\u4e3a\u53ef\u5b66\u4e60\u7684\u53c2\u6570","title":"\u6838\u5fc3\u7ed3\u6784"},{"location":"Planning_Control_DL/Cognitive Mapping and Planning for Visual Navigation/","text":"Cognitive Mapping and Planning for Visual Navigation \u8fd9\u7bc7\u8bba\u6587\u57282017\u5e74\u63d0\u51fa\u4e86\u76f4\u63a5\u5229\u7528\u89c6\u89c9\u8fdb\u884c\u5bfc\u822a\u7684\u601d\u8def \u603b\u4f53\u7ed3\u6784: \u8f93\u5165\u4e3aEgomotion, Goal, \u89c6\u89c9\u56fe\u50cf\u8f93\u5165, \u8f93\u51fa\u65f6action\uff0c\u4e2d\u95f4\u4f7f\u7528\u53ef\u5fae\u5206Mapper\u548c\u53ef\u5fae\u5206Planner Mapper \u8fd9\u91cc\u7ed9\u51fa\u7684mapper\u7ed3\u6784\u5982\u4e0a\u56fe\uff0c\u5df2\u77e5\u4e0a\u4e00\u65f6\u523b\u5bf9\u73af\u5883\u5efa\u56fe\u7ed3\u679c\u4ee5\u53ca\u672c\u4f53\u8fd0\u52a8\uff0c\u901a\u8fc7\u53ef\u5fae\u5206\u7684\u56fe\u7247\u5e73\u79fb\u548c\u65cb\u8f6c\uff0c\u5f97\u5230\u5bf9\u73b0\u5728\u5730\u56fe\u7684\u4f30\u8ba1\uff0c\u4e0e\u65b0\u56fe\u7247\u7ecf\u8fc7encoder\u3001decoder\u4e4b\u540e\u7684\u8f93\u51fa\u8fdb\u884c\u5408\u5e76\uff0c\u5f97\u5230\u5f53\u524d\u4e16\u754c\u7684\u4f30\u8ba1\u3002 Planner \u8fd9\u91cc\u7ed9\u51fa\u7684\u591a\u5c42\u7ea7Planner\u7ed3\u6784\u5982\u4e0a\u56fe\uff0c\u7b97\u6cd5\u5982\u4e0b \u5728\u6700\u5927\u7684\u5730\u56fe\u6700\u5c0f\u5b9e\u9645\u8ddd\u79bb\u5206\u8fa8\u7387\u7684costmap(\u6765\u81eamapper)\u4e0a\u5e26\u7740goal\u4fe1\u606f(\u5377\u79ef\u5408\u6210)\uff0c\u8fdb\u884cvalue-iteration(\u65b9\u6cd5\u540cQMDP\u4e2d\u63d0\u5230\u7684planner\u7684\u505a\u6cd5) \u5206\u5272\u51faValue Map\u4e2d\u5fc3\u90e8\u5206\uff0c\u4e0b\u91c7\u6837,\u4e0eGoal\u548cCostmap\u5377\u79ef\u5408\u6210\uff0c\u518d\u8fdb\u884cvalue-iteration \u91cd\u590d2\uff0c\u76f4\u5230\u5206\u8fa8\u7387\u8db3\u591f\u5c0f\u4e3a\u6b62\uff0c\u6700\u7ec8\u5168\u8fde\u63a5\u8f93\u5165\u884c\u52a8\u503c\u3002 \u663e\u7136\u8fd9\u4e2aplanner\u4e0eMapper\u90fd\u662f\u53ef\u5bfc\u7684\u8fd0\u7b97\u8fc7\u7a0b\uff0c\u53ef\u4ee5\u7aef\u5230\u7aef\u5b66\u4e60\u3002\u7f3a\u70b9\u5728\u4e8eValue-iteration\u7528\u4e8eplanner\u8fd9\u4e2a\u76ee\u524d\u53ea\u57282D\u5e73\u9762\u5bfc\u822a\u4e2d\u89c2\u5bdf\u8fc7\uff0c\u6709\u5f85\u8003\u8651\u3002","title":"Cognitive Mapping and Planning for Visual Navigation"},{"location":"Planning_Control_DL/Cognitive Mapping and Planning for Visual Navigation/#cognitive-mapping-and-planning-for-visual-navigation","text":"\u8fd9\u7bc7\u8bba\u6587\u57282017\u5e74\u63d0\u51fa\u4e86\u76f4\u63a5\u5229\u7528\u89c6\u89c9\u8fdb\u884c\u5bfc\u822a\u7684\u601d\u8def \u603b\u4f53\u7ed3\u6784: \u8f93\u5165\u4e3aEgomotion, Goal, \u89c6\u89c9\u56fe\u50cf\u8f93\u5165, \u8f93\u51fa\u65f6action\uff0c\u4e2d\u95f4\u4f7f\u7528\u53ef\u5fae\u5206Mapper\u548c\u53ef\u5fae\u5206Planner","title":"Cognitive Mapping and Planning for Visual Navigation"},{"location":"Planning_Control_DL/Cognitive Mapping and Planning for Visual Navigation/#mapper","text":"\u8fd9\u91cc\u7ed9\u51fa\u7684mapper\u7ed3\u6784\u5982\u4e0a\u56fe\uff0c\u5df2\u77e5\u4e0a\u4e00\u65f6\u523b\u5bf9\u73af\u5883\u5efa\u56fe\u7ed3\u679c\u4ee5\u53ca\u672c\u4f53\u8fd0\u52a8\uff0c\u901a\u8fc7\u53ef\u5fae\u5206\u7684\u56fe\u7247\u5e73\u79fb\u548c\u65cb\u8f6c\uff0c\u5f97\u5230\u5bf9\u73b0\u5728\u5730\u56fe\u7684\u4f30\u8ba1\uff0c\u4e0e\u65b0\u56fe\u7247\u7ecf\u8fc7encoder\u3001decoder\u4e4b\u540e\u7684\u8f93\u51fa\u8fdb\u884c\u5408\u5e76\uff0c\u5f97\u5230\u5f53\u524d\u4e16\u754c\u7684\u4f30\u8ba1\u3002","title":"Mapper"},{"location":"Planning_Control_DL/Cognitive Mapping and Planning for Visual Navigation/#planner","text":"\u8fd9\u91cc\u7ed9\u51fa\u7684\u591a\u5c42\u7ea7Planner\u7ed3\u6784\u5982\u4e0a\u56fe\uff0c\u7b97\u6cd5\u5982\u4e0b \u5728\u6700\u5927\u7684\u5730\u56fe\u6700\u5c0f\u5b9e\u9645\u8ddd\u79bb\u5206\u8fa8\u7387\u7684costmap(\u6765\u81eamapper)\u4e0a\u5e26\u7740goal\u4fe1\u606f(\u5377\u79ef\u5408\u6210)\uff0c\u8fdb\u884cvalue-iteration(\u65b9\u6cd5\u540cQMDP\u4e2d\u63d0\u5230\u7684planner\u7684\u505a\u6cd5) \u5206\u5272\u51faValue Map\u4e2d\u5fc3\u90e8\u5206\uff0c\u4e0b\u91c7\u6837,\u4e0eGoal\u548cCostmap\u5377\u79ef\u5408\u6210\uff0c\u518d\u8fdb\u884cvalue-iteration \u91cd\u590d2\uff0c\u76f4\u5230\u5206\u8fa8\u7387\u8db3\u591f\u5c0f\u4e3a\u6b62\uff0c\u6700\u7ec8\u5168\u8fde\u63a5\u8f93\u5165\u884c\u52a8\u503c\u3002 \u663e\u7136\u8fd9\u4e2aplanner\u4e0eMapper\u90fd\u662f\u53ef\u5bfc\u7684\u8fd0\u7b97\u8fc7\u7a0b\uff0c\u53ef\u4ee5\u7aef\u5230\u7aef\u5b66\u4e60\u3002\u7f3a\u70b9\u5728\u4e8eValue-iteration\u7528\u4e8eplanner\u8fd9\u4e2a\u76ee\u524d\u53ea\u57282D\u5e73\u9762\u5bfc\u822a\u4e2d\u89c2\u5bdf\u8fc7\uff0c\u6709\u5f85\u8003\u8651\u3002","title":"Planner"},{"location":"Planning_Control_DL/Composable_Action-Conditioned_Predictors_Flexible_Off-Policy_Learning_for_Robot_Navigation/","text":"Composable Action-Conditioned Predictors: Flexible Off-Policy Learning for Robot Navigation \u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7075\u6d3b\u7684\u3001\u5c11\u76d1\u7763\u7684\u589e\u5f3a\u5b66\u4e60\u5bfc\u822a\u6846\u67b6\u3002\u6a21\u578b\u7684\u5b66\u4e60\u8fc7\u7a0b\u4f7f\u7528\u8f83\u4e3a\u6709\u9650\u7684\u76d1\u7763\uff0c\u540c\u4e00\u4e2a\u6a21\u578b\u53ef\u5728deploy\u65f6\u901a\u8fc7\u4fee\u6539reward\u51fd\u6570\u662f\u7684\u673a\u5668\u4eba\u8fbe\u5230\u6211\u4eec\u60f3\u8981\u7684\u5bfc\u822a\u6548\u679c CAPs\u6a21\u578b\u4ecb\u7ecd CAPs\u7ed3\u6784\u7684\u76ee\u7684\u662f\u901a\u8fc7\u8f93\u5165\u7684\u56fe\u7247\u3001\u72b6\u6001\u5e8f\u5217\uff0c\u8f93\u51fa\u5f53\u524d\u72b6\u6001\u4e0b\u51e0\u4e2a\u91cd\u8981\u7684encoded event\u7684\u76f8\u5173\u53c2\u6570\u3002\u672c\u8bba\u6587\u4f7f\u7528\u7684\u662fcollision, heading\uff0c or road lanes and doorways(\u95e8\u5728\u56fe\u7247\u4e2d\u7684\u6bd4\u4f8b)\u3002\u8fc7\u7a0b\u662foff-policy\u7684\uff0c\u6a21\u578b\u53d6\u51b3\u4e8e\u4e00\u4e2a\u957f\u5ea6\u4e3aN\u7684\u672a\u6765\u7684action list\uff0c\u6570\u636e\u91c7\u96c6\u8fc7\u7a0b\u91c7\u7528\u7684policy\u4e0e\u6700\u7ec8deploy\u6ca1\u6709\u5fc5\u7136\u8054\u7cfb\u3002 \u5728deploy\u7684\u65f6\u5019\uff0c\u7528\u6237\u57fa\u4e8eencoded event\u5b9a\u4e49\u65b0\u7684reward function\uff0c \u7cfb\u7edf\u901a\u8fc7MPC\u4f18\u5316\u5b9e\u73b0\u63a7\u5236\u3002 \u6df1\u5ea6\u5b66\u4e60\u7ed3\u6784 \u5377\u79ef\u63d0\u7279\u5f81->concat\u72b6\u6001\u5411\u91cf->\u5168\u8fde\u63a5-> multiplicative integration LSTM \u7684\u521d\u59cb\u72b6\u6001\u503c->\u8f93\u5165\u5e8f\u5217action->\u901a\u8fc7FC\u5206\u652f\u8f93\u51fa\u5404\u4e2aencoded event\u7684\u53c2\u6570 encoded events (event cues) \u8fd9\u91cc\u9009\u62e9\u7684collision\u4ee5\u53caheading\u4ee5\u53ca\u901f\u5ea6\u7b49\u53ef\u4ee5\u901a\u8fc7\u8f66\u8eab\u4f20\u611f\u5668\u6d4b\u5f97\u81ea\u52a8\u6807\u6ce8\uff0croad lanes\u548cdoorways\u8fd9\u91cc\u4f7f\u7528\u4e86\u4e00\u4e2apretrained FCN\u8fdb\u884c\u8bed\u4e49\u5206\u5272\u76f4\u63a5\u5f97\u5230\u7ed3\u679c \u4e09\u4e2a\u5b9e\u9a8c\u9879\u76ee \u4eff\u771f\u68ee\u6797\u8d70\u52a8 \u5956\u52b1\u51fd\u6570\u4e3a\uff1a R\\left(\\hat{E}_{t}^{(H, I)}\\right)=\\sum_{t^{\\prime}=t}^{t+H-1} 500 \\cdot\\left(1-\\hat{e}_{t^{\\prime}}^{(c o l l)}\\right)+\\left(\\cos \\left(\\hat{e}_{t^{\\prime}}^{(h e a d i n g)}-\\mathrm{GOAL}_{-} \\mathrm{HEADING}\\right)-1\\right) Carla\u4eff\u771f\u8fd0\u884c \u5956\u52b1\u51fd\u6570\u4e3a \\begin{aligned} R\\left(\\hat{E}_{t}^{(H, I)}\\right)=& \\sum_{t^{\\prime}=t}^{t+H-1} 50 \\cdot\\left(1-\\hat{e}_{t^{\\prime}}^{(c o l l)}\\right)-3 \\cdot \\frac{\\left|\\hat{e}_{t^{\\prime}}^{(s p e e d)}-\\operatorname{GOAL}_{-} \\operatorname{SPEB}\\right|}{\\operatorname{GOAL}_{-} \\operatorname{SPEED}}+5 \\cdot \\hat{e}_{t^{\\prime}}^{(l a n e-s e e n)}\\left(1-\\left|\\hat{e}_{t^{\\prime}}^{\\left(l a n e_{-} d i f f\\right)}\\right|\\right) \\\\ &-\\frac{5}{\\pi} \\cdot\\left|\\hat{e}_{t^{\\prime}}^{(h e a d i n g)}-\\operatorname{GOAL}_{-} \\operatorname{HEADING}\\right|-0.15 \\cdot\\left\\|\\mathbf{a}_{t^{\\prime}}^{(s t e e r)}\\right\\|_{2}^{2} \\end{aligned} \u9700\u8981\u9884\u6d4b\u7684\u5185\u5bb9\u5305\u62ec\uff1a\u78b0\u649e\u3001\u901f\u5ea6\u3001\u53ef\u89c1\u9053\u8def\u6bd4\u7387\u3001\u53ef\u89c1\u9053\u8def\u6bd4\u7387\u53d8\u5316\u7387\u3001\u671d\u5411 \u5b9e\u9645\u8f66\u8f86\u8fd0\u884c R\\left(\\hat{E}_{t}^{(H, I)}\\right)=\\sum_{t^{\\prime}=t}^{t+H-1}\\left(1-\\hat{e}_{t^{\\prime}}^{(c o l l)}\\right) \\cdot\\left[1-\\frac{0.1}{\\pi} \\cdot\\left|\\hat{e}_{t^{\\prime}}^{(h e a d i n g)}-\\operatorname{coth}_{-} \\operatorname{HEADING}\\right|+0.05 \\cdot \\hat{e}_{t^{\\prime}}^{(d o o r-f r a c)}\\right]-0.01 \\cdot\\left\\|\\mathbf{a}_{t^{\\prime}}\\right\\|_{2}^{2} \u9700\u8981\u9884\u6d4b\u7684\u5185\u5bb9\u5305\u62ec\uff1a\u78b0\u649e\u3001\u671d\u5411\u3001\u623f\u95f4\u95e8\u5360\u753b\u9762\u6bd4\u7387 \u5b83\u4eec\u4e3a\u4e86\u8bad\u7ec3Segmentation\u7f51\u7edc\u6807\u6ce8\u4e86\u8bad\u7ec3\u8fc7\u7a0b\u4e2d0.2%\u7684\u56fe\u50cf\u6570\u636e\u3002","title":"Composable Action-Conditioned Predictors: Flexible Off-Policy Learning for Robot Navigation"},{"location":"Planning_Control_DL/Composable_Action-Conditioned_Predictors_Flexible_Off-Policy_Learning_for_Robot_Navigation/#composable-action-conditioned-predictors-flexible-off-policy-learning-for-robot-navigation","text":"\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7075\u6d3b\u7684\u3001\u5c11\u76d1\u7763\u7684\u589e\u5f3a\u5b66\u4e60\u5bfc\u822a\u6846\u67b6\u3002\u6a21\u578b\u7684\u5b66\u4e60\u8fc7\u7a0b\u4f7f\u7528\u8f83\u4e3a\u6709\u9650\u7684\u76d1\u7763\uff0c\u540c\u4e00\u4e2a\u6a21\u578b\u53ef\u5728deploy\u65f6\u901a\u8fc7\u4fee\u6539reward\u51fd\u6570\u662f\u7684\u673a\u5668\u4eba\u8fbe\u5230\u6211\u4eec\u60f3\u8981\u7684\u5bfc\u822a\u6548\u679c","title":"Composable Action-Conditioned Predictors: Flexible Off-Policy Learning for Robot Navigation"},{"location":"Planning_Control_DL/Composable_Action-Conditioned_Predictors_Flexible_Off-Policy_Learning_for_Robot_Navigation/#caps","text":"CAPs\u7ed3\u6784\u7684\u76ee\u7684\u662f\u901a\u8fc7\u8f93\u5165\u7684\u56fe\u7247\u3001\u72b6\u6001\u5e8f\u5217\uff0c\u8f93\u51fa\u5f53\u524d\u72b6\u6001\u4e0b\u51e0\u4e2a\u91cd\u8981\u7684encoded event\u7684\u76f8\u5173\u53c2\u6570\u3002\u672c\u8bba\u6587\u4f7f\u7528\u7684\u662fcollision, heading\uff0c or road lanes and doorways(\u95e8\u5728\u56fe\u7247\u4e2d\u7684\u6bd4\u4f8b)\u3002\u8fc7\u7a0b\u662foff-policy\u7684\uff0c\u6a21\u578b\u53d6\u51b3\u4e8e\u4e00\u4e2a\u957f\u5ea6\u4e3aN\u7684\u672a\u6765\u7684action list\uff0c\u6570\u636e\u91c7\u96c6\u8fc7\u7a0b\u91c7\u7528\u7684policy\u4e0e\u6700\u7ec8deploy\u6ca1\u6709\u5fc5\u7136\u8054\u7cfb\u3002 \u5728deploy\u7684\u65f6\u5019\uff0c\u7528\u6237\u57fa\u4e8eencoded event\u5b9a\u4e49\u65b0\u7684reward function\uff0c \u7cfb\u7edf\u901a\u8fc7MPC\u4f18\u5316\u5b9e\u73b0\u63a7\u5236\u3002","title":"CAPs\u6a21\u578b\u4ecb\u7ecd"},{"location":"Planning_Control_DL/Composable_Action-Conditioned_Predictors_Flexible_Off-Policy_Learning_for_Robot_Navigation/#_1","text":"\u5377\u79ef\u63d0\u7279\u5f81->concat\u72b6\u6001\u5411\u91cf->\u5168\u8fde\u63a5-> multiplicative integration LSTM \u7684\u521d\u59cb\u72b6\u6001\u503c->\u8f93\u5165\u5e8f\u5217action->\u901a\u8fc7FC\u5206\u652f\u8f93\u51fa\u5404\u4e2aencoded event\u7684\u53c2\u6570","title":"\u6df1\u5ea6\u5b66\u4e60\u7ed3\u6784"},{"location":"Planning_Control_DL/Composable_Action-Conditioned_Predictors_Flexible_Off-Policy_Learning_for_Robot_Navigation/#encoded-events-event-cues","text":"\u8fd9\u91cc\u9009\u62e9\u7684collision\u4ee5\u53caheading\u4ee5\u53ca\u901f\u5ea6\u7b49\u53ef\u4ee5\u901a\u8fc7\u8f66\u8eab\u4f20\u611f\u5668\u6d4b\u5f97\u81ea\u52a8\u6807\u6ce8\uff0croad lanes\u548cdoorways\u8fd9\u91cc\u4f7f\u7528\u4e86\u4e00\u4e2apretrained FCN\u8fdb\u884c\u8bed\u4e49\u5206\u5272\u76f4\u63a5\u5f97\u5230\u7ed3\u679c","title":"encoded events (event cues)"},{"location":"Planning_Control_DL/Composable_Action-Conditioned_Predictors_Flexible_Off-Policy_Learning_for_Robot_Navigation/#_2","text":"","title":"\u4e09\u4e2a\u5b9e\u9a8c\u9879\u76ee"},{"location":"Planning_Control_DL/Composable_Action-Conditioned_Predictors_Flexible_Off-Policy_Learning_for_Robot_Navigation/#_3","text":"\u5956\u52b1\u51fd\u6570\u4e3a\uff1a R\\left(\\hat{E}_{t}^{(H, I)}\\right)=\\sum_{t^{\\prime}=t}^{t+H-1} 500 \\cdot\\left(1-\\hat{e}_{t^{\\prime}}^{(c o l l)}\\right)+\\left(\\cos \\left(\\hat{e}_{t^{\\prime}}^{(h e a d i n g)}-\\mathrm{GOAL}_{-} \\mathrm{HEADING}\\right)-1\\right)","title":"\u4eff\u771f\u68ee\u6797\u8d70\u52a8"},{"location":"Planning_Control_DL/Composable_Action-Conditioned_Predictors_Flexible_Off-Policy_Learning_for_Robot_Navigation/#carla","text":"\u5956\u52b1\u51fd\u6570\u4e3a \\begin{aligned} R\\left(\\hat{E}_{t}^{(H, I)}\\right)=& \\sum_{t^{\\prime}=t}^{t+H-1} 50 \\cdot\\left(1-\\hat{e}_{t^{\\prime}}^{(c o l l)}\\right)-3 \\cdot \\frac{\\left|\\hat{e}_{t^{\\prime}}^{(s p e e d)}-\\operatorname{GOAL}_{-} \\operatorname{SPEB}\\right|}{\\operatorname{GOAL}_{-} \\operatorname{SPEED}}+5 \\cdot \\hat{e}_{t^{\\prime}}^{(l a n e-s e e n)}\\left(1-\\left|\\hat{e}_{t^{\\prime}}^{\\left(l a n e_{-} d i f f\\right)}\\right|\\right) \\\\ &-\\frac{5}{\\pi} \\cdot\\left|\\hat{e}_{t^{\\prime}}^{(h e a d i n g)}-\\operatorname{GOAL}_{-} \\operatorname{HEADING}\\right|-0.15 \\cdot\\left\\|\\mathbf{a}_{t^{\\prime}}^{(s t e e r)}\\right\\|_{2}^{2} \\end{aligned} \u9700\u8981\u9884\u6d4b\u7684\u5185\u5bb9\u5305\u62ec\uff1a\u78b0\u649e\u3001\u901f\u5ea6\u3001\u53ef\u89c1\u9053\u8def\u6bd4\u7387\u3001\u53ef\u89c1\u9053\u8def\u6bd4\u7387\u53d8\u5316\u7387\u3001\u671d\u5411","title":"Carla\u4eff\u771f\u8fd0\u884c"},{"location":"Planning_Control_DL/Composable_Action-Conditioned_Predictors_Flexible_Off-Policy_Learning_for_Robot_Navigation/#_4","text":"R\\left(\\hat{E}_{t}^{(H, I)}\\right)=\\sum_{t^{\\prime}=t}^{t+H-1}\\left(1-\\hat{e}_{t^{\\prime}}^{(c o l l)}\\right) \\cdot\\left[1-\\frac{0.1}{\\pi} \\cdot\\left|\\hat{e}_{t^{\\prime}}^{(h e a d i n g)}-\\operatorname{coth}_{-} \\operatorname{HEADING}\\right|+0.05 \\cdot \\hat{e}_{t^{\\prime}}^{(d o o r-f r a c)}\\right]-0.01 \\cdot\\left\\|\\mathbf{a}_{t^{\\prime}}\\right\\|_{2}^{2} \u9700\u8981\u9884\u6d4b\u7684\u5185\u5bb9\u5305\u62ec\uff1a\u78b0\u649e\u3001\u671d\u5411\u3001\u623f\u95f4\u95e8\u5360\u753b\u9762\u6bd4\u7387 \u5b83\u4eec\u4e3a\u4e86\u8bad\u7ec3Segmentation\u7f51\u7edc\u6807\u6ce8\u4e86\u8bad\u7ec3\u8fc7\u7a0b\u4e2d0.2%\u7684\u56fe\u50cf\u6570\u636e\u3002","title":"\u5b9e\u9645\u8f66\u8f86\u8fd0\u884c"},{"location":"Planning_Control_DL/DESPOT-\u03b1: Online POMDP Planning With Large State And Observation Spaces/","text":"DESPOT-\u03b1: Online POMDP Planning With Large State And Observation Spaces Under Construction \u5bf9\u8fd9\u7bc7\u6587\u7ae0\u7684\u7406\u89e3\u8fd8\u6ca1\u5b8c\u5168\uff0c\u8fd9\u7bc7\u6587\u7ae0\u6709\u4e00\u4e2a\u91cd\u8981\u7684 \u524d\u7f6e \u4e5f\u6ca1\u8bfb\u5b8c\u3002\u6570\u5b66\u96be\u5ea6\u8f83\u9ad8\u3002\u8fd9\u91cc\u5c1d\u8bd5\u540c\u65f6\u5199\u4e24\u4e2a\u6587\u7ae0\u7684review\u3002\u8fd9\u4e24\u7bc7\u6587\u7ae0\u89e3\u7b54\u7684\u90fd\u662f\u6c42\u89e3POMDP(partially observable markov decision process)\u7684\u95ee\u9898\uff0c\u57fa\u672c\u601d\u8def\u662f\u8499\u7279\u5361\u6d1b\u7b97\u6cd5(\u7136\u800c\u8fd8\u6709\u5927\u91cf\u7684\u6570\u5b66\u7406\u8bba\u4ee5\u53ca\u5206\u6790\uff0c\u76ee\u524d\u5e76\u672a\u5b66\u8d2f\u901a) \u524d\u7f6e\u8bba\u6587\u7b97\u6cd5:","title":"DESPOT-\u03b1: Online POMDP Planning With Large State And Observation Spaces"},{"location":"Planning_Control_DL/DESPOT-\u03b1: Online POMDP Planning With Large State And Observation Spaces/#despot-online-pomdp-planning-with-large-state-and-observation-spaces","text":"","title":"DESPOT-\u03b1: Online POMDP Planning With Large State And Observation Spaces"},{"location":"Planning_Control_DL/DESPOT-\u03b1: Online POMDP Planning With Large State And Observation Spaces/#under-construction","text":"\u5bf9\u8fd9\u7bc7\u6587\u7ae0\u7684\u7406\u89e3\u8fd8\u6ca1\u5b8c\u5168\uff0c\u8fd9\u7bc7\u6587\u7ae0\u6709\u4e00\u4e2a\u91cd\u8981\u7684 \u524d\u7f6e \u4e5f\u6ca1\u8bfb\u5b8c\u3002\u6570\u5b66\u96be\u5ea6\u8f83\u9ad8\u3002\u8fd9\u91cc\u5c1d\u8bd5\u540c\u65f6\u5199\u4e24\u4e2a\u6587\u7ae0\u7684review\u3002\u8fd9\u4e24\u7bc7\u6587\u7ae0\u89e3\u7b54\u7684\u90fd\u662f\u6c42\u89e3POMDP(partially observable markov decision process)\u7684\u95ee\u9898\uff0c\u57fa\u672c\u601d\u8def\u662f\u8499\u7279\u5361\u6d1b\u7b97\u6cd5(\u7136\u800c\u8fd8\u6709\u5927\u91cf\u7684\u6570\u5b66\u7406\u8bba\u4ee5\u53ca\u5206\u6790\uff0c\u76ee\u524d\u5e76\u672a\u5b66\u8d2f\u901a) \u524d\u7f6e\u8bba\u6587\u7b97\u6cd5:","title":"Under Construction"},{"location":"Planning_Control_DL/Differentiable Algorithm Networks forComposable Robot Learning/","text":"Differentiable Algorithm Networks for Composable Robot Learning \u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u53ef\u5fae\u5206\u7b97\u6cd5\u7f51\u7edc\uff0c\u5176\u5b9e\u4e5f\u5c31\u662f\u5206\u6a21\u5757\u5730\u5b9e\u73b0\u53ef\u5fae\u5206\u7aef\u5230\u7aef\u8bad\u7ec3\u3002 \u57fa\u672c\u601d\u8def\u548cQMDP-Net\u4e00\u81f4\u3002","title":"Differentiable Algorithm Networks for Composable Robot Learning"},{"location":"Planning_Control_DL/Differentiable Algorithm Networks forComposable Robot Learning/#differentiable-algorithm-networks-for-composable-robot-learning","text":"\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u53ef\u5fae\u5206\u7b97\u6cd5\u7f51\u7edc\uff0c\u5176\u5b9e\u4e5f\u5c31\u662f\u5206\u6a21\u5757\u5730\u5b9e\u73b0\u53ef\u5fae\u5206\u7aef\u5230\u7aef\u8bad\u7ec3\u3002 \u57fa\u672c\u601d\u8def\u548cQMDP-Net\u4e00\u81f4\u3002","title":"Differentiable Algorithm Networks for Composable Robot Learning"},{"location":"Planning_Control_DL/Differentiable MPC for End-to-end Planning and Control/","text":"Differentiable MPC for End-to-end Planning and Control \u8fd9\u7bc7\u8bba\u6587\u5ef6\u7eed\u4e86 OptNet \u7684\u601d\u8def\uff0c\u4e5f\u5c31\u662f\u901a\u8fc7\u6c42\u89e3\u53ef\u5b66\u4e60\u7684\u4e8c\u6b21\u6700\u4f18\u6765\u5f97\u5230\u6700\u4f18\u63a7\u5236\u7684\u6548\u679c","title":"Differentiable MPC for End-to-end Planning and Control"},{"location":"Planning_Control_DL/Differentiable MPC for End-to-end Planning and Control/#differentiable-mpc-for-end-to-end-planning-and-control","text":"\u8fd9\u7bc7\u8bba\u6587\u5ef6\u7eed\u4e86 OptNet \u7684\u601d\u8def\uff0c\u4e5f\u5c31\u662f\u901a\u8fc7\u6c42\u89e3\u53ef\u5b66\u4e60\u7684\u4e8c\u6b21\u6700\u4f18\u6765\u5f97\u5230\u6700\u4f18\u63a7\u5236\u7684\u6548\u679c","title":"Differentiable MPC for End-to-end Planning and Control"},{"location":"Planning_Control_DL/EUDM/","text":"Efficient Uncertainty-aware Decision-making for Automated Driving Using Guided Branching \u8fd9\u7bc7paper\u662f\u6c88\u6559\u6388\u7ec4 Wenchao Ding \u5728\u8f66\u8f86\u610f\u56fe\u9884\u6d4b\uff0c\u51b3\u7b56\u4ee5\u53ca\u8def\u5f84\u89c4\u5212\u7684\u51e0\u4e2a\u5de5\u4f5c\u4e4b\u4e00\u3002\u8be5\u4f5c\u8005\u5728\u5b9e\u8f66\u4e0a\u5b9e\u73b0\u4e86\u6027\u80fd\u8f83\u597d\u7684demo\u3002 \u8fd9\u7bc7paper\u57fa\u672c\u6ca1\u6709\u4f7f\u7528\u5b66\u4e60\u7b97\u6cd5\uff0c\u91cd\u70b9\u662f\u57fa\u4e8e\u7ecf\u9a8c\u7684\u62bd\u8c61\u4e0e\u526a\u679d\uff0c\u89e3\u91ca\u6027\u4ee5\u53ca\u6269\u5c55\u6027\u90fd\u5f88\u5f3a\u3002 \u8bbe\u8ba1\u6846\u67b6 \u84dd\u8272\u6846\u90e8\u5206\u4e3b\u8981\u662f\u4e00\u4e2a\u90e8\u5206\u53ef\u89c2\u6d4b\u7684\u9a6c\u5c14\u79d1\u592b\u6a21\u578b(POMDP), \u6838\u5fc3\u5355\u5143\u6709\u4e09\uff0c\u7b2c\u4e00\u4e2a\u8868\u5f81\u662f\u672c\u4f53\u51b3\u7b56\u5e8f\u5217\u7684DCP-Tree, \u7b2c\u4e8c\u4e2a\u662f\u5bf9\u91cd\u70b9\u8f66\u8f86\u7684\u884c\u4e3a\u8fdb\u884c\u7a77\u4e3e\u7684CFB\uff0c \u7b2c\u4e09\u4e2a\u662f\u6bcf\u4e2a\u88ab\u7a77\u4e3e\u573a\u666f\u7684\u4eff\u771f Domain-specific Closed-loop Policy Tree (DCP-Tree) \u4f5c\u8005\u8bbe\u8ba1\u4e86\u4e00\u4e2a8s\u7684planning horizon,\u6bcf2s\u4e3a\u4e00\u4e2apolicy\u66f4\u65b0\u7684\u8282\u70b9\uff0c\u6240\u4ee5DCP\u6811\u7684\u6df1\u5ea6\u4e3a4\u3002\u4f5c\u8005\u8fdb\u4e00\u6b65\u8003\u8651\u4e86\u4e00\u4e2a\u526a\u679d\u65b9\u6cd5\uff0c\u4f5c\u8005\u8ba4\u4e3a\u6bcf\u4e2a\u89c4\u5212\u5468\u671f\u4e2d\uff0c\u53ea\u4f1a\u53d1\u751f\u4e00\u6b21\u7b56\u7565\u66f4\u65b0\uff0c\u5982\u679c\u9700\u8981\u590d\u6742\u7684\u89c4\u5219\u53d8\u5316(lane-keep -> lane-change -> lane-keep),\u5219\u53ef\u4ee5\u901a\u8fc7\u9ad8\u9891\u7387\u7684\u91cd\u65b0\u89c4\u5212\u5b9e\u73b0\u3002 Conditional Focused Branching (CFB) \u4f5c\u8005\u7684\u8bbe\u8ba1\u662f\u7a77\u4e3e\u76f8\u5173\u8f66\u8f86\u7684\u6240\u6709intention\uff0c \u4f46\u662f\u8fd9\u4e2a\"\u76f8\u5173\"\u8f66\u8f86\u662f\u7531\u672c\u8f66\u7684\u51b3\u7b56\u51b3\u5b9a\u7684\u3002\u6bd4\u5982\u5de6\u8f6c\u7684\u65f6\u5019\u4f1a\u4ec5\u8003\u8651\u672c\u7ebf\u4ee5\u53ca\u5de6\u4fa7\u7684\u8f66\u8f86\uff0c\u9650\u5236\u4e86\u641c\u7d22\u7684agent\u6570\u91cf\u3002 \u5185\u90e8\u4eff\u771f \u4f5c\u8005\u5728\u6cd5\u5411\u65b9\u5411\u5bf9\u5176\u4ed6\u8f66\u8f86\u7684\u63a7\u5236\u7b97\u6cd5\u662fpure pursuit controller, \u6cbf\u7ebf\u65b9\u5411\u7684\u63a7\u5236\u903b\u8f91\u4e3a IDM","title":"Efficient Uncertainty-aware Decision-making for Automated Driving Using Guided Branching"},{"location":"Planning_Control_DL/EUDM/#efficient-uncertainty-aware-decision-making-for-automated-driving-using-guided-branching","text":"\u8fd9\u7bc7paper\u662f\u6c88\u6559\u6388\u7ec4 Wenchao Ding \u5728\u8f66\u8f86\u610f\u56fe\u9884\u6d4b\uff0c\u51b3\u7b56\u4ee5\u53ca\u8def\u5f84\u89c4\u5212\u7684\u51e0\u4e2a\u5de5\u4f5c\u4e4b\u4e00\u3002\u8be5\u4f5c\u8005\u5728\u5b9e\u8f66\u4e0a\u5b9e\u73b0\u4e86\u6027\u80fd\u8f83\u597d\u7684demo\u3002 \u8fd9\u7bc7paper\u57fa\u672c\u6ca1\u6709\u4f7f\u7528\u5b66\u4e60\u7b97\u6cd5\uff0c\u91cd\u70b9\u662f\u57fa\u4e8e\u7ecf\u9a8c\u7684\u62bd\u8c61\u4e0e\u526a\u679d\uff0c\u89e3\u91ca\u6027\u4ee5\u53ca\u6269\u5c55\u6027\u90fd\u5f88\u5f3a\u3002","title":"Efficient Uncertainty-aware Decision-making for Automated Driving Using Guided Branching"},{"location":"Planning_Control_DL/EUDM/#_1","text":"\u84dd\u8272\u6846\u90e8\u5206\u4e3b\u8981\u662f\u4e00\u4e2a\u90e8\u5206\u53ef\u89c2\u6d4b\u7684\u9a6c\u5c14\u79d1\u592b\u6a21\u578b(POMDP), \u6838\u5fc3\u5355\u5143\u6709\u4e09\uff0c\u7b2c\u4e00\u4e2a\u8868\u5f81\u662f\u672c\u4f53\u51b3\u7b56\u5e8f\u5217\u7684DCP-Tree, \u7b2c\u4e8c\u4e2a\u662f\u5bf9\u91cd\u70b9\u8f66\u8f86\u7684\u884c\u4e3a\u8fdb\u884c\u7a77\u4e3e\u7684CFB\uff0c \u7b2c\u4e09\u4e2a\u662f\u6bcf\u4e2a\u88ab\u7a77\u4e3e\u573a\u666f\u7684\u4eff\u771f Domain-specific Closed-loop Policy Tree (DCP-Tree) \u4f5c\u8005\u8bbe\u8ba1\u4e86\u4e00\u4e2a8s\u7684planning horizon,\u6bcf2s\u4e3a\u4e00\u4e2apolicy\u66f4\u65b0\u7684\u8282\u70b9\uff0c\u6240\u4ee5DCP\u6811\u7684\u6df1\u5ea6\u4e3a4\u3002\u4f5c\u8005\u8fdb\u4e00\u6b65\u8003\u8651\u4e86\u4e00\u4e2a\u526a\u679d\u65b9\u6cd5\uff0c\u4f5c\u8005\u8ba4\u4e3a\u6bcf\u4e2a\u89c4\u5212\u5468\u671f\u4e2d\uff0c\u53ea\u4f1a\u53d1\u751f\u4e00\u6b21\u7b56\u7565\u66f4\u65b0\uff0c\u5982\u679c\u9700\u8981\u590d\u6742\u7684\u89c4\u5219\u53d8\u5316(lane-keep -> lane-change -> lane-keep),\u5219\u53ef\u4ee5\u901a\u8fc7\u9ad8\u9891\u7387\u7684\u91cd\u65b0\u89c4\u5212\u5b9e\u73b0\u3002 Conditional Focused Branching (CFB) \u4f5c\u8005\u7684\u8bbe\u8ba1\u662f\u7a77\u4e3e\u76f8\u5173\u8f66\u8f86\u7684\u6240\u6709intention\uff0c \u4f46\u662f\u8fd9\u4e2a\"\u76f8\u5173\"\u8f66\u8f86\u662f\u7531\u672c\u8f66\u7684\u51b3\u7b56\u51b3\u5b9a\u7684\u3002\u6bd4\u5982\u5de6\u8f6c\u7684\u65f6\u5019\u4f1a\u4ec5\u8003\u8651\u672c\u7ebf\u4ee5\u53ca\u5de6\u4fa7\u7684\u8f66\u8f86\uff0c\u9650\u5236\u4e86\u641c\u7d22\u7684agent\u6570\u91cf\u3002 \u5185\u90e8\u4eff\u771f \u4f5c\u8005\u5728\u6cd5\u5411\u65b9\u5411\u5bf9\u5176\u4ed6\u8f66\u8f86\u7684\u63a7\u5236\u7b97\u6cd5\u662fpure pursuit controller, \u6cbf\u7ebf\u65b9\u5411\u7684\u63a7\u5236\u903b\u8f91\u4e3a IDM","title":"\u8bbe\u8ba1\u6846\u67b6"},{"location":"Planning_Control_DL/Intention-Net Integrating Planning and DeepLearning for Goal-Directed Autonomous Navigation/","text":"Intention-Net: Integrating Planning and DeepLearning for Goal-Directed Autonomous Navigation \u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86Intention Net\u3002\u7ed9\u51fa\u4e86\u4e24\u79cd\u6982\u5ff5\u4ee5\u53ca\uff0c\u4e00\u4e2a\u662fDLM(Discrete Local Motion)\u53ca\u5176\u7f51\u7edc\uff0c\u4e00\u4e2a\u662fLPE(local path and environment)\u53ca\u5176\u7f51\u7edc DLM\uff1a\u79bb\u6563\u5c40\u90e8\u8fd0\u52a8 \u672c\u6587\u7684\u79bb\u6563\u5c40\u90e8\u8fd0\u52a8\u4e5f\u5c31\u662f\u6307\u5f53\u524d\u5efa\u8bae\uff08\u547d\u4ee4\uff09\u7684\u5c40\u90e8\u8fd0\u52a8\uff0c\u6bd4\u5982\u8bf4\u5de6\u53f3\u8f6c\u3001\u76f4\u884c\u4ee5\u53ca\u505c\u8f66\uff0c\u8bba\u6587\u5b9e\u73b0\u7684\u662f\u901a\u8fc7\u5f53\u524d\u8def\u5f84\u7684\u66f2\u7387\u6765\u5224\u5b9a\u5c40\u90e8\u8fd0\u52a8\u7684\u3002 \u4f46\u662f\u53ef\u4ee5\u7531\u5b9a\u4e49\u770b\u5230\uff0c\u8fd9\u4e2a\u662f\u4e00\u4e2a\u4e0d\u5b8c\u6574\u7684\u63cf\u8ff0\uff0c\u6bd4\u5982\u8bf4\u524d\u65b9\u6709\u591a\u4e2a\u5206\u5c94\u53e3\u65f6\u5de6\u53f3\u8f6c\u4fe1\u606f\u5e76\u4e0d\u5145\u5206\u3002 LPE\uff1a\u5c40\u90e8\u8def\u5f84\u4e0e\u73af\u5883 \u672c\u6587\u7684\u5c40\u90e8\u8def\u5f84\u4e0e\u73af\u5883\uff0c\u7528\u4e00\u4e2a224*224\u7684\u9e1f\u77b0\u89c6\u89d2\u7684\u56fe\u7247\uff0c\u56fe\u4e2d\u5305\u542b\u5730\u56fe\u4e2d\u7684\u969c\u788d\u7269\u4fe1\u606f(costmap)\u3001\u6700\u8fd1\u8d70\u8fc7\u7684\u8f68\u8ff9\u3001\u4ee5\u53ca\u5c06\u6765\u89c4\u5212\u7684\u8f68\u8ff9 \u7f51\u7edc\u7ed3\u6784 \u5206\u522b\u7528\u8fd9\u4e24\u4e2a\u7ed3\u6784\uff0c\u5728\u63a5\u53d7\u8def\u5f84\u89c4\u5212\u7684\u5c40\u90e8\u8def\u5f84\u8f93\u5165\u4ee5\u53ca\u5730\u56fe\u4fe1\u606f\u4e4b\u540e\u8f93\u51fa\u63a7\u5236\u6307\u4ee4\uff0c\u53ef\u4ee5\u7aef\u5230\u7aef\u5b66\u4e60\u3002","title":"Intention-Net: Integrating Planning and DeepLearning for Goal-Directed Autonomous Navigation"},{"location":"Planning_Control_DL/Intention-Net Integrating Planning and DeepLearning for Goal-Directed Autonomous Navigation/#intention-net-integrating-planning-and-deeplearning-for-goal-directed-autonomous-navigation","text":"\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86Intention Net\u3002\u7ed9\u51fa\u4e86\u4e24\u79cd\u6982\u5ff5\u4ee5\u53ca\uff0c\u4e00\u4e2a\u662fDLM(Discrete Local Motion)\u53ca\u5176\u7f51\u7edc\uff0c\u4e00\u4e2a\u662fLPE(local path and environment)\u53ca\u5176\u7f51\u7edc","title":"Intention-Net: Integrating Planning and DeepLearning for Goal-Directed Autonomous Navigation"},{"location":"Planning_Control_DL/Intention-Net Integrating Planning and DeepLearning for Goal-Directed Autonomous Navigation/#dlm","text":"\u672c\u6587\u7684\u79bb\u6563\u5c40\u90e8\u8fd0\u52a8\u4e5f\u5c31\u662f\u6307\u5f53\u524d\u5efa\u8bae\uff08\u547d\u4ee4\uff09\u7684\u5c40\u90e8\u8fd0\u52a8\uff0c\u6bd4\u5982\u8bf4\u5de6\u53f3\u8f6c\u3001\u76f4\u884c\u4ee5\u53ca\u505c\u8f66\uff0c\u8bba\u6587\u5b9e\u73b0\u7684\u662f\u901a\u8fc7\u5f53\u524d\u8def\u5f84\u7684\u66f2\u7387\u6765\u5224\u5b9a\u5c40\u90e8\u8fd0\u52a8\u7684\u3002 \u4f46\u662f\u53ef\u4ee5\u7531\u5b9a\u4e49\u770b\u5230\uff0c\u8fd9\u4e2a\u662f\u4e00\u4e2a\u4e0d\u5b8c\u6574\u7684\u63cf\u8ff0\uff0c\u6bd4\u5982\u8bf4\u524d\u65b9\u6709\u591a\u4e2a\u5206\u5c94\u53e3\u65f6\u5de6\u53f3\u8f6c\u4fe1\u606f\u5e76\u4e0d\u5145\u5206\u3002","title":"DLM\uff1a\u79bb\u6563\u5c40\u90e8\u8fd0\u52a8"},{"location":"Planning_Control_DL/Intention-Net Integrating Planning and DeepLearning for Goal-Directed Autonomous Navigation/#lpe","text":"\u672c\u6587\u7684\u5c40\u90e8\u8def\u5f84\u4e0e\u73af\u5883\uff0c\u7528\u4e00\u4e2a224*224\u7684\u9e1f\u77b0\u89c6\u89d2\u7684\u56fe\u7247\uff0c\u56fe\u4e2d\u5305\u542b\u5730\u56fe\u4e2d\u7684\u969c\u788d\u7269\u4fe1\u606f(costmap)\u3001\u6700\u8fd1\u8d70\u8fc7\u7684\u8f68\u8ff9\u3001\u4ee5\u53ca\u5c06\u6765\u89c4\u5212\u7684\u8f68\u8ff9","title":"LPE\uff1a\u5c40\u90e8\u8def\u5f84\u4e0e\u73af\u5883"},{"location":"Planning_Control_DL/Intention-Net Integrating Planning and DeepLearning for Goal-Directed Autonomous Navigation/#_1","text":"\u5206\u522b\u7528\u8fd9\u4e24\u4e2a\u7ed3\u6784\uff0c\u5728\u63a5\u53d7\u8def\u5f84\u89c4\u5212\u7684\u5c40\u90e8\u8def\u5f84\u8f93\u5165\u4ee5\u53ca\u5730\u56fe\u4fe1\u606f\u4e4b\u540e\u8f93\u51fa\u63a7\u5236\u6307\u4ee4\uff0c\u53ef\u4ee5\u7aef\u5230\u7aef\u5b66\u4e60\u3002","title":"\u7f51\u7edc\u7ed3\u6784"},{"location":"Planning_Control_DL/Learning-based_MPC/","text":"Learning-based Model Predictive Control for Autonomous Racing \u8fd9\u7bc7\u6765\u81eaETH\u7684\u8bba\u6587\u8bb2\u8ff0\u4e86\u4e00\u4e2adata-driven MPC for racing\u7684\u7b97\u6cd5\u7cfb\u7edf\u6784\u5efa\u3002\u6838\u5fc3\u601d\u8def\u662f\u4f7f\u7528GP(\u9ad8\u65af\u8fc7\u7a0b)\u8865\u507f\u52a8\u529b\u5b66\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\u4e0e\u5efa\u6a21\u8bef\u5dee\uff0c\u7136\u540e\u7528\u6839\u636e\u6b64\u4e0d\u786e\u5b9a\u6027\u6784\u5efa\u975e\u7ebf\u6027\u4f18\u5316\u95ee\u9898\u4f5c\u4e3aMPC\u7684\u6846\u67b6\u8fdb\u884c\u6c42\u89e3\u3002\u6587\u7ae0\u7b2c\u4e8c\u7ae0\u4ecb\u7ecd\u4e86GP\u6a21\u578b\u4ee5\u53ca\u7a00\u758fGP\u56de\u5f52\u7b97\u6cd5\u3002\u4ece\u7b2c\u4e09\u8282\u5f00\u59cb\u6309\u987a\u5e8f\u8bf4\u660e\u4e86\u540d\u4e49\u52a8\u529b\u5b66\u6a21\u578b\u3001GP\u8865\u507f\u95ee\u9898\u8868\u8ff0\u3001MPC\u635f\u5931\u51fd\u6570\u8868\u8ff0\u3001\u5e26\u6709\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u7684MPC\u7ea6\u675f\u51fd\u6570\u8868\u8ff0\u3001\u89e3\u8026MPC\u4e0eGP\u5e76\u7b80\u5316MPC\u8ba1\u7b97\u7684\u65b9\u6cd5\u3001\u7b80\u5316GP\u8fed\u4ee3\u8ba1\u7b97\u7684\u65b9\u6cd5\u3002 \u540d\u5b57\u52a8\u529b\u5b66\u6a21\u578b \u5bf9\u4e8eRacing Car,\u8fd9\u91cc\u9009\u62e9\u7684\u52a8\u529b\u5b66\u5efa\u6a21\u662f\u8f83\u4e3a\u7cbe\u786e\u7684\u52a8\u529b\u5b66\u6a21\u578b\uff0c\u5e76\u4e14\u8f6e\u80ce\u6a21\u578b\u9009\u62e9\u7684\u662fPacejka\u6a21\u578b(\u5177\u4f53\u770b\u516c\u5f0f) \\dot{\\mathbf{x}}=\\left[\\begin{array}{c}{v_{x} \\cos \\varphi-v_{y} \\sin \\varphi} \\\\ {v_{x} \\sin \\varphi+v_{y} \\cos \\varphi} \\\\ {r} \\\\ {\\frac{1}{m}\\left(F_{R, y}+F_{F, y} \\cos \\delta-m v_{x} r\\right)} \\\\ {\\frac{1}{I_{z}}\\left(F_{F, y} l_{F} \\cos \\delta-F_{R, y} l_{R}+\\tau_{\\mathrm{TV}}\\right)} \\\\ {\\Delta \\delta} \\\\ {\\Delta T}\\end{array}\\right] \\begin{aligned} r_{\\text {target }} &=\\delta \\frac{v_{x}}{l_{F}+l_{R}} \\\\ \\tau_{\\mathrm{TV}} &=\\left(r_{\\text {target }}-r\\right) P_{\\mathrm{TV}} \\\\ \\alpha_{R} &=\\arctan \\left(\\frac{v_{y}-l_{R} r}{v_{x}}\\right) \\\\ \\alpha_{F} &=\\arctan \\left(\\frac{v_{y}+l_{F} r}{v_{x}}\\right)-\\delta \\\\ F_{R, y} &=D_{R} \\sin \\left(C_{R} \\arctan \\left(B_{R} \\alpha_{R}\\right)\\right) \\\\ F_{F, y} &=D_{F} \\sin \\left(C_{F} \\arctan \\left(B_{F} \\alpha_{F}\\right)\\right) \\end{aligned} \u79ef\u5206\u4f7f\u7528\u7684\u662fRK4, T_s = 50ms GP\u6a21\u578b\u56de\u5f52\u95ee\u9898\u63cf\u8ff0 GP\u6a21\u578b\u7684\u8f93\u5165\u4e3a z = [v_x;v_y; r;\\delta + \\frac{1}{2}\\Delta\\delta; T+ \\frac{1}{2}\\Delta T] \u540d\u4e49\u8fd0\u52a8\u5b66\u7684\u9884\u6d4b\u7ed3\u679c\u4e0e\u5b9e\u9645\u6d4b\u91cf\u7ed3\u679c\u7684\u5dee\u503c\u5c31\u662fGP\u7684\u76ee\u6807\u8f93\u51fa\u3002 \\mathbf{y}_{k}=\\mathbf{B}_{d}^{\\dagger}\\left(\\mathbf{x}_{k+1}-\\mathbf{f}\\left(\\mathbf{x}_{k}, \\mathbf{u}_{k}\\right)\\right)=\\mathbf{d}_{\\mathrm{true}}\\left(\\mathbf{z}_{k}\\right)+\\mathbf{w}_{k} \u5176\u4e2d B_d = [0_{3\\times 3}; I{3\\times 3}; 0_{2\\times}3] \u8bf4\u660e\u53ea\u6709\u4e00\u90e8\u5206\u503c\u9700\u8981\u8865\u507f(\u5176\u5b9e\u53ea\u6709xy\u65b9\u5411\u52a0\u901f\u5ea6\u8fd8\u6709\u89d2\u52a0\u901f\u5ea6\u9700\u8981\u8865\u507f), B_d^\\dagger \u4e3a\u4f2a\u9006. \u5747\u503c\u4e0e\u65b9\u5dee\u7684\u4f20\u9012 \\begin{aligned} \\boldsymbol{\\mu}_{k+1}^{\\mathrm{x}}=&\\mathbf{f}\\left(\\boldsymbol{\\mu}_{k}^{\\mathrm{x}}, \\mathbf{u}_{k}\\right)+\\mathbf{B}_{d} \\boldsymbol{\\mu}^{d}\\left(\\boldsymbol{\\mu}_{k}^{\\mathrm{z}}\\right) \\\\ \\mathbf{\\Sigma}_{k+1}^{\\mathrm{x}}=&\\left[\\nabla_{x} \\mathbf{f}\\left(\\boldsymbol{\\mu}_{k}^{\\mathrm{x}}, \\mathbf{u}_{k}\\right) \\quad \\mathbf{B}_{d}\\right] \\\\ &\\left[\\begin{array}{cc}{\\mathbf{\\Sigma}_{k}^{\\mathbf{x}}} & {\\mathbf{\\Sigma}^{d}\\left(\\boldsymbol{\\mu}_{k}^{\\mathrm{z}}\\right)+\\mathbf{\\Sigma}^{\\mathrm{w}}}\\end{array}\\right] \\\\ &\\left[\\nabla_{x} \\mathbf{f}\\left(\\boldsymbol{\\mu}_{k}^{\\mathbf{x}}, \\mathbf{u}_{k}\\right) \\quad \\mathbf{B}_{d}\\right]^{T} \\end{aligned} \u635f\u5931\u51fd\u6570 \u8fd9\u91cc\u4e0d\u8a8a\u6284\u5176\u516c\u5f0f\uff0c\u539f\u56e0\u662f\u7531\u4e8eRacing\u7684\u6027\u8d28\u4f7f\u5f97\u5b83\u53ea\u9700\u8981\u7ed5\u5708\uff0c\u635f\u5931\u51fd\u6570\u4e0e\u57fa\u7840\u7684\u975e\u7ebf\u6027MPC\u6ca1\u6709\u672c\u8d28\u533a\u522b\u3002 \u5e26\u6709\u4e0d\u786e\u5b9a\u6027\u7684\u7ea6\u675f \u8ddd\u79bb\u8f68\u8ff9\u70b9\u7684\u504f\u79bb\u6982\u7387\u5927\u4e8e p \u5bf9\u5e94\u7684\u8ddd\u79bb\u504f\u5dee\u503c\u4e3a R_{GP}(\\sum^{XY}_k) = \\sqrt{\\chi^2_2(p) \\lambda_{max}(\\sum_k^{XY})} \u5176\u4e2d \\sum^{XY} \u8868\u8fbe XY \u4f4d\u79fb\u5206\u91cf\u7684covariance\u77e9\u9635\u3002 \\lambda \u4e3a\u53d6\u7279\u5f81\u503c\u64cd\u4f5c\uff0c \\chi^2_2 \u4e3a\u8868\u8fbe\u5361\u65b9\u5206\u5e03\u3002\u6839\u53f7\u91cc\u9762\u7684\u610f\u601d\u662f\uff0c\u5148\u53d6\u6700\u5927\u7279\u5f81\u503c\uff0c\u4e5f\u5c31\u662f XY \u504f\u5dee\u77e9\u9635\u4e2d\u53d6\u51fa\u4e3b\u65b9\u5411\u7684\u65b9\u5dee\u503c\uff0c\u7136\u540e\u5361\u65b9\u5206\u5e03\u8868\u8fbe\u7684\u662f\u6b63\u6001\u5206\u5e03\u5e73\u65b9\u503c\u7684\u6982\u7387\u5206\u5e03\u3002 \u6700\u540e\u7ea6\u675f\u53ef\u4ee5\u8868\u8fbe\u4e3a \\left\\|\\left[\\begin{array}{c}{\\mu_{k}^{X}} \\\\ {\\mu_{k}^{X}}\\end{array}\\right]-\\left[\\begin{array}{c}{X_{c}\\left(\\theta_{k}\\right)} \\\\ {Y_{c}\\left(\\theta_{k}\\right)}\\end{array}\\right]\\right\\|^{2} \\leq\\left\\|R\\left(\\theta_{k}\\right)-R_{\\mathrm{GP}}\\left(\\Sigma_{k}^{X Y}\\right)\\right\\|^{2} \u5b9e\u9645\u8fd0\u7b97\u65f6\u53ea\u5bf9\u524d\u51e0\u6b65\u6709\u6548\u3002 \u5176\u4ed6\u5173\u4e8e\u529b\u3001\u8f93\u5165\u3001\u8f93\u5165\u53d8\u5316\u7387\u7684\u56fa\u5b9a\u7ea6\u675f\u8fd9\u91cc\u4e0d\u518d\u8a8a\u5199\u3002 \u8ba1\u7b97\u8003\u8651 \u7531\u4e8e\u7ea6\u675f\u4e2d\u5e26\u6709\u65b9\u5dee\uff0c\u6240\u4ee5\u4f1a\u548c\u5b9e\u9645\u91c7\u53d6\u7684\u63a7\u5236\u7ed3\u679c\u8026\u5408\uff0c\u8fd9\u91cc\u91c7\u53d6\u4e86\u4e00\u4e2a\u5b9e\u65f6\u8fd0\u7b97\u7684\u7b80\u5316\u3002\u7531\u4e8e\u4e0a\u4e00\u65f6\u523b\u7684\u4f18\u5316\u7ed3\u679c\u4f1a\u4fdd\u5b58\u5230\u8fd9\u4e00\u65f6\u523b\uff0c\u56e0\u800c\u53ef\u4ee5\u8fd1\u4f3c\u8ba4\u4e3a\u4f18\u5316\u524d\u540e\u7684\u63a7\u5236\u8f93\u5165\u5dee\u4e0d\u4f1a\u592a\u5927\uff0c\u8fdb\u800c\u65b9\u5dee\u7684\u4f20\u9012\u53ea\u4ee5\u672c\u65f6\u523b\u7b2c\u4e00\u6b21\u7684\u7ed3\u679c\u4e3a\u51c6\uff0c\u672c\u65f6\u523b\u540e\u7eed\u8fed\u4ee3\u4f18\u5316\u4e0d\u518d\u6539\u53d8\u65b9\u5dee\u3002 \u5728\u7ebf\u5b66\u4e60GP\u8865\u507f\u53c2\u6570 \u4f5c\u8005\u5f00\u53d1\u4e86\u4e00\u5957\u5728\u7ebf\u9009\u62e9\u6570\u636e\u6dfb\u52a0\u3001\u9009\u62e9\u6570\u636e\u66ff\u6362\u3001\u53bb\u9664outlier\u7684\u7b97\u6cd5\uff0c\u8fd9\u91cc\u4e0d\u590d\u8ff0\u3002","title":"Learning-based Model Predictive Control for Autonomous Racing"},{"location":"Planning_Control_DL/Learning-based_MPC/#learning-based-model-predictive-control-for-autonomous-racing","text":"\u8fd9\u7bc7\u6765\u81eaETH\u7684\u8bba\u6587\u8bb2\u8ff0\u4e86\u4e00\u4e2adata-driven MPC for racing\u7684\u7b97\u6cd5\u7cfb\u7edf\u6784\u5efa\u3002\u6838\u5fc3\u601d\u8def\u662f\u4f7f\u7528GP(\u9ad8\u65af\u8fc7\u7a0b)\u8865\u507f\u52a8\u529b\u5b66\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\u4e0e\u5efa\u6a21\u8bef\u5dee\uff0c\u7136\u540e\u7528\u6839\u636e\u6b64\u4e0d\u786e\u5b9a\u6027\u6784\u5efa\u975e\u7ebf\u6027\u4f18\u5316\u95ee\u9898\u4f5c\u4e3aMPC\u7684\u6846\u67b6\u8fdb\u884c\u6c42\u89e3\u3002\u6587\u7ae0\u7b2c\u4e8c\u7ae0\u4ecb\u7ecd\u4e86GP\u6a21\u578b\u4ee5\u53ca\u7a00\u758fGP\u56de\u5f52\u7b97\u6cd5\u3002\u4ece\u7b2c\u4e09\u8282\u5f00\u59cb\u6309\u987a\u5e8f\u8bf4\u660e\u4e86\u540d\u4e49\u52a8\u529b\u5b66\u6a21\u578b\u3001GP\u8865\u507f\u95ee\u9898\u8868\u8ff0\u3001MPC\u635f\u5931\u51fd\u6570\u8868\u8ff0\u3001\u5e26\u6709\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u7684MPC\u7ea6\u675f\u51fd\u6570\u8868\u8ff0\u3001\u89e3\u8026MPC\u4e0eGP\u5e76\u7b80\u5316MPC\u8ba1\u7b97\u7684\u65b9\u6cd5\u3001\u7b80\u5316GP\u8fed\u4ee3\u8ba1\u7b97\u7684\u65b9\u6cd5\u3002","title":"Learning-based Model Predictive Control for Autonomous Racing"},{"location":"Planning_Control_DL/Learning-based_MPC/#_1","text":"\u5bf9\u4e8eRacing Car,\u8fd9\u91cc\u9009\u62e9\u7684\u52a8\u529b\u5b66\u5efa\u6a21\u662f\u8f83\u4e3a\u7cbe\u786e\u7684\u52a8\u529b\u5b66\u6a21\u578b\uff0c\u5e76\u4e14\u8f6e\u80ce\u6a21\u578b\u9009\u62e9\u7684\u662fPacejka\u6a21\u578b(\u5177\u4f53\u770b\u516c\u5f0f) \\dot{\\mathbf{x}}=\\left[\\begin{array}{c}{v_{x} \\cos \\varphi-v_{y} \\sin \\varphi} \\\\ {v_{x} \\sin \\varphi+v_{y} \\cos \\varphi} \\\\ {r} \\\\ {\\frac{1}{m}\\left(F_{R, y}+F_{F, y} \\cos \\delta-m v_{x} r\\right)} \\\\ {\\frac{1}{I_{z}}\\left(F_{F, y} l_{F} \\cos \\delta-F_{R, y} l_{R}+\\tau_{\\mathrm{TV}}\\right)} \\\\ {\\Delta \\delta} \\\\ {\\Delta T}\\end{array}\\right] \\begin{aligned} r_{\\text {target }} &=\\delta \\frac{v_{x}}{l_{F}+l_{R}} \\\\ \\tau_{\\mathrm{TV}} &=\\left(r_{\\text {target }}-r\\right) P_{\\mathrm{TV}} \\\\ \\alpha_{R} &=\\arctan \\left(\\frac{v_{y}-l_{R} r}{v_{x}}\\right) \\\\ \\alpha_{F} &=\\arctan \\left(\\frac{v_{y}+l_{F} r}{v_{x}}\\right)-\\delta \\\\ F_{R, y} &=D_{R} \\sin \\left(C_{R} \\arctan \\left(B_{R} \\alpha_{R}\\right)\\right) \\\\ F_{F, y} &=D_{F} \\sin \\left(C_{F} \\arctan \\left(B_{F} \\alpha_{F}\\right)\\right) \\end{aligned} \u79ef\u5206\u4f7f\u7528\u7684\u662fRK4, T_s = 50ms","title":"\u540d\u5b57\u52a8\u529b\u5b66\u6a21\u578b"},{"location":"Planning_Control_DL/Learning-based_MPC/#gp","text":"GP\u6a21\u578b\u7684\u8f93\u5165\u4e3a z = [v_x;v_y; r;\\delta + \\frac{1}{2}\\Delta\\delta; T+ \\frac{1}{2}\\Delta T] \u540d\u4e49\u8fd0\u52a8\u5b66\u7684\u9884\u6d4b\u7ed3\u679c\u4e0e\u5b9e\u9645\u6d4b\u91cf\u7ed3\u679c\u7684\u5dee\u503c\u5c31\u662fGP\u7684\u76ee\u6807\u8f93\u51fa\u3002 \\mathbf{y}_{k}=\\mathbf{B}_{d}^{\\dagger}\\left(\\mathbf{x}_{k+1}-\\mathbf{f}\\left(\\mathbf{x}_{k}, \\mathbf{u}_{k}\\right)\\right)=\\mathbf{d}_{\\mathrm{true}}\\left(\\mathbf{z}_{k}\\right)+\\mathbf{w}_{k} \u5176\u4e2d B_d = [0_{3\\times 3}; I{3\\times 3}; 0_{2\\times}3] \u8bf4\u660e\u53ea\u6709\u4e00\u90e8\u5206\u503c\u9700\u8981\u8865\u507f(\u5176\u5b9e\u53ea\u6709xy\u65b9\u5411\u52a0\u901f\u5ea6\u8fd8\u6709\u89d2\u52a0\u901f\u5ea6\u9700\u8981\u8865\u507f), B_d^\\dagger \u4e3a\u4f2a\u9006.","title":"GP\u6a21\u578b\u56de\u5f52\u95ee\u9898\u63cf\u8ff0"},{"location":"Planning_Control_DL/Learning-based_MPC/#_2","text":"\\begin{aligned} \\boldsymbol{\\mu}_{k+1}^{\\mathrm{x}}=&\\mathbf{f}\\left(\\boldsymbol{\\mu}_{k}^{\\mathrm{x}}, \\mathbf{u}_{k}\\right)+\\mathbf{B}_{d} \\boldsymbol{\\mu}^{d}\\left(\\boldsymbol{\\mu}_{k}^{\\mathrm{z}}\\right) \\\\ \\mathbf{\\Sigma}_{k+1}^{\\mathrm{x}}=&\\left[\\nabla_{x} \\mathbf{f}\\left(\\boldsymbol{\\mu}_{k}^{\\mathrm{x}}, \\mathbf{u}_{k}\\right) \\quad \\mathbf{B}_{d}\\right] \\\\ &\\left[\\begin{array}{cc}{\\mathbf{\\Sigma}_{k}^{\\mathbf{x}}} & {\\mathbf{\\Sigma}^{d}\\left(\\boldsymbol{\\mu}_{k}^{\\mathrm{z}}\\right)+\\mathbf{\\Sigma}^{\\mathrm{w}}}\\end{array}\\right] \\\\ &\\left[\\nabla_{x} \\mathbf{f}\\left(\\boldsymbol{\\mu}_{k}^{\\mathbf{x}}, \\mathbf{u}_{k}\\right) \\quad \\mathbf{B}_{d}\\right]^{T} \\end{aligned}","title":"\u5747\u503c\u4e0e\u65b9\u5dee\u7684\u4f20\u9012"},{"location":"Planning_Control_DL/Learning-based_MPC/#_3","text":"\u8fd9\u91cc\u4e0d\u8a8a\u6284\u5176\u516c\u5f0f\uff0c\u539f\u56e0\u662f\u7531\u4e8eRacing\u7684\u6027\u8d28\u4f7f\u5f97\u5b83\u53ea\u9700\u8981\u7ed5\u5708\uff0c\u635f\u5931\u51fd\u6570\u4e0e\u57fa\u7840\u7684\u975e\u7ebf\u6027MPC\u6ca1\u6709\u672c\u8d28\u533a\u522b\u3002","title":"\u635f\u5931\u51fd\u6570"},{"location":"Planning_Control_DL/Learning-based_MPC/#_4","text":"\u8ddd\u79bb\u8f68\u8ff9\u70b9\u7684\u504f\u79bb\u6982\u7387\u5927\u4e8e p \u5bf9\u5e94\u7684\u8ddd\u79bb\u504f\u5dee\u503c\u4e3a R_{GP}(\\sum^{XY}_k) = \\sqrt{\\chi^2_2(p) \\lambda_{max}(\\sum_k^{XY})} \u5176\u4e2d \\sum^{XY} \u8868\u8fbe XY \u4f4d\u79fb\u5206\u91cf\u7684covariance\u77e9\u9635\u3002 \\lambda \u4e3a\u53d6\u7279\u5f81\u503c\u64cd\u4f5c\uff0c \\chi^2_2 \u4e3a\u8868\u8fbe\u5361\u65b9\u5206\u5e03\u3002\u6839\u53f7\u91cc\u9762\u7684\u610f\u601d\u662f\uff0c\u5148\u53d6\u6700\u5927\u7279\u5f81\u503c\uff0c\u4e5f\u5c31\u662f XY \u504f\u5dee\u77e9\u9635\u4e2d\u53d6\u51fa\u4e3b\u65b9\u5411\u7684\u65b9\u5dee\u503c\uff0c\u7136\u540e\u5361\u65b9\u5206\u5e03\u8868\u8fbe\u7684\u662f\u6b63\u6001\u5206\u5e03\u5e73\u65b9\u503c\u7684\u6982\u7387\u5206\u5e03\u3002 \u6700\u540e\u7ea6\u675f\u53ef\u4ee5\u8868\u8fbe\u4e3a \\left\\|\\left[\\begin{array}{c}{\\mu_{k}^{X}} \\\\ {\\mu_{k}^{X}}\\end{array}\\right]-\\left[\\begin{array}{c}{X_{c}\\left(\\theta_{k}\\right)} \\\\ {Y_{c}\\left(\\theta_{k}\\right)}\\end{array}\\right]\\right\\|^{2} \\leq\\left\\|R\\left(\\theta_{k}\\right)-R_{\\mathrm{GP}}\\left(\\Sigma_{k}^{X Y}\\right)\\right\\|^{2} \u5b9e\u9645\u8fd0\u7b97\u65f6\u53ea\u5bf9\u524d\u51e0\u6b65\u6709\u6548\u3002 \u5176\u4ed6\u5173\u4e8e\u529b\u3001\u8f93\u5165\u3001\u8f93\u5165\u53d8\u5316\u7387\u7684\u56fa\u5b9a\u7ea6\u675f\u8fd9\u91cc\u4e0d\u518d\u8a8a\u5199\u3002","title":"\u5e26\u6709\u4e0d\u786e\u5b9a\u6027\u7684\u7ea6\u675f"},{"location":"Planning_Control_DL/Learning-based_MPC/#_5","text":"\u7531\u4e8e\u7ea6\u675f\u4e2d\u5e26\u6709\u65b9\u5dee\uff0c\u6240\u4ee5\u4f1a\u548c\u5b9e\u9645\u91c7\u53d6\u7684\u63a7\u5236\u7ed3\u679c\u8026\u5408\uff0c\u8fd9\u91cc\u91c7\u53d6\u4e86\u4e00\u4e2a\u5b9e\u65f6\u8fd0\u7b97\u7684\u7b80\u5316\u3002\u7531\u4e8e\u4e0a\u4e00\u65f6\u523b\u7684\u4f18\u5316\u7ed3\u679c\u4f1a\u4fdd\u5b58\u5230\u8fd9\u4e00\u65f6\u523b\uff0c\u56e0\u800c\u53ef\u4ee5\u8fd1\u4f3c\u8ba4\u4e3a\u4f18\u5316\u524d\u540e\u7684\u63a7\u5236\u8f93\u5165\u5dee\u4e0d\u4f1a\u592a\u5927\uff0c\u8fdb\u800c\u65b9\u5dee\u7684\u4f20\u9012\u53ea\u4ee5\u672c\u65f6\u523b\u7b2c\u4e00\u6b21\u7684\u7ed3\u679c\u4e3a\u51c6\uff0c\u672c\u65f6\u523b\u540e\u7eed\u8fed\u4ee3\u4f18\u5316\u4e0d\u518d\u6539\u53d8\u65b9\u5dee\u3002","title":"\u8ba1\u7b97\u8003\u8651"},{"location":"Planning_Control_DL/Learning-based_MPC/#gp_1","text":"\u4f5c\u8005\u5f00\u53d1\u4e86\u4e00\u5957\u5728\u7ebf\u9009\u62e9\u6570\u636e\u6dfb\u52a0\u3001\u9009\u62e9\u6570\u636e\u66ff\u6362\u3001\u53bb\u9664outlier\u7684\u7b97\u6cd5\uff0c\u8fd9\u91cc\u4e0d\u590d\u8ff0\u3002","title":"\u5728\u7ebf\u5b66\u4e60GP\u8865\u507f\u53c2\u6570"},{"location":"Planning_Control_DL/PMPNet/","text":"Probabilistic End-to-End Vehicle Navigation in Complex Dynamic Environments with Multimodal Sensor Fusion \u8fd9\u7bc7paper\u4e5f\u662f\u5b9e\u9a8c\u5ba4\u5b66\u957f\u7684\u5de5\u4f5c. \u6709 \u89c6\u9891 : Network structure Route\u6765\u81ea\u4e8eCARLA\u7684\u8f93\u5165\uff0c\u8fd9\u91cc\u91c7\u7528\u6700\u8fd1\u7684130\u4e2awaypoints(CARLA\u5730\u56fe\u4e0a\u7684\u5c0f\u70b9)\u3002 attention\u662f\u7528\u4e8e\u8868\u8fbe\u4e0d\u540c\u4f20\u611f\u5668\u7684\u7279\u5f81\u7684\u6743\u91cd. a_1 \u8868\u8fbe\u7684\u662f\u6a21\u4eff\u5b66\u4e60\u7ed9\u51fa\u7684throttle, steering and brake GMM\u7684\u56de\u5f52\u4f7f\u7528\u6765\u81ea\u4e8e \u8fd9\u4e00\u7bc7paper.pdf \u3002\u8f93\u51fa\u7684\u662f\u672a\u6765\u6570\u79d2\u5185\u8f66\u5b50\u7684\u8fd0\u52a8\u89c4\u5212\u503c(\u901f\u5ea6\u4e0e\u89d2\u5ea6\u5206\u5e03\u56fe)\uff0c\u5bf9\u5176\u8fdb\u884c\u79ef\u5206\u5f97\u5230\u672a\u67655m\u7684\u76ee\u6807\u4f4d\u7f6e\uff0c\u7528PID\u63a7\u5236\u5668\u8ddf\u8e2a\u8fd9\u4e2a\u76ee\u6807\u70b9\u5f97\u5230 a_2 ,\u4e24\u4e2a\u63a7\u5236\u6307\u4ee4\u7684\u878d\u5408\u5219\u662f\u4f9d\u636e\u5bf9\u7d2f\u8ba1\u65b9\u5dee\u503c\u7684\u4f30\u8ba1\u3002\u4e0b\u56fe\u6765\u81ea\u4e8e\u8fd9\u7bc7\u5f15\u7528\u7684\u8bba\u6587\uff0c\u5177\u4f53\u529f\u80fd\u4e0e\u672c\u6587\u65e0\u5173\uff1a \\boldsymbol{a}_{f}=(1-\\lambda) \\boldsymbol{a}_{1}+\\lambda \\boldsymbol{a}_{2}, \\lambda=e^{-c_{1} \\cdot \\max \\left(0, \\Sigma_{i}^{k} \\sigma^{2}-c_{2}\\right)} \u878d\u5408\u4e86GMM\u6a21\u4eff\u5b66\u4e60\u7684\u601d\u60f3\uff0c\u5229\u7528GMM\u66ff\u4ee3\u4f20\u7edfplanning\uff0c\u7ed9\u51fa\u5e26\u65b9\u5dee\u4f30\u8ba1\u7684learning\u7ed3\u679c\uff0c\u7528\u6a21\u4eff\u5b66\u4e60\u63d0\u9ad8\u6027\u80fd\uff0c\u914d\u5408\u65b9\u5dee\u4f30\u8ba1\u7ed9\u51fa\u63a7\u5236\u7ed3\u679c\u3002","title":"Probabilistic End-to-End Vehicle Navigation in Complex Dynamic Environments with Multimodal Sensor Fusion"},{"location":"Planning_Control_DL/PMPNet/#probabilistic-end-to-end-vehicle-navigation-in-complex-dynamic-environments-with-multimodal-sensor-fusion","text":"\u8fd9\u7bc7paper\u4e5f\u662f\u5b9e\u9a8c\u5ba4\u5b66\u957f\u7684\u5de5\u4f5c. \u6709 \u89c6\u9891 :","title":"Probabilistic End-to-End Vehicle Navigation in Complex Dynamic Environments with Multimodal Sensor Fusion"},{"location":"Planning_Control_DL/PMPNet/#network-structure","text":"Route\u6765\u81ea\u4e8eCARLA\u7684\u8f93\u5165\uff0c\u8fd9\u91cc\u91c7\u7528\u6700\u8fd1\u7684130\u4e2awaypoints(CARLA\u5730\u56fe\u4e0a\u7684\u5c0f\u70b9)\u3002 attention\u662f\u7528\u4e8e\u8868\u8fbe\u4e0d\u540c\u4f20\u611f\u5668\u7684\u7279\u5f81\u7684\u6743\u91cd. a_1 \u8868\u8fbe\u7684\u662f\u6a21\u4eff\u5b66\u4e60\u7ed9\u51fa\u7684throttle, steering and brake GMM\u7684\u56de\u5f52\u4f7f\u7528\u6765\u81ea\u4e8e \u8fd9\u4e00\u7bc7paper.pdf \u3002\u8f93\u51fa\u7684\u662f\u672a\u6765\u6570\u79d2\u5185\u8f66\u5b50\u7684\u8fd0\u52a8\u89c4\u5212\u503c(\u901f\u5ea6\u4e0e\u89d2\u5ea6\u5206\u5e03\u56fe)\uff0c\u5bf9\u5176\u8fdb\u884c\u79ef\u5206\u5f97\u5230\u672a\u67655m\u7684\u76ee\u6807\u4f4d\u7f6e\uff0c\u7528PID\u63a7\u5236\u5668\u8ddf\u8e2a\u8fd9\u4e2a\u76ee\u6807\u70b9\u5f97\u5230 a_2 ,\u4e24\u4e2a\u63a7\u5236\u6307\u4ee4\u7684\u878d\u5408\u5219\u662f\u4f9d\u636e\u5bf9\u7d2f\u8ba1\u65b9\u5dee\u503c\u7684\u4f30\u8ba1\u3002\u4e0b\u56fe\u6765\u81ea\u4e8e\u8fd9\u7bc7\u5f15\u7528\u7684\u8bba\u6587\uff0c\u5177\u4f53\u529f\u80fd\u4e0e\u672c\u6587\u65e0\u5173\uff1a \\boldsymbol{a}_{f}=(1-\\lambda) \\boldsymbol{a}_{1}+\\lambda \\boldsymbol{a}_{2}, \\lambda=e^{-c_{1} \\cdot \\max \\left(0, \\Sigma_{i}^{k} \\sigma^{2}-c_{2}\\right)} \u878d\u5408\u4e86GMM\u6a21\u4eff\u5b66\u4e60\u7684\u601d\u60f3\uff0c\u5229\u7528GMM\u66ff\u4ee3\u4f20\u7edfplanning\uff0c\u7ed9\u51fa\u5e26\u65b9\u5dee\u4f30\u8ba1\u7684learning\u7ed3\u679c\uff0c\u7528\u6a21\u4eff\u5b66\u4e60\u63d0\u9ad8\u6027\u80fd\uff0c\u914d\u5408\u65b9\u5dee\u4f30\u8ba1\u7ed9\u51fa\u63a7\u5236\u7ed3\u679c\u3002","title":"Network structure"},{"location":"Planning_Control_DL/Path Integral Networks_End-to-End Differentiable Optimal Control/","text":"Path Integral Networks: End-to-End Differentiable Optimal Control \u8fd9\u7bc7\u8bba\u6587\u5c06\u8def\u5f84\u79ef\u5206\u63a7\u5236\u7528\u5728\u4e86\u7aef\u5230\u7aef\u7684\u53ef\u5fae\u5206\u6700\u4f18\u63a7\u5236\u4e2d\uff0cPath Integral Control \u53ef\u4ee5\u53c2\u8003 \u8fd9\u7bc7 \u57fa\u672cPath Integral\u7b97\u6cd5 \u7c7b\u4f3c\u4e8ePath Integal \u63a7\u5236\u8bba\u6587\u4e2d\u7ed9\u51fa\u7684\u7b97\u6cd5\uff0c\u6ce8\u610f\u7cfb\u7edf\u5728\u6a21\u578b\u9884\u6d4b\u4ee5\u53careward\u9884\u6d4b\u7684\u65f6\u5019\u4f7f\u7528\u7684\u51fd\u6570\u4e3a\u795e\u7ecf\u7f51\u7edc\u5c42\u3002\u7531\u6b64\u53ef\u4ee5\u5f15\u51fa\u4ee5\u4e0b\u7684\u7ed3\u6784\u56fe \u5728\u6709\u4e13\u5bb6\u8f93\u5165\u53c2\u8003\u7684\u60c5\u51b5\u4e0b\uff0c\u6a21\u578b\u9884\u6d4b\u51fd\u6570\u4ee5\u53careward\u7684\u9884\u6d4b\u51fd\u6570\u53ef\u4ee5\u7aef\u5230\u7aef\u5b66\u4e60\u3002","title":"Path Integral Networks: End-to-End Differentiable Optimal Control"},{"location":"Planning_Control_DL/Path Integral Networks_End-to-End Differentiable Optimal Control/#path-integral-networks-end-to-end-differentiable-optimal-control","text":"\u8fd9\u7bc7\u8bba\u6587\u5c06\u8def\u5f84\u79ef\u5206\u63a7\u5236\u7528\u5728\u4e86\u7aef\u5230\u7aef\u7684\u53ef\u5fae\u5206\u6700\u4f18\u63a7\u5236\u4e2d\uff0cPath Integral Control \u53ef\u4ee5\u53c2\u8003 \u8fd9\u7bc7","title":"Path Integral Networks: End-to-End Differentiable Optimal Control"},{"location":"Planning_Control_DL/Path Integral Networks_End-to-End Differentiable Optimal Control/#path-integral","text":"\u7c7b\u4f3c\u4e8ePath Integal \u63a7\u5236\u8bba\u6587\u4e2d\u7ed9\u51fa\u7684\u7b97\u6cd5\uff0c\u6ce8\u610f\u7cfb\u7edf\u5728\u6a21\u578b\u9884\u6d4b\u4ee5\u53careward\u9884\u6d4b\u7684\u65f6\u5019\u4f7f\u7528\u7684\u51fd\u6570\u4e3a\u795e\u7ecf\u7f51\u7edc\u5c42\u3002\u7531\u6b64\u53ef\u4ee5\u5f15\u51fa\u4ee5\u4e0b\u7684\u7ed3\u6784\u56fe","title":"\u57fa\u672cPath Integral\u7b97\u6cd5"},{"location":"Planning_Control_DL/QMDP-Net_ Deep Learning for Planning underPartial Observability/","text":"QMDP-Net: Deep Learning for Planning under Partial Observability \u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u7684QMDP\u7f51\u7edc\uff0c\u76ee\u7684\u662f\u5f53\u673a\u5668\u4eba\u53ea\u80fd\u89c2\u6d4b\u5230\u573a\u666f\u7684\u4e00\u90e8\u5206\u4e14\u4e0d\u80fd\u786e\u5b9a\u81ea\u5df1\u7684\u72b6\u6001\u7684\u65f6\u5019\uff0c\u5982\u679c\u5728\u4e0d\u786e\u5b9a\u6027\u4e2d\u4e00\u8fb9\u63a2\u7d22\u4e00\u8fb9\u8fdb\u884c\u89c4\u5212\u3002 \u672c\u6587\u7684\u56fe\u4e00\u8bf4\u660e\u4e86\u672c\u6587\u53ef\u4ee5\u4f7f\u7528\u6a21\u4eff\u5b66\u4e60\uff0c\u5b66\u4f1a\u4e00\u4e9b\u63a2\u7d22\u7684\u65b9\u5f0f\uff0c\u7136\u540e\u673a\u5668\u4eba\u80fd\u591f\u65b0\u7684\u8ff7\u5bab\u4e2d\u6210\u529f\u5bfc\u822a\u3002 \u4e3b\u8981\u8d21\u732e\u4e0e\u7f51\u7edc\u7ed3\u6784 \u5b8f\u89c2\u6765\u770b\uff0c\u4e00\u4e2aPolicy\u7684\u8f93\u5165\u662f\u5386\u53f2\u4e00\u7cfb\u5217\u7684actions\u548cobservations\uff0c\u8f93\u51fa\u7684\u662f\u4e00\u4e2a\u4e0b\u4e00\u4e2aaction\u3002\u800cQMDP\u7f51\u7edc\u7531\u4e24\u90e8\u5206\u7ec4\u6210\uff0c\u4e00\u4e2a\u662fRNN\u7ed3\u6784\u7684\u8d1d\u53f6\u65af\u6ee4\u6ce2\u5668\uff08\u7528\u4e8e\u7f16\u7801\u4fe1\u606f\uff09\uff0c\u4e00\u4e2a\u662fQMDP planner\u7f51\u7edc\u3002 \u6ee4\u6ce2\u6a21\u5757 \u6ee4\u6ce2\u6a21\u5757\uff0c\u5c06\u4e00\u4e2abelief\u3001\u884c\u52a8\u4ee5\u53ca\u89c2\u6d4b\u6620\u5c04\u5230\u4e0b\u4e00\u4e2abelief b_{t+1} = f(b_t|a_t, o_t) \u3002\u5b9e\u9645\u4e0a\u4f1a\u5206\u4e24\u6b65\uff0c\u7b2c\u4e00\u6b65\u8003\u8651action\uff0c\u7b2c\u4e8c\u6b65\u8003\u8651\u89c2\u6d4b\u3002 \u5bf9\u4e8e\u672c\u6587\u7684\u4e00\u4e2a N*N \u7f51\u683c\u7684\u5bfc\u822a\u4efb\u52a1\uff0cbelief\u662f\u4e00\u4e2aN*N\u7684\u5f20\u91cf\uff0c\u5927\u81f4\u8868\u8fbe\u7684\u662f\u5bf9\u673a\u5668\u4eba\u5f53\u524d\u4f4d\u7f6e\u7684\u7f6e\u4fe1\u5ea6\u3002 \u56fe\u4e2d\u7684 f_T \u662f\u4e00\u4e2a\u5e26\u6709|A|\u7ec4\u6ee4\u6ce2\u5668\u7684\u5377\u79ef\uff0c\u8f93\u51fa\u7684 b_t^\\prime \u662f\u4e0d\u540c\u8fd0\u52a8\u6761\u4ef6\u4e0b\uff0c\u7269\u4f53\u5bf9\u81ea\u8eab\u65b0\u7684\u4f4d\u7f6e\u7684\u4e00\u4e2a\u4f30\u8ba1\u3002 \u7406\u8bba\u4e0a\u6765\u8bf4\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528hard indexing\u53d6\u51fa\u5f53\u524d\u884c\u52a8\u5bf9\u5e94\u7684\u8fd0\u52a8\u540e\u7684\u4f30\u8ba1\uff0c\u4f46\u662f\u8fd9\u91cc\u8bba\u6587\u91c7\u7528\u4e86soft index\uff0c\u7528\u5168\u8fde\u63a5\u5c42\u5c06action\u6620\u5c04\u5230 f_A(a) (\u5f62\u72b6\u4e3aA\u7684\u5f20\u91cf)\u4e2d\uff0c\u518d\u7528\u6c42\u548c(\u70b9\u4e58\uff0c\u5173\u4e8eA\u8fd9\u4e2a\u7ef4\u5ea6\u6c42\u548c)\u7684\u5f62\u5f0f\u6267\u884csoft indexing\u3002 \u89c2\u6d4b\u6a21\u578b\u8f93\u51fa\u4e00\u4e2a N*N*O \u7684\u5f20\u91cf\uff0c\u5176\u4e2d\u6bcf\u4e00\u4e2a\u6570\u4ee3\u8868\u7684\u662f\u7f51\u683c\u5f53\u524d\u70b9\u5f97\u5230\u67d0\u4e00\u4e2a\u6d4b\u91cf\u503c\u7684\u6982\u7387\u3002\u540c\u6837\u91c7\u7528\u4e00\u4e2a\u5168\u8fde\u63a5\u6620\u5c04\u4ee5\u53casoft indexing\uff0c\u5f97\u5230\u4e00\u4e2aN*N\u7684\u6839\u636e\u89c2\u6d4b\u5f97\u5230\u7684\u4f30\u8ba1\u3002 \u5c06\u8fd0\u52a8\u4e0e\u89c2\u6d4b\u5f97\u5230\u7684\u4f30\u8ba1\u4f7f\u7528element-wise multiplication\u878d\u5408 planner \u6a21\u5757 \u4f7f\u7528Value-iteration\u5c42\u8ba1\u7b97\u51fa\u4e00\u4e2aN*N\u7684\u4ef7\u503c\u56fe\u3002\u8fd9\u4e2a\u5c42\u7684\u7b97\u6cd5\u662f 1. \u5c06\u521d\u59cb \\theta \u7528\u4e00\u4e2a\u5377\u79ef\u5c42\u6620\u5c04\u5230Reward\u56fe( N*N*A )\uff0c\u521d\u59cb\u5316Q\u51fd\u6570\u56fe 2. \u5bf9Q\u51fd\u6570\u56fe\u7684Action\u7ef4\u4f5cmax pool (1*1) \u5f97\u5230 V_k 3. \u5377\u79ef V_k \u4ee3\u8868state transition\u518d\u52a0\u4e0areward\u56fe\u5f97\u5230\u65b0\u7684Q\u51fd\u6570\u56fe 4. \u8fed\u4ee32\u30013\u591a\u6b21\uff0c\u5f97\u5230\u6700\u7ec8\u7684Q\u51fd\u6570 \u51b3\u7b56\u7684\u65f6\u5019\uff0c\u5c06Q\u51fd\u6570 (N*N*A) \u4e0e b_t (N*N) \u76f8\u4e58\uff0c\u5e76\u6c42\u548c\u5f97\u5230 q(a) (\u5f62\u72b6\u4e3aA\u7684\u5f20\u91cf) \u518d\u7528\u5168\u8fde\u63a5\u5c06\u8fd9\u4e2aq\u6620\u5c04\u5230action\u4e2d\u3002 \u6a21\u4eff\u8bad\u7ec3\u4e0e\u4f7f\u7528 \u6574\u4e2a\u8fd0\u7b97\u662f\u53ef\u5bfc\uff0c\u56e0\u800c\u53ef\u4ee5\u4f7f\u7528\u6a21\u4eff\u5b66\u4e60\u540c\u65f6\u8bad\u7ec3\u6ee4\u6ce2\u6a21\u5757\u4ee5\u53ca\u89c4\u5212\u6a21\u5757\u3002 \u5b9e\u9a8c\u76f4\u89c9 \u53efgeneralize\u5230\u65b0\u73af\u5883 \u7528soft index\u4ee5\u53ca\u53ef\u5b66\u4e60\u7684transition\u6709\u6548\u7684\u89e3\u51b3\u4e86\u4e0d\u786e\u5b9a\u6027\u95ee\u9898 QMDP-net\u5b66\u4e60\u5230\u7684\u6a21\u578b\u4e0d\u6b63\u786e\uff0c\u4f46\u662f\u6709\u7528 \u5728N\u6bd4\u8f83\u5c0f\u7684\u73af\u5883\u4e2d\u5f97\u5230\u7684\u7f51\u7edc\u53ef\u4ee5\u5feb\u901f\u5b66\u4e60\u5230N\u6bd4\u8f83\u5927\u7684\u73af\u5883 \u53ef\u4ee5\u7528CNN-LSTM\u7ed3\u6784\u66ff\u4ee3\u672c\u6587\u7684filter \u6a21\u5757\uff0c\u4f46\u662f\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u672c\u6587\u7684\u6548\u679c\u66f4\u597d(\u66f4\u591aregularization)","title":"QMDP-Net: Deep Learning for Planning under Partial Observability"},{"location":"Planning_Control_DL/QMDP-Net_ Deep Learning for Planning underPartial Observability/#qmdp-net-deep-learning-for-planning-under-partial-observability","text":"\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u7684QMDP\u7f51\u7edc\uff0c\u76ee\u7684\u662f\u5f53\u673a\u5668\u4eba\u53ea\u80fd\u89c2\u6d4b\u5230\u573a\u666f\u7684\u4e00\u90e8\u5206\u4e14\u4e0d\u80fd\u786e\u5b9a\u81ea\u5df1\u7684\u72b6\u6001\u7684\u65f6\u5019\uff0c\u5982\u679c\u5728\u4e0d\u786e\u5b9a\u6027\u4e2d\u4e00\u8fb9\u63a2\u7d22\u4e00\u8fb9\u8fdb\u884c\u89c4\u5212\u3002 \u672c\u6587\u7684\u56fe\u4e00\u8bf4\u660e\u4e86\u672c\u6587\u53ef\u4ee5\u4f7f\u7528\u6a21\u4eff\u5b66\u4e60\uff0c\u5b66\u4f1a\u4e00\u4e9b\u63a2\u7d22\u7684\u65b9\u5f0f\uff0c\u7136\u540e\u673a\u5668\u4eba\u80fd\u591f\u65b0\u7684\u8ff7\u5bab\u4e2d\u6210\u529f\u5bfc\u822a\u3002","title":"QMDP-Net: Deep Learning for Planning under Partial Observability"},{"location":"Planning_Control_DL/QMDP-Net_ Deep Learning for Planning underPartial Observability/#_1","text":"\u5b8f\u89c2\u6765\u770b\uff0c\u4e00\u4e2aPolicy\u7684\u8f93\u5165\u662f\u5386\u53f2\u4e00\u7cfb\u5217\u7684actions\u548cobservations\uff0c\u8f93\u51fa\u7684\u662f\u4e00\u4e2a\u4e0b\u4e00\u4e2aaction\u3002\u800cQMDP\u7f51\u7edc\u7531\u4e24\u90e8\u5206\u7ec4\u6210\uff0c\u4e00\u4e2a\u662fRNN\u7ed3\u6784\u7684\u8d1d\u53f6\u65af\u6ee4\u6ce2\u5668\uff08\u7528\u4e8e\u7f16\u7801\u4fe1\u606f\uff09\uff0c\u4e00\u4e2a\u662fQMDP planner\u7f51\u7edc\u3002","title":"\u4e3b\u8981\u8d21\u732e\u4e0e\u7f51\u7edc\u7ed3\u6784"},{"location":"Planning_Control_DL/QMDP-Net_ Deep Learning for Planning underPartial Observability/#_2","text":"\u6ee4\u6ce2\u6a21\u5757\uff0c\u5c06\u4e00\u4e2abelief\u3001\u884c\u52a8\u4ee5\u53ca\u89c2\u6d4b\u6620\u5c04\u5230\u4e0b\u4e00\u4e2abelief b_{t+1} = f(b_t|a_t, o_t) \u3002\u5b9e\u9645\u4e0a\u4f1a\u5206\u4e24\u6b65\uff0c\u7b2c\u4e00\u6b65\u8003\u8651action\uff0c\u7b2c\u4e8c\u6b65\u8003\u8651\u89c2\u6d4b\u3002 \u5bf9\u4e8e\u672c\u6587\u7684\u4e00\u4e2a N*N \u7f51\u683c\u7684\u5bfc\u822a\u4efb\u52a1\uff0cbelief\u662f\u4e00\u4e2aN*N\u7684\u5f20\u91cf\uff0c\u5927\u81f4\u8868\u8fbe\u7684\u662f\u5bf9\u673a\u5668\u4eba\u5f53\u524d\u4f4d\u7f6e\u7684\u7f6e\u4fe1\u5ea6\u3002 \u56fe\u4e2d\u7684 f_T \u662f\u4e00\u4e2a\u5e26\u6709|A|\u7ec4\u6ee4\u6ce2\u5668\u7684\u5377\u79ef\uff0c\u8f93\u51fa\u7684 b_t^\\prime \u662f\u4e0d\u540c\u8fd0\u52a8\u6761\u4ef6\u4e0b\uff0c\u7269\u4f53\u5bf9\u81ea\u8eab\u65b0\u7684\u4f4d\u7f6e\u7684\u4e00\u4e2a\u4f30\u8ba1\u3002 \u7406\u8bba\u4e0a\u6765\u8bf4\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528hard indexing\u53d6\u51fa\u5f53\u524d\u884c\u52a8\u5bf9\u5e94\u7684\u8fd0\u52a8\u540e\u7684\u4f30\u8ba1\uff0c\u4f46\u662f\u8fd9\u91cc\u8bba\u6587\u91c7\u7528\u4e86soft index\uff0c\u7528\u5168\u8fde\u63a5\u5c42\u5c06action\u6620\u5c04\u5230 f_A(a) (\u5f62\u72b6\u4e3aA\u7684\u5f20\u91cf)\u4e2d\uff0c\u518d\u7528\u6c42\u548c(\u70b9\u4e58\uff0c\u5173\u4e8eA\u8fd9\u4e2a\u7ef4\u5ea6\u6c42\u548c)\u7684\u5f62\u5f0f\u6267\u884csoft indexing\u3002 \u89c2\u6d4b\u6a21\u578b\u8f93\u51fa\u4e00\u4e2a N*N*O \u7684\u5f20\u91cf\uff0c\u5176\u4e2d\u6bcf\u4e00\u4e2a\u6570\u4ee3\u8868\u7684\u662f\u7f51\u683c\u5f53\u524d\u70b9\u5f97\u5230\u67d0\u4e00\u4e2a\u6d4b\u91cf\u503c\u7684\u6982\u7387\u3002\u540c\u6837\u91c7\u7528\u4e00\u4e2a\u5168\u8fde\u63a5\u6620\u5c04\u4ee5\u53casoft indexing\uff0c\u5f97\u5230\u4e00\u4e2aN*N\u7684\u6839\u636e\u89c2\u6d4b\u5f97\u5230\u7684\u4f30\u8ba1\u3002 \u5c06\u8fd0\u52a8\u4e0e\u89c2\u6d4b\u5f97\u5230\u7684\u4f30\u8ba1\u4f7f\u7528element-wise multiplication\u878d\u5408","title":"\u6ee4\u6ce2\u6a21\u5757"},{"location":"Planning_Control_DL/QMDP-Net_ Deep Learning for Planning underPartial Observability/#planner","text":"\u4f7f\u7528Value-iteration\u5c42\u8ba1\u7b97\u51fa\u4e00\u4e2aN*N\u7684\u4ef7\u503c\u56fe\u3002\u8fd9\u4e2a\u5c42\u7684\u7b97\u6cd5\u662f 1. \u5c06\u521d\u59cb \\theta \u7528\u4e00\u4e2a\u5377\u79ef\u5c42\u6620\u5c04\u5230Reward\u56fe( N*N*A )\uff0c\u521d\u59cb\u5316Q\u51fd\u6570\u56fe 2. \u5bf9Q\u51fd\u6570\u56fe\u7684Action\u7ef4\u4f5cmax pool (1*1) \u5f97\u5230 V_k 3. \u5377\u79ef V_k \u4ee3\u8868state transition\u518d\u52a0\u4e0areward\u56fe\u5f97\u5230\u65b0\u7684Q\u51fd\u6570\u56fe 4. \u8fed\u4ee32\u30013\u591a\u6b21\uff0c\u5f97\u5230\u6700\u7ec8\u7684Q\u51fd\u6570 \u51b3\u7b56\u7684\u65f6\u5019\uff0c\u5c06Q\u51fd\u6570 (N*N*A) \u4e0e b_t (N*N) \u76f8\u4e58\uff0c\u5e76\u6c42\u548c\u5f97\u5230 q(a) (\u5f62\u72b6\u4e3aA\u7684\u5f20\u91cf) \u518d\u7528\u5168\u8fde\u63a5\u5c06\u8fd9\u4e2aq\u6620\u5c04\u5230action\u4e2d\u3002","title":"planner \u6a21\u5757"},{"location":"Planning_Control_DL/QMDP-Net_ Deep Learning for Planning underPartial Observability/#_3","text":"\u6574\u4e2a\u8fd0\u7b97\u662f\u53ef\u5bfc\uff0c\u56e0\u800c\u53ef\u4ee5\u4f7f\u7528\u6a21\u4eff\u5b66\u4e60\u540c\u65f6\u8bad\u7ec3\u6ee4\u6ce2\u6a21\u5757\u4ee5\u53ca\u89c4\u5212\u6a21\u5757\u3002","title":"\u6a21\u4eff\u8bad\u7ec3\u4e0e\u4f7f\u7528"},{"location":"Planning_Control_DL/QMDP-Net_ Deep Learning for Planning underPartial Observability/#_4","text":"\u53efgeneralize\u5230\u65b0\u73af\u5883 \u7528soft index\u4ee5\u53ca\u53ef\u5b66\u4e60\u7684transition\u6709\u6548\u7684\u89e3\u51b3\u4e86\u4e0d\u786e\u5b9a\u6027\u95ee\u9898 QMDP-net\u5b66\u4e60\u5230\u7684\u6a21\u578b\u4e0d\u6b63\u786e\uff0c\u4f46\u662f\u6709\u7528 \u5728N\u6bd4\u8f83\u5c0f\u7684\u73af\u5883\u4e2d\u5f97\u5230\u7684\u7f51\u7edc\u53ef\u4ee5\u5feb\u901f\u5b66\u4e60\u5230N\u6bd4\u8f83\u5927\u7684\u73af\u5883 \u53ef\u4ee5\u7528CNN-LSTM\u7ed3\u6784\u66ff\u4ee3\u672c\u6587\u7684filter \u6a21\u5757\uff0c\u4f46\u662f\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u672c\u6587\u7684\u6548\u679c\u66f4\u597d(\u66f4\u591aregularization)","title":"\u5b9e\u9a8c\u76f4\u89c9"},{"location":"Planning_Control_DL/Universal Planning Networks/","text":"Universal Planning Networks \u8fd9\u7bc7\u8bba\u6587\u7ed9\u51fa\u4e86\u4e00\u4e2a\u901a\u7528\u7684\u7528\u4e8eplanning\u7684\u7f51\u7edc\u7ed3\u6784\uff0c\u76ee\u7684\u662f\u8f93\u51fa\u4e00\u7cfb\u5217\u7684state\u4ee5\u63a5\u8fd1goal state\u3002\u5b83\u4e00\u65b9\u9762\u53ef\u4ee5\u7528\u4e8eplanning\uff0c\u4e5f\u53ef\u4ee5\u6839\u636e\u5b66\u4e60\u5230\u7684\u53c2\u6570\u7ed9\u51fa\u5f3a\u5316\u5b66\u4e60\u4f7f\u7528\u7684\u6210\u672c\u51fd\u6570 \u4e3b\u8981\u8d21\u732e 1. \u7f51\u7edc\u7ed3\u6784\u4e0e\u7b97\u6cd5 \u7ed9\u51fa\u5f53\u524d\u89c2\u6d4b o_t \u4ee5\u53ca\u76ee\u6807\u89c2\u6d4b o_g \u4f5c\u4e3a\u8f93\u5165\u56fe\u50cf\uff0c \\hat a_t \u4e3a t \u65f6\u523b\u9884\u6d4b\u7684\u884c\u52a8 \u5728GDP(Gradien Descent Planner)\u4e2d\uff0c\u7528\u53ef\u5b66\u4e60\u7684\u7f16\u7801\u5668 f_\\phi \u5c06\u89c2\u6d4b o_t \u8f6c\u6362\u4e3alatent space x_t ,\u518d\u7528\u53ef\u5b66\u4e60\u7684\u6a21\u578b\u8f6c\u6362\u53c2\u6570 \\hat x_{t+1} = g_\\theta(x_t, a_t) \u5b66\u4e60 n_p \u6b65\u3002\u5176\u4e2d\u7684action a_t \u4e3a\u968f\u673a\u521d\u59cb\u5316\uff0c\u5176\u540e\u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u8fdb\u884c\u4f18\u5316\u66f4\u65b0\u3002 \u4e2a\u4eba\u7406\u89e3\uff0c\u5176\u5b9estate transition\u7ed3\u6784\u53ef\u4ee5\u4f7f\u7528res\u6b8b\u5dee\u8fde\u63a5\u66f4\u79d1\u5b66\u3002 \u89c4\u5212\u8fc7\u7a0b\u4e2d\u7684\u635f\u5931\u51fd\u6570 L_{plan}^{(i)} \u4e3a\u6700\u7ec8\u9884\u6d4b\u7684 x_{t+T+1} \u4e0e x_g \u7684\u8ddd\u79bb\uff08\u53ef\u5bfc\uff09\u3002 \u5bf9planner\u7684\u8bad\u7ec3\u53ef\u4ee5\u7528Imitation\uff0c\u56e0\u4e3aGDP\u7ed9\u51faaction\u7684\u7b97\u6cd5\u5c3d\u7ba1\u6709\u68af\u5ea6\u7684\u4f7f\u7528\uff0c\u4f46\u662f\u662f\u5b8c\u5168\u53ef\u5bfc\u7684\u3002\u5728\u8fd9\u4e2a\u57fa\u7840\u4e0a\u7ed9\u51fa\u76f8\u5bf9\u53c2\u8003\u884c\u52a8\u7684\u635f\u5931\u51fd\u6570 L_{imitate} = ||\\hat a_{t:T} - a^{*}_{t:t+T}||_2^2 ,\u7528\u68af\u5ea6\u66f4\u65b0\u7f16\u7801\u5668\u4ee5\u53ca\u8fc7\u7a0b\u7f51\u7edc\u7684\u53c2\u6570\u3002 \u672c\u6587\u8fdb\u4e00\u6b65\u4ecb\u7ecd\u4e86\u4f7f\u7528\u8fd9\u4e2a\u5b66\u4e60\u5230\u7684\u7f16\u7801\u5668\u4e0e\u7cfb\u7edf\u6a21\u578b\u6765\u8f85\u52a9\u5f3a\u5316\u5b66\u4e60\u7684\u8fd0\u52a8\u751f\u6210\u3002 \u4e2a\u4eba\u7406\u89e3\uff0c\u8fd9\u4e2a\u6587\u7ae0\u7684\u4ee3\u7801\u96be\u5ea6\u5728\u4e8e\u6a21\u4eff\u5b66\u4e60\u7684\u65f6\u5019\uff0c\u4e00\u65b9\u9762\u9700\u8981\u7528\u68af\u5ea6\u66f4\u65b0\u8fd0\u52a8\uff0c\u53e6\u4e00\u65b9\u9762\u8981\u8fdb\u4e00\u6b65\u7684\u7528\u68af\u5ea6\u66f4\u65b0\u7cfb\u7edf\u53c2\u6570\u3002pytorch\u4ee5\u53caTensorflow\u9ed8\u8ba4\u60c5\u51b5\u4e0b\u53ea\u4f1a\u8bb0\u4f4f\u4e00\u6b21\u8fd0\u7b97\u8fc7\u7a0b\u4e2d\u7684\u68af\u5ea6\u4fe1\u606f\uff0c\u7136\u540e\u5728\u68af\u5ea6\u66f4\u65b0\u7684\u65f6\u5019\u9700\u8981\u5220\u9664\u6b64\u524d\u8bb0\u5f55\u7684\u6240\u6709\u8fd0\u7b97\u56fe\u3002\u4f46\u662f\u8fd9\u91cc\u6a21\u4eff\u7684\u65f6\u5019\u4f3c\u4e4e\u9700\u8981\u6211\u4eec\u8bb0\u4f4f\u68af\u5ea6\u66f4\u65b0\u7684\u65f6\u5019\u4f7f\u7528\u7684\u6574\u4e2a\u8fd0\u7b97\u56fe(\u4e5f\u53ef\u80fd\u53ea\u9700\u8981\u6700\u540e\u4e00\u6b65\uff0c\u5e76\u4fdd\u7559\u6700\u540e\u4e00\u6b65\u7684\u68af\u5ea6)","title":"Universal Planning Networks"},{"location":"Planning_Control_DL/Universal Planning Networks/#universal-planning-networks","text":"\u8fd9\u7bc7\u8bba\u6587\u7ed9\u51fa\u4e86\u4e00\u4e2a\u901a\u7528\u7684\u7528\u4e8eplanning\u7684\u7f51\u7edc\u7ed3\u6784\uff0c\u76ee\u7684\u662f\u8f93\u51fa\u4e00\u7cfb\u5217\u7684state\u4ee5\u63a5\u8fd1goal state\u3002\u5b83\u4e00\u65b9\u9762\u53ef\u4ee5\u7528\u4e8eplanning\uff0c\u4e5f\u53ef\u4ee5\u6839\u636e\u5b66\u4e60\u5230\u7684\u53c2\u6570\u7ed9\u51fa\u5f3a\u5316\u5b66\u4e60\u4f7f\u7528\u7684\u6210\u672c\u51fd\u6570","title":"Universal Planning Networks"},{"location":"Planning_Control_DL/Universal Planning Networks/#_1","text":"","title":"\u4e3b\u8981\u8d21\u732e"},{"location":"Planning_Control_DL/Universal Planning Networks/#1","text":"\u7ed9\u51fa\u5f53\u524d\u89c2\u6d4b o_t \u4ee5\u53ca\u76ee\u6807\u89c2\u6d4b o_g \u4f5c\u4e3a\u8f93\u5165\u56fe\u50cf\uff0c \\hat a_t \u4e3a t \u65f6\u523b\u9884\u6d4b\u7684\u884c\u52a8 \u5728GDP(Gradien Descent Planner)\u4e2d\uff0c\u7528\u53ef\u5b66\u4e60\u7684\u7f16\u7801\u5668 f_\\phi \u5c06\u89c2\u6d4b o_t \u8f6c\u6362\u4e3alatent space x_t ,\u518d\u7528\u53ef\u5b66\u4e60\u7684\u6a21\u578b\u8f6c\u6362\u53c2\u6570 \\hat x_{t+1} = g_\\theta(x_t, a_t) \u5b66\u4e60 n_p \u6b65\u3002\u5176\u4e2d\u7684action a_t \u4e3a\u968f\u673a\u521d\u59cb\u5316\uff0c\u5176\u540e\u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u8fdb\u884c\u4f18\u5316\u66f4\u65b0\u3002 \u4e2a\u4eba\u7406\u89e3\uff0c\u5176\u5b9estate transition\u7ed3\u6784\u53ef\u4ee5\u4f7f\u7528res\u6b8b\u5dee\u8fde\u63a5\u66f4\u79d1\u5b66\u3002 \u89c4\u5212\u8fc7\u7a0b\u4e2d\u7684\u635f\u5931\u51fd\u6570 L_{plan}^{(i)} \u4e3a\u6700\u7ec8\u9884\u6d4b\u7684 x_{t+T+1} \u4e0e x_g \u7684\u8ddd\u79bb\uff08\u53ef\u5bfc\uff09\u3002 \u5bf9planner\u7684\u8bad\u7ec3\u53ef\u4ee5\u7528Imitation\uff0c\u56e0\u4e3aGDP\u7ed9\u51faaction\u7684\u7b97\u6cd5\u5c3d\u7ba1\u6709\u68af\u5ea6\u7684\u4f7f\u7528\uff0c\u4f46\u662f\u662f\u5b8c\u5168\u53ef\u5bfc\u7684\u3002\u5728\u8fd9\u4e2a\u57fa\u7840\u4e0a\u7ed9\u51fa\u76f8\u5bf9\u53c2\u8003\u884c\u52a8\u7684\u635f\u5931\u51fd\u6570 L_{imitate} = ||\\hat a_{t:T} - a^{*}_{t:t+T}||_2^2 ,\u7528\u68af\u5ea6\u66f4\u65b0\u7f16\u7801\u5668\u4ee5\u53ca\u8fc7\u7a0b\u7f51\u7edc\u7684\u53c2\u6570\u3002 \u672c\u6587\u8fdb\u4e00\u6b65\u4ecb\u7ecd\u4e86\u4f7f\u7528\u8fd9\u4e2a\u5b66\u4e60\u5230\u7684\u7f16\u7801\u5668\u4e0e\u7cfb\u7edf\u6a21\u578b\u6765\u8f85\u52a9\u5f3a\u5316\u5b66\u4e60\u7684\u8fd0\u52a8\u751f\u6210\u3002 \u4e2a\u4eba\u7406\u89e3\uff0c\u8fd9\u4e2a\u6587\u7ae0\u7684\u4ee3\u7801\u96be\u5ea6\u5728\u4e8e\u6a21\u4eff\u5b66\u4e60\u7684\u65f6\u5019\uff0c\u4e00\u65b9\u9762\u9700\u8981\u7528\u68af\u5ea6\u66f4\u65b0\u8fd0\u52a8\uff0c\u53e6\u4e00\u65b9\u9762\u8981\u8fdb\u4e00\u6b65\u7684\u7528\u68af\u5ea6\u66f4\u65b0\u7cfb\u7edf\u53c2\u6570\u3002pytorch\u4ee5\u53caTensorflow\u9ed8\u8ba4\u60c5\u51b5\u4e0b\u53ea\u4f1a\u8bb0\u4f4f\u4e00\u6b21\u8fd0\u7b97\u8fc7\u7a0b\u4e2d\u7684\u68af\u5ea6\u4fe1\u606f\uff0c\u7136\u540e\u5728\u68af\u5ea6\u66f4\u65b0\u7684\u65f6\u5019\u9700\u8981\u5220\u9664\u6b64\u524d\u8bb0\u5f55\u7684\u6240\u6709\u8fd0\u7b97\u56fe\u3002\u4f46\u662f\u8fd9\u91cc\u6a21\u4eff\u7684\u65f6\u5019\u4f3c\u4e4e\u9700\u8981\u6211\u4eec\u8bb0\u4f4f\u68af\u5ea6\u66f4\u65b0\u7684\u65f6\u5019\u4f7f\u7528\u7684\u6574\u4e2a\u8fd0\u7b97\u56fe(\u4e5f\u53ef\u80fd\u53ea\u9700\u8981\u6700\u540e\u4e00\u6b65\uff0c\u5e76\u4fdd\u7559\u6700\u540e\u4e00\u6b65\u7684\u68af\u5ea6)","title":"1. \u7f51\u7edc\u7ed3\u6784\u4e0e\u7b97\u6cd5"},{"location":"Planning_Control_DL/diff_MPC_ARE/","text":"Infinite-Horizon Differentiable Model Predictive Control \u8fd9\u7bc7paper\u4e0e OptNet \u6709\u5f88\u5f3a\u7684\u5173\u8054\u6027. OptNet \u5229\u7528KKT condition\u5bf9QP\u95ee\u9898\u7684\u63a8\u7406\u7ed3\u679c\u8fdb\u884c\u53cd\u5411\u6c42\u5bfc\uff0c\u4f7f\u5f97\u4e8c\u6b21\u89c4\u5212\u4f18\u5316\u95ee\u9898\u7684backward\u9636\u6bb5\u4e0d\u9700\u8981\u88abforward\u9636\u6bb5\u7684\u8fed\u4ee3\u6240\u5f71\u54cd\u3002\u6548\u7387\u663e\u8457\u63d0\u9ad8\u3002 \u8fd9\u7bc7paper\u5219\u4f7f\u7528\u4e86\u63a7\u5236\u9886\u57df\u7684\u4e00\u4e2a\u5e38\u89c1\u7684trick\uff0c\u5728\u4f7f\u7528\u975e\u7ebf\u6027\u4f18\u5316\u5668/\u590d\u6742\u7b97\u6cd5\u65f6\uff0c\u5148\u4f7f\u7528\u4e00\u4e2a\u53ef\u9760\u7684\u63a7\u5236\u5668\u4f7f\u539f\u6765\u7684\u7cfb\u7edf\u57fa\u672c\u7a33\u5b9a\uff0c\u518d\u8ba9\u989d\u5916\u6dfb\u52a0\u7684\u4f18\u5316\u5668\u5bf9\u6b8b\u5dee\u7ed3\u679c\u8fdb\u884c\u56de\u5f52\u3002 \u672c\u6587\u4f7f\u7528\u7684\u9884\u7a33\u5b9a\u63a7\u5236\u5668\u662f\u4e00\u4e2aLQR\u63a7\u5236\u5668\u3002\u800cLQR\u4e2d\u5b58\u5728\u6709Q\uff0cR\u4e24\u4e2a\u4ee3\u8868\u5404\u4e2astate\u4e0einput\u7684\u635f\u5931\u8d85\u53c2\uff0c\u4f5c\u8005\u7684\u4e00\u4e2a\u4e3b\u8981\u8d21\u732e\u5c31\u662f\u8ba9\u8fd9\u4e24\u4e2a\u635f\u5931\u8d85\u53c2\u4e5f\u53d8\u6210\u53ef\u4ee5\u88ab\u5b66\u4e60\u7684\u53c2\u6570\uff0c\u7ed9\u51fa\u4e86\u5bf9Riccati\u65b9\u7a0b\u7684\u5bfc\u6570\u8fdb\u884c\u4f20\u64ad\u7684\u516c\u5f0f\u3002 \u6587\u7ae0\u7684\u7b97\u6cd5\u6846\u67b6\u5982\u56fe: MPC Review \u5bf9\u4e8e\u4e00\u4e2a\u7ebf\u6027\u7cfb\u7edf\uff0c\u6b65\u957f\u4e3a N \u7684MPC\u63a7\u5236\uff0c\u53ef\u4ee5\u5212\u5f52\u4e3a\u4ee5\u4e0b\u5e26\u6709\u677e\u5f1b\u53d8\u91cf(slack variables)\u7684\u4e8c\u6b21\u4f18\u5316\u95ee\u9898.\u4f7f\u5f97\u95ee\u9898\u603b\u662f\u6709\u89e3\u7684\u3002 \\begin{aligned} \\hat{u}_{0: N}^{\\star}=\\underset{\\hat{u}}{\\operatorname{argmin}} &\\frac{1}{2} \\sum_{k=0}^{N-1} \\hat{u}_{k}^{\\top} R \\hat{u}_{k}+\\frac{1}{2} \\sum_{k=1}^{N-1} \\hat{x}_{k}^{\\top} Q \\hat{x}_{k}+\\frac{1}{2} \\hat{x}_{N}^{\\top} Q_{N} \\hat{x}_{N}+k_{u} \\sum_{k=0}^{N-1} \\mathbf{1}_{m}^{\\top} r_{k}+k_{x} \\sum_{k=1}^{N} \\mathbf{1}_{n}^{\\top} s_{k} \\\\ \\text { s.t. } &\\hat{x}_{0}=x_{t} \\\\ &\\hat{x}_{k+1}=A \\hat{x}_{k}+B \\hat{u}_{k}, \\quad k \\in\\{0, \\ldots, N-1\\} \\\\ &\\underline{u}-r_{k} \\leq \\hat{u}_{k} \\leq \\bar{u}+r_{k} \\quad \\text { and } \\quad r_{k} \\geq 0, \\quad k \\in\\{0, \\cdots N-1\\} \\\\ &\\underline{x}-s_{k} \\leq \\hat{x}_{k} \\leq \\bar{x}+s_{k} \\quad \\text { and } \\quad s_{k} \\geq 0, \\quad k \\in\\{1, \\ldots, N\\} \\end{aligned} \u5982\u679c\u5c06\u8f93\u5165\u63a7\u5236\u53d8\u91cf\u5206\u89e3\u4e3a u_t = Kx_t + \\delta u_t ,\u5176\u4e2d K \u4e3a\u7ebf\u6027\u72b6\u6001\u53cd\u9988\u77e9\u9635\u3002\u4e0a\u8ff0\u95ee\u9898\u53d8\u4e3a \\begin{aligned} \\delta \\hat{u}_{0: N}^{\\star}=\\underset{\\delta \\hat{u}}{\\operatorname{argmin}} & \\frac{1}{2} \\sum_{k=0}^{N-1}\\left(K \\hat{x}_{k}+\\delta \\hat{u}_{k}\\right)^{\\top} R\\left(K \\hat{x}_{k}+\\delta \\hat{u}_{k}\\right)+\\frac{1}{2} \\sum_{k=1}^{N-1} \\hat{x}_{k}^{\\top} Q \\hat{x}_{k}+\\frac{1}{2} \\hat{x}_{N}^{\\top} Q_{N} \\hat{x}_{N} \\\\ &+k_{u} \\sum_{k=0}^{N-1} \\mathbf{1}_{m}^{\\top} r_{k}+k_{x} \\sum_{k=1}^{N} \\mathbf{1}_{n}^{\\top} s_{k} \\\\ \\text { s.t. } & \\hat{x}_{0}=x_{t} \\\\ &\\hat{x}_{k+1}=(A+B K) \\hat{x}_{k}+B \\delta \\hat{u}_{k}, \\quad k \\in\\{0, \\ldots, N-1\\} \\\\ & \\underline{u}-r_{k} \\leq K \\hat{x}_{k}+\\delta \\hat{u}_{k} \\leq \\bar{u}+r_{k} \\quad \\text { and } \\quad r_{k} \\geq 0, \\quad k \\in\\{0, \\ldots, N-1\\} \\\\ &\\underline{x}-s_{k} \\leq \\hat{x}_{k} \\leq \\bar{x}+s_{k} \\text { and } \\quad s_{k} \\geq 0, \\quad k \\in\\{1, \\ldots, N\\} \\end{aligned} \u5c06\u5b83\u4eec\u91cd\u6574\u4e3aQP\u95ee\u9898\u540e\uff0c\u53ef\u4ee5\u4f7f\u7528 OptNet \u7684\u6a21\u5757\u5f97\u5230\u4f18\u5316\u7ed3\u679c\u4ee5\u53ca\u5bf9 Q, R, A, B, \\underline{u}, \\bar{u}, \\underline{x}, \\bar{x}, k_{x} \u548c k_{u} \u7684\u5bfc\u6570\u3002 \u6a21\u4eff\u5b66\u4e60\u5219\u53ef\u4ee5\u6839\u636e\u4f18\u5316\u7ed3\u679c\u4ee5\u53ca\u4e13\u5bb6\u6807\u6ce8\u7ed9\u51fa\u635f\u5931\u3002 Infinite Horizon Terminal Cost LQR\u6700\u4f18\u63a7\u5236\u5668\u5f97\u5230\u7684\u63a7\u5236\u7ed3\u679c\u662f\u9488\u5bf9\u65e0\u9650\u9884\u6d4b\u6b65\u957f\u7684LTI\u7cfb\u7edfMPC\u95ee\u9898\u3002\u5176 K \u4e3a K=-\\left(R+B^{\\top} P B\\right)^{-1} B^{\\top} P A \u5176\u4e2d P \u4e3a\u79bb\u6563Riccati\u65b9\u7a0b\u7684\u89e3: P=A^{\\top} P A-A^{\\top} P B\\left(R+B^{\\top} P B\\right)^{-1} B^{\\top} P A+Q \u6ce8\u610f P \u7684 \u6570\u5b66\u610f\u4e49 ,Final cost J = x_0^TPx_0 .\u672c\u6587\u63d0\u51fa\u524d\u6587\u7684MPC\u4e2d\uff0c\u7528\u4e8e\u8868\u8fbe\u7a33\u6001cost\u7684\u77e9\u9635 Q_N = P . \u5bf9\u4e8e\u9009\u62e9 Q_N=P \u7684MPC\uff0c\u4f5c\u8005\u8bc1\u660e\u4e86\u4e00\u7cfb\u5217\u597d\u7684\u6027\u8d28\uff0c\u5305\u62ec\u5b58\u5728\u6709\u9650\u89c6\u754cMPC\u4f7f\u5f97\u65e0\u9650\u89c6\u754c\u6700\u4f18\uff0cMPC\u53ef\u884c\u6027\u3001\u6e10\u8fdb\u7a33\u5b9a\u6027\uff0c\u9c81\u68d2\u6027\u7b49\u3002 \u4f5c\u8005\u63d0\u51fa\u4e86 P \u4e0e A,B,Q,R \u7684\u77e2\u91cf\u5173\u7cfb\u3002 \\frac{\\partial \\operatorname{vec} P}{\\partial \\operatorname{vec} A}=Z_{1}^{-1} Z_{2}, \\quad \\frac{\\partial \\operatorname{vec} P}{\\partial \\operatorname{vec} B}=Z_{1}^{-1} Z_{3}, \\quad \\frac{\\partial \\operatorname{vec} P}{\\partial \\operatorname{vec} Q}=Z_{1}^{-1} Z_{4}, \\quad \\frac{\\partial \\operatorname{vec} P}{\\partial \\operatorname{vec} R}=Z_{1}^{-1} Z_{5} \\begin{aligned} Z_{1}&:=\\mathbf{I}_{n^{2}}-\\left(A^{\\top} \\otimes A^{\\top}\\right)\\left[\\mathbf{I}_{n^{2}}-\\left(P B M_{2} B^{\\top} \\otimes \\mathbf{I}_{n}\\right)-\\left(\\mathbf{I}_{n} \\otimes P B M_{2} B^{\\top}\\right)\\right. \\\\ &\\left.+(P B \\otimes P B)\\left(M_{2} \\otimes M_{2}\\right)\\left(B^{\\top} \\otimes B^{\\top}\\right)\\right] \\\\ Z_{2}&:=\\left(\\mathbf{V}_{n, n}+\\mathbf{I}_{n^{2}}\\right)\\left(\\mathbf{I}_{n} \\otimes A^{\\top} M_{1}\\right) \\\\ Z_{3}&:=\\left(A^{\\top} \\otimes A^{\\top}\\right)\\left[(P B \\otimes P B)\\left(M_{2} \\otimes M_{2}\\right)\\left(\\mathbf{I}_{m^{2}}+\\mathbf{V}_{m, m}\\right)\\left(\\mathbf{I}_{m} \\otimes B^{\\top} P\\right)\\right. \\\\ &\\left.-\\left(\\mathbf{I}_{n^{2}}+\\mathbf{V}_{n, n}\\right)\\left(P B M_{2} \\otimes P\\right)\\right] \\\\ Z_{4}&:=\\mathbf{I}_{n^{2}} \\\\ Z_{5}&:=\\left(A^{\\top} \\otimes A^{\\top}\\right)(P B \\otimes P B)\\left(M_{2} \\otimes M_{2}\\right) \\end{aligned} \\\\ \u5176\u4e2d \\otimes \u4e3a kronecker product","title":"Infinite-Horizon Differentiable Model Predictive Control"},{"location":"Planning_Control_DL/diff_MPC_ARE/#infinite-horizon-differentiable-model-predictive-control","text":"\u8fd9\u7bc7paper\u4e0e OptNet \u6709\u5f88\u5f3a\u7684\u5173\u8054\u6027. OptNet \u5229\u7528KKT condition\u5bf9QP\u95ee\u9898\u7684\u63a8\u7406\u7ed3\u679c\u8fdb\u884c\u53cd\u5411\u6c42\u5bfc\uff0c\u4f7f\u5f97\u4e8c\u6b21\u89c4\u5212\u4f18\u5316\u95ee\u9898\u7684backward\u9636\u6bb5\u4e0d\u9700\u8981\u88abforward\u9636\u6bb5\u7684\u8fed\u4ee3\u6240\u5f71\u54cd\u3002\u6548\u7387\u663e\u8457\u63d0\u9ad8\u3002 \u8fd9\u7bc7paper\u5219\u4f7f\u7528\u4e86\u63a7\u5236\u9886\u57df\u7684\u4e00\u4e2a\u5e38\u89c1\u7684trick\uff0c\u5728\u4f7f\u7528\u975e\u7ebf\u6027\u4f18\u5316\u5668/\u590d\u6742\u7b97\u6cd5\u65f6\uff0c\u5148\u4f7f\u7528\u4e00\u4e2a\u53ef\u9760\u7684\u63a7\u5236\u5668\u4f7f\u539f\u6765\u7684\u7cfb\u7edf\u57fa\u672c\u7a33\u5b9a\uff0c\u518d\u8ba9\u989d\u5916\u6dfb\u52a0\u7684\u4f18\u5316\u5668\u5bf9\u6b8b\u5dee\u7ed3\u679c\u8fdb\u884c\u56de\u5f52\u3002 \u672c\u6587\u4f7f\u7528\u7684\u9884\u7a33\u5b9a\u63a7\u5236\u5668\u662f\u4e00\u4e2aLQR\u63a7\u5236\u5668\u3002\u800cLQR\u4e2d\u5b58\u5728\u6709Q\uff0cR\u4e24\u4e2a\u4ee3\u8868\u5404\u4e2astate\u4e0einput\u7684\u635f\u5931\u8d85\u53c2\uff0c\u4f5c\u8005\u7684\u4e00\u4e2a\u4e3b\u8981\u8d21\u732e\u5c31\u662f\u8ba9\u8fd9\u4e24\u4e2a\u635f\u5931\u8d85\u53c2\u4e5f\u53d8\u6210\u53ef\u4ee5\u88ab\u5b66\u4e60\u7684\u53c2\u6570\uff0c\u7ed9\u51fa\u4e86\u5bf9Riccati\u65b9\u7a0b\u7684\u5bfc\u6570\u8fdb\u884c\u4f20\u64ad\u7684\u516c\u5f0f\u3002 \u6587\u7ae0\u7684\u7b97\u6cd5\u6846\u67b6\u5982\u56fe:","title":"Infinite-Horizon Differentiable Model Predictive Control"},{"location":"Planning_Control_DL/diff_MPC_ARE/#mpc-review","text":"\u5bf9\u4e8e\u4e00\u4e2a\u7ebf\u6027\u7cfb\u7edf\uff0c\u6b65\u957f\u4e3a N \u7684MPC\u63a7\u5236\uff0c\u53ef\u4ee5\u5212\u5f52\u4e3a\u4ee5\u4e0b\u5e26\u6709\u677e\u5f1b\u53d8\u91cf(slack variables)\u7684\u4e8c\u6b21\u4f18\u5316\u95ee\u9898.\u4f7f\u5f97\u95ee\u9898\u603b\u662f\u6709\u89e3\u7684\u3002 \\begin{aligned} \\hat{u}_{0: N}^{\\star}=\\underset{\\hat{u}}{\\operatorname{argmin}} &\\frac{1}{2} \\sum_{k=0}^{N-1} \\hat{u}_{k}^{\\top} R \\hat{u}_{k}+\\frac{1}{2} \\sum_{k=1}^{N-1} \\hat{x}_{k}^{\\top} Q \\hat{x}_{k}+\\frac{1}{2} \\hat{x}_{N}^{\\top} Q_{N} \\hat{x}_{N}+k_{u} \\sum_{k=0}^{N-1} \\mathbf{1}_{m}^{\\top} r_{k}+k_{x} \\sum_{k=1}^{N} \\mathbf{1}_{n}^{\\top} s_{k} \\\\ \\text { s.t. } &\\hat{x}_{0}=x_{t} \\\\ &\\hat{x}_{k+1}=A \\hat{x}_{k}+B \\hat{u}_{k}, \\quad k \\in\\{0, \\ldots, N-1\\} \\\\ &\\underline{u}-r_{k} \\leq \\hat{u}_{k} \\leq \\bar{u}+r_{k} \\quad \\text { and } \\quad r_{k} \\geq 0, \\quad k \\in\\{0, \\cdots N-1\\} \\\\ &\\underline{x}-s_{k} \\leq \\hat{x}_{k} \\leq \\bar{x}+s_{k} \\quad \\text { and } \\quad s_{k} \\geq 0, \\quad k \\in\\{1, \\ldots, N\\} \\end{aligned} \u5982\u679c\u5c06\u8f93\u5165\u63a7\u5236\u53d8\u91cf\u5206\u89e3\u4e3a u_t = Kx_t + \\delta u_t ,\u5176\u4e2d K \u4e3a\u7ebf\u6027\u72b6\u6001\u53cd\u9988\u77e9\u9635\u3002\u4e0a\u8ff0\u95ee\u9898\u53d8\u4e3a \\begin{aligned} \\delta \\hat{u}_{0: N}^{\\star}=\\underset{\\delta \\hat{u}}{\\operatorname{argmin}} & \\frac{1}{2} \\sum_{k=0}^{N-1}\\left(K \\hat{x}_{k}+\\delta \\hat{u}_{k}\\right)^{\\top} R\\left(K \\hat{x}_{k}+\\delta \\hat{u}_{k}\\right)+\\frac{1}{2} \\sum_{k=1}^{N-1} \\hat{x}_{k}^{\\top} Q \\hat{x}_{k}+\\frac{1}{2} \\hat{x}_{N}^{\\top} Q_{N} \\hat{x}_{N} \\\\ &+k_{u} \\sum_{k=0}^{N-1} \\mathbf{1}_{m}^{\\top} r_{k}+k_{x} \\sum_{k=1}^{N} \\mathbf{1}_{n}^{\\top} s_{k} \\\\ \\text { s.t. } & \\hat{x}_{0}=x_{t} \\\\ &\\hat{x}_{k+1}=(A+B K) \\hat{x}_{k}+B \\delta \\hat{u}_{k}, \\quad k \\in\\{0, \\ldots, N-1\\} \\\\ & \\underline{u}-r_{k} \\leq K \\hat{x}_{k}+\\delta \\hat{u}_{k} \\leq \\bar{u}+r_{k} \\quad \\text { and } \\quad r_{k} \\geq 0, \\quad k \\in\\{0, \\ldots, N-1\\} \\\\ &\\underline{x}-s_{k} \\leq \\hat{x}_{k} \\leq \\bar{x}+s_{k} \\text { and } \\quad s_{k} \\geq 0, \\quad k \\in\\{1, \\ldots, N\\} \\end{aligned} \u5c06\u5b83\u4eec\u91cd\u6574\u4e3aQP\u95ee\u9898\u540e\uff0c\u53ef\u4ee5\u4f7f\u7528 OptNet \u7684\u6a21\u5757\u5f97\u5230\u4f18\u5316\u7ed3\u679c\u4ee5\u53ca\u5bf9 Q, R, A, B, \\underline{u}, \\bar{u}, \\underline{x}, \\bar{x}, k_{x} \u548c k_{u} \u7684\u5bfc\u6570\u3002 \u6a21\u4eff\u5b66\u4e60\u5219\u53ef\u4ee5\u6839\u636e\u4f18\u5316\u7ed3\u679c\u4ee5\u53ca\u4e13\u5bb6\u6807\u6ce8\u7ed9\u51fa\u635f\u5931\u3002","title":"MPC Review"},{"location":"Planning_Control_DL/diff_MPC_ARE/#infinite-horizon-terminal-cost","text":"LQR\u6700\u4f18\u63a7\u5236\u5668\u5f97\u5230\u7684\u63a7\u5236\u7ed3\u679c\u662f\u9488\u5bf9\u65e0\u9650\u9884\u6d4b\u6b65\u957f\u7684LTI\u7cfb\u7edfMPC\u95ee\u9898\u3002\u5176 K \u4e3a K=-\\left(R+B^{\\top} P B\\right)^{-1} B^{\\top} P A \u5176\u4e2d P \u4e3a\u79bb\u6563Riccati\u65b9\u7a0b\u7684\u89e3: P=A^{\\top} P A-A^{\\top} P B\\left(R+B^{\\top} P B\\right)^{-1} B^{\\top} P A+Q \u6ce8\u610f P \u7684 \u6570\u5b66\u610f\u4e49 ,Final cost J = x_0^TPx_0 .\u672c\u6587\u63d0\u51fa\u524d\u6587\u7684MPC\u4e2d\uff0c\u7528\u4e8e\u8868\u8fbe\u7a33\u6001cost\u7684\u77e9\u9635 Q_N = P . \u5bf9\u4e8e\u9009\u62e9 Q_N=P \u7684MPC\uff0c\u4f5c\u8005\u8bc1\u660e\u4e86\u4e00\u7cfb\u5217\u597d\u7684\u6027\u8d28\uff0c\u5305\u62ec\u5b58\u5728\u6709\u9650\u89c6\u754cMPC\u4f7f\u5f97\u65e0\u9650\u89c6\u754c\u6700\u4f18\uff0cMPC\u53ef\u884c\u6027\u3001\u6e10\u8fdb\u7a33\u5b9a\u6027\uff0c\u9c81\u68d2\u6027\u7b49\u3002 \u4f5c\u8005\u63d0\u51fa\u4e86 P \u4e0e A,B,Q,R \u7684\u77e2\u91cf\u5173\u7cfb\u3002 \\frac{\\partial \\operatorname{vec} P}{\\partial \\operatorname{vec} A}=Z_{1}^{-1} Z_{2}, \\quad \\frac{\\partial \\operatorname{vec} P}{\\partial \\operatorname{vec} B}=Z_{1}^{-1} Z_{3}, \\quad \\frac{\\partial \\operatorname{vec} P}{\\partial \\operatorname{vec} Q}=Z_{1}^{-1} Z_{4}, \\quad \\frac{\\partial \\operatorname{vec} P}{\\partial \\operatorname{vec} R}=Z_{1}^{-1} Z_{5} \\begin{aligned} Z_{1}&:=\\mathbf{I}_{n^{2}}-\\left(A^{\\top} \\otimes A^{\\top}\\right)\\left[\\mathbf{I}_{n^{2}}-\\left(P B M_{2} B^{\\top} \\otimes \\mathbf{I}_{n}\\right)-\\left(\\mathbf{I}_{n} \\otimes P B M_{2} B^{\\top}\\right)\\right. \\\\ &\\left.+(P B \\otimes P B)\\left(M_{2} \\otimes M_{2}\\right)\\left(B^{\\top} \\otimes B^{\\top}\\right)\\right] \\\\ Z_{2}&:=\\left(\\mathbf{V}_{n, n}+\\mathbf{I}_{n^{2}}\\right)\\left(\\mathbf{I}_{n} \\otimes A^{\\top} M_{1}\\right) \\\\ Z_{3}&:=\\left(A^{\\top} \\otimes A^{\\top}\\right)\\left[(P B \\otimes P B)\\left(M_{2} \\otimes M_{2}\\right)\\left(\\mathbf{I}_{m^{2}}+\\mathbf{V}_{m, m}\\right)\\left(\\mathbf{I}_{m} \\otimes B^{\\top} P\\right)\\right. \\\\ &\\left.-\\left(\\mathbf{I}_{n^{2}}+\\mathbf{V}_{n, n}\\right)\\left(P B M_{2} \\otimes P\\right)\\right] \\\\ Z_{4}&:=\\mathbf{I}_{n^{2}} \\\\ Z_{5}&:=\\left(A^{\\top} \\otimes A^{\\top}\\right)(P B \\otimes P B)\\left(M_{2} \\otimes M_{2}\\right) \\end{aligned} \\\\ \u5176\u4e2d \\otimes \u4e3a kronecker product","title":"Infinite Horizon Terminal Cost"},{"location":"The_theory/CNN_position_information/","text":"How much Position Information Do Convolutional Neural Networks Encode? \u8fd9\u7bc7\u8bba\u6587\u8ba8\u8bba\u7684\u662f\u5173\u4e8eCNN\u5982\u4f55\u5b58\u50a8\u7edd\u5bf9\u4f4d\u7f6e\u4fe1\u606f\u7684\u3002\u8fd9\u7bc7\u6587\u7ae0\u6700\u7ec8\u7ed3\u8bba\u662fCNN\u901a\u8fc7zero-padding\u5f97\u5230\u8fb9\u754c\u4fe1\u606f\uff0c\u5e76\u4e14\u901a\u8fc7\u5927\u611f\u53d7\u91ce\u7684\u795e\u7ecf\u5143\u5c06\u7edd\u5bf9\u4f4d\u7f6e\u4fe1\u606f\u4f20\u9012\u3002\u672c\u6587\u66f4\u503c\u5f97\u4e00\u8bfb\u7684\u662f\u9762\u5bf9CNN\u65f6\u5176\u4e2d\u8fde\u8d2f\u7684\u903b\u8f91\u63a8\u7406\u601d\u8def\u4ee5\u53ca\u5b9e\u9a8c\u8bbe\u8ba1\u3002\u4f5c\u8005\u4f7f\u7528\u5b9e\u9a8c\u8fde\u7eed\u5730\u8bf4\u660e\u51e0\u4e2a\u95ee\u9898\uff0c\u9996\u5148\u662f\u4ecesegmentation\u5b9e\u9a8c\u4e2d\uff0cmotivated\u5f97\u77e5CNN\u4f3c\u4e4e\u786e\u5b9e\u5bf9\u7edd\u5bf9\u4f4d\u7f6e\u6709\u611f\u77e5\u80fd\u529b,\u5176\u6b21\u8bbe\u8ba1\u4e86\u4e00\u4e2arandom test\u8bf4\u660e\u76ee\u524d\u5e38\u89c1\u7684CNN\u786e\u5b9e\u6709\u7edd\u5bf9\u4f4d\u7f6e\u63a8\u7406\u80fd\u529b\uff0c\u518d\u63a5\u7740\u8bbe\u8ba1\u591a\u7ec4\u5bf9\u6bd4\u5b9e\u9a8c\u4ee5\u53caabelation study,\u53d1\u73b0\u4e86\u8d8a\u6df1\u7684feature map\u5bf9\u7edd\u5bf9\u4f4d\u7f6e\u611f\u77e5\u529b\u8d8a\u5f3a\uff0c\u540c\u65f6\u53d1\u73b0padding\u7684\u6709\u65e0\u5bf9\u6574\u4e2a\u7f51\u7edc\u7edd\u5bf9\u4f4d\u7f6e\u611f\u77e5\u80fd\u529b\u7684\u5de8\u5927\u5f71\u54cd\u3002 Motivation \u56fe\u4e2d\u53d1\u73b0\u7684\u662fsalient detection\u5bf9cropped\u7684\u56fe\u7247inference\u7ed3\u679c\u4e0e\u539f\u56fe\u6709\u5dee\u522b\uff0c\u5982\u679cCNN\u4ec5\u4f9d\u8d56\u50cf\u7d20\u7279\u5f81\u4e0d\u5e94\u6709\u5982\u6b64\u5927\u7684\u5dee\u522b\uff0c\u8fd9\u91cc\u63a8\u6d4b\u7269\u4f53\u4f4d\u7f6e\u4e5f\u4f1a\u5f71\u54cddetection\u7ed3\u679c\uff0c\u4e5f\u5c31\u662fCNN\u6709\u5b58\u50a8\u7a7a\u95f4\u4f4d\u7f6e\u7684\u80fd\u529b\u3002 Random Test random test\u7684\u4efb\u52a1: 1. \u5c06\u56fe\u7247\u9001\u5165freezed \u7684 f_{enc} \u7f51\u7edc\u8f93\u51famulti-scale feature maps 2. \u5bf9multi-scale feature maps\u9001\u5165\u4e00\u4e2a\u5c0f\u7684\u7f51\u7edc\u4e2d\uff0c\u8f93\u51faposition maps position maps\u7684groud truth\u7ed3\u679c\u4e3a\u9884\u5148\u5b9a\u4e49\u7684\uff0c\u4e0e\u56fe\u7247\u5185\u5bb9\u65e0\u5173\u7684\u6761\u7eb9\u56fe\uff0c\u8fd9\u4e9b\u6761\u7eb9\u56fe\u4e0a\u70b9\u7684\u50cf\u7d20\u503c\u4ec5\u4e0e\u5176\u4f4d\u7f6e\u76f8\u5173\u3002\u4f5c\u8005\u5728training \u4e0evalidation\u7684\u65f6\u5019\u4f7f\u7528\u5b8c\u5168\u4e0d\u540c\u5185\u5bb9\u7684\u56fe\u7247\uff0c\u7406\u8bba\u4e0a\u6765\u8bf4\uff0c\u7531\u4e8e\u4f4d\u7f6e\u4fe1\u606f\u4e0e\u8f93\u5165\u56fe\u7247\u5b8c\u5168\u6ca1\u6709\u76f8\u5173\u6027\uff0c\u56e0\u800c\u5982\u679cCNN\u80fd\u5b58\u50a8\u4f4d\u7f6e\u4fe1\u606f\uff0c\u5c31\u5927\u6982\u7387\u80fd\u5728test set\u4e0a\u590d\u73b0\u8fd9\u4e9b\u6761\u7eb9 \u5b9e\u9a8c\u7ed3\u679c\u4e0e\u4f5c\u8005\u9884\u8ba1\u76f8\u4f3c\uff0c\u53d1\u73b0\u7684\u60c5\u51b5\u662f\u6d45\u5c42\u7684posEnet\u65e0\u6cd5\u8fd8\u539f\u4f4d\u7f6e\u4fe1\u606f\uff0c\u800cVGG\u548cResnet\u6709\u76f8\u5f53\u7684\u5b58\u50a8\u4f4d\u7f6e\u4fe1\u606f\u7684\u80fd\u529b\uff0c\u5728test set\u4e0a\u4ecd\u7136\u53ef\u4ee5\u590d\u73b0\u4f4d\u7f6e\u6761\u7eb9\u56fe\u3002 Abelation Study \u63a5\u7740\u4f5c\u8005\u8fdb\u884c\u4e86\u51e0\u4e2a\u7b80\u5355\u7684\u5bf9\u6bd4\u5b9e\u9a8c\u3002\u5f97\u5230\u7684\u7ecf\u9a8c\u7ed3\u8bba\u662f:feature map\u8d8a\u6df1\uff0c\u4f4d\u7f6e\u4fe1\u606f\u8fd8\u539f\u8d8a\u597d;kernel_size\u8d8a\u5927\uff0c\u4f4d\u7f6e\u4fe1\u606f\u8fd8\u539f\u8d8a\u597d\u3002\u8fd9\u91cc\u4f5c\u8005\u70b9\u51fa\u8fd9\u4e24\u70b9\u6307\u5411\u540c\u4e00\u4e2a\u7ed3\u8bba\u5c31\u662f\u7edd\u5bf9\u4f4d\u7f6e\u7684\u611f\u77e5\u4e0e\u611f\u53d7\u91ce\u6b63\u76f8\u5173\u3002 \u4e0a\u56fe\u53f3\u4fa7\u8868\u683c\u4ee3\u8868\u4f5c\u8005\u7684\u53e6\u4e00\u4e2a\u5b9e\u9a8c\uff0c\u5728\u53bb\u9664VGG\u7684 padding\u5c42\u540e\uff0c\u4f1a\u53d1\u73b0\u5176\u5bf9\u7edd\u5bf9\u4f4d\u7f6e\u7684\u611f\u53d7\u80fd\u529b\u8fd1\u4e4e\u51cf\u534a\uff0c\u800c\u5bf9\u6d45\u5c42\u7f51\u7edc\u9644\u52a0padding\u7684\u7ed3\u679c\u53d1\u73b0\u7edd\u5bf9\u4f4d\u7f6e\u611f\u77e5\u80fd\u529b\u4e0epadding\u7684\u6570\u91cf\u6709\u5f88\u5f3a\u7684\u6b63\u76f8\u5173\u6027\u3002 \u4f5c\u8005\u8fdb\u800c\u70b9\u51fa\uff0c\u5f88\u6709\u53ef\u80fd\u662fzero-padding\u5728\u7f51\u7edc\u4e2d\u63d0\u4f9b\u4e86\u4e00\u4e2a\u56fe\u7247\u5185\u5bb9\u7684\u8fb9\u754c\u4fe1\u606f\uff0c\u7ecf\u8fc7CNN\u590d\u6742\u7684\u5904\u7406\u4ee5\u53ca\u591a\u5c42\u7684\u611f\u53d7\u91ce\u4f20\u9012\u540e\uff0c\u5728\u6df1\u5c42\u7684\u7f51\u7edc\u4e2d\u5b58\u50a8\u4e86\u56fe\u7247\u4e2d\u5404\u4e2a\u533a\u57df\u7684\u7edd\u5bf9\u4f4d\u7f6e\u4fe1\u606f\u3002 Pretrained on other tasks \u4f5c\u8005\u8fdb\u4e00\u6b65\u6307\u51fa\uff0c\u76f4\u89c9\u6765\u8bb2\uff0csalient object detection\u4e0esemantic segmentation\u4f1a\u6bd4\u5206\u7c7b\u95ee\u9898\u9700\u8981\u66f4\u591a\u7684\u4f4d\u7f6e\u4fe1\u606f\uff0c\u56e0\u800c\u5728\u8fd9\u4e24\u4e2a\u4efb\u52a1\u4e0apretrained\u7684\u7f51\u7edc\u4f1a\u63d0\u4f9b\u66f4\u591a\u7684\u4f4d\u7f6e\u4fe1\u606f\u3002 \u4e0a\u56fe\u5bf9\u6bd4\u6307\u51fa\uff0c\u5728\u5176\u4ed6\u4efb\u52a1\u4e0afine-tuned\u7684VGG backbone\u76f8\u6bd4\u4e8e\u5728imagenet\u4e0apretrained\u7684\u4f1a\u663e\u8457\u5730\u591a\u5b58\u50a8\u50cf\u7d20\u7684\u7edd\u5bf9\u5750\u6807\u4fe1\u606f\u3002","title":"How much Position Information Do Convolutional Neural Networks Encode?"},{"location":"The_theory/CNN_position_information/#how-much-position-information-do-convolutional-neural-networks-encode","text":"\u8fd9\u7bc7\u8bba\u6587\u8ba8\u8bba\u7684\u662f\u5173\u4e8eCNN\u5982\u4f55\u5b58\u50a8\u7edd\u5bf9\u4f4d\u7f6e\u4fe1\u606f\u7684\u3002\u8fd9\u7bc7\u6587\u7ae0\u6700\u7ec8\u7ed3\u8bba\u662fCNN\u901a\u8fc7zero-padding\u5f97\u5230\u8fb9\u754c\u4fe1\u606f\uff0c\u5e76\u4e14\u901a\u8fc7\u5927\u611f\u53d7\u91ce\u7684\u795e\u7ecf\u5143\u5c06\u7edd\u5bf9\u4f4d\u7f6e\u4fe1\u606f\u4f20\u9012\u3002\u672c\u6587\u66f4\u503c\u5f97\u4e00\u8bfb\u7684\u662f\u9762\u5bf9CNN\u65f6\u5176\u4e2d\u8fde\u8d2f\u7684\u903b\u8f91\u63a8\u7406\u601d\u8def\u4ee5\u53ca\u5b9e\u9a8c\u8bbe\u8ba1\u3002\u4f5c\u8005\u4f7f\u7528\u5b9e\u9a8c\u8fde\u7eed\u5730\u8bf4\u660e\u51e0\u4e2a\u95ee\u9898\uff0c\u9996\u5148\u662f\u4ecesegmentation\u5b9e\u9a8c\u4e2d\uff0cmotivated\u5f97\u77e5CNN\u4f3c\u4e4e\u786e\u5b9e\u5bf9\u7edd\u5bf9\u4f4d\u7f6e\u6709\u611f\u77e5\u80fd\u529b,\u5176\u6b21\u8bbe\u8ba1\u4e86\u4e00\u4e2arandom test\u8bf4\u660e\u76ee\u524d\u5e38\u89c1\u7684CNN\u786e\u5b9e\u6709\u7edd\u5bf9\u4f4d\u7f6e\u63a8\u7406\u80fd\u529b\uff0c\u518d\u63a5\u7740\u8bbe\u8ba1\u591a\u7ec4\u5bf9\u6bd4\u5b9e\u9a8c\u4ee5\u53caabelation study,\u53d1\u73b0\u4e86\u8d8a\u6df1\u7684feature map\u5bf9\u7edd\u5bf9\u4f4d\u7f6e\u611f\u77e5\u529b\u8d8a\u5f3a\uff0c\u540c\u65f6\u53d1\u73b0padding\u7684\u6709\u65e0\u5bf9\u6574\u4e2a\u7f51\u7edc\u7edd\u5bf9\u4f4d\u7f6e\u611f\u77e5\u80fd\u529b\u7684\u5de8\u5927\u5f71\u54cd\u3002","title":"How much Position Information Do Convolutional Neural Networks Encode?"},{"location":"The_theory/CNN_position_information/#motivation","text":"\u56fe\u4e2d\u53d1\u73b0\u7684\u662fsalient detection\u5bf9cropped\u7684\u56fe\u7247inference\u7ed3\u679c\u4e0e\u539f\u56fe\u6709\u5dee\u522b\uff0c\u5982\u679cCNN\u4ec5\u4f9d\u8d56\u50cf\u7d20\u7279\u5f81\u4e0d\u5e94\u6709\u5982\u6b64\u5927\u7684\u5dee\u522b\uff0c\u8fd9\u91cc\u63a8\u6d4b\u7269\u4f53\u4f4d\u7f6e\u4e5f\u4f1a\u5f71\u54cddetection\u7ed3\u679c\uff0c\u4e5f\u5c31\u662fCNN\u6709\u5b58\u50a8\u7a7a\u95f4\u4f4d\u7f6e\u7684\u80fd\u529b\u3002","title":"Motivation"},{"location":"The_theory/CNN_position_information/#random-test","text":"random test\u7684\u4efb\u52a1: 1. \u5c06\u56fe\u7247\u9001\u5165freezed \u7684 f_{enc} \u7f51\u7edc\u8f93\u51famulti-scale feature maps 2. \u5bf9multi-scale feature maps\u9001\u5165\u4e00\u4e2a\u5c0f\u7684\u7f51\u7edc\u4e2d\uff0c\u8f93\u51faposition maps position maps\u7684groud truth\u7ed3\u679c\u4e3a\u9884\u5148\u5b9a\u4e49\u7684\uff0c\u4e0e\u56fe\u7247\u5185\u5bb9\u65e0\u5173\u7684\u6761\u7eb9\u56fe\uff0c\u8fd9\u4e9b\u6761\u7eb9\u56fe\u4e0a\u70b9\u7684\u50cf\u7d20\u503c\u4ec5\u4e0e\u5176\u4f4d\u7f6e\u76f8\u5173\u3002\u4f5c\u8005\u5728training \u4e0evalidation\u7684\u65f6\u5019\u4f7f\u7528\u5b8c\u5168\u4e0d\u540c\u5185\u5bb9\u7684\u56fe\u7247\uff0c\u7406\u8bba\u4e0a\u6765\u8bf4\uff0c\u7531\u4e8e\u4f4d\u7f6e\u4fe1\u606f\u4e0e\u8f93\u5165\u56fe\u7247\u5b8c\u5168\u6ca1\u6709\u76f8\u5173\u6027\uff0c\u56e0\u800c\u5982\u679cCNN\u80fd\u5b58\u50a8\u4f4d\u7f6e\u4fe1\u606f\uff0c\u5c31\u5927\u6982\u7387\u80fd\u5728test set\u4e0a\u590d\u73b0\u8fd9\u4e9b\u6761\u7eb9 \u5b9e\u9a8c\u7ed3\u679c\u4e0e\u4f5c\u8005\u9884\u8ba1\u76f8\u4f3c\uff0c\u53d1\u73b0\u7684\u60c5\u51b5\u662f\u6d45\u5c42\u7684posEnet\u65e0\u6cd5\u8fd8\u539f\u4f4d\u7f6e\u4fe1\u606f\uff0c\u800cVGG\u548cResnet\u6709\u76f8\u5f53\u7684\u5b58\u50a8\u4f4d\u7f6e\u4fe1\u606f\u7684\u80fd\u529b\uff0c\u5728test set\u4e0a\u4ecd\u7136\u53ef\u4ee5\u590d\u73b0\u4f4d\u7f6e\u6761\u7eb9\u56fe\u3002","title":"Random Test"},{"location":"The_theory/CNN_position_information/#abelation-study","text":"\u63a5\u7740\u4f5c\u8005\u8fdb\u884c\u4e86\u51e0\u4e2a\u7b80\u5355\u7684\u5bf9\u6bd4\u5b9e\u9a8c\u3002\u5f97\u5230\u7684\u7ecf\u9a8c\u7ed3\u8bba\u662f:feature map\u8d8a\u6df1\uff0c\u4f4d\u7f6e\u4fe1\u606f\u8fd8\u539f\u8d8a\u597d;kernel_size\u8d8a\u5927\uff0c\u4f4d\u7f6e\u4fe1\u606f\u8fd8\u539f\u8d8a\u597d\u3002\u8fd9\u91cc\u4f5c\u8005\u70b9\u51fa\u8fd9\u4e24\u70b9\u6307\u5411\u540c\u4e00\u4e2a\u7ed3\u8bba\u5c31\u662f\u7edd\u5bf9\u4f4d\u7f6e\u7684\u611f\u77e5\u4e0e\u611f\u53d7\u91ce\u6b63\u76f8\u5173\u3002 \u4e0a\u56fe\u53f3\u4fa7\u8868\u683c\u4ee3\u8868\u4f5c\u8005\u7684\u53e6\u4e00\u4e2a\u5b9e\u9a8c\uff0c\u5728\u53bb\u9664VGG\u7684 padding\u5c42\u540e\uff0c\u4f1a\u53d1\u73b0\u5176\u5bf9\u7edd\u5bf9\u4f4d\u7f6e\u7684\u611f\u53d7\u80fd\u529b\u8fd1\u4e4e\u51cf\u534a\uff0c\u800c\u5bf9\u6d45\u5c42\u7f51\u7edc\u9644\u52a0padding\u7684\u7ed3\u679c\u53d1\u73b0\u7edd\u5bf9\u4f4d\u7f6e\u611f\u77e5\u80fd\u529b\u4e0epadding\u7684\u6570\u91cf\u6709\u5f88\u5f3a\u7684\u6b63\u76f8\u5173\u6027\u3002 \u4f5c\u8005\u8fdb\u800c\u70b9\u51fa\uff0c\u5f88\u6709\u53ef\u80fd\u662fzero-padding\u5728\u7f51\u7edc\u4e2d\u63d0\u4f9b\u4e86\u4e00\u4e2a\u56fe\u7247\u5185\u5bb9\u7684\u8fb9\u754c\u4fe1\u606f\uff0c\u7ecf\u8fc7CNN\u590d\u6742\u7684\u5904\u7406\u4ee5\u53ca\u591a\u5c42\u7684\u611f\u53d7\u91ce\u4f20\u9012\u540e\uff0c\u5728\u6df1\u5c42\u7684\u7f51\u7edc\u4e2d\u5b58\u50a8\u4e86\u56fe\u7247\u4e2d\u5404\u4e2a\u533a\u57df\u7684\u7edd\u5bf9\u4f4d\u7f6e\u4fe1\u606f\u3002","title":"Abelation Study"},{"location":"The_theory/CNN_position_information/#pretrained-on-other-tasks","text":"\u4f5c\u8005\u8fdb\u4e00\u6b65\u6307\u51fa\uff0c\u76f4\u89c9\u6765\u8bb2\uff0csalient object detection\u4e0esemantic segmentation\u4f1a\u6bd4\u5206\u7c7b\u95ee\u9898\u9700\u8981\u66f4\u591a\u7684\u4f4d\u7f6e\u4fe1\u606f\uff0c\u56e0\u800c\u5728\u8fd9\u4e24\u4e2a\u4efb\u52a1\u4e0apretrained\u7684\u7f51\u7edc\u4f1a\u63d0\u4f9b\u66f4\u591a\u7684\u4f4d\u7f6e\u4fe1\u606f\u3002 \u4e0a\u56fe\u5bf9\u6bd4\u6307\u51fa\uff0c\u5728\u5176\u4ed6\u4efb\u52a1\u4e0afine-tuned\u7684VGG backbone\u76f8\u6bd4\u4e8e\u5728imagenet\u4e0apretrained\u7684\u4f1a\u663e\u8457\u5730\u591a\u5b58\u50a8\u50cf\u7d20\u7684\u7edd\u5bf9\u5750\u6807\u4fe1\u606f\u3002","title":"Pretrained on other tasks"},{"location":"The_theory/Channel_Pruning_for_Accelerating_Very_Deep_Neural_Networks/","text":"Channel Pruning for Accelerating Very Deep Neural Networks \u8fd9\u7bc7\u6587\u7ae0\u4ecb\u7ecd\u4e86\u4e00\u79cd\u5b9e\u73b0channel pruning\u7684\u7b97\u6cd5\u3002\u5176\u6838\u5fc3\u7b97\u6cd5\u4ee3\u7801\u5728\u8be5\u5e93\u7684./lib/net.py -> R3\u65b9\u6cd5\u4e2d\u3002 \u5bf9pretrained\u7684\u6a21\u578b\uff0c\u8981\u8fdb\u884c\u6a21\u578b\u7684\u4fee\u526a\uff0c\u672c\u6587\u63d0\u5230\u6709\u4e09\u79cd\u65b9\u6cd5\uff0c\u7b2c\u4e00\u79cd\u662fsparse connection, \u7b2c\u4e8c\u79cd\u662ftensor factorization,\u7b2c\u4e09\u79cd\u662fchannel pruning. sparse connection\u7531\u4e8e\u5f15\u5165\u4e86\u4e0d\u89c4\u5219\u7684\u6a21\u578b\u7ed3\u6784\uff0c\u4f1a\u5bfc\u81f4\u5728GPU\u4e0a\u7684\u6267\u884c\u6548\u7387\u4e0b\u964d(\u5c3d\u7ba1flops\u4e0b\u964d\u4e86)\u3002tensor factorization\u672c\u8d28\u4e0a\u662f\u5bf9\u6743\u91cd\u77e9\u9635\u7684\u5206\u89e3\uff0c\u5bf9\u4e8e\u73b0\u4ee3\u7684Res-Connect\u6548\u679c\u4e0d\u4f73\u3002channel pruning\u4e0d\u6539\u53d8\u7ed3\u6784\uff0c\u4e0d\u6539\u53d8\u5e76\u884c\u8fd0\u884c\u60c5\u51b5\uff0c\u4ec5\u4ec5\u6539\u53d8channel\u6570\u91cf\u3002\u4e09\u79cd\u65b9\u5f0f\u7684\u56fe\u793a\u5982\u4e0b\uff1a \u7b97\u6cd5\u4ecb\u7ecd \u8fd9\u4e2a\u7b97\u6cd5\u5206\u4e3a\u4e24\u6b65\u8fed\u4ee3\uff0c\u5206\u522b\u4e3achannel selection \u4ee5\u53ca reconstruction.\u7b2c\u4e00\u6b65\u627e\u5230\u6700\u6709\u4fe1\u606f\u91cf\u7684channel\uff0c\u4fee\u526a\u5197\u4f59\u7684channel\uff0c\u8fd9\u91cc\u4f7f\u7528\u7684\u662fLasso regression, \u7b2c\u4e8c\u6b65reconstruct with Linear least square. \u4ee4\u8f93\u5165\u7684feature map\u7684channel\u6570\u4e3a c , \u5377\u79ef\u6838 W \u7684\u6743\u91cd\u4e3a n\\times c \\times k_h \\times k_w ,\u5377\u79ef\u6838\u6bcf\u6b21\u5377\u79ef\u4f1a\u5728\u4e00\u4e2a\u50cf\u7d20\u70b9\u4e0a\u751f\u6210\u4e00\u4e2a N\\times n \u7684\u8f93\u51fa\u77e9\u9635 Y ,\u5176\u4e2d N \u4e3abatch_num\uff0c\u8fd9\u91cc\u6682\u65f6\u4e0d\u8003\u8651bias\u9879\u3002\u8981\u5c06 c \u4fee\u526a\u4e3a c' .\u540c\u65f6\u6700\u5c0f\u5316reconstruction error\uff0c\u8fd9\u4e2a\u4f18\u5316\u95ee\u9898\u662f \\begin{array}{c}{\\underset{\\boldsymbol{\\beta}, \\mathbf{W}}{\\arg \\min } \\frac{1}{2 N}\\left\\|\\mathbf{Y}-\\sum_{i=1}^{c} \\beta_{i} \\mathbf{X}_{\\mathbf{i}} \\mathbf{W}_{\\mathbf{i}}^{\\top}\\right\\|_{F}^{2}} \\\\ {\\text { subject to }\\|\\boldsymbol{\\beta}\\|_{0} \\leq c^{\\prime}}\\end{array} \u5176\u4e2d ||\\cdot||_F \u4e3a\u4e8c\u9636\u8303\u6570, X_i \u662f\u4e00\u4e2a N\\times k_h k_w \u7684\u77e9\u9635\u88c1\u526a\u81ea\u8f93\u5165 X , \\beta \u662f\u957f\u5ea6\u4e3a c \u7684\u77e2\u91cf\u53c2\u6570\u3002 \u6c42\u89e3\u8fd9\u4e2a\u95ee\u9898\u662fNP\u96be\u7684,\u8fd9\u91cc\u9996\u5148\u5c06\u95ee\u9898\u7528l1\u8303\u6570\u677e\u5f1b\u4e3a \\begin{array}{l}{\\underset{\\boldsymbol{\\beta}, \\mathbf{W}}{\\arg \\min } \\frac{1}{2 N}\\left\\|\\mathrm{Y}-\\sum_{i=1}^{c} \\beta_{i} \\mathrm{X}_{\\mathrm{i}} \\mathrm{W}_{\\mathrm{i}}^{\\top}\\right\\|_{F}^{2}+\\lambda\\|\\boldsymbol{\\beta}\\|_{1}} \\\\ {\\text { subject to }\\|\\boldsymbol{\\beta}\\|_{0} \\leq c^{\\prime}, \\forall i\\left\\|\\mathrm{W}_{\\mathrm{i}}\\right\\|_{F}=1}\\end{array} \u540c\u65f6\u9650\u5236 ||W_i||_F = 1 \u7136\u540e\u5728\u4ee5\u4e0b\u4e24\u4e2a\u6b65\u9aa4\u4e2d\u8fed\u4ee3 \\beta \u5b50\u95ee\u9898 \u9996\u5148\u9501\u5b9a W ,\u6c42\u89e3 \\beta \u4f5c\u4e3achannel selection\u95ee\u9898,\u8fd9\u53d8\u6210\u4e86\u96f6\u8303\u6570\u7684LASSO regression,\u4ee3\u7801\u4e2d\u53ef\u4ee5\u77e5\u9053\u4f5c\u8005\u662f\u4f7f\u7528sklearn\u7684Lasso regression\u51fd\u6570\u505a\u7684\u3002 W \u5b50\u95ee\u9898 \u9501\u5b9a \\beta ,\u95ee\u9898\u53d8\u4e3a argmin_{W'} ||Y - X'(W')^T||^2_F ,\u8fd9\u91cc\u7684 X' = [\\beta_1X_1, \\beta_2 X_2 ...] ( N\\times ck_hk_w ), W' \u5f62\u72b6\u4e3a n\\times c k_hk_w , W' = [W_1, W_2...] ,\u4e4b\u540e\u518d\u4ee4 \\beta_i \\leftarrow \\beta_i ||W_i||_F, W_i \\leftarrow W_i/||W_i||_F ,\u8fd9\u91cc\u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u7ebf\u6027\u56de\u5f52\u3002 \u4f18\u5316\u8fc7\u7a0b \u4ece\u5df2\u7ecf\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u4e2d\u521d\u59cb\u5316W, \\lambda=0, ||\\beta||_0 = c .\u9010\u6e10\u589e\u52a0 \\lambda ,\u5bf9\u4e8e\u6bcf\u4e00\u4e2a \\lambda \uff0c\u8fed\u4ee3\u4e24\u4e2a\u5b50\u95ee\u9898\u7684\u6c42\u89e3\u76f4\u5230 ||\\beta||_0 \u7a33\u5b9a,\u9010\u6e10\u589e\u52a0 \\lambda \u76f4\u5230\u6ee1\u8db3 ||\\beta||_0 \\leq c' .\u540e\u6765\u53c8\u53d1\u73b0\u8fd9\u6837\u592a\u6162\uff0c\u4e8e\u662f\u6267\u884c\u5b50\u95ee\u9898(1)\u591a\u6b21\uff0c\u76f4\u5230 \\beta \u6ee1\u8db3\uff0c\u7136\u540e\u4ec5\u6267\u884c\u4e00\u6b21\u5b50\u95ee\u9898(2) \u5168\u6a21\u578b\u4fee\u5efa \u5728\u4fee\u526a\u65f6\uff0c\u6bcf\u4e00\u4e2a\u5c42\u5355\u72ec\u5904\u7406,\u9700\u8981\u6ce8\u610f\u7684\u662f\u6700\u4f18\u5316\u95ee\u9898\u4e2d\u7684 Y \u9700\u8981\u4f7f\u7528\u7684\u662f\u539f\u6a21\u578b\u7684\u8f93\u51fa\u4f5c\u4e3a\u76ee\u6807 Y \uff0c\u8f93\u5165 X \u5219\u662f\u4fee\u526a\u540e\u7684\u6a21\u578b\u7684\uff0c\u8fd9\u6837\u53ef\u4ee5\u907f\u514d\u8bef\u5dee\u7684\u7d2f\u79ef\u3002 \u5904\u7406\u591a\u5206\u652f\u6a21\u578b \u8fd9\u91cc\u4e3b\u8981\u8ba8\u8bbaResNet. \u8fd9\u91cc\u4e00\u5171\u6709\u4e09\u4e2a\u5377\u79ef\u5c42\uff0c\u7531\u4e8eResNet\u9700\u8981\u4fdd\u6301\u4e0d\u540c\u5c42\u4e4b\u95f4channel\u6570\u7684\u7a33\u5b9a\uff0c\u6240\u4ee5\u53ea\u6709\u4e2d\u95f4\u7684bottlenect\u4e5f\u5c31\u662f c1 \u7684\u8f93\u5165\u5c42\u53ef\u4ee5\u5982\u524d\u6587\u4e00\u6837\u6b63\u5e38\u4fee\u526a\u3002 \u6700\u540e\u4e00\u5c42\u7684\u4fee\u526a \u8fd9\u91cc\u5c06\u4f18\u5316\u76ee\u6807\u4ece Y_2 \u6539\u4e3a Y_1 - Y_1'+Y_2 ,\u8fd9\u91cc Y_1' \u662f\u524d\u9762\u5c42\u4fee\u526a\u540e\u8f93\u51fa\u7684feature map, \u7b2c\u4e00\u5c42\u7684\u4fee\u526a \u589e\u52a0\u4e00\u4e2asampler\u5c42\uff0c\u6b63\u5e38\u51cf\u5c11 c_0 \u5377\u79ef\u5c42\u7684\u8f93\u5165channel\u6570\uff0c\u6ce8\u610f\u8fd9\u4e2asampler\u4e0d\u6539\u53d8short-connection\u8def\u5f84\u4e0a\u7684 Y_1","title":"Channel Pruning for Accelerating Very Deep Neural Networks"},{"location":"The_theory/Channel_Pruning_for_Accelerating_Very_Deep_Neural_Networks/#channel-pruning-for-accelerating-very-deep-neural-networks","text":"\u8fd9\u7bc7\u6587\u7ae0\u4ecb\u7ecd\u4e86\u4e00\u79cd\u5b9e\u73b0channel pruning\u7684\u7b97\u6cd5\u3002\u5176\u6838\u5fc3\u7b97\u6cd5\u4ee3\u7801\u5728\u8be5\u5e93\u7684./lib/net.py -> R3\u65b9\u6cd5\u4e2d\u3002 \u5bf9pretrained\u7684\u6a21\u578b\uff0c\u8981\u8fdb\u884c\u6a21\u578b\u7684\u4fee\u526a\uff0c\u672c\u6587\u63d0\u5230\u6709\u4e09\u79cd\u65b9\u6cd5\uff0c\u7b2c\u4e00\u79cd\u662fsparse connection, \u7b2c\u4e8c\u79cd\u662ftensor factorization,\u7b2c\u4e09\u79cd\u662fchannel pruning. sparse connection\u7531\u4e8e\u5f15\u5165\u4e86\u4e0d\u89c4\u5219\u7684\u6a21\u578b\u7ed3\u6784\uff0c\u4f1a\u5bfc\u81f4\u5728GPU\u4e0a\u7684\u6267\u884c\u6548\u7387\u4e0b\u964d(\u5c3d\u7ba1flops\u4e0b\u964d\u4e86)\u3002tensor factorization\u672c\u8d28\u4e0a\u662f\u5bf9\u6743\u91cd\u77e9\u9635\u7684\u5206\u89e3\uff0c\u5bf9\u4e8e\u73b0\u4ee3\u7684Res-Connect\u6548\u679c\u4e0d\u4f73\u3002channel pruning\u4e0d\u6539\u53d8\u7ed3\u6784\uff0c\u4e0d\u6539\u53d8\u5e76\u884c\u8fd0\u884c\u60c5\u51b5\uff0c\u4ec5\u4ec5\u6539\u53d8channel\u6570\u91cf\u3002\u4e09\u79cd\u65b9\u5f0f\u7684\u56fe\u793a\u5982\u4e0b\uff1a","title":"Channel Pruning for Accelerating Very Deep Neural Networks"},{"location":"The_theory/Channel_Pruning_for_Accelerating_Very_Deep_Neural_Networks/#_1","text":"\u8fd9\u4e2a\u7b97\u6cd5\u5206\u4e3a\u4e24\u6b65\u8fed\u4ee3\uff0c\u5206\u522b\u4e3achannel selection \u4ee5\u53ca reconstruction.\u7b2c\u4e00\u6b65\u627e\u5230\u6700\u6709\u4fe1\u606f\u91cf\u7684channel\uff0c\u4fee\u526a\u5197\u4f59\u7684channel\uff0c\u8fd9\u91cc\u4f7f\u7528\u7684\u662fLasso regression, \u7b2c\u4e8c\u6b65reconstruct with Linear least square. \u4ee4\u8f93\u5165\u7684feature map\u7684channel\u6570\u4e3a c , \u5377\u79ef\u6838 W \u7684\u6743\u91cd\u4e3a n\\times c \\times k_h \\times k_w ,\u5377\u79ef\u6838\u6bcf\u6b21\u5377\u79ef\u4f1a\u5728\u4e00\u4e2a\u50cf\u7d20\u70b9\u4e0a\u751f\u6210\u4e00\u4e2a N\\times n \u7684\u8f93\u51fa\u77e9\u9635 Y ,\u5176\u4e2d N \u4e3abatch_num\uff0c\u8fd9\u91cc\u6682\u65f6\u4e0d\u8003\u8651bias\u9879\u3002\u8981\u5c06 c \u4fee\u526a\u4e3a c' .\u540c\u65f6\u6700\u5c0f\u5316reconstruction error\uff0c\u8fd9\u4e2a\u4f18\u5316\u95ee\u9898\u662f \\begin{array}{c}{\\underset{\\boldsymbol{\\beta}, \\mathbf{W}}{\\arg \\min } \\frac{1}{2 N}\\left\\|\\mathbf{Y}-\\sum_{i=1}^{c} \\beta_{i} \\mathbf{X}_{\\mathbf{i}} \\mathbf{W}_{\\mathbf{i}}^{\\top}\\right\\|_{F}^{2}} \\\\ {\\text { subject to }\\|\\boldsymbol{\\beta}\\|_{0} \\leq c^{\\prime}}\\end{array} \u5176\u4e2d ||\\cdot||_F \u4e3a\u4e8c\u9636\u8303\u6570, X_i \u662f\u4e00\u4e2a N\\times k_h k_w \u7684\u77e9\u9635\u88c1\u526a\u81ea\u8f93\u5165 X , \\beta \u662f\u957f\u5ea6\u4e3a c \u7684\u77e2\u91cf\u53c2\u6570\u3002 \u6c42\u89e3\u8fd9\u4e2a\u95ee\u9898\u662fNP\u96be\u7684,\u8fd9\u91cc\u9996\u5148\u5c06\u95ee\u9898\u7528l1\u8303\u6570\u677e\u5f1b\u4e3a \\begin{array}{l}{\\underset{\\boldsymbol{\\beta}, \\mathbf{W}}{\\arg \\min } \\frac{1}{2 N}\\left\\|\\mathrm{Y}-\\sum_{i=1}^{c} \\beta_{i} \\mathrm{X}_{\\mathrm{i}} \\mathrm{W}_{\\mathrm{i}}^{\\top}\\right\\|_{F}^{2}+\\lambda\\|\\boldsymbol{\\beta}\\|_{1}} \\\\ {\\text { subject to }\\|\\boldsymbol{\\beta}\\|_{0} \\leq c^{\\prime}, \\forall i\\left\\|\\mathrm{W}_{\\mathrm{i}}\\right\\|_{F}=1}\\end{array} \u540c\u65f6\u9650\u5236 ||W_i||_F = 1 \u7136\u540e\u5728\u4ee5\u4e0b\u4e24\u4e2a\u6b65\u9aa4\u4e2d\u8fed\u4ee3","title":"\u7b97\u6cd5\u4ecb\u7ecd"},{"location":"The_theory/Channel_Pruning_for_Accelerating_Very_Deep_Neural_Networks/#beta","text":"\u9996\u5148\u9501\u5b9a W ,\u6c42\u89e3 \\beta \u4f5c\u4e3achannel selection\u95ee\u9898,\u8fd9\u53d8\u6210\u4e86\u96f6\u8303\u6570\u7684LASSO regression,\u4ee3\u7801\u4e2d\u53ef\u4ee5\u77e5\u9053\u4f5c\u8005\u662f\u4f7f\u7528sklearn\u7684Lasso regression\u51fd\u6570\u505a\u7684\u3002","title":"\\beta \u5b50\u95ee\u9898"},{"location":"The_theory/Channel_Pruning_for_Accelerating_Very_Deep_Neural_Networks/#w","text":"\u9501\u5b9a \\beta ,\u95ee\u9898\u53d8\u4e3a argmin_{W'} ||Y - X'(W')^T||^2_F ,\u8fd9\u91cc\u7684 X' = [\\beta_1X_1, \\beta_2 X_2 ...] ( N\\times ck_hk_w ), W' \u5f62\u72b6\u4e3a n\\times c k_hk_w , W' = [W_1, W_2...] ,\u4e4b\u540e\u518d\u4ee4 \\beta_i \\leftarrow \\beta_i ||W_i||_F, W_i \\leftarrow W_i/||W_i||_F ,\u8fd9\u91cc\u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u7ebf\u6027\u56de\u5f52\u3002","title":"W \u5b50\u95ee\u9898"},{"location":"The_theory/Channel_Pruning_for_Accelerating_Very_Deep_Neural_Networks/#_2","text":"\u4ece\u5df2\u7ecf\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u4e2d\u521d\u59cb\u5316W, \\lambda=0, ||\\beta||_0 = c .\u9010\u6e10\u589e\u52a0 \\lambda ,\u5bf9\u4e8e\u6bcf\u4e00\u4e2a \\lambda \uff0c\u8fed\u4ee3\u4e24\u4e2a\u5b50\u95ee\u9898\u7684\u6c42\u89e3\u76f4\u5230 ||\\beta||_0 \u7a33\u5b9a,\u9010\u6e10\u589e\u52a0 \\lambda \u76f4\u5230\u6ee1\u8db3 ||\\beta||_0 \\leq c' .\u540e\u6765\u53c8\u53d1\u73b0\u8fd9\u6837\u592a\u6162\uff0c\u4e8e\u662f\u6267\u884c\u5b50\u95ee\u9898(1)\u591a\u6b21\uff0c\u76f4\u5230 \\beta \u6ee1\u8db3\uff0c\u7136\u540e\u4ec5\u6267\u884c\u4e00\u6b21\u5b50\u95ee\u9898(2)","title":"\u4f18\u5316\u8fc7\u7a0b"},{"location":"The_theory/Channel_Pruning_for_Accelerating_Very_Deep_Neural_Networks/#_3","text":"\u5728\u4fee\u526a\u65f6\uff0c\u6bcf\u4e00\u4e2a\u5c42\u5355\u72ec\u5904\u7406,\u9700\u8981\u6ce8\u610f\u7684\u662f\u6700\u4f18\u5316\u95ee\u9898\u4e2d\u7684 Y \u9700\u8981\u4f7f\u7528\u7684\u662f\u539f\u6a21\u578b\u7684\u8f93\u51fa\u4f5c\u4e3a\u76ee\u6807 Y \uff0c\u8f93\u5165 X \u5219\u662f\u4fee\u526a\u540e\u7684\u6a21\u578b\u7684\uff0c\u8fd9\u6837\u53ef\u4ee5\u907f\u514d\u8bef\u5dee\u7684\u7d2f\u79ef\u3002","title":"\u5168\u6a21\u578b\u4fee\u5efa"},{"location":"The_theory/Channel_Pruning_for_Accelerating_Very_Deep_Neural_Networks/#_4","text":"\u8fd9\u91cc\u4e3b\u8981\u8ba8\u8bbaResNet. \u8fd9\u91cc\u4e00\u5171\u6709\u4e09\u4e2a\u5377\u79ef\u5c42\uff0c\u7531\u4e8eResNet\u9700\u8981\u4fdd\u6301\u4e0d\u540c\u5c42\u4e4b\u95f4channel\u6570\u7684\u7a33\u5b9a\uff0c\u6240\u4ee5\u53ea\u6709\u4e2d\u95f4\u7684bottlenect\u4e5f\u5c31\u662f c1 \u7684\u8f93\u5165\u5c42\u53ef\u4ee5\u5982\u524d\u6587\u4e00\u6837\u6b63\u5e38\u4fee\u526a\u3002","title":"\u5904\u7406\u591a\u5206\u652f\u6a21\u578b"},{"location":"The_theory/Channel_Pruning_for_Accelerating_Very_Deep_Neural_Networks/#_5","text":"\u8fd9\u91cc\u5c06\u4f18\u5316\u76ee\u6807\u4ece Y_2 \u6539\u4e3a Y_1 - Y_1'+Y_2 ,\u8fd9\u91cc Y_1' \u662f\u524d\u9762\u5c42\u4fee\u526a\u540e\u8f93\u51fa\u7684feature map,","title":"\u6700\u540e\u4e00\u5c42\u7684\u4fee\u526a"},{"location":"The_theory/Channel_Pruning_for_Accelerating_Very_Deep_Neural_Networks/#_6","text":"\u589e\u52a0\u4e00\u4e2asampler\u5c42\uff0c\u6b63\u5e38\u51cf\u5c11 c_0 \u5377\u79ef\u5c42\u7684\u8f93\u5165channel\u6570\uff0c\u6ce8\u610f\u8fd9\u4e2asampler\u4e0d\u6539\u53d8short-connection\u8def\u5f84\u4e0a\u7684 Y_1","title":"\u7b2c\u4e00\u5c42\u7684\u4fee\u526a"},{"location":"The_theory/CheckerBoardDeconv/","text":"Deconvolution and Checkerboard Artifacts \u8fd9\u7bc7paper\u7684\"pdf\u94fe\u63a5\"\u6307\u5411\u7684\u5c31\u662f\u8fd9\u7bc7paper\u7684\u5b98\u7f51\uff0c\u5f88\u5f3a\u7684\u53ef\u89c6\u5316\u6548\u679c\uff0c\u8ba8\u8bba\u7684\u95ee\u9898\u662fdeconvolution\u4ee5\u53ca\u5b83\u9020\u6210\u7684\u68cb\u76d8\u683c\u5b50\u6548\u5e94\u3002 \u5177\u4f53\u539f\u7406\u4e0e\u53ef\u89c6\u5316\u5728\u5b98\u65b9\u7684\u52a8\u56fe\u4e2d\u5f88\u6e05\u6670\u3002\u8fd9\u91cc\u7efc\u5408\u4e00\u4e0b\u672c\u6587\u7684\u7ed3\u8bba \u5728upsampling\u7684\u65f6\u5019\u7528deconv\u4f1a\u5f62\u6210\u68cb\u76d8\u683c\u5b50,\u5c24\u5176\u662fkernel_size\u4e0d\u80fd\u6574\u9664stride\u7684\u65f6\u5019(\u5e38\u89c1kernel_size=3, stride=2\u5c31\u662f\u5982\u6b64) \u591a\u5c42\u6df1\u5ea6\u7f51\u7edc\u5728\u7406\u8bba\u4e0a\u53ef\u4ee5\u5b66\u4e60\u6743\u91cd\u6d88\u9664\u8fd9\u4e2a\u68cb\u76d8\u6837\u5f0f\uff0c\u4f46\u662f\u8fd9\u4e2a\u5f88\u96be\uff0c\u81ea\u7136\u60c5\u51b5\u4e0b\u591a\u5c42\u7f51\u7edc\uff0c\u4e8c\u7ef4\u5377\u79ef\u53ea\u4f1a\u52a0\u5f3a\u8fd9\u4e2aartifact\u3002 \u4f7f\u7528resizing \u52a0\u4e0aconvolution\u80fd\u66f4\u597d\u7684\u6d88\u9664artifact deconv\u7684artifact\u4e5f\u4f1a\u8bf4\u660e\u4e8c\u7ef4Downsample\u7684\u65f6\u5019\uff0c\u5982\u679c\u4f7f\u7528convolution\u76f4\u63a5\u4e0b\u91c7\u6837\uff0c\u4e5f\u4f1a\u5728\u68af\u5ea6\u4e0a\u5f62\u6210artifact\uff0c\u4e5f\u5c31\u662f\u4f1a\u5f62\u6210\u566a\u97f3\uff0c\u6709\u4e9b\u50cf\u7d20\u5f97\u5230\u7684\u68af\u5ea6\u66f4\u591a\u6709\u7684\u4f1a\u5c11\u3002\u8fd9\u4f1a\u5f71\u54cdGAN\u7684\u8bad\u7ec3\u4ee5\u53ca\u4e00\u822c\u5377\u79ef\u7f51\u7edc\u7684\u8bad\u7ec3\u3002","title":"Deconvolution and Checkerboard Artifacts"},{"location":"The_theory/CheckerBoardDeconv/#deconvolution-and-checkerboard-artifacts","text":"\u8fd9\u7bc7paper\u7684\"pdf\u94fe\u63a5\"\u6307\u5411\u7684\u5c31\u662f\u8fd9\u7bc7paper\u7684\u5b98\u7f51\uff0c\u5f88\u5f3a\u7684\u53ef\u89c6\u5316\u6548\u679c\uff0c\u8ba8\u8bba\u7684\u95ee\u9898\u662fdeconvolution\u4ee5\u53ca\u5b83\u9020\u6210\u7684\u68cb\u76d8\u683c\u5b50\u6548\u5e94\u3002 \u5177\u4f53\u539f\u7406\u4e0e\u53ef\u89c6\u5316\u5728\u5b98\u65b9\u7684\u52a8\u56fe\u4e2d\u5f88\u6e05\u6670\u3002\u8fd9\u91cc\u7efc\u5408\u4e00\u4e0b\u672c\u6587\u7684\u7ed3\u8bba \u5728upsampling\u7684\u65f6\u5019\u7528deconv\u4f1a\u5f62\u6210\u68cb\u76d8\u683c\u5b50,\u5c24\u5176\u662fkernel_size\u4e0d\u80fd\u6574\u9664stride\u7684\u65f6\u5019(\u5e38\u89c1kernel_size=3, stride=2\u5c31\u662f\u5982\u6b64) \u591a\u5c42\u6df1\u5ea6\u7f51\u7edc\u5728\u7406\u8bba\u4e0a\u53ef\u4ee5\u5b66\u4e60\u6743\u91cd\u6d88\u9664\u8fd9\u4e2a\u68cb\u76d8\u6837\u5f0f\uff0c\u4f46\u662f\u8fd9\u4e2a\u5f88\u96be\uff0c\u81ea\u7136\u60c5\u51b5\u4e0b\u591a\u5c42\u7f51\u7edc\uff0c\u4e8c\u7ef4\u5377\u79ef\u53ea\u4f1a\u52a0\u5f3a\u8fd9\u4e2aartifact\u3002 \u4f7f\u7528resizing \u52a0\u4e0aconvolution\u80fd\u66f4\u597d\u7684\u6d88\u9664artifact deconv\u7684artifact\u4e5f\u4f1a\u8bf4\u660e\u4e8c\u7ef4Downsample\u7684\u65f6\u5019\uff0c\u5982\u679c\u4f7f\u7528convolution\u76f4\u63a5\u4e0b\u91c7\u6837\uff0c\u4e5f\u4f1a\u5728\u68af\u5ea6\u4e0a\u5f62\u6210artifact\uff0c\u4e5f\u5c31\u662f\u4f1a\u5f62\u6210\u566a\u97f3\uff0c\u6709\u4e9b\u50cf\u7d20\u5f97\u5230\u7684\u68af\u5ea6\u66f4\u591a\u6709\u7684\u4f1a\u5c11\u3002\u8fd9\u4f1a\u5f71\u54cdGAN\u7684\u8bad\u7ec3\u4ee5\u53ca\u4e00\u822c\u5377\u79ef\u7f51\u7edc\u7684\u8bad\u7ec3\u3002","title":"Deconvolution and Checkerboard Artifacts"},{"location":"The_theory/ClosingGap/","text":"Train longer, generalize better: closing the generalization gap in large batch training of neural networks \u8fd9\u7bc7paper\u4ece\u7406\u8bba\u4ee5\u53ca\u5b9e\u9a8c\u4e0a\u5bf9\u8bad\u7ec3\u8fc7\u7a0b\u4ee5\u53caGeneralization\u8fdb\u884c\u4e86\u5206\u6790\u3002\u7ed9\u51fa\u4e86\u4e00\u4e9b\u6709\u8da3\u7684\u7ed3\u8bba\u4ee5\u53ca\u6709\u8da3\u7684module\u3002 \u4ee5\u524d\u7684paper\u7684\u4e00\u4e9b\u7ed3\u8bba \u7528\u5927batch\u8bad\u7ec3\uff0cgeneralization error\u4f1a\u63d0\u5347 \u5373\u4f7f\u7f51\u7edc\u8bad\u7ec3\u5f88\u957f\u65f6\u95f4\uff0c\u8fd9\u4e2a\u635f\u5931\u4e5f\u4e0d\u4f1a\u53d8\u5316 \u597d\u7684generalization\u5bf9\u5e94\u5e73\u6ed1\u7684minima \u5c0fbatch\u80fd\u8ba9\u6743\u91cd\u66f4\u8fdc\u79bb\u521d\u59cb\u503c\u3002 \u5927batch\u4e2d\u6a21\u4eff\u5c0fbatch\u7684\u7edf\u8ba1\u6570\u636e \u8bad\u7ec3\u65f6\u957f \u4f5c\u8005\u5206\u6790\u8ba4\u4e3a\uff0c\u5728\u8bad\u7ec3\u7684\u521d\u671f\uff0c\u5728\u7f51\u7edc\u4e0d\u53d1\u6563\u7684\u60c5\u51b5\u4e0b\uff0c\u7f51\u7edc\u7684random-walk\u4f1a\u6781\u6162\u5730\u8fdc\u79bb\u521d\u59cb\u503c\uff0c\u5f97\u5230\u66f4\u597d\u7684\u7ed3\u679c\u3002\u5efa\u8bae\u7684\u5b9e\u73b0\u65b9\u6cd5\u662f\u5c3d\u53ef\u80fd\u5927\u7684\u4e0d\u53d1\u6563\u7684\u5b66\u4e60\u7387\uff0c\u8db3\u591f\u5927\u7684\u5b66\u4e60\u6b65\u957f\u3002 \u5b66\u4e60\u7387\u5e94\u6b63\u6bd4\u4e8ebatchsize\u7684\u5e73\u65b9\u6839 \u8fd9\u6837\u7684\u539f\u7531\u662f\u5bf9\u5e94\u76f8\u540c\u7684\u53c2\u6570\u5347\u7ea7\u534f\u65b9\u5dee \\operatorname{cov}(\\Delta \\mathbf{w}, \\Delta \\mathbf{w}) \\approx \\frac{\\eta^{2}}{M}\\left(\\frac{1}{N} \\sum_{n=1}^{N} \\mathbf{g}_{n} \\mathbf{g}_{n}^{\\top}\\right) \u4f7f\u7528Ghost BatchNorm\u6a21\u4eff\u5c0fbatch\u65f6\u6570\u636e\u7684\u7edf\u8ba1\u7279\u6027\u3002 \u6839\u636eTensorflow Batchnorm\u7684 \u5b98\u65b9API\u6587\u6863 ,\u8bbe\u5b9a layer = tf . keras . layers . BatchNormalization ( * args , virtual_batch_size =< any_number > ) \u53ef\u4ee5\u8ba9batchnorm\u5bf9\u5927batch\u62c6\u5206\uff0c\u5206\u6210\u5927\u5c0f\u4e3a <any\\_number> \u7684\u5c0fbatch\u8fd0\u884cbatchnorm \u8bad\u7ec3loss\u8d8b\u4e8e\u5e73\u6ed1\u540e\u4e0d\u8981\u754f\u60e7overfitting\uff0c \u7ee7\u7eedtrain \u4f5c\u8005\u5b9e\u9a8c\u5224\u65ad\u7684\u8ba4\u4e3a\u662f\uff0c\u5927batch\u6027\u80fd\u5dee\u7684\u4e3b\u8981\u539f\u56e0\u662fupdate\u7684\u6b21\u6570\u4e0d\u591f\u591a(\u65c1\u767d:\u8fd9\u4e2a\u6709\u4e9b\u65f6\u5019\u5f88\u771f\u5b9e)\u3002","title":"Train longer, generalize better: closing the generalization gap in large batch training of neural networks"},{"location":"The_theory/ClosingGap/#train-longer-generalize-better-closing-the-generalization-gap-in-large-batch-training-of-neural-networks","text":"\u8fd9\u7bc7paper\u4ece\u7406\u8bba\u4ee5\u53ca\u5b9e\u9a8c\u4e0a\u5bf9\u8bad\u7ec3\u8fc7\u7a0b\u4ee5\u53caGeneralization\u8fdb\u884c\u4e86\u5206\u6790\u3002\u7ed9\u51fa\u4e86\u4e00\u4e9b\u6709\u8da3\u7684\u7ed3\u8bba\u4ee5\u53ca\u6709\u8da3\u7684module\u3002","title":"Train longer, generalize better: closing the generalization gap in large batch training of neural networks"},{"location":"The_theory/ClosingGap/#paper","text":"\u7528\u5927batch\u8bad\u7ec3\uff0cgeneralization error\u4f1a\u63d0\u5347 \u5373\u4f7f\u7f51\u7edc\u8bad\u7ec3\u5f88\u957f\u65f6\u95f4\uff0c\u8fd9\u4e2a\u635f\u5931\u4e5f\u4e0d\u4f1a\u53d8\u5316 \u597d\u7684generalization\u5bf9\u5e94\u5e73\u6ed1\u7684minima \u5c0fbatch\u80fd\u8ba9\u6743\u91cd\u66f4\u8fdc\u79bb\u521d\u59cb\u503c\u3002","title":"\u4ee5\u524d\u7684paper\u7684\u4e00\u4e9b\u7ed3\u8bba"},{"location":"The_theory/ClosingGap/#batchbatch","text":"","title":"\u5927batch\u4e2d\u6a21\u4eff\u5c0fbatch\u7684\u7edf\u8ba1\u6570\u636e"},{"location":"The_theory/ClosingGap/#_1","text":"\u4f5c\u8005\u5206\u6790\u8ba4\u4e3a\uff0c\u5728\u8bad\u7ec3\u7684\u521d\u671f\uff0c\u5728\u7f51\u7edc\u4e0d\u53d1\u6563\u7684\u60c5\u51b5\u4e0b\uff0c\u7f51\u7edc\u7684random-walk\u4f1a\u6781\u6162\u5730\u8fdc\u79bb\u521d\u59cb\u503c\uff0c\u5f97\u5230\u66f4\u597d\u7684\u7ed3\u679c\u3002\u5efa\u8bae\u7684\u5b9e\u73b0\u65b9\u6cd5\u662f\u5c3d\u53ef\u80fd\u5927\u7684\u4e0d\u53d1\u6563\u7684\u5b66\u4e60\u7387\uff0c\u8db3\u591f\u5927\u7684\u5b66\u4e60\u6b65\u957f\u3002","title":"\u8bad\u7ec3\u65f6\u957f"},{"location":"The_theory/ClosingGap/#batchsize","text":"\u8fd9\u6837\u7684\u539f\u7531\u662f\u5bf9\u5e94\u76f8\u540c\u7684\u53c2\u6570\u5347\u7ea7\u534f\u65b9\u5dee \\operatorname{cov}(\\Delta \\mathbf{w}, \\Delta \\mathbf{w}) \\approx \\frac{\\eta^{2}}{M}\\left(\\frac{1}{N} \\sum_{n=1}^{N} \\mathbf{g}_{n} \\mathbf{g}_{n}^{\\top}\\right)","title":"\u5b66\u4e60\u7387\u5e94\u6b63\u6bd4\u4e8ebatchsize\u7684\u5e73\u65b9\u6839"},{"location":"The_theory/ClosingGap/#ghost-batchnormbatch","text":"\u6839\u636eTensorflow Batchnorm\u7684 \u5b98\u65b9API\u6587\u6863 ,\u8bbe\u5b9a layer = tf . keras . layers . BatchNormalization ( * args , virtual_batch_size =< any_number > ) \u53ef\u4ee5\u8ba9batchnorm\u5bf9\u5927batch\u62c6\u5206\uff0c\u5206\u6210\u5927\u5c0f\u4e3a <any\\_number> \u7684\u5c0fbatch\u8fd0\u884cbatchnorm","title":"\u4f7f\u7528Ghost BatchNorm\u6a21\u4eff\u5c0fbatch\u65f6\u6570\u636e\u7684\u7edf\u8ba1\u7279\u6027\u3002"},{"location":"The_theory/ClosingGap/#lossoverfitting-train","text":"\u4f5c\u8005\u5b9e\u9a8c\u5224\u65ad\u7684\u8ba4\u4e3a\u662f\uff0c\u5927batch\u6027\u80fd\u5dee\u7684\u4e3b\u8981\u539f\u56e0\u662fupdate\u7684\u6b21\u6570\u4e0d\u591f\u591a(\u65c1\u767d:\u8fd9\u4e2a\u6709\u4e9b\u65f6\u5019\u5f88\u771f\u5b9e)\u3002","title":"\u8bad\u7ec3loss\u8d8b\u4e8e\u5e73\u6ed1\u540e\u4e0d\u8981\u754f\u60e7overfitting\uff0c \u7ee7\u7eedtrain"},{"location":"The_theory/Designing_Network_Design_Spaces/","text":"Designing Network Design Spaces \u8fd9\u4e00\u7bc7\u662f\u4f55\u51ef\u660e\u7ec4\u8d85\u8d8aNAS\u8fdb\u884c\u601d\u8003\u7684\u4e00\u9879\u5de5\u4f5c\uff0c\u4e2d\u6587\u6e90\u6709\u76f8\u5f53\u591a\u7684\u4ecb\u7ecd\uff0c \u77e5\u4e4e , CSDN NAS for image classification\uff0c\u5305\u62ec\u6700\u8fd1\u7684 EfficientNet \uff0c\u6838\u5fc3\u601d\u8def\u662f\u901a\u8fc7\u641c\u7d22\u6216\u8005\u5b66\u4e60\uff0c\u5f97\u5230\u5355\u4e00\u4e00\u4e2abest model\uff0c\u6587\u7ae0\u8ba8\u8bba\u7684\u91cd\u70b9\u4e5f\u662f\u5728\u4e8e\u5982\u4f55\u7f29\u5c0f\u65e0\u7a77\u7684\u641c\u7d22\u7a7a\u95f4\u4ee5\u53ca\u5982\u4f55\u5b66\u4e60\u7684\u65b9\u6cd5\u3002 \u672c\u6587\u7684\u6838\u5fc3\u601d\u8def\u8d21\u732e\u5728\u4e8e\u5bf9\u641c\u7d22\u7a7a\u95f4\u8fdb\u884c\u5927\u5e45\u5ea6\u91c7\u6837\u3001\u7edf\u8ba1\u5206\u6790\uff0c\u518d\u8fdb\u884c\u526a\u679d\u5206\u6790\uff0c\u5f97\u5230\u4e00\u4e9b\u66f4\u9c81\u68d2\u7684\u5206\u6790\u7ed3\u8bba\uff0c\u6240\u4ee5\u79f0\u4e3a\"designing network design spaces\"\u3002 \u641c\u7d22\u7a7a\u95f4\u63a2\u7d22 \u4f5c\u8005\u7684\u601d\u8def\u662f\u642d\u5efa\u63a7\u5236\u6a21\u578b\u7684FLOPS\u5728400MFLOPS\u7ea7\u522b\uff0c\u5728\u5206\u6790\u67d0\u4e00\u4e2a\u641c\u7d22\u7a7a\u95f4\u7684\u65f6\u5019\uff0c\u5728\u5176\u4e2d\u91c7\u6837500\u4e2a\u6a21\u578b\uff0c\u5feb\u901f\u5728imagenet\u4e0a\u8bad\u7ec3(\u4f7f\u7528\u6700\u7b80\u5355\u7684\u8bbe\u5b9a\uff0c\u6bd4\u5982\u51cf\u5c11\u6570\u636e\u589e\u5f3a\uff0cepoch\u4ec5\u4e3a10) \u7edf\u8ba1\u5206\u6790\u8fd9\u4e9b\u6a21\u578b\u7684\u6027\u80fd\uff0c\u7528\u6765\u8bc4\u4f30\u8fd9\u4e2a\u8bbe\u8ba1\u7a7a\u95f4\u7684\u6027\u80fd\uff0c\u540c\u65f6\u6839\u636e\u8bbe\u5b9a\u7684\u4e00\u4e9b\u53d8\u91cf\u4e0e\u6027\u80fd\u7684\u76f8\u5173\u6027\u627e\u51fa\u4fee\u526a\u6216\u8005\u6539\u8fdb\u641c\u7d22\u7a7a\u95f4\u7684\u65b9\u5411\u3002 \u4f5c\u8005\u4eceAnyNetXa\u9010\u6b65\u7f29\u5c0f\u7a7a\u95f4\u65e9AnyNetXe,\u6700\u540e\u5230RegNet\u7684\u641c\u7d22\u7a7a\u95f4\u3002\u8fd9\u4e2a\u8fc7\u7a0b\u4e2d\u6709\u4e00\u7cfb\u5217\u7684\u7ed3\u8bba \u7f51\u7edc\u6df1\u5ea6\u6700\u597d\u572820\u4e2ablock\uff0c\u4e5f\u5c31\u662f60\u5c42\u9644\u8fd1\uff0c bottleneck ratio\u5e94\u8be5\u53d61\uff0c\u4e5f\u5c31\u662f\u4e0d\u4f7f\u7528Bottleneck \u6bcf\u6b21\u4e0b\u91c7\u6837\uff0cchannel\u5bbd\u5ea6\u7684\u4e58\u79ef\u5e94\u5f53\u4e3a2.5\u5de6\u53f3\uff0c\u800c\u4e0d\u662f\u666e\u904d\u4f7f\u7528\u76842(\u4e5f\u76f8\u8fd1) \"activation\"\u4e5f\u5c31\u662f\u5377\u79ef\u5c42\u8f93\u51fatensor\u7684\u5927\u5c0f\u4e0e\u8fd0\u7b97\u65f6\u95f4\u7684\u76f8\u5173\u6027\u8d85\u8d8aFLOPS inverted bottleneck\u4ee5\u53ca depthwise_conv(\u6bcf\u4e00\u4e2achannel\u4e00\u7ec4\u5377\u79ef\u53c2\u6570)\u5bf9\u6027\u80fd\u662f\u6709\u635f\u5bb3\u7684\u3002 squeeze and excitation\u662f\u6709\u6548\u7684 \u6700\u540e\u5c06 EfficientNet \u7684\u70b9\u6570\u9524\u4e86\u4e00\u4e0b,\u4e14\u66f4\u52a0\u8f7b\u91cf.","title":"Designing Network Design Spaces"},{"location":"The_theory/Designing_Network_Design_Spaces/#designing-network-design-spaces","text":"\u8fd9\u4e00\u7bc7\u662f\u4f55\u51ef\u660e\u7ec4\u8d85\u8d8aNAS\u8fdb\u884c\u601d\u8003\u7684\u4e00\u9879\u5de5\u4f5c\uff0c\u4e2d\u6587\u6e90\u6709\u76f8\u5f53\u591a\u7684\u4ecb\u7ecd\uff0c \u77e5\u4e4e , CSDN NAS for image classification\uff0c\u5305\u62ec\u6700\u8fd1\u7684 EfficientNet \uff0c\u6838\u5fc3\u601d\u8def\u662f\u901a\u8fc7\u641c\u7d22\u6216\u8005\u5b66\u4e60\uff0c\u5f97\u5230\u5355\u4e00\u4e00\u4e2abest model\uff0c\u6587\u7ae0\u8ba8\u8bba\u7684\u91cd\u70b9\u4e5f\u662f\u5728\u4e8e\u5982\u4f55\u7f29\u5c0f\u65e0\u7a77\u7684\u641c\u7d22\u7a7a\u95f4\u4ee5\u53ca\u5982\u4f55\u5b66\u4e60\u7684\u65b9\u6cd5\u3002 \u672c\u6587\u7684\u6838\u5fc3\u601d\u8def\u8d21\u732e\u5728\u4e8e\u5bf9\u641c\u7d22\u7a7a\u95f4\u8fdb\u884c\u5927\u5e45\u5ea6\u91c7\u6837\u3001\u7edf\u8ba1\u5206\u6790\uff0c\u518d\u8fdb\u884c\u526a\u679d\u5206\u6790\uff0c\u5f97\u5230\u4e00\u4e9b\u66f4\u9c81\u68d2\u7684\u5206\u6790\u7ed3\u8bba\uff0c\u6240\u4ee5\u79f0\u4e3a\"designing network design spaces\"\u3002","title":"Designing Network Design Spaces"},{"location":"The_theory/Designing_Network_Design_Spaces/#_1","text":"\u4f5c\u8005\u7684\u601d\u8def\u662f\u642d\u5efa\u63a7\u5236\u6a21\u578b\u7684FLOPS\u5728400MFLOPS\u7ea7\u522b\uff0c\u5728\u5206\u6790\u67d0\u4e00\u4e2a\u641c\u7d22\u7a7a\u95f4\u7684\u65f6\u5019\uff0c\u5728\u5176\u4e2d\u91c7\u6837500\u4e2a\u6a21\u578b\uff0c\u5feb\u901f\u5728imagenet\u4e0a\u8bad\u7ec3(\u4f7f\u7528\u6700\u7b80\u5355\u7684\u8bbe\u5b9a\uff0c\u6bd4\u5982\u51cf\u5c11\u6570\u636e\u589e\u5f3a\uff0cepoch\u4ec5\u4e3a10) \u7edf\u8ba1\u5206\u6790\u8fd9\u4e9b\u6a21\u578b\u7684\u6027\u80fd\uff0c\u7528\u6765\u8bc4\u4f30\u8fd9\u4e2a\u8bbe\u8ba1\u7a7a\u95f4\u7684\u6027\u80fd\uff0c\u540c\u65f6\u6839\u636e\u8bbe\u5b9a\u7684\u4e00\u4e9b\u53d8\u91cf\u4e0e\u6027\u80fd\u7684\u76f8\u5173\u6027\u627e\u51fa\u4fee\u526a\u6216\u8005\u6539\u8fdb\u641c\u7d22\u7a7a\u95f4\u7684\u65b9\u5411\u3002 \u4f5c\u8005\u4eceAnyNetXa\u9010\u6b65\u7f29\u5c0f\u7a7a\u95f4\u65e9AnyNetXe,\u6700\u540e\u5230RegNet\u7684\u641c\u7d22\u7a7a\u95f4\u3002\u8fd9\u4e2a\u8fc7\u7a0b\u4e2d\u6709\u4e00\u7cfb\u5217\u7684\u7ed3\u8bba \u7f51\u7edc\u6df1\u5ea6\u6700\u597d\u572820\u4e2ablock\uff0c\u4e5f\u5c31\u662f60\u5c42\u9644\u8fd1\uff0c bottleneck ratio\u5e94\u8be5\u53d61\uff0c\u4e5f\u5c31\u662f\u4e0d\u4f7f\u7528Bottleneck \u6bcf\u6b21\u4e0b\u91c7\u6837\uff0cchannel\u5bbd\u5ea6\u7684\u4e58\u79ef\u5e94\u5f53\u4e3a2.5\u5de6\u53f3\uff0c\u800c\u4e0d\u662f\u666e\u904d\u4f7f\u7528\u76842(\u4e5f\u76f8\u8fd1) \"activation\"\u4e5f\u5c31\u662f\u5377\u79ef\u5c42\u8f93\u51fatensor\u7684\u5927\u5c0f\u4e0e\u8fd0\u7b97\u65f6\u95f4\u7684\u76f8\u5173\u6027\u8d85\u8d8aFLOPS inverted bottleneck\u4ee5\u53ca depthwise_conv(\u6bcf\u4e00\u4e2achannel\u4e00\u7ec4\u5377\u79ef\u53c2\u6570)\u5bf9\u6027\u80fd\u662f\u6709\u635f\u5bb3\u7684\u3002 squeeze and excitation\u662f\u6709\u6548\u7684 \u6700\u540e\u5c06 EfficientNet \u7684\u70b9\u6570\u9524\u4e86\u4e00\u4e0b,\u4e14\u66f4\u52a0\u8f7b\u91cf.","title":"\u641c\u7d22\u7a7a\u95f4\u63a2\u7d22"},{"location":"The_theory/Do Better ImageNet Models Transfer Better/","text":"Do Better ImageNet Models Transfer Better? \u8fd9\u7bc7\u8bba\u6587\u8ba4\u771f\u5730\u6d4b\u8bd5\u4e86\u4e0d\u540cImageNet Models\u7684transfer learning\u80fd\u529b\u3002\u521d\u6b65\u5b9e\u9a8c\u65b9\u5f0f\u662f\u572812\u4e2a\u4e0d\u540c\u79cd\u7c7b\u4e0d\u540csize\u7684\u8bad\u7ec3\u96c6\u4e2d\uff0c\u752816\u4e2apretrained \u7f51\u7edc\u5206\u522b\u8fdb\u884cfix-feature-extractor logistic regression\u3001fine-tuning\u3001re-train. \u90fd\u7528grid-search \u5bfb\u627e\u6700\u4f18\u5b66\u4e60\u7387\u7b49\u8d85\u53c2\u6570\u3002 metrics in comparison \u7ecf\u9a8c\u7ed3\u8bba\uff1a 1. ImageNet \u7684\u51c6\u786e\u7387\u80fd\u9884\u6d4blogistic regression\u7684\u51c6\u786e\u7387\uff0c\u4e24\u8005\u6709\u8f83\u5f3a\u7684\u6b63\u76f8\u5173\u6027\uff0c\u4f46\u662fregularization setting\u4f1a\u6709\u5f71\u54cd\u3002 Google\u4f7f\u7528\u76f8\u540c\u7684training setting\u65f6\uff0c\u7ed3\u8bba\u524d\u534a\u53e5\u6210\u7acb\uff0c\u5728imageNet\u8868\u73b0\u6700\u597d\u7684Inception-ResNet v2 and NASNet Large\u7a33\u5750\u524d\u4e24\u540d\u3002\u4f46\u662f\u4ece\u516c\u5f00\u80fd\u83b7\u5f97\u7684checkpoint\u4e2d\u5f00\u59cbtrain\u7684\u8bdd,ResNet\u548cDenseNet\u51e0\u4e4e\u603b\u662f\u6700\u597d\u7684\uff0c\u4e14transfer and basic accuracy\u7684\u76f8\u5173\u6027\u5f88\u5dee\uff0c\u8fdb\u4e00\u6b65\u7814\u7a76\u53d1\u73b0\u8fd9\u4e2a\u662f\u56e0\u4e3aregularization\u3002 \u627e\u5230\u56db\u4e2a\u635f\u5bb3Inception Net transfer accuracy\u7684\u64cd\u4f5c\uff0c\u5206\u522b\u662f \u5728batchnorm\u5c42\u4e0d\u4f7f\u7528scale parameter(\u4e0d\u5b66\u4e60\u65b9\u5dee) label smoothing(\u6e90\u81eainception-v3,\u5728\u8bad\u7ec3\u65f6\u6709\u4e00\u5b9a\u6982\u7387\u4e0d\u91c7\u53d6\u539flabel\uff0c\u800c\u5747\u5300\u968f\u673a\u9009\u62e9\u53e6\u4e00\u4e2aclass\u4f5c\u4e3aground truth) dropout \u989d\u5916\u7684\u5206\u7c7b\u8f93\u51fa(\u5728\u65e9\u671f\u5c42\u63d0\u524d\u8f93\u51fa\u7ed3\u679c) \u8fd9\u4e9b\u65b9\u6cd5\u5bf9top-1\u51c6\u786e\u7387\u63d0\u5347\u4e0d\u52301%\uff0c\u4f46\u662f\u5728transfer\u4e0a\u9020\u6210\u635f\u5bb3\uff0c\u5728\u76f8\u5bf9log\u6bd4\u4f8b\u4e0a\u6765\u8bf4\u76f8\u5f53\u4e8e\u628a\u6700\u597d\u7684backbone\u6362\u6210\u6700\u5f31\u7684backbone\uff0c\u8fd9\u4e2a\u4e0d\u4f46\u80fd\u5728transfer learning\u7684\u7ed3\u679c\u4e0a\u770b\u5230\u5dee\u522b\uff0c\u5728t-SNE\u7684\u53ef\u89c6\u5316\u7ed3\u679c\u4e2d\u4e5f\u53ef\u89c1\u5230\u3002 2. ImageNet\u51c6\u786e\u7387\u80fd\u9884\u6d4bfine-tunning\u7684\u8868\u73b0 regularizaion \u8fd8\u6709training setting\u7684\u6548\u679c\u5728fine-tuning\u7684\u7ed3\u679c\u4e0a\u5f71\u54cd\u4e0d\u5927(\u6709\u4e00\u5b9a\u635f\u4f24\uff0c\u6709\u4e9b\u8fd8\u6ca1\u6709\u635f\u4f24\uff0c\u6839\u636e\u56fe5\uff0c\u53ef\u4ee5\u8bf4\u662f\u6570\u636e\u4e0a\u4e0d\u663e\u8457)\u3002 \u4f46\u662f\u8fd9\u4e2a\u76f8\u5173\u6027\u5728\u4e0d\u540cdataset\u4e0a\u6709\u4e0d\u540c\uff0c\u5728\u5c0f\u7684\u6570\u636e\u96c6\u4e0a\u76f8\u5173\u6027\u6700\u660e\u663e 3. ImageNet\u51c6\u786e\u7387\u80fd\u9884\u6d4b\u968f\u673a\u521d\u59cb\u5316\u65f6\u7684\u8868\u73b0 \u8fd9\u4e2a\u76f8\u5173\u6027\u76f8\u5bf9\u5c0f\u4e00\u4e9b\uff0c\u800c\u4e14\u66f4\u7ec6\u81f4\u5730\u770b\uff0c\u6570\u636e\u96c6\u5927\u5c0f\u8f83\u5c0f\u65f6\u76f8\u5173\u6027\u4e0d\u663e\u8457\uff0c\u4f46\u662f\u5bf9\u4e8e\u5927\u6570\u636e\u96c6\uff0c\u76f8\u5173\u6027\u4f1a\u5f88\u663e\u8457\u3002 4. \u9009\u62e9\u66f4\u597d\u7684backbone\u6a21\u578b\u6027\u80fd\u63d0\u5347\u6bd4\u5f97\u4e0a\u4e3atransfer learning\u4e13\u95e8\u8bbe\u8ba1\u7684\u7279\u6b8a\u65b9\u6cd5 \u7ed3\u679c\u8868\u660epretrained model\u5bf9transfer\u7ed3\u679c\u5f88\u91cd\u8981\uff0c\u672c\u6587\u58f0\u79f0\u5728\u76ee\u524d\u4f7f\u7528\u7684dataset\u4e2d\uff0c\u5b83\u4eec\u901a\u8fc7\u66f4\u6362\u5e76fine-tuning backbone\u8d85\u8fc7\u4e86\u6587\u4e2d\u63d0\u5230\u7684N\u79cdtransfer learning\u7b97\u6cd5\u3002 \u672c\u6587\u6700\u540e\u8868\u793atransfer tricks\u4e0e\u66f4\u6362backbone\u5e76\u4e0d\u77db\u76fe\uff0c\u751a\u81f3\u53ef\u4ee5\u76f8\u4e92\u53e0\u52a0\uff0c\u4f46\u662f\u8fd9\u4e2a\u63d0\u5347\u5e45\u5ea6\u503c\u5f97\u5173\u6ce8 5. \u5bf9\u4e8e\u5206\u7c7b\u66f4\u7ec6\u81f4\u7684\u5982\u8f66\u5206\u7c7b\u4ee5\u53ca\u98de\u884c\u5668\u5206\u7c7b\uff0cImageNet Pretraining\u4e0e\u968f\u673a\u521d\u59cb\u5316\u76f8\u6bd4\u5dee\u8ddd\u4e0d\u5927 \u5176\u4f59\u5927\u90e8\u5206\u6570\u636e\u4e4b\u4e2d\uff0cfine_tune > pretrained > random\u662f\u663e\u8457\u5730 6. ImageNet\u52a0\u901f\u6536\u655b 7. \u5982\u4f55\u9009\u62e9\u662f\u5426pretrained \u7ed3\u8bba\uff1a \u6570\u636e\u6700\u5c11\u662flogistic regression\u53ef\u80fd\u662f\u6700\u597d\u7684(\u901f\u5ea6\u5feb\uff0c\u6027\u80fd\u597d)\uff0c\u5927\u4e00\u4e9b\u7684dataset,fine-tuning\u6700\u597d\uff0c\u66f4\u5927\u7684\u6570\u636e\u96c6\u4e2d\uff0c\u968f\u673a\u521d\u59cb\u5316\u7684\u6700\u7ec8\u6027\u80fd\u4f1a\u903c\u8fd1pretrained","title":"Do Better ImageNet Models Transfer Better?"},{"location":"The_theory/Do Better ImageNet Models Transfer Better/#do-better-imagenet-models-transfer-better","text":"\u8fd9\u7bc7\u8bba\u6587\u8ba4\u771f\u5730\u6d4b\u8bd5\u4e86\u4e0d\u540cImageNet Models\u7684transfer learning\u80fd\u529b\u3002\u521d\u6b65\u5b9e\u9a8c\u65b9\u5f0f\u662f\u572812\u4e2a\u4e0d\u540c\u79cd\u7c7b\u4e0d\u540csize\u7684\u8bad\u7ec3\u96c6\u4e2d\uff0c\u752816\u4e2apretrained \u7f51\u7edc\u5206\u522b\u8fdb\u884cfix-feature-extractor logistic regression\u3001fine-tuning\u3001re-train. \u90fd\u7528grid-search \u5bfb\u627e\u6700\u4f18\u5b66\u4e60\u7387\u7b49\u8d85\u53c2\u6570\u3002","title":"Do Better ImageNet Models Transfer Better?"},{"location":"The_theory/Do Better ImageNet Models Transfer Better/#metrics-in-comparison","text":"","title":"metrics in comparison"},{"location":"The_theory/Do Better ImageNet Models Transfer Better/#_1","text":"","title":"\u7ecf\u9a8c\u7ed3\u8bba\uff1a"},{"location":"The_theory/Do Better ImageNet Models Transfer Better/#1-imagenet-logistic-regressionregularization-setting","text":"Google\u4f7f\u7528\u76f8\u540c\u7684training setting\u65f6\uff0c\u7ed3\u8bba\u524d\u534a\u53e5\u6210\u7acb\uff0c\u5728imageNet\u8868\u73b0\u6700\u597d\u7684Inception-ResNet v2 and NASNet Large\u7a33\u5750\u524d\u4e24\u540d\u3002\u4f46\u662f\u4ece\u516c\u5f00\u80fd\u83b7\u5f97\u7684checkpoint\u4e2d\u5f00\u59cbtrain\u7684\u8bdd,ResNet\u548cDenseNet\u51e0\u4e4e\u603b\u662f\u6700\u597d\u7684\uff0c\u4e14transfer and basic accuracy\u7684\u76f8\u5173\u6027\u5f88\u5dee\uff0c\u8fdb\u4e00\u6b65\u7814\u7a76\u53d1\u73b0\u8fd9\u4e2a\u662f\u56e0\u4e3aregularization\u3002 \u627e\u5230\u56db\u4e2a\u635f\u5bb3Inception Net transfer accuracy\u7684\u64cd\u4f5c\uff0c\u5206\u522b\u662f \u5728batchnorm\u5c42\u4e0d\u4f7f\u7528scale parameter(\u4e0d\u5b66\u4e60\u65b9\u5dee) label smoothing(\u6e90\u81eainception-v3,\u5728\u8bad\u7ec3\u65f6\u6709\u4e00\u5b9a\u6982\u7387\u4e0d\u91c7\u53d6\u539flabel\uff0c\u800c\u5747\u5300\u968f\u673a\u9009\u62e9\u53e6\u4e00\u4e2aclass\u4f5c\u4e3aground truth) dropout \u989d\u5916\u7684\u5206\u7c7b\u8f93\u51fa(\u5728\u65e9\u671f\u5c42\u63d0\u524d\u8f93\u51fa\u7ed3\u679c) \u8fd9\u4e9b\u65b9\u6cd5\u5bf9top-1\u51c6\u786e\u7387\u63d0\u5347\u4e0d\u52301%\uff0c\u4f46\u662f\u5728transfer\u4e0a\u9020\u6210\u635f\u5bb3\uff0c\u5728\u76f8\u5bf9log\u6bd4\u4f8b\u4e0a\u6765\u8bf4\u76f8\u5f53\u4e8e\u628a\u6700\u597d\u7684backbone\u6362\u6210\u6700\u5f31\u7684backbone\uff0c\u8fd9\u4e2a\u4e0d\u4f46\u80fd\u5728transfer learning\u7684\u7ed3\u679c\u4e0a\u770b\u5230\u5dee\u522b\uff0c\u5728t-SNE\u7684\u53ef\u89c6\u5316\u7ed3\u679c\u4e2d\u4e5f\u53ef\u89c1\u5230\u3002","title":"1. ImageNet \u7684\u51c6\u786e\u7387\u80fd\u9884\u6d4blogistic regression\u7684\u51c6\u786e\u7387\uff0c\u4e24\u8005\u6709\u8f83\u5f3a\u7684\u6b63\u76f8\u5173\u6027\uff0c\u4f46\u662fregularization setting\u4f1a\u6709\u5f71\u54cd\u3002"},{"location":"The_theory/Do Better ImageNet Models Transfer Better/#2-imagenetfine-tunning","text":"regularizaion \u8fd8\u6709training setting\u7684\u6548\u679c\u5728fine-tuning\u7684\u7ed3\u679c\u4e0a\u5f71\u54cd\u4e0d\u5927(\u6709\u4e00\u5b9a\u635f\u4f24\uff0c\u6709\u4e9b\u8fd8\u6ca1\u6709\u635f\u4f24\uff0c\u6839\u636e\u56fe5\uff0c\u53ef\u4ee5\u8bf4\u662f\u6570\u636e\u4e0a\u4e0d\u663e\u8457)\u3002 \u4f46\u662f\u8fd9\u4e2a\u76f8\u5173\u6027\u5728\u4e0d\u540cdataset\u4e0a\u6709\u4e0d\u540c\uff0c\u5728\u5c0f\u7684\u6570\u636e\u96c6\u4e0a\u76f8\u5173\u6027\u6700\u660e\u663e","title":"2. ImageNet\u51c6\u786e\u7387\u80fd\u9884\u6d4bfine-tunning\u7684\u8868\u73b0"},{"location":"The_theory/Do Better ImageNet Models Transfer Better/#3-imagenet","text":"\u8fd9\u4e2a\u76f8\u5173\u6027\u76f8\u5bf9\u5c0f\u4e00\u4e9b\uff0c\u800c\u4e14\u66f4\u7ec6\u81f4\u5730\u770b\uff0c\u6570\u636e\u96c6\u5927\u5c0f\u8f83\u5c0f\u65f6\u76f8\u5173\u6027\u4e0d\u663e\u8457\uff0c\u4f46\u662f\u5bf9\u4e8e\u5927\u6570\u636e\u96c6\uff0c\u76f8\u5173\u6027\u4f1a\u5f88\u663e\u8457\u3002","title":"3. ImageNet\u51c6\u786e\u7387\u80fd\u9884\u6d4b\u968f\u673a\u521d\u59cb\u5316\u65f6\u7684\u8868\u73b0"},{"location":"The_theory/Do Better ImageNet Models Transfer Better/#4-backbonetransfer-learning","text":"\u7ed3\u679c\u8868\u660epretrained model\u5bf9transfer\u7ed3\u679c\u5f88\u91cd\u8981\uff0c\u672c\u6587\u58f0\u79f0\u5728\u76ee\u524d\u4f7f\u7528\u7684dataset\u4e2d\uff0c\u5b83\u4eec\u901a\u8fc7\u66f4\u6362\u5e76fine-tuning backbone\u8d85\u8fc7\u4e86\u6587\u4e2d\u63d0\u5230\u7684N\u79cdtransfer learning\u7b97\u6cd5\u3002 \u672c\u6587\u6700\u540e\u8868\u793atransfer tricks\u4e0e\u66f4\u6362backbone\u5e76\u4e0d\u77db\u76fe\uff0c\u751a\u81f3\u53ef\u4ee5\u76f8\u4e92\u53e0\u52a0\uff0c\u4f46\u662f\u8fd9\u4e2a\u63d0\u5347\u5e45\u5ea6\u503c\u5f97\u5173\u6ce8","title":"4. \u9009\u62e9\u66f4\u597d\u7684backbone\u6a21\u578b\u6027\u80fd\u63d0\u5347\u6bd4\u5f97\u4e0a\u4e3atransfer learning\u4e13\u95e8\u8bbe\u8ba1\u7684\u7279\u6b8a\u65b9\u6cd5"},{"location":"The_theory/Do Better ImageNet Models Transfer Better/#5-imagenet-pretraining","text":"\u5176\u4f59\u5927\u90e8\u5206\u6570\u636e\u4e4b\u4e2d\uff0cfine_tune > pretrained > random\u662f\u663e\u8457\u5730","title":"5. \u5bf9\u4e8e\u5206\u7c7b\u66f4\u7ec6\u81f4\u7684\u5982\u8f66\u5206\u7c7b\u4ee5\u53ca\u98de\u884c\u5668\u5206\u7c7b\uff0cImageNet Pretraining\u4e0e\u968f\u673a\u521d\u59cb\u5316\u76f8\u6bd4\u5dee\u8ddd\u4e0d\u5927"},{"location":"The_theory/Do Better ImageNet Models Transfer Better/#6-imagenet","text":"","title":"6. ImageNet\u52a0\u901f\u6536\u655b"},{"location":"The_theory/Do Better ImageNet Models Transfer Better/#7-pretrained","text":"\u7ed3\u8bba\uff1a \u6570\u636e\u6700\u5c11\u662flogistic regression\u53ef\u80fd\u662f\u6700\u597d\u7684(\u901f\u5ea6\u5feb\uff0c\u6027\u80fd\u597d)\uff0c\u5927\u4e00\u4e9b\u7684dataset,fine-tuning\u6700\u597d\uff0c\u66f4\u5927\u7684\u6570\u636e\u96c6\u4e2d\uff0c\u968f\u673a\u521d\u59cb\u5316\u7684\u6700\u7ec8\u6027\u80fd\u4f1a\u903c\u8fd1pretrained","title":"7. \u5982\u4f55\u9009\u62e9\u662f\u5426pretrained"},{"location":"The_theory/Framework_Uncertainty_Propagation/","text":"Uncertainty Propagation in Neural Network \u672c\u6587\u4e3b\u8981\u8ba8\u8bba\u4e0d\u786e\u5b9a\u6027\u5728\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u4f20\u64ad\u7684\u4e00\u4e2a\u65b9\u6cd5\u3002 \u5728Bayesian Neural Network\u4e2d\uff0c\u6709\u4e24\u4e2a\u6d41\u6d3e\uff0c\u7b2c\u4e00\u4e2a\u662f\u628a\u6bcf\u4e00\u4e2aweight\u5efa\u6a21\u4e3a\u4e00\u4e2a\u9ad8\u65af\u5206\u5e03\uff0c\u53e6\u4e00\u4e2a\u662f\u628a\u8f93\u5165\u4e0e\u6fc0\u6d3b\u5efa\u6a21\u4e3a\u6982\u7387\u5206\u5e03\uff0c\u800cweight\u53ea\u662f\u5e38\u6570\u3002 \u8fd9\u91cc\u5206\u4eab\u4e00\u7bc7\u5728Robotics\u4e2d\u5e94\u7528\u7b2c\u4e8c\u79cdBNN\u7684paper\uff0c\u5728\u8fd9\u4e4b\u524d\u5206\u4eab\u672c\u6587\u7684\u4e3b\u8981\u6570\u5b66\u524d\u7f6e\uff0c Lightweight Probabilistic Deep Networks pdf \u672c\u6587\u76f4\u63a5\u4ecb\u7ecdADF\uff0c\u5c06\u4e2d\u95f4\u6240\u6709\u7684\u6fc0\u6d3b\u5c42\u90fd\u7406\u89e3\u4e3a\u6982\u7387\u5206\u5e03. \u5bf9\u4e8e\u4e00\u4e2a\u6807\u51c6\u7684\u795e\u7ecf\u7f51\u7edc\u524d\u5411\u4f20\u9012\uff0c\u53ef\u4ee5\u7528\u6982\u7387\u89e3\u8bfb\uff0c\u5199\u4e3a: \\begin{aligned} p\\left(\\mathbf{z}^{(0: l)}\\right) &=p\\left(\\mathbf{z}^{(0)}\\right) \\prod_{i=1}^{l} p\\left(\\mathbf{z}^{(i)} | \\mathbf{z}^{(i-1)}\\right) \\\\ p\\left(\\mathbf{z}^{(i)} | \\mathbf{z}^{(i-1)}\\right) &=\\delta\\left[\\mathbf{z}^{(i)}-\\mathbf{f}^{(i)}\\left(\\mathbf{z}^{(i-1)}\\right)\\right] \\end{aligned} \u6211\u4eec\u5f00\u59cb\u5047\u8bbe\uff0c\u7f51\u7edc\u7684\u8f93\u5165\u5c42\u6709\u566a\u97f3\uff0c\u53ef\u4ee5\u7528element-wise\u7684\u9ad8\u65af\u5206\u5e03\u5efa\u6a21(\u6ce8\u610f\u8fd9\u91cc\u5c06\u8f93\u5165\u566a\u97f3\u8bbe\u5b9a\u4e3a\u5404\u4e2a\u5143\u7d20\u72ec\u7acb\u7684\u65e0\u5473\u7684\u8bef\u5dee, aleatoric uncertaint)\u3002 p\\left(\\mathbf{z}^{(0)}\\right)=\\prod_{j} \\mathcal{N}\\left(z_{j}^{(0)} | x_{j}, \\sigma_{n}^{2}\\right) \u9ad8\u65af\u5206\u5e03\u5728\u7f51\u7edc\u4f20\u64ad\u4e2d\uff0c\u5c24\u5176\u662f\u975e\u7ebf\u6027\u5c42\u4f20\u64ad\u540e\u663e\u7136\u4e0d\u518d\u662f\u9ad8\u65af\u5206\u5e03\u3002\u4f5c\u8005\u6307\u51fa\uff0c\u4e3a\u4e86\u66f4\u597d\u7684\u5efa\u6a21\u4f20\u64ad\u540e\u7684\u5747\u503c\u4e0e\u65b9\u5dee\uff0c\u8981\u6c42\u7528\u4e00\u4e2a\u4e0e\u5b9e\u9645\u5206\u5e03\u7684 KL divergence \u5c3d\u53ef\u80fd\u5c0f\u7684\u5206\u5e03\uff0c \u8fd9\u7bc7paper \u6307\u51fa\u8fd9\u7b49\u4ef7\u4e8e\u8ba9\u6982\u7387\u5206\u5e03\u7684\u77e9\u76f8\u7b49\uff0c\u5728\u9ad8\u65af\u5047\u8bbe\u4e0b\uff0c\u5c31\u662f\u5747\u503c\u4e0e\u65b9\u5dee\u76f8\u7b49(\u9ad8\u65af\u53ea\u6709\u4e24\u4e2a\u53c2\u6570\uff0c\u53ea\u80fd\u63a7\u5236\u524d\u4e24\u9636\u7684\u77e9)\u3002 \u5bf9\u4e8e\u5377\u79ef\u5c42\u4ee5\u53ca\u666e\u901a\u5168\u8fde\u63a5\u5c42\uff0c\u672c\u8d28\u4e0a\u6765\u8bf4\u5b83\u4eec\u90fd\u662f\u7ebf\u6027\u5c42\uff0c\u65b9\u5dee\u4e0e\u5747\u503c\u7684\u8ba1\u7b97\u662f\u89e3\u8026\u7684\u3002 \\mathbb{E}[\\mathbf{f}(\\mathbf{z})]=W \\boldsymbol{\\mu}_{z}+\\mathbf{b} \\mathbb{V}[\\mathbf{f}(\\mathbf{z})]=(W \\circ W) \\boldsymbol{v}_{z} \\circ \u6307element-wise\u76f8\u4e58\uff0c\u5728implementation\u65f6\uff0c\u53ef\u4ee5\u53d1\u73b0\u8fd0\u7b97\u89c4\u5219\u4e0e\u539f\u6765\u7684Forward\u662f\u4e00\u81f4\u7684\uff0c\u7528\u4e0d\u540c\u7684weight\u548cbias\u5c31\u53ef\u4ee5\u4e86\u3002 \u5bf9\u4e8eReLU, \u8fd9\u7bc7paper \u8bc1\u660e\u4e86: \\begin{aligned} \\mu_{\\text {relu }}(\\mu, v) &=\\mu \\cdot \\Phi\\left(\\frac{\\mu}{\\sigma}\\right)+\\sigma \\cdot \\phi\\left(\\frac{\\mu}{\\sigma}\\right) \\\\ v_{\\text {relu }}(\\mu, v) &=(\\mu+v) \\cdot \\Phi\\left(\\frac{\\mu}{\\sigma}\\right)+\\mu \\sigma \\cdot \\phi\\left(\\frac{\\mu}{\\sigma}\\right)-\\mu_{\\text {relu }}^{2}(\\mu, v) \\end{aligned} \u5176\u4e2d \\sigma = \\sqrt{v} \u4e14 \\Phi \u662f\u6807\u51c6\u6b63\u592a\u7684\u7d2f\u8ba1\u51fd\u6570, \\phi \u662f\u6807\u51c6\u6b63\u6001\u51fd\u6570\u5bc6\u5ea6\u51fd\u6570 \u5bf9\u4e8eMaxPooling, \u8fd9\u7bc7paper \u6307\u51fa,\u5bf9\u4e8e\u4e24\u4e2a\u9ad8\u65af\u51fd\u6570: \\begin{aligned} E[Y] &=\\mu_{X_{i}} \\Phi(\\alpha)+\\mu_{X_{j}} \\Phi(-\\alpha)+\\theta \\phi(\\alpha) \\\\ \\operatorname{Var}[Y] &=\\left(\\sigma_{X_{i}}^{2}+\\mu_{X_{i}}^{2}\\right) \\Phi(\\alpha)+\\left(\\sigma_{X_{j}}^{2}+\\mu_{X_{j}}^{2}\\right) \\Phi(-\\alpha)+\\left(\\mu_{X_{i}}+\\mu_{X_{j}}\\right) \\theta \\phi(\\alpha)-E[Y]^{2} \\end{aligned} \\alpha=\\frac{\\left(\\mu_{X_{i}}-\\mu_{X_{j}}\\right)}{\\theta}, \\theta=\\sqrt{\\sigma_{X_{i}}^{2}+\\sigma_{X_{j}}^{2}} \u8fed\u4ee3\u5c06\u6240\u6709\u9700\u8981\u5904\u7406\u7684\u5143\u7d20\u9010\u4e2aMax\u8fd0\u7b97\u3002\u987a\u5e8f\u662f\u6709\u76f8\u5173\u7684\uff0c\u4f46\u662f\u672c\u6587\u5efa\u8bae\u4e3a\u4e86\u63d0\u901f\u53ef\u4ee5\u5c3d\u53ef\u80fd\u5e76\u884c\uff0c\u5148\u6c34\u5e73\u518d\u7ad6\u76f4\u65b9\u5411\uff0c\u76f4\u63a5\u5206\u5f00\u8ba1\u7b97\u3002 A General Framework for Uncertainty Estimation in Deep Learning \u672c\u6587\u5728end-to-end learning\u4e0a\u7efc\u5408\u4e24\u79cdbayesian uncertainty,\u7b2c\u4e00\u4e2a\u662f\u7531\u8f93\u5165\u6570\u636e\u4e0d\u786e\u5b9a\u6027\u5411\u540e\u4f20\u64ad\u7684\u7ed3\u679c\u3002\u7b2c\u4e8c\u4e2a\u662f T \u6b21\u91c7\u6837Dropout,\u5f97\u5230 T \u4e2a\u4e0d\u540c\u7684\u7ed3\u679c\u5982\u56fe\u878d\u5408\u3002","title":"Uncertainty Propagation in Neural Network"},{"location":"The_theory/Framework_Uncertainty_Propagation/#uncertainty-propagation-in-neural-network","text":"\u672c\u6587\u4e3b\u8981\u8ba8\u8bba\u4e0d\u786e\u5b9a\u6027\u5728\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u4f20\u64ad\u7684\u4e00\u4e2a\u65b9\u6cd5\u3002 \u5728Bayesian Neural Network\u4e2d\uff0c\u6709\u4e24\u4e2a\u6d41\u6d3e\uff0c\u7b2c\u4e00\u4e2a\u662f\u628a\u6bcf\u4e00\u4e2aweight\u5efa\u6a21\u4e3a\u4e00\u4e2a\u9ad8\u65af\u5206\u5e03\uff0c\u53e6\u4e00\u4e2a\u662f\u628a\u8f93\u5165\u4e0e\u6fc0\u6d3b\u5efa\u6a21\u4e3a\u6982\u7387\u5206\u5e03\uff0c\u800cweight\u53ea\u662f\u5e38\u6570\u3002 \u8fd9\u91cc\u5206\u4eab\u4e00\u7bc7\u5728Robotics\u4e2d\u5e94\u7528\u7b2c\u4e8c\u79cdBNN\u7684paper\uff0c\u5728\u8fd9\u4e4b\u524d\u5206\u4eab\u672c\u6587\u7684\u4e3b\u8981\u6570\u5b66\u524d\u7f6e\uff0c","title":"Uncertainty Propagation in Neural Network"},{"location":"The_theory/Framework_Uncertainty_Propagation/#lightweight-probabilistic-deep-networks","text":"pdf \u672c\u6587\u76f4\u63a5\u4ecb\u7ecdADF\uff0c\u5c06\u4e2d\u95f4\u6240\u6709\u7684\u6fc0\u6d3b\u5c42\u90fd\u7406\u89e3\u4e3a\u6982\u7387\u5206\u5e03. \u5bf9\u4e8e\u4e00\u4e2a\u6807\u51c6\u7684\u795e\u7ecf\u7f51\u7edc\u524d\u5411\u4f20\u9012\uff0c\u53ef\u4ee5\u7528\u6982\u7387\u89e3\u8bfb\uff0c\u5199\u4e3a: \\begin{aligned} p\\left(\\mathbf{z}^{(0: l)}\\right) &=p\\left(\\mathbf{z}^{(0)}\\right) \\prod_{i=1}^{l} p\\left(\\mathbf{z}^{(i)} | \\mathbf{z}^{(i-1)}\\right) \\\\ p\\left(\\mathbf{z}^{(i)} | \\mathbf{z}^{(i-1)}\\right) &=\\delta\\left[\\mathbf{z}^{(i)}-\\mathbf{f}^{(i)}\\left(\\mathbf{z}^{(i-1)}\\right)\\right] \\end{aligned} \u6211\u4eec\u5f00\u59cb\u5047\u8bbe\uff0c\u7f51\u7edc\u7684\u8f93\u5165\u5c42\u6709\u566a\u97f3\uff0c\u53ef\u4ee5\u7528element-wise\u7684\u9ad8\u65af\u5206\u5e03\u5efa\u6a21(\u6ce8\u610f\u8fd9\u91cc\u5c06\u8f93\u5165\u566a\u97f3\u8bbe\u5b9a\u4e3a\u5404\u4e2a\u5143\u7d20\u72ec\u7acb\u7684\u65e0\u5473\u7684\u8bef\u5dee, aleatoric uncertaint)\u3002 p\\left(\\mathbf{z}^{(0)}\\right)=\\prod_{j} \\mathcal{N}\\left(z_{j}^{(0)} | x_{j}, \\sigma_{n}^{2}\\right) \u9ad8\u65af\u5206\u5e03\u5728\u7f51\u7edc\u4f20\u64ad\u4e2d\uff0c\u5c24\u5176\u662f\u975e\u7ebf\u6027\u5c42\u4f20\u64ad\u540e\u663e\u7136\u4e0d\u518d\u662f\u9ad8\u65af\u5206\u5e03\u3002\u4f5c\u8005\u6307\u51fa\uff0c\u4e3a\u4e86\u66f4\u597d\u7684\u5efa\u6a21\u4f20\u64ad\u540e\u7684\u5747\u503c\u4e0e\u65b9\u5dee\uff0c\u8981\u6c42\u7528\u4e00\u4e2a\u4e0e\u5b9e\u9645\u5206\u5e03\u7684 KL divergence \u5c3d\u53ef\u80fd\u5c0f\u7684\u5206\u5e03\uff0c \u8fd9\u7bc7paper \u6307\u51fa\u8fd9\u7b49\u4ef7\u4e8e\u8ba9\u6982\u7387\u5206\u5e03\u7684\u77e9\u76f8\u7b49\uff0c\u5728\u9ad8\u65af\u5047\u8bbe\u4e0b\uff0c\u5c31\u662f\u5747\u503c\u4e0e\u65b9\u5dee\u76f8\u7b49(\u9ad8\u65af\u53ea\u6709\u4e24\u4e2a\u53c2\u6570\uff0c\u53ea\u80fd\u63a7\u5236\u524d\u4e24\u9636\u7684\u77e9)\u3002 \u5bf9\u4e8e\u5377\u79ef\u5c42\u4ee5\u53ca\u666e\u901a\u5168\u8fde\u63a5\u5c42\uff0c\u672c\u8d28\u4e0a\u6765\u8bf4\u5b83\u4eec\u90fd\u662f\u7ebf\u6027\u5c42\uff0c\u65b9\u5dee\u4e0e\u5747\u503c\u7684\u8ba1\u7b97\u662f\u89e3\u8026\u7684\u3002 \\mathbb{E}[\\mathbf{f}(\\mathbf{z})]=W \\boldsymbol{\\mu}_{z}+\\mathbf{b} \\mathbb{V}[\\mathbf{f}(\\mathbf{z})]=(W \\circ W) \\boldsymbol{v}_{z} \\circ \u6307element-wise\u76f8\u4e58\uff0c\u5728implementation\u65f6\uff0c\u53ef\u4ee5\u53d1\u73b0\u8fd0\u7b97\u89c4\u5219\u4e0e\u539f\u6765\u7684Forward\u662f\u4e00\u81f4\u7684\uff0c\u7528\u4e0d\u540c\u7684weight\u548cbias\u5c31\u53ef\u4ee5\u4e86\u3002 \u5bf9\u4e8eReLU, \u8fd9\u7bc7paper \u8bc1\u660e\u4e86: \\begin{aligned} \\mu_{\\text {relu }}(\\mu, v) &=\\mu \\cdot \\Phi\\left(\\frac{\\mu}{\\sigma}\\right)+\\sigma \\cdot \\phi\\left(\\frac{\\mu}{\\sigma}\\right) \\\\ v_{\\text {relu }}(\\mu, v) &=(\\mu+v) \\cdot \\Phi\\left(\\frac{\\mu}{\\sigma}\\right)+\\mu \\sigma \\cdot \\phi\\left(\\frac{\\mu}{\\sigma}\\right)-\\mu_{\\text {relu }}^{2}(\\mu, v) \\end{aligned} \u5176\u4e2d \\sigma = \\sqrt{v} \u4e14 \\Phi \u662f\u6807\u51c6\u6b63\u592a\u7684\u7d2f\u8ba1\u51fd\u6570, \\phi \u662f\u6807\u51c6\u6b63\u6001\u51fd\u6570\u5bc6\u5ea6\u51fd\u6570 \u5bf9\u4e8eMaxPooling, \u8fd9\u7bc7paper \u6307\u51fa,\u5bf9\u4e8e\u4e24\u4e2a\u9ad8\u65af\u51fd\u6570: \\begin{aligned} E[Y] &=\\mu_{X_{i}} \\Phi(\\alpha)+\\mu_{X_{j}} \\Phi(-\\alpha)+\\theta \\phi(\\alpha) \\\\ \\operatorname{Var}[Y] &=\\left(\\sigma_{X_{i}}^{2}+\\mu_{X_{i}}^{2}\\right) \\Phi(\\alpha)+\\left(\\sigma_{X_{j}}^{2}+\\mu_{X_{j}}^{2}\\right) \\Phi(-\\alpha)+\\left(\\mu_{X_{i}}+\\mu_{X_{j}}\\right) \\theta \\phi(\\alpha)-E[Y]^{2} \\end{aligned} \\alpha=\\frac{\\left(\\mu_{X_{i}}-\\mu_{X_{j}}\\right)}{\\theta}, \\theta=\\sqrt{\\sigma_{X_{i}}^{2}+\\sigma_{X_{j}}^{2}} \u8fed\u4ee3\u5c06\u6240\u6709\u9700\u8981\u5904\u7406\u7684\u5143\u7d20\u9010\u4e2aMax\u8fd0\u7b97\u3002\u987a\u5e8f\u662f\u6709\u76f8\u5173\u7684\uff0c\u4f46\u662f\u672c\u6587\u5efa\u8bae\u4e3a\u4e86\u63d0\u901f\u53ef\u4ee5\u5c3d\u53ef\u80fd\u5e76\u884c\uff0c\u5148\u6c34\u5e73\u518d\u7ad6\u76f4\u65b9\u5411\uff0c\u76f4\u63a5\u5206\u5f00\u8ba1\u7b97\u3002","title":"Lightweight Probabilistic Deep Networks"},{"location":"The_theory/Framework_Uncertainty_Propagation/#a-general-framework-for-uncertainty-estimation-in-deep-learning","text":"\u672c\u6587\u5728end-to-end learning\u4e0a\u7efc\u5408\u4e24\u79cdbayesian uncertainty,\u7b2c\u4e00\u4e2a\u662f\u7531\u8f93\u5165\u6570\u636e\u4e0d\u786e\u5b9a\u6027\u5411\u540e\u4f20\u64ad\u7684\u7ed3\u679c\u3002\u7b2c\u4e8c\u4e2a\u662f T \u6b21\u91c7\u6837Dropout,\u5f97\u5230 T \u4e2a\u4e0d\u540c\u7684\u7ed3\u679c\u5982\u56fe\u878d\u5408\u3002","title":"A General Framework for Uncertainty Estimation in Deep Learning"},{"location":"The_theory/FreeAnchor_Learning_to_Match_Anchors_for_Visual_Object_Detection/","text":"FreeAnchor: Learning to Match Anchors for Visual Object Detection \u8fd9\u7bc7\u8bba\u6587\u6765\u81ea\u4e8eNIPS2019,\u4ecb\u7ecd\u4e86\u65b0\u7684\u65b9\u5f0f\u6765\u5b9e\u73b02D object detection\u4e2d\u7684matching. \u603b\u4f53\u601d\u8def\u6765\u8bf4\uff0c\u4f7f\u7528\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u7684\u6846\u67b6\u5728Object Detection\u7684\u8fc7\u7a0b\u4e2d\uff0c\u91c7\u7528\u4e00\u4e2a\u5355\u4e00\u7684loss\uff0c\u540c\u65f6\u5b8c\u6210proposal\u4e0eobject\u7684\u5339\u914d\u4ee5\u53ca\u56de\u5f52\u8bad\u7ec3\uff0c\u5c06\u4e2d\u95f4matching\u6b65\u9aa4\u81ea\u52a8\u5316\u4e86 \u6838\u5fc3\u7b97\u6cd5 \u7f51\u7edc\u6b63\u5e38\u524d\u4f20\u7ed9\u51fa\u4e00\u7cfb\u5217\u7684anchor box,\u6bcf\u4e00\u4e2aanchor box\u6709\u5206\u7c7b\u4ee5\u53calocalization\u4fe1\u606f \u5bf9\u6bcf\u4e00\u4e2a\u969c\u788d\u7269\uff0c\u9009\u62e9\u4e0e\u5b83IOU\u6700\u5927\u7684n\u4e2aanchor\uff0c\u5e26\u6709\u4e00\u4e2athreshold\uff0c\u5982\u679c\u4e00\u4e2aanchor\u4e0e\u591a\u4e2a\u7269\u4f53\u5339\u914d\uff0c \u5219\u4f7f\u8fd9\u4e2aanchor\u53ea\u4e0eIOU\u6700\u5927\u90a3\u4e2a\u7269\u4f53\u5339\u914d(\u662f\u5426\u6709\u8fd9\u4e2a\u9650\u5236\u9700\u8981\u770b\u5177\u4f53\u4ee3\u7801\u5b9e\u73b0) \u5bf9\u5f53\u524d\u7684\u5339\u914d\u5206\u914d\u8ba1\u7b97\u4e00\u4e2aLoss \u53cd\u4f20\u8bad\u7ec3 \u57fa\u4e8e\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u7684\u5339\u914dLoss \u5148\u7ed9\u51fa\u6700\u7ec8\u7684\u516c\u5f0f \\mathcal{L}^{\\prime}(\\theta)=-w_{1} \\sum_{i} \\log \\left(\\operatorname{Mean}-\\max \\left(X_{i}\\right)\\right)+w_{2} \\sum_{j} F L_{-}\\left(P\\left\\{a_{j} \\in A_{-}\\right\\}\\left(1-\\mathcal{P}(\\theta)_{j}^{b g}\\right)\\right) \u5176\u4e2d X_{i}=\\left\\{\\mathcal{P}(\\theta)_{i j}^{c l s} \\mathcal{P}(\\theta)_{i j}^{l o c} | a_{j} \\in A_{i}\\right\\} \u4ee3\u8868\u6bcf\u4e00\u4e2a\u7269\u4f53\u5bf9\u5e94\u7684anchor bag\u7684Likelihood \uff0c\u7b2c\u4e8c\u9879\u5219\u4ee3\u8868\u6ca1\u6709\u88ab\u9009\u5165anchor bag\u7684anchor\u4f5c\u4e3abackground\u7684Focal Loss\uff0cFocal Loss\u6e90\u81ea\u4e0e \u8fd9\u7bc7\u6587\u7ae0 ,\u76f4\u89c9\u5c31\u662f\u5bf9\u4e8e\u628a\u63e1\u5df2\u7ecf\u5f88\u5927\u7684\u6b63\u786e\u7684\u70b9\u964d\u4f4e\u6743\u91cd\uff0c \u5bf9\u96be\u5ea6\u8f83\u5927\u7684\u90e8\u5206\u589e\u52a0\u5b83\u4eec\u5728cost\u4e2d\u7684\u6743\u91cd\u3002 \u7b2c\u4e00\u9879\u3001Mean-max\u4ee5\u53ca\u6982\u7387\u5b9a\u4e49 Mean-max\u51fd\u6570\u8868\u8fbe\u5f0f\u4e3a: \\operatorname{Mean}-\\max (X)=\\frac{\\sum_{x_{j} \\in X} \\frac{x_{j}}{1-x_{j}}}{\\sum_{x_{j} \\in X} \\frac{1}{1-x_{j}}} \u5176\u5bf9\u5e94\u7684\u51fd\u6570\u56fe\u50cf\u4e3a \u76f4\u89c9\u6765\u8bf4\uff0c\u5c31\u662f\u5f53likelihood\u51fd\u6570\u503c\u8f83\u5c0f\uff0c\u7f51\u7edc\u521a\u521d\u59cb\u5316\u7684\u65f6\u5019\uff0c\u51fd\u6570\u7ed3\u679c\u8fd1\u4f3c\u4e8e\u5404\u4e2a\u6570\u7684\u5e73\u5747\u503c\uff0c \u5f53\u6709\u90e8\u5206likelihood\u51fd\u6570\u8f83\u5927\uff0c\u7f51\u7edc\u8bad\u7ec3\u6210\u719f\u4e4b\u540e\uff0c\u51fd\u6570\u7ed3\u679c\u8fd1\u4f3c\u4e8e\u5404\u4e2a\u6570\u7684max. \u6839\u636e\u4f5c\u8005\u7684\u8bbe\u8ba1 P(\\theta)^{cls}_{ij} = e^{-L(\\theta)^{cls}_{ij}} , Loc\u540c\u7406\uff0c\u7686\u4e3a\u5bf9\u5e94\u57fa\u7840cost\u51fd\u6570\u503c\u7684\u8d1f\u6307\u6570 Background\u9879\u5b9a\u4e49 P\\left\\{a_{j} \\in A_{-}\\right\\} = 1-\\max _{i} P\\left\\{a_{j} \\rightarrow b_{i}\\right\\} \u6307proposal\u6846 a_j \u4e0d\u4e0e\u6240\u6709\u7269\u4f53\u91cd\u5408\u7684\u6982\u7387 \u5176\u4e2d P\\left\\{a_{j} \\rightarrow b_{i}\\right\\}=\\text { Saturated linear }\\left(I o U_{i j}^{l o c}, t, \\max _{j}\\left(I o U_{i j}^{l o c}\\right)\\right) \\text { Saturated linear }\\left(x, t_{1}, t_{2}\\right)=\\left\\{\\begin{array}{ll}{0,} & {x \\leq t_{1}} \\\\ {\\frac{x-t_{1}}{t_{2}-t_{1}},} & {t_{1}<x<t_{2}} \\\\ {1,} & {x \\geq t_{2}}\\end{array}\\right.","title":"FreeAnchor: Learning to Match Anchors for Visual Object Detection"},{"location":"The_theory/FreeAnchor_Learning_to_Match_Anchors_for_Visual_Object_Detection/#freeanchor-learning-to-match-anchors-for-visual-object-detection","text":"\u8fd9\u7bc7\u8bba\u6587\u6765\u81ea\u4e8eNIPS2019,\u4ecb\u7ecd\u4e86\u65b0\u7684\u65b9\u5f0f\u6765\u5b9e\u73b02D object detection\u4e2d\u7684matching. \u603b\u4f53\u601d\u8def\u6765\u8bf4\uff0c\u4f7f\u7528\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u7684\u6846\u67b6\u5728Object Detection\u7684\u8fc7\u7a0b\u4e2d\uff0c\u91c7\u7528\u4e00\u4e2a\u5355\u4e00\u7684loss\uff0c\u540c\u65f6\u5b8c\u6210proposal\u4e0eobject\u7684\u5339\u914d\u4ee5\u53ca\u56de\u5f52\u8bad\u7ec3\uff0c\u5c06\u4e2d\u95f4matching\u6b65\u9aa4\u81ea\u52a8\u5316\u4e86","title":"FreeAnchor: Learning to Match Anchors for Visual Object Detection"},{"location":"The_theory/FreeAnchor_Learning_to_Match_Anchors_for_Visual_Object_Detection/#_1","text":"\u7f51\u7edc\u6b63\u5e38\u524d\u4f20\u7ed9\u51fa\u4e00\u7cfb\u5217\u7684anchor box,\u6bcf\u4e00\u4e2aanchor box\u6709\u5206\u7c7b\u4ee5\u53calocalization\u4fe1\u606f \u5bf9\u6bcf\u4e00\u4e2a\u969c\u788d\u7269\uff0c\u9009\u62e9\u4e0e\u5b83IOU\u6700\u5927\u7684n\u4e2aanchor\uff0c\u5e26\u6709\u4e00\u4e2athreshold\uff0c\u5982\u679c\u4e00\u4e2aanchor\u4e0e\u591a\u4e2a\u7269\u4f53\u5339\u914d\uff0c \u5219\u4f7f\u8fd9\u4e2aanchor\u53ea\u4e0eIOU\u6700\u5927\u90a3\u4e2a\u7269\u4f53\u5339\u914d(\u662f\u5426\u6709\u8fd9\u4e2a\u9650\u5236\u9700\u8981\u770b\u5177\u4f53\u4ee3\u7801\u5b9e\u73b0) \u5bf9\u5f53\u524d\u7684\u5339\u914d\u5206\u914d\u8ba1\u7b97\u4e00\u4e2aLoss \u53cd\u4f20\u8bad\u7ec3","title":"\u6838\u5fc3\u7b97\u6cd5"},{"location":"The_theory/FreeAnchor_Learning_to_Match_Anchors_for_Visual_Object_Detection/#loss","text":"\u5148\u7ed9\u51fa\u6700\u7ec8\u7684\u516c\u5f0f \\mathcal{L}^{\\prime}(\\theta)=-w_{1} \\sum_{i} \\log \\left(\\operatorname{Mean}-\\max \\left(X_{i}\\right)\\right)+w_{2} \\sum_{j} F L_{-}\\left(P\\left\\{a_{j} \\in A_{-}\\right\\}\\left(1-\\mathcal{P}(\\theta)_{j}^{b g}\\right)\\right) \u5176\u4e2d X_{i}=\\left\\{\\mathcal{P}(\\theta)_{i j}^{c l s} \\mathcal{P}(\\theta)_{i j}^{l o c} | a_{j} \\in A_{i}\\right\\} \u4ee3\u8868\u6bcf\u4e00\u4e2a\u7269\u4f53\u5bf9\u5e94\u7684anchor bag\u7684Likelihood \uff0c\u7b2c\u4e8c\u9879\u5219\u4ee3\u8868\u6ca1\u6709\u88ab\u9009\u5165anchor bag\u7684anchor\u4f5c\u4e3abackground\u7684Focal Loss\uff0cFocal Loss\u6e90\u81ea\u4e0e \u8fd9\u7bc7\u6587\u7ae0 ,\u76f4\u89c9\u5c31\u662f\u5bf9\u4e8e\u628a\u63e1\u5df2\u7ecf\u5f88\u5927\u7684\u6b63\u786e\u7684\u70b9\u964d\u4f4e\u6743\u91cd\uff0c \u5bf9\u96be\u5ea6\u8f83\u5927\u7684\u90e8\u5206\u589e\u52a0\u5b83\u4eec\u5728cost\u4e2d\u7684\u6743\u91cd\u3002","title":"\u57fa\u4e8e\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u7684\u5339\u914dLoss"},{"location":"The_theory/FreeAnchor_Learning_to_Match_Anchors_for_Visual_Object_Detection/#mean-max","text":"Mean-max\u51fd\u6570\u8868\u8fbe\u5f0f\u4e3a: \\operatorname{Mean}-\\max (X)=\\frac{\\sum_{x_{j} \\in X} \\frac{x_{j}}{1-x_{j}}}{\\sum_{x_{j} \\in X} \\frac{1}{1-x_{j}}} \u5176\u5bf9\u5e94\u7684\u51fd\u6570\u56fe\u50cf\u4e3a \u76f4\u89c9\u6765\u8bf4\uff0c\u5c31\u662f\u5f53likelihood\u51fd\u6570\u503c\u8f83\u5c0f\uff0c\u7f51\u7edc\u521a\u521d\u59cb\u5316\u7684\u65f6\u5019\uff0c\u51fd\u6570\u7ed3\u679c\u8fd1\u4f3c\u4e8e\u5404\u4e2a\u6570\u7684\u5e73\u5747\u503c\uff0c \u5f53\u6709\u90e8\u5206likelihood\u51fd\u6570\u8f83\u5927\uff0c\u7f51\u7edc\u8bad\u7ec3\u6210\u719f\u4e4b\u540e\uff0c\u51fd\u6570\u7ed3\u679c\u8fd1\u4f3c\u4e8e\u5404\u4e2a\u6570\u7684max. \u6839\u636e\u4f5c\u8005\u7684\u8bbe\u8ba1 P(\\theta)^{cls}_{ij} = e^{-L(\\theta)^{cls}_{ij}} , Loc\u540c\u7406\uff0c\u7686\u4e3a\u5bf9\u5e94\u57fa\u7840cost\u51fd\u6570\u503c\u7684\u8d1f\u6307\u6570","title":"\u7b2c\u4e00\u9879\u3001Mean-max\u4ee5\u53ca\u6982\u7387\u5b9a\u4e49"},{"location":"The_theory/FreeAnchor_Learning_to_Match_Anchors_for_Visual_Object_Detection/#background","text":"P\\left\\{a_{j} \\in A_{-}\\right\\} = 1-\\max _{i} P\\left\\{a_{j} \\rightarrow b_{i}\\right\\} \u6307proposal\u6846 a_j \u4e0d\u4e0e\u6240\u6709\u7269\u4f53\u91cd\u5408\u7684\u6982\u7387 \u5176\u4e2d P\\left\\{a_{j} \\rightarrow b_{i}\\right\\}=\\text { Saturated linear }\\left(I o U_{i j}^{l o c}, t, \\max _{j}\\left(I o U_{i j}^{l o c}\\right)\\right) \\text { Saturated linear }\\left(x, t_{1}, t_{2}\\right)=\\left\\{\\begin{array}{ll}{0,} & {x \\leq t_{1}} \\\\ {\\frac{x-t_{1}}{t_{2}-t_{1}},} & {t_{1}<x<t_{2}} \\\\ {1,} & {x \\geq t_{2}}\\end{array}\\right.","title":"Background\u9879\u5b9a\u4e49"},{"location":"The_theory/Localization-aware Channel Pruning for Object Detection/","text":"Localization-aware Channel Pruning for Object Detection \u8fd9\u7bc7\u8bba\u6587\u5c1d\u8bd5\u89e3\u51b3\u7684\u662f\u9488\u5bf92D\u7269\u4f53\u68c0\u6d4b\u7684 channel pruning \u95ee\u9898.localization-aware\u7684\u52a8\u673a\u8d77\u6e90\u4e8e DCP.pdf , \u539fchannel prunning\u7684\u95ee\u9898 \u7684\u505a\u6cd5\u662f\u9009\u62e9channel\u5e76\u7ebf\u6027\u91cd\u5efa\uff0c\u51cf\u5c11\u8f93\u51fa\u7684l2\u53d8\u5316\uff0c\u95ee\u9898\u5212\u5f52\u4e3alasso regression.\u4f46\u662fchannel\u4e2d\u6709\u5f88\u591a\u662f\u5197\u4f59\u7684\uff0c\u8f93\u51fa\u4e5f\u662f\u5197\u4f59\u7684\uff0c\u5b8c\u6574\u7684\u590d\u539f\u5e76\u4e0d\u4e00\u5b9a\u662f\u6700\u6709\u6548\u7684\uff0cDCP\u90a3\u7bc7\u5219\u662f\u57fa\u4e8e\u8fd9\u4e2a\u95ee\u9898\u5bf9\u5206\u7c7b\u95ee\u9898\u8fdb\u884c\u4f18\u5316\uff0c\u672c\u6587\u5219\u662f\u57fa\u4e8e\u8fd9\u4e2a\u95ee\u9898\uff0c\u5728object detection(\u4e3b\u8981\u57fa\u4e8eSSD\u7b97\u6cd5)\u4e2d\uff0c\u9488\u5bf9\u4f4d\u7f6e\u8f93\u51fa\u8fdb\u884c\u4f18\u5316\u3002\u8fc7\u7a0b\u4e2d\u63d0\u51fa\u4e86 contextual ROIAlign\u5c42. \u672c\u6587\u5efa\u8bae\u5728\u4f7f\u7528\u8fd9\u7bc7\u6587\u7ae0\u4e4b\u524d\u5148\u8865\u5145 DCP.pdf \u603b\u4f53pipeline Contextual ROIAlign Layer default bounding box\u4e0d\u4e00\u5b9a\u5305\u542b\u8db3\u591f\u7684\u8bed\u4e49\u4fe1\u606f\uff0c\u6240\u4ee5\u9700\u8981\u66f4\u5927\u7684\u6846\u6846. \\mathcal{F_O} = ROIAlign(\\mathcal{F_B}) + ROIAlign(\\mathcal{F_C}) \u5176\u4e2d A, B \u5206\u522b\u4e3aGroudTruth/Proposal box, C \u4e0e A, B \u7684\u5173\u7cfb\u5982\u56fe Channel Pruning Loss \u4f5c\u8005\u7684\u601d\u8def\u662f\u5f62\u6210\u4e00\u4e2a\u4e3a\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u7684loss\uff0c\u4ece\u800c\u53ef\u4ee5\u7528\u8fd9\u4e2a\u9644\u52a0\u7f51\u7edc\u7684\u68af\u5ea6\u8f85\u52a9\u6a21\u578b\u4fee\u526a\u3002 \u8fd9\u91cc\u7528 G \u6307\u4ee3 Generalized IoU \\begin{aligned} GIoU_{AB} &= IoU_{AB} - \\frac{C-U}{C} \\\\ U &= A + B - IoU_{AB} \\end{aligned} \u63a5\u7740\u5b9a\u4e49 E \u4e3a\u4ea4\u53c9\u71b5\uff0c \\mathcal{L_{ac}} \u4e3a\u9644\u52a0\u7f51\u7edc\u7684\u5206\u7c7b\u635f\u5931, \\mathcal{L_{ar}} \u4e3a\u9644\u52a0\u7f51\u8def\u7684\u5b9a\u4f4d\u635f\u5931\u3002 \\begin{aligned} \\mathcal{L}_{ac} &= \\sum_i E_i \\\\ \\mathcal{L}_{ar} &= \\sum_i m(1 - G_i) \\\\ \\mathcal{L_a} = \\mathcal{L}_{ac} + \\mathcal{L}_{ar} \\end{aligned} \u5176\u4e2d m \u4e3a\u6743\u91cd\u53c2\u6570\u3002 Localization-aware Channel Pruning \u603b\u4f53\u7b97\u6cd5\u6982\u8ff0 \u7b2c\u4e09\u884c \\mathcal{L_f} = \\mathcal{L_a} + \\mathcal{L_c} + \\mathcal{L_r} \u6307\u4ee3\u622a\u6b62\u5230\u73b0\u5728\u4fee\u526a\u540e\u7684loss\uff0c \u7b2c\u56db\u884c\u6307\u5bf9\u9644\u52a0\u7f51\u7edc\u548c\u4fee\u526a\u5230\u7b2ci\u5c42\u7684model\u8fdb\u884c\u8bad\u7ec3 \u7b2c\u4e94\u884c: \\begin{aligned} \\mathcal{L_{re}} &= \\frac{1}{2Q} ||F - X * W_C||^2_2 \\\\ \\mathcal{L}(W_C) &= \\mathcal{L}_{re}(W_C) + \\alpha\\mathcal{L_a}(W_C) \\\\ ||C||_0 &\\le K \\end{aligned} \\mathcal{L}_{re} \u4e3a\u91cd\u5efa\u8bef\u5dee \u7b2c\u516d\u884c\u6307\uff0c\u6c42\u51fa \\mathcal{L} \u5173\u4e8e\u5f53\u524d\u5c42W\u7684\u68af\u5ea6\u3002 S_k = \\sum^H_{i=1} \\sum^W_{j=1} ||\\frac{\\partial\\mathcal{L}}{\\partial W_{k,i,j}}||^2_2 \u6307\u4ee3\u7b2c k \u8f93\u51fachannel\u7684\u68af\u5ea6\u5747\u65b9\u548c\uff0c\u53ea\u4fdd\u7559\u68af\u5ea6\u6700\u5927\u7684\u51e0\u4e2achannel \u7b2c\u4e03\u884c\u6307 W_C = W_C - \\gamma\\frac{\\partial\\mathcal{L}}{\\partial W_C}","title":"Localization-aware Channel Pruning for Object Detection"},{"location":"The_theory/Localization-aware Channel Pruning for Object Detection/#localization-aware-channel-pruning-for-object-detection","text":"\u8fd9\u7bc7\u8bba\u6587\u5c1d\u8bd5\u89e3\u51b3\u7684\u662f\u9488\u5bf92D\u7269\u4f53\u68c0\u6d4b\u7684 channel pruning \u95ee\u9898.localization-aware\u7684\u52a8\u673a\u8d77\u6e90\u4e8e DCP.pdf , \u539fchannel prunning\u7684\u95ee\u9898 \u7684\u505a\u6cd5\u662f\u9009\u62e9channel\u5e76\u7ebf\u6027\u91cd\u5efa\uff0c\u51cf\u5c11\u8f93\u51fa\u7684l2\u53d8\u5316\uff0c\u95ee\u9898\u5212\u5f52\u4e3alasso regression.\u4f46\u662fchannel\u4e2d\u6709\u5f88\u591a\u662f\u5197\u4f59\u7684\uff0c\u8f93\u51fa\u4e5f\u662f\u5197\u4f59\u7684\uff0c\u5b8c\u6574\u7684\u590d\u539f\u5e76\u4e0d\u4e00\u5b9a\u662f\u6700\u6709\u6548\u7684\uff0cDCP\u90a3\u7bc7\u5219\u662f\u57fa\u4e8e\u8fd9\u4e2a\u95ee\u9898\u5bf9\u5206\u7c7b\u95ee\u9898\u8fdb\u884c\u4f18\u5316\uff0c\u672c\u6587\u5219\u662f\u57fa\u4e8e\u8fd9\u4e2a\u95ee\u9898\uff0c\u5728object detection(\u4e3b\u8981\u57fa\u4e8eSSD\u7b97\u6cd5)\u4e2d\uff0c\u9488\u5bf9\u4f4d\u7f6e\u8f93\u51fa\u8fdb\u884c\u4f18\u5316\u3002\u8fc7\u7a0b\u4e2d\u63d0\u51fa\u4e86 contextual ROIAlign\u5c42. \u672c\u6587\u5efa\u8bae\u5728\u4f7f\u7528\u8fd9\u7bc7\u6587\u7ae0\u4e4b\u524d\u5148\u8865\u5145 DCP.pdf","title":"Localization-aware Channel Pruning for Object Detection"},{"location":"The_theory/Localization-aware Channel Pruning for Object Detection/#pipeline","text":"","title":"\u603b\u4f53pipeline"},{"location":"The_theory/Localization-aware Channel Pruning for Object Detection/#contextual-roialign-layer","text":"default bounding box\u4e0d\u4e00\u5b9a\u5305\u542b\u8db3\u591f\u7684\u8bed\u4e49\u4fe1\u606f\uff0c\u6240\u4ee5\u9700\u8981\u66f4\u5927\u7684\u6846\u6846. \\mathcal{F_O} = ROIAlign(\\mathcal{F_B}) + ROIAlign(\\mathcal{F_C}) \u5176\u4e2d A, B \u5206\u522b\u4e3aGroudTruth/Proposal box, C \u4e0e A, B \u7684\u5173\u7cfb\u5982\u56fe","title":"Contextual ROIAlign Layer"},{"location":"The_theory/Localization-aware Channel Pruning for Object Detection/#channel-pruning-loss","text":"\u4f5c\u8005\u7684\u601d\u8def\u662f\u5f62\u6210\u4e00\u4e2a\u4e3a\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u7684loss\uff0c\u4ece\u800c\u53ef\u4ee5\u7528\u8fd9\u4e2a\u9644\u52a0\u7f51\u7edc\u7684\u68af\u5ea6\u8f85\u52a9\u6a21\u578b\u4fee\u526a\u3002 \u8fd9\u91cc\u7528 G \u6307\u4ee3 Generalized IoU \\begin{aligned} GIoU_{AB} &= IoU_{AB} - \\frac{C-U}{C} \\\\ U &= A + B - IoU_{AB} \\end{aligned} \u63a5\u7740\u5b9a\u4e49 E \u4e3a\u4ea4\u53c9\u71b5\uff0c \\mathcal{L_{ac}} \u4e3a\u9644\u52a0\u7f51\u7edc\u7684\u5206\u7c7b\u635f\u5931, \\mathcal{L_{ar}} \u4e3a\u9644\u52a0\u7f51\u8def\u7684\u5b9a\u4f4d\u635f\u5931\u3002 \\begin{aligned} \\mathcal{L}_{ac} &= \\sum_i E_i \\\\ \\mathcal{L}_{ar} &= \\sum_i m(1 - G_i) \\\\ \\mathcal{L_a} = \\mathcal{L}_{ac} + \\mathcal{L}_{ar} \\end{aligned} \u5176\u4e2d m \u4e3a\u6743\u91cd\u53c2\u6570\u3002","title":"Channel Pruning Loss"},{"location":"The_theory/Localization-aware Channel Pruning for Object Detection/#localization-aware-channel-pruning","text":"\u603b\u4f53\u7b97\u6cd5\u6982\u8ff0 \u7b2c\u4e09\u884c \\mathcal{L_f} = \\mathcal{L_a} + \\mathcal{L_c} + \\mathcal{L_r} \u6307\u4ee3\u622a\u6b62\u5230\u73b0\u5728\u4fee\u526a\u540e\u7684loss\uff0c \u7b2c\u56db\u884c\u6307\u5bf9\u9644\u52a0\u7f51\u7edc\u548c\u4fee\u526a\u5230\u7b2ci\u5c42\u7684model\u8fdb\u884c\u8bad\u7ec3 \u7b2c\u4e94\u884c: \\begin{aligned} \\mathcal{L_{re}} &= \\frac{1}{2Q} ||F - X * W_C||^2_2 \\\\ \\mathcal{L}(W_C) &= \\mathcal{L}_{re}(W_C) + \\alpha\\mathcal{L_a}(W_C) \\\\ ||C||_0 &\\le K \\end{aligned} \\mathcal{L}_{re} \u4e3a\u91cd\u5efa\u8bef\u5dee \u7b2c\u516d\u884c\u6307\uff0c\u6c42\u51fa \\mathcal{L} \u5173\u4e8e\u5f53\u524d\u5c42W\u7684\u68af\u5ea6\u3002 S_k = \\sum^H_{i=1} \\sum^W_{j=1} ||\\frac{\\partial\\mathcal{L}}{\\partial W_{k,i,j}}||^2_2 \u6307\u4ee3\u7b2c k \u8f93\u51fachannel\u7684\u68af\u5ea6\u5747\u65b9\u548c\uff0c\u53ea\u4fdd\u7559\u68af\u5ea6\u6700\u5927\u7684\u51e0\u4e2achannel \u7b2c\u4e03\u884c\u6307 W_C = W_C - \\gamma\\frac{\\partial\\mathcal{L}}{\\partial W_C}","title":"Localization-aware Channel Pruning"},{"location":"The_theory/Rethinking ImageNet Pre-training/","text":"Rethinking ImageNet Pre-training \u8fd9\u7bc7\u8bba\u6587\u6765\u81ea\u4f55\u51ef\u660e\u7684\u8bba\u6587\u8ba8\u8bba\u4e86pretraining\u5bf9detection task\u7684\u5f71\u54cd\uff0c\u5206\u6790\u4e86\u6570\u4e2a\u8981\u7d20 \u4e3b\u8981\u7ed3\u8bba pretrained\u52a0\u901f\u6536\u655b imagenet pretrained\u4e0d\u4e00\u5b9a\u63d0\u5347regularization\uff0c\u9664\u975e\u539f\u6765\u6570\u636e\u96c6\u91cf\u771f\u7684\u5f88\u5c0f \u5f53\u8bad\u7ec3\u4efb\u52a1\u5bf9\u4f4d\u7f6e\u4fe1\u606f\u975e\u5e38\u654f\u611f\u65f6\uff0c\u6bd4\u5982key-point\u68c0\u6d4b\uff0cimagenet pretrained\u7528\u5904\u4e0d\u5927 \u5176\u4ed6\u6280\u672f\u7ec6\u8282 Normalization\u5fc5\u4e0d\u53ef\u5c11\uff0c\u4f46\u662f\u7531\u4e8eDetection\u9ad8\u6e05\u56fe\u8981\u6c42\u9ad8\uff0c\u663e\u5b58\u4e0d\u591f\uff0c\u6240\u4ee5\u5982\u679c\u9700\u8981\u4ece\u5934\u5f00\u59cbtrain batch normalization\u4f1a\u56e0\u4e3abatch\u592a\u5c0f\u5f71\u54cd\u6548\u679c\uff0c\u6240\u4ee5\u5c1d\u8bd5GroupNorm\u7b49\u3002 \u5bf9\u4e8e\u6570\u636e\u91cf\u8db3\u591f\u5927\u7684detection task\u6765\u8bf4\uff0cpretrain\u53ef\u4ee5\u4f7f\u7ed3\u679c\u66f4\u5feb\u6536\u655b\uff0c\u4f46\u662frandom-initialization\u8db3\u591f\u957fepoch\u540e\u5f97\u5230\u7684\u7ed3\u679c\u4e00\u822c\u4e0d\u4f1a\u5dee\u4e8epretrain\uff0c\u5f53\u7136\u8981\u6c42\u6709GN \u4f7f\u7528\u521d\u59cb\u5b66\u4e60\u7387(\u8f83\u5927\u7684\u5b66\u4e60\u7387)\uff0c\u8bad\u7ec3\u66f4\u957f\u7684\u65f6\u95f4\u662f\u6709\u7528\u7684\uff0c\u957f\u65f6\u95f4\u4f7f\u7528\u4f4e\u5b66\u4e60\u7387\u63d0\u9ad8\u51c6\u786e\u7387\u7ecf\u5e38\u4f1a\u5bfc\u81f4overfitting","title":"Rethinking ImageNet Pre-training"},{"location":"The_theory/Rethinking ImageNet Pre-training/#rethinking-imagenet-pre-training","text":"\u8fd9\u7bc7\u8bba\u6587\u6765\u81ea\u4f55\u51ef\u660e\u7684\u8bba\u6587\u8ba8\u8bba\u4e86pretraining\u5bf9detection task\u7684\u5f71\u54cd\uff0c\u5206\u6790\u4e86\u6570\u4e2a\u8981\u7d20","title":"Rethinking ImageNet Pre-training"},{"location":"The_theory/Rethinking ImageNet Pre-training/#_1","text":"pretrained\u52a0\u901f\u6536\u655b imagenet pretrained\u4e0d\u4e00\u5b9a\u63d0\u5347regularization\uff0c\u9664\u975e\u539f\u6765\u6570\u636e\u96c6\u91cf\u771f\u7684\u5f88\u5c0f \u5f53\u8bad\u7ec3\u4efb\u52a1\u5bf9\u4f4d\u7f6e\u4fe1\u606f\u975e\u5e38\u654f\u611f\u65f6\uff0c\u6bd4\u5982key-point\u68c0\u6d4b\uff0cimagenet pretrained\u7528\u5904\u4e0d\u5927","title":"\u4e3b\u8981\u7ed3\u8bba"},{"location":"The_theory/Rethinking ImageNet Pre-training/#_2","text":"Normalization\u5fc5\u4e0d\u53ef\u5c11\uff0c\u4f46\u662f\u7531\u4e8eDetection\u9ad8\u6e05\u56fe\u8981\u6c42\u9ad8\uff0c\u663e\u5b58\u4e0d\u591f\uff0c\u6240\u4ee5\u5982\u679c\u9700\u8981\u4ece\u5934\u5f00\u59cbtrain batch normalization\u4f1a\u56e0\u4e3abatch\u592a\u5c0f\u5f71\u54cd\u6548\u679c\uff0c\u6240\u4ee5\u5c1d\u8bd5GroupNorm\u7b49\u3002 \u5bf9\u4e8e\u6570\u636e\u91cf\u8db3\u591f\u5927\u7684detection task\u6765\u8bf4\uff0cpretrain\u53ef\u4ee5\u4f7f\u7ed3\u679c\u66f4\u5feb\u6536\u655b\uff0c\u4f46\u662frandom-initialization\u8db3\u591f\u957fepoch\u540e\u5f97\u5230\u7684\u7ed3\u679c\u4e00\u822c\u4e0d\u4f1a\u5dee\u4e8epretrain\uff0c\u5f53\u7136\u8981\u6c42\u6709GN \u4f7f\u7528\u521d\u59cb\u5b66\u4e60\u7387(\u8f83\u5927\u7684\u5b66\u4e60\u7387)\uff0c\u8bad\u7ec3\u66f4\u957f\u7684\u65f6\u95f4\u662f\u6709\u7528\u7684\uff0c\u957f\u65f6\u95f4\u4f7f\u7528\u4f4e\u5b66\u4e60\u7387\u63d0\u9ad8\u51c6\u786e\u7387\u7ecf\u5e38\u4f1a\u5bfc\u81f4overfitting","title":"\u5176\u4ed6\u6280\u672f\u7ec6\u8282"},{"location":"The_theory/ShuffleNet_V2:_Practical_Guidelines_for_Efficient_CNN_Architecture_Design/","text":"ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design \u8fd9\u7bc7\u6587\u7ae0\u4e0d\u4ec5\u5f15\u8fdb\u4e86ShuffleNet V2,\u66f4\u91cd\u8981\u7684\u662f\u63d0\u4f9b\u4e86\u5927\u91cf\u4f18\u5316\u7f51\u7edc\u7ed3\u6784\u3001\u52a0\u901f\u8fd0\u7b97\u3001\u63d0\u5347\u6548\u7387\u7684\u7f51\u7edc\u642d\u5efa\u5efa\u8bae\u3002 \u4e3a\u4ec0\u4e48FLOPs\u6307\u6807\u8fd8\u4e0d\u5145\u5206 FLOPs\u6307\u7684\u662f\u7f51\u7edc\u8fd0\u7b97\u8fc7\u7a0b\u4e2d\u9700\u8981\u6267\u884c\u7684\u4e58\u52a0\u6b65\u9aa4\u6b21\u6570\u3002 \u4f17\u6240\u5468\u77e5\uff0c\u5927\u91cf\u7f51\u7edc\u5982MobileNet,\u91c7\u7528group convolution \u4e0e depth-wise convolution,\u4e0edense convolution\u7f51\u7edc\u76f8\u6bd4\uff0c\u51e0\u4f55\u7ea7\u5730\u964d\u4f4e\u4e86\u6bcf\u4e00\u5c42\u7684FLOPs.\u4f46\u662fFLOPs\u5e76\u4e0d\u662f\u4e00\u4e2a\u5bf9\u8fd0\u7b97\u901f\u5ea6\u4e0e\u8fd0\u7b97\u590d\u6742\u5ea6\u6700\u76f4\u63a5\u7684\u4f30\u91cf\u6307\u6807\uff0c\u5b83\u53ea\u662f\u4e00\u4e2a\u8fd1\u4f3c\u3002\u4e0d\u540c\u7684\u7f51\u7edc\uff0c\u5c3d\u7ba1\u6709\u76f8\u4f3c\u7684FLOPs\uff0c\u5176\u901f\u5ea6\u4e5f\u4f1a\u6709\u5f88\u5927\u4e0d\u540c\u3002 FLOPs\u4e0e\u5b9e\u9645\u5ef6\u8fdf\u4e4b\u95f4\u4e00\u5927\u5dee\u522b\u5728\u4e8e\u6ca1\u6709\u8003\u8651Memory access cost(MAC),\u7b2c\u4e8c\u5927\u533a\u522b\u5728\u4e8e\u5e73\u884c\u8fd0\u7b97\u5ea6(degree of parallelism).\u540c\u65f6\u76f8\u540c\u7684\u8fd0\u7b97\u7ed3\u679c\u4f1a\u56e0\u5e73\u53f0\u800c\u5f02\uff0c \u524d\u6587 \u63d0\u51fa\u7684\u901a\u8fc7matrix decomposition\u964d\u7ef4\u52a0\u901f\uff0c\u7406\u8bba\u4e0a\u6765\u8bf4\u80fd\u6709\u66f4\u4f4e\u7684FLOPs,\u4f46\u662f\u5728GPU\u4e0a\u7684\u6267\u884c\u901f\u5ea6\u5374\u66f4\u6162\uff0c\u539f\u56e0\u662f\u67d0\u4e00\u4e2a\u7248\u672c\u7684CUDNN\u4e3a 3\\times 3 \u5377\u79ef\u7279\u6b8a\u4f18\u5316\u8fc7\u3002 \u56e0\u6b64\u63d0\u51fa\u5efa\u8bae\u5e94\u8be5\u7528\u901f\u5ea6\u800c\u975eFLOPs\u8fdb\u884c\u8ba8\u8bba\uff0c\u5e76\u4e14\u9700\u8981\u8bf4\u660e\u5e73\u53f0\u3002 \u672c\u6587\u7684\u8d21\u732e\u5c31\u662f\u5148\u63d0\u51fa\u4e86\u8bbe\u8ba1\u9ad8\u6548\u7f51\u7edc\u7684\u4e00\u4e9b\u5efa\u8bae\uff0c\u5e76\u63d0\u51fashuffleNet V2 \u5b9e\u7528\u5efa\u8bae \u5efa\u8bae\u4e00,\u4f7f\u7528\u7b49channel\u5bbd\u5ea6\u4ee5\u51cf\u5c11MAC 1 \\times 1 \u5377\u79ef\u7684FLOPs\u4e3a B = hwc_1c_2 ,\u5047\u8bbe\u5185\u5b58\u8db3\u591f\u5927\uff0cMAC\u4e3a MAC=hw(c_1+c_2)+c_1c_2 \u8fdb\u4e00\u6b65\u63a8\u5f97 MAC \\ge 2\\sqrt{hwB} + \\frac{B}{hw} \u56e0\u6b64\u5bf9\u4e8e\u76f8\u7b49\u7684FLOPs\u4ee5\u53ca\u76f8\u540c\u7684feature map\u5927\u5c0f\uff0c\u8f93\u5165\u8f93\u51fachannel\u6570\u4e00\u81f4\u65f6\uff0cMAC\u6700\u5c0f\u3002\u5c3d\u7ba1\u8fd9\u53ea\u662f\u7406\u8bba\u503c\uff0c\u4f46\u662f\u5b9e\u9a8c\u53ef\u4ee5\u8bc1\u660e\u8fd9\u4e00\u70b9(\u672c\u6587\u5bf9\u4e0d\u540c\u7684 1\\times 1 \u5377\u79ef\u7684c1,c2\u914d\u6bd4\u8fdb\u884c\u4e86\u5b9e\u9a8c\u5bf9\u6bd4\uff0c\u8bc1\u660e\u4e86\u8fd9\u70b9)\u3002 \u5efa\u8bae\u4e8c\uff0c\u8fc7\u591a\u7684group convolution\u63d0\u5347\u4e86MAC \u7406\u8bba\u5206\u6790 \\begin{aligned} \\mathrm{MAC} &=h w\\left(c_{1}+c_{2}\\right)+\\frac{c_{1} c_{2}}{g} \\\\ &=h w c_{1}+\\frac{B g}{c_{1}}+\\frac{B}{h w} \\end{aligned} MAC\u4e0e g the number of groups \u6b63\u76f8\u5173\u3002 \u5728\u540c\u7b49FLOPs\u7684\u60c5\u51b5\u4e0b\uff0cgroup number\u8d8a\u5927\u901f\u5ea6\u8d8a\u6162\uff0c\u4f46\u662f\u503c\u5f97\u6ce8\u610f\u7684\u662f\u4e3a\u4e86\u4fdd\u8bc1\u540c\u7b49FLOPs,\u589e\u5927group number\u65f6channel\u6570\u4e5f\u4f1a\u63d0\u5347\u3002\u6548\u679c\u5728GPU\u4e0a\u6bd4\u8f83\u660e\u663e\u3002 \u5efa\u8bae\u4e09\uff0c\u7f51\u7edc\u7684\u788e\u7247\u5316\u964d\u4f4e\u4e86\u5e76\u884c\u5ea6 \u8fd9\u91cc\u6307\u7684\u662f\u4e00\u4e2ablock\u91cc\u9762\u5e76\u884c\u7684\u5377\u79ef\u4e0epooling\u5c42\uff0c\u8fd9\u4e9b\u5e73\u884c\u4f46\u4e0d\u5e76\u884c\u7684\u8fd0\u7b97\u4f1a\u591a\u6b21\u89e6\u53d1GPU\u7684\u542f\u52a8\u4e0e\u540c\u6b65\u3002\u788e\u7247\u5316\u8fd0\u884c\u5728GPU\u4e0a\u5f71\u54cd\u8f83\u5927\uff0c\u5728CPU\u4e0a\u5f71\u54cd\u4e0d\u5927 \u5efa\u8bae\u56db\uff0cReLU,\u5143\u7d20\u95f4\u76f8\u52a0\u7b49element-wise operators\u540c\u6837\u4e0d\u53ef\u5ffd\u7565 \u5220\u9664ResNet\u4e2d\u7684ReLU\u4e0eshortcut\u4f1a\u770b\u5230\u7ea620%\u7684\u52a0\u901f\uff0c\u5c3d\u7ba1\u5b83\u4eec\u5f88\u5fc5\u8981\uff0c\u4f46\u662f\u5374\u662f\u4e8b\u5b9e\u4e0a\u5f71\u54cd\u901f\u5ea6\u7684\u3002 ShuffleNet V2: \u57fa\u672c\u5355\u5143\u7ed3\u6784\u53ca\u5176\u4e0eShuffleNet V1\u7684\u6bd4\u8f83\u5982\u56fe \u76f4\u89c9\uff1a \u7528 1\\times 1 \u5377\u79ef\u66ff\u4ee3Group Convolution+ channel shuffle \u4f7f\u7528Concat + Channel Shuffle\u66ff\u4ee3Add downsampling\u65f6\u4e0d\u4f7f\u7528avg pooling Channel split\u5c31\u662f\u7b80\u5355\u5730torch.split(dim=1) \u8fde\u7eed\u51fa\u73b0\u7684Concat, Channel Shuffle, Channel Split\u53ef\u4ee5\u653e\u5728\u4e00\u8d77\u4f5c\u4e3a\u4e00\u4e2a\u7edf\u4e00\u7684element-wise operation\u3002","title":"ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design"},{"location":"The_theory/ShuffleNet_V2:_Practical_Guidelines_for_Efficient_CNN_Architecture_Design/#shufflenet-v2-practical-guidelines-for-efficient-cnn-architecture-design","text":"\u8fd9\u7bc7\u6587\u7ae0\u4e0d\u4ec5\u5f15\u8fdb\u4e86ShuffleNet V2,\u66f4\u91cd\u8981\u7684\u662f\u63d0\u4f9b\u4e86\u5927\u91cf\u4f18\u5316\u7f51\u7edc\u7ed3\u6784\u3001\u52a0\u901f\u8fd0\u7b97\u3001\u63d0\u5347\u6548\u7387\u7684\u7f51\u7edc\u642d\u5efa\u5efa\u8bae\u3002","title":"ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design"},{"location":"The_theory/ShuffleNet_V2:_Practical_Guidelines_for_Efficient_CNN_Architecture_Design/#flops","text":"FLOPs\u6307\u7684\u662f\u7f51\u7edc\u8fd0\u7b97\u8fc7\u7a0b\u4e2d\u9700\u8981\u6267\u884c\u7684\u4e58\u52a0\u6b65\u9aa4\u6b21\u6570\u3002 \u4f17\u6240\u5468\u77e5\uff0c\u5927\u91cf\u7f51\u7edc\u5982MobileNet,\u91c7\u7528group convolution \u4e0e depth-wise convolution,\u4e0edense convolution\u7f51\u7edc\u76f8\u6bd4\uff0c\u51e0\u4f55\u7ea7\u5730\u964d\u4f4e\u4e86\u6bcf\u4e00\u5c42\u7684FLOPs.\u4f46\u662fFLOPs\u5e76\u4e0d\u662f\u4e00\u4e2a\u5bf9\u8fd0\u7b97\u901f\u5ea6\u4e0e\u8fd0\u7b97\u590d\u6742\u5ea6\u6700\u76f4\u63a5\u7684\u4f30\u91cf\u6307\u6807\uff0c\u5b83\u53ea\u662f\u4e00\u4e2a\u8fd1\u4f3c\u3002\u4e0d\u540c\u7684\u7f51\u7edc\uff0c\u5c3d\u7ba1\u6709\u76f8\u4f3c\u7684FLOPs\uff0c\u5176\u901f\u5ea6\u4e5f\u4f1a\u6709\u5f88\u5927\u4e0d\u540c\u3002 FLOPs\u4e0e\u5b9e\u9645\u5ef6\u8fdf\u4e4b\u95f4\u4e00\u5927\u5dee\u522b\u5728\u4e8e\u6ca1\u6709\u8003\u8651Memory access cost(MAC),\u7b2c\u4e8c\u5927\u533a\u522b\u5728\u4e8e\u5e73\u884c\u8fd0\u7b97\u5ea6(degree of parallelism).\u540c\u65f6\u76f8\u540c\u7684\u8fd0\u7b97\u7ed3\u679c\u4f1a\u56e0\u5e73\u53f0\u800c\u5f02\uff0c \u524d\u6587 \u63d0\u51fa\u7684\u901a\u8fc7matrix decomposition\u964d\u7ef4\u52a0\u901f\uff0c\u7406\u8bba\u4e0a\u6765\u8bf4\u80fd\u6709\u66f4\u4f4e\u7684FLOPs,\u4f46\u662f\u5728GPU\u4e0a\u7684\u6267\u884c\u901f\u5ea6\u5374\u66f4\u6162\uff0c\u539f\u56e0\u662f\u67d0\u4e00\u4e2a\u7248\u672c\u7684CUDNN\u4e3a 3\\times 3 \u5377\u79ef\u7279\u6b8a\u4f18\u5316\u8fc7\u3002 \u56e0\u6b64\u63d0\u51fa\u5efa\u8bae\u5e94\u8be5\u7528\u901f\u5ea6\u800c\u975eFLOPs\u8fdb\u884c\u8ba8\u8bba\uff0c\u5e76\u4e14\u9700\u8981\u8bf4\u660e\u5e73\u53f0\u3002 \u672c\u6587\u7684\u8d21\u732e\u5c31\u662f\u5148\u63d0\u51fa\u4e86\u8bbe\u8ba1\u9ad8\u6548\u7f51\u7edc\u7684\u4e00\u4e9b\u5efa\u8bae\uff0c\u5e76\u63d0\u51fashuffleNet V2","title":"\u4e3a\u4ec0\u4e48FLOPs\u6307\u6807\u8fd8\u4e0d\u5145\u5206"},{"location":"The_theory/ShuffleNet_V2:_Practical_Guidelines_for_Efficient_CNN_Architecture_Design/#_1","text":"","title":"\u5b9e\u7528\u5efa\u8bae"},{"location":"The_theory/ShuffleNet_V2:_Practical_Guidelines_for_Efficient_CNN_Architecture_Design/#channelmac","text":"1 \\times 1 \u5377\u79ef\u7684FLOPs\u4e3a B = hwc_1c_2 ,\u5047\u8bbe\u5185\u5b58\u8db3\u591f\u5927\uff0cMAC\u4e3a MAC=hw(c_1+c_2)+c_1c_2 \u8fdb\u4e00\u6b65\u63a8\u5f97 MAC \\ge 2\\sqrt{hwB} + \\frac{B}{hw} \u56e0\u6b64\u5bf9\u4e8e\u76f8\u7b49\u7684FLOPs\u4ee5\u53ca\u76f8\u540c\u7684feature map\u5927\u5c0f\uff0c\u8f93\u5165\u8f93\u51fachannel\u6570\u4e00\u81f4\u65f6\uff0cMAC\u6700\u5c0f\u3002\u5c3d\u7ba1\u8fd9\u53ea\u662f\u7406\u8bba\u503c\uff0c\u4f46\u662f\u5b9e\u9a8c\u53ef\u4ee5\u8bc1\u660e\u8fd9\u4e00\u70b9(\u672c\u6587\u5bf9\u4e0d\u540c\u7684 1\\times 1 \u5377\u79ef\u7684c1,c2\u914d\u6bd4\u8fdb\u884c\u4e86\u5b9e\u9a8c\u5bf9\u6bd4\uff0c\u8bc1\u660e\u4e86\u8fd9\u70b9)\u3002","title":"\u5efa\u8bae\u4e00,\u4f7f\u7528\u7b49channel\u5bbd\u5ea6\u4ee5\u51cf\u5c11MAC"},{"location":"The_theory/ShuffleNet_V2:_Practical_Guidelines_for_Efficient_CNN_Architecture_Design/#group-convolutionmac","text":"\u7406\u8bba\u5206\u6790 \\begin{aligned} \\mathrm{MAC} &=h w\\left(c_{1}+c_{2}\\right)+\\frac{c_{1} c_{2}}{g} \\\\ &=h w c_{1}+\\frac{B g}{c_{1}}+\\frac{B}{h w} \\end{aligned} MAC\u4e0e g the number of groups \u6b63\u76f8\u5173\u3002 \u5728\u540c\u7b49FLOPs\u7684\u60c5\u51b5\u4e0b\uff0cgroup number\u8d8a\u5927\u901f\u5ea6\u8d8a\u6162\uff0c\u4f46\u662f\u503c\u5f97\u6ce8\u610f\u7684\u662f\u4e3a\u4e86\u4fdd\u8bc1\u540c\u7b49FLOPs,\u589e\u5927group number\u65f6channel\u6570\u4e5f\u4f1a\u63d0\u5347\u3002\u6548\u679c\u5728GPU\u4e0a\u6bd4\u8f83\u660e\u663e\u3002","title":"\u5efa\u8bae\u4e8c\uff0c\u8fc7\u591a\u7684group convolution\u63d0\u5347\u4e86MAC"},{"location":"The_theory/ShuffleNet_V2:_Practical_Guidelines_for_Efficient_CNN_Architecture_Design/#_2","text":"\u8fd9\u91cc\u6307\u7684\u662f\u4e00\u4e2ablock\u91cc\u9762\u5e76\u884c\u7684\u5377\u79ef\u4e0epooling\u5c42\uff0c\u8fd9\u4e9b\u5e73\u884c\u4f46\u4e0d\u5e76\u884c\u7684\u8fd0\u7b97\u4f1a\u591a\u6b21\u89e6\u53d1GPU\u7684\u542f\u52a8\u4e0e\u540c\u6b65\u3002\u788e\u7247\u5316\u8fd0\u884c\u5728GPU\u4e0a\u5f71\u54cd\u8f83\u5927\uff0c\u5728CPU\u4e0a\u5f71\u54cd\u4e0d\u5927","title":"\u5efa\u8bae\u4e09\uff0c\u7f51\u7edc\u7684\u788e\u7247\u5316\u964d\u4f4e\u4e86\u5e76\u884c\u5ea6"},{"location":"The_theory/ShuffleNet_V2:_Practical_Guidelines_for_Efficient_CNN_Architecture_Design/#reluelement-wise-operators","text":"\u5220\u9664ResNet\u4e2d\u7684ReLU\u4e0eshortcut\u4f1a\u770b\u5230\u7ea620%\u7684\u52a0\u901f\uff0c\u5c3d\u7ba1\u5b83\u4eec\u5f88\u5fc5\u8981\uff0c\u4f46\u662f\u5374\u662f\u4e8b\u5b9e\u4e0a\u5f71\u54cd\u901f\u5ea6\u7684\u3002","title":"\u5efa\u8bae\u56db\uff0cReLU,\u5143\u7d20\u95f4\u76f8\u52a0\u7b49element-wise operators\u540c\u6837\u4e0d\u53ef\u5ffd\u7565"},{"location":"The_theory/ShuffleNet_V2:_Practical_Guidelines_for_Efficient_CNN_Architecture_Design/#shufflenet-v2","text":"\u57fa\u672c\u5355\u5143\u7ed3\u6784\u53ca\u5176\u4e0eShuffleNet V1\u7684\u6bd4\u8f83\u5982\u56fe \u76f4\u89c9\uff1a \u7528 1\\times 1 \u5377\u79ef\u66ff\u4ee3Group Convolution+ channel shuffle \u4f7f\u7528Concat + Channel Shuffle\u66ff\u4ee3Add downsampling\u65f6\u4e0d\u4f7f\u7528avg pooling Channel split\u5c31\u662f\u7b80\u5355\u5730torch.split(dim=1) \u8fde\u7eed\u51fa\u73b0\u7684Concat, Channel Shuffle, Channel Split\u53ef\u4ee5\u653e\u5728\u4e00\u8d77\u4f5c\u4e3a\u4e00\u4e2a\u7edf\u4e00\u7684element-wise operation\u3002","title":"ShuffleNet V2:"},{"location":"The_theory/TranslationInvarianceinCNN/","text":"On Translation Invariance in CNNs: Convolutional Layers can Exploit Absolute Spatial Location \u8fd9\u4e0d\u662f\u672c\u7ad9\u7b2c\u4e00\u7bc7\u8ba8\u8bba\u5377\u79ef\u7f51\u7edc\u7684\u4f4d\u7f6e\u4fe1\u606f,\u53e6\u4e00\u7bc7\u662f How much Position Information Do Convolutional Neural Networks Encode? \u8fd9\u7bc7\u6587\u7ae0\u5206\u6790\u7684\u89d2\u5ea6\u4e0e\u6700\u540e\u7684\u7ed3\u8bba\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u4e0e\u524d\u6587\u6709\u533a\u522b\uff0c\u524d\u9762\u90a3\u7bc7\u6587\u7ae0\u7684\u7ed3\u8bba\u662f\u591a\u5c42Zero-Padding\u52a0\u5927\u611f\u53d7\u91ce\u4e5f\u80fd\u5f97\u5230\u5145\u5206\u7684\u4f4d\u7f6e\u4fe1\u606f\uff0c\u4e3b\u8981\u5728\u7528\u5728\u8bed\u4e49\u5206\u5272\uff0c\u800c\u672c\u6587\u5219\u6709\u6240\u4e0d\u540c\uff0c\u4e3b\u8981\u8ba8\u8bba\u5206\u7c7b\u95ee\u9898\u3002 Inspiration \u7b2c\u4e00\u4e2a\u5b9e\u9a8c\u8ba8\u8bba\u7684\u662f\u540c\u4e00\u5f20\u56fe\u51fa\u73b0\u5728\u4e0d\u540c\u89d2\u843d\uff0c\u7528\u5355\u5c42CNN\u52a0global pooling\u5c31\u80fd\u6210\u529f\u533a\u5206\u3002 Case Study \u4f5c\u8005\u540c\u6837\u8003\u8651\u5230\u4e86CNN\u8fb9\u754c\u5904\u7406\u7684\u95ee\u9898\uff0c\u4ee5\u4e0b\u9762\u8fd9\u4e2acase\u8ba8\u8bba\u4e0d\u540cpadding\u8bbe\u7f6e\u5bf9\u8f93\u51fa\u7684\u5f71\u54cd\u3002 \u5206\u522b\u89c2\u5bdf: No padding. same zero padding same circular padding. Full padding. \u4ece\u5168\u5c40global pool\u7684\u7ed3\u679c\u6765\u770b\uff0c3\u4e0e4\u90fd\u4f1a\u8f93\u51fa\u4e00\u6837\u7684\u7ed3\u679c\uff0c\u800c1\u4e0e2\u8f93\u51fa\u7684\u7ed3\u679c\u4f1a\u56e0\u7edd\u5bf9\u4f4d\u7f6e\u800c\u5f02\u3002 Receptive Field \u8fd9\u91cc\u7684\u5b9e\u9a8c\u4e0e\u524d\u6587\u540c\u6837\u8bc1\u660e\u4e86\u7f51\u7edc\u611f\u53d7\u91ce\u8d8a\u5927\uff0c\u7f51\u7edc\u53ef\u4ee5\u5224\u65ad\u7edd\u5bf9\u4f4d\u7f6e\u7684border size\u5c31\u8d8a\u5927(\u5982\u679c\u56fe\u7247\u6709\u6548\u90e8\u5206\u8ddd\u79bb\u8fb9\u754c\u8fc7\u8fdc\uff0c\u8d85\u51fa\u611f\u53d7\u91ce\u8303\u56f4\uff0cCNN\u5c31\u4e0d\u53ef\u80fd\u5b9e\u73b0\u5206\u7c7b\u4e86)\u3002 \u7edd\u5bf9\u4f4d\u7f6e\u4e0e\u76f8\u5bf9\u4f4d\u7f6e \u4f5c\u8005\u8fdb\u4e00\u6b65\u505a\u4e86\u4e00\u4e2a\u5b9e\u9a8c\uff0c\u8981\u6c42\u7f51\u7edctrain\u4ee5\u4e0a\u7684\u8fd9\u4e2a\u6570\u636e\u96c6\uff0c\u5206\u7c7b\u7684\u6807\u51c6\u662f\u76f8\u5bf9\u4f4d\u7f6e\u3002\uff08\u5e94\u8be5\u7559\u610f\u5230\uff0c\u53ea\u770btraining set\u7684\u8bdd\uff0cdissimilar Testset\u8fd9\u91cc\u7684\u7ed3\u679c\u53ea\u662f\u4e00\u4e2a\u53ef\u80fd\u7684\u5206\u7c7b\u7b54\u6848\uff0c\u53ea\u662f\u4f5c\u8005\u5f3a\u8c03\u76f8\u5bf9\u4f4d\u7f6e\u624d\u6709\u6548\u6240\u4ee5\u5f97\u5230\u8fd9\u4e2a\u7ed3\u679c\uff09 \u7406\u8bba\u4e0a\u6765\u8bf4\uff0c\u4e00\u4e2a\u7f51\u7edc\u53ef\u4ee5\u638c\u63e1\u7ea2\u4e0e\u7eff\u7684\u7edd\u5bf9\u4f4d\u7f6e\uff0c\u4e5f\u5c31\u80fd\u63a8\u7406\u5176\u76f8\u5bf9\u4f4d\u7f6e\uff0c\u4f46\u662f\u8fd9\u6837\u7684\u505a\u6cd5\u5bb9\u6613\u5bf9\u7edd\u5bf9\u4f4d\u7f6eoverfit,\u5bf9\u4e8e\u65b0\u7684\u6ca1\u89c1\u8fc7\u7684\u7edd\u5bf9\u4f4d\u7f6e\u4f1a\u6709\u6027\u80fd\u4e0b\u964d\u3002 \u5bf9\u4e8e\u672c\u6570\u636e\uff0c1/2\u90fd\u80fd\u5bf9similar testset\u6b63\u786e\u5224\u65ad\uff0c\u4f46\u662f\u96be\u4ee5\u6b63\u786e\u5224\u65addissimilar testset. \u800c3/4\u5bf9\u4e24\u4e2atest set\u7684\u4f30\u8ba1\u51c6\u786e\u7387\u662f\u4e00\u81f4\u7684\u3002","title":"On Translation Invariance in CNNs: Convolutional Layers can Exploit Absolute Spatial Location"},{"location":"The_theory/TranslationInvarianceinCNN/#on-translation-invariance-in-cnns-convolutional-layers-can-exploit-absolute-spatial-location","text":"\u8fd9\u4e0d\u662f\u672c\u7ad9\u7b2c\u4e00\u7bc7\u8ba8\u8bba\u5377\u79ef\u7f51\u7edc\u7684\u4f4d\u7f6e\u4fe1\u606f,\u53e6\u4e00\u7bc7\u662f How much Position Information Do Convolutional Neural Networks Encode? \u8fd9\u7bc7\u6587\u7ae0\u5206\u6790\u7684\u89d2\u5ea6\u4e0e\u6700\u540e\u7684\u7ed3\u8bba\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u4e0e\u524d\u6587\u6709\u533a\u522b\uff0c\u524d\u9762\u90a3\u7bc7\u6587\u7ae0\u7684\u7ed3\u8bba\u662f\u591a\u5c42Zero-Padding\u52a0\u5927\u611f\u53d7\u91ce\u4e5f\u80fd\u5f97\u5230\u5145\u5206\u7684\u4f4d\u7f6e\u4fe1\u606f\uff0c\u4e3b\u8981\u5728\u7528\u5728\u8bed\u4e49\u5206\u5272\uff0c\u800c\u672c\u6587\u5219\u6709\u6240\u4e0d\u540c\uff0c\u4e3b\u8981\u8ba8\u8bba\u5206\u7c7b\u95ee\u9898\u3002","title":"On Translation Invariance in CNNs: Convolutional Layers can Exploit Absolute Spatial Location"},{"location":"The_theory/TranslationInvarianceinCNN/#inspiration","text":"\u7b2c\u4e00\u4e2a\u5b9e\u9a8c\u8ba8\u8bba\u7684\u662f\u540c\u4e00\u5f20\u56fe\u51fa\u73b0\u5728\u4e0d\u540c\u89d2\u843d\uff0c\u7528\u5355\u5c42CNN\u52a0global pooling\u5c31\u80fd\u6210\u529f\u533a\u5206\u3002","title":"Inspiration"},{"location":"The_theory/TranslationInvarianceinCNN/#case-study","text":"\u4f5c\u8005\u540c\u6837\u8003\u8651\u5230\u4e86CNN\u8fb9\u754c\u5904\u7406\u7684\u95ee\u9898\uff0c\u4ee5\u4e0b\u9762\u8fd9\u4e2acase\u8ba8\u8bba\u4e0d\u540cpadding\u8bbe\u7f6e\u5bf9\u8f93\u51fa\u7684\u5f71\u54cd\u3002 \u5206\u522b\u89c2\u5bdf: No padding. same zero padding same circular padding. Full padding. \u4ece\u5168\u5c40global pool\u7684\u7ed3\u679c\u6765\u770b\uff0c3\u4e0e4\u90fd\u4f1a\u8f93\u51fa\u4e00\u6837\u7684\u7ed3\u679c\uff0c\u800c1\u4e0e2\u8f93\u51fa\u7684\u7ed3\u679c\u4f1a\u56e0\u7edd\u5bf9\u4f4d\u7f6e\u800c\u5f02\u3002","title":"Case Study"},{"location":"The_theory/TranslationInvarianceinCNN/#receptive-field","text":"\u8fd9\u91cc\u7684\u5b9e\u9a8c\u4e0e\u524d\u6587\u540c\u6837\u8bc1\u660e\u4e86\u7f51\u7edc\u611f\u53d7\u91ce\u8d8a\u5927\uff0c\u7f51\u7edc\u53ef\u4ee5\u5224\u65ad\u7edd\u5bf9\u4f4d\u7f6e\u7684border size\u5c31\u8d8a\u5927(\u5982\u679c\u56fe\u7247\u6709\u6548\u90e8\u5206\u8ddd\u79bb\u8fb9\u754c\u8fc7\u8fdc\uff0c\u8d85\u51fa\u611f\u53d7\u91ce\u8303\u56f4\uff0cCNN\u5c31\u4e0d\u53ef\u80fd\u5b9e\u73b0\u5206\u7c7b\u4e86)\u3002","title":"Receptive Field"},{"location":"The_theory/TranslationInvarianceinCNN/#_1","text":"\u4f5c\u8005\u8fdb\u4e00\u6b65\u505a\u4e86\u4e00\u4e2a\u5b9e\u9a8c\uff0c\u8981\u6c42\u7f51\u7edctrain\u4ee5\u4e0a\u7684\u8fd9\u4e2a\u6570\u636e\u96c6\uff0c\u5206\u7c7b\u7684\u6807\u51c6\u662f\u76f8\u5bf9\u4f4d\u7f6e\u3002\uff08\u5e94\u8be5\u7559\u610f\u5230\uff0c\u53ea\u770btraining set\u7684\u8bdd\uff0cdissimilar Testset\u8fd9\u91cc\u7684\u7ed3\u679c\u53ea\u662f\u4e00\u4e2a\u53ef\u80fd\u7684\u5206\u7c7b\u7b54\u6848\uff0c\u53ea\u662f\u4f5c\u8005\u5f3a\u8c03\u76f8\u5bf9\u4f4d\u7f6e\u624d\u6709\u6548\u6240\u4ee5\u5f97\u5230\u8fd9\u4e2a\u7ed3\u679c\uff09 \u7406\u8bba\u4e0a\u6765\u8bf4\uff0c\u4e00\u4e2a\u7f51\u7edc\u53ef\u4ee5\u638c\u63e1\u7ea2\u4e0e\u7eff\u7684\u7edd\u5bf9\u4f4d\u7f6e\uff0c\u4e5f\u5c31\u80fd\u63a8\u7406\u5176\u76f8\u5bf9\u4f4d\u7f6e\uff0c\u4f46\u662f\u8fd9\u6837\u7684\u505a\u6cd5\u5bb9\u6613\u5bf9\u7edd\u5bf9\u4f4d\u7f6eoverfit,\u5bf9\u4e8e\u65b0\u7684\u6ca1\u89c1\u8fc7\u7684\u7edd\u5bf9\u4f4d\u7f6e\u4f1a\u6709\u6027\u80fd\u4e0b\u964d\u3002 \u5bf9\u4e8e\u672c\u6570\u636e\uff0c1/2\u90fd\u80fd\u5bf9similar testset\u6b63\u786e\u5224\u65ad\uff0c\u4f46\u662f\u96be\u4ee5\u6b63\u786e\u5224\u65addissimilar testset. \u800c3/4\u5bf9\u4e24\u4e2atest set\u7684\u4f30\u8ba1\u51c6\u786e\u7387\u662f\u4e00\u81f4\u7684\u3002","title":"\u7edd\u5bf9\u4f4d\u7f6e\u4e0e\u76f8\u5bf9\u4f4d\u7f6e"},{"location":"The_theory/UNDERSTANDING DEEP LEARNING REQUIRES RETHINKING GENERALIZATION/","text":"Understanding Deep Learning Requires Rethinking Generalization \u8fd9\u7bc7\u6587\u7ae0\u8ba8\u8bba\u7f51\u7edc\u7684generalization\u80fd\u529b\u3002 \u4e00\u4e2a\u7279\u6b8a\u7684\u5b9e\u9a8c\uff1a \u5728\u4e00\u4e2adataset\u4e2d\uff0c\u5c06label\u6539\u4e3a\u5b8c\u5168\u968f\u673a\u62bd\u53d6\uff0c\u5b9e\u9a8c\u8bc1\u660e\uff0c\u76ee\u524d\u7684\u795e\u7ecf\u7f51\u7edc\u80fd\u591f\u5b8c\u5168\u8bb0\u5fc6\u6240\u6709\u7684\u968f\u673alabel\uff0c\u4f18\u5316\u96be\u5ea6\u5e76\u6ca1\u6709\u663e\u8457\u63d0\u5347\uff0c\u4f46\u662f\u660e\u786e\u53ef\u4ee5\u77e5\u9053\uff0cgeneralization\u7684\u7ed3\u679c\u5fc5\u7136\u7b49\u540c\u4e8e\u968f\u673a(training \u4e0e testing\u5b8c\u5168\u4e0d\u76f8\u5173)\u3002 \u6240\u4ee5\u9996\u5148\u53ef\u4ee5\u77e5\u9053\u4f18\u5316\u662f\u5426\u987a\u5229\u4e0e\u80fd\u5426generalize\u6ca1\u6709\u76f4\u63a5\u663e\u8457\u7684\u5173\u7cfb \u5173\u4e8eregularization\u6280\u5de7\uff1a \u6570\u636e\u589e\u5f3a\u3001weight delay( l_2 regularizer)\u3001dropout\uff0c\u7ecf\u9a8c\u4e0a\u90fd\u80fd\u63d0\u5347\u7f51\u7edc\u7684test\u51c6\u786e\u7387\uff0c\u4f46\u662f\u5728fitting random labels\u7684\u65f6\u5019\u90fd\u662f\u80fd\u8fbe\u5230training accuracy = 100%,test accuracy\u4ecd\u7136\u662f10%. BatchNorm\u548cEarlyStop\u90fd\u662f\u6709\u6548\u7684\u3002","title":"Understanding Deep Learning Requires Rethinking Generalization"},{"location":"The_theory/UNDERSTANDING DEEP LEARNING REQUIRES RETHINKING GENERALIZATION/#understanding-deep-learning-requires-rethinking-generalization","text":"\u8fd9\u7bc7\u6587\u7ae0\u8ba8\u8bba\u7f51\u7edc\u7684generalization\u80fd\u529b\u3002 \u4e00\u4e2a\u7279\u6b8a\u7684\u5b9e\u9a8c\uff1a \u5728\u4e00\u4e2adataset\u4e2d\uff0c\u5c06label\u6539\u4e3a\u5b8c\u5168\u968f\u673a\u62bd\u53d6\uff0c\u5b9e\u9a8c\u8bc1\u660e\uff0c\u76ee\u524d\u7684\u795e\u7ecf\u7f51\u7edc\u80fd\u591f\u5b8c\u5168\u8bb0\u5fc6\u6240\u6709\u7684\u968f\u673alabel\uff0c\u4f18\u5316\u96be\u5ea6\u5e76\u6ca1\u6709\u663e\u8457\u63d0\u5347\uff0c\u4f46\u662f\u660e\u786e\u53ef\u4ee5\u77e5\u9053\uff0cgeneralization\u7684\u7ed3\u679c\u5fc5\u7136\u7b49\u540c\u4e8e\u968f\u673a(training \u4e0e testing\u5b8c\u5168\u4e0d\u76f8\u5173)\u3002 \u6240\u4ee5\u9996\u5148\u53ef\u4ee5\u77e5\u9053\u4f18\u5316\u662f\u5426\u987a\u5229\u4e0e\u80fd\u5426generalize\u6ca1\u6709\u76f4\u63a5\u663e\u8457\u7684\u5173\u7cfb \u5173\u4e8eregularization\u6280\u5de7\uff1a \u6570\u636e\u589e\u5f3a\u3001weight delay( l_2 regularizer)\u3001dropout\uff0c\u7ecf\u9a8c\u4e0a\u90fd\u80fd\u63d0\u5347\u7f51\u7edc\u7684test\u51c6\u786e\u7387\uff0c\u4f46\u662f\u5728fitting random labels\u7684\u65f6\u5019\u90fd\u662f\u80fd\u8fbe\u5230training accuracy = 100%,test accuracy\u4ecd\u7136\u662f10%. BatchNorm\u548cEarlyStop\u90fd\u662f\u6709\u6548\u7684\u3002","title":"Understanding Deep Learning Requires Rethinking Generalization"},{"location":"The_theory/VovNet/","text":"An Energy and GPU-Computation Efficient Backbone Network for Real-Time Object Detection \u8fd9\u7bc7paper\u4ece DenseNet\u51fa\u53d1\uff0c\u7ed3\u5408\u8fd0\u7b97\u901f\u7387\u4e0e\u80fd\u91cf\u6548\u7387\u8c03\u6574\u66f4\u597d\u7684backbone\u7ed3\u6784\u3002 VovNet OSA\u6a21\u5757\u7ed3\u6784 \u5f71\u54cd\u8fd0\u7b97\u901f\u5ea6\u4e0e\u80fd\u91cf\u6d88\u8017\u7684\u5173\u952e\u56e0\u7d20 \u672c\u6587\u7ed3\u5408 ShuffleNet_V2 \u7684\u7ed3\u8bba\uff0c\u5e76\u7ee7\u7eed\u5ef6\u4f38\u3002 \u672c\u6587\u6307\u51fa\u5185\u5b58\u7684\u8bfb\u53d6\u4f7f\u7528(MAC)\u65f6\u95f4\u4ee5\u53ca\u80fd\u91cf\u6d88\u8017\u5f80\u5f80\u4f1a\u591a\u4e8e\u8ba1\u7b97\u7684\u82b1\u8d39\u3002 \u5bf9\u4e8e\u5377\u79ef\u5c42 MAC = hw(c_i + c_i) + k^2 c_i c_o \u7531 ShuffleNet_V2 ,\u540c\u6837\u7684\u7ed3\u8bba\uff0c\u5e94\u8be5\u5c3d\u53ef\u80fd\u4fdd\u8bc1\u8f93\u5165\u8f93\u51fafeature\u4e00\u6837\u591a\uff0c\u56e0\u800cDenseNet\u7684\u7ed3\u6784\u6548\u7387\u4e0d\u591f\u597d\u3002 DenseNet\u7684\u95ee\u9898: DenseNet\u7684\u6743\u91cdnorm\u53cd\u6620\u4e86\u5b83\u7684\u5197\u4f59\uff0c\u8981\u4e48Intermediate \u6743\u91cd\u5f88\u4f4e\uff0c\u8981\u4e48\u662f\u524d\u9762\u7684\u6743\u91cd\u5f88\u4f4e\u3002\u56e0\u800c\u7528OSA\u66ff\u4ee3Dense Connection.","title":"An Energy and GPU-Computation Efficient Backbone Network for Real-Time Object Detection"},{"location":"The_theory/VovNet/#an-energy-and-gpu-computation-efficient-backbone-network-for-real-time-object-detection","text":"\u8fd9\u7bc7paper\u4ece DenseNet\u51fa\u53d1\uff0c\u7ed3\u5408\u8fd0\u7b97\u901f\u7387\u4e0e\u80fd\u91cf\u6548\u7387\u8c03\u6574\u66f4\u597d\u7684backbone\u7ed3\u6784\u3002","title":"An Energy and GPU-Computation Efficient Backbone Network for Real-Time Object Detection"},{"location":"The_theory/VovNet/#vovnet-osa","text":"","title":"VovNet OSA\u6a21\u5757\u7ed3\u6784"},{"location":"The_theory/VovNet/#_1","text":"\u672c\u6587\u7ed3\u5408 ShuffleNet_V2 \u7684\u7ed3\u8bba\uff0c\u5e76\u7ee7\u7eed\u5ef6\u4f38\u3002 \u672c\u6587\u6307\u51fa\u5185\u5b58\u7684\u8bfb\u53d6\u4f7f\u7528(MAC)\u65f6\u95f4\u4ee5\u53ca\u80fd\u91cf\u6d88\u8017\u5f80\u5f80\u4f1a\u591a\u4e8e\u8ba1\u7b97\u7684\u82b1\u8d39\u3002 \u5bf9\u4e8e\u5377\u79ef\u5c42 MAC = hw(c_i + c_i) + k^2 c_i c_o \u7531 ShuffleNet_V2 ,\u540c\u6837\u7684\u7ed3\u8bba\uff0c\u5e94\u8be5\u5c3d\u53ef\u80fd\u4fdd\u8bc1\u8f93\u5165\u8f93\u51fafeature\u4e00\u6837\u591a\uff0c\u56e0\u800cDenseNet\u7684\u7ed3\u6784\u6548\u7387\u4e0d\u591f\u597d\u3002","title":"\u5f71\u54cd\u8fd0\u7b97\u901f\u5ea6\u4e0e\u80fd\u91cf\u6d88\u8017\u7684\u5173\u952e\u56e0\u7d20"},{"location":"The_theory/VovNet/#densenet","text":"DenseNet\u7684\u6743\u91cdnorm\u53cd\u6620\u4e86\u5b83\u7684\u5197\u4f59\uff0c\u8981\u4e48Intermediate \u6743\u91cd\u5f88\u4f4e\uff0c\u8981\u4e48\u662f\u524d\u9762\u7684\u6743\u91cd\u5f88\u4f4e\u3002\u56e0\u800c\u7528OSA\u66ff\u4ee3Dense Connection.","title":"DenseNet\u7684\u95ee\u9898:"},{"location":"The_theory/Why_gradien_clip_norm/","text":"WHY GRADIENT CLIPPING ACCELERATES TRAINING: A THEORETICAL JUSTIFICATION FOR ADAPTIVITY \u8fd9\u7bc7paper\u662f2020ICLR\u7684\u6ee1\u5206\u8bba\u6587\uff0c\u4f5c\u8005\u4ece\u7406\u8bba\u4e0e\u5b9e\u8df5\u4e0a\u53bb\u8bba\u8bc1\u4e86\u4e3a\u4ec0\u4e48\u5efa\u8bae clip gradient norm \u68af\u5ea6\u7684\u674e\u666e\u5e0c\u5179\u8fde\u7eed(Lipschitz Continuity) \u674e\u666e\u5e0c\u5179\u8fde\u7eed \u539f\u6307\u68af\u5ea6\u7684\u7edd\u5bf9\u503c\u6709\u6709\u9650\u4e0a\u9650\u3002 \u4f18\u5316\u4e2d\uff0c\u5b9a\u4e49\u4e00\u4e2a\u51fd\u6570\u4e3a L -\u5149\u6ed1( L-smooth )\u5982\u679c\u5bf9\u4efb\u610fx,y \\|\\nabla f(x)-\\nabla f(y)\\| \\leq L\\|x-y\\| \u53ef\u4ee5\u7406\u89e3\u4e3a\u51fd\u6570\u7684\u4e8c\u9636\u5bfc\u6709\u9650\u3002\u5bf9\u4e8e\u8fd9\u79cd\u6210\u672c\u51fd\u6570\uff0c\u68af\u5ea6\u4e0b\u964d\u4e2d\u9009\u62e9\u5b66\u4e60\u7387 h = 1/L \u4e3a\u7406\u8bba\u6700\u4f18\u5b66\u4e60\u7387\u9009\u62e9\u3002 \u4f46\u662f\u4e00\u4e2a\u7b80\u5355\u7684 y = x^3 \u51fd\u6570\u5c31\u5df2\u7ecf\u6253\u7834\u8fd9\u4e2a L -\u5149\u6ed1\u7684\u7406\u8bba\u9650\u5236\uff0c\u66f4\u4e0d\u7528\u8bf4\u9ad8\u7ef4\u7684\u7f51\u7edc\u51fd\u6570\u3002\u5bf9\u4e8e\u8fd9\u6837\u7684\u51fd\u6570\uff0c\u4f20\u7edf\u7684\u65b9\u6cd5\u662f\u8bbe\u7f6e\u4e00\u4e2a\u5b9a\u4e49\u57df\u7684\u8f93\u5165\u8303\u56f4\uff0c\u5f97\u5230\u4e00\u4e2a\u6709\u9650\u7684 L \u503c,\u4e3a\u4e86\u80fd\u6ee1\u8db3\u8db3\u591f\u591a\u7684\u8f93\u5165\u8303\u56f4\uff0c\u8fd9\u4e2aL\u503c\u5f80\u5f80\u4f1a\u8f83\u5927\uff0c\u4f7f\u5f97\u5b66\u4e60\u7387\u66f4\u4e3a\u4fdd\u5b88\u3002 \u53e6\u5916\u4f5c\u8005\u5728\u5b9e\u9a8c\u4e2d\u53d1\u73b0\u4e86gradient norm\u4e0e\u5149\u6ed1\u5ea6 L \u4e4b\u95f4\u7684\u5173\u7cfb (L_0-L_1) \u5149\u6ed1 \u5b9a\u4e49 \\left\\|\\nabla^{2} f(x)\\right\\| \\leq L_{0}+L_{1}\\|\\nabla f(x)\\| \u5373\u6ee1\u8db3\u4e8c\u9636\u5bfc\u77e9\u9635\u7684\u6a21\u4e0e\u4e00\u9636\u5bfc\u77e9\u9635\u7684\u6a21\u7684\u6bd4\u503c\u6709\u9650\u3002\u8fd9\u4e2a\u662f\u4e00\u4e2a\u6bd4\u8f83\u677e\u7684\u5149\u6ed1\u5b9a\u4e49\uff0c\u5bb9\u6613\u77e5\u9053\uff0c\u4efb\u610f\u9ad8\u9636\u7684\u591a\u9879\u5f0f\u51fd\u6570\u90fd\u4f1a\u5728\u6574\u4e2a\u5b9e\u6570\u96c6\u4e0a\u6ee1\u8db3\u8fd9\u4e00\u6761\u4ef6 \u4e4b\u540e\u4f5c\u8005\u6570\u5b66\u8bc1\u660e\u4e86\u5f53\u7b26\u5408\u6b64\u5149\u6ed1\u6761\u4ef6\u65f6\uff0c\u5982\u679c\u521d\u59cb\u5316\u4e0e\u5b9e\u9645\u7ed3\u679c\u6709\u4e00\u5b9a\u5dee\u8ddd\uff0cclip-GD\u7684\u6536\u655b\u901f\u5ea6\u4f1a\u8fdc\u8fdc\u5feb\u4e8efix GD Remark 5 . Theorem 1 of Carmon et al. (2017) and Theorem 4 together show that gradient descent with a fixed step size cannot converge to an \\epsilon -stationary point faster than \\Omega\\left(\\left(L_{1} M / \\log (M)+L_{0}\\right)\\left(f\\left(x_{0}\\right)-f^{*}\\right) \\epsilon^{-2}\\right) . Recall that clipped GD algorithm converges as \\mathcal{O}\\left(L_{0}\\left(f\\left(x_{0}\\right)-f^{*}\\right) \\epsilon^{-2}+L_{1}^{2}\\left(f\\left(x_{0}\\right)-f^{*}\\right) L_{0}^{-1}\\right) . Therefore, clipped GD can be arbitrarily faster than GD when L_{1} M is large, or in other words, when the problem has a poor initialization.","title":"WHY GRADIENT CLIPPING ACCELERATES TRAINING: A THEORETICAL JUSTIFICATION FOR ADAPTIVITY"},{"location":"The_theory/Why_gradien_clip_norm/#why-gradient-clipping-accelerates-training-a-theoretical-justification-for-adaptivity","text":"\u8fd9\u7bc7paper\u662f2020ICLR\u7684\u6ee1\u5206\u8bba\u6587\uff0c\u4f5c\u8005\u4ece\u7406\u8bba\u4e0e\u5b9e\u8df5\u4e0a\u53bb\u8bba\u8bc1\u4e86\u4e3a\u4ec0\u4e48\u5efa\u8bae clip gradient norm","title":"WHY GRADIENT CLIPPING ACCELERATES TRAINING: A THEORETICAL JUSTIFICATION FOR ADAPTIVITY"},{"location":"The_theory/Why_gradien_clip_norm/#lipschitz-continuity","text":"\u674e\u666e\u5e0c\u5179\u8fde\u7eed \u539f\u6307\u68af\u5ea6\u7684\u7edd\u5bf9\u503c\u6709\u6709\u9650\u4e0a\u9650\u3002 \u4f18\u5316\u4e2d\uff0c\u5b9a\u4e49\u4e00\u4e2a\u51fd\u6570\u4e3a L -\u5149\u6ed1( L-smooth )\u5982\u679c\u5bf9\u4efb\u610fx,y \\|\\nabla f(x)-\\nabla f(y)\\| \\leq L\\|x-y\\| \u53ef\u4ee5\u7406\u89e3\u4e3a\u51fd\u6570\u7684\u4e8c\u9636\u5bfc\u6709\u9650\u3002\u5bf9\u4e8e\u8fd9\u79cd\u6210\u672c\u51fd\u6570\uff0c\u68af\u5ea6\u4e0b\u964d\u4e2d\u9009\u62e9\u5b66\u4e60\u7387 h = 1/L \u4e3a\u7406\u8bba\u6700\u4f18\u5b66\u4e60\u7387\u9009\u62e9\u3002 \u4f46\u662f\u4e00\u4e2a\u7b80\u5355\u7684 y = x^3 \u51fd\u6570\u5c31\u5df2\u7ecf\u6253\u7834\u8fd9\u4e2a L -\u5149\u6ed1\u7684\u7406\u8bba\u9650\u5236\uff0c\u66f4\u4e0d\u7528\u8bf4\u9ad8\u7ef4\u7684\u7f51\u7edc\u51fd\u6570\u3002\u5bf9\u4e8e\u8fd9\u6837\u7684\u51fd\u6570\uff0c\u4f20\u7edf\u7684\u65b9\u6cd5\u662f\u8bbe\u7f6e\u4e00\u4e2a\u5b9a\u4e49\u57df\u7684\u8f93\u5165\u8303\u56f4\uff0c\u5f97\u5230\u4e00\u4e2a\u6709\u9650\u7684 L \u503c,\u4e3a\u4e86\u80fd\u6ee1\u8db3\u8db3\u591f\u591a\u7684\u8f93\u5165\u8303\u56f4\uff0c\u8fd9\u4e2aL\u503c\u5f80\u5f80\u4f1a\u8f83\u5927\uff0c\u4f7f\u5f97\u5b66\u4e60\u7387\u66f4\u4e3a\u4fdd\u5b88\u3002 \u53e6\u5916\u4f5c\u8005\u5728\u5b9e\u9a8c\u4e2d\u53d1\u73b0\u4e86gradient norm\u4e0e\u5149\u6ed1\u5ea6 L \u4e4b\u95f4\u7684\u5173\u7cfb","title":"\u68af\u5ea6\u7684\u674e\u666e\u5e0c\u5179\u8fde\u7eed(Lipschitz Continuity)"},{"location":"The_theory/Why_gradien_clip_norm/#l_0-l_1","text":"\u5b9a\u4e49 \\left\\|\\nabla^{2} f(x)\\right\\| \\leq L_{0}+L_{1}\\|\\nabla f(x)\\| \u5373\u6ee1\u8db3\u4e8c\u9636\u5bfc\u77e9\u9635\u7684\u6a21\u4e0e\u4e00\u9636\u5bfc\u77e9\u9635\u7684\u6a21\u7684\u6bd4\u503c\u6709\u9650\u3002\u8fd9\u4e2a\u662f\u4e00\u4e2a\u6bd4\u8f83\u677e\u7684\u5149\u6ed1\u5b9a\u4e49\uff0c\u5bb9\u6613\u77e5\u9053\uff0c\u4efb\u610f\u9ad8\u9636\u7684\u591a\u9879\u5f0f\u51fd\u6570\u90fd\u4f1a\u5728\u6574\u4e2a\u5b9e\u6570\u96c6\u4e0a\u6ee1\u8db3\u8fd9\u4e00\u6761\u4ef6 \u4e4b\u540e\u4f5c\u8005\u6570\u5b66\u8bc1\u660e\u4e86\u5f53\u7b26\u5408\u6b64\u5149\u6ed1\u6761\u4ef6\u65f6\uff0c\u5982\u679c\u521d\u59cb\u5316\u4e0e\u5b9e\u9645\u7ed3\u679c\u6709\u4e00\u5b9a\u5dee\u8ddd\uff0cclip-GD\u7684\u6536\u655b\u901f\u5ea6\u4f1a\u8fdc\u8fdc\u5feb\u4e8efix GD Remark 5 . Theorem 1 of Carmon et al. (2017) and Theorem 4 together show that gradient descent with a fixed step size cannot converge to an \\epsilon -stationary point faster than \\Omega\\left(\\left(L_{1} M / \\log (M)+L_{0}\\right)\\left(f\\left(x_{0}\\right)-f^{*}\\right) \\epsilon^{-2}\\right) . Recall that clipped GD algorithm converges as \\mathcal{O}\\left(L_{0}\\left(f\\left(x_{0}\\right)-f^{*}\\right) \\epsilon^{-2}+L_{1}^{2}\\left(f\\left(x_{0}\\right)-f^{*}\\right) L_{0}^{-1}\\right) . Therefore, clipped GD can be arbitrarily faster than GD when L_{1} M is large, or in other words, when the problem has a poor initialization.","title":"(L_0-L_1)\u5149\u6ed1"},{"location":"The_theory/compondingTechforCNN/","text":"Compounding the Performance Improvements of Assembled Techniques in a Convolutional Neural Network This paper is essentially a summary for a bag of training techniques for training CNN. Neural Network Model ResNet-D Channel-Attention (SE & SK) Squeeze and Excitation (SE) module has been introduced by this paper Selective Kernel can be described in: A light-weight SK implementation in pytorch can be found here Anti-Alias Downsampling AA Downsampling is first proposed in this paper.pdf . This is also called Blur-Pool implemented in keras here Big Little Network (BL) Big Little Network is first proposed in This paper.pdf Regularization AutoAugment Auto Augmentation is proposed in This paper.pdf which applies reinforcement learning to train a agent to do image augmentation. Tensorflow open source code can be found here Mixup Mix up has been introduced in Bag of Freebies DropBlock Dropblock is first proposed in This paper.pdf dropblock has been implemented in Pytorch here Label Smoothing label smoothing \u6e90\u81eainception-v3,\u5728\u8bad\u7ec3\u65f6\u6709\u4e00\u5b9a\u6982\u7387\u4e0d\u91c7\u53d6\u539flabel\uff0c\u800c\u5747\u5300\u968f\u673a\u9009\u62e9\u53e6\u4e00\u4e2aclass\u4f5c\u4e3aground truth. The paper indeed shows that almost all methods induce improvement in ImageNet results and transfer learning result","title":"Compounding the Performance Improvements of Assembled Techniques in a Convolutional Neural Network"},{"location":"The_theory/compondingTechforCNN/#compounding-the-performance-improvements-of-assembled-techniques-in-a-convolutional-neural-network","text":"This paper is essentially a summary for a bag of training techniques for training CNN.","title":"Compounding the Performance Improvements of Assembled Techniques in a Convolutional Neural Network"},{"location":"The_theory/compondingTechforCNN/#neural-network-model","text":"","title":"Neural Network Model"},{"location":"The_theory/compondingTechforCNN/#resnet-d","text":"","title":"ResNet-D"},{"location":"The_theory/compondingTechforCNN/#channel-attention-se-sk","text":"Squeeze and Excitation (SE) module has been introduced by this paper Selective Kernel can be described in: A light-weight SK implementation in pytorch can be found here","title":"Channel-Attention  (SE &amp; SK)"},{"location":"The_theory/compondingTechforCNN/#anti-alias-downsampling","text":"AA Downsampling is first proposed in this paper.pdf . This is also called Blur-Pool implemented in keras here","title":"Anti-Alias Downsampling"},{"location":"The_theory/compondingTechforCNN/#big-little-network-bl","text":"Big Little Network is first proposed in This paper.pdf","title":"Big Little Network (BL)"},{"location":"The_theory/compondingTechforCNN/#regularization","text":"","title":"Regularization"},{"location":"The_theory/compondingTechforCNN/#autoaugment","text":"Auto Augmentation is proposed in This paper.pdf which applies reinforcement learning to train a agent to do image augmentation. Tensorflow open source code can be found here","title":"AutoAugment"},{"location":"The_theory/compondingTechforCNN/#mixup","text":"Mix up has been introduced in Bag of Freebies","title":"Mixup"},{"location":"The_theory/compondingTechforCNN/#dropblock","text":"Dropblock is first proposed in This paper.pdf dropblock has been implemented in Pytorch here","title":"DropBlock"},{"location":"The_theory/compondingTechforCNN/#label-smoothing","text":"label smoothing \u6e90\u81eainception-v3,\u5728\u8bad\u7ec3\u65f6\u6709\u4e00\u5b9a\u6982\u7387\u4e0d\u91c7\u53d6\u539flabel\uff0c\u800c\u5747\u5300\u968f\u673a\u9009\u62e9\u53e6\u4e00\u4e2aclass\u4f5c\u4e3aground truth. The paper indeed shows that almost all methods induce improvement in ImageNet results and transfer learning result","title":"Label Smoothing"},{"location":"The_theory/ddn/","text":"Deep Declarative Networks: A New Hope \u8fd9\u4e2a\u6982\u5ff5\u7c7b\u4f3c\u4e8e\u6df1\u5ea6\u5747\u8861paper\u91cc\u9762\u7684 implicit deep learning \uff0c\u4e5f\u5c31\u662f\u7f51\u7edc\u6a21\u5757\u7684\u5b9a\u4e49\u7684\u662f\u7531\u5bf9\u8f93\u51fa\u7ed3\u679c\u7684\u5b9a\u4e49\u6765\u51b3\u5b9a\u7684\u3002 MDEQ \u8003\u8651\u7684\u662f\u5b9e\u73b0\u4e00\u4e2a\u65e0\u7a77\u6df1\u7684\u7f51\u7edc\uff0c\u66f4\u591a\u60c5\u51b5\u4e0b\u8fd9\u7c7b\u7f51\u7edc\u5c42\u4f7f\u7528\u7684\u662f\u4f18\u5316\u95ee\u9898\uff0c\u5982 EPnP , OptNet , SS3D \u8fd9\u7bc7paper\u5219\u7ed9\u51fa\u4e00\u7c7b\u57fa\u4e8e\u4f18\u5316\u7684 declarative networks \u7684\u6c42\u5bfc\u8bad\u7ec3\u65b9\u6cd5\u3002 \u4ee5\u65e0\u7ea6\u675f\u7684\u4f18\u5316\u95ee\u9898\u4e3a\u4f8b\uff0c\u8f93\u5165\u4e3a x , \u8f93\u51fa\u4e3a y , \\begin{array}{ll} \\operatorname{minimize} & J(x, y) \\\\ \\text { subject to } & y \\in \\arg \\min _{u \\in C} f(x, u) \\end{array} \u5728\u6700\u4f18\u7684\u70b9\u4e0a\uff0c \\frac{\\partial f}{\\partial y} = 0 , \u4e14\u8fd9\u4e2a\u4e0d\u7531 x \u53d8\u5316\uff0c\u518d\u6b21\u6c42\u5bfc\u53ef\u5f97 \\begin{aligned} 0_{m \\times n} &=\\mathrm{D}\\left(\\mathrm{D}_{Y} f(x, y)\\right)^{\\top} \\\\ &=\\mathrm{D}_{X Y}^{2} f(x, y)+\\mathrm{D}_{Y Y}^{2} f(x, y) \\mathrm{D} y(x) \\end{aligned} \\mathrm{D} y(x)=-\\left(\\mathrm{D}_{Y Y}^{2} f(x, y)\\right)^{-1} \\mathrm{D}_{X Y}^{2} f(x, y) \u5bf9\u4e8e\u5e26\u7b49\u5f0f\u4e0e\u4e0d\u7b49\u5f0f\u7684\u7ea6\u675f\uff0c\u672c\u6587\u5206\u522b\u7ed9\u51fa\u4e86\u6c42\u5bfc\u7684\u8ba1\u7b97\u65b9\u5f0f\u3002 \u4ee3\u7801 \u672c\u6587\u5f00\u6e90\u4e86\u524d\u6587\u6240\u6709\u7c7b\u578b\u7684\u8282\u70b9\u7684\u6c42\u5bfc\u65b9\u6cd5\u3002\u4ee3\u7801\u4e0a\u53ea\u8981\u5b9e\u73b0\u4e3b\u51fd\u6570\uff0c\u7ea6\u675f\u51fd\u6570\u4ee5\u53ca\u4f18\u5316\u8fc7\u7a0b(\u4e0e\u53cd\u5411\u65e0\u5173)\u5373\u53ef\u3002 \u5176\u6b21\u5728\u672c\u6587\u7684\u4ee3\u7801\u4e2d\u770b\u5230\u4e86pytorch\u81ea\u5e26\u7684\u4e00\u4e2a\u5b8c\u6574\u7684\u4f18\u5316\u51fd\u6570 torch.optim.LBFGS \u3002\u672c\u6587\u5229\u7528\u8fd9\u4e2a\u51fd\u6570\u5b9e\u73b0\u4e86\u4e00\u4e2a\u5f88\u901a\u7528\u7684PnP\u975e\u7ebf\u6027\u4f18\u5316","title":"Deep Declarative Networks: A New Hope"},{"location":"The_theory/ddn/#deep-declarative-networks-a-new-hope","text":"\u8fd9\u4e2a\u6982\u5ff5\u7c7b\u4f3c\u4e8e\u6df1\u5ea6\u5747\u8861paper\u91cc\u9762\u7684 implicit deep learning \uff0c\u4e5f\u5c31\u662f\u7f51\u7edc\u6a21\u5757\u7684\u5b9a\u4e49\u7684\u662f\u7531\u5bf9\u8f93\u51fa\u7ed3\u679c\u7684\u5b9a\u4e49\u6765\u51b3\u5b9a\u7684\u3002 MDEQ \u8003\u8651\u7684\u662f\u5b9e\u73b0\u4e00\u4e2a\u65e0\u7a77\u6df1\u7684\u7f51\u7edc\uff0c\u66f4\u591a\u60c5\u51b5\u4e0b\u8fd9\u7c7b\u7f51\u7edc\u5c42\u4f7f\u7528\u7684\u662f\u4f18\u5316\u95ee\u9898\uff0c\u5982 EPnP , OptNet , SS3D \u8fd9\u7bc7paper\u5219\u7ed9\u51fa\u4e00\u7c7b\u57fa\u4e8e\u4f18\u5316\u7684 declarative networks \u7684\u6c42\u5bfc\u8bad\u7ec3\u65b9\u6cd5\u3002 \u4ee5\u65e0\u7ea6\u675f\u7684\u4f18\u5316\u95ee\u9898\u4e3a\u4f8b\uff0c\u8f93\u5165\u4e3a x , \u8f93\u51fa\u4e3a y , \\begin{array}{ll} \\operatorname{minimize} & J(x, y) \\\\ \\text { subject to } & y \\in \\arg \\min _{u \\in C} f(x, u) \\end{array} \u5728\u6700\u4f18\u7684\u70b9\u4e0a\uff0c \\frac{\\partial f}{\\partial y} = 0 , \u4e14\u8fd9\u4e2a\u4e0d\u7531 x \u53d8\u5316\uff0c\u518d\u6b21\u6c42\u5bfc\u53ef\u5f97 \\begin{aligned} 0_{m \\times n} &=\\mathrm{D}\\left(\\mathrm{D}_{Y} f(x, y)\\right)^{\\top} \\\\ &=\\mathrm{D}_{X Y}^{2} f(x, y)+\\mathrm{D}_{Y Y}^{2} f(x, y) \\mathrm{D} y(x) \\end{aligned} \\mathrm{D} y(x)=-\\left(\\mathrm{D}_{Y Y}^{2} f(x, y)\\right)^{-1} \\mathrm{D}_{X Y}^{2} f(x, y) \u5bf9\u4e8e\u5e26\u7b49\u5f0f\u4e0e\u4e0d\u7b49\u5f0f\u7684\u7ea6\u675f\uff0c\u672c\u6587\u5206\u522b\u7ed9\u51fa\u4e86\u6c42\u5bfc\u7684\u8ba1\u7b97\u65b9\u5f0f\u3002","title":"Deep Declarative Networks: A New Hope"},{"location":"The_theory/ddn/#_1","text":"\u672c\u6587\u5f00\u6e90\u4e86\u524d\u6587\u6240\u6709\u7c7b\u578b\u7684\u8282\u70b9\u7684\u6c42\u5bfc\u65b9\u6cd5\u3002\u4ee3\u7801\u4e0a\u53ea\u8981\u5b9e\u73b0\u4e3b\u51fd\u6570\uff0c\u7ea6\u675f\u51fd\u6570\u4ee5\u53ca\u4f18\u5316\u8fc7\u7a0b(\u4e0e\u53cd\u5411\u65e0\u5173)\u5373\u53ef\u3002 \u5176\u6b21\u5728\u672c\u6587\u7684\u4ee3\u7801\u4e2d\u770b\u5230\u4e86pytorch\u81ea\u5e26\u7684\u4e00\u4e2a\u5b8c\u6574\u7684\u4f18\u5316\u51fd\u6570 torch.optim.LBFGS \u3002\u672c\u6587\u5229\u7528\u8fd9\u4e2a\u51fd\u6570\u5b9e\u73b0\u4e86\u4e00\u4e2a\u5f88\u901a\u7528\u7684PnP\u975e\u7ebf\u6027\u4f18\u5316","title":"\u4ee3\u7801"},{"location":"other_categories/Deep-Navigation/ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst/","text":"ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst \u8fd9\u7bc7RSS\u8bba\u6587\u6765\u81ea\u4e8eWaymo,\u82f1\u6587\u540d\u5b57\u7684\u7ffb\u8bd1\u610f\u601d\u662f\"\u53f8\u673a\u7f51\",\u7ed9\u51fa\u4e86\u4e00\u4e2aimitation learning\u7cfb\u7edf\uff0c\u5e76\u5b9e\u73b0\u4e86\u4e0a\u8f66\u6d4b\u8bd5\uff0c\u4e3a\u4e86\u4fdd\u8bc1\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u672c\u6587\u505a\u4e86\u5f88\u591a\u7684\u9009\u62e9\u4e0e\u52a0\u5f3a\uff0c\u503c\u5f97\u4e86\u89e3\u3002\u8fd9\u7bc7\u8bba\u6587\u6709 \u6765\u81eawaymo\u7684\u5b98\u65b9medium\u82f1\u6587\u89e3\u8bfb Imitation Learning\u7684\u5e38\u89c1\u95ee\u9898 \u4eceraw data\u5230\u5e95\u5c42 control\uff0cgeneralization\u96be\u5ea6\u5f88\u5927\uff0c\u4e0d\u9002\u7528\u4e8e\u4e0d\u540c\u7684\u4f20\u611f\u4e0e\u5e95\u5c42\u7269\u7406\u6a21\u578b\uff0c\u7f51\u7edc\u88ab\u8feb\u5f00\u73af\u5730\u5b66\u4e60\u5e95\u5c42\u7269\u7406\u6a21\u578b\uff0c\u6d6a\u8d39\u7f51\u7edc\u80fd\u529b\u3002 \u5373\u65f6\u8f6c\u6362\u4e3a\u672c\u6587\u7ed9\u51fa\u7684\u4e2d\u5c42\u8f93\u5165\u8f93\u51fa(processed percepetion and planning and map information -> target poses sequences),\u964d\u4f4e\u4e86\u7f51\u7edc\u7684\u4eff\u771f\u96be\u5ea6\uff0c30M\u7684\u6570\u636e\u70b9\u4ecd\u4e0d\u8db3\u4ee5\u4f7f\u4f20\u7edf\u7684Cloning\u7b97\u6cd5\u5f97\u5230\u597d\u7684\u7ed3\u679c\u3002 \u672c\u6587\u7f51\u7edc\u7684\u8f93\u5165\u8f93\u51fadata representation \u516b\u5f20\u56fe\u5206\u522b\u4e3a: 1. \u57ce\u5e02\u9053\u8def\u5730\u56fe 2. traffic light\u53ef\u901a\u884c\u4ee5\u53ca\u65f6\u95f4\u4fe1\u606f(\u5b9e\u9645\u4e0a\u662f\u7ed9\u4e86\u8fde\u7eed\u51e0\u5f20\u56fe\u7684) 3. \u901f\u5ea6\u9650\u5236 4. \u76ee\u6807\u8def\u5f84(\u7c7b\u4f3c\u5730\u56feAPP\u7684\u6307\u793a) 5. \u5f53\u524dagent\u4f4d\u7f6e 6. \u6700\u8fd1\u4e00\u7cfb\u5217\u7684\u52a8\u6001\u969c\u788d\u7269\u7684\u4f4d\u7f6e 7. \u8fc7\u53bb\u4e00\u6bb5\u65f6\u95f4\u7684agent poses 8. \u672a\u6765\u7684agent poses(\u8f93\u51fa) \u6240\u6709\u8f93\u5165\u56fe\u4ee5\u8f66\u8f86\u5f53\u524d\u5750\u6807\u7cfb\u7ed9\u51fa\uff0c\u8f66\u8f86\u5f53\u524dpose\u4f1a\u56fa\u5b9a\u5728\u4e00\u4e2a (u_0, v_0) \u70b9,\u8bad\u7ec3\u7684\u65f6\u5019\u4f1a\u989d\u5916\u5bf9\u6570\u636e\u4e2d\u7684\u8f66\u5b50\u7684heading\u52a0\u4e00\u4e2a\u6270\u52a8\uff0c\u76f8\u5f53\u4e8e\u8bad\u7ec3\u65f6\u7684\u8fd9\u4e9bfeature map\u4f1a\u76f8\u5bf9\u6709\u989d\u5916\u7684\u65cb\u8f6c\u3002 \u7f51\u7edc\u7ed3\u6784 \u6574\u4f53\u7ed3\u6784\u5982\u56fe\uff0c\u6838\u5fc3\u90e8\u5206\u4e3a\"\u8f93\u5165->\u7279\u5f81\u63d0\u53d6->RNN->\u671d\u5411\u3001\u901f\u5ea6\u3001\u672a\u6765\u76ee\u6807\u70b9\u3001\u5916\u6765heat map\"\u3002additional target \u5305\u62ecroad mask\u4ee5\u53ca\u4e00\u4e2adynamic object prediction \u4ee5\u4e0b\u52a8\u56fe\u8868\u8fbe\u4e86Agent RNN\u7684RNN\u7279\u5f81(\u5305\u62ecmemory) \u5411\u4e13\u5bb6\u6a21\u4eff\u5b66\u4e60 \u51e0\u4e2acost\u662f\u5e38\u89c1\u7684\uff0c\u8fd9\u91cc\u4e3b\u8981\u8bb0\u5f55\u4e00\u4e2atrick Past Motion Dropout \u8bad\u7ec3\u7684\u65f6\u5019\uff0c\u7531\u4e8e\u4e13\u5bb6\u7684\u8def\u5f84\u592a\u5e73\u6ed1\uff0c\u6709\u65f6\u5019\u53ea\u9700\u8981\u5bf9\u5148\u524d\u51e0\u4e2a\u65f6\u95f4\u70b9\u7684\u8def\u5f84\u70b9\u8fdb\u884c\u63d2\u503c\u5c31\u80fd\u987a\u5229\u5f97\u5230\u540e\u9762\u7684\u76ee\u6807\u70b9\uff0c\u4e14\u8bef\u5dee\u5f88\u5c0f\uff0c\u8fd9\u91cc\u4e3a\u4e86\u51cf\u8f7b\u8fd9\u4e2a\u95ee\u9898\uff0c\u5728\u8bad\u7ec3\u7684\u8fc7\u7a0b\u4e2d\u4f1a\u968f\u673adrop\u6389\u4e00\u4e9b\u5386\u53f2\u7684poses\uff0c\u5177\u4f53\u6765\u8bf4\u5c31\u662f50%\u7684training data\u91cc\u9762\u5386\u53f2poses\u4e3a\u7a7a\uff0c\u53ea\u5269\u4e0b\u5f53\u524dpose \u63d0\u5347\u96be\u5ea6 \u5408\u6210\u5e72\u6270 \u5c06\u4e00\u4e9b\u5e73\u6ed1\u7684\u4e13\u5bb6path\u4e2d\u95f4\uff0c\u968f\u673a\u9009\u4e00\u4e9b\u70b9\u6c34\u5e73\u6270\u52a8\uff0c\u7136\u540e\u7528\u5e73\u6ed1\u7684\u63d2\u503c\u91cd\u65b0\u751f\u6210\u5047\u7684\u4e13\u5bb6\u8f68\u8ff9\uff0c \u8fd9\u4e9b\u65b0\u7684\u8f68\u8ff9\u53ef\u80fd\u4f1a\u78b0\u649e\uff0c\u6240\u4ee5\u8fd9\u7c7bdata\u7684weight\u53ea\u6709\u6b63\u786edata\u76840.1\uff0c\u4e0d\u8fc7\u53ef\u4ee5\u5f88\u597d\u7684\u589e\u52a0\u6b63\u5e38\u53f8\u673a\u4e0d\u4f1a\u5230\u8fbe\u7684\u5371\u9669\u60c5\u666f \u8f85\u52a9loss \u78b0\u649e loss\uff0c\u4e3b\u8981\u5728\u4e8e\u60e9\u7f5aperturbation\u7684\u65f6\u5019\u7684\u4e00\u4e9b\u78b0\u649e on road loss: \u51e0\u4f55loss\uff0c\u52a0\u5f3a\u4e0e\u539f\u8f68\u8ff9\u7684\u91cd\u5408\u5ea6 road masking \u4e0e prediction \u6a21\u4effdropout \u6709\u4e00\u5b9a\u7684\u6982\u7387\u4e0d\u9700\u8981\u7f51\u7edc\u5b9e\u73b0imitation\uff0c\u8ba9imitation\u90e8\u5206loss\u4e3a0\uff0c\u53ea\u7559\u4e0b\u524d\u4e00\u6bb5\u5199\u5230\u7684\u9644\u52a0loss","title":"ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst"},{"location":"other_categories/Deep-Navigation/ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst/#chauffeurnet-learning-to-drive-by-imitating-the-best-and-synthesizing-the-worst","text":"\u8fd9\u7bc7RSS\u8bba\u6587\u6765\u81ea\u4e8eWaymo,\u82f1\u6587\u540d\u5b57\u7684\u7ffb\u8bd1\u610f\u601d\u662f\"\u53f8\u673a\u7f51\",\u7ed9\u51fa\u4e86\u4e00\u4e2aimitation learning\u7cfb\u7edf\uff0c\u5e76\u5b9e\u73b0\u4e86\u4e0a\u8f66\u6d4b\u8bd5\uff0c\u4e3a\u4e86\u4fdd\u8bc1\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u672c\u6587\u505a\u4e86\u5f88\u591a\u7684\u9009\u62e9\u4e0e\u52a0\u5f3a\uff0c\u503c\u5f97\u4e86\u89e3\u3002\u8fd9\u7bc7\u8bba\u6587\u6709 \u6765\u81eawaymo\u7684\u5b98\u65b9medium\u82f1\u6587\u89e3\u8bfb","title":"ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst"},{"location":"other_categories/Deep-Navigation/ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst/#imitation-learning","text":"\u4eceraw data\u5230\u5e95\u5c42 control\uff0cgeneralization\u96be\u5ea6\u5f88\u5927\uff0c\u4e0d\u9002\u7528\u4e8e\u4e0d\u540c\u7684\u4f20\u611f\u4e0e\u5e95\u5c42\u7269\u7406\u6a21\u578b\uff0c\u7f51\u7edc\u88ab\u8feb\u5f00\u73af\u5730\u5b66\u4e60\u5e95\u5c42\u7269\u7406\u6a21\u578b\uff0c\u6d6a\u8d39\u7f51\u7edc\u80fd\u529b\u3002 \u5373\u65f6\u8f6c\u6362\u4e3a\u672c\u6587\u7ed9\u51fa\u7684\u4e2d\u5c42\u8f93\u5165\u8f93\u51fa(processed percepetion and planning and map information -> target poses sequences),\u964d\u4f4e\u4e86\u7f51\u7edc\u7684\u4eff\u771f\u96be\u5ea6\uff0c30M\u7684\u6570\u636e\u70b9\u4ecd\u4e0d\u8db3\u4ee5\u4f7f\u4f20\u7edf\u7684Cloning\u7b97\u6cd5\u5f97\u5230\u597d\u7684\u7ed3\u679c\u3002","title":"Imitation Learning\u7684\u5e38\u89c1\u95ee\u9898"},{"location":"other_categories/Deep-Navigation/ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst/#data-representation","text":"\u516b\u5f20\u56fe\u5206\u522b\u4e3a: 1. \u57ce\u5e02\u9053\u8def\u5730\u56fe 2. traffic light\u53ef\u901a\u884c\u4ee5\u53ca\u65f6\u95f4\u4fe1\u606f(\u5b9e\u9645\u4e0a\u662f\u7ed9\u4e86\u8fde\u7eed\u51e0\u5f20\u56fe\u7684) 3. \u901f\u5ea6\u9650\u5236 4. \u76ee\u6807\u8def\u5f84(\u7c7b\u4f3c\u5730\u56feAPP\u7684\u6307\u793a) 5. \u5f53\u524dagent\u4f4d\u7f6e 6. \u6700\u8fd1\u4e00\u7cfb\u5217\u7684\u52a8\u6001\u969c\u788d\u7269\u7684\u4f4d\u7f6e 7. \u8fc7\u53bb\u4e00\u6bb5\u65f6\u95f4\u7684agent poses 8. \u672a\u6765\u7684agent poses(\u8f93\u51fa) \u6240\u6709\u8f93\u5165\u56fe\u4ee5\u8f66\u8f86\u5f53\u524d\u5750\u6807\u7cfb\u7ed9\u51fa\uff0c\u8f66\u8f86\u5f53\u524dpose\u4f1a\u56fa\u5b9a\u5728\u4e00\u4e2a (u_0, v_0) \u70b9,\u8bad\u7ec3\u7684\u65f6\u5019\u4f1a\u989d\u5916\u5bf9\u6570\u636e\u4e2d\u7684\u8f66\u5b50\u7684heading\u52a0\u4e00\u4e2a\u6270\u52a8\uff0c\u76f8\u5f53\u4e8e\u8bad\u7ec3\u65f6\u7684\u8fd9\u4e9bfeature map\u4f1a\u76f8\u5bf9\u6709\u989d\u5916\u7684\u65cb\u8f6c\u3002","title":"\u672c\u6587\u7f51\u7edc\u7684\u8f93\u5165\u8f93\u51fadata representation"},{"location":"other_categories/Deep-Navigation/ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst/#_1","text":"\u6574\u4f53\u7ed3\u6784\u5982\u56fe\uff0c\u6838\u5fc3\u90e8\u5206\u4e3a\"\u8f93\u5165->\u7279\u5f81\u63d0\u53d6->RNN->\u671d\u5411\u3001\u901f\u5ea6\u3001\u672a\u6765\u76ee\u6807\u70b9\u3001\u5916\u6765heat map\"\u3002additional target \u5305\u62ecroad mask\u4ee5\u53ca\u4e00\u4e2adynamic object prediction \u4ee5\u4e0b\u52a8\u56fe\u8868\u8fbe\u4e86Agent RNN\u7684RNN\u7279\u5f81(\u5305\u62ecmemory)","title":"\u7f51\u7edc\u7ed3\u6784"},{"location":"other_categories/Deep-Navigation/ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst/#_2","text":"\u51e0\u4e2acost\u662f\u5e38\u89c1\u7684\uff0c\u8fd9\u91cc\u4e3b\u8981\u8bb0\u5f55\u4e00\u4e2atrick","title":"\u5411\u4e13\u5bb6\u6a21\u4eff\u5b66\u4e60"},{"location":"other_categories/Deep-Navigation/ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst/#past-motion-dropout","text":"\u8bad\u7ec3\u7684\u65f6\u5019\uff0c\u7531\u4e8e\u4e13\u5bb6\u7684\u8def\u5f84\u592a\u5e73\u6ed1\uff0c\u6709\u65f6\u5019\u53ea\u9700\u8981\u5bf9\u5148\u524d\u51e0\u4e2a\u65f6\u95f4\u70b9\u7684\u8def\u5f84\u70b9\u8fdb\u884c\u63d2\u503c\u5c31\u80fd\u987a\u5229\u5f97\u5230\u540e\u9762\u7684\u76ee\u6807\u70b9\uff0c\u4e14\u8bef\u5dee\u5f88\u5c0f\uff0c\u8fd9\u91cc\u4e3a\u4e86\u51cf\u8f7b\u8fd9\u4e2a\u95ee\u9898\uff0c\u5728\u8bad\u7ec3\u7684\u8fc7\u7a0b\u4e2d\u4f1a\u968f\u673adrop\u6389\u4e00\u4e9b\u5386\u53f2\u7684poses\uff0c\u5177\u4f53\u6765\u8bf4\u5c31\u662f50%\u7684training data\u91cc\u9762\u5386\u53f2poses\u4e3a\u7a7a\uff0c\u53ea\u5269\u4e0b\u5f53\u524dpose","title":"Past Motion Dropout"},{"location":"other_categories/Deep-Navigation/ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst/#_3","text":"","title":"\u63d0\u5347\u96be\u5ea6"},{"location":"other_categories/Deep-Navigation/ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst/#_4","text":"\u5c06\u4e00\u4e9b\u5e73\u6ed1\u7684\u4e13\u5bb6path\u4e2d\u95f4\uff0c\u968f\u673a\u9009\u4e00\u4e9b\u70b9\u6c34\u5e73\u6270\u52a8\uff0c\u7136\u540e\u7528\u5e73\u6ed1\u7684\u63d2\u503c\u91cd\u65b0\u751f\u6210\u5047\u7684\u4e13\u5bb6\u8f68\u8ff9\uff0c \u8fd9\u4e9b\u65b0\u7684\u8f68\u8ff9\u53ef\u80fd\u4f1a\u78b0\u649e\uff0c\u6240\u4ee5\u8fd9\u7c7bdata\u7684weight\u53ea\u6709\u6b63\u786edata\u76840.1\uff0c\u4e0d\u8fc7\u53ef\u4ee5\u5f88\u597d\u7684\u589e\u52a0\u6b63\u5e38\u53f8\u673a\u4e0d\u4f1a\u5230\u8fbe\u7684\u5371\u9669\u60c5\u666f","title":"\u5408\u6210\u5e72\u6270"},{"location":"other_categories/Deep-Navigation/ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst/#loss","text":"\u78b0\u649e loss\uff0c\u4e3b\u8981\u5728\u4e8e\u60e9\u7f5aperturbation\u7684\u65f6\u5019\u7684\u4e00\u4e9b\u78b0\u649e on road loss: \u51e0\u4f55loss\uff0c\u52a0\u5f3a\u4e0e\u539f\u8f68\u8ff9\u7684\u91cd\u5408\u5ea6 road masking \u4e0e prediction","title":"\u8f85\u52a9loss"},{"location":"other_categories/Deep-Navigation/ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst/#dropout","text":"\u6709\u4e00\u5b9a\u7684\u6982\u7387\u4e0d\u9700\u8981\u7f51\u7edc\u5b9e\u73b0imitation\uff0c\u8ba9imitation\u90e8\u5206loss\u4e3a0\uff0c\u53ea\u7559\u4e0b\u524d\u4e00\u6bb5\u5199\u5230\u7684\u9644\u52a0loss","title":"\u6a21\u4effdropout"},{"location":"other_categories/Deep-Navigation/DriftingCaiRal/","text":"High-speed Autonomous Drifting with Deep Reinforcement Learning \u8fd9\u7bc7\u8bba\u6587\u662f\u5b9e\u9a8c\u5ba4\u5b66\u957f\u4eec\u7684\u4e00\u7bc7\u5408\u4f5c\u8bba\u6587\uff0c\u5b8c\u6210\u7684\u4efb\u52a1\u662f\u7528\u5f3a\u5316\u5b66\u4e60\u6559\u4f1a\u8f66\u5b50\u5728Carla\u4e2d\u6f02\u79fb,\u6210\u679c\u662f\u6210\u529f\u8ba9\u8f66\u5b50\u5728Carla\u8fbe\u5230\u8fd1100km/h\u7684\u8fc7\u5f2f\u901f\u5ea6\u3002\u672c\u6587\u6709\u4e00\u4e2a \u5b98\u65b9\u4e3b\u9875 \uff0c\u4ee5\u4e0b\u4e3a\u5176\u5728bilibili\u4e0a\u53d1\u5e03\u7684 \u89c6\u9891 \u5f3a\u5316\u5b66\u4e60\u5b9a\u4e49 \u5730\u56fe\u4e0e\u76ee\u6807\u8f68\u8ff9 \u5730\u56fe\u662f\u6839\u636e\u67d0\u77e5\u540d\u5361\u4e01\u8f66\u6e38\u620f\u7684\u5730\u56fe\u6539\u7f16\u7684\uff0c\u4f7f\u7528RoadRunner\u753b\u51fa\u6765\u5e76\u52a0\u8f7d\u5230Carla\u4e2d\u3002\u53c2\u8003\u8f68\u8ff9\u7531\u67d0\u53f8\u673a\u5728\u573a\u666f\u4e2d\u6a21\u62df\u9a7e\u9a76\u5f62\u6210\uff0c\u8981\u6c42\u662f\u5c3d\u53ef\u80fd\u5f00\u5f97\u5feb\u5e76\u4e14\u4f7f\u7528\u6f02\u79fb\u5f62\u6210\u5c16\u9510\u7684\u8f6c\u89d2\u3002 \u72b6\u6001\u53d8\u91cf\u4e0e\u884c\u52a8\u7a7a\u95f4 \u72b6\u6001\u53d8\u91cf\u5305\u542b:\u5f53\u524d\u8235\u89d2\uff0c\u5f53\u524d\u6cb9\u95e8\uff0c\u6b63\u5411\u3001\u6cd5\u5411\u3001\u603b\u901f\u5ea6\uff0c\u4fa7\u504f\u89d2\uff0c\u671d\u5411\u89d2\u3002 \u671d\u5411\u89d2\u7684Ground truth\u7531Vector Field Guidance(VFG)\u8ba1\u7b97\uff0c\u8fd9\u91cc\u5efa\u8bae\u53c2\u8003\u539f\u6587\u3002 \u72b6\u6001\u7a7a\u95f4\u4e3a: \\mathcal{S}=\\left\\{\\delta, \\tau, e_{y}, \\dot{e}_{y}, e_{\\psi}, \\dot{e}_{\\psi}, e_{\\beta}, \\dot{e}_{\\beta}, e_{v x}, \\dot{e}_{v x}, e_{v y}, \\dot{e}_{v y}, \\mathcal{T}\\right\\} \u5176\u4e2d \\mathcal{T} \u5305\u542b\u5341\u4e2a\u672a\u6765\u7684{ x, y, \\beta }\u76ee\u6807\u3002 \u884c\u52a8\u7a7a\u95f4\u4e3a\u4e3a\u5f52\u4e00\u5316\u5230[-1,1]\u7684\u8235\u89d2.Carla\u4e2dthrottle\u4e3a[0, 1],\u4f46\u662f\u4e3a\u4e86\u4f7f\u5f97\u8f66\u5b50\u5f00\u5f97\u5feb\uff0c\u52a0\u5feb\u8bad\u7ec3\uff0c\u8fd9\u91cc\u6709\u6548\u7684throttle\u8303\u56f4\u4e3a[0.6, 1]. \u8f93\u51fa\u503c\u7ecf\u4e00\u9636\u6570\u5b57\u6ee4\u6ce2\u5f97\u5230\u5b9e\u9645\u8f93\u5165\u5230Carla\u7684\u63a7\u5236\u503c\u3002 Reward\u51fd\u6570 \\begin{array}{ll}{r_{e_{y}}=e^{-k_{1} e_{y}}} \\\\ {r_{e_{\\psi}}, r_{e_{\\beta}}=f(x)=} & {\\left\\{\\begin{array}{cc}{e^{-k_{2}|x|}} & {|x|<90^{\\circ}} \\\\ {-e^{-k_{2}\\left(180^{\\circ}-x\\right)}} & {x \\geq 90^{\\circ}} \\\\ {-e^{-k_{2}\\left(180^{\\circ}+x\\right)}} & {x \\leq-90^{\\circ}}\\end{array}\\right.}\\end{array} r=v\\left(k_{e_{y}} r_{e_{y}}+k_{e_{\\psi}} r_{e_{\\psi}}+k_{e_{\\beta}} r_{e_{\\beta}}\\right) SAC \u7b97\u6cd5 \u8fd8\u6709\u4e00\u4e9b\u66f4\u4e3a\u5177\u4f53\u7684Trick\u5728\u8bba\u6587\u4e2d\u63d0\u5230\uff0c\u5efa\u8bae\u53c2\u8003\u5f00\u6e90\u4ee3\u7801\u3002 \u5b9e\u9a8c\u6548\u679c\u5efa\u8bae\u67e5\u8be2\u5176 \u5b98\u65b9\u4e3b\u9875 ,\u4e0e \u5b98\u65b9\u89c6\u9891","title":"High-speed Autonomous Drifting with Deep Reinforcement Learning"},{"location":"other_categories/Deep-Navigation/DriftingCaiRal/#high-speed-autonomous-drifting-with-deep-reinforcement-learning","text":"\u8fd9\u7bc7\u8bba\u6587\u662f\u5b9e\u9a8c\u5ba4\u5b66\u957f\u4eec\u7684\u4e00\u7bc7\u5408\u4f5c\u8bba\u6587\uff0c\u5b8c\u6210\u7684\u4efb\u52a1\u662f\u7528\u5f3a\u5316\u5b66\u4e60\u6559\u4f1a\u8f66\u5b50\u5728Carla\u4e2d\u6f02\u79fb,\u6210\u679c\u662f\u6210\u529f\u8ba9\u8f66\u5b50\u5728Carla\u8fbe\u5230\u8fd1100km/h\u7684\u8fc7\u5f2f\u901f\u5ea6\u3002\u672c\u6587\u6709\u4e00\u4e2a \u5b98\u65b9\u4e3b\u9875 \uff0c\u4ee5\u4e0b\u4e3a\u5176\u5728bilibili\u4e0a\u53d1\u5e03\u7684 \u89c6\u9891","title":"High-speed Autonomous Drifting with Deep Reinforcement Learning"},{"location":"other_categories/Deep-Navigation/DriftingCaiRal/#_1","text":"","title":"\u5f3a\u5316\u5b66\u4e60\u5b9a\u4e49"},{"location":"other_categories/Deep-Navigation/DriftingCaiRal/#_2","text":"\u5730\u56fe\u662f\u6839\u636e\u67d0\u77e5\u540d\u5361\u4e01\u8f66\u6e38\u620f\u7684\u5730\u56fe\u6539\u7f16\u7684\uff0c\u4f7f\u7528RoadRunner\u753b\u51fa\u6765\u5e76\u52a0\u8f7d\u5230Carla\u4e2d\u3002\u53c2\u8003\u8f68\u8ff9\u7531\u67d0\u53f8\u673a\u5728\u573a\u666f\u4e2d\u6a21\u62df\u9a7e\u9a76\u5f62\u6210\uff0c\u8981\u6c42\u662f\u5c3d\u53ef\u80fd\u5f00\u5f97\u5feb\u5e76\u4e14\u4f7f\u7528\u6f02\u79fb\u5f62\u6210\u5c16\u9510\u7684\u8f6c\u89d2\u3002","title":"\u5730\u56fe\u4e0e\u76ee\u6807\u8f68\u8ff9"},{"location":"other_categories/Deep-Navigation/DriftingCaiRal/#_3","text":"\u72b6\u6001\u53d8\u91cf\u5305\u542b:\u5f53\u524d\u8235\u89d2\uff0c\u5f53\u524d\u6cb9\u95e8\uff0c\u6b63\u5411\u3001\u6cd5\u5411\u3001\u603b\u901f\u5ea6\uff0c\u4fa7\u504f\u89d2\uff0c\u671d\u5411\u89d2\u3002 \u671d\u5411\u89d2\u7684Ground truth\u7531Vector Field Guidance(VFG)\u8ba1\u7b97\uff0c\u8fd9\u91cc\u5efa\u8bae\u53c2\u8003\u539f\u6587\u3002 \u72b6\u6001\u7a7a\u95f4\u4e3a: \\mathcal{S}=\\left\\{\\delta, \\tau, e_{y}, \\dot{e}_{y}, e_{\\psi}, \\dot{e}_{\\psi}, e_{\\beta}, \\dot{e}_{\\beta}, e_{v x}, \\dot{e}_{v x}, e_{v y}, \\dot{e}_{v y}, \\mathcal{T}\\right\\} \u5176\u4e2d \\mathcal{T} \u5305\u542b\u5341\u4e2a\u672a\u6765\u7684{ x, y, \\beta }\u76ee\u6807\u3002 \u884c\u52a8\u7a7a\u95f4\u4e3a\u4e3a\u5f52\u4e00\u5316\u5230[-1,1]\u7684\u8235\u89d2.Carla\u4e2dthrottle\u4e3a[0, 1],\u4f46\u662f\u4e3a\u4e86\u4f7f\u5f97\u8f66\u5b50\u5f00\u5f97\u5feb\uff0c\u52a0\u5feb\u8bad\u7ec3\uff0c\u8fd9\u91cc\u6709\u6548\u7684throttle\u8303\u56f4\u4e3a[0.6, 1]. \u8f93\u51fa\u503c\u7ecf\u4e00\u9636\u6570\u5b57\u6ee4\u6ce2\u5f97\u5230\u5b9e\u9645\u8f93\u5165\u5230Carla\u7684\u63a7\u5236\u503c\u3002","title":"\u72b6\u6001\u53d8\u91cf\u4e0e\u884c\u52a8\u7a7a\u95f4"},{"location":"other_categories/Deep-Navigation/DriftingCaiRal/#reward","text":"\\begin{array}{ll}{r_{e_{y}}=e^{-k_{1} e_{y}}} \\\\ {r_{e_{\\psi}}, r_{e_{\\beta}}=f(x)=} & {\\left\\{\\begin{array}{cc}{e^{-k_{2}|x|}} & {|x|<90^{\\circ}} \\\\ {-e^{-k_{2}\\left(180^{\\circ}-x\\right)}} & {x \\geq 90^{\\circ}} \\\\ {-e^{-k_{2}\\left(180^{\\circ}+x\\right)}} & {x \\leq-90^{\\circ}}\\end{array}\\right.}\\end{array} r=v\\left(k_{e_{y}} r_{e_{y}}+k_{e_{\\psi}} r_{e_{\\psi}}+k_{e_{\\beta}} r_{e_{\\beta}}\\right)","title":"Reward\u51fd\u6570"},{"location":"other_categories/Deep-Navigation/DriftingCaiRal/#sac","text":"\u8fd8\u6709\u4e00\u4e9b\u66f4\u4e3a\u5177\u4f53\u7684Trick\u5728\u8bba\u6587\u4e2d\u63d0\u5230\uff0c\u5efa\u8bae\u53c2\u8003\u5f00\u6e90\u4ee3\u7801\u3002 \u5b9e\u9a8c\u6548\u679c\u5efa\u8bae\u67e5\u8be2\u5176 \u5b98\u65b9\u4e3b\u9875 ,\u4e0e \u5b98\u65b9\u89c6\u9891","title":"SAC \u7b97\u6cd5"},{"location":"other_categories/Deep-Navigation/DroNet Learning to Fly by Driving/","text":"DroNet: Learning to Fly by Driving \u6838\u5fc3\u662f\u4e00\u4e2a\u6a21\u4eff\u5b66\u4e60\uff0c\u8f93\u51fa\u8235\u89d2\u4ee5\u53ca\u78b0\u649e\u6982\u7387\uff0c\u78b0\u649e\u6982\u7387\u6765\u81ea\u4e8e\u4f5c\u8005\u989d\u5916\u624b\u5de5\u6807\u6ce8\u7684\u6570\u636e\u96c6\u3002 \u7a81\u51fa\u7684\u7ed3\u679c\u662f\u7528\u65e0\u4eba\u8f66\u6536\u96c6\u7684\u6570\u636e\u80fd\u591f\u6269\u5c55\u5230\u65e0\u4eba\u673a\u4f7f\u7528\u3002","title":"DroNet: Learning to Fly by Driving"},{"location":"other_categories/Deep-Navigation/DroNet Learning to Fly by Driving/#dronet-learning-to-fly-by-driving","text":"\u6838\u5fc3\u662f\u4e00\u4e2a\u6a21\u4eff\u5b66\u4e60\uff0c\u8f93\u51fa\u8235\u89d2\u4ee5\u53ca\u78b0\u649e\u6982\u7387\uff0c\u78b0\u649e\u6982\u7387\u6765\u81ea\u4e8e\u4f5c\u8005\u989d\u5916\u624b\u5de5\u6807\u6ce8\u7684\u6570\u636e\u96c6\u3002 \u7a81\u51fa\u7684\u7ed3\u679c\u662f\u7528\u65e0\u4eba\u8f66\u6536\u96c6\u7684\u6570\u636e\u80fd\u591f\u6269\u5c55\u5230\u65e0\u4eba\u673a\u4f7f\u7528\u3002","title":"DroNet: Learning to Fly by Driving"},{"location":"other_categories/Deep-Navigation/End-to-end Driving Deploying through Uncertainty-Aware ImitationLearning and Stochastic Visual Domain Adaptation/","text":"End-to-end Driving Deploying through Uncertainty-Aware Imitation Learning and Stochastic Visual Domain Adaptation \u8fd9\u662f\u4e00\u7bc7\u672c\u5b9e\u9a8c\u5ba4\u5e08\u5144\u7684\u4e00\u7bc7\u6587\u7ae0\u3002\u8bb2\u7684\u662f\u7aef\u5230\u7aef\u7684\u5e26\u6709\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7684\u6a21\u4eff\u5b66\u4e60\u4ee5\u53catransfer learning\u7684\u4f5c\u7528 \u5e26\u6709\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7684\u6a21\u4eff\u5b66\u4e60 \u5c06\u56de\u5f52\u4efb\u52a1\u8f6c\u5316\u4e3a\u4ee5\u4e0b\u65b9\u7a0b: [y, \\sigma] = f^\\theta(x) L(\\theta)=\\frac{1}{2} \\frac{||y-\\hat y||^2}{\\sigma^2} + \\frac{1}{2}log \\sigma^2 \u65b9\u7a0b\u4e00\u662f\u795e\u7ecf\u7f51\u7edc\u7684forward pass\uff0c\u65b9\u7a0b\u4e8c\u662f\u56de\u5f52\u7684cost function\u3002 real-to-sim \u8f6c\u6362 \u5e08\u5144\u7684\u53e6\u4e00\u7bc7\u8bba\u6587\u53c8\u63d0\u5230\u4f7f\u7528Real-to-sim\u7684\u5b9e\u65f6\u8f6c\u6362\uff0c\u53ef\u4ee5\u8ba9\u5728simulation\u4e0b\u8bad\u7ec3\u7684agent\u5728\u9762\u5bf9\u73b0\u5b9e\u5f97\u5230\u7684\u56fe\u7247\u65f6\u6709\u66f4\u597d\u7684\u8868\u73b0\u3002\u672c\u6587\u7684\u601d\u8def\u662f\u5c06\u6d4b\u8bd5domain\u8f6c\u6362\u5230\u8bad\u7ec3\u7684\u4e09\u4e2adomain\u4e2d\uff0c\u5e76\u5206\u522b\u7ed9\u51fa\u8f93\u51fa\u3002","title":"End-to-end Driving Deploying through Uncertainty-Aware Imitation Learning and Stochastic Visual Domain Adaptation"},{"location":"other_categories/Deep-Navigation/End-to-end Driving Deploying through Uncertainty-Aware ImitationLearning and Stochastic Visual Domain Adaptation/#end-to-end-driving-deploying-through-uncertainty-aware-imitation-learning-and-stochastic-visual-domain-adaptation","text":"\u8fd9\u662f\u4e00\u7bc7\u672c\u5b9e\u9a8c\u5ba4\u5e08\u5144\u7684\u4e00\u7bc7\u6587\u7ae0\u3002\u8bb2\u7684\u662f\u7aef\u5230\u7aef\u7684\u5e26\u6709\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7684\u6a21\u4eff\u5b66\u4e60\u4ee5\u53catransfer learning\u7684\u4f5c\u7528","title":"End-to-end Driving Deploying through Uncertainty-Aware Imitation Learning and Stochastic Visual Domain Adaptation"},{"location":"other_categories/Deep-Navigation/End-to-end Driving Deploying through Uncertainty-Aware ImitationLearning and Stochastic Visual Domain Adaptation/#_1","text":"\u5c06\u56de\u5f52\u4efb\u52a1\u8f6c\u5316\u4e3a\u4ee5\u4e0b\u65b9\u7a0b: [y, \\sigma] = f^\\theta(x) L(\\theta)=\\frac{1}{2} \\frac{||y-\\hat y||^2}{\\sigma^2} + \\frac{1}{2}log \\sigma^2 \u65b9\u7a0b\u4e00\u662f\u795e\u7ecf\u7f51\u7edc\u7684forward pass\uff0c\u65b9\u7a0b\u4e8c\u662f\u56de\u5f52\u7684cost function\u3002","title":"\u5e26\u6709\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7684\u6a21\u4eff\u5b66\u4e60"},{"location":"other_categories/Deep-Navigation/End-to-end Driving Deploying through Uncertainty-Aware ImitationLearning and Stochastic Visual Domain Adaptation/#real-to-sim","text":"\u5e08\u5144\u7684\u53e6\u4e00\u7bc7\u8bba\u6587\u53c8\u63d0\u5230\u4f7f\u7528Real-to-sim\u7684\u5b9e\u65f6\u8f6c\u6362\uff0c\u53ef\u4ee5\u8ba9\u5728simulation\u4e0b\u8bad\u7ec3\u7684agent\u5728\u9762\u5bf9\u73b0\u5b9e\u5f97\u5230\u7684\u56fe\u7247\u65f6\u6709\u66f4\u597d\u7684\u8868\u73b0\u3002\u672c\u6587\u7684\u601d\u8def\u662f\u5c06\u6d4b\u8bd5domain\u8f6c\u6362\u5230\u8bad\u7ec3\u7684\u4e09\u4e2adomain\u4e2d\uff0c\u5e76\u5206\u522b\u7ed9\u51fa\u8f93\u51fa\u3002","title":"real-to-sim \u8f6c\u6362"},{"location":"other_categories/Deep-Navigation/Gaze  Training  by  Modulated  Dropout  Improves  Imitation  Learning/","text":"Gaze Training by Modulated Dropout Improves Imitation Learning \u8fd9\u7bc7\u8bba\u6587\u6e90\u81ea\u4e8e\u5b9e\u9a8c\u5ba4\u5e08\u59d0\u3002 \u6838\u5fc3\u8d21\u732e\uff0c\u7528encoder-decoder\u8bad\u7ec3\u4e00\u4e2aGaze_map\u751f\u6210\u7f51\u7edc(\u6570\u636e\u6765\u81ea\u4e8e\u4eba\u5de5\u6807\u6ce8),\u7136\u540e\u5728\u6a21\u4eff\u5b66\u4e60\u7684\u65f6\u5019\u4f7f\u7528Gaze-modulated Dropout,\u8fd9\u4e2a\u6a21\u5757\u7684\u601d\u8def\u662f\u5728\u4f7f\u7528dropout\u7684\u65f6\u5019\uff0c\u51cf\u5c11gaze_map\u76f8\u5173\u90e8\u5206\u7684dropout\uff0c\u5c31\u50cf\u4eba\u773c\u6ce8\u89c6\u5355\u4e00\u533a\u57df\u4e00\u6837\u3002\u6ce8\u610f\u8fd9\u91cc\u4f7f\u7528\u7684dropout\u662ftensorflow\u9ed8\u8ba4\u7248\u672c\u7684dropout\u800c\u4e0d\u662fpytorch\u9ed8\u8ba4\u7684dropout2d(spatial-dropout).","title":"Gaze  Training  by  Modulated  Dropout  Improves  Imitation  Learning"},{"location":"other_categories/Deep-Navigation/Gaze  Training  by  Modulated  Dropout  Improves  Imitation  Learning/#gaze-training-by-modulated-dropout-improves-imitation-learning","text":"\u8fd9\u7bc7\u8bba\u6587\u6e90\u81ea\u4e8e\u5b9e\u9a8c\u5ba4\u5e08\u59d0\u3002 \u6838\u5fc3\u8d21\u732e\uff0c\u7528encoder-decoder\u8bad\u7ec3\u4e00\u4e2aGaze_map\u751f\u6210\u7f51\u7edc(\u6570\u636e\u6765\u81ea\u4e8e\u4eba\u5de5\u6807\u6ce8),\u7136\u540e\u5728\u6a21\u4eff\u5b66\u4e60\u7684\u65f6\u5019\u4f7f\u7528Gaze-modulated Dropout,\u8fd9\u4e2a\u6a21\u5757\u7684\u601d\u8def\u662f\u5728\u4f7f\u7528dropout\u7684\u65f6\u5019\uff0c\u51cf\u5c11gaze_map\u76f8\u5173\u90e8\u5206\u7684dropout\uff0c\u5c31\u50cf\u4eba\u773c\u6ce8\u89c6\u5355\u4e00\u533a\u57df\u4e00\u6837\u3002\u6ce8\u610f\u8fd9\u91cc\u4f7f\u7528\u7684dropout\u662ftensorflow\u9ed8\u8ba4\u7248\u672c\u7684dropout\u800c\u4e0d\u662fpytorch\u9ed8\u8ba4\u7684dropout2d(spatial-dropout).","title":"Gaze  Training  by  Modulated  Dropout  Improves  Imitation  Learning"},{"location":"other_categories/Deep-Navigation/Robustness_to_Out-of-Distribution_Inputs_via_Task-Aware_Generative_Uncertainty/","text":"Robustness to Out-of-Distribution Inputs via Task-Aware Generative Uncertainty \u8d1d\u53f6\u65af\u7406\u8bba\u80cc\u666f \u7f51\u7edc\u8bad\u7ec3\u7684\u65f6\u5019\u76f8\u5f53\u4e8e\u5bfb\u627e\u53c2\u6570 w \u6ee1\u8db3 w_{MAP} =argmax_{w}\\sum_ip(y_i|x_i,A_i,w) \u5176\u4e2d y,x,A,w \u5206\u522b\u4e3a\u89c2\u6d4b\u503c\uff0c\u884c\u52a8\u5e8f\u5217\u4ee5\u53ca\u53c2\u6570\u77e2\u91cf\u3002\u8fd9\u4e2a\u65b9\u6cd5\u53ef\u4ee5\u4f30\u6d4b\u8f93\u51fa\u7ed3\u679c\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u4f46\u662f\u4e0d\u80fd\u4f30\u8ba1\u6a21\u578b\u672c\u8eab\u53c2\u6570\u9009\u62e9\u7684\u4e0d\u786e\u5b9a\u6027\u3002 p(y|x,A) = \\int p(y|x,A,w)p(w|D_{train})dw \u7406\u8bba\u4e0a\u6765\u8bf4\u8fd9\u4e2a\u79ef\u5206\u662f\u65e0\u6cd5\u6c42\u89e3\u7684\u3002 \u5c3d\u7ba1\u8d1d\u53f6\u65af\u65b9\u6cd5\u53ef\u4ee5\u5904\u7406\u7531\u4e8e\u6570\u636e\u91cf\u4e0d\u8db3\u5f15\u8d77\u7684\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\uff0c\u4f46\u662f\u5bf9\u4e8e\u4e0etraining data\u5206\u5e03\u4e0d\u540c\u7684\u8f93\u5165\uff0c\u5176\u4f30\u8ba1\u503c\u4e0d\u591f\u51c6\u786e\u3002\u8fd9\u4e9b\u60c5\u51b5\u8bb0\u4e3a p(y|x^*,A) \u7f51\u7edc\u4e0e\u5b9e\u9645\u7b97\u6cd5 \u8bad\u7ec3\u65f6\uff1a \u6839\u636e\u8f93\u5165\u56fe\u7247\uff0c\u8bad\u7ec3\u4e00\u4e2a VAE \uff0c\u53e6\u5916\u6b63\u5e38\u5730\u4f7f\u7528\u539f\u6765\u9700\u8981\u7684\u6a21\u578b(\u672c\u6587\u4e3a\u4e00\u4e2a\u5377\u79ef+LSTM\u6a21\u578b)\u5f97\u5230 p(y|x,A) \u6d4b\u8bd5\u65f6: \u5c06\u6d4b\u8bd5\u8f93\u5165\u653e\u5230VAE\u4e2d\uff0c\u5728\u4e2d\u95f4\u9690\u5c42\u4e2d\u591a\u6b21\u91c7\u6837\u5f97\u5230\u591a\u4e2a\u8f93\u51fa\u56fe\u7247\uff0c\u6b63\u5e38\u5730\u4f7f\u7528\u539f\u6765\u7684\u6a21\u578b\u5f97\u5230\u591a\u4e2a\u8f93\u51fa\u7ed3\u679c\uff0c\u5bf9\u5176\u6c42\u5747\u503c\u4e0e\u65b9\u5dee\u5f97\u5230\u5bf9\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u7684\u4f30\u8ba1 \u80cc\u540e\u7684\u4e00\u4e9b\u5206\u6790 \u672c\u6587\u4e00\u4e2a\u4e0e\u5176\u4ed6\u6587\u7ae0\u4e0d\u540c\u7684\u7406\u7531\u662f\uff0c\u4e0d\u5e94\u8be5\u5355\u7eaf\u5730\u56e0\u4e3a\u6d4b\u8bd5\u65f6\u8f93\u5165\u56fe\u7247\u4e0e\u8bad\u7ec3\u65f6\u4e0d\u540c\u5c31\u5224\u65ad\u7ed3\u679c\u4f1a\u6709\u5f88\u5927\u7684\u4e0d\u786e\u5b9a\u6027\u3002\u7b80\u5355\u7684\u4f8b\u5b50\u6bd4\u5982\u8bf4\u5929\u82b1\u677f\u7684\u989c\u8272\uff0c\u5982\u679c\u6d4b\u8bd5\u65f6\u4e0e\u8bad\u7ec3\u65f6\u4e0d\u540c\uff0c\u4e00\u4e2a\u6b63\u5e38\u597d\u7684\u673a\u5668\u4eba\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e0d\u4f1a\u56e0\u6b64\u5f97\u5230\u4e0d\u540c\u7684\u884c\u52a8\u8f93\u51fa\uff0c\"\u8f93\u51fa\u7ed3\u679c\u7684\u4e0d\u786e\u5b9a\u6027\u4e0d\u4f1a\u56e0\u65e0\u5173\u90e8\u5206\u7684\u533a\u522b\u800c\u63d0\u5347\"\u3002\u8fd9\u4e2a\u60c5\u51b5\u5728\u672c\u6587\u7684\u6a21\u578b\u4e2d\u4e5f\u6709\u6240\u4f53\u73b0\uff0c\u4f5c\u8005\u5b9e\u9a8c\u5ba4\u80fd\u53d1\u73b0VAE\u6d4b\u8bd5\u65f6\u8f93\u51fa\u7684\u56fe\u7247\u7684\u5929\u82b1\u677f\u989c\u8272\u4e0e\u5b9e\u9645\u7684\u8f93\u5165\u4e0d\u7b26\u5408\uff0c\u4f46\u662f\u6700\u7ec8\u8f93\u51fa\u7684\u884c\u52a8\u5dee\u522b\u4e0d\u5927\uff0c\u4e5f\u5c31\u4e0d\u4f1a\u63d0\u5347\u5bf9\u5e94\u7684\u4e0d\u786e\u5b9a\u6027\u3002\u8fd9\u4e5f\u662f\u4f5c\u8005\u5728\u4f30\u8ba1\u4e0d\u786e\u5b9a\u6027\u7684\u65f6\u5019\uff0c\u575a\u6301\u8981\u53bb\u5230\u6700\u540e\u884c\u52a8\u8f93\u51fa\u65f6\u518d\u4f30\u8ba1\u4e0d\u786e\u5b9a\u6027\uff0c\u800c\u4e0d\u662f\u4ece\u56fe\u50cf\u7684\u8f93\u5165\u5c31\u5f00\u59cb\u4f30\u8ba1\u3002","title":"Robustness to Out-of-Distribution Inputs via Task-Aware Generative Uncertainty"},{"location":"other_categories/Deep-Navigation/Robustness_to_Out-of-Distribution_Inputs_via_Task-Aware_Generative_Uncertainty/#robustness-to-out-of-distribution-inputs-via-task-aware-generative-uncertainty","text":"","title":"Robustness to Out-of-Distribution Inputs via Task-Aware Generative Uncertainty"},{"location":"other_categories/Deep-Navigation/Robustness_to_Out-of-Distribution_Inputs_via_Task-Aware_Generative_Uncertainty/#_1","text":"\u7f51\u7edc\u8bad\u7ec3\u7684\u65f6\u5019\u76f8\u5f53\u4e8e\u5bfb\u627e\u53c2\u6570 w \u6ee1\u8db3 w_{MAP} =argmax_{w}\\sum_ip(y_i|x_i,A_i,w) \u5176\u4e2d y,x,A,w \u5206\u522b\u4e3a\u89c2\u6d4b\u503c\uff0c\u884c\u52a8\u5e8f\u5217\u4ee5\u53ca\u53c2\u6570\u77e2\u91cf\u3002\u8fd9\u4e2a\u65b9\u6cd5\u53ef\u4ee5\u4f30\u6d4b\u8f93\u51fa\u7ed3\u679c\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u4f46\u662f\u4e0d\u80fd\u4f30\u8ba1\u6a21\u578b\u672c\u8eab\u53c2\u6570\u9009\u62e9\u7684\u4e0d\u786e\u5b9a\u6027\u3002 p(y|x,A) = \\int p(y|x,A,w)p(w|D_{train})dw \u7406\u8bba\u4e0a\u6765\u8bf4\u8fd9\u4e2a\u79ef\u5206\u662f\u65e0\u6cd5\u6c42\u89e3\u7684\u3002 \u5c3d\u7ba1\u8d1d\u53f6\u65af\u65b9\u6cd5\u53ef\u4ee5\u5904\u7406\u7531\u4e8e\u6570\u636e\u91cf\u4e0d\u8db3\u5f15\u8d77\u7684\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\uff0c\u4f46\u662f\u5bf9\u4e8e\u4e0etraining data\u5206\u5e03\u4e0d\u540c\u7684\u8f93\u5165\uff0c\u5176\u4f30\u8ba1\u503c\u4e0d\u591f\u51c6\u786e\u3002\u8fd9\u4e9b\u60c5\u51b5\u8bb0\u4e3a p(y|x^*,A)","title":"\u8d1d\u53f6\u65af\u7406\u8bba\u80cc\u666f"},{"location":"other_categories/Deep-Navigation/Robustness_to_Out-of-Distribution_Inputs_via_Task-Aware_Generative_Uncertainty/#_2","text":"\u8bad\u7ec3\u65f6\uff1a \u6839\u636e\u8f93\u5165\u56fe\u7247\uff0c\u8bad\u7ec3\u4e00\u4e2a VAE \uff0c\u53e6\u5916\u6b63\u5e38\u5730\u4f7f\u7528\u539f\u6765\u9700\u8981\u7684\u6a21\u578b(\u672c\u6587\u4e3a\u4e00\u4e2a\u5377\u79ef+LSTM\u6a21\u578b)\u5f97\u5230 p(y|x,A) \u6d4b\u8bd5\u65f6: \u5c06\u6d4b\u8bd5\u8f93\u5165\u653e\u5230VAE\u4e2d\uff0c\u5728\u4e2d\u95f4\u9690\u5c42\u4e2d\u591a\u6b21\u91c7\u6837\u5f97\u5230\u591a\u4e2a\u8f93\u51fa\u56fe\u7247\uff0c\u6b63\u5e38\u5730\u4f7f\u7528\u539f\u6765\u7684\u6a21\u578b\u5f97\u5230\u591a\u4e2a\u8f93\u51fa\u7ed3\u679c\uff0c\u5bf9\u5176\u6c42\u5747\u503c\u4e0e\u65b9\u5dee\u5f97\u5230\u5bf9\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u7684\u4f30\u8ba1","title":"\u7f51\u7edc\u4e0e\u5b9e\u9645\u7b97\u6cd5"},{"location":"other_categories/Deep-Navigation/Robustness_to_Out-of-Distribution_Inputs_via_Task-Aware_Generative_Uncertainty/#_3","text":"\u672c\u6587\u4e00\u4e2a\u4e0e\u5176\u4ed6\u6587\u7ae0\u4e0d\u540c\u7684\u7406\u7531\u662f\uff0c\u4e0d\u5e94\u8be5\u5355\u7eaf\u5730\u56e0\u4e3a\u6d4b\u8bd5\u65f6\u8f93\u5165\u56fe\u7247\u4e0e\u8bad\u7ec3\u65f6\u4e0d\u540c\u5c31\u5224\u65ad\u7ed3\u679c\u4f1a\u6709\u5f88\u5927\u7684\u4e0d\u786e\u5b9a\u6027\u3002\u7b80\u5355\u7684\u4f8b\u5b50\u6bd4\u5982\u8bf4\u5929\u82b1\u677f\u7684\u989c\u8272\uff0c\u5982\u679c\u6d4b\u8bd5\u65f6\u4e0e\u8bad\u7ec3\u65f6\u4e0d\u540c\uff0c\u4e00\u4e2a\u6b63\u5e38\u597d\u7684\u673a\u5668\u4eba\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e0d\u4f1a\u56e0\u6b64\u5f97\u5230\u4e0d\u540c\u7684\u884c\u52a8\u8f93\u51fa\uff0c\"\u8f93\u51fa\u7ed3\u679c\u7684\u4e0d\u786e\u5b9a\u6027\u4e0d\u4f1a\u56e0\u65e0\u5173\u90e8\u5206\u7684\u533a\u522b\u800c\u63d0\u5347\"\u3002\u8fd9\u4e2a\u60c5\u51b5\u5728\u672c\u6587\u7684\u6a21\u578b\u4e2d\u4e5f\u6709\u6240\u4f53\u73b0\uff0c\u4f5c\u8005\u5b9e\u9a8c\u5ba4\u80fd\u53d1\u73b0VAE\u6d4b\u8bd5\u65f6\u8f93\u51fa\u7684\u56fe\u7247\u7684\u5929\u82b1\u677f\u989c\u8272\u4e0e\u5b9e\u9645\u7684\u8f93\u5165\u4e0d\u7b26\u5408\uff0c\u4f46\u662f\u6700\u7ec8\u8f93\u51fa\u7684\u884c\u52a8\u5dee\u522b\u4e0d\u5927\uff0c\u4e5f\u5c31\u4e0d\u4f1a\u63d0\u5347\u5bf9\u5e94\u7684\u4e0d\u786e\u5b9a\u6027\u3002\u8fd9\u4e5f\u662f\u4f5c\u8005\u5728\u4f30\u8ba1\u4e0d\u786e\u5b9a\u6027\u7684\u65f6\u5019\uff0c\u575a\u6301\u8981\u53bb\u5230\u6700\u540e\u884c\u52a8\u8f93\u51fa\u65f6\u518d\u4f30\u8ba1\u4e0d\u786e\u5b9a\u6027\uff0c\u800c\u4e0d\u662f\u4ece\u56fe\u50cf\u7684\u8f93\u5165\u5c31\u5f00\u59cb\u4f30\u8ba1\u3002","title":"\u80cc\u540e\u7684\u4e00\u4e9b\u5206\u6790"},{"location":"other_categories/SLAM/CubeSLAM/","text":"CubeSLAM: Monocular 3D Object SLAM \u8fd9\u7bc7\u6587\u7ae0\u5c06\u5355\u76ee3D\u7269\u4f53\u68c0\u6d4b\u4ee5\u53ca\u5355\u76eeSLAM\u653e\u5728\u540c\u4e00\u4e2a\u6846\u67b6\u91cc\u9762\u4f18\u5316\uff0c\u5f97\u5230\u7684\u7ed3\u679c\u662f\u540c\u65f6\u66f4\u4f18\u5316\u7684SLAM\u7ed3\u679c\u4ee5\u53ca\u68c0\u6d4b\u7ed3\u679c\u3002\u8fd9\u7bc7\u6587\u7ae0\u5c5e\u4e8e\u6240\u8c13\u7269\u4f53\u7ea7\u7684SLAM\u3002 \u5355\u76ee\u56fe\u7247\u7406\u89e3 \u5355\u76ee3D proposal\u751f\u6210 \u672c\u6587\u7684\u601d\u8def\u662f\u901a\u8fc7\u4e00\u4e2a\u89d2\u70b9\u52a0\u4e0a\u6d88\u5931\u70b9&\u65cb\u8f6c\u77e9\u9635\u4ee5\u53ca2D \u68c0\u6d4b\u6846\u8fd8\u539f\u4e09\u7ef4\u7ed3\u679c\u3002 \u7531\u65cb\u8f6c\u77e9\u9635\u5f97\u5230\u957f\u65b9\u5f62\u6846\u4e09\u4e2a\u6d88\u5931\u70b9\u7684\u516c\u5f0f\u4e3a: VP_i = KR_{col(i)}, i\\in \\{1,2,3\\} \u7531\u4e0a\u56fe\u53ef\u77e5,\u4ee5a\u5c0f\u56fe\u4e3a\u4f8b,\u5728\u5df2\u77e5\u6d88\u5931\u70b9\u4ee5\u53ca p_1 \u7684\u60c5\u51b5\u4e0b,\u5176\u4f59\u7684\u70b9\u53ef\u4ee5\u7528\u6c42\u4ea4\u70b9\u7684\u65b9\u5f0f\u5f97\u5230 p_2 = (VP_1, p1) \\times (B, C), p_4 = (VP_2, p1) \\times (A, D), p_3 = (VP_1, p_4)\\times(VP_2, p_2), p_5 = (VP_3, p_3) \\times (C, D), p_6 = (VP_2, p_5) \\times(VP_2, p_5), p_7=(VP_3, p_1)\\times(VP_1, p_6), p_8 = (VP_3, p_4)\\times(VP_2, p_7) \u4e8b\u5b9e\u4e0a\u540e\u9762\u7684\u70b9\u9009\u62e9\u7a7a\u95f4\u5f88\u5927. \u5f97\u5230\u89d2\u70b9\u540e\u8fdb\u4e00\u6b65\u6536\u7f29\u81ea\u7531\u5ea6 \u5bf9\u4e8e\u4efb\u610f\u59ff\u6001\u7684\u7269\u4f53\uff0c\u9009\u53d6\u4e0d\u5171\u9762\u7684\u56db\u4e2a\u89d2\u70b9\u59821,2,4,7\u8fdb\u884cPnP\u6c42\u89e3 \u5bf9\u4e8e\u5730\u9762\u4e0a\u7684\u7269\u4f53\uff0c\u5047\u8bbe\u5176roll,pitch\u89d2\u5ea6\u90fd\u4e3a0\u5ea6\uff0c\u5c31\u53ef\u4ee5\u4e0d\u4f7f\u7528PnP\u6c42\u89e3\u4e86\uff0c\u53ef\u4ee5\u6839\u636e\u76f8\u673a\u9ad8\u5ea6\u5c06\u5e95\u9762\u7684\u89d2\u70b9\u76f4\u63a5\u6295\u5f71\u5230\u4e16\u754c\u5750\u6807\u4e2d \u4e00\u822c\u6765\u8bf4\uff0c\u6211\u4eec\u53ef\u4ee5\u7528\u795e\u7ecf\u7f51\u7edc\u76f4\u63a5\u8f93\u51fa\u89d2\u5ea6\uff0c\u4f46\u662f\u8fd9\u91cc\u4e3a\u4e86\u63d0\u9ad8\u6cdb\u5316\u6027\u80fd\uff0c\u9009\u62e9\u91c7\u6837\u5e76\u5404\u81ea\u8bc4\u5206\u4ee5\u8ba1\u7b97\u65cb\u8f6c\u77e9\u9635\u3002 Proposal \u8bc4\u5206 \u603b\u4f53\u635f\u5931\u51fd\u6570\u4e3a: E(O|I) = \\phi_{dist}(O, I) + w_1\\phi_{angle}(O,I) + w_2 \\phi_{shape}(O) \u5176\u4e2d O \u4e3a\u635f\u5931\u51fd\u6570, w \u4e3a\u6743\u91cd\u8d85\u53c2\u6570 \\phi_{dist} ,\u5bf9\u56fe\u7247\u8fd0\u884ccanny edge\uff0c\u57fa\u4e8e\u6b64\u5efa\u7acbdistance map\uff0c\u5bf9\u6bcf\u4e00\u4e2a\u7ad6\u7ebf\uff0c\u91c7\u683710\u4e2a\u70b9\uff0c\u8ba1\u7b97\u8ddd\u79bb\u56fe\u4e2d\u7684\u8ddd\u79bb\u503c\u603b\u548c\uff0c\u6700\u540e\u5f97\u5206\u9664\u4ee52D\u6846\u7684\u5bf9\u89d2\u7ebf\u957f\u5ea6 \\phi_{angle} \u524d\u4e00\u4e2a\u51fd\u6570\u5bf9false positive\u7684\u5c0f\u76f4\u7ebf\u6bb5\u975e\u5e38\u654f\u611f\uff0c\u9996\u5148\u627e\u51fa\u4e0a\u4e0b\u9762\u7684\u957f\u8fb9\uff0c\u627e\u51fa\u76f8\u5bf9\u6d88\u5931\u70b9\u503e\u659c\u89d2\u6700\u5927\u4e0e\u6700\u5c0f\u7684. \\left\\langle a, b \\right\\rangle \u4e3a\u70b9 a,b \u76f4\u7ebf\u7684\u503e\u659c\u89d2\uff0c \\begin{aligned} \\phi_{\\text {angle}}(O, I)=& \\sum_{i=1: 3}\\left\\|\\left\\langle l_{i_{-} m s}, l_{i_{-} m t}\\right\\rangle-\\left\\langle\\mathrm{VP}_{i}, l_{i_{-} m t}\\right\\rangle\\right\\|+\\\\ &\\left\\|\\left\\langle l_{i_{-} n s}, l_{i_{-} n t}\\right\\rangle-\\left\\langle\\mathrm{VP}_{i}, l_{i_{-} n t}\\right\\rangle\\right\\| \\end{aligned} \u672c\u8d28\u4e0a\u662f\u8981\u6c42\u957f\u8fb9\u7ecf\u8fc7\u6d88\u5931\u70b9 \\phi_{shape} \u5982\u679c\u957f\u5bbd\u6bd4\u5f88\u5927\u7684\uff0c\u7ed9\u4e88\u4e00\u4e2a\u60e9\u7f5a\u3002 SLAM bundle adjustment\u95ee\u9898 \u8bb0\u76f8\u673a\u59ff\u6001\u30013D\u7269\u4f53\u3001\u7279\u5f81\u70b9\u5206\u522b\u4e3a C = \\{C_i\\}, O = \\{O_j\\}, P = \\{P_k\\} , BA\u5c31\u63cf\u8ff0\u4e3a\u4ee5\u4e0b\u7684\u6700\u5c0f\u4e8c\u4e58\u95ee\u9898 \\begin{aligned} C^{*}, O^{*}, P^{*}=& \\underset{\\{C, O, P\\}}{\\arg \\min } \\sum_{C_{i}, O_{j}, P_{k}}\\left\\|\\mathbf{e}\\left(c_{i}, o_{j}\\right)\\right\\|_{\\Sigma_{i j}}^{2}+\\\\ &\\left\\|\\mathbf{e}\\left(c_{i}, p_{k}\\right)\\right\\|_{\\Sigma_{i k}}^{2}+\\left\\|\\mathbf{e}\\left(o_{j}, p_{k}\\right)\\right\\|_{\\Sigma_{j k}}^{2} \\end{aligned} \u53f3\u4e0b\u89d2\u7684 \\sum \u8868\u8fbe\u7684\u662f\u4e0d\u540c\u8bef\u5dee\u4e4b\u95f4\u7684\u534f\u65b9\u5dee \u8bef\u5dee\u9879 \u76f8\u673a\u3001\u7269\u4f53\u4e0e\u4e16\u754c\u5750\u6807\u7cfb\u7684\u8f6c\u6362\u5e94\u4e0e\u76f8\u673a\u4e2d\u7269\u4f53\u7684\u76f8\u5bf9\u8f6c\u6362\u6709\u5bf9\u5e94 e_{c o_{-} 3 D}=\\left[\\log \\left(\\left(T_{c}^{-1} T_{o}\\right) T_{o m}^{-1}\\right)_{\\mathrm{se}_{3}}^{\\vee} \\quad \\mathbf{d}-\\mathbf{d}_{m}\\right] \u5176\u4e2d T = \\{R |t\\}, d \u4e3adimension 2. 3D\u7269\u4f53\u5728\u6295\u5f71\u5230\u76f8\u673a\u4e2d\uff0c\u4e0e2D\u6846\u7684\u4e2d\u5fc3\u3001\u957f\u5bbd\u7684\u8bef\u5dee e_{co\\_2D} = [c, s] - [c_m, s_m] 3. \u7269\u4f53\u4e0e\u70b9\u7684\u5bf9\u5e94\uff0c\u5df2\u77e5\u70b9P\u5728\u7269\u4f53O\u4e2d,\u90a3\u4e48\u5982\u679c\u70b9P\u4e0d\u5728\u8fd9\u4e2a3D\u6846\u91cc\u9762\u5c31\u7ed9\u4e88\u60e9\u7f5a. e_{op} = max(|T_o^{-1}P| - d_m, 0) 4. \u70b9\u4e0e\u76f8\u673a\u7684\u5bf9\u5e94\uff0c\u4e0e\u4f20\u7edf\u7684feature-based SLAM\u4e00\u81f4\u3002 e_{cp} = \\pi(T_c^{-1}P) - z_m \u5176\u4e2d z_m \u4e3a\u70b9P\u539f\u672c\u88ab\u89c2\u5bdf\u5230\u7684\u76f8\u673a\u5750\u6807\u3002 \u4f5c\u8005\u8fdb\u4e00\u6b65\u8ba8\u8bba\u4e86\u52a8\u6001\u573a\u666f\u4e2d\u7684SLAM,\u8fd9\u91cc\u7701\u7565","title":"CubeSLAM: Monocular 3D Object SLAM"},{"location":"other_categories/SLAM/CubeSLAM/#cubeslam-monocular-3d-object-slam","text":"\u8fd9\u7bc7\u6587\u7ae0\u5c06\u5355\u76ee3D\u7269\u4f53\u68c0\u6d4b\u4ee5\u53ca\u5355\u76eeSLAM\u653e\u5728\u540c\u4e00\u4e2a\u6846\u67b6\u91cc\u9762\u4f18\u5316\uff0c\u5f97\u5230\u7684\u7ed3\u679c\u662f\u540c\u65f6\u66f4\u4f18\u5316\u7684SLAM\u7ed3\u679c\u4ee5\u53ca\u68c0\u6d4b\u7ed3\u679c\u3002\u8fd9\u7bc7\u6587\u7ae0\u5c5e\u4e8e\u6240\u8c13\u7269\u4f53\u7ea7\u7684SLAM\u3002","title":"CubeSLAM: Monocular 3D Object SLAM"},{"location":"other_categories/SLAM/CubeSLAM/#_1","text":"","title":"\u5355\u76ee\u56fe\u7247\u7406\u89e3"},{"location":"other_categories/SLAM/CubeSLAM/#3d-proposal","text":"\u672c\u6587\u7684\u601d\u8def\u662f\u901a\u8fc7\u4e00\u4e2a\u89d2\u70b9\u52a0\u4e0a\u6d88\u5931\u70b9&\u65cb\u8f6c\u77e9\u9635\u4ee5\u53ca2D \u68c0\u6d4b\u6846\u8fd8\u539f\u4e09\u7ef4\u7ed3\u679c\u3002 \u7531\u65cb\u8f6c\u77e9\u9635\u5f97\u5230\u957f\u65b9\u5f62\u6846\u4e09\u4e2a\u6d88\u5931\u70b9\u7684\u516c\u5f0f\u4e3a: VP_i = KR_{col(i)}, i\\in \\{1,2,3\\} \u7531\u4e0a\u56fe\u53ef\u77e5,\u4ee5a\u5c0f\u56fe\u4e3a\u4f8b,\u5728\u5df2\u77e5\u6d88\u5931\u70b9\u4ee5\u53ca p_1 \u7684\u60c5\u51b5\u4e0b,\u5176\u4f59\u7684\u70b9\u53ef\u4ee5\u7528\u6c42\u4ea4\u70b9\u7684\u65b9\u5f0f\u5f97\u5230 p_2 = (VP_1, p1) \\times (B, C), p_4 = (VP_2, p1) \\times (A, D), p_3 = (VP_1, p_4)\\times(VP_2, p_2), p_5 = (VP_3, p_3) \\times (C, D), p_6 = (VP_2, p_5) \\times(VP_2, p_5), p_7=(VP_3, p_1)\\times(VP_1, p_6), p_8 = (VP_3, p_4)\\times(VP_2, p_7) \u4e8b\u5b9e\u4e0a\u540e\u9762\u7684\u70b9\u9009\u62e9\u7a7a\u95f4\u5f88\u5927. \u5f97\u5230\u89d2\u70b9\u540e\u8fdb\u4e00\u6b65\u6536\u7f29\u81ea\u7531\u5ea6 \u5bf9\u4e8e\u4efb\u610f\u59ff\u6001\u7684\u7269\u4f53\uff0c\u9009\u53d6\u4e0d\u5171\u9762\u7684\u56db\u4e2a\u89d2\u70b9\u59821,2,4,7\u8fdb\u884cPnP\u6c42\u89e3 \u5bf9\u4e8e\u5730\u9762\u4e0a\u7684\u7269\u4f53\uff0c\u5047\u8bbe\u5176roll,pitch\u89d2\u5ea6\u90fd\u4e3a0\u5ea6\uff0c\u5c31\u53ef\u4ee5\u4e0d\u4f7f\u7528PnP\u6c42\u89e3\u4e86\uff0c\u53ef\u4ee5\u6839\u636e\u76f8\u673a\u9ad8\u5ea6\u5c06\u5e95\u9762\u7684\u89d2\u70b9\u76f4\u63a5\u6295\u5f71\u5230\u4e16\u754c\u5750\u6807\u4e2d \u4e00\u822c\u6765\u8bf4\uff0c\u6211\u4eec\u53ef\u4ee5\u7528\u795e\u7ecf\u7f51\u7edc\u76f4\u63a5\u8f93\u51fa\u89d2\u5ea6\uff0c\u4f46\u662f\u8fd9\u91cc\u4e3a\u4e86\u63d0\u9ad8\u6cdb\u5316\u6027\u80fd\uff0c\u9009\u62e9\u91c7\u6837\u5e76\u5404\u81ea\u8bc4\u5206\u4ee5\u8ba1\u7b97\u65cb\u8f6c\u77e9\u9635\u3002","title":"\u5355\u76ee3D proposal\u751f\u6210"},{"location":"other_categories/SLAM/CubeSLAM/#proposal","text":"\u603b\u4f53\u635f\u5931\u51fd\u6570\u4e3a: E(O|I) = \\phi_{dist}(O, I) + w_1\\phi_{angle}(O,I) + w_2 \\phi_{shape}(O) \u5176\u4e2d O \u4e3a\u635f\u5931\u51fd\u6570, w \u4e3a\u6743\u91cd\u8d85\u53c2\u6570 \\phi_{dist} ,\u5bf9\u56fe\u7247\u8fd0\u884ccanny edge\uff0c\u57fa\u4e8e\u6b64\u5efa\u7acbdistance map\uff0c\u5bf9\u6bcf\u4e00\u4e2a\u7ad6\u7ebf\uff0c\u91c7\u683710\u4e2a\u70b9\uff0c\u8ba1\u7b97\u8ddd\u79bb\u56fe\u4e2d\u7684\u8ddd\u79bb\u503c\u603b\u548c\uff0c\u6700\u540e\u5f97\u5206\u9664\u4ee52D\u6846\u7684\u5bf9\u89d2\u7ebf\u957f\u5ea6 \\phi_{angle} \u524d\u4e00\u4e2a\u51fd\u6570\u5bf9false positive\u7684\u5c0f\u76f4\u7ebf\u6bb5\u975e\u5e38\u654f\u611f\uff0c\u9996\u5148\u627e\u51fa\u4e0a\u4e0b\u9762\u7684\u957f\u8fb9\uff0c\u627e\u51fa\u76f8\u5bf9\u6d88\u5931\u70b9\u503e\u659c\u89d2\u6700\u5927\u4e0e\u6700\u5c0f\u7684. \\left\\langle a, b \\right\\rangle \u4e3a\u70b9 a,b \u76f4\u7ebf\u7684\u503e\u659c\u89d2\uff0c \\begin{aligned} \\phi_{\\text {angle}}(O, I)=& \\sum_{i=1: 3}\\left\\|\\left\\langle l_{i_{-} m s}, l_{i_{-} m t}\\right\\rangle-\\left\\langle\\mathrm{VP}_{i}, l_{i_{-} m t}\\right\\rangle\\right\\|+\\\\ &\\left\\|\\left\\langle l_{i_{-} n s}, l_{i_{-} n t}\\right\\rangle-\\left\\langle\\mathrm{VP}_{i}, l_{i_{-} n t}\\right\\rangle\\right\\| \\end{aligned} \u672c\u8d28\u4e0a\u662f\u8981\u6c42\u957f\u8fb9\u7ecf\u8fc7\u6d88\u5931\u70b9 \\phi_{shape} \u5982\u679c\u957f\u5bbd\u6bd4\u5f88\u5927\u7684\uff0c\u7ed9\u4e88\u4e00\u4e2a\u60e9\u7f5a\u3002","title":"Proposal \u8bc4\u5206"},{"location":"other_categories/SLAM/CubeSLAM/#slam","text":"","title":"SLAM"},{"location":"other_categories/SLAM/CubeSLAM/#bundle-adjustment","text":"\u8bb0\u76f8\u673a\u59ff\u6001\u30013D\u7269\u4f53\u3001\u7279\u5f81\u70b9\u5206\u522b\u4e3a C = \\{C_i\\}, O = \\{O_j\\}, P = \\{P_k\\} , BA\u5c31\u63cf\u8ff0\u4e3a\u4ee5\u4e0b\u7684\u6700\u5c0f\u4e8c\u4e58\u95ee\u9898 \\begin{aligned} C^{*}, O^{*}, P^{*}=& \\underset{\\{C, O, P\\}}{\\arg \\min } \\sum_{C_{i}, O_{j}, P_{k}}\\left\\|\\mathbf{e}\\left(c_{i}, o_{j}\\right)\\right\\|_{\\Sigma_{i j}}^{2}+\\\\ &\\left\\|\\mathbf{e}\\left(c_{i}, p_{k}\\right)\\right\\|_{\\Sigma_{i k}}^{2}+\\left\\|\\mathbf{e}\\left(o_{j}, p_{k}\\right)\\right\\|_{\\Sigma_{j k}}^{2} \\end{aligned} \u53f3\u4e0b\u89d2\u7684 \\sum \u8868\u8fbe\u7684\u662f\u4e0d\u540c\u8bef\u5dee\u4e4b\u95f4\u7684\u534f\u65b9\u5dee","title":"bundle adjustment\u95ee\u9898"},{"location":"other_categories/SLAM/CubeSLAM/#_2","text":"\u76f8\u673a\u3001\u7269\u4f53\u4e0e\u4e16\u754c\u5750\u6807\u7cfb\u7684\u8f6c\u6362\u5e94\u4e0e\u76f8\u673a\u4e2d\u7269\u4f53\u7684\u76f8\u5bf9\u8f6c\u6362\u6709\u5bf9\u5e94 e_{c o_{-} 3 D}=\\left[\\log \\left(\\left(T_{c}^{-1} T_{o}\\right) T_{o m}^{-1}\\right)_{\\mathrm{se}_{3}}^{\\vee} \\quad \\mathbf{d}-\\mathbf{d}_{m}\\right] \u5176\u4e2d T = \\{R |t\\}, d \u4e3adimension 2. 3D\u7269\u4f53\u5728\u6295\u5f71\u5230\u76f8\u673a\u4e2d\uff0c\u4e0e2D\u6846\u7684\u4e2d\u5fc3\u3001\u957f\u5bbd\u7684\u8bef\u5dee e_{co\\_2D} = [c, s] - [c_m, s_m] 3. \u7269\u4f53\u4e0e\u70b9\u7684\u5bf9\u5e94\uff0c\u5df2\u77e5\u70b9P\u5728\u7269\u4f53O\u4e2d,\u90a3\u4e48\u5982\u679c\u70b9P\u4e0d\u5728\u8fd9\u4e2a3D\u6846\u91cc\u9762\u5c31\u7ed9\u4e88\u60e9\u7f5a. e_{op} = max(|T_o^{-1}P| - d_m, 0) 4. \u70b9\u4e0e\u76f8\u673a\u7684\u5bf9\u5e94\uff0c\u4e0e\u4f20\u7edf\u7684feature-based SLAM\u4e00\u81f4\u3002 e_{cp} = \\pi(T_c^{-1}P) - z_m \u5176\u4e2d z_m \u4e3a\u70b9P\u539f\u672c\u88ab\u89c2\u5bdf\u5230\u7684\u76f8\u673a\u5750\u6807\u3002 \u4f5c\u8005\u8fdb\u4e00\u6b65\u8ba8\u8bba\u4e86\u52a8\u6001\u573a\u666f\u4e2d\u7684SLAM,\u8fd9\u91cc\u7701\u7565","title":"\u8bef\u5dee\u9879"},{"location":"other_categories/SLAM/DeepICP:_An_End-to-End_Deep_Neural_Network_for_3D_Point_Cloud_Registration/","text":"DeepICP: An End-to-End Deep Neural Network for 3D Point Cloud Registration \u7aef\u5230\u7aef\u65b9\u6cd5\u5b9e\u73b0\u57fa\u4e8ekeypoint\u7684\u70b9\u4e91ICP,\u8f93\u5165\u662f\u4e24\u5e27\u76f8\u90bb\u7684\u70b9\u4e91\uff0c\u4e00\u4e2a\u5bf9\u4e8e\u76f8\u5bf9\u8fd0\u52a8\u7684\u521d\u59cb\u4f30\u8ba1\u3002 \u6574\u4f53\u7ed3\u6784 \u7279\u5f81\u63d0\u53d6\u5c42 \u4e24\u5e27\u70b9\u4e91\u9996\u5148\u8f93\u5165\u5230\u4e00\u4e2a\u5171\u7528\u7684\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u3002\u4f7f\u7528\u7684\u7f51\u7edc\u4e0ePointNet++\u4e00\u81f4\u3002\u4f5c\u8005\u7684\u4e00\u4e2a\u7406\u8bba\u662f\u8bf4\u8fd9\u91cc\u4f1a\u5e26\u6709\u4e00\u4e9b\u8bed\u4e49\u4fe1\u606f\uff0c\u8fd9\u4e9b\u8bed\u4e49\u4fe1\u606f\u53ef\u4ee5\u6709\u6548\u5730\u5e2e\u52a9\u907f\u514d\u52a8\u6001\u7269\u4f53\u3002 \u70b9\u52a0\u6743 \u7406\u8bba\u4e0a\u6765\u8bf4\uff0c\u5177\u6709\u5f3a\u7279\u5f81\u7684\u70b9\u5e94\u8be5\u4f1a\u5206\u914d\u66f4\u5927\u7684\u6743\u91cd\u3002\u8fd9\u91cc\u7684\u505a\u6cd5\u662f\u5bf9\u6bcf\u4e00\u4e2a\u70b9\u8fdb\u884c\u4e09\u5c42\u5168\u8fde\u63a5\uff0c\u524d\u9762\u4e24\u5c42\u5e26\u6709batchnorm\u4ee5\u53caReLU\uff0c\u6700\u540e\u4e00\u5c42softplus\u6fc0\u6d3b: y = ln(1 + e^x) ,\u6700\u540e\u9009\u51fa\u8f93\u51fa\u6743\u91cd\u6700\u5927\u7684N\u4e2a\u70b9\uff0c\u8fd9\u4e9b\u70b9\u4ee5\u53ca\u5bf9\u5e94\u7684\u6743\u91cd\u5728\u540e\u7eed\u7ee7\u7eed\u4f7f\u7528\u3002 \u6df1\u5ea6\u7279\u5f81\u63d0\u53d6(embedding) \u4f7f\u7528\u4e00\u4e2amini-PointNet(\u6709\u5f85\u5f15\u7528\u8bf4\u660e), \u5bf9\u524d\u9762\u63d0\u51fa\u7684N\u4e2akeypoint\uff0c\u5728\u534a\u5f84\u4e3a d \u7684\u8303\u56f4\u5185\uff0c\u6536\u96c6K\u4e2a\u4e34\u8fd1\u70b9(\u53ef\u91cd\u590d),\u5bf9\u8fd9\u4e9b\u70b9\uff0c\u628a\u4ed6\u4eec\u7684\u76f8\u5bf9\u5750\u6807normalized by d \uff0c\u518d\u52a0\u4e0alidar\u5f3a\u5ea6\uff0c\u8fd9\u4e9b\u7279\u5f81\u4e0e\u7279\u5f81\u63d0\u53d6\u5c42\u7684\u7279\u5f81concat\uff0c mini-pointNet \u7531\u4e09\u5c42\u5168\u8fde\u63a5\u548cmax-pooling\u7ec4\u6210\uff0c\u8f93\u5165\u662f N\\times K \\times 36 \u7684\u77e2\u91cf\uff0c\u8f93\u51fa\u662f\u4e00\u4e2a,\u8f93\u51fa\u4ecd\u7136\u662f N\\times 32 \u7ef4\u7684\u5411\u91cf \u5bf9\u5e94\u70b9\u751f\u6210 \u4f20\u7edfICP\u76f4\u63a5\u9009\u62e9\u6700\u9760\u8fd1\u7684\u70b9\u6700\u4e3a\u5bf9\u5e94\u70b9\uff0c\u8fd9\u4f7f\u5f97\u53cd\u5411\u4f20\u64ad\u65e0\u6cd5\u8fdb\u884c\uff0c\u800c\u4e14\u7531\u4e8e\u70b9\u4e91\u7684\u7a00\u758f\u7279\u6027\uff0c\u5f88\u591a\u65f6\u5019\u6839\u672c\u4e0d\u5b58\u5728\u5bf9\u5e94\u70b9\uff0c\u8fd9\u91cc\u63d0\u51fa\u4e86\u4f7f\u7528CPG\u5c42. \u9996\u5148\u5c06N\u4e2a\u5728\u6e90\u70b9\u4e91\u7684keypoint\u901a\u8fc7\u9884\u4f30\u8ba1\u7684\u8f6c\u79fb\u77e9\u9635\u8fdb\u884c\u4e00\u6b21\u5750\u6807\u53d8\u6362\u3002\u5728\u8f6c\u6362\u540e\u7684\u4f4d\u7f6e\u4e0a\uff0c\u5c06\u5b83\u7684\u4e34\u8fd1\u7a7a\u95f4\u5206\u4e3a (\\frac{2r}{s} + 1, \\frac{2r}{s} + 1, \\frac{2r}{s} + 1) 3D\u7f51\u683c\uff0c\u6bcf\u4e00\u4e2a\u7f51\u683c\u7684\u4e2d\u5fc3{ y^{'}_j, j=1,...,C }\u53ef\u7406\u89e3\u4e3a\u53ef\u80fd\u7684\u5bf9\u5e94\u70b9\uff0c\u4e0e\u524d\u6587\u6df1\u5ea6\u7279\u5f81\u63d0\u53d6\u4e00\u81f4\uff0c\u4f7f\u7528\u7279\u5f81\u63d0\u53d6\u5f97\u5230 N\\times C \\times 32 \u7684\u77e2\u91cf\u3002\u6765\u81ea\u6e90\u57df\u4e0e\u76ee\u6807\u57df\u7684\u7279\u5f81\u9001\u52303D CNN + softmax\u4e2d\uff0c\u76ee\u6807\u662f\u5b66\u4e60\u4e00\u4e2asimilarity distance metric. Loss \u51fd\u6570 \u5bf9\u4e8e\u6bcf\u4e00\u4e2akeypoint\uff0c\u6211\u4eec\u901a\u8fc7GT\u53ef\u4ee5\u77e5\u9053\u5b83\u6700\u540e\u7684cooresponding points\uff0c\u7528GT\u7684\u5bf9\u5e94\u70b9\u4e0e\u9884\u6d4b\u7684\u5bf9\u5e94\u70b9\u4e4b\u95f4\u7684\u8bef\u5dee\u53ef\u4ee5\u7ed9\u51fa\u4e00\u4e2aLoss \u5c06\u6240\u6709\u7684\u5bf9\u5e94\u70b9\u878d\u5408\u8d77\u6765\uff0c\u53ef\u4ee5\u7528SVD\u6c42\u51faR\uff0cT\uff0c\u7528RT\u4ee3\u66ff\u9884\u6d4b\u7684\u5bf9\u5e94\u70b9\u6c42\u51fa\u7b2c\u4e8c\u4e2aloss\uff0cTensorflow\u63d0\u4f9b\u4e86\u53ef\u5fae\u5206\u7684SVD\u5b9e\u73b0\uff0c \u6700\u7ec8loss\u4e3a\u4e24\u8005\u7684\u878d\u5408","title":"DeepICP: An End-to-End Deep Neural Network for 3D Point Cloud Registration"},{"location":"other_categories/SLAM/DeepICP:_An_End-to-End_Deep_Neural_Network_for_3D_Point_Cloud_Registration/#deepicp-an-end-to-end-deep-neural-network-for-3d-point-cloud-registration","text":"\u7aef\u5230\u7aef\u65b9\u6cd5\u5b9e\u73b0\u57fa\u4e8ekeypoint\u7684\u70b9\u4e91ICP,\u8f93\u5165\u662f\u4e24\u5e27\u76f8\u90bb\u7684\u70b9\u4e91\uff0c\u4e00\u4e2a\u5bf9\u4e8e\u76f8\u5bf9\u8fd0\u52a8\u7684\u521d\u59cb\u4f30\u8ba1\u3002","title":"DeepICP: An End-to-End Deep Neural Network for 3D Point Cloud Registration"},{"location":"other_categories/SLAM/DeepICP:_An_End-to-End_Deep_Neural_Network_for_3D_Point_Cloud_Registration/#_1","text":"","title":"\u6574\u4f53\u7ed3\u6784"},{"location":"other_categories/SLAM/DeepICP:_An_End-to-End_Deep_Neural_Network_for_3D_Point_Cloud_Registration/#_2","text":"\u4e24\u5e27\u70b9\u4e91\u9996\u5148\u8f93\u5165\u5230\u4e00\u4e2a\u5171\u7528\u7684\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u3002\u4f7f\u7528\u7684\u7f51\u7edc\u4e0ePointNet++\u4e00\u81f4\u3002\u4f5c\u8005\u7684\u4e00\u4e2a\u7406\u8bba\u662f\u8bf4\u8fd9\u91cc\u4f1a\u5e26\u6709\u4e00\u4e9b\u8bed\u4e49\u4fe1\u606f\uff0c\u8fd9\u4e9b\u8bed\u4e49\u4fe1\u606f\u53ef\u4ee5\u6709\u6548\u5730\u5e2e\u52a9\u907f\u514d\u52a8\u6001\u7269\u4f53\u3002","title":"\u7279\u5f81\u63d0\u53d6\u5c42"},{"location":"other_categories/SLAM/DeepICP:_An_End-to-End_Deep_Neural_Network_for_3D_Point_Cloud_Registration/#_3","text":"\u7406\u8bba\u4e0a\u6765\u8bf4\uff0c\u5177\u6709\u5f3a\u7279\u5f81\u7684\u70b9\u5e94\u8be5\u4f1a\u5206\u914d\u66f4\u5927\u7684\u6743\u91cd\u3002\u8fd9\u91cc\u7684\u505a\u6cd5\u662f\u5bf9\u6bcf\u4e00\u4e2a\u70b9\u8fdb\u884c\u4e09\u5c42\u5168\u8fde\u63a5\uff0c\u524d\u9762\u4e24\u5c42\u5e26\u6709batchnorm\u4ee5\u53caReLU\uff0c\u6700\u540e\u4e00\u5c42softplus\u6fc0\u6d3b: y = ln(1 + e^x) ,\u6700\u540e\u9009\u51fa\u8f93\u51fa\u6743\u91cd\u6700\u5927\u7684N\u4e2a\u70b9\uff0c\u8fd9\u4e9b\u70b9\u4ee5\u53ca\u5bf9\u5e94\u7684\u6743\u91cd\u5728\u540e\u7eed\u7ee7\u7eed\u4f7f\u7528\u3002","title":"\u70b9\u52a0\u6743"},{"location":"other_categories/SLAM/DeepICP:_An_End-to-End_Deep_Neural_Network_for_3D_Point_Cloud_Registration/#embedding","text":"\u4f7f\u7528\u4e00\u4e2amini-PointNet(\u6709\u5f85\u5f15\u7528\u8bf4\u660e), \u5bf9\u524d\u9762\u63d0\u51fa\u7684N\u4e2akeypoint\uff0c\u5728\u534a\u5f84\u4e3a d \u7684\u8303\u56f4\u5185\uff0c\u6536\u96c6K\u4e2a\u4e34\u8fd1\u70b9(\u53ef\u91cd\u590d),\u5bf9\u8fd9\u4e9b\u70b9\uff0c\u628a\u4ed6\u4eec\u7684\u76f8\u5bf9\u5750\u6807normalized by d \uff0c\u518d\u52a0\u4e0alidar\u5f3a\u5ea6\uff0c\u8fd9\u4e9b\u7279\u5f81\u4e0e\u7279\u5f81\u63d0\u53d6\u5c42\u7684\u7279\u5f81concat\uff0c mini-pointNet \u7531\u4e09\u5c42\u5168\u8fde\u63a5\u548cmax-pooling\u7ec4\u6210\uff0c\u8f93\u5165\u662f N\\times K \\times 36 \u7684\u77e2\u91cf\uff0c\u8f93\u51fa\u662f\u4e00\u4e2a,\u8f93\u51fa\u4ecd\u7136\u662f N\\times 32 \u7ef4\u7684\u5411\u91cf","title":"\u6df1\u5ea6\u7279\u5f81\u63d0\u53d6(embedding)"},{"location":"other_categories/SLAM/DeepICP:_An_End-to-End_Deep_Neural_Network_for_3D_Point_Cloud_Registration/#_4","text":"\u4f20\u7edfICP\u76f4\u63a5\u9009\u62e9\u6700\u9760\u8fd1\u7684\u70b9\u6700\u4e3a\u5bf9\u5e94\u70b9\uff0c\u8fd9\u4f7f\u5f97\u53cd\u5411\u4f20\u64ad\u65e0\u6cd5\u8fdb\u884c\uff0c\u800c\u4e14\u7531\u4e8e\u70b9\u4e91\u7684\u7a00\u758f\u7279\u6027\uff0c\u5f88\u591a\u65f6\u5019\u6839\u672c\u4e0d\u5b58\u5728\u5bf9\u5e94\u70b9\uff0c\u8fd9\u91cc\u63d0\u51fa\u4e86\u4f7f\u7528CPG\u5c42. \u9996\u5148\u5c06N\u4e2a\u5728\u6e90\u70b9\u4e91\u7684keypoint\u901a\u8fc7\u9884\u4f30\u8ba1\u7684\u8f6c\u79fb\u77e9\u9635\u8fdb\u884c\u4e00\u6b21\u5750\u6807\u53d8\u6362\u3002\u5728\u8f6c\u6362\u540e\u7684\u4f4d\u7f6e\u4e0a\uff0c\u5c06\u5b83\u7684\u4e34\u8fd1\u7a7a\u95f4\u5206\u4e3a (\\frac{2r}{s} + 1, \\frac{2r}{s} + 1, \\frac{2r}{s} + 1) 3D\u7f51\u683c\uff0c\u6bcf\u4e00\u4e2a\u7f51\u683c\u7684\u4e2d\u5fc3{ y^{'}_j, j=1,...,C }\u53ef\u7406\u89e3\u4e3a\u53ef\u80fd\u7684\u5bf9\u5e94\u70b9\uff0c\u4e0e\u524d\u6587\u6df1\u5ea6\u7279\u5f81\u63d0\u53d6\u4e00\u81f4\uff0c\u4f7f\u7528\u7279\u5f81\u63d0\u53d6\u5f97\u5230 N\\times C \\times 32 \u7684\u77e2\u91cf\u3002\u6765\u81ea\u6e90\u57df\u4e0e\u76ee\u6807\u57df\u7684\u7279\u5f81\u9001\u52303D CNN + softmax\u4e2d\uff0c\u76ee\u6807\u662f\u5b66\u4e60\u4e00\u4e2asimilarity distance metric.","title":"\u5bf9\u5e94\u70b9\u751f\u6210"},{"location":"other_categories/SLAM/DeepICP:_An_End-to-End_Deep_Neural_Network_for_3D_Point_Cloud_Registration/#loss","text":"\u5bf9\u4e8e\u6bcf\u4e00\u4e2akeypoint\uff0c\u6211\u4eec\u901a\u8fc7GT\u53ef\u4ee5\u77e5\u9053\u5b83\u6700\u540e\u7684cooresponding points\uff0c\u7528GT\u7684\u5bf9\u5e94\u70b9\u4e0e\u9884\u6d4b\u7684\u5bf9\u5e94\u70b9\u4e4b\u95f4\u7684\u8bef\u5dee\u53ef\u4ee5\u7ed9\u51fa\u4e00\u4e2aLoss \u5c06\u6240\u6709\u7684\u5bf9\u5e94\u70b9\u878d\u5408\u8d77\u6765\uff0c\u53ef\u4ee5\u7528SVD\u6c42\u51faR\uff0cT\uff0c\u7528RT\u4ee3\u66ff\u9884\u6d4b\u7684\u5bf9\u5e94\u70b9\u6c42\u51fa\u7b2c\u4e8c\u4e2aloss\uff0cTensorflow\u63d0\u4f9b\u4e86\u53ef\u5fae\u5206\u7684SVD\u5b9e\u73b0\uff0c \u6700\u7ec8loss\u4e3a\u4e24\u8005\u7684\u878d\u5408","title":"Loss \u51fd\u6570"},{"location":"other_categories/SLAM/Joint_Unsupervised_Learning_of_Optical_Flow_and_Depth_by_Watching_Stereo_Videos/","text":"Joint Unsupervised Learning of Optical Flow and Depth by Watching Stereo Videos \u6b63\u5982\u9898\u76ee\u8868\u793a\uff0c\u672c\u6587\u7684\u76ee\u6807\u662f\u4f7f\u7528\u8fde\u7eed\u7684\u53cc\u76ee\u89c6\u9891\uff0c\u540c\u65f6\u9884\u6d4b\u5149\u6d41\u3001\u6df1\u5ea6\u4ee5\u53ca\u76f8\u673a\u8fd0\u52a8\u3002\u5927\u5e45\u5ea6\u91cd\u7528\u524d\u4eba\u7684\u7814\u7a76\uff0c\u7279\u70b9\u662f\u6ce8\u91cd\u5bf9\u8fd0\u52a8\u4ee5\u53ca\u906e\u6321\u7269\u4f53\u7684\u53bb\u9664 \u4e3b\u4f53\u6d41\u7a0b\u56fe \u8fd9\u4e2apipeline\u5206\u4e3a\u597d\u51e0\u4e2astages \u9996\u5148\uff0c\u7528PWC-Flow\u9884\u6d4b\u5de6\u76ee\u76f8\u673a\u7684\u4e24\u5f20\u56fe\u4e4b\u95f4\u7684\u5149\u6d41 F_{12}^{opt} \uff0c\u7528MotionNet\u9884\u6d4b\u5de6\u76ee\u76f8\u673a\u4e24\u5f20\u56fe\u4e4b\u95f4\u7684\u8fd0\u52a8 T_{12} , \u7528PWD-Disp\u4f30\u8ba1\u53cc\u76ee\u76f8\u673a\u4e4b\u95f4\u7684\u89c6\u5dee\uff0c\u7528\u89c6\u5dee\u53ef\u4ee5\u8f6c\u6362\u4e3a\u6df1\u5ea6 D = B f_x / d \u3002 \u7b2c\u4e8c\uff0c\u7ed3\u5408 D_1, T_{12} \uff0c\u6211\u4eec\u53ef\u4ee5\u8ba1\u7b97\u51fa\u56e0\u76f8\u673a\u521a\u4f53\u8fd0\u52a8\u800c\u4ea7\u751f\u7684\u5149\u6d41\uff0c\u8bb0\u4e3a F^{rig}_{12} \uff0c\u56fe\u4e2d\u672a\u5448\u73b0\u3002\u7136\u540erigid-alignment module\u5c06\u76f8\u673a\u8fd0\u52a8\u4ece T_{12} \u7cbe\u4fee\u4e3a T_{12}' ,\u5e76\u8fdb\u4e00\u6b65\u5f97\u5230\u7cbe\u4fee\u7684 F^{rig'}_{12} \u7b2c\u4e09\uff0cConsistency check\u53bb\u9664\u8fd0\u52a8\u533a\u57df\u3002 \u7b2c\u4e00\u3001\u7f51\u7edc\u7ed3\u6784 PWC-Flow\u6309\u7167 \u8fd9\u7bc7\u6587\u7ae0 \u7684 \u4ecb\u7ecd MotionNet\u6309\u7167 \u8fd9\u7bc7\u6587\u7ae0 \u7684 \u4ecb\u7ecd PWC-Disp\u4ecePWC-Flow\u66f4\u6539\uff0c\u5728Cost volumn\u8ba1\u7b97\u7684\u65f6\u5019\u5f3a\u8feb\u5b83\u53ea\u5728\u6c34\u5e73\u65b9\u5411\u4e0a\u641c\u7d22\uff0c\u8f93\u51fa\u5f62\u72b6\u81ea\u7136\u53d8\u6210\u4e86 d\\times H \\times W \u7b2c\u4e8c\u3001Rigid Alighment Module \u8fd9\u4e2a\u6a21\u5757\u76ee\u6807\u662f\u7b2c\u4e00\u6b65\u7cbe\u4fee \u9996\u5148\u901a\u8fc7 Q_t(i,j) = D_t(i,j) K^{-1P_t(i,j)} \u5c06\u5f53\u524d\u56fe\u50cf\u8f6c\u6362\u4e3a\u76f8\u673a\u5750\u6807\u7cfb\uff0c3D\u7a7a\u95f4\u4e2d\u7684\u70b9\uff0c\u7136\u540e\u4f7f\u7528 T_{12} \u8f6c\u6362\uff0c\u5f97\u5230\u5bf9\u5e94\u70b9\u5728\u7b2c\u4e8c\u65f6\u523b\u76f8\u673a\u5750\u6807\u7cfb\u4e2d\u7684\u70b9 \\hat Q_1 \u3002 \\widetilde Q_1 \u5219\u8868\u793a Q_2 \u901a\u8fc7\u5149\u6d41 F^{opt}_{12} \u56de\u5230\u7b2c\u4e00\u65f6\u523b\u7684\u5750\u6807\uff0c \u901a\u8fc7\u6c42\u89e3\u4ee5\u4e0a\u4e24\u4e2a\u6b65\u9aa4\uff0c\u53ef\u4ee5\u5f97\u5230\u7cbe\u4fee\u7684T \u7b2c\u4e09\u3001Consistent Check \u7cbe\u4fee\u7684rigid\u5149\u6d41\u4e0e\u7f51\u7edc\u5149\u6d41\u7684\u5dee\u4e2d\uff0c\u503c\u8fc7\u5927\u6216\u8005\u88ab\u906e\u6321\u7684\u90e8\u5206\u4f1a\u88ab\u8fc7\u6ee4\u6389\uff0c\u4f7f\u7528thresholding\u7ed9\u51fa\u4e00\u4e2amask\uff0c\u53ea\u6709mask\u4e2d\u8ba4\u4e3a\u662f\u9759\u6b62\u7269\u4f53\u7684\u624d\u4f1a\u8fdb\u884closs\u8ba1\u7b97\u3002","title":"Joint Unsupervised Learning of Optical Flow and Depth by Watching Stereo Videos"},{"location":"other_categories/SLAM/Joint_Unsupervised_Learning_of_Optical_Flow_and_Depth_by_Watching_Stereo_Videos/#joint-unsupervised-learning-of-optical-flow-and-depth-by-watching-stereo-videos","text":"\u6b63\u5982\u9898\u76ee\u8868\u793a\uff0c\u672c\u6587\u7684\u76ee\u6807\u662f\u4f7f\u7528\u8fde\u7eed\u7684\u53cc\u76ee\u89c6\u9891\uff0c\u540c\u65f6\u9884\u6d4b\u5149\u6d41\u3001\u6df1\u5ea6\u4ee5\u53ca\u76f8\u673a\u8fd0\u52a8\u3002\u5927\u5e45\u5ea6\u91cd\u7528\u524d\u4eba\u7684\u7814\u7a76\uff0c\u7279\u70b9\u662f\u6ce8\u91cd\u5bf9\u8fd0\u52a8\u4ee5\u53ca\u906e\u6321\u7269\u4f53\u7684\u53bb\u9664","title":"Joint Unsupervised Learning of Optical Flow and Depth by Watching Stereo Videos"},{"location":"other_categories/SLAM/Joint_Unsupervised_Learning_of_Optical_Flow_and_Depth_by_Watching_Stereo_Videos/#_1","text":"\u8fd9\u4e2apipeline\u5206\u4e3a\u597d\u51e0\u4e2astages \u9996\u5148\uff0c\u7528PWC-Flow\u9884\u6d4b\u5de6\u76ee\u76f8\u673a\u7684\u4e24\u5f20\u56fe\u4e4b\u95f4\u7684\u5149\u6d41 F_{12}^{opt} \uff0c\u7528MotionNet\u9884\u6d4b\u5de6\u76ee\u76f8\u673a\u4e24\u5f20\u56fe\u4e4b\u95f4\u7684\u8fd0\u52a8 T_{12} , \u7528PWD-Disp\u4f30\u8ba1\u53cc\u76ee\u76f8\u673a\u4e4b\u95f4\u7684\u89c6\u5dee\uff0c\u7528\u89c6\u5dee\u53ef\u4ee5\u8f6c\u6362\u4e3a\u6df1\u5ea6 D = B f_x / d \u3002 \u7b2c\u4e8c\uff0c\u7ed3\u5408 D_1, T_{12} \uff0c\u6211\u4eec\u53ef\u4ee5\u8ba1\u7b97\u51fa\u56e0\u76f8\u673a\u521a\u4f53\u8fd0\u52a8\u800c\u4ea7\u751f\u7684\u5149\u6d41\uff0c\u8bb0\u4e3a F^{rig}_{12} \uff0c\u56fe\u4e2d\u672a\u5448\u73b0\u3002\u7136\u540erigid-alignment module\u5c06\u76f8\u673a\u8fd0\u52a8\u4ece T_{12} \u7cbe\u4fee\u4e3a T_{12}' ,\u5e76\u8fdb\u4e00\u6b65\u5f97\u5230\u7cbe\u4fee\u7684 F^{rig'}_{12} \u7b2c\u4e09\uff0cConsistency check\u53bb\u9664\u8fd0\u52a8\u533a\u57df\u3002","title":"\u4e3b\u4f53\u6d41\u7a0b\u56fe"},{"location":"other_categories/SLAM/Joint_Unsupervised_Learning_of_Optical_Flow_and_Depth_by_Watching_Stereo_Videos/#_2","text":"PWC-Flow\u6309\u7167 \u8fd9\u7bc7\u6587\u7ae0 \u7684 \u4ecb\u7ecd MotionNet\u6309\u7167 \u8fd9\u7bc7\u6587\u7ae0 \u7684 \u4ecb\u7ecd PWC-Disp\u4ecePWC-Flow\u66f4\u6539\uff0c\u5728Cost volumn\u8ba1\u7b97\u7684\u65f6\u5019\u5f3a\u8feb\u5b83\u53ea\u5728\u6c34\u5e73\u65b9\u5411\u4e0a\u641c\u7d22\uff0c\u8f93\u51fa\u5f62\u72b6\u81ea\u7136\u53d8\u6210\u4e86 d\\times H \\times W","title":"\u7b2c\u4e00\u3001\u7f51\u7edc\u7ed3\u6784"},{"location":"other_categories/SLAM/Joint_Unsupervised_Learning_of_Optical_Flow_and_Depth_by_Watching_Stereo_Videos/#rigid-alighment-module","text":"\u8fd9\u4e2a\u6a21\u5757\u76ee\u6807\u662f\u7b2c\u4e00\u6b65\u7cbe\u4fee \u9996\u5148\u901a\u8fc7 Q_t(i,j) = D_t(i,j) K^{-1P_t(i,j)} \u5c06\u5f53\u524d\u56fe\u50cf\u8f6c\u6362\u4e3a\u76f8\u673a\u5750\u6807\u7cfb\uff0c3D\u7a7a\u95f4\u4e2d\u7684\u70b9\uff0c\u7136\u540e\u4f7f\u7528 T_{12} \u8f6c\u6362\uff0c\u5f97\u5230\u5bf9\u5e94\u70b9\u5728\u7b2c\u4e8c\u65f6\u523b\u76f8\u673a\u5750\u6807\u7cfb\u4e2d\u7684\u70b9 \\hat Q_1 \u3002 \\widetilde Q_1 \u5219\u8868\u793a Q_2 \u901a\u8fc7\u5149\u6d41 F^{opt}_{12} \u56de\u5230\u7b2c\u4e00\u65f6\u523b\u7684\u5750\u6807\uff0c \u901a\u8fc7\u6c42\u89e3\u4ee5\u4e0a\u4e24\u4e2a\u6b65\u9aa4\uff0c\u53ef\u4ee5\u5f97\u5230\u7cbe\u4fee\u7684T","title":"\u7b2c\u4e8c\u3001Rigid Alighment Module"},{"location":"other_categories/SLAM/Joint_Unsupervised_Learning_of_Optical_Flow_and_Depth_by_Watching_Stereo_Videos/#consistent-check","text":"\u7cbe\u4fee\u7684rigid\u5149\u6d41\u4e0e\u7f51\u7edc\u5149\u6d41\u7684\u5dee\u4e2d\uff0c\u503c\u8fc7\u5927\u6216\u8005\u88ab\u906e\u6321\u7684\u90e8\u5206\u4f1a\u88ab\u8fc7\u6ee4\u6389\uff0c\u4f7f\u7528thresholding\u7ed9\u51fa\u4e00\u4e2amask\uff0c\u53ea\u6709mask\u4e2d\u8ba4\u4e3a\u662f\u9759\u6b62\u7269\u4f53\u7684\u624d\u4f1a\u8fdb\u884closs\u8ba1\u7b97\u3002","title":"\u7b2c\u4e09\u3001Consistent Check"},{"location":"other_categories/SLAM/LO-Net: Deep Real-time Lidar Odometry/","text":"LO-Net: Deep Real-time Lidar Odometry \u8fd9\u7bc7\u6587\u7ae0\u4e3b\u8981\u6709\u4e09\u4e2a\u8d21\u732e\uff0c\u7b2c\u4e00\u63d0\u51fa\u4e86scan-to-scan lidar odometry\u7f51\u7edc\uff0c\u540c\u65f6\u4f30\u8ba1\u9762\u7684\u6cd5\u5411\u4ee5\u53camask for dynamic regions\u3002\u7b2c\u4e8c\u878d\u5408\u76f8\u90bb\u4e24\u5e27\u7f51\u7edc\u8fdb\u884c\u4f30\u8ba1\uff0c\u7b2c\u4e09\uff0c\u878d\u5408\u4e00\u4e2amapping module. \u6ce8\u610fGithub \u94fe\u63a5\u4ee3\u7801\u5c1a\u672a\u516c\u5e03\u3002 \u7f51\u7edc\u4e3b\u8981\u7ed3\u6784 \u6574\u4f53\u6765\u8bf4\uff0c\u7f51\u7edc\u7531\u4e09\u4e2a\u7f51\u7edc\u6784\u6210\uff0c\u5206\u522b\u662f\u6cd5\u5411\u4f30\u8ba1\u7f51\u7edc(point wise)\uff0cmask \u4f30\u8ba1\u7f51\u7edc\u4ee5\u53ca\u4e00\u4e2a\u5171\u7528\u53c2\u6570\u7684\u53cc\u751f\u59ff\u6001\u56de\u5f52\u4e3b\u7f51\u8def\u3002\u5b83\u4ee5\u4e24\u4e2a\u76f8\u90bb\u7684lidar\u70b9\u4f5c\u4e3a\u8f93\u5165\uff0c\u4f30\u8ba1\u51fa6\u81ea\u7531\u5ea6\u7684\u76f8\u5bf9\u8fd0\u52a8\u3001\u70b9\u4e91\u5404\u70b9\u7684\u9762\u6cd5\u5411\u4ee5\u53ca\u52a8\u6001\u533a\u57dfmask\u3002odometry\u7684\u8f93\u51fa\u4f1a\u901a\u8fc7mapping\u6a21\u5757\u8fdb\u4e00\u6b65\u63d0\u9ad8\uff0c\u6700\u7ec8\u7684\u8f93\u51fa\u4f1a\u662f\u76f8\u5bf9\u4e8e\u521d\u59cb\u4f4d\u7f6e\u7684\u504f\u79fb \u8f93\u5165\u7f16\u7801 \u4e3a\u4e86\u8ba9\u7f51\u7edc\u7684\u6570\u636e\u7f16\u6392\u53d8\u5f97\u7d27\u51d1\uff0c\u8fd9\u91cc\u4f7f\u7528\u5706\u67f1\u5750\u6807\u7cfb \\alpha = arctan(y/x)/\\Delta \\alpha \\beta = arcsin(z/\\sqrt{x^2+y^2 + z^2} / \u0394\u03b2) \u5982\u679c\u540c\u4e00\u4e2a \\alpha, \\beta \u5750\u6807\u6709\u4e0d\u6b62\u4e00\u4e2a\u70b9\uff0c\u5219\u4ee5\u6700\u8fd1\u7684\u70b9\u4e3a\u51c6\uff0c\u6bcf\u4e00\u4e2a\u70b9\u7684\u7279\u5f81\u5305\u62ec\u5f3a\u5ea6\u503c\u4ee5\u53ca\u8ddd\u79bb\u503c\u3002 \u51e0\u4f55\u7ea6\u675f \u6cd5\u5411\u4f30\u8ba1 \u4e25\u8c28\u6765\u8bf4\uff0c\u4ee5\u4e0a\u56fe\u4e3a\u4f8b\u5b50\uff0c\u70b9\u4e91\u7684\u6cd5\u5411\u5e94\u8be5\u7531\u70b9 X^i \u4ee5\u53ca\u5176 k \u4e2a\u76f8\u90bb\u7684\u70b9\uff0c\u7531\u4e0b\u5f0f\u5b9a\u4e49 \\argmin_{\\mathcal{N}(X^i)} ||[w_{i1}(X^{i_1}-X^i),...]^T\\mathcal{N}(X^i)||_2 \u4e5f\u5c31\u662f\u5bfb\u627e\u4e00\u4e2a\u77e2\u91cf\uff0c\u4f7f\u5f97\u8fd9\u4e2a\u77e2\u91cf\u4e0ek\u4e2a\u76f8\u90bb\u70b9\u77e2\u91cf\u7684\u70b9\u4e58\u7684\u52a0\u6743\u6c42\u548c\u503c(\u6216\u8005\u662f\u52a0\u6743\u8303\u6570)\u6700\u5c0f.\u4e00\u822c\u6765\u8bf4\u8ddd\u79bb\u8d8a\u8fd1\u6743\u91cd\u8d8a\u5927\uff0c\u8ddd\u79bb\u8d8a\u8fdc\u6743\u91cd\u8d8a\u5c0f\u3002 \u672c\u6587\u4e3a\u4e86\u7b80\u5316\u8fd9\u4e00\u8ba1\u7b97\uff0c\u4f7f\u7528\u4ee5\u4e0b\u65b9\u7a0b \\mathcal{N}(X^i) = \\sum_{X^{i_k}, X^{i_j} in \\mathcal{P}} (w_{ik}(X^{i_k} - X^i) \\times w_{ij}(X^{i_j} - X^i)) \u5176\u4e2d \\mathcal{P} \u4e3a\u5f53\u524d\u70b9\u7684\u4e34\u8fd1\u70b9\u3002 \u76f8\u90bb\u4e24\u7c07\u70b9\u4e91\u4e4b\u95f4\u6709\u4e00\u5b9a\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u4ee4 P \u4e3a\u6295\u5f71\u8fc7\u7a0b\u800c T_t \u4e3a\u76f8\u5bf9\u4f4d\u79fb\uff0c\u53ef\u4ee5\u627e\u5230\u70b9 X^{\\alpha \\beta}_{t-1} \u7684\u5bf9\u5e94\u70b9 \\hat X^{\\alpha \\beta}_t = P T_t P^{-1} X^{\\alpha\\beta}_{t-1} \u7531\u4e8e\u76f8\u5bf9\u5e94\u7684\u70b9\u6cd5\u5411\u4f30\u8ba1\u7406\u5e94\u6bd4\u8f83\u76f8\u4f3c\uff0c\u6240\u4ee5\u4e00\u4e2a\u7ea6\u675f\u662f \\mathcal{L}_n = \\sum_{\\alpha \\beta}||\\mathcal{N}(\\hat X^{\\alpha\\beta}_t) - \\mathcal{N}(X^{\\alpha\\beta}_t) ||_1 \\dot e^{|\\nabla_r(\\hat X^{\\alpha \\beta}_t)|} \u5176\u4e2d \\nabla_r(\\hat X^{\\alpha \\beta}_t) \u662f\u8ddd\u79bb\u5173\u4e8e \\alpha \\beta \u7684\u5fae\u5206\uff0c\u610f\u601d\u662f\u53d8\u5316\u8d8a\u5267\u70c8\u7684\u5730\u65b9\u8d8a\u91cd\u8981 \u91cc\u7a0b\u56de\u5f52 \u8fd9\u91cc\u8ba9\u7f51\u7edc\u5728\u5b8c\u5168\u8fde\u63a5\u5c42\u8f93\u51fa7\u4e2a\u6570\u503c\uff0c\u524d\u4e09\u4e2a\u662f\u5e73\u79fb\u5411\u91cf\uff0c\u540e\u9762\u56db\u4e2a\u662f\u56db\u5143\u6570\u3002\u5927\u90e8\u5206\u7f51\u7edc\u5c42\u4f7f\u7528\u7684\u662f fireConv \u7531\u4e8e\u70b9\u4e91\u7684\u7279\u6027\uff0cfeature map\u7684\u9ad8\u5ea6\u8fdc\u5c0f\u4e8e\u5bbd\u5ea6(360\u00b0\u70b9\u4e91)\uff0c\u6240\u4ee5\u5728\u4e0b\u91c7\u6837\u7684\u65f6\u5019\u53ea\u5bf9\u5bbd\u5ea6\u8fdb\u884cmax pooling \u5728\u5b66\u4e60\u65f6\u7531\u4e8e\u65cb\u8f6c\u4e0e\u5e73\u79fb\u7684\u5355\u4f4d\u4e0d\u540c\uff0c\u540c\u65f6\u4e3a\u4e86\u907f\u514d\u8c03\u8282\u8d85\u53c2\uff0c\u4f7f\u7528\u81ea\u52a8\u5b66\u4e60\u7684\u53c2\u6570(\u4e2a\u4eba\u6ce8\u89e3:\u5c3d\u7ba1\u516c\u5f0f\u4e0d\u540c\uff0c\u5f15\u7528\u7684\u6587\u7ae0\u4e5f\u4e0d\u4e00\u81f4\uff0c\u4f46\u662f\u57fa\u672c\u53ef\u4ee5\u786e\u8ba4\u7406\u8bba\u672c\u8d28\u6765\u81ea\u4e8e multi-loss ) \\begin{aligned} \\mathcal{L}_{o} &=\\mathcal{L}_{x}\\left(S_{t-1} ; S_{t}\\right) \\exp \\left(-s_{x}\\right)+s_{x} \\\\ &+\\mathcal{L}_{q}\\left(S_{t-1} ; S_{t}\\right) \\exp \\left(-s_{q}\\right)+s_{q} \\end{aligned} Mask\u4f30\u8ba1 \u8f93\u51fa\u7684mask\u4f1a\u5f71\u54cd\u5230\u51e0\u4f55\u7ea6\u675f\u7684cost function\uff0c\u88ab\u6539\u9020\u4e3a \\mathcal{L}_{n}=\\sum_{\\alpha \\beta} \\mathcal{M}\\left(X_{t}^{\\alpha \\beta}\\right)\\left\\|\\mathcal{N}\\left(\\hat{X}_{t}^{\\alpha \\beta}\\right)-\\mathcal{N}\\left(X_{t}^{\\alpha \\beta}\\right)\\right\\|_{1} \\cdot e^{\\left|\\nabla r\\left(\\hat{X}_{t}^{\\alpha \\beta}\\right)\\right|} \u6ce8\u610f\u5230\u7531\u4e8emask prediction\u6ca1\u6709ground truth \u6240\u4ee5\u5c06\u6240\u6709mask\u8bbe\u7f6e\u4e3a0\u53ef\u4ee5\u8ba9cost\u53d8\u5f97\u6700\u5c0f\uff0c\u6240\u4ee5\u9644\u52a0\u4ee5\u4e0b\u7684cost\uff0c\u76ee\u6807\u662f\u8ba9\u7f51\u7edc\u80fd\u591f\u6743\u8861\u3002 \\mathcal{L}_{r}=-\\sum_{\\alpha \\beta} \\log P\\left(\\mathcal{M}\\left(X_{t}^{\\alpha \\beta}\\right)=1\\right) Mapping refinement * \u8868\u793a\u7684\u662f\u5bf9\u6cd5\u5411\u4f30\u8ba1\u7684\u4e00\u4e2a\u9884\u8bbe\u7684 3\\times 5 \u5377\u79ef\uff0c\u4e2d\u592e\u4e3a-14.\u5176\u4ed6\u503c\u4e3a1\uff0c\u662f\u4e00\u4e2a\u9ad8\u901a\u6ee4\u6ce2\u5668\u3002feature map\u4e0a\u503c\u6700\u5c0f\u7684 n_c \u4e2amask\u5916\u7684\u70b9\u9009\u51fa\u6765\uff0c\u8ba4\u4e3a\u662f\u5e73\u9762\u533a\u57df\u3002 \\mathbf{\\Pi} \u6307\u7684\u662f\u8ba1\u7b97lidar pose\u7684\u5148\u9a8c\u8ba1\u7b97(\u5047\u8bbe\u4e0a\u4e00\u65f6\u523b\u8f6c\u6362\u77e9\u9635\u4e0d\u53d8) M_{init} = M_{t-1}M^{-1}_{t-2}M_{t-1} \\mathbf{\\Psi} \u9996\u5148\u5229\u7528\u7f51\u7edc\u9884\u6d4b\u7684\u4e24\u5e27\u95f4\u4f4d\u79fb\u7ebf\u6027\u63d2\u503c\u8865\u507f\u8fd0\u52a8\u7578\u53d8\uff0c\u7136\u540e\u7528 M_{init} \u5c06\u65b0\u7684\u70b9\u4e91\u8f6c\u79fb\u5230\u4e16\u754c\u5750\u6807\u7cfb\u4e0b\u3002 \u5047\u8bbe p_i \u662f\u5f53\u524dscan\u7684\u70b9\uff0c m_i \u662f\u5bf9\u5e94\u70b9\uff0c\u800c n_i \u662f\u5bf9\u5e94\u70b9\u7684\u6cd5\u5411\u3002\u5168\u5c40mapping\u7684\u76ee\u6807\u5c31\u662f\u8981\u627e\u5230\u4e00\u4e2a\u6700\u4f18\u7684 M \u4f7f\u5f97 \\hat{\\mathbf{M}}_{o p t}=\\underset{\\hat{\\mathbf{M}}}{\\arg \\min } \\sum_{i}\\left(\\left(\\hat{\\mathbf{M}} \\cdot \\boldsymbol{p}_{i}-\\boldsymbol{m}_{i}\\right) \\cdot \\boldsymbol{n}_{i}\\right)^{2} \\Theta :\u8fed\u4ee3\u5730\u6c42\u89e3\u4e0a\u6587\u63d0\u5230\u7684\u65b9\u7a0b\uff0c \\mathbf{M}_{t}=\\prod_{k=1}^{n_{i t e r}} \\hat{\\mathbf{M}}_{k} \\mathbf{M}_{i n i t} \\Phi \u6839\u636e\u4f18\u5316\u540e\u7684\u4f4d\u79fb\u7ed3\u679c\u751f\u6210\u6700\u7ec8\u7684\u70b9\u4e91\u7ed3\u679c\u3002 \\sum,N \u5c06\u65b0\u7684\u70b9\u4e91\u52a0\u5230\u5730\u56fe\u4e2d\uff0c\u7136\u540e\u6e05\u9664\u6700\u65e7\u7684\u70b9\u4e91\uff0c\u53ea\u4fdd\u5b58\u6700\u65e7\u7684 n_m \u4e2a\u70b9\u4e91","title":"LO-Net: Deep Real-time Lidar Odometry"},{"location":"other_categories/SLAM/LO-Net: Deep Real-time Lidar Odometry/#lo-net-deep-real-time-lidar-odometry","text":"\u8fd9\u7bc7\u6587\u7ae0\u4e3b\u8981\u6709\u4e09\u4e2a\u8d21\u732e\uff0c\u7b2c\u4e00\u63d0\u51fa\u4e86scan-to-scan lidar odometry\u7f51\u7edc\uff0c\u540c\u65f6\u4f30\u8ba1\u9762\u7684\u6cd5\u5411\u4ee5\u53camask for dynamic regions\u3002\u7b2c\u4e8c\u878d\u5408\u76f8\u90bb\u4e24\u5e27\u7f51\u7edc\u8fdb\u884c\u4f30\u8ba1\uff0c\u7b2c\u4e09\uff0c\u878d\u5408\u4e00\u4e2amapping module. \u6ce8\u610fGithub \u94fe\u63a5\u4ee3\u7801\u5c1a\u672a\u516c\u5e03\u3002","title":"LO-Net: Deep Real-time Lidar Odometry"},{"location":"other_categories/SLAM/LO-Net: Deep Real-time Lidar Odometry/#_1","text":"\u6574\u4f53\u6765\u8bf4\uff0c\u7f51\u7edc\u7531\u4e09\u4e2a\u7f51\u7edc\u6784\u6210\uff0c\u5206\u522b\u662f\u6cd5\u5411\u4f30\u8ba1\u7f51\u7edc(point wise)\uff0cmask \u4f30\u8ba1\u7f51\u7edc\u4ee5\u53ca\u4e00\u4e2a\u5171\u7528\u53c2\u6570\u7684\u53cc\u751f\u59ff\u6001\u56de\u5f52\u4e3b\u7f51\u8def\u3002\u5b83\u4ee5\u4e24\u4e2a\u76f8\u90bb\u7684lidar\u70b9\u4f5c\u4e3a\u8f93\u5165\uff0c\u4f30\u8ba1\u51fa6\u81ea\u7531\u5ea6\u7684\u76f8\u5bf9\u8fd0\u52a8\u3001\u70b9\u4e91\u5404\u70b9\u7684\u9762\u6cd5\u5411\u4ee5\u53ca\u52a8\u6001\u533a\u57dfmask\u3002odometry\u7684\u8f93\u51fa\u4f1a\u901a\u8fc7mapping\u6a21\u5757\u8fdb\u4e00\u6b65\u63d0\u9ad8\uff0c\u6700\u7ec8\u7684\u8f93\u51fa\u4f1a\u662f\u76f8\u5bf9\u4e8e\u521d\u59cb\u4f4d\u7f6e\u7684\u504f\u79fb","title":"\u7f51\u7edc\u4e3b\u8981\u7ed3\u6784"},{"location":"other_categories/SLAM/LO-Net: Deep Real-time Lidar Odometry/#_2","text":"\u4e3a\u4e86\u8ba9\u7f51\u7edc\u7684\u6570\u636e\u7f16\u6392\u53d8\u5f97\u7d27\u51d1\uff0c\u8fd9\u91cc\u4f7f\u7528\u5706\u67f1\u5750\u6807\u7cfb \\alpha = arctan(y/x)/\\Delta \\alpha \\beta = arcsin(z/\\sqrt{x^2+y^2 + z^2} / \u0394\u03b2) \u5982\u679c\u540c\u4e00\u4e2a \\alpha, \\beta \u5750\u6807\u6709\u4e0d\u6b62\u4e00\u4e2a\u70b9\uff0c\u5219\u4ee5\u6700\u8fd1\u7684\u70b9\u4e3a\u51c6\uff0c\u6bcf\u4e00\u4e2a\u70b9\u7684\u7279\u5f81\u5305\u62ec\u5f3a\u5ea6\u503c\u4ee5\u53ca\u8ddd\u79bb\u503c\u3002","title":"\u8f93\u5165\u7f16\u7801"},{"location":"other_categories/SLAM/LO-Net: Deep Real-time Lidar Odometry/#_3","text":"","title":"\u51e0\u4f55\u7ea6\u675f"},{"location":"other_categories/SLAM/LO-Net: Deep Real-time Lidar Odometry/#_4","text":"\u4e25\u8c28\u6765\u8bf4\uff0c\u4ee5\u4e0a\u56fe\u4e3a\u4f8b\u5b50\uff0c\u70b9\u4e91\u7684\u6cd5\u5411\u5e94\u8be5\u7531\u70b9 X^i \u4ee5\u53ca\u5176 k \u4e2a\u76f8\u90bb\u7684\u70b9\uff0c\u7531\u4e0b\u5f0f\u5b9a\u4e49 \\argmin_{\\mathcal{N}(X^i)} ||[w_{i1}(X^{i_1}-X^i),...]^T\\mathcal{N}(X^i)||_2 \u4e5f\u5c31\u662f\u5bfb\u627e\u4e00\u4e2a\u77e2\u91cf\uff0c\u4f7f\u5f97\u8fd9\u4e2a\u77e2\u91cf\u4e0ek\u4e2a\u76f8\u90bb\u70b9\u77e2\u91cf\u7684\u70b9\u4e58\u7684\u52a0\u6743\u6c42\u548c\u503c(\u6216\u8005\u662f\u52a0\u6743\u8303\u6570)\u6700\u5c0f.\u4e00\u822c\u6765\u8bf4\u8ddd\u79bb\u8d8a\u8fd1\u6743\u91cd\u8d8a\u5927\uff0c\u8ddd\u79bb\u8d8a\u8fdc\u6743\u91cd\u8d8a\u5c0f\u3002 \u672c\u6587\u4e3a\u4e86\u7b80\u5316\u8fd9\u4e00\u8ba1\u7b97\uff0c\u4f7f\u7528\u4ee5\u4e0b\u65b9\u7a0b \\mathcal{N}(X^i) = \\sum_{X^{i_k}, X^{i_j} in \\mathcal{P}} (w_{ik}(X^{i_k} - X^i) \\times w_{ij}(X^{i_j} - X^i)) \u5176\u4e2d \\mathcal{P} \u4e3a\u5f53\u524d\u70b9\u7684\u4e34\u8fd1\u70b9\u3002 \u76f8\u90bb\u4e24\u7c07\u70b9\u4e91\u4e4b\u95f4\u6709\u4e00\u5b9a\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u4ee4 P \u4e3a\u6295\u5f71\u8fc7\u7a0b\u800c T_t \u4e3a\u76f8\u5bf9\u4f4d\u79fb\uff0c\u53ef\u4ee5\u627e\u5230\u70b9 X^{\\alpha \\beta}_{t-1} \u7684\u5bf9\u5e94\u70b9 \\hat X^{\\alpha \\beta}_t = P T_t P^{-1} X^{\\alpha\\beta}_{t-1} \u7531\u4e8e\u76f8\u5bf9\u5e94\u7684\u70b9\u6cd5\u5411\u4f30\u8ba1\u7406\u5e94\u6bd4\u8f83\u76f8\u4f3c\uff0c\u6240\u4ee5\u4e00\u4e2a\u7ea6\u675f\u662f \\mathcal{L}_n = \\sum_{\\alpha \\beta}||\\mathcal{N}(\\hat X^{\\alpha\\beta}_t) - \\mathcal{N}(X^{\\alpha\\beta}_t) ||_1 \\dot e^{|\\nabla_r(\\hat X^{\\alpha \\beta}_t)|} \u5176\u4e2d \\nabla_r(\\hat X^{\\alpha \\beta}_t) \u662f\u8ddd\u79bb\u5173\u4e8e \\alpha \\beta \u7684\u5fae\u5206\uff0c\u610f\u601d\u662f\u53d8\u5316\u8d8a\u5267\u70c8\u7684\u5730\u65b9\u8d8a\u91cd\u8981","title":"\u6cd5\u5411\u4f30\u8ba1"},{"location":"other_categories/SLAM/LO-Net: Deep Real-time Lidar Odometry/#_5","text":"\u8fd9\u91cc\u8ba9\u7f51\u7edc\u5728\u5b8c\u5168\u8fde\u63a5\u5c42\u8f93\u51fa7\u4e2a\u6570\u503c\uff0c\u524d\u4e09\u4e2a\u662f\u5e73\u79fb\u5411\u91cf\uff0c\u540e\u9762\u56db\u4e2a\u662f\u56db\u5143\u6570\u3002\u5927\u90e8\u5206\u7f51\u7edc\u5c42\u4f7f\u7528\u7684\u662f fireConv \u7531\u4e8e\u70b9\u4e91\u7684\u7279\u6027\uff0cfeature map\u7684\u9ad8\u5ea6\u8fdc\u5c0f\u4e8e\u5bbd\u5ea6(360\u00b0\u70b9\u4e91)\uff0c\u6240\u4ee5\u5728\u4e0b\u91c7\u6837\u7684\u65f6\u5019\u53ea\u5bf9\u5bbd\u5ea6\u8fdb\u884cmax pooling \u5728\u5b66\u4e60\u65f6\u7531\u4e8e\u65cb\u8f6c\u4e0e\u5e73\u79fb\u7684\u5355\u4f4d\u4e0d\u540c\uff0c\u540c\u65f6\u4e3a\u4e86\u907f\u514d\u8c03\u8282\u8d85\u53c2\uff0c\u4f7f\u7528\u81ea\u52a8\u5b66\u4e60\u7684\u53c2\u6570(\u4e2a\u4eba\u6ce8\u89e3:\u5c3d\u7ba1\u516c\u5f0f\u4e0d\u540c\uff0c\u5f15\u7528\u7684\u6587\u7ae0\u4e5f\u4e0d\u4e00\u81f4\uff0c\u4f46\u662f\u57fa\u672c\u53ef\u4ee5\u786e\u8ba4\u7406\u8bba\u672c\u8d28\u6765\u81ea\u4e8e multi-loss ) \\begin{aligned} \\mathcal{L}_{o} &=\\mathcal{L}_{x}\\left(S_{t-1} ; S_{t}\\right) \\exp \\left(-s_{x}\\right)+s_{x} \\\\ &+\\mathcal{L}_{q}\\left(S_{t-1} ; S_{t}\\right) \\exp \\left(-s_{q}\\right)+s_{q} \\end{aligned}","title":"\u91cc\u7a0b\u56de\u5f52"},{"location":"other_categories/SLAM/LO-Net: Deep Real-time Lidar Odometry/#mask","text":"\u8f93\u51fa\u7684mask\u4f1a\u5f71\u54cd\u5230\u51e0\u4f55\u7ea6\u675f\u7684cost function\uff0c\u88ab\u6539\u9020\u4e3a \\mathcal{L}_{n}=\\sum_{\\alpha \\beta} \\mathcal{M}\\left(X_{t}^{\\alpha \\beta}\\right)\\left\\|\\mathcal{N}\\left(\\hat{X}_{t}^{\\alpha \\beta}\\right)-\\mathcal{N}\\left(X_{t}^{\\alpha \\beta}\\right)\\right\\|_{1} \\cdot e^{\\left|\\nabla r\\left(\\hat{X}_{t}^{\\alpha \\beta}\\right)\\right|} \u6ce8\u610f\u5230\u7531\u4e8emask prediction\u6ca1\u6709ground truth \u6240\u4ee5\u5c06\u6240\u6709mask\u8bbe\u7f6e\u4e3a0\u53ef\u4ee5\u8ba9cost\u53d8\u5f97\u6700\u5c0f\uff0c\u6240\u4ee5\u9644\u52a0\u4ee5\u4e0b\u7684cost\uff0c\u76ee\u6807\u662f\u8ba9\u7f51\u7edc\u80fd\u591f\u6743\u8861\u3002 \\mathcal{L}_{r}=-\\sum_{\\alpha \\beta} \\log P\\left(\\mathcal{M}\\left(X_{t}^{\\alpha \\beta}\\right)=1\\right)","title":"Mask\u4f30\u8ba1"},{"location":"other_categories/SLAM/LO-Net: Deep Real-time Lidar Odometry/#mapping-refinement","text":"* \u8868\u793a\u7684\u662f\u5bf9\u6cd5\u5411\u4f30\u8ba1\u7684\u4e00\u4e2a\u9884\u8bbe\u7684 3\\times 5 \u5377\u79ef\uff0c\u4e2d\u592e\u4e3a-14.\u5176\u4ed6\u503c\u4e3a1\uff0c\u662f\u4e00\u4e2a\u9ad8\u901a\u6ee4\u6ce2\u5668\u3002feature map\u4e0a\u503c\u6700\u5c0f\u7684 n_c \u4e2amask\u5916\u7684\u70b9\u9009\u51fa\u6765\uff0c\u8ba4\u4e3a\u662f\u5e73\u9762\u533a\u57df\u3002 \\mathbf{\\Pi} \u6307\u7684\u662f\u8ba1\u7b97lidar pose\u7684\u5148\u9a8c\u8ba1\u7b97(\u5047\u8bbe\u4e0a\u4e00\u65f6\u523b\u8f6c\u6362\u77e9\u9635\u4e0d\u53d8) M_{init} = M_{t-1}M^{-1}_{t-2}M_{t-1} \\mathbf{\\Psi} \u9996\u5148\u5229\u7528\u7f51\u7edc\u9884\u6d4b\u7684\u4e24\u5e27\u95f4\u4f4d\u79fb\u7ebf\u6027\u63d2\u503c\u8865\u507f\u8fd0\u52a8\u7578\u53d8\uff0c\u7136\u540e\u7528 M_{init} \u5c06\u65b0\u7684\u70b9\u4e91\u8f6c\u79fb\u5230\u4e16\u754c\u5750\u6807\u7cfb\u4e0b\u3002 \u5047\u8bbe p_i \u662f\u5f53\u524dscan\u7684\u70b9\uff0c m_i \u662f\u5bf9\u5e94\u70b9\uff0c\u800c n_i \u662f\u5bf9\u5e94\u70b9\u7684\u6cd5\u5411\u3002\u5168\u5c40mapping\u7684\u76ee\u6807\u5c31\u662f\u8981\u627e\u5230\u4e00\u4e2a\u6700\u4f18\u7684 M \u4f7f\u5f97 \\hat{\\mathbf{M}}_{o p t}=\\underset{\\hat{\\mathbf{M}}}{\\arg \\min } \\sum_{i}\\left(\\left(\\hat{\\mathbf{M}} \\cdot \\boldsymbol{p}_{i}-\\boldsymbol{m}_{i}\\right) \\cdot \\boldsymbol{n}_{i}\\right)^{2} \\Theta :\u8fed\u4ee3\u5730\u6c42\u89e3\u4e0a\u6587\u63d0\u5230\u7684\u65b9\u7a0b\uff0c \\mathbf{M}_{t}=\\prod_{k=1}^{n_{i t e r}} \\hat{\\mathbf{M}}_{k} \\mathbf{M}_{i n i t} \\Phi \u6839\u636e\u4f18\u5316\u540e\u7684\u4f4d\u79fb\u7ed3\u679c\u751f\u6210\u6700\u7ec8\u7684\u70b9\u4e91\u7ed3\u679c\u3002 \\sum,N \u5c06\u65b0\u7684\u70b9\u4e91\u52a0\u5230\u5730\u56fe\u4e2d\uff0c\u7136\u540e\u6e05\u9664\u6700\u65e7\u7684\u70b9\u4e91\uff0c\u53ea\u4fdd\u5b58\u6700\u65e7\u7684 n_m \u4e2a\u70b9\u4e91","title":"Mapping refinement"},{"location":"other_categories/SLAM/PWC-Net_CNNs_for_Optical_Flow_Using_Pyramid_Warping_and_Cost_Volume/","text":"PWC-Net: CNNs for Optical Flow Using Pyramid, Warping, and Cost Volume \u8fd9\u7bc7\u8bba\u6587\u662f Joint Unsupervised Learning of Optical Flow and Depth by Watching Stereo Videos \u7684\u524d\u7f6e \u7f51\u7edc\u7ed3\u6784 \u8f93\u5165\u7684\u7279\u5f81\u5206\u4e3a6\u5c42\uff0c\u7b2c\u4e00\u5c42\u4e3a\u8f93\u5165\u56fe\u7247\uff0c\u7b2c\u4e8c\u5c42\u5f00\u59cb\u4e3aConvNet\u4e0b\u91c7\u6837\u7684\u8f93\u51fa, \u8f93\u51fa\u5149\u6d41 Warping Layer \u5728\u7b2cL\u5c42\uff0c\u5c06\u7b2c\u4e8c\u5f20\u56fe\u7b2cl+1\u5c42\u7684feature\u901a\u8fc7\u4e0a\u91c7\u6837\u8f6c\u6362\u5230\u7b2c\u4e00\u5f20\u56fe c^l_w(x) = c^l_2(x + up_2(w^{l+1})(x)) \u91c7\u7528\u7684\u662fbilinear interpolation Cost volume layer \u8868\u793a\u7684\u662f\u4e00\u4e2apixel\u4e0e\u4e0b\u4e00\u65f6\u523b\u5bf9\u5e94pixel match\u7684cost\u3002\u4f7f\u7528\u7279\u5f81\u7684coorelation\u6765\u8868\u793a cv^l(x1, x2) = \\frac{1}{N} (c^l_1(x_1))^T c^l_w(x_2) \u5177\u4f53\uff1a\u8f93\u51fa\u662f d^2\\times H^l \\times W^l \u5176\u5b9e\u5c31\u662f\u5de6\u89c6\u89d2\u6bcf\u4e00\u4e2a\u70b9 x_1 \u4e0ewarp\u7ed3\u679c\u5bf9\u5e94\u5468\u56f4 d\\times d \u4e2apixels\u7684\u7279\u5f81\u5411\u91cf\u6c42\u76f8\u5173\u6027 Optical flow estimator \u8fd9\u662f\u4e00\u4e2a\u591a\u5c42CNN\uff0c\u8f93\u5165\u662fCost Volumn, \u7b2c\u4e00\u56fe\u7684\u7279\u5f81\u4ee5\u53ca\u4e0a\u91c7\u6837\u7684\u5149\u6d41\uff0c\u5b83\u7684\u8f93\u51fa\u662f\u7b2c l \u5c42\u7684\u5149\u6d41 w^l .\u4e0d\u540c\u5c42\u4e4b\u95f4\u7684CNN\u7279\u5f81\u4e0d\u5171\u4eab\uff0c Context Network \u4f7f\u7528\u6700\u7ec8\u8f93\u51fa\u7684\u5149\u6d41\u4ee5\u53ca\u524d\u4e00\u5c42\u7684\u7279\u5f81\u4f5c\u4e3a\u8f93\u5165\uff0c\u518d\u8f93\u51fa\u66f4\u7cbe\u786e\u7684\u5149\u6d41\u503c\uff0c\u591a\u4f7f\u7528dilated Conv\u53bb\u63d0\u5347\u611f\u53d7\u91ce","title":"PWC-Net: CNNs for Optical Flow Using Pyramid, Warping, and Cost Volume"},{"location":"other_categories/SLAM/PWC-Net_CNNs_for_Optical_Flow_Using_Pyramid_Warping_and_Cost_Volume/#pwc-net-cnns-for-optical-flow-using-pyramid-warping-and-cost-volume","text":"\u8fd9\u7bc7\u8bba\u6587\u662f Joint Unsupervised Learning of Optical Flow and Depth by Watching Stereo Videos \u7684\u524d\u7f6e","title":"PWC-Net: CNNs for Optical Flow Using Pyramid, Warping, and Cost Volume"},{"location":"other_categories/SLAM/PWC-Net_CNNs_for_Optical_Flow_Using_Pyramid_Warping_and_Cost_Volume/#_1","text":"\u8f93\u5165\u7684\u7279\u5f81\u5206\u4e3a6\u5c42\uff0c\u7b2c\u4e00\u5c42\u4e3a\u8f93\u5165\u56fe\u7247\uff0c\u7b2c\u4e8c\u5c42\u5f00\u59cb\u4e3aConvNet\u4e0b\u91c7\u6837\u7684\u8f93\u51fa, \u8f93\u51fa\u5149\u6d41","title":"\u7f51\u7edc\u7ed3\u6784"},{"location":"other_categories/SLAM/PWC-Net_CNNs_for_Optical_Flow_Using_Pyramid_Warping_and_Cost_Volume/#warping-layer","text":"\u5728\u7b2cL\u5c42\uff0c\u5c06\u7b2c\u4e8c\u5f20\u56fe\u7b2cl+1\u5c42\u7684feature\u901a\u8fc7\u4e0a\u91c7\u6837\u8f6c\u6362\u5230\u7b2c\u4e00\u5f20\u56fe c^l_w(x) = c^l_2(x + up_2(w^{l+1})(x)) \u91c7\u7528\u7684\u662fbilinear interpolation","title":"Warping Layer"},{"location":"other_categories/SLAM/PWC-Net_CNNs_for_Optical_Flow_Using_Pyramid_Warping_and_Cost_Volume/#cost-volume-layer","text":"\u8868\u793a\u7684\u662f\u4e00\u4e2apixel\u4e0e\u4e0b\u4e00\u65f6\u523b\u5bf9\u5e94pixel match\u7684cost\u3002\u4f7f\u7528\u7279\u5f81\u7684coorelation\u6765\u8868\u793a cv^l(x1, x2) = \\frac{1}{N} (c^l_1(x_1))^T c^l_w(x_2) \u5177\u4f53\uff1a\u8f93\u51fa\u662f d^2\\times H^l \\times W^l \u5176\u5b9e\u5c31\u662f\u5de6\u89c6\u89d2\u6bcf\u4e00\u4e2a\u70b9 x_1 \u4e0ewarp\u7ed3\u679c\u5bf9\u5e94\u5468\u56f4 d\\times d \u4e2apixels\u7684\u7279\u5f81\u5411\u91cf\u6c42\u76f8\u5173\u6027","title":"Cost volume layer"},{"location":"other_categories/SLAM/PWC-Net_CNNs_for_Optical_Flow_Using_Pyramid_Warping_and_Cost_Volume/#optical-flow-estimator","text":"\u8fd9\u662f\u4e00\u4e2a\u591a\u5c42CNN\uff0c\u8f93\u5165\u662fCost Volumn, \u7b2c\u4e00\u56fe\u7684\u7279\u5f81\u4ee5\u53ca\u4e0a\u91c7\u6837\u7684\u5149\u6d41\uff0c\u5b83\u7684\u8f93\u51fa\u662f\u7b2c l \u5c42\u7684\u5149\u6d41 w^l .\u4e0d\u540c\u5c42\u4e4b\u95f4\u7684CNN\u7279\u5f81\u4e0d\u5171\u4eab\uff0c","title":"Optical flow estimator"},{"location":"other_categories/SLAM/PWC-Net_CNNs_for_Optical_Flow_Using_Pyramid_Warping_and_Cost_Volume/#context-network","text":"\u4f7f\u7528\u6700\u7ec8\u8f93\u51fa\u7684\u5149\u6d41\u4ee5\u53ca\u524d\u4e00\u5c42\u7684\u7279\u5f81\u4f5c\u4e3a\u8f93\u5165\uff0c\u518d\u8f93\u51fa\u66f4\u7cbe\u786e\u7684\u5149\u6d41\u503c\uff0c\u591a\u4f7f\u7528dilated Conv\u53bb\u63d0\u5347\u611f\u53d7\u91ce","title":"Context Network"},{"location":"other_categories/SLAM/SuperPoint:Self-Supervised_Interest_Point_Detection_and_Description/","text":"SuperPoint: Self-Supervised Interest Point Detection and Description \u8fd9\u7bc7\u8bba\u6587\u5b8c\u6210\u7684\u4efb\u52a1\u662f\u4ece\u4e00\u5f20\u56fe\u4e2d\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u63d0\u53d6\u51fakeypoints\uff0c\u8fd9\u4e9bkeypoints\u7684\u5173\u952e\u662f\u8981\u6c42\u5bf9\u65cb\u8f6c\uff0cscale\uff0c\u5e73\u79fb\u9c81\u68d2\u3002 Training procedure \u8bad\u7ec3\u8fc7\u7a0b\u9700\u8981\u4e09\u4e2a\u9636\u6bb5\uff0c\u7b2c\u4e00\u4e2a\u9636\u6bb5\uff0c\u4f7f\u7528\u4e00\u4e9b\u7b80\u5355\u7684\u51e0\u4f55\u56fe\u7247,\u7528\u4e00\u4e9b\u6ca1\u6709\u6b67\u4e49\u7684\u56fe\u7247\u548ckeypoint\uff0c\u8fdb\u884c\u521d\u59cb\u8bad\u7ec3\u3002 \u7b2c\u4e8c\u9636\u6bb5\uff0c\u4f7f\u7528\u4e00\u4e9b\u6ca1\u6709label\u7684\u771f\u5b9e\u56fe\u7247\uff0c\u5bf9\u540c\u4e00\u5f20\u56fe\uff0c\u4f7f\u7528Homographic transform(\u65cb\u8f6c\u5e73\u79fb\u7b49\u7684\u7ec4\u5408),\u8f6c\u6362\u6210\u4e00\u4e2abatch\u7684\u56fe.\u7528\u524d\u6587\u7684detector\uff0c\u751f\u6210keypoint\uff0c\u518d\u8f6c\u6362\u4e3a\u539f\u56fe\u5750\u6807\u7cfb\u4e2d\u3002\u8fd9\u4e2abatch\u4f1a\u5728\u5f53\u524d\u56fe\u5f62\u6210\u4e00\u4e2akeypoint\u7684heatmap. \\mathbf{x}=\\mathcal{H}^{-1} f_{\\theta}(\\mathcal{H}(I)) \\hat{F}\\left(I ; f_{\\theta}\\right)=\\frac{1}{N_{h}} \\sum_{i=1}^{N_{h}} \\mathcal{H}_{i}^{-1} f_{\\theta}\\left(\\mathcal{H}_{i}(I)\\right) \u7b2c\u4e09\u9636\u6bb5\uff0c\u4f7f\u7528joint training\u3002\u8fdb\u884c\u8bad\u7ec3 \u7f51\u7edc\u6a21\u578b \u7b2c\u4e00\u9636\u6bb5\u53ea\u4f7f\u7528\u4e0a\u90e8\u5206\u90a3\u4e00\u652f\uff0c\u7b2c\u4e09\u9636\u6bb5\u4f1a\u6709descriptor\u90e8\u5206\u3002 Encoder\u7c7b\u4f3c\u4e8eVGG, Interest Point Decoder\uff0c65\u4e2aChannels,\u610f\u601d\u662f\u5468\u8fb9 8\\times 8 \u4e2a\u65b9\u5757\u6709keypoint\u7684\u6982\u7387\uff0c\u8fd8\u6709\u4e00\u4e2a\u662f\u7a7a\u7c7b. \u8fd9\u91cc\u7684 reshape \u5bf9\u5e94\u7684\u662fpytorch.nn.pixelshuffel\u64cd\u4f5c\uff0c\u5c06channel\u7684\u5185\u5bb9\u7ffb\u5230feature map\u7a7a\u95f4\u7684\u533a\u57df\u3002 \u5982\u679cground truth\u91cc\u9762 8\\times 8 \u533a\u57df\u91cc\u9762\u6709\u4e0d\u6b62\u4e00\u4e2a\u70b9\u5219\u968f\u673a\u9009\u53d6\u4e00\u4e2a\u4f5c\u4e3a\u8be5\u533a\u57df\u91cc\u9762\u6709\u6548\u7684ground truth\u3002 \u8fd9\u91cc\u4f7f\u7528cross-entropy,\u8ba1\u7b97 \\mathcal{L}_p \u8fdb\u884c\u8bad\u7ec3\u3002 descriptor\u7684\u8bad\u7ec3\uff0c\u4f9d\u9760\u7684\u662f\u540c\u4e00\u5f20\u56fe\uff0c\u5c06\u56fehomographic transform\u5230\u53e6\u4e00\u5f20\u56fe\u53bb\uff0c\u8981\u6c42keypoint\u5bf9\u5e94\u7684\u4f4d\u7f6e\u63cf\u8ff0\u76f8\u540c\u3002 s_{h w h^{\\prime} w^{\\prime}} \u6307\u4ee3\u5bf9\u5e94\u5173\u7cfb s_{h w h^{\\prime} w^{\\prime}}=\\left\\{\\begin{array}{ll}{1,} & {\\text { if } \\| \\widehat{\\mathcal{H} \\mathbf{p}_{h w}}-\\mathbf{p}_{h^{\\prime} w^{\\prime}}|| \\leq 8} \\\\ {0,} & {\\text { otherwise }}\\end{array}\\right. \\begin{aligned} l_{d}\\left(\\mathbf{d}, \\mathbf{d}^{\\prime} ; s\\right) &=\\lambda_{d} * s * \\max \\left(0, m_{p}-\\mathbf{d}^{T} \\mathbf{d}^{\\prime}\\right) \\\\ &+(1-s) * \\max \\left(0, \\mathbf{d}^{T} \\mathbf{d}^{\\prime}-m_{n}\\right) \\end{aligned} \\begin{aligned} \\mathcal{L}_{d}\\left(\\mathcal{D}, \\mathcal{D}^{\\prime}, S\\right) &=\\\\ \\frac{1}{\\left(H_{c} W_{c}\\right)^{2}} &\\sum_{h=1}^{H_{c}, W_{c} H_{c}, W_{c}} l_{d}\\left(\\mathbf{d}_{h w}, \\mathbf{d}_{h^{\\prime} w^{\\prime}}^{\\prime} ; s_{h w h^{\\prime} w^{\\prime}}\\right) \\end{aligned} \\begin{aligned} \\mathcal{L}\\left(\\mathcal{X}, \\mathcal{X}^{\\prime}, \\mathcal{D}, \\mathcal{D}^{\\prime} ; Y, Y^{\\prime}, S\\right) &=\\\\ \\mathcal{L}_{p}(\\mathcal{X}, Y)&+\\mathcal{L}_{p}\\left(\\mathcal{X}^{\\prime}, Y^{\\prime}\\right)+\\lambda \\mathcal{L}_{d}\\left(\\mathcal{D}, \\mathcal{D}^{\\prime}, S\\right) \\end{aligned}","title":"SuperPoint: Self-Supervised Interest Point Detection and Description"},{"location":"other_categories/SLAM/SuperPoint:Self-Supervised_Interest_Point_Detection_and_Description/#superpoint-self-supervised-interest-point-detection-and-description","text":"\u8fd9\u7bc7\u8bba\u6587\u5b8c\u6210\u7684\u4efb\u52a1\u662f\u4ece\u4e00\u5f20\u56fe\u4e2d\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u63d0\u53d6\u51fakeypoints\uff0c\u8fd9\u4e9bkeypoints\u7684\u5173\u952e\u662f\u8981\u6c42\u5bf9\u65cb\u8f6c\uff0cscale\uff0c\u5e73\u79fb\u9c81\u68d2\u3002","title":"SuperPoint: Self-Supervised Interest Point Detection and Description"},{"location":"other_categories/SLAM/SuperPoint:Self-Supervised_Interest_Point_Detection_and_Description/#training-procedure","text":"\u8bad\u7ec3\u8fc7\u7a0b\u9700\u8981\u4e09\u4e2a\u9636\u6bb5\uff0c\u7b2c\u4e00\u4e2a\u9636\u6bb5\uff0c\u4f7f\u7528\u4e00\u4e9b\u7b80\u5355\u7684\u51e0\u4f55\u56fe\u7247,\u7528\u4e00\u4e9b\u6ca1\u6709\u6b67\u4e49\u7684\u56fe\u7247\u548ckeypoint\uff0c\u8fdb\u884c\u521d\u59cb\u8bad\u7ec3\u3002 \u7b2c\u4e8c\u9636\u6bb5\uff0c\u4f7f\u7528\u4e00\u4e9b\u6ca1\u6709label\u7684\u771f\u5b9e\u56fe\u7247\uff0c\u5bf9\u540c\u4e00\u5f20\u56fe\uff0c\u4f7f\u7528Homographic transform(\u65cb\u8f6c\u5e73\u79fb\u7b49\u7684\u7ec4\u5408),\u8f6c\u6362\u6210\u4e00\u4e2abatch\u7684\u56fe.\u7528\u524d\u6587\u7684detector\uff0c\u751f\u6210keypoint\uff0c\u518d\u8f6c\u6362\u4e3a\u539f\u56fe\u5750\u6807\u7cfb\u4e2d\u3002\u8fd9\u4e2abatch\u4f1a\u5728\u5f53\u524d\u56fe\u5f62\u6210\u4e00\u4e2akeypoint\u7684heatmap. \\mathbf{x}=\\mathcal{H}^{-1} f_{\\theta}(\\mathcal{H}(I)) \\hat{F}\\left(I ; f_{\\theta}\\right)=\\frac{1}{N_{h}} \\sum_{i=1}^{N_{h}} \\mathcal{H}_{i}^{-1} f_{\\theta}\\left(\\mathcal{H}_{i}(I)\\right) \u7b2c\u4e09\u9636\u6bb5\uff0c\u4f7f\u7528joint training\u3002\u8fdb\u884c\u8bad\u7ec3","title":"Training procedure"},{"location":"other_categories/SLAM/SuperPoint:Self-Supervised_Interest_Point_Detection_and_Description/#_1","text":"\u7b2c\u4e00\u9636\u6bb5\u53ea\u4f7f\u7528\u4e0a\u90e8\u5206\u90a3\u4e00\u652f\uff0c\u7b2c\u4e09\u9636\u6bb5\u4f1a\u6709descriptor\u90e8\u5206\u3002 Encoder\u7c7b\u4f3c\u4e8eVGG, Interest Point Decoder\uff0c65\u4e2aChannels,\u610f\u601d\u662f\u5468\u8fb9 8\\times 8 \u4e2a\u65b9\u5757\u6709keypoint\u7684\u6982\u7387\uff0c\u8fd8\u6709\u4e00\u4e2a\u662f\u7a7a\u7c7b. \u8fd9\u91cc\u7684 reshape \u5bf9\u5e94\u7684\u662fpytorch.nn.pixelshuffel\u64cd\u4f5c\uff0c\u5c06channel\u7684\u5185\u5bb9\u7ffb\u5230feature map\u7a7a\u95f4\u7684\u533a\u57df\u3002 \u5982\u679cground truth\u91cc\u9762 8\\times 8 \u533a\u57df\u91cc\u9762\u6709\u4e0d\u6b62\u4e00\u4e2a\u70b9\u5219\u968f\u673a\u9009\u53d6\u4e00\u4e2a\u4f5c\u4e3a\u8be5\u533a\u57df\u91cc\u9762\u6709\u6548\u7684ground truth\u3002 \u8fd9\u91cc\u4f7f\u7528cross-entropy,\u8ba1\u7b97 \\mathcal{L}_p \u8fdb\u884c\u8bad\u7ec3\u3002 descriptor\u7684\u8bad\u7ec3\uff0c\u4f9d\u9760\u7684\u662f\u540c\u4e00\u5f20\u56fe\uff0c\u5c06\u56fehomographic transform\u5230\u53e6\u4e00\u5f20\u56fe\u53bb\uff0c\u8981\u6c42keypoint\u5bf9\u5e94\u7684\u4f4d\u7f6e\u63cf\u8ff0\u76f8\u540c\u3002 s_{h w h^{\\prime} w^{\\prime}} \u6307\u4ee3\u5bf9\u5e94\u5173\u7cfb s_{h w h^{\\prime} w^{\\prime}}=\\left\\{\\begin{array}{ll}{1,} & {\\text { if } \\| \\widehat{\\mathcal{H} \\mathbf{p}_{h w}}-\\mathbf{p}_{h^{\\prime} w^{\\prime}}|| \\leq 8} \\\\ {0,} & {\\text { otherwise }}\\end{array}\\right. \\begin{aligned} l_{d}\\left(\\mathbf{d}, \\mathbf{d}^{\\prime} ; s\\right) &=\\lambda_{d} * s * \\max \\left(0, m_{p}-\\mathbf{d}^{T} \\mathbf{d}^{\\prime}\\right) \\\\ &+(1-s) * \\max \\left(0, \\mathbf{d}^{T} \\mathbf{d}^{\\prime}-m_{n}\\right) \\end{aligned} \\begin{aligned} \\mathcal{L}_{d}\\left(\\mathcal{D}, \\mathcal{D}^{\\prime}, S\\right) &=\\\\ \\frac{1}{\\left(H_{c} W_{c}\\right)^{2}} &\\sum_{h=1}^{H_{c}, W_{c} H_{c}, W_{c}} l_{d}\\left(\\mathbf{d}_{h w}, \\mathbf{d}_{h^{\\prime} w^{\\prime}}^{\\prime} ; s_{h w h^{\\prime} w^{\\prime}}\\right) \\end{aligned} \\begin{aligned} \\mathcal{L}\\left(\\mathcal{X}, \\mathcal{X}^{\\prime}, \\mathcal{D}, \\mathcal{D}^{\\prime} ; Y, Y^{\\prime}, S\\right) &=\\\\ \\mathcal{L}_{p}(\\mathcal{X}, Y)&+\\mathcal{L}_{p}\\left(\\mathcal{X}^{\\prime}, Y^{\\prime}\\right)+\\lambda \\mathcal{L}_{d}\\left(\\mathcal{D}, \\mathcal{D}^{\\prime}, S\\right) \\end{aligned}","title":"\u7f51\u7edc\u6a21\u578b"},{"location":"other_categories/SLAM/Unsupervised_Learning_of_Depth_and_Ego-Motion_from_Video/","text":"Unsupervised Learning of Depth and Ego-Motion from Video \u8fd9\u7bc7\u6587\u7ae0\u5bf9\u6211\u6765\u8bf4\u8bf4\u662f \u8fd9\u7bc7\u6587\u7ae0 \u7684\u524d\u7f6e \u8fd9\u7bc7\u6587\u7ae0\u89e3\u51b3\u7684\u95ee\u9898\u4e5f\u662f\u8f93\u5165\u89c6\u9891\uff0c\u8f93\u51fa\u6df1\u5ea6\u4e0e\u76f8\u673a\u8fd0\u52a8\u7684\u4f30\u8ba1 \u4e3bpipeline \u4f7f\u7528\u76f8\u90bb\u4e09\u5f20\u56fe\uff0c\u5c06\u5f53\u524d I_t \u8f93\u5165\u5230Depth CNN\u8f93\u51fa\u6df1\u5ea6\u56fe\uff0c\u5c06\u76f8\u90bb\u7684 I_{t-1}, I_{t+1} \u5171\u4e09\u5f20\u56fe\u8f93\u5165\u5230pose CNN(CNN\u76f4\u63a5\u8f93\u51fa\u516d\u81ea\u7531\u5ea6\u8fd0\u52a8)\u4e2d\u8f93\u51fa\u524d\u540e\u4e24\u4e2a\u76f8\u5bf9pose\uff0c\u5728\u5df2\u77e5\u5f53\u524d\u56fe\u7684\u6df1\u5ea6\u4ee5\u53ca\u8fd0\u52a8\uff0c\u5c06\u5f53\u524d\u56fe\u8f6c\u6362\u5230\u524d\u540e\u65f6\u523b\u7684\u56fe\u7247\u4e0a(\u4f7f\u7528bilinear intepolation\u8fdb\u884c\u53ef\u5bfc\u7684\u8f6c\u6362) \u672c\u6587\u8fd8\u6709\u66f4\u591a\u5185\u5bb9\u5982(Explainability mask)\uff0c\u6b64\u5904\u8ba8\u8bba\u5230\u6b64\u4e3a\u6b62\u3002","title":"Unsupervised Learning of Depth and Ego-Motion from Video"},{"location":"other_categories/SLAM/Unsupervised_Learning_of_Depth_and_Ego-Motion_from_Video/#unsupervised-learning-of-depth-and-ego-motion-from-video","text":"\u8fd9\u7bc7\u6587\u7ae0\u5bf9\u6211\u6765\u8bf4\u8bf4\u662f \u8fd9\u7bc7\u6587\u7ae0 \u7684\u524d\u7f6e \u8fd9\u7bc7\u6587\u7ae0\u89e3\u51b3\u7684\u95ee\u9898\u4e5f\u662f\u8f93\u5165\u89c6\u9891\uff0c\u8f93\u51fa\u6df1\u5ea6\u4e0e\u76f8\u673a\u8fd0\u52a8\u7684\u4f30\u8ba1","title":"Unsupervised Learning of Depth and Ego-Motion from Video"},{"location":"other_categories/SLAM/Unsupervised_Learning_of_Depth_and_Ego-Motion_from_Video/#pipeline","text":"\u4f7f\u7528\u76f8\u90bb\u4e09\u5f20\u56fe\uff0c\u5c06\u5f53\u524d I_t \u8f93\u5165\u5230Depth CNN\u8f93\u51fa\u6df1\u5ea6\u56fe\uff0c\u5c06\u76f8\u90bb\u7684 I_{t-1}, I_{t+1} \u5171\u4e09\u5f20\u56fe\u8f93\u5165\u5230pose CNN(CNN\u76f4\u63a5\u8f93\u51fa\u516d\u81ea\u7531\u5ea6\u8fd0\u52a8)\u4e2d\u8f93\u51fa\u524d\u540e\u4e24\u4e2a\u76f8\u5bf9pose\uff0c\u5728\u5df2\u77e5\u5f53\u524d\u56fe\u7684\u6df1\u5ea6\u4ee5\u53ca\u8fd0\u52a8\uff0c\u5c06\u5f53\u524d\u56fe\u8f6c\u6362\u5230\u524d\u540e\u65f6\u523b\u7684\u56fe\u7247\u4e0a(\u4f7f\u7528bilinear intepolation\u8fdb\u884c\u53ef\u5bfc\u7684\u8f6c\u6362) \u672c\u6587\u8fd8\u6709\u66f4\u591a\u5185\u5bb9\u5982(Explainability mask)\uff0c\u6b64\u5904\u8ba8\u8bba\u5230\u6b64\u4e3a\u6b62\u3002","title":"\u4e3bpipeline"},{"location":"other_categories/Segmentation/Actor-Critic Instance Segmentation/","text":"Actor-Critic Instance Segmentation \u8fd9\u7bc7\u8bba\u6587\u4f7f\u7528actor critic \u5f3a\u5316\u5b66\u4e60\uff0c\u4fbf\u4e8e\u9884\u6d4b\u4e00\u7cfb\u5217\u7684segmentation result \u6574\u4f53\u7ed3\u6784 \u5f3a\u5316\u5b66\u4e60\u5b9a\u4e49 \u72b6\u6001\u7a7a\u95f4 s_t = (I, M_t) \u5176\u4e2d I \u4e3a\u8f93\u5165\u56fe\u7247\uff0c M_t \u4e3a\u7b2c t \u65f6\u523b\u7684\u7efc\u5408mask \u884c\u52a8 a_t \u662fdecoder\u7684\u8f93\u5165\uff0c\u662f\u4e00\u4e2a\u8f83\u4e3a\u4f4e\u7ef4\u7684\u8fde\u7eed\u77e2\u91cf \u72b6\u6001\u8f6c\u79fb T = (I, max(M_t, D(a_t))) \uff0c\u76f8\u5f53\u4e8e\u5c06\u65b0decode\u7684mask\u52a0\u548c\u5728\u539f\u6765\u7684\u7d2f\u52a0mask\u4e0a reward\uff0c\u5148\u5b9a\u4e49 \\phi_t = max(\\sum_{i=1}^t F(S_i, T_{ki})) \u610f\u601d\u662f\u5bfb\u627e\u6700\u4f18\u7684predicted instance-ground truth\u642d\u914d\uff0c\u5f97\u5230\u7684\u6700\u5927\u5956\u52b1\uff0c\u7136\u540ereward\u5c31\u662f r_t = \\phi(s_{t+1}) - \\phi(s_t) \u4f7f\u7528\u91cd\u70b9\uff1a 1. decoder\u9700\u8981\u63d0\u524dtrain\u597d\uff0c\u6700\u597d\u4e0d\u8981\u6539\u53d8,\u9700\u8981\u7684\u662f\u4e00\u4e2aconditional variational encoder(cVAE) 2. \u9700\u8981\u5141\u8bb8critics warm-up AC training","title":"Actor-Critic Instance Segmentation"},{"location":"other_categories/Segmentation/Actor-Critic Instance Segmentation/#actor-critic-instance-segmentation","text":"\u8fd9\u7bc7\u8bba\u6587\u4f7f\u7528actor critic \u5f3a\u5316\u5b66\u4e60\uff0c\u4fbf\u4e8e\u9884\u6d4b\u4e00\u7cfb\u5217\u7684segmentation result","title":"Actor-Critic Instance Segmentation"},{"location":"other_categories/Segmentation/Actor-Critic Instance Segmentation/#_1","text":"","title":"\u6574\u4f53\u7ed3\u6784"},{"location":"other_categories/Segmentation/Actor-Critic Instance Segmentation/#_2","text":"\u72b6\u6001\u7a7a\u95f4 s_t = (I, M_t) \u5176\u4e2d I \u4e3a\u8f93\u5165\u56fe\u7247\uff0c M_t \u4e3a\u7b2c t \u65f6\u523b\u7684\u7efc\u5408mask \u884c\u52a8 a_t \u662fdecoder\u7684\u8f93\u5165\uff0c\u662f\u4e00\u4e2a\u8f83\u4e3a\u4f4e\u7ef4\u7684\u8fde\u7eed\u77e2\u91cf \u72b6\u6001\u8f6c\u79fb T = (I, max(M_t, D(a_t))) \uff0c\u76f8\u5f53\u4e8e\u5c06\u65b0decode\u7684mask\u52a0\u548c\u5728\u539f\u6765\u7684\u7d2f\u52a0mask\u4e0a reward\uff0c\u5148\u5b9a\u4e49 \\phi_t = max(\\sum_{i=1}^t F(S_i, T_{ki})) \u610f\u601d\u662f\u5bfb\u627e\u6700\u4f18\u7684predicted instance-ground truth\u642d\u914d\uff0c\u5f97\u5230\u7684\u6700\u5927\u5956\u52b1\uff0c\u7136\u540ereward\u5c31\u662f r_t = \\phi(s_{t+1}) - \\phi(s_t) \u4f7f\u7528\u91cd\u70b9\uff1a 1. decoder\u9700\u8981\u63d0\u524dtrain\u597d\uff0c\u6700\u597d\u4e0d\u8981\u6539\u53d8,\u9700\u8981\u7684\u662f\u4e00\u4e2aconditional variational encoder(cVAE) 2. \u9700\u8981\u5141\u8bb8critics warm-up AC training","title":"\u5f3a\u5316\u5b66\u4e60\u5b9a\u4e49"},{"location":"other_categories/Segmentation/CONVOLUTIONAL CRFS  FOR SEMANTIC SEGMENTATION/","text":"Convolutional CRFs for Semantic Segmentation \u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u5377\u79ef\u7248\u7684Conditional Random Field(CRF)\u7528\u4e8e\u4f18\u5316\u8bed\u4e49\u5206\u5272\u7684\u7ed3\u679c\u3002\u9996\u5148\u56de\u987e(\u5bf9\u5199review\u7684\u6211\u6b64\u65f6\u662f\u65b0\u5b66\u7684) FullCRF\u7684\u7b97\u6cd5\uff0c\u7136\u540e\u63d0\u51fa\u4e86ConvCRF\u7684\u7b97\u6cd5\u4ee5\u53caimplementation, \u4f5c\u8005\u4ee3\u7801\u5df2\u5f00\u6e90 FullCRF CRF\u7684\u539f\u610f\u5728\u4e8e\u8ba9\u7279\u5f81\u76f8\u4f3c\u7684\u70b9\u8f93\u51fa\u76f8\u4f3c\u7684\u503c\uff0c\u6700\u540e\u8f6c\u6362\u4e3a\u4f18\u5316\u4e00\u4e0b\u8fd9\u4e2a\u6761\u4ef6\u6982\u7387: E(\\hat{x} | I)=\\sum_{i \\leq N} \\psi_{u}\\left(\\hat{x}_{i} | I\\right)+\\sum_{i \\neq j \\leq N} \\psi_{p}\\left(\\hat{x}_{i}, \\hat{x}_{j} | I\\right) \u7b2c\u4e00\u9879\u4e3a\u57fa\u7840\u5168\u8bed\u4e49\u5206\u5272\u7f51\u7edc\u8f93\u51fa\u7684\u503c\uff0c\u7b2c\u4e8c\u9879\u4f53\u73b0\u56fe\u7247\u4e2d\u4e0d\u540c\u4f4d\u7f6e\u7684\u76f8\u4e92\u5f71\u54cd\u3002FullCRF\u4e2d\uff0c\u7b2c\u4e8c\u9879\u8ba1\u7b97\u516c\u5f0f\u4e3a \\psi_{p}\\left(x_{i}, x_{j} | I\\right) :=\\mu\\left(x_{i}, x_{j}\\right) \\sum_{m=1}^{M} w^{(m)} k_{G}^{(m)}\\left(f_{i}^{I}, f_{j}^{I}\\right) \u5176\u4e2d \\mu(x_i,x_j) = |x_i \\neq x_j| \u4e5f\u5c31\u662f\u56fe\u4e2d\u6bcf\u4e00\u4e2a\u70b9(\u9664\u4e86\u70b9i\u4e4b\u5916).\u5e38\u7528\u7684\u6838\u51fd\u6570 k \u6709\u5982\u4ee5\u4e0b\u7684\u9ad8\u65af\u51fd\u6570 k\\left(f_{i}^{I}, f_{j}^{I}\\right) :=w^{(1)} \\exp \\left(-\\frac{\\left|p_{i}-p_{j}\\right|^{2}}{2 \\theta_{\\alpha}^{2}}-\\frac{\\left|I_{i}-I_{j}\\right|^{2}}{2 \\theta_{\\beta}^{2}}\\right)+w^{(2)} \\exp \\left(-\\frac{\\left|p_{i}-p_{j}\\right|^{2}}{2 \\theta_{\\gamma}^{2}}\\right) \u5176\u4e2d w^{(1)},\\theta \u7b49\u662f\u4ec5\u6709\u7684\u53ef\u5b66\u4e60\u53c2\u6570\uff0c\u76f4\u89c9\u800c\u8a00\uff0c\u5c31\u662f\u7279\u5f81\u76f8\u4f3c\u8005\u76f8\u4e92\u5f71\u54cd\u5927\uff0c\u8ddd\u79bb\u8fd1\u8005\u76f8\u4e92\u5f71\u54cd\u5927\u3002 \u6700\u7ec8\u5b9e\u73b0\u7684\u8fed\u4ee3\u7b97\u6cd5: ConvCRF ConvCRF\u5148\u5047\u8bbe\u4e24\u4e2a\u66fc\u54c8\u987f\u8ddd\u79bb\u5927\u4e8e\u4e00\u5b9a\u9608\u503c k \u7684\u70b9\u76f8\u4e92\u72ec\u7acb\uff0c\u8fd9\u4e2a k \u79f0\u4e3aConvCRF\u7684filter size.\u8fd9\u4e5f\u5c31\u662fConvCRF\u5bf9\u524d\u6587 \\mu(x_i,x_j) \u7684\u9884\u8bbe\u65b9\u5f0f \u5bf9\u4e8e\u4f4d\u4e8e x,y \u7684\u70b9\u5b83\u5bf9\u5e94\u7684\u5377\u79ef\u6838/CRF\u6838\u4e3a k_{g}[b, d x, d y, x, y] :=\\exp \\left(-\\sum_{i=1}^{d} \\frac{\\left|f_{i}^{(d)}[b, x, y]-f_{i}^{(d)}[b, x-d x, y-d y]\\right|^{2}}{2 \\dot{\\theta}_{i}^{2}}\\right) \u5176\u4e2d \\theta_i \u4e3a\u53ef\u5b66\u4e60\u7684\u53d8\u91cf f_i \u4e3a\u7279\u5f81\u5411\u91cf,\u5377\u79ef\u8303\u56f4\u5185\u7684\u6bcf\u4e00\u4e2apair\u6709\u4e00\u4e2a\u5bf9\u5e94\u7684, K=\\sum^s_{i=1}w_i g_i \u7ed3\u679cQ,combined message\u5219\u7531\u6b64\u5f0f\u5b50\u7ed9\u51fa Q[b, c, x, y]=\\sum_{d x, d y \\leq k} K[b, d x, d y, x, y] \\cdot P[b, c, x+d x, y+d y] \u4f5c\u8005\u63d0\u5230\uff0c\u8fd9\u4e2a\u8fd0\u7b97\u64cd\u4f5c\u53ef\u4ee5\u8bf4\u7c7b\u4f3c\u4e8elocally connected layers(every pixel has its own filter),\u533a\u522b\u5728\u4e8e\u6bcf\u4e00\u4e2akernel\u5728channel\u65b9\u5411\u4e0a\u662f\u4e00\u4e2a\u5e38\u6570(\u53ea\u8d1f\u8d23\u52a0\u6743\u6c42\u548c\u6574\u4e2afeature vector\u800c\u4e0d\u9700\u8981\u91cd\u6574feature)\u3002 (\u9898\u5916\u8bdd\uff0clocally connected layer\u76ee\u524d\u6709keras implementation\u4f46\u662f\u8fd8\u6ca1\u6709officail pytorch implementation\uff0c \u53c2\u8003 )","title":"Convolutional CRFs for Semantic Segmentation"},{"location":"other_categories/Segmentation/CONVOLUTIONAL CRFS  FOR SEMANTIC SEGMENTATION/#convolutional-crfs-for-semantic-segmentation","text":"\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u5377\u79ef\u7248\u7684Conditional Random Field(CRF)\u7528\u4e8e\u4f18\u5316\u8bed\u4e49\u5206\u5272\u7684\u7ed3\u679c\u3002\u9996\u5148\u56de\u987e(\u5bf9\u5199review\u7684\u6211\u6b64\u65f6\u662f\u65b0\u5b66\u7684) FullCRF\u7684\u7b97\u6cd5\uff0c\u7136\u540e\u63d0\u51fa\u4e86ConvCRF\u7684\u7b97\u6cd5\u4ee5\u53caimplementation, \u4f5c\u8005\u4ee3\u7801\u5df2\u5f00\u6e90","title":"Convolutional CRFs for Semantic Segmentation"},{"location":"other_categories/Segmentation/CONVOLUTIONAL CRFS  FOR SEMANTIC SEGMENTATION/#fullcrf","text":"CRF\u7684\u539f\u610f\u5728\u4e8e\u8ba9\u7279\u5f81\u76f8\u4f3c\u7684\u70b9\u8f93\u51fa\u76f8\u4f3c\u7684\u503c\uff0c\u6700\u540e\u8f6c\u6362\u4e3a\u4f18\u5316\u4e00\u4e0b\u8fd9\u4e2a\u6761\u4ef6\u6982\u7387: E(\\hat{x} | I)=\\sum_{i \\leq N} \\psi_{u}\\left(\\hat{x}_{i} | I\\right)+\\sum_{i \\neq j \\leq N} \\psi_{p}\\left(\\hat{x}_{i}, \\hat{x}_{j} | I\\right) \u7b2c\u4e00\u9879\u4e3a\u57fa\u7840\u5168\u8bed\u4e49\u5206\u5272\u7f51\u7edc\u8f93\u51fa\u7684\u503c\uff0c\u7b2c\u4e8c\u9879\u4f53\u73b0\u56fe\u7247\u4e2d\u4e0d\u540c\u4f4d\u7f6e\u7684\u76f8\u4e92\u5f71\u54cd\u3002FullCRF\u4e2d\uff0c\u7b2c\u4e8c\u9879\u8ba1\u7b97\u516c\u5f0f\u4e3a \\psi_{p}\\left(x_{i}, x_{j} | I\\right) :=\\mu\\left(x_{i}, x_{j}\\right) \\sum_{m=1}^{M} w^{(m)} k_{G}^{(m)}\\left(f_{i}^{I}, f_{j}^{I}\\right) \u5176\u4e2d \\mu(x_i,x_j) = |x_i \\neq x_j| \u4e5f\u5c31\u662f\u56fe\u4e2d\u6bcf\u4e00\u4e2a\u70b9(\u9664\u4e86\u70b9i\u4e4b\u5916).\u5e38\u7528\u7684\u6838\u51fd\u6570 k \u6709\u5982\u4ee5\u4e0b\u7684\u9ad8\u65af\u51fd\u6570 k\\left(f_{i}^{I}, f_{j}^{I}\\right) :=w^{(1)} \\exp \\left(-\\frac{\\left|p_{i}-p_{j}\\right|^{2}}{2 \\theta_{\\alpha}^{2}}-\\frac{\\left|I_{i}-I_{j}\\right|^{2}}{2 \\theta_{\\beta}^{2}}\\right)+w^{(2)} \\exp \\left(-\\frac{\\left|p_{i}-p_{j}\\right|^{2}}{2 \\theta_{\\gamma}^{2}}\\right) \u5176\u4e2d w^{(1)},\\theta \u7b49\u662f\u4ec5\u6709\u7684\u53ef\u5b66\u4e60\u53c2\u6570\uff0c\u76f4\u89c9\u800c\u8a00\uff0c\u5c31\u662f\u7279\u5f81\u76f8\u4f3c\u8005\u76f8\u4e92\u5f71\u54cd\u5927\uff0c\u8ddd\u79bb\u8fd1\u8005\u76f8\u4e92\u5f71\u54cd\u5927\u3002 \u6700\u7ec8\u5b9e\u73b0\u7684\u8fed\u4ee3\u7b97\u6cd5:","title":"FullCRF"},{"location":"other_categories/Segmentation/CONVOLUTIONAL CRFS  FOR SEMANTIC SEGMENTATION/#convcrf","text":"ConvCRF\u5148\u5047\u8bbe\u4e24\u4e2a\u66fc\u54c8\u987f\u8ddd\u79bb\u5927\u4e8e\u4e00\u5b9a\u9608\u503c k \u7684\u70b9\u76f8\u4e92\u72ec\u7acb\uff0c\u8fd9\u4e2a k \u79f0\u4e3aConvCRF\u7684filter size.\u8fd9\u4e5f\u5c31\u662fConvCRF\u5bf9\u524d\u6587 \\mu(x_i,x_j) \u7684\u9884\u8bbe\u65b9\u5f0f \u5bf9\u4e8e\u4f4d\u4e8e x,y \u7684\u70b9\u5b83\u5bf9\u5e94\u7684\u5377\u79ef\u6838/CRF\u6838\u4e3a k_{g}[b, d x, d y, x, y] :=\\exp \\left(-\\sum_{i=1}^{d} \\frac{\\left|f_{i}^{(d)}[b, x, y]-f_{i}^{(d)}[b, x-d x, y-d y]\\right|^{2}}{2 \\dot{\\theta}_{i}^{2}}\\right) \u5176\u4e2d \\theta_i \u4e3a\u53ef\u5b66\u4e60\u7684\u53d8\u91cf f_i \u4e3a\u7279\u5f81\u5411\u91cf,\u5377\u79ef\u8303\u56f4\u5185\u7684\u6bcf\u4e00\u4e2apair\u6709\u4e00\u4e2a\u5bf9\u5e94\u7684, K=\\sum^s_{i=1}w_i g_i \u7ed3\u679cQ,combined message\u5219\u7531\u6b64\u5f0f\u5b50\u7ed9\u51fa Q[b, c, x, y]=\\sum_{d x, d y \\leq k} K[b, d x, d y, x, y] \\cdot P[b, c, x+d x, y+d y] \u4f5c\u8005\u63d0\u5230\uff0c\u8fd9\u4e2a\u8fd0\u7b97\u64cd\u4f5c\u53ef\u4ee5\u8bf4\u7c7b\u4f3c\u4e8elocally connected layers(every pixel has its own filter),\u533a\u522b\u5728\u4e8e\u6bcf\u4e00\u4e2akernel\u5728channel\u65b9\u5411\u4e0a\u662f\u4e00\u4e2a\u5e38\u6570(\u53ea\u8d1f\u8d23\u52a0\u6743\u6c42\u548c\u6574\u4e2afeature vector\u800c\u4e0d\u9700\u8981\u91cd\u6574feature)\u3002 (\u9898\u5916\u8bdd\uff0clocally connected layer\u76ee\u524d\u6709keras implementation\u4f46\u662f\u8fd8\u6ca1\u6709officail pytorch implementation\uff0c \u53c2\u8003 )","title":"ConvCRF"},{"location":"other_categories/Segmentation/Deep Multi-Sensor Lane Detection/","text":"Deep Multi-Sensor Lane Detection \u8fd9\u7bc7\u8bba\u6587\u7ed9\u51fa\u7528lidar\u548c\u56fe\u7247\u4e24\u8005\u5171\u540c\u8fdb\u884c\u5b66\u4e60\u4fa6\u6d4b\u9053\u8def\u7ebf\u7684\u7b97\u6cd5 \u5173\u952e\u70b9\uff1a \u4f5c\u8005\u7528\u56fe\u7247\u793a\u4f8b\u8bf4\u660e\uff0c\u5373\u4f7f\u5728\u76f8\u673a\u5750\u6807\u7cfb(\u56fe\u7247)\u4e2d\u5b9e\u73b0\u4e86\u8fd1\u4e4e\u5b8c\u7f8e\u7cbe\u786e\u7684road-segmentation,\u8f6c\u6362\u5230\u4fef\u89c6\u56fe\u7684\u65f6\u5019\u7cbe\u786e\u5ea6\u4ecd\u7136\u5f88\u4f4e\uff0c\u6240\u4ee5\u9700\u8981\u7528\u4fef\u89c6\u56fe\u76f4\u63a5\u5904\u7406\u3002 \u8f93\u51fa\u7684\u4fef\u89c6\u56fe\u4e2d\u6bcf\u4e00\u4e2a\u50cf\u7d20\u4ee3\u8868\u7684\u662f\u8be5\u70b9\u8ddd\u79bb\u6700\u8fd1\u9053\u8def\u7ebf\u7684\u8ddd\u79bb\u3002\u4e0e\u76f4\u63a5segmentation\u76f8\u6bd4\uff0c\u53ef\u4ee5\u7f13\u89e3\u8f93\u51fa\u7ed3\u679c\u4ec5\u4e0e\u7ed3\u679c\u7a0d\u7a0doffset\u65f6\u7684loss\u8fc7\u5927\u7b49\u7684\u95ee\u9898\u3002 \u70b9\u4e91\u8bc6\u522b\u8def\u5f84\u65f6\uff0c\u5730\u9762\u70b9\u8fc7\u4e8e\u7a00\u758f\uff0c\u6240\u4ee5\u9700\u8981\u6570\u4e2a\u70b9\u4e91\u6d4b\u91cf\u7ed3\u679c\u5408\u5e76\u4e00\u8d77\u4f7f\u7528\uff0c\u7136\u540e\u538b\u5728\u5e73\u9762\u56fe\u4e2d\u8f93\u5165CNN\u3002","title":"Deep Multi-Sensor Lane Detection"},{"location":"other_categories/Segmentation/Deep Multi-Sensor Lane Detection/#deep-multi-sensor-lane-detection","text":"\u8fd9\u7bc7\u8bba\u6587\u7ed9\u51fa\u7528lidar\u548c\u56fe\u7247\u4e24\u8005\u5171\u540c\u8fdb\u884c\u5b66\u4e60\u4fa6\u6d4b\u9053\u8def\u7ebf\u7684\u7b97\u6cd5 \u5173\u952e\u70b9\uff1a \u4f5c\u8005\u7528\u56fe\u7247\u793a\u4f8b\u8bf4\u660e\uff0c\u5373\u4f7f\u5728\u76f8\u673a\u5750\u6807\u7cfb(\u56fe\u7247)\u4e2d\u5b9e\u73b0\u4e86\u8fd1\u4e4e\u5b8c\u7f8e\u7cbe\u786e\u7684road-segmentation,\u8f6c\u6362\u5230\u4fef\u89c6\u56fe\u7684\u65f6\u5019\u7cbe\u786e\u5ea6\u4ecd\u7136\u5f88\u4f4e\uff0c\u6240\u4ee5\u9700\u8981\u7528\u4fef\u89c6\u56fe\u76f4\u63a5\u5904\u7406\u3002 \u8f93\u51fa\u7684\u4fef\u89c6\u56fe\u4e2d\u6bcf\u4e00\u4e2a\u50cf\u7d20\u4ee3\u8868\u7684\u662f\u8be5\u70b9\u8ddd\u79bb\u6700\u8fd1\u9053\u8def\u7ebf\u7684\u8ddd\u79bb\u3002\u4e0e\u76f4\u63a5segmentation\u76f8\u6bd4\uff0c\u53ef\u4ee5\u7f13\u89e3\u8f93\u51fa\u7ed3\u679c\u4ec5\u4e0e\u7ed3\u679c\u7a0d\u7a0doffset\u65f6\u7684loss\u8fc7\u5927\u7b49\u7684\u95ee\u9898\u3002 \u70b9\u4e91\u8bc6\u522b\u8def\u5f84\u65f6\uff0c\u5730\u9762\u70b9\u8fc7\u4e8e\u7a00\u758f\uff0c\u6240\u4ee5\u9700\u8981\u6570\u4e2a\u70b9\u4e91\u6d4b\u91cf\u7ed3\u679c\u5408\u5e76\u4e00\u8d77\u4f7f\u7528\uff0c\u7136\u540e\u538b\u5728\u5e73\u9762\u56fe\u4e2d\u8f93\u5165CNN\u3002","title":"Deep Multi-Sensor Lane Detection"},{"location":"other_categories/Segmentation/DeepSnake/","text":"Deep Snake for Real-Time Instance Segmentation \u8fd9\u7bc7paper\u5f15\u5165\u4e86\u6df1\u5ea6\u5b66\u4e60\u5316\u7684snake\u7b97\u6cd5\u3002snake\u7b97\u6cd5\u7684\u601d\u8def\u662f\u7ed9\u5b9a\u4e00\u4e2a\u521d\u59cb\u7684\u56de\u73afcontour, \u6bcf\u4e00\u4e2a\u8fb9\u7f18\u70b9\u6839\u636e\u81ea\u5df1\u9644\u8fd1\u56fe\u7247\u6027\u8d28\u7684energy function\u4ee5\u53ca\u5176\u4ed6\u4fe1\u606f\uff0c\u9010\u6b65\u574d\u7f29\u5230\u6240\u5173\u6ce8\u7684\u7269\u4f53\u7684\u8fb9\u7f18\u4e0a\uff0c\u7279\u70b9\u5728\u4e8e\u5bf9\u6210\u529f\u8fa8\u8bc6\u7684\u7269\u4f53\u8fd9\u4e2a\u7b97\u6cd5\u8fb9\u7f18\u4e0a\u7684\u7cbe\u786e\u5ea6\u76f8\u5bf9\u6709\u4fdd\u8bc1\u3002 Deep snake intuition \u521d\u59cbcontour \\rightarrow circular conv \\rightarrow conv \\rightarrow \u6bcf\u4e00\u4e2a\u70b9\u7684\u504f\u79fb\u3002 Circular Conv \u672c\u6587\u4ee3\u7801\u91cc\u9762\u4f7f\u7528\u4e00\u4e2a\u4e8c\u7ef4tensor\u6309\u5706\u5468\u987a\u5e8f\u5b58\u50a8contour\u70b9\uff0c\u5e76\u6ca1\u6709\u4f7f\u7528\u8fc7\u5ea6\u7684\u6280\u5de7\u3002 \u603b\u4f53\u7ed3\u6784 \u56feb\u8bf4\u660e\u6574\u4e2a\u56fe\u7684\u7ed3\u6784\uff0c\u9996\u5148\u4f7f\u75282D detector\u5f97\u5230\u57fa\u7840bounding box\uff0c\u7136\u540e\u8f6c\u5316\u4e3acoutour, \u7136\u540e\u4f7f\u7528\u7b2c\u4e00\u5c42deep snake(\u5927\u611f\u53d7\u91ce) \u8ba1\u7b97offset \\rightarrow upsampling\u523040\u4e2a\u70b9\uff0c\u518d\u7ecf\u8fc7deep snake(\u5c0f\u611f\u53d7\u91ce)\u5f97\u5230\u6700\u540e\u7684deformation output\u3002","title":"Deep Snake for Real-Time Instance Segmentation"},{"location":"other_categories/Segmentation/DeepSnake/#deep-snake-for-real-time-instance-segmentation","text":"\u8fd9\u7bc7paper\u5f15\u5165\u4e86\u6df1\u5ea6\u5b66\u4e60\u5316\u7684snake\u7b97\u6cd5\u3002snake\u7b97\u6cd5\u7684\u601d\u8def\u662f\u7ed9\u5b9a\u4e00\u4e2a\u521d\u59cb\u7684\u56de\u73afcontour, \u6bcf\u4e00\u4e2a\u8fb9\u7f18\u70b9\u6839\u636e\u81ea\u5df1\u9644\u8fd1\u56fe\u7247\u6027\u8d28\u7684energy function\u4ee5\u53ca\u5176\u4ed6\u4fe1\u606f\uff0c\u9010\u6b65\u574d\u7f29\u5230\u6240\u5173\u6ce8\u7684\u7269\u4f53\u7684\u8fb9\u7f18\u4e0a\uff0c\u7279\u70b9\u5728\u4e8e\u5bf9\u6210\u529f\u8fa8\u8bc6\u7684\u7269\u4f53\u8fd9\u4e2a\u7b97\u6cd5\u8fb9\u7f18\u4e0a\u7684\u7cbe\u786e\u5ea6\u76f8\u5bf9\u6709\u4fdd\u8bc1\u3002","title":"Deep Snake for Real-Time Instance Segmentation"},{"location":"other_categories/Segmentation/DeepSnake/#deep-snake-intuition","text":"\u521d\u59cbcontour \\rightarrow circular conv \\rightarrow conv \\rightarrow \u6bcf\u4e00\u4e2a\u70b9\u7684\u504f\u79fb\u3002","title":"Deep snake intuition"},{"location":"other_categories/Segmentation/DeepSnake/#circular-conv","text":"\u672c\u6587\u4ee3\u7801\u91cc\u9762\u4f7f\u7528\u4e00\u4e2a\u4e8c\u7ef4tensor\u6309\u5706\u5468\u987a\u5e8f\u5b58\u50a8contour\u70b9\uff0c\u5e76\u6ca1\u6709\u4f7f\u7528\u8fc7\u5ea6\u7684\u6280\u5de7\u3002","title":"Circular Conv"},{"location":"other_categories/Segmentation/DeepSnake/#_1","text":"\u56feb\u8bf4\u660e\u6574\u4e2a\u56fe\u7684\u7ed3\u6784\uff0c\u9996\u5148\u4f7f\u75282D detector\u5f97\u5230\u57fa\u7840bounding box\uff0c\u7136\u540e\u8f6c\u5316\u4e3acoutour, \u7136\u540e\u4f7f\u7528\u7b2c\u4e00\u5c42deep snake(\u5927\u611f\u53d7\u91ce) \u8ba1\u7b97offset \\rightarrow upsampling\u523040\u4e2a\u70b9\uff0c\u518d\u7ecf\u8fc7deep snake(\u5c0f\u611f\u53d7\u91ce)\u5f97\u5230\u6700\u540e\u7684deformation output\u3002","title":"\u603b\u4f53\u7ed3\u6784"},{"location":"other_categories/Segmentation/LRNNET/","text":"LRNNET: A LIGHT-WEIGHTED NETWORK WITH EFFICIENT REDUCED NON-LOCAL OPERATION FOR REAL-TIME SEMANTIC SEGMENTATION \u8fd9\u7bc7paper\u7684\u4e3b\u8981\u8d21\u732e\u5728\u4e8e\u63d0\u51fa\u4e86\u4e00\u4e2a\u7b80\u5316\u7248\u7684non-local\u7b97\u6cd5\u3002 \u5177\u4f53\u7684\u505a\u6cd5\u662f\u628a C\\times H \\times W \u7684\u5f20\u91cf\u4ee5 S \u4e3a\u91cf\u5316\u5355\u4f4d\uff0c\u5206\u5272\u4e3a S=\\frac{H\\times W}{H'\\times W'} \u4e2a\u8d85\u50cf\u7d20\uff0cnon-local\u7684\u9762\u79ef\u5927\u5c0f\u53d8\u4e3a H', W' \uff0c\u5927\u5e45\u5ea6\u964d\u4f4e\u8fd0\u7b97\u91cf\u3002 \u5bf9\u4e8e\u5404\u4e2a\u65b9\u5757\uff0c C \\times H' \\times W' , \u672c\u6587\u63d0\u51fa\u4e86\u4f7f\u7528normalized\u5de6\u5947\u5f02\u4e3b\u5411\u91cf\u4f5c\u4e3a\u5bf9\u6574\u4e2a\u8d85\u50cf\u7d20\u7684\u66ff\u4ee3\uff0c\u5c06\u5b83\u5e73\u6574\u4e3a C\\times (H'\\times W') \u77e9\u9635\uff0c\u7136\u540e\u4f7f\u7528power iteration\u7b97\u6cd5\u8ba1\u7b97\u5de6\u4e3b\u5947\u5f02\u77e2\u91cf C'\\times 1 .","title":"LRNNET: A LIGHT-WEIGHTED NETWORK WITH EFFICIENT REDUCED NON-LOCAL OPERATION FOR REAL-TIME SEMANTIC SEGMENTATION"},{"location":"other_categories/Segmentation/LRNNET/#lrnnet-a-light-weighted-network-with-efficient-reduced-non-local-operation-for-real-time-semantic-segmentation","text":"\u8fd9\u7bc7paper\u7684\u4e3b\u8981\u8d21\u732e\u5728\u4e8e\u63d0\u51fa\u4e86\u4e00\u4e2a\u7b80\u5316\u7248\u7684non-local\u7b97\u6cd5\u3002 \u5177\u4f53\u7684\u505a\u6cd5\u662f\u628a C\\times H \\times W \u7684\u5f20\u91cf\u4ee5 S \u4e3a\u91cf\u5316\u5355\u4f4d\uff0c\u5206\u5272\u4e3a S=\\frac{H\\times W}{H'\\times W'} \u4e2a\u8d85\u50cf\u7d20\uff0cnon-local\u7684\u9762\u79ef\u5927\u5c0f\u53d8\u4e3a H', W' \uff0c\u5927\u5e45\u5ea6\u964d\u4f4e\u8fd0\u7b97\u91cf\u3002 \u5bf9\u4e8e\u5404\u4e2a\u65b9\u5757\uff0c C \\times H' \\times W' , \u672c\u6587\u63d0\u51fa\u4e86\u4f7f\u7528normalized\u5de6\u5947\u5f02\u4e3b\u5411\u91cf\u4f5c\u4e3a\u5bf9\u6574\u4e2a\u8d85\u50cf\u7d20\u7684\u66ff\u4ee3\uff0c\u5c06\u5b83\u5e73\u6574\u4e3a C\\times (H'\\times W') \u77e9\u9635\uff0c\u7136\u540e\u4f7f\u7528power iteration\u7b97\u6cd5\u8ba1\u7b97\u5de6\u4e3b\u5947\u5f02\u77e2\u91cf C'\\times 1 .","title":"LRNNET: A LIGHT-WEIGHTED NETWORK WITH EFFICIENT REDUCED NON-LOCAL OPERATION FOR REAL-TIME SEMANTIC SEGMENTATION"},{"location":"other_categories/Segmentation/Lane Detection and Classification usingCascaded CNNs/","text":"Lane Detection and Classification using Cascaded CNNs \u8fd9\u7bc7\u8bba\u6587\u7ed9\u51fa\u7684\u662f\u7aef\u5230\u7aef\u8def\u7ebf\u70b9\u7684\u5206\u5272\u3001\u805a\u7c7b\u4ee5\u53ca\u5206\u7c7b\u7684\u7b97\u6cd5\u3002 \u6574\u4f53\u7ed3\u6784\u5982\u56fe 1. Instance Segmentation \u7528\u7269\u4f53\u5206\u5272\u505a\u7b2c\u4e00\u6b65\uff0c\u53ea\u63a2\u6d4b\u6700\u591a4\u6761\u7ebf\u3002\u4e2d\u5fc3\u4e24\u6761\u4ee5\u53ca\u5de6\u53f3\u4e00\u6761\u3002 2. \u5206\u7c7b \u6570\u636e\u4e0a\u4f7f\u7528\u989d\u5916\u7684\u4eba\u5de5\u6807\u6ce8\uff0c\u5f97\u5230\u56fe\u68ee\u6570\u636e\u96c6\u7684\u9053\u8def\u7ebf\u7c7b\u522b\uff0c github \u4eceSegmentation\u7684\u70b9\u4e2d\u627e\u5230\u539f\u56fe\u4e0a\u7684\u70b9\uff0c\u4ece\u4e2d\u91c7\u6837\u56fa\u5b9a\u6570\u91cf\u7684\u70b9(\u4f5c\u4e3a\u7a33\u5b9a\u7684\u8f93\u5165\u5927\u5c0f)\u3002 \u628a\u8fd9\u4e9bdescriptor(\u56fa\u5b9a\u6570\u91cf)\u8f93\u5165\u5230\u53e6\u4e00\u4e2a\u5355\u72ec\u8bad\u7ec3\u7684CNN\u4e2d\u5b8c\u6210\u5206\u7c7b\u3002","title":"Lane Detection and Classification using Cascaded CNNs"},{"location":"other_categories/Segmentation/Lane Detection and Classification usingCascaded CNNs/#lane-detection-and-classification-using-cascaded-cnns","text":"\u8fd9\u7bc7\u8bba\u6587\u7ed9\u51fa\u7684\u662f\u7aef\u5230\u7aef\u8def\u7ebf\u70b9\u7684\u5206\u5272\u3001\u805a\u7c7b\u4ee5\u53ca\u5206\u7c7b\u7684\u7b97\u6cd5\u3002 \u6574\u4f53\u7ed3\u6784\u5982\u56fe","title":"Lane Detection and Classification using Cascaded CNNs"},{"location":"other_categories/Segmentation/Lane Detection and Classification usingCascaded CNNs/#1-instance-segmentation","text":"\u7528\u7269\u4f53\u5206\u5272\u505a\u7b2c\u4e00\u6b65\uff0c\u53ea\u63a2\u6d4b\u6700\u591a4\u6761\u7ebf\u3002\u4e2d\u5fc3\u4e24\u6761\u4ee5\u53ca\u5de6\u53f3\u4e00\u6761\u3002","title":"1. Instance Segmentation"},{"location":"other_categories/Segmentation/Lane Detection and Classification usingCascaded CNNs/#2","text":"\u6570\u636e\u4e0a\u4f7f\u7528\u989d\u5916\u7684\u4eba\u5de5\u6807\u6ce8\uff0c\u5f97\u5230\u56fe\u68ee\u6570\u636e\u96c6\u7684\u9053\u8def\u7ebf\u7c7b\u522b\uff0c github \u4eceSegmentation\u7684\u70b9\u4e2d\u627e\u5230\u539f\u56fe\u4e0a\u7684\u70b9\uff0c\u4ece\u4e2d\u91c7\u6837\u56fa\u5b9a\u6570\u91cf\u7684\u70b9(\u4f5c\u4e3a\u7a33\u5b9a\u7684\u8f93\u5165\u5927\u5c0f)\u3002 \u628a\u8fd9\u4e9bdescriptor(\u56fa\u5b9a\u6570\u91cf)\u8f93\u5165\u5230\u53e6\u4e00\u4e2a\u5355\u72ec\u8bad\u7ec3\u7684CNN\u4e2d\u5b8c\u6210\u5206\u7c7b\u3002","title":"2. \u5206\u7c7b"},{"location":"other_categories/Segmentation/PointRend/","text":"PointRend: Image Segmentation as Rendering \u8fd9\u7bc7\u6765\u81eaFAIR\u7684\u8bba\u6587\u5c06\u8bed\u4e49\u5206\u5272\u7684\u540e\u5904\u7406\u7406\u89e3\u4e3a\u8ba1\u7b97\u673a\u56fe\u5f62\u5b66\u7684\u6e32\u67d3\u95ee\u9898\uff0c\u76ee\u6807\u5c31\u662f\u8981\u63d0\u5347\u8bed\u4e49\u5206\u5272\u5728\u7269\u4f53\u8fb9\u7f18\u7684\u6027\u80fd\uff0c\u540c\u65f6\u63a7\u5236\u8fd0\u7b97\u91cf\u3002\u91c7\u53d6\u7684\u65b9\u6cd5\u662f\u5148\u8f93\u51fa\u4e00\u4e2a\u4f4e\u5206\u8fa8\u7387\u7684\u5206\u5272\u56fe\uff0c\u518d\u9010\u6b65\u4e0a\u91c7\u6837\uff0c\u5728\u4e0a\u91c7\u6837\u7684\u8fc7\u7a0b\u4e2d\u5bf9\u8fb9\u7f18\u8fdb\u884c\u5904\u7406\uff0c\u6548\u679c\u50cf\u662f\u6e32\u67d3\u4e2d\u9010\u6b65\u7cbe\u4fee\u8fb9\u7f18\u7684\u89c6\u89c9\u6548\u679c\u3002 PointRend\u56fe\u793a \u5bf9\u4e8einstance segmentation\uff0c\u5148\u8f93\u51fa\u4e00\u4e2a\u7c97\u7cd9\u7684\u8bed\u4e49\u5206\u5272\u7ed3\u679c( 7\\times 7 )\uff0c\u7136\u540e\u8fed\u4ee3\u4e0a\u91c7\u6837\u8fc7\u7a0b\uff0c\u6bcf\u4e00\u4e2a\u4e0a\u91c7\u6837\u8fc7\u7a0b\u5305\u542b \u53cc\u7ebf\u6027\u63d2\u503c\u4e0a\u91c7\u6837 \u6267\u884cPointRend\u6a21\u5757\uff0c\u9009\u53d6\u4e0d\u786e\u5b9a\u6027\u9ad8\u7684\u70b9\uff0c\u63d0\u53d6\u51fa\u5176\u7279\u5f81\u77e2\u91cf\uff0c\u7528\u4e00\u4e2ashared\u7684MLP\u5f97\u5230\u5176\u8f93\u51fa\u7ed3\u679c\u3002 \u70b9\u7684\u9009\u62e9, \u63a8\u7406\u65f6 \u9009\u62e9\u7684\u8981\u6c42\u662f\u5bfb\u627eprobability\u6700\u63a5\u8fd10.5\u7684\u70b9\u8fdb\u884c\u5904\u7406\u3002 \u5bf9\u4e8e\u4e00\u4e2a\u76ee\u6807\u4e3a M\\times M \u7684\u5206\u5272\u56fe\uff0cPointRend\u53ea\u9700\u8981 N log_2\\frac{M}{M_0} \u6b21\u8f93\u51fa. \u5bf9\u4e8e M = 224, M_0 = 7 \u672c\u6587\u9009\u62e9 N = 28^2 ,\u662f\u539f\u6765\u7684 1/16 . \u70b9\u7684\u9009\u62e9\uff0c\u8bad\u7ec3\u65f6 \u672c\u6587\u91c7\u7528\u7684\u662f\u4e00\u4e2a\u5e26\u504f\u89c1\u7684\u968f\u673a\u91c7\u6837\uff0c\u7b97\u6cd5\u5982\u4e0b\uff1a \u8fc7\u91c7\u6837\uff0c\u603b\u5171\u4f1a\u968f\u673a\u91c7 kN (k > 1) \u4e2a\u70b9 \u4ece\u8fd9 kN \u4e2a\u70b9\u4e2d\u9009\u62e9 (\\beta N) \u4e2a\u6700\u4e0d\u786e\u5b9a\u7684\u70b9 \u4ece\u5269\u4e0b\u70b9\u4e2d\u5b8c\u5168\u968f\u673a\u91c7\u6837 (1-\\beta) N \u4e2a\u70b9, \u8bad\u7ec3\u8fc7\u7a0b\u4e0e\u7c97\u7cd9\u7684\u8bed\u4e49\u5206\u5272\u521d\u59cb\u4f30\u8ba1\u662f\u5e73\u884c\u7684\u3001\u5206\u79bb\u7684 \u6297\u952f\u9f7f\u6548\u679c\u56fe:","title":"PointRend: Image Segmentation as Rendering"},{"location":"other_categories/Segmentation/PointRend/#pointrend-image-segmentation-as-rendering","text":"\u8fd9\u7bc7\u6765\u81eaFAIR\u7684\u8bba\u6587\u5c06\u8bed\u4e49\u5206\u5272\u7684\u540e\u5904\u7406\u7406\u89e3\u4e3a\u8ba1\u7b97\u673a\u56fe\u5f62\u5b66\u7684\u6e32\u67d3\u95ee\u9898\uff0c\u76ee\u6807\u5c31\u662f\u8981\u63d0\u5347\u8bed\u4e49\u5206\u5272\u5728\u7269\u4f53\u8fb9\u7f18\u7684\u6027\u80fd\uff0c\u540c\u65f6\u63a7\u5236\u8fd0\u7b97\u91cf\u3002\u91c7\u53d6\u7684\u65b9\u6cd5\u662f\u5148\u8f93\u51fa\u4e00\u4e2a\u4f4e\u5206\u8fa8\u7387\u7684\u5206\u5272\u56fe\uff0c\u518d\u9010\u6b65\u4e0a\u91c7\u6837\uff0c\u5728\u4e0a\u91c7\u6837\u7684\u8fc7\u7a0b\u4e2d\u5bf9\u8fb9\u7f18\u8fdb\u884c\u5904\u7406\uff0c\u6548\u679c\u50cf\u662f\u6e32\u67d3\u4e2d\u9010\u6b65\u7cbe\u4fee\u8fb9\u7f18\u7684\u89c6\u89c9\u6548\u679c\u3002","title":"PointRend: Image Segmentation as Rendering"},{"location":"other_categories/Segmentation/PointRend/#pointrend","text":"\u5bf9\u4e8einstance segmentation\uff0c\u5148\u8f93\u51fa\u4e00\u4e2a\u7c97\u7cd9\u7684\u8bed\u4e49\u5206\u5272\u7ed3\u679c( 7\\times 7 )\uff0c\u7136\u540e\u8fed\u4ee3\u4e0a\u91c7\u6837\u8fc7\u7a0b\uff0c\u6bcf\u4e00\u4e2a\u4e0a\u91c7\u6837\u8fc7\u7a0b\u5305\u542b \u53cc\u7ebf\u6027\u63d2\u503c\u4e0a\u91c7\u6837 \u6267\u884cPointRend\u6a21\u5757\uff0c\u9009\u53d6\u4e0d\u786e\u5b9a\u6027\u9ad8\u7684\u70b9\uff0c\u63d0\u53d6\u51fa\u5176\u7279\u5f81\u77e2\u91cf\uff0c\u7528\u4e00\u4e2ashared\u7684MLP\u5f97\u5230\u5176\u8f93\u51fa\u7ed3\u679c\u3002","title":"PointRend\u56fe\u793a"},{"location":"other_categories/Segmentation/PointRend/#_1","text":"\u9009\u62e9\u7684\u8981\u6c42\u662f\u5bfb\u627eprobability\u6700\u63a5\u8fd10.5\u7684\u70b9\u8fdb\u884c\u5904\u7406\u3002 \u5bf9\u4e8e\u4e00\u4e2a\u76ee\u6807\u4e3a M\\times M \u7684\u5206\u5272\u56fe\uff0cPointRend\u53ea\u9700\u8981 N log_2\\frac{M}{M_0} \u6b21\u8f93\u51fa. \u5bf9\u4e8e M = 224, M_0 = 7 \u672c\u6587\u9009\u62e9 N = 28^2 ,\u662f\u539f\u6765\u7684 1/16 .","title":"\u70b9\u7684\u9009\u62e9, \u63a8\u7406\u65f6"},{"location":"other_categories/Segmentation/PointRend/#_2","text":"\u672c\u6587\u91c7\u7528\u7684\u662f\u4e00\u4e2a\u5e26\u504f\u89c1\u7684\u968f\u673a\u91c7\u6837\uff0c\u7b97\u6cd5\u5982\u4e0b\uff1a \u8fc7\u91c7\u6837\uff0c\u603b\u5171\u4f1a\u968f\u673a\u91c7 kN (k > 1) \u4e2a\u70b9 \u4ece\u8fd9 kN \u4e2a\u70b9\u4e2d\u9009\u62e9 (\\beta N) \u4e2a\u6700\u4e0d\u786e\u5b9a\u7684\u70b9 \u4ece\u5269\u4e0b\u70b9\u4e2d\u5b8c\u5168\u968f\u673a\u91c7\u6837 (1-\\beta) N \u4e2a\u70b9, \u8bad\u7ec3\u8fc7\u7a0b\u4e0e\u7c97\u7cd9\u7684\u8bed\u4e49\u5206\u5272\u521d\u59cb\u4f30\u8ba1\u662f\u5e73\u884c\u7684\u3001\u5206\u79bb\u7684 \u6297\u952f\u9f7f\u6548\u679c\u56fe:","title":"\u70b9\u7684\u9009\u62e9\uff0c\u8bad\u7ec3\u65f6"},{"location":"other_categories/Segmentation/PolorMask/","text":"PolarMask: Single Shot Instance Segmentation with Polar Representation \u8fd9\u7bc7paper\u53d7\u542f\u53d1\u4e8e FCOS \uff0c\u4f7f\u7528\u65b0\u7684\u6570\u636e\u8868\u8fbe\u65b9\u5f0f\uff0c\u5c06Instance Segmentation\u5728network inference\u4e0a\u5212\u5f52\u4e3a\u4e0e2D detection\u5b8c\u5168\u4e00\u81f4\u7684\u590d\u6742\u5ea6\u3002\u6709\u673a\u4f1a\u4e0e YOLOACT \u7ade\u4e89\u6210\u4e3aInstance Seg\u5de5\u4e1a\u4f7f\u7528\u7684\u6807\u51c6\u3002 \u603b\u4f53\u7ed3\u6784 \u5728\u7f51\u7edc\u7ed3\u6784\u4e0a\u9762\u8fd9\u7bc7paper\u9009\u62e9\u7684\u662f\u4e0e FCOS \u4e00\u81f4\u7684\u7ed3\u6784\uff0c\u4ec5\u4ec5\u5728 regression\u5206\u652f\u4e0a\u6539\u4e3a\u5bf9 n=36 \u4e2a\u5c04\u7ebf\u65b9\u5411\u7684\u8ddd\u79bb\u8fdb\u884c\u56de\u5f52\u3002 \u6bcf\u4e00\u4e2ainstance\u88ab\u5efa\u6a21\u4e3a\u4e2d\u5fc3\u70b9+\u5bc6\u96c6\u7684\u4ece\u4e2d\u5fc3\u70b9\u5f80\u5916\u7684\u5c04\u7ebf\u5f62\u6210\u7684contour. \"\u4e2d\u5fc3\"\u5b9a\u4e49 \u4e0e FCOS \u7c7b\u4f3c\uff0c\u8fd9\u91cc\u9700\u8981\u5b9a\u4e49\u4e00\u4e2a\u4e2d\u5fc3\u70b9\uff0c\u540c\u65f6\u9700\u8981\u5b9a\u4e49\u4e00\u4e2a\u4e2d\u5fc3\u5ea6\u3002\u4f5c\u8005\u6bd4\u8f83\u8fc7\u4f7f\u7528bounding box\u7684\u4e2d\u70b9\u4e0e\u8d28\u5fc3\uff0c\u53d1\u73b0\u4f7f\u7528\u8d28\u5fc3\u7406\u8bba\u6027\u80fd\u4e0a\u9650\u66f4\u597d\uff0c\u6240\u4ee5\u672c\u6587\u7684ground truth center\u7684\u4f4d\u7f6e\u4e2d\u5fc3\u5728\u8d28\u5fc3\u4e0a\uff0c\u4f5c\u8005\u5141\u8bb8\u51e0\u4e2apixel\u7ea7\u522b\u7684\u6270\u52a8\uff0c\u589e\u52a0\u6b63\u6837\u672c\u6570\u91cf\u3002 \u800c\u4e2d\u5fc3\u5ea6\u4e0e FCOS \u7684centerness\u6709\u4e00\u5b9a\u533a\u522b\uff0c\u4f46\u662f\u601d\u8def\u4e00\u81f4\uff0c\u516c\u5f0f\u5982\u4e0b\uff1a \\text { Polar Centerness }=\\sqrt{\\frac{\\min \\left(\\left\\{d_{1}, d_{2}, \\ldots, d_{n}\\right\\}\\right)}{\\max \\left(\\left\\{d_{1}, d_{2}, \\ldots, d_{n}\\right\\}\\right)}} \u8fd9\u4e2a\u6570\u503c\u9700\u8981 polar centerness\u5206\u652f\u8fdb\u884c\u76d1\u7763\u5b66\u4e60\uff0c\u5728inference\u7684\u65f6\u5019\u4f1a\u4e0eclassification score\u76f8\u4e58\u4f5c\u4e3aNMS\u7684\u5224\u636e\u3002 Polar IoU Loss \u4f5c\u8005\u8ba4\u4e3a\u76f4\u63a5\u7528SmoothL1 Loss\u8bad\u7ec3\u662f\u5355\u72ec\u5730\u8bad\u7ec3\u65b9\u5f0f\uff0c\u4f5c\u8005\u8ba4\u4e3a\u5e94\u5f53n\u4e2a\u5c04\u7ebf\u8ddd\u79bb\u4e00\u8d77train\u3002\u5e76\u63d0\u51fa\u4e86Polar IoU Loss \u5047\u8bbe\u4e2d\u5fc3\u70b9\u6b63\u786e\uff0cIoU\u5373\u662f\u5982\u56fe(\u8fd9\u4e2a\u56fe\u7247\u53ef\u89c6\u5316\u77ac\u95f4\u5c06\u770b\u4f3c\u6bd4\u8f83\u590d\u6742\u7684\u95ee\u9898\u89e3\u91ca\u5f97\u5f88\u597d)\uff0c\u663e\u7136\u6211\u4eec\u4f1a\u7528\u79bb\u6563\u5316\u8868\u8fbe\u66ff\u4ee3\u79ef\u5206\uff0c\u516c\u5f0f\u5982\u4e0b\uff1a \\text{IoU} = \\lim_{N\\rightarrow\\infty}\\frac{\\sum^N_{i=1} \\frac{1}{2} d^2_{min} \\Delta \\theta_i}{\\sum^N_{i=1} \\frac{1}{2} d^2_{max} \\Delta \\theta_i} \u4f5c\u8005\u53d1\u73b0\u5e73\u65b9\u5bf9\u6027\u80fd\u63d0\u5347\u6709\u9650\uff0c\u9009\u62e9\u4e86\u76f4\u63a5\u4f7f\u7528\u4e00\u6b21\u65b9\u8fd1\u4f3c\u4ee3\u66ff\uff0c\u5e76\u53d6log\u5f97\u5230loss \\text { Polar IoU }=\\frac{\\sum_{i=1}^{n} d_{\\min }}{\\sum_{i=1}^{n} d_{\\max }} \\text { Polar IoU Loss}= -\\text{log} (\\text{Polar IoU}) distance labeling \u6700\u540e\u4e00\u4e2a\u95ee\u9898\u5c31\u662f\u5982\u4f55\u83b7\u5f97\u6bcf\u4e00\u4e2ainstance\u4e2d\u6bcf\u4e00\u4e2acenter point\u7684\u5c04\u7ebfground truth. \u7b2c\u4e00\u6b65\u662f\u9884\u5904\u7406\u7684\u65f6\u5019\u4f7f\u7528 cv2 . findCoutours \u5f97\u5230\u4e00\u7cfb\u5217\u8fb9\u7f18\u70b9\u3002\u7136\u540e\u5bf9\u6bcf\u4e00\u4e2a\u9700\u8981\u8ba1\u7b97distance groud truth\u7684center\u70b9\u8fd0\u884c\uff1a \u7ffb\u8bd1\u89e3\u91ca \u8ba1\u7b97\u6bcf\u4e00\u4e2a\u8fb9\u7f18\u70b9\u5230\"center\"\u70b9\u7684\u8ddd\u79bb\u4e0e\u76f8\u5bf9\u5939\u89d2\u3002 \u5bf9\u6bcf\u4e00\u4e2a\u9700\u8981ground truth\u7684\u5939\u89d2\uff1a \u5982\u679c\u57281\u4e2d\u6709\u8ba1\u7b97\u5230\uff0c\u5219\u5bf9\u5e94\u6700\u5927\u7684d(\u53ef\u80fd\u4e00\u4e2a\u89d2\u5ea6\u4e0d\u6b62\u4e00\u4e2a\u6700\u8fdc\u70b9\uff0c\u8981\u7a0d\u5fae\u8003\u8651\u51f9\u5f62\u72b6\uff0c\u8fd9\u79cd\u6570\u91cf\u4e0d\u591a)\u3002 \u5982\u679c\u6ca1\u6709\uff0c\u5219\u53d6\u6700\u90bb\u8fd1\u7684\u5df2\u6709\u7684theta\u5bf9\u5e94\u7684\u8ddd\u79bb\u6700\u4e3aground truth\uff0c\u5426\u5219\u53d6\u4e00\u4e2a\u6781\u5c0f\u503c\u3002","title":"PolarMask: Single Shot Instance Segmentation with Polar Representation"},{"location":"other_categories/Segmentation/PolorMask/#polarmask-single-shot-instance-segmentation-with-polar-representation","text":"\u8fd9\u7bc7paper\u53d7\u542f\u53d1\u4e8e FCOS \uff0c\u4f7f\u7528\u65b0\u7684\u6570\u636e\u8868\u8fbe\u65b9\u5f0f\uff0c\u5c06Instance Segmentation\u5728network inference\u4e0a\u5212\u5f52\u4e3a\u4e0e2D detection\u5b8c\u5168\u4e00\u81f4\u7684\u590d\u6742\u5ea6\u3002\u6709\u673a\u4f1a\u4e0e YOLOACT \u7ade\u4e89\u6210\u4e3aInstance Seg\u5de5\u4e1a\u4f7f\u7528\u7684\u6807\u51c6\u3002","title":"PolarMask: Single Shot Instance Segmentation with Polar Representation"},{"location":"other_categories/Segmentation/PolorMask/#_1","text":"\u5728\u7f51\u7edc\u7ed3\u6784\u4e0a\u9762\u8fd9\u7bc7paper\u9009\u62e9\u7684\u662f\u4e0e FCOS \u4e00\u81f4\u7684\u7ed3\u6784\uff0c\u4ec5\u4ec5\u5728 regression\u5206\u652f\u4e0a\u6539\u4e3a\u5bf9 n=36 \u4e2a\u5c04\u7ebf\u65b9\u5411\u7684\u8ddd\u79bb\u8fdb\u884c\u56de\u5f52\u3002 \u6bcf\u4e00\u4e2ainstance\u88ab\u5efa\u6a21\u4e3a\u4e2d\u5fc3\u70b9+\u5bc6\u96c6\u7684\u4ece\u4e2d\u5fc3\u70b9\u5f80\u5916\u7684\u5c04\u7ebf\u5f62\u6210\u7684contour.","title":"\u603b\u4f53\u7ed3\u6784"},{"location":"other_categories/Segmentation/PolorMask/#_2","text":"\u4e0e FCOS \u7c7b\u4f3c\uff0c\u8fd9\u91cc\u9700\u8981\u5b9a\u4e49\u4e00\u4e2a\u4e2d\u5fc3\u70b9\uff0c\u540c\u65f6\u9700\u8981\u5b9a\u4e49\u4e00\u4e2a\u4e2d\u5fc3\u5ea6\u3002\u4f5c\u8005\u6bd4\u8f83\u8fc7\u4f7f\u7528bounding box\u7684\u4e2d\u70b9\u4e0e\u8d28\u5fc3\uff0c\u53d1\u73b0\u4f7f\u7528\u8d28\u5fc3\u7406\u8bba\u6027\u80fd\u4e0a\u9650\u66f4\u597d\uff0c\u6240\u4ee5\u672c\u6587\u7684ground truth center\u7684\u4f4d\u7f6e\u4e2d\u5fc3\u5728\u8d28\u5fc3\u4e0a\uff0c\u4f5c\u8005\u5141\u8bb8\u51e0\u4e2apixel\u7ea7\u522b\u7684\u6270\u52a8\uff0c\u589e\u52a0\u6b63\u6837\u672c\u6570\u91cf\u3002 \u800c\u4e2d\u5fc3\u5ea6\u4e0e FCOS \u7684centerness\u6709\u4e00\u5b9a\u533a\u522b\uff0c\u4f46\u662f\u601d\u8def\u4e00\u81f4\uff0c\u516c\u5f0f\u5982\u4e0b\uff1a \\text { Polar Centerness }=\\sqrt{\\frac{\\min \\left(\\left\\{d_{1}, d_{2}, \\ldots, d_{n}\\right\\}\\right)}{\\max \\left(\\left\\{d_{1}, d_{2}, \\ldots, d_{n}\\right\\}\\right)}} \u8fd9\u4e2a\u6570\u503c\u9700\u8981 polar centerness\u5206\u652f\u8fdb\u884c\u76d1\u7763\u5b66\u4e60\uff0c\u5728inference\u7684\u65f6\u5019\u4f1a\u4e0eclassification score\u76f8\u4e58\u4f5c\u4e3aNMS\u7684\u5224\u636e\u3002","title":"\"\u4e2d\u5fc3\"\u5b9a\u4e49"},{"location":"other_categories/Segmentation/PolorMask/#polar-iou-loss","text":"\u4f5c\u8005\u8ba4\u4e3a\u76f4\u63a5\u7528SmoothL1 Loss\u8bad\u7ec3\u662f\u5355\u72ec\u5730\u8bad\u7ec3\u65b9\u5f0f\uff0c\u4f5c\u8005\u8ba4\u4e3a\u5e94\u5f53n\u4e2a\u5c04\u7ebf\u8ddd\u79bb\u4e00\u8d77train\u3002\u5e76\u63d0\u51fa\u4e86Polar IoU Loss \u5047\u8bbe\u4e2d\u5fc3\u70b9\u6b63\u786e\uff0cIoU\u5373\u662f\u5982\u56fe(\u8fd9\u4e2a\u56fe\u7247\u53ef\u89c6\u5316\u77ac\u95f4\u5c06\u770b\u4f3c\u6bd4\u8f83\u590d\u6742\u7684\u95ee\u9898\u89e3\u91ca\u5f97\u5f88\u597d)\uff0c\u663e\u7136\u6211\u4eec\u4f1a\u7528\u79bb\u6563\u5316\u8868\u8fbe\u66ff\u4ee3\u79ef\u5206\uff0c\u516c\u5f0f\u5982\u4e0b\uff1a \\text{IoU} = \\lim_{N\\rightarrow\\infty}\\frac{\\sum^N_{i=1} \\frac{1}{2} d^2_{min} \\Delta \\theta_i}{\\sum^N_{i=1} \\frac{1}{2} d^2_{max} \\Delta \\theta_i} \u4f5c\u8005\u53d1\u73b0\u5e73\u65b9\u5bf9\u6027\u80fd\u63d0\u5347\u6709\u9650\uff0c\u9009\u62e9\u4e86\u76f4\u63a5\u4f7f\u7528\u4e00\u6b21\u65b9\u8fd1\u4f3c\u4ee3\u66ff\uff0c\u5e76\u53d6log\u5f97\u5230loss \\text { Polar IoU }=\\frac{\\sum_{i=1}^{n} d_{\\min }}{\\sum_{i=1}^{n} d_{\\max }} \\text { Polar IoU Loss}= -\\text{log} (\\text{Polar IoU})","title":"Polar IoU Loss"},{"location":"other_categories/Segmentation/PolorMask/#distance-labeling","text":"\u6700\u540e\u4e00\u4e2a\u95ee\u9898\u5c31\u662f\u5982\u4f55\u83b7\u5f97\u6bcf\u4e00\u4e2ainstance\u4e2d\u6bcf\u4e00\u4e2acenter point\u7684\u5c04\u7ebfground truth. \u7b2c\u4e00\u6b65\u662f\u9884\u5904\u7406\u7684\u65f6\u5019\u4f7f\u7528 cv2 . findCoutours \u5f97\u5230\u4e00\u7cfb\u5217\u8fb9\u7f18\u70b9\u3002\u7136\u540e\u5bf9\u6bcf\u4e00\u4e2a\u9700\u8981\u8ba1\u7b97distance groud truth\u7684center\u70b9\u8fd0\u884c\uff1a \u7ffb\u8bd1\u89e3\u91ca \u8ba1\u7b97\u6bcf\u4e00\u4e2a\u8fb9\u7f18\u70b9\u5230\"center\"\u70b9\u7684\u8ddd\u79bb\u4e0e\u76f8\u5bf9\u5939\u89d2\u3002 \u5bf9\u6bcf\u4e00\u4e2a\u9700\u8981ground truth\u7684\u5939\u89d2\uff1a \u5982\u679c\u57281\u4e2d\u6709\u8ba1\u7b97\u5230\uff0c\u5219\u5bf9\u5e94\u6700\u5927\u7684d(\u53ef\u80fd\u4e00\u4e2a\u89d2\u5ea6\u4e0d\u6b62\u4e00\u4e2a\u6700\u8fdc\u70b9\uff0c\u8981\u7a0d\u5fae\u8003\u8651\u51f9\u5f62\u72b6\uff0c\u8fd9\u79cd\u6570\u91cf\u4e0d\u591a)\u3002 \u5982\u679c\u6ca1\u6709\uff0c\u5219\u53d6\u6700\u90bb\u8fd1\u7684\u5df2\u6709\u7684theta\u5bf9\u5e94\u7684\u8ddd\u79bb\u6700\u4e3aground truth\uff0c\u5426\u5219\u53d6\u4e00\u4e2a\u6781\u5c0f\u503c\u3002","title":"distance labeling"},{"location":"other_categories/Segmentation/RDSNet/","text":"RDSNet: A New Deep Architecture for Reciprocal Object Detection and Instance Segmentation \u8fd9\u7bc7paper\u63d0\u51fa\u7684RDSNet,\u6838\u5fc3\u7684\u601d\u60f3\u5728\u4e8e\u8ba92D object detection\u4e0einstance segmentation\u76f8\u4e92\u5e2e\u52a9,\u5f00\u6e90\u7684\u4ee3\u7801\u57fa\u4e8emmdetection. \u7ed3\u6784\u4e0e\u65b9\u6cd5 object stream\u4e0epixel stream\u5206\u522b\u4e0e YOLOACT \u76f8\u4f3c\uff0c\u4e0d\u540c\u7684\u5730\u65b9\u5728\u4e8eRDSNet\u4f1a\u989d\u5916\u5bf9\u6bcf\u4e00\u4e2aanchor\u9884\u6d4b\u4e00\u4e2a 2\\times d \u7ef4\u7684representation. Instance Aware Pixel Stream \u8fd9\u4e00\u6b65\u7684\u8003\u8651\u662f\u8ba9pixel stream\u5f97\u5230object \u7279\u5f81\u4fe1\u606f\u3002 \u5bf9\u4e8e\u6bcf\u4e00\u4e2aobject o , \u6709\u5b83\u7684 2\\times d\\times 1\\times 1 \u7684representation \\phi(v_o) \u3002\u6574\u5f20\u56fe\u5728pixel stream\u4f1a\u5f62\u6210\u4e00\u4e2a 1\\times d\\times h_f\\times w_f \u7684\u7279\u5f81\uff0c\u62bd\u51fa\u4e0e\u76ee\u6807object\u76f8\u4f3c\u7684features M_{o}=\\operatorname{softmax}\\left(\\Psi(U) \\star \\phi\\left(v_{o}\\right)\\right) \u5176\u4e2d M_o \u7684\u7ef4\u5ea6\u662f 2\\times 1\\times h_f\\times w_f ,\u4f7f\u7528cross-entropy\u6765\u8bad\u7ec3\u3002\u6709\u70b9\u50cf\u662fmetric learning Cropping to Translation-variant \u524d\u4e00\u6b65\u7684\u4e00\u4e2a\u5173\u952e\u95ee\u9898\u5728\u4e8e\u540c\u7c7bobject \u4e0d\u540cinstance\u5728\u4e0a\u4e00\u6b65\u8fd8\u662f\u4f1a\u5f97\u5230\u9ad8\u7684\u76f8\u5173\u6027\uff0c\u5728cropping\u8fd9\u4e00\u6b65\u9700\u8981\u6253\u7834\u8fd9\u4e2a\u76f8\u5173\u6027\u3002\u4f5c\u8005\u7684\u505a\u6cd5\u6bd4\u8f83\u76f4\u767d\uff0c\u5c06\u73b0\u6709\u7684object \u8fb9\u7f18expand\u4e00\u4e2a\u9884\u8bbe\u7684\u6bd4\u4f8b\u4e4b\u540e(expand\u7684\u539f\u56e0\u662f\u907f\u514d\u56e0\u4e3a\u4f30\u8ba1\u7684\u4e0d\u51c6\u786e\u5ea6)\uff0c\u5c06\u5bf9\u5e94pixel stream\u4e2d\u5728\u8fb9\u7f18\u5916\u7684\u70b9\u8bbe\u4e3a\u80cc\u666f\u3002 MBRM mask assisted detection \u8fd9\u4e00\u6b65\u7684\u8003\u8651\u662f\u8ba9instance segmentation\u53bb\u63d0\u5347object detection\u7684\u51c6\u786e\u5ea6,\u4e2a\u4eba\u7684\u611f\u89c9\u4e0e\u76f4\u89c9\u5e76\u4e0d\u592a\u76f8\u7b26\u5408, \u4ee3\u7801","title":"RDSNet: A New Deep Architecture for Reciprocal Object Detection and Instance Segmentation"},{"location":"other_categories/Segmentation/RDSNet/#rdsnet-a-new-deep-architecture-for-reciprocal-object-detection-and-instance-segmentation","text":"\u8fd9\u7bc7paper\u63d0\u51fa\u7684RDSNet,\u6838\u5fc3\u7684\u601d\u60f3\u5728\u4e8e\u8ba92D object detection\u4e0einstance segmentation\u76f8\u4e92\u5e2e\u52a9,\u5f00\u6e90\u7684\u4ee3\u7801\u57fa\u4e8emmdetection.","title":"RDSNet: A New Deep Architecture for Reciprocal Object Detection and Instance Segmentation"},{"location":"other_categories/Segmentation/RDSNet/#_1","text":"object stream\u4e0epixel stream\u5206\u522b\u4e0e YOLOACT \u76f8\u4f3c\uff0c\u4e0d\u540c\u7684\u5730\u65b9\u5728\u4e8eRDSNet\u4f1a\u989d\u5916\u5bf9\u6bcf\u4e00\u4e2aanchor\u9884\u6d4b\u4e00\u4e2a 2\\times d \u7ef4\u7684representation.","title":"\u7ed3\u6784\u4e0e\u65b9\u6cd5"},{"location":"other_categories/Segmentation/RDSNet/#instance-aware-pixel-stream","text":"\u8fd9\u4e00\u6b65\u7684\u8003\u8651\u662f\u8ba9pixel stream\u5f97\u5230object \u7279\u5f81\u4fe1\u606f\u3002 \u5bf9\u4e8e\u6bcf\u4e00\u4e2aobject o , \u6709\u5b83\u7684 2\\times d\\times 1\\times 1 \u7684representation \\phi(v_o) \u3002\u6574\u5f20\u56fe\u5728pixel stream\u4f1a\u5f62\u6210\u4e00\u4e2a 1\\times d\\times h_f\\times w_f \u7684\u7279\u5f81\uff0c\u62bd\u51fa\u4e0e\u76ee\u6807object\u76f8\u4f3c\u7684features M_{o}=\\operatorname{softmax}\\left(\\Psi(U) \\star \\phi\\left(v_{o}\\right)\\right) \u5176\u4e2d M_o \u7684\u7ef4\u5ea6\u662f 2\\times 1\\times h_f\\times w_f ,\u4f7f\u7528cross-entropy\u6765\u8bad\u7ec3\u3002\u6709\u70b9\u50cf\u662fmetric learning","title":"Instance Aware Pixel Stream"},{"location":"other_categories/Segmentation/RDSNet/#cropping-to-translation-variant","text":"\u524d\u4e00\u6b65\u7684\u4e00\u4e2a\u5173\u952e\u95ee\u9898\u5728\u4e8e\u540c\u7c7bobject \u4e0d\u540cinstance\u5728\u4e0a\u4e00\u6b65\u8fd8\u662f\u4f1a\u5f97\u5230\u9ad8\u7684\u76f8\u5173\u6027\uff0c\u5728cropping\u8fd9\u4e00\u6b65\u9700\u8981\u6253\u7834\u8fd9\u4e2a\u76f8\u5173\u6027\u3002\u4f5c\u8005\u7684\u505a\u6cd5\u6bd4\u8f83\u76f4\u767d\uff0c\u5c06\u73b0\u6709\u7684object \u8fb9\u7f18expand\u4e00\u4e2a\u9884\u8bbe\u7684\u6bd4\u4f8b\u4e4b\u540e(expand\u7684\u539f\u56e0\u662f\u907f\u514d\u56e0\u4e3a\u4f30\u8ba1\u7684\u4e0d\u51c6\u786e\u5ea6)\uff0c\u5c06\u5bf9\u5e94pixel stream\u4e2d\u5728\u8fb9\u7f18\u5916\u7684\u70b9\u8bbe\u4e3a\u80cc\u666f\u3002","title":"Cropping to Translation-variant"},{"location":"other_categories/Segmentation/RDSNet/#mbrm-mask-assisted-detection","text":"\u8fd9\u4e00\u6b65\u7684\u8003\u8651\u662f\u8ba9instance segmentation\u53bb\u63d0\u5347object detection\u7684\u51c6\u786e\u5ea6,\u4e2a\u4eba\u7684\u611f\u89c9\u4e0e\u76f4\u89c9\u5e76\u4e0d\u592a\u76f8\u7b26\u5408, \u4ee3\u7801","title":"MBRM mask assisted detection"},{"location":"other_categories/Segmentation/SAUNet/","text":"SAUNet: Shape Attentive U-Net for Interpretable Medical Image Segmentation Structure \u672c\u6587\u5c06\u7f51\u7edc\u5206\u4e3atexture branch\u4e0eshape branch\u3002\u6ce8\u91cd\u4f7f\u7528Attention\u5f62\u6210\u53ef\u89e3\u91ca\u6027\u3002Loss\u4f7f\u7528\u57fa\u672c\u7684CE loss\u4ee5\u53ca Dice Loss","title":"SAUNet: Shape Attentive U-Net for Interpretable Medical Image Segmentation"},{"location":"other_categories/Segmentation/SAUNet/#saunet-shape-attentive-u-net-for-interpretable-medical-image-segmentation","text":"","title":"SAUNet: Shape Attentive U-Net for Interpretable Medical Image Segmentation"},{"location":"other_categories/Segmentation/SAUNet/#structure","text":"\u672c\u6587\u5c06\u7f51\u7edc\u5206\u4e3atexture branch\u4e0eshape branch\u3002\u6ce8\u91cd\u4f7f\u7528Attention\u5f62\u6210\u53ef\u89e3\u91ca\u6027\u3002Loss\u4f7f\u7528\u57fa\u672c\u7684CE loss\u4ee5\u53ca Dice Loss","title":"Structure"},{"location":"other_categories/Segmentation/SOLO/","text":"SOLO: Segmenting Objects by Locations \u8fd9\u7bc7\u6587\u7ae0\u7528\u4e00\u4e2a\u6bd4\u8f83\u7b80\u5355\u7684\u65b9\u6cd5\u5b9e\u73b0instance segmentation\uff0c\u601d\u8def\u5728\u4e8e\u5c06\u56fe\u7247\u5206\u4e3a S\\times S \u4e2a\u5c0fgrid\uff0c\u7136\u540e\u5047\u8bbe\u6bcf\u4e00\u4e2agrid\u91cc\u9762\u540c\u7c7b\u7269\u4f53\u53ea\u6709\u4e00\u4e2ainstance\uff0c\u7136\u540e\u8981\u6c42\u5206\u7c7b\u4efb\u52a1\u8f93\u51fa\u7684\u7ed3\u679c\u91cc\u9762\u5e26\u6709\"\u4f4d\u7f6e\u7c7b\".\u4ece\u800c\u5c06\u4e0d\u540c\u4f4d\u7f6e\u7684\u7ed3\u679c\u5206\u79bb\u51fa\u6765 Update: 2020/03/26: \u4f5c\u8005\u7ec4\u63a8\u51fa SOLOv2 : pdf Framework \u672c\u6587\u4f7f\u7528retinanet\u7684\u601d\u8def\uff0c\u4f7f\u7528multi-scale\u8f93\u51fa\uff0c\u4e0d\u540c\u7684scale\u5206\u89e3\u7684\u56fe\u50cf\u533a\u5757 S \u6570\u76ee\u662f\u4e0d\u540c\u7684 Breaking Translational Invariance \u4f46\u662f\u7f51\u7edc\u4e2d\u9700\u8981\u6ce8\u610f\u7684\u5730\u65b9\u5728\u4e8e\u4e00\u822c\u7684\u5b8c\u5168\u5377\u79ef\u7f51\u7edc\u662f\u5e73\u79fb\u4e0d\u53d8\u7684\uff0c\u4e5f\u5c31\u662f\u5728\u4e0d\u540c\u4f4d\u7f6e\u7684\u76f8\u4f3c\u7684\u7269\u4f53\uff0c\u5728\u7f51\u7edc\u4e2d\u5f62\u6210\u7684feature\u5e94\u8be5\u662f\u76f8\u4f3c\u7684\uff0c\u4f46\u662f\u5728\u672c\u6587\u4e2d\u8fd9\u662f\u4e0d\u88ab\u5141\u8bb8\u7684\uff0c\u56e0\u4e3a\u8f93\u51fa\u7684mask branch\u4e2d,\u6211\u4eec\u5e0c\u671b\u540c\u6837\u7684\u753b\u9762\u5185\u5bb9\uff0c\u5728\u4e0d\u540c\u4f4d\u7f6e\u8f93\u51fa\u7684feature\u5b8c\u5168\u4e0d\u540c\uff0c\u56e0\u800c\u5728mask branch\u4e2d\u4f7f\u7528 Coord Conv \u800c\u4e0d\u662f\u4e0d\u540c\u666e\u901a\u7684\u5377\u79ef\u6838\uff0c\u4f5c\u8005\u4e2d\u95f4\u63d0\u5230\u4e86 Semi Conv \u8fd9\u4e5f\u662f\u4e00\u79cd\u9009\u62e9\uff0c\u4e0d\u8fc7\u6700\u7ec8\u9009\u62e9\u7684\u662f Coord Conv Loss Function \u4f5c\u8005\u9762\u5bf9class imbalance problem,\u9009\u62e9\u4e86 Dice Loss \u800c\u4e0d\u662ffocal loss. \u5176\u516c\u5f0f\u4e3a: \\begin{aligned} L_{\\text {Dice}}&=1-D(\\mathbf{p}, \\mathbf{q})\\\\ D(\\mathbf{p}, \\mathbf{q})&=\\frac{2 \\sum_{x, y}\\left(\\mathbf{p}_{x, y} \\cdot \\mathbf{q}_{x, y}\\right)}{\\sum_{x, y} \\mathbf{p}_{x, y}^{2}+\\sum_{x, y} \\mathbf{q}_{x, y}^{2}} \\end{aligned} \u4ed4\u7ec6\u89c2\u5bdf D(p, q) \u7684\u516c\u5f0f\uff0c\u53ef\u4ee5\u4e86\u89e3\u5230\u8fd9\u662f\u4e00\u4e2a\u7c7b\u4f3c\u4e8eIoU\u7684metric, Decoupled SOLO \u7531\u4e8e\u8981\u5206\u7c7b S^2 \uff0c\u8fd9\u4e2achannel\u6570\u592a\u5927\u4e86\uff0c\u540c\u65f6\u6709\u5f88\u5927\u5197\u4f59\uff0c\u56e0\u800c\u8f6c\u800c\u8ba9\u7f51\u7edc\u5c06 X, Y \u4e0a\u7684bin\u5206\u522b\u5206\u7c7b\uff0cinference\u7684\u65f6\u5019\u8ba9\u5bf9\u5e94\u884c\u5217\u7684sigmoid\u76f8\u4e58 SOLOv2 performance: \u63d0\u5347\u5728\u4e8e\u4e09\u4e2a\u95ee\u9898 \u5bf9\u7a00\u758f\u7684Mask prediction \u4f7f\u7528dynamic head\u8fdb\u884c\u4f18\u5316 \u5145\u5206\u5229\u7528FPN\u878d\u5408\u591a\u5c3a\u5ea6 Matrix NMS Dynamic head Dynamic head\u7684\u7b97\u6cd5\u6765\u8bf4\uff0c\u5c31\u662f\u8ba9\u7f51\u7edc\u5355\u72ec\u8bad\u7ec3\u4e00\u4e2a\u5377\u79ef\u6838\u7528\u4e8e\u6700\u540e\u4e00\u6b65\u7684 1\\times 1 \u5377\u79ef\u3002 \u76f4\u89c9\u5982\u6b64\uff1a\u89c2\u5bdf\u539f\u6765\u7684SOLO\uff0c S\\times S \u4e2aMask\u8fd9\u6837\u7684\u9884\u6d4b\u662f\u5f88\u7a00\u758f\u7684\uff0c\u53ea\u6709\u90e8\u5206\u6709\u7528\uff0c\u4e0d\u5982train\u4e00\u4e2a\u52a8\u6001\u7684 1\\times 1 or 3\\times 3 \u5377\u79ef\u6838\u5b66\u4f1a\u4ece\u91cc\u9762\u7f51\u7edc\u4e2d\u5206\u5f00\u4e0d\u540c\u4f4d\u7f6e\u7684\u7ed3\u679c(\u6ce8\u610f\u8fd9\u4e2a\u5377\u79ef\u6838\u7684\u751f\u6210\u8fc7\u7a0b\u7684\u611f\u53d7\u91ce\u662f\u5168\u56fe)\u3002(\u7a0d\u7a0d\u6709\u4e00\u70b9\u8be1\u5f02\u4e0d\u8fc7\u53ef\u4ee5\u63a5\u53d7)\u3002 Mask Feature prediction \u7b80\u5355\u6765\u8bf4\u5c31\u662f\u7528 Coord Conv \u8ba1\u7b97\u540e\u4e0a\u91c7\u6837\u6240\u6709scale\u7684\u7279\u5f81\uff0c\u6c42\u548c\uff0c\u7136\u540e 1\\times 1 \u5377\u79ef\u5f97\u5230\u6700\u7ec8\u8f93\u51fa Matrix NMS \u91c7\u7528\u7684\u6982\u5ff5\u662f SoftNMS\u7684\u6982\u5ff5\uff0c\u4e5f\u5c31\u662f\u6839\u636e\u91cd\u5408\u7684\u6846\u7684IOU\u4e0e\u6982\u7387 \u8fdb\u4e00\u6b65\u964d\u4f4e \u4f4escore box\u7684score\u7684\u505a\u6cd5\u3002\u8fd9\u91cc\u5728\u540e\u9762NMS\u65f6\uff0c\u7528IoU\u7684\u51fd\u6570\u66ff\u4ee3\u6982\u7387\u503c\uff0c\u56e0\u800cdecay scale\u53ea\u4e0eIoU\u6709\u5173","title":"SOLO: Segmenting Objects by Locations"},{"location":"other_categories/Segmentation/SOLO/#solo-segmenting-objects-by-locations","text":"\u8fd9\u7bc7\u6587\u7ae0\u7528\u4e00\u4e2a\u6bd4\u8f83\u7b80\u5355\u7684\u65b9\u6cd5\u5b9e\u73b0instance segmentation\uff0c\u601d\u8def\u5728\u4e8e\u5c06\u56fe\u7247\u5206\u4e3a S\\times S \u4e2a\u5c0fgrid\uff0c\u7136\u540e\u5047\u8bbe\u6bcf\u4e00\u4e2agrid\u91cc\u9762\u540c\u7c7b\u7269\u4f53\u53ea\u6709\u4e00\u4e2ainstance\uff0c\u7136\u540e\u8981\u6c42\u5206\u7c7b\u4efb\u52a1\u8f93\u51fa\u7684\u7ed3\u679c\u91cc\u9762\u5e26\u6709\"\u4f4d\u7f6e\u7c7b\".\u4ece\u800c\u5c06\u4e0d\u540c\u4f4d\u7f6e\u7684\u7ed3\u679c\u5206\u79bb\u51fa\u6765 Update: 2020/03/26: \u4f5c\u8005\u7ec4\u63a8\u51fa SOLOv2 : pdf","title":"SOLO: Segmenting Objects by Locations"},{"location":"other_categories/Segmentation/SOLO/#framework","text":"\u672c\u6587\u4f7f\u7528retinanet\u7684\u601d\u8def\uff0c\u4f7f\u7528multi-scale\u8f93\u51fa\uff0c\u4e0d\u540c\u7684scale\u5206\u89e3\u7684\u56fe\u50cf\u533a\u5757 S \u6570\u76ee\u662f\u4e0d\u540c\u7684","title":"Framework"},{"location":"other_categories/Segmentation/SOLO/#breaking-translational-invariance","text":"\u4f46\u662f\u7f51\u7edc\u4e2d\u9700\u8981\u6ce8\u610f\u7684\u5730\u65b9\u5728\u4e8e\u4e00\u822c\u7684\u5b8c\u5168\u5377\u79ef\u7f51\u7edc\u662f\u5e73\u79fb\u4e0d\u53d8\u7684\uff0c\u4e5f\u5c31\u662f\u5728\u4e0d\u540c\u4f4d\u7f6e\u7684\u76f8\u4f3c\u7684\u7269\u4f53\uff0c\u5728\u7f51\u7edc\u4e2d\u5f62\u6210\u7684feature\u5e94\u8be5\u662f\u76f8\u4f3c\u7684\uff0c\u4f46\u662f\u5728\u672c\u6587\u4e2d\u8fd9\u662f\u4e0d\u88ab\u5141\u8bb8\u7684\uff0c\u56e0\u4e3a\u8f93\u51fa\u7684mask branch\u4e2d,\u6211\u4eec\u5e0c\u671b\u540c\u6837\u7684\u753b\u9762\u5185\u5bb9\uff0c\u5728\u4e0d\u540c\u4f4d\u7f6e\u8f93\u51fa\u7684feature\u5b8c\u5168\u4e0d\u540c\uff0c\u56e0\u800c\u5728mask branch\u4e2d\u4f7f\u7528 Coord Conv \u800c\u4e0d\u662f\u4e0d\u540c\u666e\u901a\u7684\u5377\u79ef\u6838\uff0c\u4f5c\u8005\u4e2d\u95f4\u63d0\u5230\u4e86 Semi Conv \u8fd9\u4e5f\u662f\u4e00\u79cd\u9009\u62e9\uff0c\u4e0d\u8fc7\u6700\u7ec8\u9009\u62e9\u7684\u662f Coord Conv","title":"Breaking Translational Invariance"},{"location":"other_categories/Segmentation/SOLO/#loss-function","text":"\u4f5c\u8005\u9762\u5bf9class imbalance problem,\u9009\u62e9\u4e86 Dice Loss \u800c\u4e0d\u662ffocal loss. \u5176\u516c\u5f0f\u4e3a: \\begin{aligned} L_{\\text {Dice}}&=1-D(\\mathbf{p}, \\mathbf{q})\\\\ D(\\mathbf{p}, \\mathbf{q})&=\\frac{2 \\sum_{x, y}\\left(\\mathbf{p}_{x, y} \\cdot \\mathbf{q}_{x, y}\\right)}{\\sum_{x, y} \\mathbf{p}_{x, y}^{2}+\\sum_{x, y} \\mathbf{q}_{x, y}^{2}} \\end{aligned} \u4ed4\u7ec6\u89c2\u5bdf D(p, q) \u7684\u516c\u5f0f\uff0c\u53ef\u4ee5\u4e86\u89e3\u5230\u8fd9\u662f\u4e00\u4e2a\u7c7b\u4f3c\u4e8eIoU\u7684metric,","title":"Loss Function"},{"location":"other_categories/Segmentation/SOLO/#decoupled-solo","text":"\u7531\u4e8e\u8981\u5206\u7c7b S^2 \uff0c\u8fd9\u4e2achannel\u6570\u592a\u5927\u4e86\uff0c\u540c\u65f6\u6709\u5f88\u5927\u5197\u4f59\uff0c\u56e0\u800c\u8f6c\u800c\u8ba9\u7f51\u7edc\u5c06 X, Y \u4e0a\u7684bin\u5206\u522b\u5206\u7c7b\uff0cinference\u7684\u65f6\u5019\u8ba9\u5bf9\u5e94\u884c\u5217\u7684sigmoid\u76f8\u4e58","title":"Decoupled SOLO"},{"location":"other_categories/Segmentation/SOLO/#solov2","text":"performance: \u63d0\u5347\u5728\u4e8e\u4e09\u4e2a\u95ee\u9898 \u5bf9\u7a00\u758f\u7684Mask prediction \u4f7f\u7528dynamic head\u8fdb\u884c\u4f18\u5316 \u5145\u5206\u5229\u7528FPN\u878d\u5408\u591a\u5c3a\u5ea6 Matrix NMS","title":"SOLOv2"},{"location":"other_categories/Segmentation/SOLO/#dynamic-head","text":"Dynamic head\u7684\u7b97\u6cd5\u6765\u8bf4\uff0c\u5c31\u662f\u8ba9\u7f51\u7edc\u5355\u72ec\u8bad\u7ec3\u4e00\u4e2a\u5377\u79ef\u6838\u7528\u4e8e\u6700\u540e\u4e00\u6b65\u7684 1\\times 1 \u5377\u79ef\u3002 \u76f4\u89c9\u5982\u6b64\uff1a\u89c2\u5bdf\u539f\u6765\u7684SOLO\uff0c S\\times S \u4e2aMask\u8fd9\u6837\u7684\u9884\u6d4b\u662f\u5f88\u7a00\u758f\u7684\uff0c\u53ea\u6709\u90e8\u5206\u6709\u7528\uff0c\u4e0d\u5982train\u4e00\u4e2a\u52a8\u6001\u7684 1\\times 1 or 3\\times 3 \u5377\u79ef\u6838\u5b66\u4f1a\u4ece\u91cc\u9762\u7f51\u7edc\u4e2d\u5206\u5f00\u4e0d\u540c\u4f4d\u7f6e\u7684\u7ed3\u679c(\u6ce8\u610f\u8fd9\u4e2a\u5377\u79ef\u6838\u7684\u751f\u6210\u8fc7\u7a0b\u7684\u611f\u53d7\u91ce\u662f\u5168\u56fe)\u3002(\u7a0d\u7a0d\u6709\u4e00\u70b9\u8be1\u5f02\u4e0d\u8fc7\u53ef\u4ee5\u63a5\u53d7)\u3002","title":"Dynamic head"},{"location":"other_categories/Segmentation/SOLO/#mask-feature-prediction","text":"\u7b80\u5355\u6765\u8bf4\u5c31\u662f\u7528 Coord Conv \u8ba1\u7b97\u540e\u4e0a\u91c7\u6837\u6240\u6709scale\u7684\u7279\u5f81\uff0c\u6c42\u548c\uff0c\u7136\u540e 1\\times 1 \u5377\u79ef\u5f97\u5230\u6700\u7ec8\u8f93\u51fa","title":"Mask Feature prediction"},{"location":"other_categories/Segmentation/SOLO/#matrix-nms","text":"\u91c7\u7528\u7684\u6982\u5ff5\u662f SoftNMS\u7684\u6982\u5ff5\uff0c\u4e5f\u5c31\u662f\u6839\u636e\u91cd\u5408\u7684\u6846\u7684IOU\u4e0e\u6982\u7387 \u8fdb\u4e00\u6b65\u964d\u4f4e \u4f4escore box\u7684score\u7684\u505a\u6cd5\u3002\u8fd9\u91cc\u5728\u540e\u9762NMS\u65f6\uff0c\u7528IoU\u7684\u51fd\u6570\u66ff\u4ee3\u6982\u7387\u503c\uff0c\u56e0\u800cdecay scale\u53ea\u4e0eIoU\u6709\u5173","title":"Matrix NMS"},{"location":"other_categories/Segmentation/TensorMask:_A_Foundation_for_Dense_Object_Segmentation/","text":"TensorMask: A Foundation for Dense Object Segmentation \u8fd9\u7bc7\u6587\u7ae0\u63d0\u51fa\u4e86one-stage instance segmentation\u7684\u7b97\u6cd5\u3002\u4f20\u7edf\u6765\u8bf4\uff0cstate of the art \u7684instance segmentation\u7684\u505a\u6cd5\u57fa\u672c\u4e0a\u662f\u5148\u8fdb\u884cobject detection\u5f97\u52302D\u6846\uff0c\u7136\u540e\u5728\u6846\u5185\u8fdb\u884cSemantic Segmentation\u3002\u8fd9\u6837\u7684two-stage\u751a\u81f3\u662fMulti-stage\u7684\u505a\u6cd5(object detection\u53ef\u80fd\u5c31two-stage).\u8fd8\u6709\u4e00\u79cd\u505a\u6cd5\u662f\u5148\u751f\u6210label pixel\u7136\u540e\u8fdb\u884c\u805a\u7c7b\u3002 \u672c\u6587\u6838\u5fc3\u601d\u8def\u5c31\u662f\u5c06\u6574\u4e2a\u95ee\u9898\u8f6c\u6362\u4e3a\u4e00\u4e2a\u56db\u7ef4\u5f20\u91cf (V, U, H, W) \u7684\u56de\u5f52or\u5206\u7c7b\u95ee\u9898\u3002\u5bf9\u6bcf\u4e00\u4e2a\u5750\u6807\u70b9 (h, w) \u5bf9\u5e94\u4e00\u4e2a\u77e9\u9635 (V, U) \uff0c\u8bbe \\alpha \u4e3a\u5355\u4f4d\u8f6c\u6362\u6bd4\u4f8b\uff0c\u5219\u77e9\u9635\u4e2d\u7684\u5143\u7d20 (v, u) \u6307\u4ee3\u539f\u56fe (h + \\alpha v, w + \\alpha u) \u662fmask\u7684\u6982\u7387\uff0c\u6216\u5176\u4ed6\u53c2\u6570\u3002\u8fd9\u6837\u6574\u4e2a\u7f51\u7edc\u7684\u8bad\u7ec3\u76ee\u6807\u5c31\u548c\u4e00\u4e2a SSD \u6216\u8005\u8bf4Yolo\u5dee\u4e0d\u591a\u4e86,\u8fd9\u540c\u65f6\u53c8\u548cDeepMask\u4e0d\u540c\uff0c\u663e\u5f0f\u5730\u8868\u8fbe U, V \u5750\u6807\uff0c\u5e76\u4e3a\u6b64\u9002\u914d\u66f4\u591a\u7684\u8fd0\u7b97\u65b9\u5f0f. \u4e3b\u8981\u8868\u8fbe\u65b9\u5f0f\u7684\u5b9a\u4e49 Natural Representation \u8868\u8fbe\u4e3a (V, U, H, W) ,\u5bf9\u4e8e\u4e00\u4e2a4D (V,U,H,W) \u7684\u5f20\u91cf\uff0c\u5b83\u5728 (v, u, y, x) \u7684\u503c\u4ee3\u8868\u5728\u4e00\u4e2a\u4e2d\u5fc3\u5728 (y,x) \u7684\u5927\u5c0f\u4e3a \\alpha V \\times \\alpha U \u7a97\u53e3\u7684\u70b9 (y + \\alpha v, x + \\alpha u) \u7684mask\u503c\u3002 Aligned Representation \u5bf9\u4e00\u4e2a4D (\\hat V, \\hat U, \\hat H, \\hat W) \u7684\u5f20\u91cf\uff0c\u5b83\u5728 (\\hat v, \\hat u, \\hat y, \\hat x) \u7684\u503c\u4ee3\u8868\u5728\u4e00\u4e2a\u4e2d\u5fc3\u5728 (\\hat y, \\hat x) \u7684\u5927\u5c0f\u4e3a \\hat\\alpha \\hat V \\times \\hat\\alpha \\hat U \u7a97\u53e3\u7684\u70b9 (\\hat y - \\hat\\alpha \\hat v, \\hat x - \\hat\\alpha \\hat u) \u7684mask\u503c\u3002 \u5173\u952e\u7684\u7406\u89e3\u662f\u5728\u5750\u6807 (\\hat y, \\hat x) \u4e0a\u7684\u5b50\u77e9\u9635 (\\hat V, \\hat U) \uff0c\u4e0a\u7684\u6240\u6709\u503c\u90fd\u662f\u5728\u63cf\u8ff0\u8fd9\u4e2a\u5750\u6807 (\\hat y, \\hat x) \u7684\uff0c\u6240\u4ee5\u79f0\u4e3a\u4e3a aligned \u4e24\u8005\u7684\u5b9a\u4e49\u53ef\u4ee5\u7531\u8fd9\u5f20\u56fe\u663e\u793a \u4e24\u8005\u7684\u8f6c\u6362\uff1a \\begin{aligned} \\mathcal{F}(v, u, y, x) &= \\hat\\mathcal{F}(v, u, y+\\alpha v, x + \\alpha u) \\\\ \\hat\\mathcal{F}(\\hat v, \\hat u, \\hat y, \\hat x) &= \\mathcal{F}(\\hat v, \\hat u, \\hat y - \\alpha\\hat v, \\hat x- \\alpha\\hat u) \\end{aligned} \u7f51\u7edc\u7ed3\u6784, \u8f93\u51faHead, \u7ec6\u8282\u7ed3\u6784, \u8bad\u7ec3\u7ec6\u8282 \u7f51\u7edc\u91c7\u7528FPN\u8f93\u51fa\u591a\u4e2a\u4e0d\u540c\u5c3a\u5ea6\u7684feature maps,\u5f62\u72b6 (C, \\frac{1}{2^k} H, \\frac{1}{2^k}W \u8f93\u51faHead \u672c\u6587\u6bd4\u8f83\u4e865\u79cd\u8f93\u51faHead. 4\u79cd\u662fbaseline, \u533a\u522b\u5728\u4e8e\u4e0d\u540cScale\u4e0a\u7684\u56fe\uff0c\u7b2c\u4e94\u4e2ahead\u4f1a\u8f93\u51fa\u76f8\u540c\u7cbe\u786e\u5ea6\u7684\u7f51\u683c \u5176\u4e2d\u7684\u7ec6\u8282\u8fd0\u7b97\u5982\u56fe \u8fd9\u4e9b\u7ec6\u8282\u8fd0\u7b97\u672c\u8d28\u4e0a\u90fd\u662f\u5750\u6807\u53d8\u6362\u4ee5\u53ca\u91c7\u6837 \u8bad\u7ec3\u7ec6\u8282 \u5bf9FPN\u7684\u5fae\u8c03 Label\u5206\u914d Fully Contain center of m is close to center of windows unique","title":"TensorMask: A Foundation for Dense Object Segmentation"},{"location":"other_categories/Segmentation/TensorMask:_A_Foundation_for_Dense_Object_Segmentation/#tensormask-a-foundation-for-dense-object-segmentation","text":"\u8fd9\u7bc7\u6587\u7ae0\u63d0\u51fa\u4e86one-stage instance segmentation\u7684\u7b97\u6cd5\u3002\u4f20\u7edf\u6765\u8bf4\uff0cstate of the art \u7684instance segmentation\u7684\u505a\u6cd5\u57fa\u672c\u4e0a\u662f\u5148\u8fdb\u884cobject detection\u5f97\u52302D\u6846\uff0c\u7136\u540e\u5728\u6846\u5185\u8fdb\u884cSemantic Segmentation\u3002\u8fd9\u6837\u7684two-stage\u751a\u81f3\u662fMulti-stage\u7684\u505a\u6cd5(object detection\u53ef\u80fd\u5c31two-stage).\u8fd8\u6709\u4e00\u79cd\u505a\u6cd5\u662f\u5148\u751f\u6210label pixel\u7136\u540e\u8fdb\u884c\u805a\u7c7b\u3002 \u672c\u6587\u6838\u5fc3\u601d\u8def\u5c31\u662f\u5c06\u6574\u4e2a\u95ee\u9898\u8f6c\u6362\u4e3a\u4e00\u4e2a\u56db\u7ef4\u5f20\u91cf (V, U, H, W) \u7684\u56de\u5f52or\u5206\u7c7b\u95ee\u9898\u3002\u5bf9\u6bcf\u4e00\u4e2a\u5750\u6807\u70b9 (h, w) \u5bf9\u5e94\u4e00\u4e2a\u77e9\u9635 (V, U) \uff0c\u8bbe \\alpha \u4e3a\u5355\u4f4d\u8f6c\u6362\u6bd4\u4f8b\uff0c\u5219\u77e9\u9635\u4e2d\u7684\u5143\u7d20 (v, u) \u6307\u4ee3\u539f\u56fe (h + \\alpha v, w + \\alpha u) \u662fmask\u7684\u6982\u7387\uff0c\u6216\u5176\u4ed6\u53c2\u6570\u3002\u8fd9\u6837\u6574\u4e2a\u7f51\u7edc\u7684\u8bad\u7ec3\u76ee\u6807\u5c31\u548c\u4e00\u4e2a SSD \u6216\u8005\u8bf4Yolo\u5dee\u4e0d\u591a\u4e86,\u8fd9\u540c\u65f6\u53c8\u548cDeepMask\u4e0d\u540c\uff0c\u663e\u5f0f\u5730\u8868\u8fbe U, V \u5750\u6807\uff0c\u5e76\u4e3a\u6b64\u9002\u914d\u66f4\u591a\u7684\u8fd0\u7b97\u65b9\u5f0f.","title":"TensorMask: A Foundation for Dense Object Segmentation"},{"location":"other_categories/Segmentation/TensorMask:_A_Foundation_for_Dense_Object_Segmentation/#_1","text":"","title":"\u4e3b\u8981\u8868\u8fbe\u65b9\u5f0f\u7684\u5b9a\u4e49"},{"location":"other_categories/Segmentation/TensorMask:_A_Foundation_for_Dense_Object_Segmentation/#natural-representation","text":"\u8868\u8fbe\u4e3a (V, U, H, W) ,\u5bf9\u4e8e\u4e00\u4e2a4D (V,U,H,W) \u7684\u5f20\u91cf\uff0c\u5b83\u5728 (v, u, y, x) \u7684\u503c\u4ee3\u8868\u5728\u4e00\u4e2a\u4e2d\u5fc3\u5728 (y,x) \u7684\u5927\u5c0f\u4e3a \\alpha V \\times \\alpha U \u7a97\u53e3\u7684\u70b9 (y + \\alpha v, x + \\alpha u) \u7684mask\u503c\u3002","title":"Natural Representation"},{"location":"other_categories/Segmentation/TensorMask:_A_Foundation_for_Dense_Object_Segmentation/#aligned-representation","text":"\u5bf9\u4e00\u4e2a4D (\\hat V, \\hat U, \\hat H, \\hat W) \u7684\u5f20\u91cf\uff0c\u5b83\u5728 (\\hat v, \\hat u, \\hat y, \\hat x) \u7684\u503c\u4ee3\u8868\u5728\u4e00\u4e2a\u4e2d\u5fc3\u5728 (\\hat y, \\hat x) \u7684\u5927\u5c0f\u4e3a \\hat\\alpha \\hat V \\times \\hat\\alpha \\hat U \u7a97\u53e3\u7684\u70b9 (\\hat y - \\hat\\alpha \\hat v, \\hat x - \\hat\\alpha \\hat u) \u7684mask\u503c\u3002 \u5173\u952e\u7684\u7406\u89e3\u662f\u5728\u5750\u6807 (\\hat y, \\hat x) \u4e0a\u7684\u5b50\u77e9\u9635 (\\hat V, \\hat U) \uff0c\u4e0a\u7684\u6240\u6709\u503c\u90fd\u662f\u5728\u63cf\u8ff0\u8fd9\u4e2a\u5750\u6807 (\\hat y, \\hat x) \u7684\uff0c\u6240\u4ee5\u79f0\u4e3a\u4e3a aligned \u4e24\u8005\u7684\u5b9a\u4e49\u53ef\u4ee5\u7531\u8fd9\u5f20\u56fe\u663e\u793a \u4e24\u8005\u7684\u8f6c\u6362\uff1a \\begin{aligned} \\mathcal{F}(v, u, y, x) &= \\hat\\mathcal{F}(v, u, y+\\alpha v, x + \\alpha u) \\\\ \\hat\\mathcal{F}(\\hat v, \\hat u, \\hat y, \\hat x) &= \\mathcal{F}(\\hat v, \\hat u, \\hat y - \\alpha\\hat v, \\hat x- \\alpha\\hat u) \\end{aligned}","title":"Aligned Representation"},{"location":"other_categories/Segmentation/TensorMask:_A_Foundation_for_Dense_Object_Segmentation/#head","text":"\u7f51\u7edc\u91c7\u7528FPN\u8f93\u51fa\u591a\u4e2a\u4e0d\u540c\u5c3a\u5ea6\u7684feature maps,\u5f62\u72b6 (C, \\frac{1}{2^k} H, \\frac{1}{2^k}W","title":"\u7f51\u7edc\u7ed3\u6784, \u8f93\u51faHead, \u7ec6\u8282\u7ed3\u6784, \u8bad\u7ec3\u7ec6\u8282"},{"location":"other_categories/Segmentation/TensorMask:_A_Foundation_for_Dense_Object_Segmentation/#head_1","text":"\u672c\u6587\u6bd4\u8f83\u4e865\u79cd\u8f93\u51faHead. 4\u79cd\u662fbaseline, \u533a\u522b\u5728\u4e8e\u4e0d\u540cScale\u4e0a\u7684\u56fe\uff0c\u7b2c\u4e94\u4e2ahead\u4f1a\u8f93\u51fa\u76f8\u540c\u7cbe\u786e\u5ea6\u7684\u7f51\u683c \u5176\u4e2d\u7684\u7ec6\u8282\u8fd0\u7b97\u5982\u56fe \u8fd9\u4e9b\u7ec6\u8282\u8fd0\u7b97\u672c\u8d28\u4e0a\u90fd\u662f\u5750\u6807\u53d8\u6362\u4ee5\u53ca\u91c7\u6837","title":"\u8f93\u51faHead"},{"location":"other_categories/Segmentation/TensorMask:_A_Foundation_for_Dense_Object_Segmentation/#_2","text":"\u5bf9FPN\u7684\u5fae\u8c03 Label\u5206\u914d Fully Contain center of m is close to center of windows unique","title":"\u8bad\u7ec3\u7ec6\u8282"},{"location":"other_categories/Segmentation/Ultra_Fast_Structure-aware_Deep_Lane_Detection/","text":"Ultra Fast Structure-aware Deep Lane Detection \u8fd9\u7bc7paper\u4f7f\u7528\u65b0\u7684\u601d\u8def\u8fdb\u884c\u9053\u8def\u7ebf\u7684\u68c0\u6d4b\uff0c\u8fbe\u5230\u4e86300+FPS. \u9053\u8def\u68c0\u6d4b\u95ee\u9898\u5b9a\u4e49 \u672c\u6587\u5bf9\u8def\u7ebf\u68c0\u6d4b\u7684\u5b9a\u4e49\u662f\u6709\u6240\u4e0d\u540c\u7684\uff0c\u5b9a\u4e49\u4e3a\uff0c\"\u57fa\u4e8e\u5168\u5c40\u56fe\u7247\u7279\u5f81\u7684row-based selection\".\u6216\u8005\u8bf4\u5728\u6bcf\u4e00\u4e2a\u9884\u8bbe\u5b9a\u7684\u884c\u4e0a\u9009\u62e9\u884c\u5355\u5143\u3002 \u56fe\u4e2d w \u4e3a\u4e00\u884c\u5185\u5217anchor\u7684\u6570\u91cf\u3002 P_{i, j,:}=f^{i j}(X), \\text { s.t. } i \\in[1, C], j \\in[1, h] \u5176\u4e2d C \u4e3a\u6700\u5927\u9053\u8def\u7ebf\u6570\uff0c h \u4e3arow anchor\u7684\u6570\u91cf\uff0c\u6bcf\u4e00\u4e2alane\u5728\u4e00\u4e2arow-anchor\u4e0a\u53ea\u6709\u4e00\u4e2a\u5206\u7c7b\u7ed3\u679c\uff0c\u6240\u4ee5\u635f\u5931loss\u4e3a\uff1a L_{c l s}=\\sum_{i=1}^{C} \\sum_{j=1}^{h} L_{C E}\\left(P_{i, j,:}, T_{i, j, i}\\right) \u8f85\u52a9\u635f\u5931 \u76f8\u90bb\u884c\u4e4b\u95f4\u9053\u8def\u6709\u8fde\u7eed\u6027: L_{s i m}=\\sum_{i=1}^{C} \\sum_{j=1}^{h-1}\\left\\|P_{i, j,:}-P_{i, j+1,:}\\right\\|_{1} \u76f8\u90bb\u9053\u8def\u659c\u7387\u5177\u6709\u8fde\u7eed\u6027: \\begin{aligned} L_{s h p}=\\sum_{i=1}^{C} \\sum_{j=1}^{h-2} \\| &\\left(\\operatorname{Loc}_{i, j}-\\operatorname{Loc}_{i, j+1}\\right) \\\\ &-\\left(\\operatorname{Loc}_{i, j+1}-\\operatorname{Loc}_{i, j+2}\\right) \\|_{1} \\end{aligned} \u7531\u4e8elocation\u4f4d\u7f6e\u5982\u679c\u4f7f\u7528\u4e00\u884c\u4e0a\u7684argmax\u6765\u53d6\u7684\u8bdd\u4e0d\u53ef\u5bfc\uff0c\u6240\u4ee5\u91c7\u7528 softmax\u5f97\u5230\u4e00\u884c\u6bcf\u4e2a\u70b9\u7684\u6982\u7387\u540e\u52a0\u6743\u5e73\u5747\uff0c\u8fd9\u6837\u635f\u5931\u51fd\u6570\u5c31\u53ef\u5bfc\u4e86\u3002 \u7f51\u7edc\u7ed3\u6784","title":"Ultra Fast Structure-aware Deep Lane Detection"},{"location":"other_categories/Segmentation/Ultra_Fast_Structure-aware_Deep_Lane_Detection/#ultra-fast-structure-aware-deep-lane-detection","text":"\u8fd9\u7bc7paper\u4f7f\u7528\u65b0\u7684\u601d\u8def\u8fdb\u884c\u9053\u8def\u7ebf\u7684\u68c0\u6d4b\uff0c\u8fbe\u5230\u4e86300+FPS.","title":"Ultra Fast Structure-aware Deep Lane Detection"},{"location":"other_categories/Segmentation/Ultra_Fast_Structure-aware_Deep_Lane_Detection/#_1","text":"\u672c\u6587\u5bf9\u8def\u7ebf\u68c0\u6d4b\u7684\u5b9a\u4e49\u662f\u6709\u6240\u4e0d\u540c\u7684\uff0c\u5b9a\u4e49\u4e3a\uff0c\"\u57fa\u4e8e\u5168\u5c40\u56fe\u7247\u7279\u5f81\u7684row-based selection\".\u6216\u8005\u8bf4\u5728\u6bcf\u4e00\u4e2a\u9884\u8bbe\u5b9a\u7684\u884c\u4e0a\u9009\u62e9\u884c\u5355\u5143\u3002 \u56fe\u4e2d w \u4e3a\u4e00\u884c\u5185\u5217anchor\u7684\u6570\u91cf\u3002 P_{i, j,:}=f^{i j}(X), \\text { s.t. } i \\in[1, C], j \\in[1, h] \u5176\u4e2d C \u4e3a\u6700\u5927\u9053\u8def\u7ebf\u6570\uff0c h \u4e3arow anchor\u7684\u6570\u91cf\uff0c\u6bcf\u4e00\u4e2alane\u5728\u4e00\u4e2arow-anchor\u4e0a\u53ea\u6709\u4e00\u4e2a\u5206\u7c7b\u7ed3\u679c\uff0c\u6240\u4ee5\u635f\u5931loss\u4e3a\uff1a L_{c l s}=\\sum_{i=1}^{C} \\sum_{j=1}^{h} L_{C E}\\left(P_{i, j,:}, T_{i, j, i}\\right)","title":"\u9053\u8def\u68c0\u6d4b\u95ee\u9898\u5b9a\u4e49"},{"location":"other_categories/Segmentation/Ultra_Fast_Structure-aware_Deep_Lane_Detection/#_2","text":"\u76f8\u90bb\u884c\u4e4b\u95f4\u9053\u8def\u6709\u8fde\u7eed\u6027: L_{s i m}=\\sum_{i=1}^{C} \\sum_{j=1}^{h-1}\\left\\|P_{i, j,:}-P_{i, j+1,:}\\right\\|_{1} \u76f8\u90bb\u9053\u8def\u659c\u7387\u5177\u6709\u8fde\u7eed\u6027: \\begin{aligned} L_{s h p}=\\sum_{i=1}^{C} \\sum_{j=1}^{h-2} \\| &\\left(\\operatorname{Loc}_{i, j}-\\operatorname{Loc}_{i, j+1}\\right) \\\\ &-\\left(\\operatorname{Loc}_{i, j+1}-\\operatorname{Loc}_{i, j+2}\\right) \\|_{1} \\end{aligned} \u7531\u4e8elocation\u4f4d\u7f6e\u5982\u679c\u4f7f\u7528\u4e00\u884c\u4e0a\u7684argmax\u6765\u53d6\u7684\u8bdd\u4e0d\u53ef\u5bfc\uff0c\u6240\u4ee5\u91c7\u7528 softmax\u5f97\u5230\u4e00\u884c\u6bcf\u4e2a\u70b9\u7684\u6982\u7387\u540e\u52a0\u6743\u5e73\u5747\uff0c\u8fd9\u6837\u635f\u5931\u51fd\u6570\u5c31\u53ef\u5bfc\u4e86\u3002","title":"\u8f85\u52a9\u635f\u5931"},{"location":"other_categories/Segmentation/Ultra_Fast_Structure-aware_Deep_Lane_Detection/#_3","text":"","title":"\u7f51\u7edc\u7ed3\u6784"},{"location":"other_categories/Segmentation/YOLACT/","text":"YOLACT Real-time Instance Segmentation \u8fd9\u7bc7\u8bba\u6587\u5c1d\u8bd5\u89e3\u51b3\u7684\u662fone stage instance segmentation\u7684\u95ee\u9898\u3002\u672c\u6587\u6709\u6210\u719f\u7684\u5f00\u6e90\u4ee3\u7801\u4ee5\u53ca\u8f83\u5feb\u7684inference\u901f\u5ea6\uff0c\u503c\u5f97\u4e86\u89e3\u5b66\u4e60\u3002\u672c\u6587\u4e3b\u8981\u7684\u4e24\u4e2a\u8d21\u732e\uff0c\u4e00\u4e2a\u662f\u63d0\u51fa\u4e86YOLOACT\uff0c\u57fa\u4e8eprototype mask\u4ee5\u53cacoefficient\u7684\u89e3\u51b3\u65b9\u5f0f\uff0c\u53e6\u4e00\u4e2a\u662fFastNMS \u603b\u4f53\u6d41\u7a0b \u672c\u6587\u7684backbone\u9009\u62e9\u4e86\u57fa\u4e8eResNet\u7684 Feature Pyramid network,\u8fd9\u91cc\u6709\u4e00\u4e2a\u57fa\u4e8eretina\u7684\u7f51\u7edc pytorch\u5b9e\u73b0 \uff0c\u4e5f\u6709\u4e00\u4e2a \u9b54\u6539\u8fc7\u7684 . Prediction head \u6bcf\u4e00\u4e2ascale\u5305\u542b\u4e09\u4e2a\u90e8\u5206 \u5206\u522b\u4e3a\u5206\u7c7b\u30012D\u6846\u56de\u5f52\u4ee5\u53camask \u53c2\u6570 Protonet \u8fd9\u91cc\u4eceP3\u5f15\u51fa\uff0c\u91c7\u7528\u4e86FCN\u7684\u65b9\u5f0f\uff0c\u4f5c\u8005\u7684\u7406\u5ff5\u662f\uff0cCNN\u53ef\u4ee5\u4ea7\u751f spatially coherent\u7684\u7279\u5f81\uff0c\u800cFully connected layer\u4fbf\u4e8e\u4ea7\u751f\u8bed\u4e49\u7279\u5f81\uff0c\u56e0\u800c\u8ba9FC layers(conv 1*1)\u4ea7\u751fmask\uff0c\u7528FCN\u4ea7\u751fmask \u878d\u5408 M=\\sigma\\left(P C^{T}\\right) \u5176\u4e2d P: h\\times w \\times k, C:n\\times k \uff0cP\u4ee3\u8868k\u4e2aprototype\uff0cC\u4ee3\u8868n\u4e2a\u957f\u5ea6\u4e3ak\u7684nms\u540e\u7684key vector. \u6574\u4e2a\u7f51\u7edc\u7528\u5206\u7c7b\u4e0e\u56de\u5f52loss\u7aef\u5230\u7aef\u8bad\u7ec3 Fast NMS \u601d\u8def\u5c31\u662f\u5141\u8bb8\u88ab\u5220\u9664\u7684bounding box\u53bb\u6291\u5236\u5176\u4ed6\u7f51\u683c\uff0c\u5728\u539f\u7248\u7684nms\u4e2d\uff0cbox\u7684\u6291\u5236\u4e0eiou\u7684\u8ba1\u7b97\u9700\u8981\u4e00\u5b9a\u8fed\u4ee3\u8ba1\u7b97\uff0c\u8fd9\u91cc\u53ef\u4ee5\u76f4\u63a5\u5e76\u884c\u8fd0\u7b97\u5e76\u4e14\u7528 pytorch API\u76f4\u63a5\u5feb\u901f\u5b9e\u73b0 \uff0c\u53ea\u4e0d\u8fc7\u4f1a\u591asuppress\u4e00\u4e9bbbox\u3002","title":"YOLACT Real-time Instance Segmentation"},{"location":"other_categories/Segmentation/YOLACT/#yolact-real-time-instance-segmentation","text":"\u8fd9\u7bc7\u8bba\u6587\u5c1d\u8bd5\u89e3\u51b3\u7684\u662fone stage instance segmentation\u7684\u95ee\u9898\u3002\u672c\u6587\u6709\u6210\u719f\u7684\u5f00\u6e90\u4ee3\u7801\u4ee5\u53ca\u8f83\u5feb\u7684inference\u901f\u5ea6\uff0c\u503c\u5f97\u4e86\u89e3\u5b66\u4e60\u3002\u672c\u6587\u4e3b\u8981\u7684\u4e24\u4e2a\u8d21\u732e\uff0c\u4e00\u4e2a\u662f\u63d0\u51fa\u4e86YOLOACT\uff0c\u57fa\u4e8eprototype mask\u4ee5\u53cacoefficient\u7684\u89e3\u51b3\u65b9\u5f0f\uff0c\u53e6\u4e00\u4e2a\u662fFastNMS","title":"YOLACT Real-time Instance Segmentation"},{"location":"other_categories/Segmentation/YOLACT/#_1","text":"\u672c\u6587\u7684backbone\u9009\u62e9\u4e86\u57fa\u4e8eResNet\u7684 Feature Pyramid network,\u8fd9\u91cc\u6709\u4e00\u4e2a\u57fa\u4e8eretina\u7684\u7f51\u7edc pytorch\u5b9e\u73b0 \uff0c\u4e5f\u6709\u4e00\u4e2a \u9b54\u6539\u8fc7\u7684 .","title":"\u603b\u4f53\u6d41\u7a0b"},{"location":"other_categories/Segmentation/YOLACT/#prediction-head","text":"\u6bcf\u4e00\u4e2ascale\u5305\u542b\u4e09\u4e2a\u90e8\u5206 \u5206\u522b\u4e3a\u5206\u7c7b\u30012D\u6846\u56de\u5f52\u4ee5\u53camask \u53c2\u6570","title":"Prediction head"},{"location":"other_categories/Segmentation/YOLACT/#protonet","text":"\u8fd9\u91cc\u4eceP3\u5f15\u51fa\uff0c\u91c7\u7528\u4e86FCN\u7684\u65b9\u5f0f\uff0c\u4f5c\u8005\u7684\u7406\u5ff5\u662f\uff0cCNN\u53ef\u4ee5\u4ea7\u751f spatially coherent\u7684\u7279\u5f81\uff0c\u800cFully connected layer\u4fbf\u4e8e\u4ea7\u751f\u8bed\u4e49\u7279\u5f81\uff0c\u56e0\u800c\u8ba9FC layers(conv 1*1)\u4ea7\u751fmask\uff0c\u7528FCN\u4ea7\u751fmask","title":"Protonet"},{"location":"other_categories/Segmentation/YOLACT/#_2","text":"M=\\sigma\\left(P C^{T}\\right) \u5176\u4e2d P: h\\times w \\times k, C:n\\times k \uff0cP\u4ee3\u8868k\u4e2aprototype\uff0cC\u4ee3\u8868n\u4e2a\u957f\u5ea6\u4e3ak\u7684nms\u540e\u7684key vector. \u6574\u4e2a\u7f51\u7edc\u7528\u5206\u7c7b\u4e0e\u56de\u5f52loss\u7aef\u5230\u7aef\u8bad\u7ec3","title":"\u878d\u5408"},{"location":"other_categories/Segmentation/YOLACT/#fast-nms","text":"\u601d\u8def\u5c31\u662f\u5141\u8bb8\u88ab\u5220\u9664\u7684bounding box\u53bb\u6291\u5236\u5176\u4ed6\u7f51\u683c\uff0c\u5728\u539f\u7248\u7684nms\u4e2d\uff0cbox\u7684\u6291\u5236\u4e0eiou\u7684\u8ba1\u7b97\u9700\u8981\u4e00\u5b9a\u8fed\u4ee3\u8ba1\u7b97\uff0c\u8fd9\u91cc\u53ef\u4ee5\u76f4\u63a5\u5e76\u884c\u8fd0\u7b97\u5e76\u4e14\u7528 pytorch API\u76f4\u63a5\u5feb\u901f\u5b9e\u73b0 \uff0c\u53ea\u4e0d\u8fc7\u4f1a\u591asuppress\u4e00\u4e9bbbox\u3002","title":"Fast NMS"},{"location":"other_categories/Segmentation/blenderMask/","text":"BlendMask: Top-Down Meets Bottom-Up for Instance Segmentation \u8fd9\u7bc7paper\u4ece YOLOACT \u51fa\u53d1\uff0c\u8fdb\u884c\u4e86\u591a\u4e2a\u63d0\u5347\u7ec6\u8282\u3002 \u603b\u4f53pipeline \u5728 YOLOACT \u4e2d\uff0c\u6240\u8c13\"\u9876\u5c42\"detection\u7ed3\u679c\u662f\u4e00\u7cfb\u52172D detection\u7684\u7ed3\u679c\uff0c\u7531\u4e8e\u9700\u8981\u8f93\u51fa a \u4e2aanchors, \u56e0\u800c\u8f93\u51fachannel\u91cc\u9762\u6709 k\\times a \u4e2achannels\u8d1f\u8d23\u7ed9 a \u4e2aanchors\u5206\u522b\u9884\u6d4b k \u4e2a\u53c2\u6570\uff0c\u8fd9\u4e9b\u53c2\u6570\u7528\u6765\u7ed9 k \u4e2aattention mask\u4f5c\u7ebf\u6027\u7ec4\u5408\u3002\u56e0\u800c\u6bcf\u4e00\u4e2amask\u53ea\u80fd\u6709\u4e00\u4e2a\u5e38\u6570\u3002 \u672c\u6587\u91c7\u7528\u4e86 FCOS \u7684 anchor-free detection\u65b9\u6848\uff0c\u5728 FCOS \u4e2d\uff0c\u6bcf\u4e00\u4e2atower\u53ea\u9700\u8981\u8f93\u51fa6\u4e2achannel\u6765\u5b8c\u62102D detection\uff0c\u800c\u6709\u4e86\u66f4\u591a\u7684channel\u7528\u4e86\u9884\u6d4b\u65b0\u7684\u4fe1\u606f\uff0c\u4f5c\u8005\u8fd9\u91cc\u8bbe\u7f6e K \\times M \\times M \u4e2a\u53c2\u6570\uff0c\u7528\u6765\u4f5cblending\uff0c\u8fd9\u91ccK\u6307\u7684\u5c31\u662fmask\u6570\u91cf\uff0cM\u6307\u7684\u662f\u53c2\u6570\u5206\u8fa8\u7387\u3002 Bottom Module\uff0c \u9009\u62e9DeepLabV3+\u7684decoder.\u8f93\u51fa K \u4e2amask. Blender Module \u4f5c\u8005\u5c06Bottom Module\u7684\u8f93\u51fa\uff0c\u6839\u636e\u9876\u5c42detection\u7ed3\u679c\uff0c\u7528RoiPooling\u53d6\u5f97 K \u4e2a R\\times R \u7684\u7279\u5f81\u56fe\uff0c\u5c06\u9876\u5c42\u8f93\u51fa\u7684 M\\times M \u4e2a\u53c2\u6570interpolate \u5230 R\\times R \uff0c \\mathbf{a}_{d}^{\\prime}=\\text { interpolate }_{M \\times M \\rightarrow R \\times R}\\left(\\mathbf{a}_{d}\\right), \\quad \\forall d \\in\\{1 \\ldots D\\} \\mathbf{s}_{d}=\\operatorname{softmax}\\left(\\mathbf{a}_{d}^{\\prime}\\right), \\quad \\forall d \\in\\{1 \\ldots D\\} \u6700\u540e\u7528\u70b9\u4e58\u4e0e\u7d2f\u52a0\uff0c\u5982\u4e0a\u56fe\u4e00\u6837\u53e0\u52a0\u8d77\u6765 \\mathbf{m}_{d}=\\sum_{k=1}^{K} \\mathbf{s}_{d}^{k} \\circ \\mathbf{r}_{d}^{k}, \\quad \\forall d \\in\\{1 \\ldots D\\}","title":"BlendMask: Top-Down Meets Bottom-Up for Instance Segmentation"},{"location":"other_categories/Segmentation/blenderMask/#blendmask-top-down-meets-bottom-up-for-instance-segmentation","text":"\u8fd9\u7bc7paper\u4ece YOLOACT \u51fa\u53d1\uff0c\u8fdb\u884c\u4e86\u591a\u4e2a\u63d0\u5347\u7ec6\u8282\u3002","title":"BlendMask: Top-Down Meets Bottom-Up for Instance Segmentation"},{"location":"other_categories/Segmentation/blenderMask/#pipeline","text":"\u5728 YOLOACT \u4e2d\uff0c\u6240\u8c13\"\u9876\u5c42\"detection\u7ed3\u679c\u662f\u4e00\u7cfb\u52172D detection\u7684\u7ed3\u679c\uff0c\u7531\u4e8e\u9700\u8981\u8f93\u51fa a \u4e2aanchors, \u56e0\u800c\u8f93\u51fachannel\u91cc\u9762\u6709 k\\times a \u4e2achannels\u8d1f\u8d23\u7ed9 a \u4e2aanchors\u5206\u522b\u9884\u6d4b k \u4e2a\u53c2\u6570\uff0c\u8fd9\u4e9b\u53c2\u6570\u7528\u6765\u7ed9 k \u4e2aattention mask\u4f5c\u7ebf\u6027\u7ec4\u5408\u3002\u56e0\u800c\u6bcf\u4e00\u4e2amask\u53ea\u80fd\u6709\u4e00\u4e2a\u5e38\u6570\u3002 \u672c\u6587\u91c7\u7528\u4e86 FCOS \u7684 anchor-free detection\u65b9\u6848\uff0c\u5728 FCOS \u4e2d\uff0c\u6bcf\u4e00\u4e2atower\u53ea\u9700\u8981\u8f93\u51fa6\u4e2achannel\u6765\u5b8c\u62102D detection\uff0c\u800c\u6709\u4e86\u66f4\u591a\u7684channel\u7528\u4e86\u9884\u6d4b\u65b0\u7684\u4fe1\u606f\uff0c\u4f5c\u8005\u8fd9\u91cc\u8bbe\u7f6e K \\times M \\times M \u4e2a\u53c2\u6570\uff0c\u7528\u6765\u4f5cblending\uff0c\u8fd9\u91ccK\u6307\u7684\u5c31\u662fmask\u6570\u91cf\uff0cM\u6307\u7684\u662f\u53c2\u6570\u5206\u8fa8\u7387\u3002 Bottom Module\uff0c \u9009\u62e9DeepLabV3+\u7684decoder.\u8f93\u51fa K \u4e2amask.","title":"\u603b\u4f53pipeline"},{"location":"other_categories/Segmentation/blenderMask/#blender-module","text":"\u4f5c\u8005\u5c06Bottom Module\u7684\u8f93\u51fa\uff0c\u6839\u636e\u9876\u5c42detection\u7ed3\u679c\uff0c\u7528RoiPooling\u53d6\u5f97 K \u4e2a R\\times R \u7684\u7279\u5f81\u56fe\uff0c\u5c06\u9876\u5c42\u8f93\u51fa\u7684 M\\times M \u4e2a\u53c2\u6570interpolate \u5230 R\\times R \uff0c \\mathbf{a}_{d}^{\\prime}=\\text { interpolate }_{M \\times M \\rightarrow R \\times R}\\left(\\mathbf{a}_{d}\\right), \\quad \\forall d \\in\\{1 \\ldots D\\} \\mathbf{s}_{d}=\\operatorname{softmax}\\left(\\mathbf{a}_{d}^{\\prime}\\right), \\quad \\forall d \\in\\{1 \\ldots D\\} \u6700\u540e\u7528\u70b9\u4e58\u4e0e\u7d2f\u52a0\uff0c\u5982\u4e0a\u56fe\u4e00\u6837\u53e0\u52a0\u8d77\u6765 \\mathbf{m}_{d}=\\sum_{k=1}^{K} \\mathbf{s}_{d}^{k} \\circ \\mathbf{r}_{d}^{k}, \\quad \\forall d \\in\\{1 \\ldots D\\}","title":"Blender Module"},{"location":"other_categories/Segmentation/condInst/","text":"Conditional Convolutions for Instance Segmentation \u8fd9\u7bc7paper\u7ed9\u51fa\u4e86\u4e00\u70b9\u6027\u80fd\u4e0d\u9519\u4e14\u4ee3\u7801\u76f8\u5bf9\u89c4\u8303\u7b80\u6d01\u7684One-Stage Instance Segmentation\u7b97\u6cd5\u3002 \u7f51\u7edc\u7ed3\u6784 \u57fa\u4e8e FCOS \u7684\u68c0\u6d4b\u67b6\u6784\uff0c\u6bcf\u4e00\u4e2ascale\u7684Shared head\u4f1a\u9884\u6d4b\u5206\u7c7b\uff0ccenterness\u7b49\u503c\u3002\u6bcf\u4e00\u4e2a\u88ab\u68c0\u6d4b\u51fa\u6765\u7684\u7269\u4f53\u4f1a\u4f7f\u7528\u8ddf\u968fHead\u4e00\u8d77\u4f30\u8ba1\u7684Convolution filter\uff0c\u5bf9mask\u8fdb\u884c\u878d\u5408. Dynamic Mask Head\u4ee3\u7801","title":"Conditional Convolutions for Instance Segmentation"},{"location":"other_categories/Segmentation/condInst/#conditional-convolutions-for-instance-segmentation","text":"\u8fd9\u7bc7paper\u7ed9\u51fa\u4e86\u4e00\u70b9\u6027\u80fd\u4e0d\u9519\u4e14\u4ee3\u7801\u76f8\u5bf9\u89c4\u8303\u7b80\u6d01\u7684One-Stage Instance Segmentation\u7b97\u6cd5\u3002","title":"Conditional Convolutions for Instance Segmentation"},{"location":"other_categories/Segmentation/condInst/#_1","text":"\u57fa\u4e8e FCOS \u7684\u68c0\u6d4b\u67b6\u6784\uff0c\u6bcf\u4e00\u4e2ascale\u7684Shared head\u4f1a\u9884\u6d4b\u5206\u7c7b\uff0ccenterness\u7b49\u503c\u3002\u6bcf\u4e00\u4e2a\u88ab\u68c0\u6d4b\u51fa\u6765\u7684\u7269\u4f53\u4f1a\u4f7f\u7528\u8ddf\u968fHead\u4e00\u8d77\u4f30\u8ba1\u7684Convolution filter\uff0c\u5bf9mask\u8fdb\u884c\u878d\u5408. Dynamic Mask Head\u4ee3\u7801","title":"\u7f51\u7edc\u7ed3\u6784"},{"location":"other_categories/Segmentation/mmsegmentation/","text":"Some Collections Around MMSegmentation \u672c\u6587\u6536\u96c6\u4e00\u7cfb\u5217 MMSegmentation \u6536\u5f55\u7684\u7f51\u7edc\u7ed3\u6784. \u4ee5Res50-D8 512 \\times 1024 \u5728cityscapes\u4e0a\u7684\u6027\u80fd Methods mIoU FPS FCN 72.25 4.17 PSPNet 77.85 4.07 DeepLabV3+ 79.61 3.94 NonLocal 78.24 2.72 GCNet 77.69 3.93 ANN 77.40 3.71 OCRNet 74.30 10.45 Pyramid Scene Parsing Network (PSPNetwork) pdf code Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation pdf code GCNet: Non-local Networks Meet Squeeze-Excitation Networks and Beyond pdf code Asymmetric Non-local Neural Networks for Semantic Segmentation (ANN) pdf code Object-Contextual Representations for Semantic Segmentation pdf code","title":"Some Collections Around MMSegmentation"},{"location":"other_categories/Segmentation/mmsegmentation/#some-collections-around-mmsegmentation","text":"\u672c\u6587\u6536\u96c6\u4e00\u7cfb\u5217 MMSegmentation \u6536\u5f55\u7684\u7f51\u7edc\u7ed3\u6784. \u4ee5Res50-D8 512 \\times 1024 \u5728cityscapes\u4e0a\u7684\u6027\u80fd Methods mIoU FPS FCN 72.25 4.17 PSPNet 77.85 4.07 DeepLabV3+ 79.61 3.94 NonLocal 78.24 2.72 GCNet 77.69 3.93 ANN 77.40 3.71 OCRNet 74.30 10.45","title":"Some Collections Around MMSegmentation"},{"location":"other_categories/Segmentation/mmsegmentation/#pyramid-scene-parsing-network-pspnetwork","text":"pdf code","title":"Pyramid Scene Parsing Network (PSPNetwork)"},{"location":"other_categories/Segmentation/mmsegmentation/#encoder-decoder-with-atrous-separable-convolution-for-semantic-image-segmentation","text":"pdf code","title":"Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation"},{"location":"other_categories/Segmentation/mmsegmentation/#gcnet-non-local-networks-meet-squeeze-excitation-networks-and-beyond","text":"pdf code","title":"GCNet: Non-local Networks Meet Squeeze-Excitation Networks and Beyond"},{"location":"other_categories/Segmentation/mmsegmentation/#asymmetric-non-local-neural-networks-for-semantic-segmentation-ann","text":"pdf code","title":"Asymmetric Non-local Neural Networks for Semantic Segmentation (ANN)"},{"location":"other_categories/Segmentation/mmsegmentation/#object-contextual-representations-for-semantic-segmentation","text":"pdf code","title":"Object-Contextual Representations for Semantic Segmentation"},{"location":"other_categories/Segmentation/nvidia-multi-scale-seg/","text":"Hierarchical Multi-scale Attention for Semantic Segmentation \u8fd9\u7bc7paper\u7684\u601d\u8def\u662f\u4f7f\u7528auto-labelling \u53bb\u5229\u7528\u597d\u672a\u88ab\u6807\u6ce8\u7684pixels.","title":"Hierarchical Multi-scale Attention for Semantic Segmentation"},{"location":"other_categories/Segmentation/nvidia-multi-scale-seg/#hierarchical-multi-scale-attention-for-semantic-segmentation","text":"\u8fd9\u7bc7paper\u7684\u601d\u8def\u662f\u4f7f\u7528auto-labelling \u53bb\u5229\u7528\u597d\u672a\u88ab\u6807\u6ce8\u7684pixels.","title":"Hierarchical Multi-scale Attention for Semantic Segmentation"},{"location":"other_categories/Summaries/Collections_StereoMatching_KITTI/","text":"Collections of Stereo Matching from KITTI \u672c\u6587\u8bb0\u5f55\u4e86 Stereo Matching \u6709\u6587\u7ae0/\u6709code\u5b9e\u73b0\u7684\u4e3b\u8981paper.\u5c06\u4f1a\u6301\u7eedupdate Update: 2020.0714: Add CDN Methods D1-all D1-bg D1-fg Time CSPN 1.74 1.51 2.88 1.0 GANet-deep 1.81 1.48 3.46 1.8 AcfNet 1.89 1.51 3.80 0.48 CDN-GANet 1.92 1.66 3.20 0.40 AANet+ 2.03 1.65 3.96 0.06 DeepPruner 2.15 1.87 3.56 0.18 PSMNet 2.32 1.86 4.62 0.21 FADNet 2.82 2.68 3.50 0.05 NVStereoNet 3.13 2.62 5.69 0.6 RTS2Net 3.56 3.09 5.91 0.02 SsSMnet 3.40 2.70 6.92 0.8 \u5176\u4e2d\u672c\u7ad9\u5df2\u6709\u7684\u6587\u7ae0\u4e3a CSPN , AcfNet , CDN-GANet , DeepPruner , PSMNet , FADNet , SsSMnet , RTS2Net . Update: 2020.06.08: add RTS2Net GANet pdf code Feature Extraction\u4f7f\u7528\u7684\u662fstacked hourglass network. Cost Volume\u7684\u5f62\u6210\u4e0e PSMNet \u4e00\u81f4\u3002\u7136\u540e\u63a5\u6570\u4e2aSGA\u6a21\u5757\uff0c\u4ee5\u53caLGA\u6a21\u5757\u3002\u5de6\u56fe\u4f1a\u63a5\u4e0a\"guidance subnet\"\u4f7f\u7528\u6570\u4e2a\u7b80\u5355\u5377\u79ef\u751f\u6210\u6743\u91cd\u77e9\u9635\u63d0\u4f9b\u5230GA\u6a21\u5757\u4e2d\u3002 GA\u5c42\u5bf9\u5e94scanline optimization\u65b9\u6cd5 ref1 ref2 ,\u53ef\u4ee5\u7406\u89e3\u4e3a\u4e00\u4e2a\u52a8\u6001\u89c4\u5212\u7b97\u6cd5,\u5176\u4e2d\u672c\u6587\u7684 \\mathbf{r} \u4e3a\u56db\u4e2a\u65b9\u5411\u7684\u77e2\u91cf\u3002\u91cc\u9762\u7684\u6743\u91cd\u662f\u6bcf\u4e00\u4e2a\u50cf\u7d20\u4e0d\u4e00\u81f4\u7684\uff0c\u901a\u8fc7subnet\u63d0\u4f9bguidance. Semi-Global Guided Aggregation(SGA) \u9700\u8981\u7684guidence\u6743\u91cd\u5927\u5c0f\u4e3a H\\times W \\times K\\times F(K=5) \uff0c\u4e0d\u540cdisparity\u4f7f\u7528\u7684\u6743\u91cd\u4e00\u81f4: C_{\\mathbf{r}}^{A}(\\mathbf{p}, d)=\\operatorname{sum}\\left\\{\\begin{array}{l} \\mathbf{w}_{0}(\\mathbf{p}, \\mathbf{r}) \\cdot C(\\mathbf{p}, d) \\\\ \\mathbf{w}_{1}(\\mathbf{p}, \\mathbf{r}) \\cdot C_{\\mathbf{r}}^{A}(\\mathbf{p}-\\mathbf{r}, d) \\\\ \\mathbf{w}_{2}(\\mathbf{p}, \\mathbf{r}) \\cdot C_{\\mathbf{r}}^{A}(\\mathbf{p}-\\mathbf{r}, d-1) \\\\ \\mathbf{w}_{3}(\\mathbf{p}, \\mathbf{r}) \\cdot C_{\\mathbf{r}}^{A}(\\mathbf{p}-\\mathbf{r}, d+1) \\\\ \\mathbf{w}_{4}(\\mathbf{p}, \\mathbf{r}) \\cdot \\max _{i} C_{\\mathbf{r}}^{A}(\\mathbf{p}-\\mathbf{r}, i) \\end{array}\\right. \\text {s.t.} \\quad \\sum_{i=0,1,2,3,4} \\mathbf{w}_{i}(\\mathbf{p}, \\mathbf{r})=1 C^{A}(\\mathbf{p}, d)=\\max _{\\mathbf{r}} C_{\\mathbf{r}}^{A}(\\mathbf{p}, d) Local Aggregation(LGA),\u9700\u8981\u7684guidence\u6743\u91cd\u5927\u5c0f\u4e3a H\\times W\\times 3K^2 \\times F : \\begin{array}{c} C^{A}(\\mathbf{p}, d)=\\operatorname{sum}\\left\\{\\begin{array}{l} \\sum_{\\mathbf{q} \\in N_{\\mathrm{p}}} \\omega_{0}(\\mathbf{p}, \\mathbf{q}) \\cdot C(\\mathbf{q}, d) \\\\ \\sum_{\\mathbf{q} \\in N_{\\mathrm{p}}} \\omega_{1}(\\mathbf{p}, \\mathbf{q}) \\cdot C(\\mathbf{q}, d-1) \\\\ \\sum_{\\mathbf{q} \\in N_{\\mathrm{p}}} \\omega_{2}(\\mathbf{p}, \\mathbf{q}) \\cdot C(\\mathbf{q}, d+1) \\end{array}\\right. \\\\ \\text { s.t. } \\sum_{\\mathbf{q} \\in N_{\\mathrm{p}}} \\omega_{0}(\\mathbf{p}, \\mathbf{q})+\\omega_{1}(\\mathbf{p}, \\mathbf{q})+\\omega_{2}(\\mathbf{p}, \\mathbf{q})=1 \\end{array} AANet pdf code \u672c\u6587\u4f7f\u7528coorelation\u7684\u65b9\u5f0f\u751f\u62103D Cost Volume. Adaptive Intra-Scale Aggregation\u672c\u8d28\u4e0a\u662f\u5206\u7ec4\u7684\u53ef\u53d8\u5377\u79ef\uff1a \\tilde{\\boldsymbol{C}}(d, \\boldsymbol{p})=\\sum_{k=1}^{K^{2}} w_{k} \\cdot \\boldsymbol{C}\\left(d, \\boldsymbol{p}+\\boldsymbol{p}_{k}+\\Delta \\boldsymbol{p}_{k}\\right) \\cdot m_{k} \u591ascale\u878d\u5408\uff0c\u8fd9\u91cc\u91c7\u7528\u7684\u662f HRNet \u7684\u65b9\u6cd5 \\hat{\\boldsymbol{C}}^{s}=\\sum_{k=1}^{S} f_{k}\\left(\\tilde{\\boldsymbol{C}}^{k}\\right), \\quad s=1,2, \\cdots, S f_{k}=\\left\\{\\begin{array}{l} \\mathcal{I}, \\quad k=s \\\\ (s-k) \\text { stride }-2\\oplus 3 \\times 3 \\text { convs, } \\quad k<s \\\\ \\text { upsampling } \\oplus 1 \\times 1 \\text { conv, } \\quad k>s \\end{array}\\right. NVStereoNet pdf code \u635f\u5931\u4e0e monodepth \u76f8\u4f3c L=\\lambda_{1} E_{\\text {image}}+\\lambda_{2} E_{\\text {lidar}}+\\lambda_{3} E_{l r}+\\lambda_{4} E_{d s} \\begin{aligned} E_{\\text {image}} &=E_{\\text {image}}^{l}+E_{\\text {image}}^{r} \\\\ E_{\\text {lidar}} &=\\left|d_{l}-\\bar{d}_{l}\\right|+\\left|d_{r}-\\bar{d}_{r}\\right| \\\\ E_{l r} &=\\frac{1}{n} \\sum_{i j}\\left|d_{i j}^{l}-\\tilde{d}_{i j}^{l}\\right|+\\frac{1}{n} \\sum_{i j}\\left|d_{i j}^{r}-\\tilde{d}_{i j}^{r}\\right| \\\\ E_{d s} &=E_{d s}^{l}+E_{d s}^{r} \\end{aligned} \\begin{aligned} E_{\\text {image}}^{l} &=\\frac{1}{n} \\sum_{i, j} \\alpha \\frac{1-\\operatorname{SSIM}\\left(I_{i j}^{l}, \\tilde{I}_{i j}^{l}\\right)}{2}+(1-\\alpha) | I_{i j}^{l}-\\tilde{I}_{i j}^{l} \\\\ E_{d s}^{l} &=\\frac{1}{n} \\sum_{i, j}\\left|\\partial_{x} d_{i j}^{l}\\right| e^{-\\left\\|\\partial_{x} I_{i, j}^{l}\\right\\|}+\\left|\\partial_{y} d_{i j}^{l}\\right| e^{-\\| \\partial_{y} I_{i, j}^{l}} \\| \\end{aligned}","title":"Collections of Stereo Matching from KITTI"},{"location":"other_categories/Summaries/Collections_StereoMatching_KITTI/#collections-of-stereo-matching-from-kitti","text":"\u672c\u6587\u8bb0\u5f55\u4e86 Stereo Matching \u6709\u6587\u7ae0/\u6709code\u5b9e\u73b0\u7684\u4e3b\u8981paper.\u5c06\u4f1a\u6301\u7eedupdate Update: 2020.0714: Add CDN Methods D1-all D1-bg D1-fg Time CSPN 1.74 1.51 2.88 1.0 GANet-deep 1.81 1.48 3.46 1.8 AcfNet 1.89 1.51 3.80 0.48 CDN-GANet 1.92 1.66 3.20 0.40 AANet+ 2.03 1.65 3.96 0.06 DeepPruner 2.15 1.87 3.56 0.18 PSMNet 2.32 1.86 4.62 0.21 FADNet 2.82 2.68 3.50 0.05 NVStereoNet 3.13 2.62 5.69 0.6 RTS2Net 3.56 3.09 5.91 0.02 SsSMnet 3.40 2.70 6.92 0.8 \u5176\u4e2d\u672c\u7ad9\u5df2\u6709\u7684\u6587\u7ae0\u4e3a CSPN , AcfNet , CDN-GANet , DeepPruner , PSMNet , FADNet , SsSMnet , RTS2Net . Update: 2020.06.08: add RTS2Net","title":"Collections of Stereo Matching from KITTI"},{"location":"other_categories/Summaries/Collections_StereoMatching_KITTI/#ganet","text":"pdf code Feature Extraction\u4f7f\u7528\u7684\u662fstacked hourglass network. Cost Volume\u7684\u5f62\u6210\u4e0e PSMNet \u4e00\u81f4\u3002\u7136\u540e\u63a5\u6570\u4e2aSGA\u6a21\u5757\uff0c\u4ee5\u53caLGA\u6a21\u5757\u3002\u5de6\u56fe\u4f1a\u63a5\u4e0a\"guidance subnet\"\u4f7f\u7528\u6570\u4e2a\u7b80\u5355\u5377\u79ef\u751f\u6210\u6743\u91cd\u77e9\u9635\u63d0\u4f9b\u5230GA\u6a21\u5757\u4e2d\u3002 GA\u5c42\u5bf9\u5e94scanline optimization\u65b9\u6cd5 ref1 ref2 ,\u53ef\u4ee5\u7406\u89e3\u4e3a\u4e00\u4e2a\u52a8\u6001\u89c4\u5212\u7b97\u6cd5,\u5176\u4e2d\u672c\u6587\u7684 \\mathbf{r} \u4e3a\u56db\u4e2a\u65b9\u5411\u7684\u77e2\u91cf\u3002\u91cc\u9762\u7684\u6743\u91cd\u662f\u6bcf\u4e00\u4e2a\u50cf\u7d20\u4e0d\u4e00\u81f4\u7684\uff0c\u901a\u8fc7subnet\u63d0\u4f9bguidance. Semi-Global Guided Aggregation(SGA) \u9700\u8981\u7684guidence\u6743\u91cd\u5927\u5c0f\u4e3a H\\times W \\times K\\times F(K=5) \uff0c\u4e0d\u540cdisparity\u4f7f\u7528\u7684\u6743\u91cd\u4e00\u81f4: C_{\\mathbf{r}}^{A}(\\mathbf{p}, d)=\\operatorname{sum}\\left\\{\\begin{array}{l} \\mathbf{w}_{0}(\\mathbf{p}, \\mathbf{r}) \\cdot C(\\mathbf{p}, d) \\\\ \\mathbf{w}_{1}(\\mathbf{p}, \\mathbf{r}) \\cdot C_{\\mathbf{r}}^{A}(\\mathbf{p}-\\mathbf{r}, d) \\\\ \\mathbf{w}_{2}(\\mathbf{p}, \\mathbf{r}) \\cdot C_{\\mathbf{r}}^{A}(\\mathbf{p}-\\mathbf{r}, d-1) \\\\ \\mathbf{w}_{3}(\\mathbf{p}, \\mathbf{r}) \\cdot C_{\\mathbf{r}}^{A}(\\mathbf{p}-\\mathbf{r}, d+1) \\\\ \\mathbf{w}_{4}(\\mathbf{p}, \\mathbf{r}) \\cdot \\max _{i} C_{\\mathbf{r}}^{A}(\\mathbf{p}-\\mathbf{r}, i) \\end{array}\\right. \\text {s.t.} \\quad \\sum_{i=0,1,2,3,4} \\mathbf{w}_{i}(\\mathbf{p}, \\mathbf{r})=1 C^{A}(\\mathbf{p}, d)=\\max _{\\mathbf{r}} C_{\\mathbf{r}}^{A}(\\mathbf{p}, d) Local Aggregation(LGA),\u9700\u8981\u7684guidence\u6743\u91cd\u5927\u5c0f\u4e3a H\\times W\\times 3K^2 \\times F : \\begin{array}{c} C^{A}(\\mathbf{p}, d)=\\operatorname{sum}\\left\\{\\begin{array}{l} \\sum_{\\mathbf{q} \\in N_{\\mathrm{p}}} \\omega_{0}(\\mathbf{p}, \\mathbf{q}) \\cdot C(\\mathbf{q}, d) \\\\ \\sum_{\\mathbf{q} \\in N_{\\mathrm{p}}} \\omega_{1}(\\mathbf{p}, \\mathbf{q}) \\cdot C(\\mathbf{q}, d-1) \\\\ \\sum_{\\mathbf{q} \\in N_{\\mathrm{p}}} \\omega_{2}(\\mathbf{p}, \\mathbf{q}) \\cdot C(\\mathbf{q}, d+1) \\end{array}\\right. \\\\ \\text { s.t. } \\sum_{\\mathbf{q} \\in N_{\\mathrm{p}}} \\omega_{0}(\\mathbf{p}, \\mathbf{q})+\\omega_{1}(\\mathbf{p}, \\mathbf{q})+\\omega_{2}(\\mathbf{p}, \\mathbf{q})=1 \\end{array}","title":"GANet"},{"location":"other_categories/Summaries/Collections_StereoMatching_KITTI/#aanet","text":"pdf code \u672c\u6587\u4f7f\u7528coorelation\u7684\u65b9\u5f0f\u751f\u62103D Cost Volume. Adaptive Intra-Scale Aggregation\u672c\u8d28\u4e0a\u662f\u5206\u7ec4\u7684\u53ef\u53d8\u5377\u79ef\uff1a \\tilde{\\boldsymbol{C}}(d, \\boldsymbol{p})=\\sum_{k=1}^{K^{2}} w_{k} \\cdot \\boldsymbol{C}\\left(d, \\boldsymbol{p}+\\boldsymbol{p}_{k}+\\Delta \\boldsymbol{p}_{k}\\right) \\cdot m_{k} \u591ascale\u878d\u5408\uff0c\u8fd9\u91cc\u91c7\u7528\u7684\u662f HRNet \u7684\u65b9\u6cd5 \\hat{\\boldsymbol{C}}^{s}=\\sum_{k=1}^{S} f_{k}\\left(\\tilde{\\boldsymbol{C}}^{k}\\right), \\quad s=1,2, \\cdots, S f_{k}=\\left\\{\\begin{array}{l} \\mathcal{I}, \\quad k=s \\\\ (s-k) \\text { stride }-2\\oplus 3 \\times 3 \\text { convs, } \\quad k<s \\\\ \\text { upsampling } \\oplus 1 \\times 1 \\text { conv, } \\quad k>s \\end{array}\\right.","title":"AANet"},{"location":"other_categories/Summaries/Collections_StereoMatching_KITTI/#nvstereonet","text":"pdf code \u635f\u5931\u4e0e monodepth \u76f8\u4f3c L=\\lambda_{1} E_{\\text {image}}+\\lambda_{2} E_{\\text {lidar}}+\\lambda_{3} E_{l r}+\\lambda_{4} E_{d s} \\begin{aligned} E_{\\text {image}} &=E_{\\text {image}}^{l}+E_{\\text {image}}^{r} \\\\ E_{\\text {lidar}} &=\\left|d_{l}-\\bar{d}_{l}\\right|+\\left|d_{r}-\\bar{d}_{r}\\right| \\\\ E_{l r} &=\\frac{1}{n} \\sum_{i j}\\left|d_{i j}^{l}-\\tilde{d}_{i j}^{l}\\right|+\\frac{1}{n} \\sum_{i j}\\left|d_{i j}^{r}-\\tilde{d}_{i j}^{r}\\right| \\\\ E_{d s} &=E_{d s}^{l}+E_{d s}^{r} \\end{aligned} \\begin{aligned} E_{\\text {image}}^{l} &=\\frac{1}{n} \\sum_{i, j} \\alpha \\frac{1-\\operatorname{SSIM}\\left(I_{i j}^{l}, \\tilde{I}_{i j}^{l}\\right)}{2}+(1-\\alpha) | I_{i j}^{l}-\\tilde{I}_{i j}^{l} \\\\ E_{d s}^{l} &=\\frac{1}{n} \\sum_{i, j}\\left|\\partial_{x} d_{i j}^{l}\\right| e^{-\\left\\|\\partial_{x} I_{i, j}^{l}\\right\\|}+\\left|\\partial_{y} d_{i j}^{l}\\right| e^{-\\| \\partial_{y} I_{i, j}^{l}} \\| \\end{aligned}","title":"NVStereoNet"},{"location":"other_categories/Summaries/MachineLearningForRobotPlanningAndContrlGeorgiaTech/","text":"Machine Learning for Robot Planning and Control from Byron Boots Georgia Tech Robot Learning Lab \u672c\u6587\u5148\u8ba8\u8bba\u5f00\u8f66\u8fd9\u4e2a\u95ee\u9898\uff0c\u5e76\u5f15\u51fa\u6df1\u5ea6\u5b66\u4e60\u5728\u673a\u5668\u4eba\u63a7\u5236\u4e0e\u89c4\u5212\u4e2d\u7684\u5229\u7528\u7684\u4e00\u4e2a\u4e09\u89d2\u56fe\u3002 MPC \u7b2c\u4e00\u90e8\u5206\u5148\u96c6\u4e2d\u8ba8\u8bbaMPC\uff0cMPC\u662f\u4e00\u4e2a\u6210\u529f\u7684\u7b97\u6cd5\u4ee5\u53ca\u89e3\u51b3\u95ee\u9898\u7684\u65b9\u5f0f\uff0c\u4f46\u662f\u5927\u5bb6\u666e\u904d\u8ba4\u4e3a\u6210\u529f\u7684\u4f20\u7edfMPC\u6709\u4e00\u4e9b\u95ee\u9898\u3002\u603b\u7ed3\u8d77\u6765\uff0cMPC\u95ee\u9898\u4e00\u662f\u975e\u7ebf\u6027(\u52a8\u529b\u5b66\u4e0e\u7ea6\u675f)\uff0c\u95ee\u9898\u4e8c\u662f\u6a21\u578b\u4e0d\u51c6\u786e\u3002 \u7136\u540e\u4ecb\u7ecd\u4e86 MPPI\u7b97\u6cd5 \u8fd9\u91cc\u63cf\u8ff0\u7684\u53e6\u4e00\u4e2a\u95ee\u9898\u662f\u5728\u4f7f\u7528MPPI\u7b97\u6cd5\u5b9e\u65f6\u5b66\u4e60\u7684\u65f6\u5019\uff0c\u5b58\u5728\u4e00\u4e2a\u63a2\u7d22\u7684\u95ee\u9898\uff0c\u8f93\u5165\u9700\u8981\u4e30\u5bcc\uff0c\u540c\u65f6\u4e0e\u5b9e\u9645\u7684\u8f93\u5165\u5206\u5e03\u76f8\u4f3c\u3002 \u8981\u7f13\u89e3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6f14\u8bb2\u8005\u4f7f\u7528\u7684\u5176\u4e2d\u4e00\u4e2a\u65b9\u6cd5\u662f\u5148\u7528human driver\u5f97\u5230\u521d\u59cb\u6570\u636e\uff0c\u5bf9\u6a21\u578b\u8fdb\u884c\u521d\u59cb\u8bad\u7ec3(bootstrapping)\u3002 Imitation \u63a5\u7740\u6211\u4eec\u8ba8\u8bba\u6a21\u4eff\u5b66\u4e60\u4ee5\u53ca\u5728\u4e13\u5bb6\u5f15\u5bfc\u4e0b\u7684\u63a2\u7d22\u95ee\u9898\u3002 \u8fd9\u91cc\u6307\u5411\u4e86 AggreVaTeD (Aggregate Values to Imitate) [Sun, Venkatraman, Gordon, Boots, Bagnell; ICML 2017]\u3002 \u6682\u672a\u6536\u5f55\u6b64\u8bba\u6587 Parameterized a Robot \u8fd9\u91cc\u6307\u5411\u4e86differentiable MPC(\u8fd9\u7bc7\u8bba\u6587\u53c8\u5f88\u91cd\u8981\u5730\u53c2\u8003\u4e86OptNet)\uff0c","title":"Machine Learning for Robot Planning and Control from  Byron Boots Georgia Tech Robot Learning Lab"},{"location":"other_categories/Summaries/MachineLearningForRobotPlanningAndContrlGeorgiaTech/#machine-learning-for-robot-planning-and-control-from-byron-boots-georgia-tech-robot-learning-lab","text":"\u672c\u6587\u5148\u8ba8\u8bba\u5f00\u8f66\u8fd9\u4e2a\u95ee\u9898\uff0c\u5e76\u5f15\u51fa\u6df1\u5ea6\u5b66\u4e60\u5728\u673a\u5668\u4eba\u63a7\u5236\u4e0e\u89c4\u5212\u4e2d\u7684\u5229\u7528\u7684\u4e00\u4e2a\u4e09\u89d2\u56fe\u3002","title":"Machine Learning for Robot Planning and Control from  Byron Boots Georgia Tech Robot Learning Lab"},{"location":"other_categories/Summaries/MachineLearningForRobotPlanningAndContrlGeorgiaTech/#mpc","text":"\u7b2c\u4e00\u90e8\u5206\u5148\u96c6\u4e2d\u8ba8\u8bbaMPC\uff0cMPC\u662f\u4e00\u4e2a\u6210\u529f\u7684\u7b97\u6cd5\u4ee5\u53ca\u89e3\u51b3\u95ee\u9898\u7684\u65b9\u5f0f\uff0c\u4f46\u662f\u5927\u5bb6\u666e\u904d\u8ba4\u4e3a\u6210\u529f\u7684\u4f20\u7edfMPC\u6709\u4e00\u4e9b\u95ee\u9898\u3002\u603b\u7ed3\u8d77\u6765\uff0cMPC\u95ee\u9898\u4e00\u662f\u975e\u7ebf\u6027(\u52a8\u529b\u5b66\u4e0e\u7ea6\u675f)\uff0c\u95ee\u9898\u4e8c\u662f\u6a21\u578b\u4e0d\u51c6\u786e\u3002 \u7136\u540e\u4ecb\u7ecd\u4e86 MPPI\u7b97\u6cd5 \u8fd9\u91cc\u63cf\u8ff0\u7684\u53e6\u4e00\u4e2a\u95ee\u9898\u662f\u5728\u4f7f\u7528MPPI\u7b97\u6cd5\u5b9e\u65f6\u5b66\u4e60\u7684\u65f6\u5019\uff0c\u5b58\u5728\u4e00\u4e2a\u63a2\u7d22\u7684\u95ee\u9898\uff0c\u8f93\u5165\u9700\u8981\u4e30\u5bcc\uff0c\u540c\u65f6\u4e0e\u5b9e\u9645\u7684\u8f93\u5165\u5206\u5e03\u76f8\u4f3c\u3002 \u8981\u7f13\u89e3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6f14\u8bb2\u8005\u4f7f\u7528\u7684\u5176\u4e2d\u4e00\u4e2a\u65b9\u6cd5\u662f\u5148\u7528human driver\u5f97\u5230\u521d\u59cb\u6570\u636e\uff0c\u5bf9\u6a21\u578b\u8fdb\u884c\u521d\u59cb\u8bad\u7ec3(bootstrapping)\u3002","title":"MPC"},{"location":"other_categories/Summaries/MachineLearningForRobotPlanningAndContrlGeorgiaTech/#imitation","text":"\u63a5\u7740\u6211\u4eec\u8ba8\u8bba\u6a21\u4eff\u5b66\u4e60\u4ee5\u53ca\u5728\u4e13\u5bb6\u5f15\u5bfc\u4e0b\u7684\u63a2\u7d22\u95ee\u9898\u3002 \u8fd9\u91cc\u6307\u5411\u4e86 AggreVaTeD (Aggregate Values to Imitate) [Sun, Venkatraman, Gordon, Boots, Bagnell; ICML 2017]\u3002 \u6682\u672a\u6536\u5f55\u6b64\u8bba\u6587","title":"Imitation"},{"location":"other_categories/Summaries/MachineLearningForRobotPlanningAndContrlGeorgiaTech/#parameterized-a-robot","text":"\u8fd9\u91cc\u6307\u5411\u4e86differentiable MPC(\u8fd9\u7bc7\u8bba\u6587\u53c8\u5f88\u91cd\u8981\u5730\u53c2\u8003\u4e86OptNet)\uff0c","title":"Parameterized a Robot"},{"location":"other_categories/Summaries/SelfAttentionandCNN/","text":"Summary of Self Attention / Transformer in Vision System (Last update 2020-01-15) \u8fd9\u662f\u4e00\u4efd\u63cf\u8ff0\u6570\u7bc7\u5173\u4e8e\u5728CNN\u7cfb\u7edf\u4e2d\u4f7f\u7528self-attention\u7684\u5c0f\u7edf\u8ba1. \u5bf9\u4e8e\u5728NLP\u53d6\u5f97\u5f88\u597d\u8868\u73b0\u7684self-attention\u673a\u5236\uff0c\u672c\u7f51\u7ad9\u5728\u8bba\u6587 Attention is all you need \u6709\u8be6\u7ec6\u7684\u4ecb\u7ecd\u3002 2019\u5e74\u4e0a\u534a\u5e74\uff0cGoogle \u63d0\u51fa\u4e86 Attention Augmented Convolution , \u8fd9\u662f\u4e00\u4e2a\u7c7b\u4f3c Non-local \u6a21\u5757\u7684\u601d\u8def\uff0c\u501f\u7528self-attention\u7684\u673a\u5236\u52a0\u4e0apositional-encoding\uff0c\u8bbe\u8ba1\u51fa\u4e00\u4e2a\u63d0\u4f9b\u5168\u5c40attention\u7684\u6a21\u5757\uff0c\u8fd9\u4e2a\u6a21\u5757\u7684\u7f3a\u70b9\u5728\u4e8e\u5728\u56fe\u7247\u5f88\u5927\u7684\u65f6\u5019\u4f1a\u9700\u8981\u4e00\u4e2a\u5f88\u5927\u7684\u77e9\u9635\u4e58\u6cd5\uff0c\u6240\u4ee5\u8fd9\u4e2a\u6a21\u5757\u5fc5\u987b\u53ea\u80fd\u5728\u591a\u6b21\u4e0b\u91c7\u6837\u540e\u4f7f\u7528\uff0c\u4e14\u8fd8\u9700\u8981\u6ce8\u91cd\u663e\u5b58\u7ba1\u7406\uff0c\u53ef\u4ee5\u7406\u89e3\u4e3a\u662f\u4e00\u4e2a\u96be\u4ee5scale up\u7684\u65b9\u6848\u3002 \u672c\u6587\u63a5\u4e0b\u6765\u4f1a\u4ecb\u7ecd\u4e24\u7bc7paper\uff0c\u4e00\u7bc7paper\u63d0\u51fa\u4e86\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u56fe\u7247\u5c40\u90e8attention\u7684\u6a21\u5757\uff0c\u7528\u7565\u5c11\u4e8e\u4f20\u7edfConv\u7684\u8fd0\u7b97\u4e0e\u53c2\u6570\uff0c\u5728imagenet\u548cCoco\u5206\u522b\u5f97\u5230\u4e86\u4e0e\u4f20\u7edfCNN\u51e0\u4e4e\u4e00\u81f4\u7684\u6027\u80fd\u3002\u53e6\u4e00\u7bc7\u9610\u8ff0\u4e86\u5c40\u90e8Attention\u4e0eConvolution\u7684\u5173\u7cfb\uff0c\u8868\u660eMulti-head \u5c40\u90e8Attention\u53ef\u4ee5\u5b9e\u73b0\u4f20\u7edfConvolution\u7684\u6027\u80fd\u3002 Stand-Alone Self-Attention in Vision Models pdf code y_{i j}=\\sum_{a, b \\in \\mathcal{N}_{k}(i, j)} \\operatorname{softmax}_{a b}\\left(q_{i j}^{\\top} k_{a b}+q_{i j}^{\\top} r_{a-i, b-j}\\right) v_{a b} \u8fd9\u4e2a\u6a21\u5757\u7684\u8bbe\u8ba1\u53ef\u4ee5\u76f4\u63a5CNN\uff0c\u540c\u65f6\u8fd0\u7b97\u91cf\u5e76\u6ca1\u6709\u663e\u7136\u63d0\u5347\uff0c\u6027\u80fd\u5219\u76f8\u8fd1\u3002 \u4f5c\u8005\u901a\u8fc7\u5b9e\u9a8c\u53d1\u73b0\u9664\u4e86\u7b2c\u4e00\u4e2aConv\u5efa\u8bae\u7528Convolution\uff0c\u6a21\u578b\u7684\u5176\u4f59\u5377\u79ef\u6a21\u5757\u5c31\u53ef\u4ee5\u7528Attention\u66ff\u4ee3\u3002\u4f5c\u8005\u8fd8\u505a\u4e86\u66f4\u591a\u7684\u5176\u4ed6\u5b9e\u9a8c\uff0c\u8bc1\u660eattention\u66ff\u4ee3CNN\u662f\u5927\u6709\u53ef\u4e3a\u7684\u3002 On The Relationship Between Self-Attention and Convolution Layers pdf code \u672c\u6587\u8fd8\u6709\u4e00\u4e2a \u5b98\u65b9\u7f51\u7ad9 \u4ee5\u53ca \u5b98\u65b9\u82f1\u6587\u535a\u5ba2 \u7406\u8bba\u7ed3\u8bba\u662f\u5c40\u90e8Attention\u662fCNN\u7684\u6269\u5c55\uff0c\u5177\u4f53implementation\u6709\u533a\u522b\u3002","title":"Summary of Self Attention / Transformer in Vision System (Last update 2020-01-15)"},{"location":"other_categories/Summaries/SelfAttentionandCNN/#summary-of-self-attention-transformer-in-vision-system-last-update-2020-01-15","text":"\u8fd9\u662f\u4e00\u4efd\u63cf\u8ff0\u6570\u7bc7\u5173\u4e8e\u5728CNN\u7cfb\u7edf\u4e2d\u4f7f\u7528self-attention\u7684\u5c0f\u7edf\u8ba1. \u5bf9\u4e8e\u5728NLP\u53d6\u5f97\u5f88\u597d\u8868\u73b0\u7684self-attention\u673a\u5236\uff0c\u672c\u7f51\u7ad9\u5728\u8bba\u6587 Attention is all you need \u6709\u8be6\u7ec6\u7684\u4ecb\u7ecd\u3002 2019\u5e74\u4e0a\u534a\u5e74\uff0cGoogle \u63d0\u51fa\u4e86 Attention Augmented Convolution , \u8fd9\u662f\u4e00\u4e2a\u7c7b\u4f3c Non-local \u6a21\u5757\u7684\u601d\u8def\uff0c\u501f\u7528self-attention\u7684\u673a\u5236\u52a0\u4e0apositional-encoding\uff0c\u8bbe\u8ba1\u51fa\u4e00\u4e2a\u63d0\u4f9b\u5168\u5c40attention\u7684\u6a21\u5757\uff0c\u8fd9\u4e2a\u6a21\u5757\u7684\u7f3a\u70b9\u5728\u4e8e\u5728\u56fe\u7247\u5f88\u5927\u7684\u65f6\u5019\u4f1a\u9700\u8981\u4e00\u4e2a\u5f88\u5927\u7684\u77e9\u9635\u4e58\u6cd5\uff0c\u6240\u4ee5\u8fd9\u4e2a\u6a21\u5757\u5fc5\u987b\u53ea\u80fd\u5728\u591a\u6b21\u4e0b\u91c7\u6837\u540e\u4f7f\u7528\uff0c\u4e14\u8fd8\u9700\u8981\u6ce8\u91cd\u663e\u5b58\u7ba1\u7406\uff0c\u53ef\u4ee5\u7406\u89e3\u4e3a\u662f\u4e00\u4e2a\u96be\u4ee5scale up\u7684\u65b9\u6848\u3002 \u672c\u6587\u63a5\u4e0b\u6765\u4f1a\u4ecb\u7ecd\u4e24\u7bc7paper\uff0c\u4e00\u7bc7paper\u63d0\u51fa\u4e86\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u56fe\u7247\u5c40\u90e8attention\u7684\u6a21\u5757\uff0c\u7528\u7565\u5c11\u4e8e\u4f20\u7edfConv\u7684\u8fd0\u7b97\u4e0e\u53c2\u6570\uff0c\u5728imagenet\u548cCoco\u5206\u522b\u5f97\u5230\u4e86\u4e0e\u4f20\u7edfCNN\u51e0\u4e4e\u4e00\u81f4\u7684\u6027\u80fd\u3002\u53e6\u4e00\u7bc7\u9610\u8ff0\u4e86\u5c40\u90e8Attention\u4e0eConvolution\u7684\u5173\u7cfb\uff0c\u8868\u660eMulti-head \u5c40\u90e8Attention\u53ef\u4ee5\u5b9e\u73b0\u4f20\u7edfConvolution\u7684\u6027\u80fd\u3002","title":"Summary of Self Attention / Transformer in Vision System (Last update 2020-01-15)"},{"location":"other_categories/Summaries/SelfAttentionandCNN/#stand-alone-self-attention-in-vision-models","text":"pdf code y_{i j}=\\sum_{a, b \\in \\mathcal{N}_{k}(i, j)} \\operatorname{softmax}_{a b}\\left(q_{i j}^{\\top} k_{a b}+q_{i j}^{\\top} r_{a-i, b-j}\\right) v_{a b} \u8fd9\u4e2a\u6a21\u5757\u7684\u8bbe\u8ba1\u53ef\u4ee5\u76f4\u63a5CNN\uff0c\u540c\u65f6\u8fd0\u7b97\u91cf\u5e76\u6ca1\u6709\u663e\u7136\u63d0\u5347\uff0c\u6027\u80fd\u5219\u76f8\u8fd1\u3002 \u4f5c\u8005\u901a\u8fc7\u5b9e\u9a8c\u53d1\u73b0\u9664\u4e86\u7b2c\u4e00\u4e2aConv\u5efa\u8bae\u7528Convolution\uff0c\u6a21\u578b\u7684\u5176\u4f59\u5377\u79ef\u6a21\u5757\u5c31\u53ef\u4ee5\u7528Attention\u66ff\u4ee3\u3002\u4f5c\u8005\u8fd8\u505a\u4e86\u66f4\u591a\u7684\u5176\u4ed6\u5b9e\u9a8c\uff0c\u8bc1\u660eattention\u66ff\u4ee3CNN\u662f\u5927\u6709\u53ef\u4e3a\u7684\u3002","title":"Stand-Alone Self-Attention in Vision Models"},{"location":"other_categories/Summaries/SelfAttentionandCNN/#on-the-relationship-between-self-attention-and-convolution-layers","text":"pdf code \u672c\u6587\u8fd8\u6709\u4e00\u4e2a \u5b98\u65b9\u7f51\u7ad9 \u4ee5\u53ca \u5b98\u65b9\u82f1\u6587\u535a\u5ba2 \u7406\u8bba\u7ed3\u8bba\u662f\u5c40\u90e8Attention\u662fCNN\u7684\u6269\u5c55\uff0c\u5177\u4f53implementation\u6709\u533a\u522b\u3002","title":"On The Relationship Between Self-Attention and Convolution Layers"},{"location":"other_categories/Summaries/SummaryOfMono3DDetection_in2019/","text":"Monocular 3D Object Detection in Autonomous Driving \u2014 A Review \u8fd9\u662f\u4e00\u7bc7Medium\u4e0a\u7684\u4e00\u4e2a\u4f5c\u8005\u5bf92019\u5355\u76ee3D\u68c0\u6d4b\u7684\u4e00\u4e2a\u603b\u7ed3\uff0c \u539f\u6587\u8fde\u63a5 . \u5e76\u5e26\u6709\u4e00\u5f20\u5f88\u7cfb\u7edf\u7684 \u603b\u7ed3\u8868 \u4f5c\u8005\u5c063D\u68c0\u6d4b\u5212\u5206\u4e3a4\u7c7b: Representation transformation; (BEV transform or Pseudo-lidar) Keypoints and shape; Distance from Constraints; Direct 3D proposal;","title":"Monocular 3D Object Detection in Autonomous Driving \u2014 A Review"},{"location":"other_categories/Summaries/SummaryOfMono3DDetection_in2019/#monocular-3d-object-detection-in-autonomous-driving-a-review","text":"\u8fd9\u662f\u4e00\u7bc7Medium\u4e0a\u7684\u4e00\u4e2a\u4f5c\u8005\u5bf92019\u5355\u76ee3D\u68c0\u6d4b\u7684\u4e00\u4e2a\u603b\u7ed3\uff0c \u539f\u6587\u8fde\u63a5 . \u5e76\u5e26\u6709\u4e00\u5f20\u5f88\u7cfb\u7edf\u7684 \u603b\u7ed3\u8868 \u4f5c\u8005\u5c063D\u68c0\u6d4b\u5212\u5206\u4e3a4\u7c7b: Representation transformation; (BEV transform or Pseudo-lidar) Keypoints and shape; Distance from Constraints; Direct 3D proposal;","title":"Monocular 3D Object Detection in Autonomous Driving \u2014 A Review"},{"location":"other_categories/Summaries/SummaryOfSingleStageInstanceSeg/","text":"Summary of Single Stage Instance Segmentation \u8fd9\u7bc7\u6587\u7ae0\u4e3b\u8981\u662f\u6839\u636eMedium\u4e0a\u4e00\u4e2a\u535a\u4e3b\u7684 review . \u8fd9\u4e2areview\u5728\u5206\u7c7b\u4e0a\u5c06\u5355\u9636\u6bb5\u5b9e\u4f8b\u5206\u5272\u5206\u4e3a\u57fa\u4e8elocal mask\u4e0eglobal mask Local Mask local mask\u6307\u8f93\u51fa\u4e00\u4e2a\u4e2abounding box\uff0c\u5e76\u4e14\u5bf9\u5c40\u90e8instance\u7684contour\u6216\u8005mask\u8fdb\u884c\u7f16\u7801\u4e0e\u9884\u6d4b\u3002\u6587\u4e2d\u63d0\u5230\u4e86\u591a\u7bc7paper\uff0c\u5176\u4e2d TensorMask , PolarMask \u662f\u672c\u7f51\u7ad9\u5df2\u7ecf\u6709\u7b80\u4ecb\u7684paper.\u8fd9\u91cc\u8fdb\u884c\u4e00\u4e9b\u8865\u5145 Fourier Net pdf code \u8fd9\u7bc7paper\u4ee3\u7801\u4ee5\u53ca\u601d\u60f3\u4e0a\u57fa\u4e8ePolarMask,\u5bf9\u4e8e\u8fd9\u4e00\u5468\u5c04\u7ebf\u7684\u957f\u5ea6\uff0c\u6211\u4eec\u53ea\u9700\u8981\u9884\u6d4b\u5176\u5085\u91cc\u53f6\u53d8\u6362\u503c\u7684\u524d M \u9879\uff0c\u8fd9\u4e2a M \u51b3\u5b9a\u7f51\u7edc\u8bad\u7ec3\u7684\u8d85\u53c2\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5f97\u5230\u7684\u8f93\u51fa\u4e00\u822c\u6765\u8bf4\u6bd4PolarMask\u540c\u7b49\u53c2\u6570\u91cf\u7684\u7ed3\u679c\u66f4\u52a0\u7cbe\u7ec6\u3002\u4f46\u662f\u8fd9\u7bc7paper\u7684\u4f5c\u8005\u6ca1\u6709train\u51fa\u4e00\u4e2a\u4ee4\u4eba\u4fe1\u670d\u7684\u70b9\u6570\u3002 p_{n, i}=\\frac{1}{N} \\sum_{k=0}^{N-1} x_{k, i} e^{\\frac{j 2 \\pi k n}{N}} Global Mask global mask\u6307\u7f51\u7edc\u76f4\u63a5\u8f93\u51fa\u6574\u4e2a\u56fe\u5927\u5c0f\u7684mask\uff0c\u5e76\u540e\u671f\u8fdb\u884c\u6574\u5408\u6216\u8005\u7ec4\u5408\u4ee5\u5f62\u6210\u6bcf\u4e00\u4e2aobject\u7684mask\u3002\u6587\u4e2d\u63d0\u5230\u4e86\u591a\u7bc7paper\uff0c\u6700\u8fd1SOTA\u6c34\u5e73\u7684\u4e3b\u8981\u4e3a\u5176\u4e2d\u7684 YOLOACT , SOLO \uff0c\u672c\u7f51\u7ad9\u4e5f\u6709\u76f8\u5173\u7684\u4ecb\u7ecd\u3002","title":"Summary of Single Stage Instance Segmentation"},{"location":"other_categories/Summaries/SummaryOfSingleStageInstanceSeg/#summary-of-single-stage-instance-segmentation","text":"\u8fd9\u7bc7\u6587\u7ae0\u4e3b\u8981\u662f\u6839\u636eMedium\u4e0a\u4e00\u4e2a\u535a\u4e3b\u7684 review . \u8fd9\u4e2areview\u5728\u5206\u7c7b\u4e0a\u5c06\u5355\u9636\u6bb5\u5b9e\u4f8b\u5206\u5272\u5206\u4e3a\u57fa\u4e8elocal mask\u4e0eglobal mask","title":"Summary of Single Stage Instance Segmentation"},{"location":"other_categories/Summaries/SummaryOfSingleStageInstanceSeg/#local-mask","text":"local mask\u6307\u8f93\u51fa\u4e00\u4e2a\u4e2abounding box\uff0c\u5e76\u4e14\u5bf9\u5c40\u90e8instance\u7684contour\u6216\u8005mask\u8fdb\u884c\u7f16\u7801\u4e0e\u9884\u6d4b\u3002\u6587\u4e2d\u63d0\u5230\u4e86\u591a\u7bc7paper\uff0c\u5176\u4e2d TensorMask , PolarMask \u662f\u672c\u7f51\u7ad9\u5df2\u7ecf\u6709\u7b80\u4ecb\u7684paper.\u8fd9\u91cc\u8fdb\u884c\u4e00\u4e9b\u8865\u5145","title":"Local Mask"},{"location":"other_categories/Summaries/SummaryOfSingleStageInstanceSeg/#fourier-net","text":"pdf code \u8fd9\u7bc7paper\u4ee3\u7801\u4ee5\u53ca\u601d\u60f3\u4e0a\u57fa\u4e8ePolarMask,\u5bf9\u4e8e\u8fd9\u4e00\u5468\u5c04\u7ebf\u7684\u957f\u5ea6\uff0c\u6211\u4eec\u53ea\u9700\u8981\u9884\u6d4b\u5176\u5085\u91cc\u53f6\u53d8\u6362\u503c\u7684\u524d M \u9879\uff0c\u8fd9\u4e2a M \u51b3\u5b9a\u7f51\u7edc\u8bad\u7ec3\u7684\u8d85\u53c2\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5f97\u5230\u7684\u8f93\u51fa\u4e00\u822c\u6765\u8bf4\u6bd4PolarMask\u540c\u7b49\u53c2\u6570\u91cf\u7684\u7ed3\u679c\u66f4\u52a0\u7cbe\u7ec6\u3002\u4f46\u662f\u8fd9\u7bc7paper\u7684\u4f5c\u8005\u6ca1\u6709train\u51fa\u4e00\u4e2a\u4ee4\u4eba\u4fe1\u670d\u7684\u70b9\u6570\u3002 p_{n, i}=\\frac{1}{N} \\sum_{k=0}^{N-1} x_{k, i} e^{\\frac{j 2 \\pi k n}{N}}","title":"Fourier Net"},{"location":"other_categories/Summaries/SummaryOfSingleStageInstanceSeg/#global-mask","text":"global mask\u6307\u7f51\u7edc\u76f4\u63a5\u8f93\u51fa\u6574\u4e2a\u56fe\u5927\u5c0f\u7684mask\uff0c\u5e76\u540e\u671f\u8fdb\u884c\u6574\u5408\u6216\u8005\u7ec4\u5408\u4ee5\u5f62\u6210\u6bcf\u4e00\u4e2aobject\u7684mask\u3002\u6587\u4e2d\u63d0\u5230\u4e86\u591a\u7bc7paper\uff0c\u6700\u8fd1SOTA\u6c34\u5e73\u7684\u4e3b\u8981\u4e3a\u5176\u4e2d\u7684 YOLOACT , SOLO \uff0c\u672c\u7f51\u7ad9\u4e5f\u6709\u76f8\u5173\u7684\u4ecb\u7ecd\u3002","title":"Global Mask"},{"location":"other_categories/Summaries/Summary_of_ICRA_2020/","text":"Summaries for sevearl ICRA 2020 papers \u672c\u5c4aICRA\u6709\u6570\u7bc7paper\u5728\u4e4b\u524d\u5df2\u7ecf\u6709review, \"A General Framework for Uncertainty Estimation in Deep Learning\" , \"FADNet: A Fast and Accurate Network for Disparity Estimation\" \"Object-Centric Stereo Matching for 3D Object Detection\" \u8fd9\u91cc\u7ee7\u7eed\u641c\u96c6\u591a\u7bc7\u6709\u8da3\u7684ICRA 2020 papers. Event-Based Angular Velocity Regression with Spiking Networks pdf code \u8fd9\u7bc7paper\u5229\u7528\u4e862018NeurIPS\u7684\u4e00\u7bc7\u5173\u4e8e spiking neural network \u7684\u6587\u7ae0\uff0c\u8fd9\u7bc7\u6587\u7ae0\u63d0\u51fa\u4e86SNN\u7684\u4e00\u4e2a\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5e76\u4e14\u4ecb\u7ecd\u4e86\u76f8\u5173\u7684\u6982\u5ff5\uff0c\u540c\u65f6\u7ed9\u51fa\u4e86 pytorch\u5e93/cuda \u4ee3\u7801\u7528\u4e8e\u52a0\u901f\u8fd0\u7b97. \u672c\u6587\u5229\u7528\u4e86NIPS paper\u7684\u8fd9\u4e2a\u5e93\uff0c\u8f93\u5165\u4e3a\u5e8f\u5217\u7684image-like event sequence,\u8f93\u51fa\u4e3a\u5e8f\u5217\u7684\u4e09\u8f74\u89d2\u901f\u5ea6\uff0c \u4eff\u771f\u6570\u636e\u6765\u81ea\u4e8e esim\u4eff\u771f\u5668 Pedestrian Planar LiDAR Pose (PPLP) Network for Oriented Pedestrian Detection Based on Planar LiDAR and Monocular Images pdf code CNN Based Road User Detection Using the 3D Radar Cube pdf code \u8fd9\u7bc7paper\u8c03\u7528\u5e95\u5c42\u7684radar\u6570\u636e\uff0c\u540c\u65f6\u4f7f\u7528\u5e95\u5c42\u7684radar cube\u6570\u636e\u4ee5\u53caradar target\u6570\u636e\uff0c\u5728\u7eafradar\u7684\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4e86 3D object detection. PST900: RGB-Thermal Calibration, Dataset and Segmentation Network pdf code \u672c\u6587\u63d0\u51fa\u7684\u4e3b\u8981\u8d21\u732e\u662f RGB-Thermal\u7684\u6821\u6b63(\u5229\u7528\u4e00\u4e2a\u53cc\u76eeRGB\u76f8\u673a\u5f97\u5230\u6df1\u5ea6\u4f30\u8ba1\uff0c\u518d\u56de\u6295\u5230Thermal\u4e0a)\u4ee5\u53ca\u4e00\u4e2a\u8bed\u4e49\u5206\u5272\u6570\u636e\u96c6\uff0c Instance Segmentation of LiDAR Point Clouds pdf code SegVoxelNet: Exploring Semantic Context and Depth-aware Features for 3D Vehicle Detection from Point Cloud pdf \u8fd9\u7bc7paper\u6765\u81ea\u4e8e D4LCN \u7684\u7ec4\u3002 \u8bed\u4e49\u5206\u5272BEV Ground Truth\u6765\u81ea\u4e8ebbox\u76f4\u63a5\u7684\u6295\u5f71\u3002Depth Aware\u7684\u7406\u89e3\u662f\u8fd1\u5904\u3001\u8fdc\u5904\u7684\u70b9\u4e91\u5206\u5e03\u5bc6\u5ea6\u5dee\u8ddd\u8f83\u5927\uff0c\u5c06BEV\u6cbf\u7740\u6df1\u5ea6\u8f74\u5206\u6210\u5e26\u6709\u91cd\u53e0\u90e8\u5206\u7684\u51e0\u4e2a\u90e8\u5206\uff0c\u6267\u884c\u4e0d\u540c\u7684\u5377\u79ef\u64cd\u4f5c\u3002\u5728KITTI\u4e0a\u7684\u6027\u80fd\u4e0ePointPillars\u548cPointRCNN\u76f8\u8fd1\u3002 Radar as a Teacher: Weakly Supervised Vehicle Detection using Radar Labels pdf \u8fd9\u7bc7paper\u5efa\u8bae\u53c2\u8003\u6b64\u524dNIPS\u7684 co-teaching\u7684paper Self-supervised linear motion deblurring pdf code \u8fd9\u7bc7paper\u51fa\u81eaKITTI\u6570\u636e\u96c6\u7684\u5b9e\u9a8c\u5ba4\u3002\u8fd9\u7bc7paper\u7684\u4e3b\u8981idea\u662f\u4f7f\u7528\u4e00\u4e2areblur module\uff0c\u5728\u7ebf\u6027\u8fd0\u52a8\u7684\u5047\u8bbe\u4e0b\uff0c\u5229\u7528\u5149\u6d41\u4e0eblurring\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5c06\u4e00\u4e2adeblurred\u7684module\u91cd\u65b0\u53d8\u4e3ablurred\uff0c\u8fd9\u6837\u5c31\u53ef\u4ee5\u5f62\u6210\u4e00\u4e2a\u81ea\u76d1\u7763\u7684\u4f53\u7cfb\u3002 \u672c\u6587\u4f7f\u7528\u73b0\u6210\u7684deblur\u4ee5\u53ca\u5149\u6d41\u7f51\u7edc\u7ed3\u6784\uff0c\u5229\u7528\u524d\u540e\u5e27\u7684consistence\u8bad\u7ec3\u5149\u6d41\uff0c\u540c\u65f6\u5bf9deblur\u7ed3\u679c\u63d0\u51fa\u9690\u6027\u7684\u8981\u6c42\u3002\u524d\u9762\u63d0\u5230\u7684\u81ea\u76d1\u7763\u7f51\u7edcloss\u53ef\u4ee5\u8bad\u7ec3deblur\u7f51\u7edc\uff0c\u540c\u65f6\u5bf9\u5149\u6d41\u7684\u8ba1\u7b97\u63d0\u51fa\u9690\u6027\u7684\u8981\u6c42\uff0c\u672c\u6587\u7684reblur\u662f\u4e00\u4e2a\u975e\u5b66\u4e60\u53ef\u5fae\u5206\u6a21\u5757\uff0c\u56e0\u800c\u6574\u4e2a\u7f51\u7edc\u53ef\u5fae\u5206\uff0c\u53ef\u4ee5\u7aef\u5230\u7aef\u81ea\u76d1\u7763\u5b66\u4e60\u3002 reblur\u6a21\u5757\u65b9\u7a0b: \\mathbf{B}(\\mathbf{x}) \\approx \\frac{1}{2 N+1} \\sum_{i=-N}^{N}\\left(\\mathcal{W}_{0 \\rightarrow i} \\circ \\mathbf{I}_{0}\\right)(\\mathbf{x}) \u5176\u4e2d \\mathcal{W} \u6307\u7684\u662f\u5c06\u539f\u56fe\u6839\u636e\u5149\u6d41\u8fdb\u884cwarping, Fast Panoptic Segmentation Network pdf Real-Time Semantic Stereo Matching pdf \u5728\u8bed\u4e49\u5206\u5272\u548c\u53cc\u76ee\u4e0a\u90fd\u6709\u4e0d\u9519\u7684\u70b9\u6570(\u4e00\u822c\u822c)\uff0c\u4e3b\u8981\u662f\u901f\u5ea6\u6bd4\u8f83\u5feb MultiDepth: Single-Image Depth Estimation via Multi-Task Regression and Classification pdf \u6df1\u5ea6\u9884\u6d4b\u95ee\u9898\u540c\u65f6\u8d70\u5206\u7c7b\u4e0e\u56de\u5f52\u3002 MPC-Net: A First Principles Guided Policy Search pdf code \u8fd9\u7bc7paper\u4f7f\u7528\u7c7b\u6a21\u4eff\u5b66\u4e60\uff0c\u5f97\u5230\u4e00\u4e2a\u5feb\u901f\u7684MPC approximator.\u672c\u6587\u5229\u7528\u6700\u4f18\u63a7\u5236\u89e3\u7684\u5fc5\u8981\u6761\u4ef6\uff0cHJB\u65b9\u7a0b\uff0c\u8981\u6c42\u4e00\u4e0b\u54c8\u5bc6\u987f\u91cf\u6700\u5c0f\u5316, \\begin{aligned} \\boldsymbol{u}^{*}(t, \\boldsymbol{x}) &=\\arg \\min _{\\boldsymbol{u}} \\mathcal{H}(\\boldsymbol{x}, \\boldsymbol{u}, t) \\\\ \\mathcal{H}(\\boldsymbol{x}, \\boldsymbol{u}, t) &:=\\mathcal{L}(\\boldsymbol{x}, \\boldsymbol{u}, t)+\\partial_{\\boldsymbol{x}} V(t, \\boldsymbol{x}) \\boldsymbol{f}(\\boldsymbol{x}, \\boldsymbol{u}, t) \\end{aligned} \u672c\u6587\u63d0\u51fa\u4f7f\u7528SLQ(Sequential-Linear-Quadritic)\u6700\u4f18\u5316\u65b9\u6cd5\u8fdb\u884c\u6700\u4f18\u5316\u6c42\u89e3(\u8fd9\u4e2a\u7b97\u6cd5\u7c7b\u4f3c\u4e8e\u8fde\u7eed\u65f6\u95f4\u7684\u8fed\u4ee3LQR),\u901a\u8fc7\u8fd9\u4e2a\u6c42\u89e3\u5668\u53ef\u4ee5\u5f97\u5230MPC teacher\u7684\u63a7\u5236\u547d\u4ee4\uff0c\u4ee5\u53cavalue function\u5173\u4e8ex\u7684\u6c42\u5bfc \\partial_{\\boldsymbol{x}} V(t, \\boldsymbol{x}) \u5b66\u4e60\u65b9\u6cd5: 1. \u5728\u6bcf\u4e00\u6b21\u8fed\u4ee3\u4e2d\uff0c\u4f7f\u7528MPC\u4ee5\u53ca\u7f51\u7edc\u7684\u878d\u5408\u4fe1\u53f7\uff0c\u5bf9\u7cfb\u7edf\u5b8c\u6210\u4e00\u4e2a\u5e8f\u5217\u7684\u4eff\u771f\uff0c\u878d\u5408\u6bd4\u91cd\u968f\u7740\u8bad\u7ec3\u7684\u8fdb\u884c\u9010\u6e10\u7531\u7f51\u7edc\u8f93\u51fa\u4e3b\u5bfc\uff0c\u5728buffer\u4e2d\u5b58\u4e0b\u65f6\u95f4\u6233\uff0cstate\uff0cvalue\u51fd\u6570\u5bf9\u4e8estate\u7684\u5bfc\u6570\u77e2\u91cf,\u7f51\u7edc\u6700\u4f18\u8f93\u51fa\u503c\u7b49\u7ed3\u679c\u3002 2. \u4ecebuffer\u4e2d\u8fdb\u884c\u91c7\u6837\uff0c\u4f7f\u7528\u5b58\u50a8\u4e2d\u7684state, dvdx, t\u4ee5\u53ca\u7f51\u7edc\u8f93\u51fa\u7684u\uff0c\u8ba1\u7b97\u54c8\u5bc6\u987f\u91cf\u3002\u5bf9\u4e8e\u672c\u6587\u5b9e\u9a8c\u4e2d\u7ed9\u51fa\u4e8c\u6b21\u635f\u5931\u51fd\u6570\uff0c \\mathcal{L} \u4e0e u \u76f8\u5173\u7684\u53ea\u6709regularization\u9879 uRu^T ,dvdx\u4e3a\u5e38\u77e2\u91cf\uff0c f(x, u, t) \u4e3a\u6a21\u578b\u7684 \\dot x ,\u4e0e\u7cfb\u7edf\u6a21\u578b\u6709\u5173\uff0c\u4e5f\u5c31\u4f1a\u4e0e u \u6709\u5173\u3002 3. \u628a\u54c8\u5bc6\u987f\u91cf\u7406\u89e3\u4e3a\u635f\u5931\u51fd\u6570\uff0c\u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u7f51\u7edc\u53c2\u6570\uff0c MapLite: Autonomous Intersection Navigation Without a Detailed Prior Map pdf \u8fd9\u7bc7paper\u63d0\u51fa\u4e86\u4e00\u4e2a\u7cfb\u7edf\uff0c\u4ec5\u5229\u7528\u62d3\u6251\u5730\u56fe\u5b8c\u6210\u65e0\u4eba\u8f66\u7684\u5b9a\u4f4d\u4e0e\u5bfc\u822a\u4efb\u52a1\u3002\u70b9\u4e91\u7684\u8def\u9762\u5206\u5272\u4f7f\u7528\u7684\u505a\u6cd5\u662f\u5bf9\u6bcf\u4e00\u4e2a\u70b9\u63d0\u53d6\u8bbe\u5b9a\u7684\u4e94\u4e2afeature\uff0c\u4f7f\u7528linear SVM\u5224\u65ad\u5b83\u662f\u5426\u5728\u5730\u9762\u4e0a\u3002\u5173\u952e\u5bf9\u4e8e\u62d3\u6251\u5730\u56fe\u7684\u5b9a\u4f4d\uff0c\u672c\u6587\u4f7f\u7528\u4f20\u7edf\u7684\u6982\u7387\u6ee4\u6ce2\u7b97\u6cd5,\u6709\u4e00\u5b9a\u5c40\u9650\u6027\uff0c\u4f46\u662f\u5728\u4e00\u5b9a\u8303\u56f4\u5185\u663e\u7136\u662f\u6709\u6548\u7684\u3002","title":"Summaries for sevearl ICRA 2020 papers"},{"location":"other_categories/Summaries/Summary_of_ICRA_2020/#summaries-for-sevearl-icra-2020-papers","text":"\u672c\u5c4aICRA\u6709\u6570\u7bc7paper\u5728\u4e4b\u524d\u5df2\u7ecf\u6709review, \"A General Framework for Uncertainty Estimation in Deep Learning\" , \"FADNet: A Fast and Accurate Network for Disparity Estimation\" \"Object-Centric Stereo Matching for 3D Object Detection\" \u8fd9\u91cc\u7ee7\u7eed\u641c\u96c6\u591a\u7bc7\u6709\u8da3\u7684ICRA 2020 papers.","title":"Summaries for sevearl ICRA 2020 papers"},{"location":"other_categories/Summaries/Summary_of_ICRA_2020/#event-based-angular-velocity-regression-with-spiking-networks","text":"pdf code \u8fd9\u7bc7paper\u5229\u7528\u4e862018NeurIPS\u7684\u4e00\u7bc7\u5173\u4e8e spiking neural network \u7684\u6587\u7ae0\uff0c\u8fd9\u7bc7\u6587\u7ae0\u63d0\u51fa\u4e86SNN\u7684\u4e00\u4e2a\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5e76\u4e14\u4ecb\u7ecd\u4e86\u76f8\u5173\u7684\u6982\u5ff5\uff0c\u540c\u65f6\u7ed9\u51fa\u4e86 pytorch\u5e93/cuda \u4ee3\u7801\u7528\u4e8e\u52a0\u901f\u8fd0\u7b97. \u672c\u6587\u5229\u7528\u4e86NIPS paper\u7684\u8fd9\u4e2a\u5e93\uff0c\u8f93\u5165\u4e3a\u5e8f\u5217\u7684image-like event sequence,\u8f93\u51fa\u4e3a\u5e8f\u5217\u7684\u4e09\u8f74\u89d2\u901f\u5ea6\uff0c \u4eff\u771f\u6570\u636e\u6765\u81ea\u4e8e esim\u4eff\u771f\u5668","title":"Event-Based Angular Velocity Regression with Spiking Networks"},{"location":"other_categories/Summaries/Summary_of_ICRA_2020/#pedestrian-planar-lidar-pose-pplp-network-for-oriented-pedestrian-detection-based-on-planar-lidar-and-monocular-images","text":"pdf code","title":"Pedestrian Planar LiDAR Pose (PPLP) Network for Oriented Pedestrian Detection Based on Planar LiDAR and Monocular Images"},{"location":"other_categories/Summaries/Summary_of_ICRA_2020/#cnn-based-road-user-detection-using-the-3d-radar-cube","text":"pdf code \u8fd9\u7bc7paper\u8c03\u7528\u5e95\u5c42\u7684radar\u6570\u636e\uff0c\u540c\u65f6\u4f7f\u7528\u5e95\u5c42\u7684radar cube\u6570\u636e\u4ee5\u53caradar target\u6570\u636e\uff0c\u5728\u7eafradar\u7684\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4e86 3D object detection.","title":"CNN Based Road User Detection Using the 3D Radar Cube"},{"location":"other_categories/Summaries/Summary_of_ICRA_2020/#pst900-rgb-thermal-calibration-dataset-and-segmentation-network","text":"pdf code \u672c\u6587\u63d0\u51fa\u7684\u4e3b\u8981\u8d21\u732e\u662f RGB-Thermal\u7684\u6821\u6b63(\u5229\u7528\u4e00\u4e2a\u53cc\u76eeRGB\u76f8\u673a\u5f97\u5230\u6df1\u5ea6\u4f30\u8ba1\uff0c\u518d\u56de\u6295\u5230Thermal\u4e0a)\u4ee5\u53ca\u4e00\u4e2a\u8bed\u4e49\u5206\u5272\u6570\u636e\u96c6\uff0c","title":"PST900: RGB-Thermal Calibration, Dataset and Segmentation Network"},{"location":"other_categories/Summaries/Summary_of_ICRA_2020/#instance-segmentation-of-lidar-point-clouds","text":"pdf code","title":"Instance Segmentation of LiDAR Point Clouds"},{"location":"other_categories/Summaries/Summary_of_ICRA_2020/#segvoxelnet-exploring-semantic-context-and-depth-aware-features-for-3d-vehicle-detection-from-point-cloud","text":"pdf \u8fd9\u7bc7paper\u6765\u81ea\u4e8e D4LCN \u7684\u7ec4\u3002 \u8bed\u4e49\u5206\u5272BEV Ground Truth\u6765\u81ea\u4e8ebbox\u76f4\u63a5\u7684\u6295\u5f71\u3002Depth Aware\u7684\u7406\u89e3\u662f\u8fd1\u5904\u3001\u8fdc\u5904\u7684\u70b9\u4e91\u5206\u5e03\u5bc6\u5ea6\u5dee\u8ddd\u8f83\u5927\uff0c\u5c06BEV\u6cbf\u7740\u6df1\u5ea6\u8f74\u5206\u6210\u5e26\u6709\u91cd\u53e0\u90e8\u5206\u7684\u51e0\u4e2a\u90e8\u5206\uff0c\u6267\u884c\u4e0d\u540c\u7684\u5377\u79ef\u64cd\u4f5c\u3002\u5728KITTI\u4e0a\u7684\u6027\u80fd\u4e0ePointPillars\u548cPointRCNN\u76f8\u8fd1\u3002","title":"SegVoxelNet: Exploring Semantic Context and Depth-aware Features for 3D Vehicle Detection from Point Cloud"},{"location":"other_categories/Summaries/Summary_of_ICRA_2020/#radar-as-a-teacher-weakly-supervised-vehicle-detection-using-radar-labels","text":"pdf \u8fd9\u7bc7paper\u5efa\u8bae\u53c2\u8003\u6b64\u524dNIPS\u7684 co-teaching\u7684paper","title":"Radar as a Teacher: Weakly Supervised Vehicle Detection using Radar Labels"},{"location":"other_categories/Summaries/Summary_of_ICRA_2020/#self-supervised-linear-motion-deblurring","text":"pdf code \u8fd9\u7bc7paper\u51fa\u81eaKITTI\u6570\u636e\u96c6\u7684\u5b9e\u9a8c\u5ba4\u3002\u8fd9\u7bc7paper\u7684\u4e3b\u8981idea\u662f\u4f7f\u7528\u4e00\u4e2areblur module\uff0c\u5728\u7ebf\u6027\u8fd0\u52a8\u7684\u5047\u8bbe\u4e0b\uff0c\u5229\u7528\u5149\u6d41\u4e0eblurring\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5c06\u4e00\u4e2adeblurred\u7684module\u91cd\u65b0\u53d8\u4e3ablurred\uff0c\u8fd9\u6837\u5c31\u53ef\u4ee5\u5f62\u6210\u4e00\u4e2a\u81ea\u76d1\u7763\u7684\u4f53\u7cfb\u3002 \u672c\u6587\u4f7f\u7528\u73b0\u6210\u7684deblur\u4ee5\u53ca\u5149\u6d41\u7f51\u7edc\u7ed3\u6784\uff0c\u5229\u7528\u524d\u540e\u5e27\u7684consistence\u8bad\u7ec3\u5149\u6d41\uff0c\u540c\u65f6\u5bf9deblur\u7ed3\u679c\u63d0\u51fa\u9690\u6027\u7684\u8981\u6c42\u3002\u524d\u9762\u63d0\u5230\u7684\u81ea\u76d1\u7763\u7f51\u7edcloss\u53ef\u4ee5\u8bad\u7ec3deblur\u7f51\u7edc\uff0c\u540c\u65f6\u5bf9\u5149\u6d41\u7684\u8ba1\u7b97\u63d0\u51fa\u9690\u6027\u7684\u8981\u6c42\uff0c\u672c\u6587\u7684reblur\u662f\u4e00\u4e2a\u975e\u5b66\u4e60\u53ef\u5fae\u5206\u6a21\u5757\uff0c\u56e0\u800c\u6574\u4e2a\u7f51\u7edc\u53ef\u5fae\u5206\uff0c\u53ef\u4ee5\u7aef\u5230\u7aef\u81ea\u76d1\u7763\u5b66\u4e60\u3002 reblur\u6a21\u5757\u65b9\u7a0b: \\mathbf{B}(\\mathbf{x}) \\approx \\frac{1}{2 N+1} \\sum_{i=-N}^{N}\\left(\\mathcal{W}_{0 \\rightarrow i} \\circ \\mathbf{I}_{0}\\right)(\\mathbf{x}) \u5176\u4e2d \\mathcal{W} \u6307\u7684\u662f\u5c06\u539f\u56fe\u6839\u636e\u5149\u6d41\u8fdb\u884cwarping,","title":"Self-supervised linear motion deblurring"},{"location":"other_categories/Summaries/Summary_of_ICRA_2020/#fast-panoptic-segmentation-network","text":"pdf","title":"Fast Panoptic Segmentation Network"},{"location":"other_categories/Summaries/Summary_of_ICRA_2020/#real-time-semantic-stereo-matching","text":"pdf \u5728\u8bed\u4e49\u5206\u5272\u548c\u53cc\u76ee\u4e0a\u90fd\u6709\u4e0d\u9519\u7684\u70b9\u6570(\u4e00\u822c\u822c)\uff0c\u4e3b\u8981\u662f\u901f\u5ea6\u6bd4\u8f83\u5feb","title":"Real-Time Semantic Stereo Matching"},{"location":"other_categories/Summaries/Summary_of_ICRA_2020/#multidepth-single-image-depth-estimation-via-multi-task-regression-and-classification","text":"pdf \u6df1\u5ea6\u9884\u6d4b\u95ee\u9898\u540c\u65f6\u8d70\u5206\u7c7b\u4e0e\u56de\u5f52\u3002","title":"MultiDepth: Single-Image Depth Estimation via Multi-Task Regression and Classification"},{"location":"other_categories/Summaries/Summary_of_ICRA_2020/#mpc-net-a-first-principles-guided-policy-search","text":"pdf code \u8fd9\u7bc7paper\u4f7f\u7528\u7c7b\u6a21\u4eff\u5b66\u4e60\uff0c\u5f97\u5230\u4e00\u4e2a\u5feb\u901f\u7684MPC approximator.\u672c\u6587\u5229\u7528\u6700\u4f18\u63a7\u5236\u89e3\u7684\u5fc5\u8981\u6761\u4ef6\uff0cHJB\u65b9\u7a0b\uff0c\u8981\u6c42\u4e00\u4e0b\u54c8\u5bc6\u987f\u91cf\u6700\u5c0f\u5316, \\begin{aligned} \\boldsymbol{u}^{*}(t, \\boldsymbol{x}) &=\\arg \\min _{\\boldsymbol{u}} \\mathcal{H}(\\boldsymbol{x}, \\boldsymbol{u}, t) \\\\ \\mathcal{H}(\\boldsymbol{x}, \\boldsymbol{u}, t) &:=\\mathcal{L}(\\boldsymbol{x}, \\boldsymbol{u}, t)+\\partial_{\\boldsymbol{x}} V(t, \\boldsymbol{x}) \\boldsymbol{f}(\\boldsymbol{x}, \\boldsymbol{u}, t) \\end{aligned} \u672c\u6587\u63d0\u51fa\u4f7f\u7528SLQ(Sequential-Linear-Quadritic)\u6700\u4f18\u5316\u65b9\u6cd5\u8fdb\u884c\u6700\u4f18\u5316\u6c42\u89e3(\u8fd9\u4e2a\u7b97\u6cd5\u7c7b\u4f3c\u4e8e\u8fde\u7eed\u65f6\u95f4\u7684\u8fed\u4ee3LQR),\u901a\u8fc7\u8fd9\u4e2a\u6c42\u89e3\u5668\u53ef\u4ee5\u5f97\u5230MPC teacher\u7684\u63a7\u5236\u547d\u4ee4\uff0c\u4ee5\u53cavalue function\u5173\u4e8ex\u7684\u6c42\u5bfc \\partial_{\\boldsymbol{x}} V(t, \\boldsymbol{x}) \u5b66\u4e60\u65b9\u6cd5: 1. \u5728\u6bcf\u4e00\u6b21\u8fed\u4ee3\u4e2d\uff0c\u4f7f\u7528MPC\u4ee5\u53ca\u7f51\u7edc\u7684\u878d\u5408\u4fe1\u53f7\uff0c\u5bf9\u7cfb\u7edf\u5b8c\u6210\u4e00\u4e2a\u5e8f\u5217\u7684\u4eff\u771f\uff0c\u878d\u5408\u6bd4\u91cd\u968f\u7740\u8bad\u7ec3\u7684\u8fdb\u884c\u9010\u6e10\u7531\u7f51\u7edc\u8f93\u51fa\u4e3b\u5bfc\uff0c\u5728buffer\u4e2d\u5b58\u4e0b\u65f6\u95f4\u6233\uff0cstate\uff0cvalue\u51fd\u6570\u5bf9\u4e8estate\u7684\u5bfc\u6570\u77e2\u91cf,\u7f51\u7edc\u6700\u4f18\u8f93\u51fa\u503c\u7b49\u7ed3\u679c\u3002 2. \u4ecebuffer\u4e2d\u8fdb\u884c\u91c7\u6837\uff0c\u4f7f\u7528\u5b58\u50a8\u4e2d\u7684state, dvdx, t\u4ee5\u53ca\u7f51\u7edc\u8f93\u51fa\u7684u\uff0c\u8ba1\u7b97\u54c8\u5bc6\u987f\u91cf\u3002\u5bf9\u4e8e\u672c\u6587\u5b9e\u9a8c\u4e2d\u7ed9\u51fa\u4e8c\u6b21\u635f\u5931\u51fd\u6570\uff0c \\mathcal{L} \u4e0e u \u76f8\u5173\u7684\u53ea\u6709regularization\u9879 uRu^T ,dvdx\u4e3a\u5e38\u77e2\u91cf\uff0c f(x, u, t) \u4e3a\u6a21\u578b\u7684 \\dot x ,\u4e0e\u7cfb\u7edf\u6a21\u578b\u6709\u5173\uff0c\u4e5f\u5c31\u4f1a\u4e0e u \u6709\u5173\u3002 3. \u628a\u54c8\u5bc6\u987f\u91cf\u7406\u89e3\u4e3a\u635f\u5931\u51fd\u6570\uff0c\u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u7f51\u7edc\u53c2\u6570\uff0c","title":"MPC-Net: A First Principles Guided Policy Search"},{"location":"other_categories/Summaries/Summary_of_ICRA_2020/#maplite-autonomous-intersection-navigation-without-a-detailed-prior-map","text":"pdf \u8fd9\u7bc7paper\u63d0\u51fa\u4e86\u4e00\u4e2a\u7cfb\u7edf\uff0c\u4ec5\u5229\u7528\u62d3\u6251\u5730\u56fe\u5b8c\u6210\u65e0\u4eba\u8f66\u7684\u5b9a\u4f4d\u4e0e\u5bfc\u822a\u4efb\u52a1\u3002\u70b9\u4e91\u7684\u8def\u9762\u5206\u5272\u4f7f\u7528\u7684\u505a\u6cd5\u662f\u5bf9\u6bcf\u4e00\u4e2a\u70b9\u63d0\u53d6\u8bbe\u5b9a\u7684\u4e94\u4e2afeature\uff0c\u4f7f\u7528linear SVM\u5224\u65ad\u5b83\u662f\u5426\u5728\u5730\u9762\u4e0a\u3002\u5173\u952e\u5bf9\u4e8e\u62d3\u6251\u5730\u56fe\u7684\u5b9a\u4f4d\uff0c\u672c\u6587\u4f7f\u7528\u4f20\u7edf\u7684\u6982\u7387\u6ee4\u6ce2\u7b97\u6cd5,\u6709\u4e00\u5b9a\u5c40\u9650\u6027\uff0c\u4f46\u662f\u5728\u4e00\u5b9a\u8303\u56f4\u5185\u663e\u7136\u662f\u6709\u6548\u7684\u3002","title":"MapLite: Autonomous Intersection Navigation Without a Detailed Prior Map"},{"location":"other_categories/Summaries/Summary_of_SegLoss/","text":"Segmentation Loss Odyssey \u8fd9\u7bc7paper\u662f\u4e00\u4e2a\u6781\u4e3a\u7b80\u77ed\u7684\u5bf9\u4e8e\u8bed\u4e49\u5206\u5272Loss\u7684review. \u5f00\u6e90\u7684\u4ee3\u7801\u91cc\u9762\u7528pytorch\u7b80\u8981\u5730\u5b9e\u73b0\u4e86\u672c\u6587\u63d0\u5230\u7684\u6240\u6709loss\u51fd\u6570\u3002\u6587\u7ae0\u6beb\u4e0d\u62d6\u6ce5\u5e26\u6c34\uff0c\u8fd1\u4e4e\u4e8e\u7b14\u8bb0\u5c0f\u6284\u3002\u5176ReadME\u662f\u4e00\u4e2a\u5f88\u597d\u7684reference\u5e73\u53f0\u3002 \u539f\u6587README Date First Author Title Conference/Journal 202004 J. H. Moltz Contour Dice coefficient (CDC) Loss: Learning a Loss Function for Segmentation: A Feasibility Study ISBI 202003 Suprosanna Shit clDice -- a Topology-Preserving Loss Function for Tubular Structure Segmentation (pytorch) arXiv 202002 TBD Uncertainty-weighted Loss: Function for Medical Image Segmentation using Deep Convolutional Neural Network (paper) MIDL 2020 201912 Yuan Xue Shape-Aware Organ Segmentation by Predicting Signed Distance Maps (arxiv) AAAI 2020 201912 Xiaoling Hu Topology-Preserving Deep Image Segmentation (paper) NeurIPS 201912 JohannesC.Paetzold clDice-a Novel Connectivity-Preserving Loss Function for Vessel Segmentation (paper) MedNeurIPS2019 201910 Shuai Zhao Region Mutual Information Loss for Semantic Segmentation (paper) (pytorch) NeurIPS 2019 201910 Shuai Zhao Correlation Maximized Structural Similarity Loss for Semantic Segmentation (paper) arxiv 201908 Pierre-AntoineGanaye Removing Segmentation Inconsistencies with Semi-Supervised Non-Adjacency Constraint (paper) (official pytorch) Medical Image Analysis 201906 Xu Chen Learning Active Contour Models for Medical Image Segmentation (paper) (official-keras) CVPR 2019 20190422 Davood Karimi Reducing the Hausdorff Distance in Medical Image Segmentation with Convolutional Neural Networks (paper) TMI 201907 20190417 Francesco Caliva Distance Map Loss Penalty Term for Semantic Segmentation (paper) MIDL 2019 20190411 Su Yang Major Vessel Segmentation on X-ray Coronary Angiography using Deep Networks with a Novel Penalty Loss Function (paper) MIDL 2019 20190405 Boah Kim Multiphase Level-Set Loss for Semi-Supervised and Unsupervised Segmentation with Deep Learning (paper) arxiv 201901 Seyed Raein Hashemi Asymmetric Loss Functions and Deep Densely Connected Networks for Highly Imbalanced Medical Image Segmentation: Application to Multiple Sclerosis Lesion Detection (paper) IEEE Access 201812 Hoel Kervadec Boundary loss for highly unbalanced segmentation (paper) , (pytorch 1.0) MIDL 2019 201810 Nabila Abraham A Novel Focal Tversky loss function with improved Attention U-Net for lesion segmentation (paper) (keras) ISBI 2019 201809 Fabian Isensee CE+Dice: nnU-Net: Self-adapting Framework for U-Net-Based Medical Image Segmentation (paper) arxiv 20180831 Ken C. L. Wong 3D Segmentation with Exponential Logarithmic Loss for Highly Unbalanced Object Sizes (paper) MICCAI 2018 20180815 Wentao Zhu Dice+Focal: AnatomyNet: Deep Learning for Fast and Fully Automated Whole-volume Segmentation of Head and Neck Anatomy (arxiv) (pytorch) Medical Physics 201806 Javier Ribera Weighted Hausdorff Distance: Locating Objects Without Bounding Boxes (paper) , (pytorch) CVPR 2019 201805 Saeid Asgari Taghanaki Combo Loss: Handling Input and Output Imbalance in Multi-Organ Segmentation (arxiv) (keras) Computerized Medical Imaging and Graphics 201709 S M Masudur Rahman AL ARIF Shape-aware deep convolutional neural network for vertebrae segmentation (paper) MICCAI 2017 Workshop 201708 Tsung-Yi Lin Focal Loss for Dense Object Detection (paper) , (code) ICCV, TPAMI 20170711 Carole Sudre Generalised Dice overlap as a deep learning loss function for highly unbalanced segmentations (paper) DLMIA 2017 20170703 Lucas Fidon Generalised Wasserstein Dice Score for Imbalanced Multi-class Segmentation using Holistic Convolutional Networks (paper) MICCAI 2017 BrainLes 201705 Maxim Berman The Lov\u00e1sz-Softmax loss: A tractable surrogate for the optimization of the intersection-over-union measure in neural networks (paper) , (code) CVPR 2018 201701 Seyed Sadegh Mohseni Salehi Tversky loss function for image segmentation using 3D fully convolutional deep networks (paper) MICCAI 2017 MLMI 201612 Md Atiqur Rahman Optimizing Intersection-Over-Union in Deep Neural Networks for Image Segmentation (paper) 2016 International Symposium on Visual Computing 201606 Fausto Milletari \"Dice Loss\" V-net: Fully convolutional neural networks for volumetric medical image segmentation (paper) , (caffe code) International Conference on 3D Vision 201605 Zifeng Wu TopK loss Bridging Category-level and Instance-level Semantic Image Segmentation (paper) arxiv 201511 Tom Brosch \"Sensitivity-Specifity loss\" Deep Convolutional Encoder Networks for Multiple Sclerosis Lesion Segmentation (paper) (code) MICCAI 2015 201505 Olaf Ronneberger \"Weighted cross entropy\" U-Net: Convolutional Networks for Biomedical Image Segmentation (paper) MICCAI 2015 201309 Gabriela Csurka What is a good evaluation measure for semantic segmentation? (paper) BMVA 2013 Most of the corresponding tensorflow code can be found here . \u672c\u6587 citation @article{SegLossOdyssey, title={Segmentation Loss Odyssey}, author={Ma Jun}, journal={arXiv preprint arXiv:2005.13449}, year={2020} }","title":"Segmentation Loss Odyssey"},{"location":"other_categories/Summaries/Summary_of_SegLoss/#segmentation-loss-odyssey","text":"\u8fd9\u7bc7paper\u662f\u4e00\u4e2a\u6781\u4e3a\u7b80\u77ed\u7684\u5bf9\u4e8e\u8bed\u4e49\u5206\u5272Loss\u7684review. \u5f00\u6e90\u7684\u4ee3\u7801\u91cc\u9762\u7528pytorch\u7b80\u8981\u5730\u5b9e\u73b0\u4e86\u672c\u6587\u63d0\u5230\u7684\u6240\u6709loss\u51fd\u6570\u3002\u6587\u7ae0\u6beb\u4e0d\u62d6\u6ce5\u5e26\u6c34\uff0c\u8fd1\u4e4e\u4e8e\u7b14\u8bb0\u5c0f\u6284\u3002\u5176ReadME\u662f\u4e00\u4e2a\u5f88\u597d\u7684reference\u5e73\u53f0\u3002","title":"Segmentation Loss Odyssey"},{"location":"other_categories/Summaries/Summary_of_SegLoss/#readme","text":"Date First Author Title Conference/Journal 202004 J. H. Moltz Contour Dice coefficient (CDC) Loss: Learning a Loss Function for Segmentation: A Feasibility Study ISBI 202003 Suprosanna Shit clDice -- a Topology-Preserving Loss Function for Tubular Structure Segmentation (pytorch) arXiv 202002 TBD Uncertainty-weighted Loss: Function for Medical Image Segmentation using Deep Convolutional Neural Network (paper) MIDL 2020 201912 Yuan Xue Shape-Aware Organ Segmentation by Predicting Signed Distance Maps (arxiv) AAAI 2020 201912 Xiaoling Hu Topology-Preserving Deep Image Segmentation (paper) NeurIPS 201912 JohannesC.Paetzold clDice-a Novel Connectivity-Preserving Loss Function for Vessel Segmentation (paper) MedNeurIPS2019 201910 Shuai Zhao Region Mutual Information Loss for Semantic Segmentation (paper) (pytorch) NeurIPS 2019 201910 Shuai Zhao Correlation Maximized Structural Similarity Loss for Semantic Segmentation (paper) arxiv 201908 Pierre-AntoineGanaye Removing Segmentation Inconsistencies with Semi-Supervised Non-Adjacency Constraint (paper) (official pytorch) Medical Image Analysis 201906 Xu Chen Learning Active Contour Models for Medical Image Segmentation (paper) (official-keras) CVPR 2019 20190422 Davood Karimi Reducing the Hausdorff Distance in Medical Image Segmentation with Convolutional Neural Networks (paper) TMI 201907 20190417 Francesco Caliva Distance Map Loss Penalty Term for Semantic Segmentation (paper) MIDL 2019 20190411 Su Yang Major Vessel Segmentation on X-ray Coronary Angiography using Deep Networks with a Novel Penalty Loss Function (paper) MIDL 2019 20190405 Boah Kim Multiphase Level-Set Loss for Semi-Supervised and Unsupervised Segmentation with Deep Learning (paper) arxiv 201901 Seyed Raein Hashemi Asymmetric Loss Functions and Deep Densely Connected Networks for Highly Imbalanced Medical Image Segmentation: Application to Multiple Sclerosis Lesion Detection (paper) IEEE Access 201812 Hoel Kervadec Boundary loss for highly unbalanced segmentation (paper) , (pytorch 1.0) MIDL 2019 201810 Nabila Abraham A Novel Focal Tversky loss function with improved Attention U-Net for lesion segmentation (paper) (keras) ISBI 2019 201809 Fabian Isensee CE+Dice: nnU-Net: Self-adapting Framework for U-Net-Based Medical Image Segmentation (paper) arxiv 20180831 Ken C. L. Wong 3D Segmentation with Exponential Logarithmic Loss for Highly Unbalanced Object Sizes (paper) MICCAI 2018 20180815 Wentao Zhu Dice+Focal: AnatomyNet: Deep Learning for Fast and Fully Automated Whole-volume Segmentation of Head and Neck Anatomy (arxiv) (pytorch) Medical Physics 201806 Javier Ribera Weighted Hausdorff Distance: Locating Objects Without Bounding Boxes (paper) , (pytorch) CVPR 2019 201805 Saeid Asgari Taghanaki Combo Loss: Handling Input and Output Imbalance in Multi-Organ Segmentation (arxiv) (keras) Computerized Medical Imaging and Graphics 201709 S M Masudur Rahman AL ARIF Shape-aware deep convolutional neural network for vertebrae segmentation (paper) MICCAI 2017 Workshop 201708 Tsung-Yi Lin Focal Loss for Dense Object Detection (paper) , (code) ICCV, TPAMI 20170711 Carole Sudre Generalised Dice overlap as a deep learning loss function for highly unbalanced segmentations (paper) DLMIA 2017 20170703 Lucas Fidon Generalised Wasserstein Dice Score for Imbalanced Multi-class Segmentation using Holistic Convolutional Networks (paper) MICCAI 2017 BrainLes 201705 Maxim Berman The Lov\u00e1sz-Softmax loss: A tractable surrogate for the optimization of the intersection-over-union measure in neural networks (paper) , (code) CVPR 2018 201701 Seyed Sadegh Mohseni Salehi Tversky loss function for image segmentation using 3D fully convolutional deep networks (paper) MICCAI 2017 MLMI 201612 Md Atiqur Rahman Optimizing Intersection-Over-Union in Deep Neural Networks for Image Segmentation (paper) 2016 International Symposium on Visual Computing 201606 Fausto Milletari \"Dice Loss\" V-net: Fully convolutional neural networks for volumetric medical image segmentation (paper) , (caffe code) International Conference on 3D Vision 201605 Zifeng Wu TopK loss Bridging Category-level and Instance-level Semantic Image Segmentation (paper) arxiv 201511 Tom Brosch \"Sensitivity-Specifity loss\" Deep Convolutional Encoder Networks for Multiple Sclerosis Lesion Segmentation (paper) (code) MICCAI 2015 201505 Olaf Ronneberger \"Weighted cross entropy\" U-Net: Convolutional Networks for Biomedical Image Segmentation (paper) MICCAI 2015 201309 Gabriela Csurka What is a good evaluation measure for semantic segmentation? (paper) BMVA 2013 Most of the corresponding tensorflow code can be found here .","title":"\u539f\u6587README"},{"location":"other_categories/Summaries/Summary_of_SegLoss/#citation","text":"@article{SegLossOdyssey, title={Segmentation Loss Odyssey}, author={Ma Jun}, journal={arXiv preprint arXiv:2005.13449}, year={2020} }","title":"\u672c\u6587 citation"},{"location":"other_categories/Summaries/Summary_of_serveral_cvpr2020/","text":"Summaries for sevearl CVPR 2020 papers Bridging the Gap Between Anchor-based and Anchor-free Detection via Adaptive Training Sample Selection (ATSS) pdf code_head code_assigner/core \u8fd9\u7bc7paper\u505a\u4e86\u4e00\u4e2a\u76f8\u5f53\u7ec6\u81f4\u5bf9\u6bd4\u5b9e\u9a8c\u6765\u5206\u6790anchor based\u4e0eanchor free\u6a21\u5757\u7684\u533a\u522b\u7ed3\u679c\u3002\u53e6\u5916\u81ea\u5df1\u63d0\u51fa\u4e86\u66f4\u597d\u7684sampling\u65b9\u6cd5 \\rightarrow ATSS \u4f20\u7edf\u7684RetinaNet(32.5%)\u88abanchor free\u7684 FCOS (37.8%)\u6027\u80fd\u5927\u5e45\u8d85\u8d8a\uff0c\u662f\u4ec0\u4e48\u5f15\u8d77\u4e86\u8fd9\u4e9b\u5dee\u8ddd\u5462\uff0c\u662fanchor free\u4e0eanchor based\u672c\u8eab\u5417\uff1f\u4f5c\u8005\u5206\u6790\u6307\u51fa\uff0c\u5bf9\u4e8e\u4e00\u4e2a\u6bcf\u4e00\u4e2ascale\u53ea\u6709\u4e00\u4e2aanchor box\u7684 Retinanet\u6a21\u578b\u4e0eFCOS\u8fdb\u884c\u5bf9\u6bd4\uff0c\u8bad\u7ec3\u7ec6\u8282\u7684\u5dee\u522b:1. GroupNorm 2. GIoU Loss 3. Center point should be in the Box 4. Centerness branch (also helpful in NMS)5. additional trainable scalar, \u8fd9\u91cc\u9762\u6bd4\u8f83\u91cd\u8981\u7684\u662f(1),(2),(4). RetinaNet\u4e0eFCOS\u7684\u672c\u8d28\u533a\u522b\u6709\u4e8c\uff0c\u7b2c\u4e00\u4e2a\u662f\u5206\u7c7b\u65f6\u7ed9\u5b9a\u6b63\u6837\u672c\u7684\u65b9\u6cd5\u3002 \u7b2c\u4e8c\u4e2a\u662f\u56de\u5f52\u65f6\u6846\u5927\u5c0f\u7684\u56de\u5f52\u65b9\u6cd5.\u4f5c\u8005\u5728\u4e0b\u8868\u5b9e\u9a8c\u8bf4\u660e\u4e86\u6b63\u8d1f\u6837\u672c\u7684\u5206\u914d\u7b56\u7565\u624d\u662f\u5f71\u54cd\u70b9\u6570\u7684\u6700\u91cd\u8981\u56e0\u7d20\u3002 \u4f5c\u8005\u63d0\u51fa\u7684ATSS\u7b97\u6cd5. code_assigner/core Depth Sensing Beyond LiDAR Range pdf \u8fd9\u7bc7paper\u662f\u5c5e\u4e8e\u503c\u5f97\u7cbe\u8bfb\u7684\u6587\u7ae0\u4e4b\u4e00\u3002 Motivation LiDAR\u4e00\u76f4\u4ee5\u6765\u5b58\u5728\u7740\u65e0\u6cd5\u611f\u77e5\u8db3\u591f\u8fdc\u7684\u7269\u4f53\u7684\u95ee\u9898\uff0c\u5373\u4f7f\u7ebf\u6570\u5f88\u5927\uff0c\u6709\u6548\u7684\u8ddd\u79bb\u53ef\u80fd\u4e5f\u5c31\u53ea\u80fd\u53bb\u523080\u7c73\u3002\u800c\u8fd9\u4e2a\u5bf9\u4e8e\u4e2d\u901f\u884c\u9a76\u7684\u6c7d\u8f66\u6765\u8bf4\u4ec5\u4ec5\u662f\u51e0\u79d2\u5185\u7684\u91cc\u7a0b\uff0c\u56e0\u800c\u5f80\u5f80\u4e0d\u591f\u7528\u3002\u672c\u6587\u8981\u5b9e\u73b0\u8d85\u8fc7\u4e00\u767e\u7c73\u4e43\u81f3\u672c\u6587\u7ed9\u51fa\u7684\u8fd1300\u7c73\u8303\u56f4\u5185\u7684\u6df1\u5ea6\u4f30\u8ba1\uff0c\u4f7f\u7528\u4e86\u7279\u6b8a\u914d\u7f6e\u7684\u591a\u76ee\u6444\u50cf\u673a(\u4e09\u76ee)\u3002\u5bf9\u4e8e\u6444\u50cf\u673a\u53c2\u6570\u6765\u8bf4\uff0c\u5c31\u9700\u8981\u5927\u5206\u8fa8\u7387\uff0c\u5c0f\u611f\u53d7\u91ce\u7528\u4e8e\u4e13\u6ce8\u4e8e\u8fdc\u666f\uff0c\u4f46\u662f\u8fd9\u4e2a\u786c\u4ef6\u914d\u7f6e\u7684\u95ee\u9898\u5728\u4e8e\u5bf9\u5fae\u5c0f\u7684\u5916\u53c2\u6270\u52a8\u975e\u5e38\u654f\u611f\uff0c\u56e0\u800c\u9700\u8981\u9c81\u68d2\u7b97\u6cd5or\u5728\u7ebf\u8865\u507f(\u672c\u6587\u7684\u65b9\u6848)\u3002 \u786c\u4ef6\u914d\u7f6e \u4f5c\u8005\u6587\u4e2d\u4ee5\u53ca\u540e\u9762\u7684\u8ba1\u7b97\u540c\u65f6\u6307\u51fa\uff0c\u5de6\u53f3\u76ee\u7684\u8ddd\u79bb\u5e94\u8be5\u8db3\u591f\u8fdc\uff0c\u800c\u4e14\u524d\u540e\u76f8\u673a\u8ddd\u79bb\u4e5f\u5e94\u8be5\u5c3d\u53ef\u80fd\u8fdc\uff0c\u8fd9\u4e9b\u90fd\u4ec5\u4ec5\u88ab\u8f66\u8eab\u5927\u5c0f\u6240\u9650\u5236\u3002 \u7b97\u6cd5\u6d41\u7a0b \u7b2c\u4e00\u6b65\u8fdb\u884c\u7684\u662fretification,\u5f97\u5230\u4e24\u4e2a\u76f8\u673a\u4e4b\u95f4\u7684\u4e00\u4e2a\u76f8\u4e92\u8f6c\u6362\uff0c\u4f7f\u5f97Stereo matching\u7684epipolar line\u662f\u6c34\u5e73\u7684\u3002\u4f5c\u8005\u7b80\u5355\u5730\u8bc1\u660e\u4e86\uff0c\u5bf9\u4e8e\u5c0fFOV\u76f8\u673a\u4ee5\u53ca\u5c0f\u6270\u52a8\u6765\u8bf4\uff0c\u5173\u4e8ex/y\u8f74\u7684\u5fae\u5c0f\u65cb\u8f6c\u90fd\u8fd1\u4f3c\u7b49\u540c\u4e8e\u6574\u4e2a\u753b\u9762\u7684\u5e73\u79fb\u3002\u800c\u753b\u9762\u7684\u65cb\u8f6c\u672c\u8eab\u5c31\u662f\u4e00\u4e2aAffine transform.\u56e0\u800c\u5b9e\u9645\u4e0a\u53ef\u4ee5\u7528homography transform matrix(2x3)\uff0c\u5c31\u53ef\u4ee5\u5b8c\u6210\u5bf9\u539f\u6765\u56fe\u7247\u7684\u77eb\u6b63\u3002\u6574\u4e2a\u7b97\u6cd5\u7684\u601d\u8def\u5c31\u662f\u4f7f\u7528RANSAC\uff0c\u51b3\u5b9aH\u77e9\u9635\u5bf9\u5e94\u7684\u53c2\u6570\u3002\u8981\u6c42\u662f\u8ba9\u5c3d\u53ef\u80fd\u591a\u7684matched point\u90fd\u5728\u540c\u4e00\u4e2a\u6c34\u5e73\u7ebf\u4e0a\u3002\u53ef\u4ee5\u60f3\u8c61\u7684\u662f\uff0c\u8fd9\u6837\u7684retification\u65b9\u5f0f\u65e0\u6cd5\u51b3\u5b9a\u76f8\u673a\u5173\u4e8ey\u8f74\u7684\u65cb\u8f6c\uff0c\u56e0\u800cwarped\u540e\u7684\u56fe\u7247\u8ba1\u7b97\u5f97\u5230\u7684\u53cc\u76ee\u5339\u914ddisparity\u4e0e\u6b63\u786e\u7684\u503c\u4e4b\u95f4\u6709\u4e00\u4e2abias(\u53ef\u4ee5\u7406\u89e3\u4e3a\u5bf9\u65cb\u8f6c\u7684\u4f30\u8ba1\u7684bias/ambiguity) Disparity Estimation\u4f7f\u7528\u7684\u662f\u4e00\u4e2apretrained\u7684stereo matching\u7f51\u7edc. \\left\\langle\\mathbf{H}_{2,1: 3}^{(l)}, \\mathbf{x}^{(l)}\\right\\rangle-\\left\\langle\\mathbf{H}_{2,1: 3}^{(r)}, \\mathbf{x}^{(r)}\\right\\rangle=0 \u7b2c\u4e09\u6b65\u662f\u5229\u7528\u524d\u540e\u76f8\u673a\u6d88\u9664\u7b2c\u4e00\u90e8\u5206\u4ea7\u751f\u7684ambiguity.\u5bf9\u4e8e\u5de6\u76ee\u4e0a\u4efb\u610f\u4e24\u4e2a\u5177\u6709\u76f8\u540c\u6df1\u5ea6\u7684pixel x_1^{(l)}, x_2^{(l)} \uff0c\u8fd9\u4e24\u4e2a\u70b9\u57283D\u4e2d\uff0c\u76f8\u5bf9\u4e8e\u524d\u540e\u6444\u50cf\u673a\u7684 x , y \u5750\u6807\u7684\u5dee\u662f\u4e00\u81f4\u7684(\u8fd9\u91cc\u6307\u7684\u662f\u76f8\u673a\u53c2\u8003\u7cfb\u800c\u4e0d\u662f\u56fe\u7247\u53c2\u8003\u7cfb)\uff0c\u8fd9\u91cc\u5f15\u51fa\u4ee5\u4e0b\u63a8\u5bfc\u3002 \\begin{aligned} m_{l}=\\left\\|\\mathbf{x}_{1}^{(l)}-\\mathbf{x}_{2}^{(l)}\\right\\|&=\\frac{f}{z^{(l)}} \\cdot\\left\\|\\mathbf{X}_{1}^{(l)}-\\mathbf{X}_{2}^{(l)}\\right\\| \\\\ m_{b}&=\\frac{f}{z^{(b)}} \\cdot\\left\\|\\mathbf{X}_{1}^{(b)}-\\mathbf{X}_{2}^{(b)}\\right\\| \\\\ \\mathbf{X}_{1}^{(l)}-\\mathbf{X}_{2}^{(l)}&=\\mathbf{X}_{1}^{(b)}-\\mathbf{X}_{2}^{(b)}, z^{(b)}=z^{(l)}+C_{l b} \\\\ \\frac{m_{l}}{m_{b}}&=\\frac{z^{(l)}+C_{l b}}{z^{(l)}}\\\\ z=z^{(l)}&=\\frac{C_{l b}}{\\frac{m_{l}}{m_{b}}-1}\\\\ \\end{aligned} \u5bf9\u4e8e\u4e00\u7ec4\u7b26\u5408 m_l > m_b , m_l > \\delta , |d_1 - d_2| < \\eta \u7684\u70b9\uff0c\u7531\u5b83\u4eec\u7684\u6570\u503c\u53ef\u4ee5\u5f97\u5230\u7684\u5bf9disparity bias\u7684\u4f30\u8ba1\u4e3a: q=f \\cdot \\frac{C_{l r}}{C_{l b}} \\cdot\\left(\\frac{m_{l}}{m_{b}}-1\\right)-\\frac{d_{1}+d_{2}}{2} \u524d\u9762\u63d0\u5230\u7684\u8fd9\u4e09\u4e2a\u6761\u4ef6\u5206\u522b\u8868\u793a (1) \u8fd9\u4e2abatched\u662f\u5426\u4e8b\u5b9e\u4e0a\u771f\u5b9e;\u9760\u524d\u76f8\u673a\u770b\u5230\u7684\u4e24\u70b9\u8ddd\u79bb\u7406\u5e94\u66f4\u5927 (2) \u4e24\u4e2a\u70b9\u7684\u8ddd\u79bb\u5e94\u8be5\u8db3\u591f\u5927\uff0c\u6700\u597d\u4e0d\u8981\u8d34\u5728\u4e00\u8d77 (3) \u4e24\u4e2a\u50cf\u7d20\u4e4b\u95f4\u7684\u8ddd\u79bb\u51e0\u4e4e\u662f\u76f8\u7b49\u7684\u3002 \u4f5c\u8005\u540e\u9762\u7528\uff1a 1. \u7528\u4eff\u771f\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5f88\u5c0f\u7684\u8bef\u5dee\uff0c\u5728\u53cc\u76ee\u957f\u8ddd\u79bb\u5339\u914d\u4e2d\u5c31\u4f1a\u5f88\u5927\u7684\u4f7f\u6027\u80fd\u9000\u5316\u3002 2. \u4ed6\u4eec\u63d0\u51fa\u7684retification\u65b9\u6cd5\u4e0e\u6807\u51c68\u70b9\u6cd5\u5bf9\u6bd4\u5728\u8fd9\u4e2a\u573a\u666f\u4e0b\u6570\u503c\u66f4\u7a33\u5b9a\uff1b\u56e0\u4e3a\u4ed6\u4eec\u5229\u7528\u4e86\u8fd9\u4e2a\u573a\u666f\u4e0b\u7684\u5148\u9a8c\u77e5\u8bc6\u3002 3. \u5b9e\u9a8c\u8bf4\u660e\u4e86ambiguity removal\u7684\u8fc7\u7a0b\uff0c\u4ee5\u53ca\u6700\u540e\u8ba1\u7b97\u7684\u6709\u6548\u6027\u3002 RetinaTrack pdf \u7279\u70b9\uff0c\u4e0d\u540canchor\u5728\u66f4\u65e9\u671ffeatures\u5c31\u5f00\u59cb\u5206\u5f00\uff0c\u6bcf\u4e00\u4e2aanchor\u8f93\u51fa\u4e00\u4e2a256\u7ef4\u5ea6\u7684features. \u5bf9 \u5355\u4e00\u56fe\u7247 \u7528triplet loss \\mathcal{L}_{B H}(\\theta ; X)=\\sum_{j=1}^{A} \\text { SoftPlus }\\left(m+\\max _{p=1 \\rightarrow A \\atop t_{j}=t_{p}} D_{j p}-\\min _{\\ell=1 \\ldots A \\atop t_{j} \\neq t_{\\ell}} D_{j \\ell}\\right) \u6838\u5fc3\u601d\u8def\u5c31\u662f\u76f8\u540cinstance\u7684\u4e0d\u540canchor\u8f93\u51fa\u76f8\u4f3c\u7684embedding\uff0c\u4e0d\u540cinstance\u7684\u4e0d\u540canchor\u8f93\u51fa\u4e0d\u540c\u7684embedding\u3002\u672c\u6587\u7528\u57fa\u7840\u7684euclidean distance\u4f5c\u4e3aloss MUXConv: Information Multiplexing in Convolutional Neural Networks pdf code Structure Aware Single-stage 3D Object Detection from Point Cloud pdf code \u57fa\u4e8eMMdetection\u5f00\u53d1\u7684\u70b9\u4e913D \u68c0\u6d4b\uff0c\u6027\u80fd\u5f88\u9ad8\uff0c\u91cd\u70b9\u5728\u4e8e\u9644\u52a0task\u7684\u8bbe\u8ba1\u7684\uff0c\u80fd\u8ba9\u4e00\u4e2a\u63a5\u8fd1\u4e8eVoxelNet\u7684\u7ed3\u6784\u5f97\u5230\u5f88\u5927\u7684\u63d0\u5347 Camouflaged Object Detection pdf code \u672c\u95ee\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u95ee\u9898\u4ee5\u53ca\u65b0\u7684\u6570\u636e\u96c6\uff0c\u6709 \u4e2d\u6587paper . Lightweight Multi-View 3D Pose Estimation through Camera-Disentangled Representation pdf FTL\u5c42\u4e0d\u662f\u4e00\u4e2a\u5b66\u4e60\u5c42\uff0c\u7528\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42\uff0c\u5c062D\u9884\u6d4b\u7528\u65cb\u8f6c\u53d8\u6362\u8f6c\u6362\u5230\u4e0ecamera\u65b9\u4f4d\u65e0\u5173\u7684\u7ed3\u679c \\mathbf{y}=F_{T_{1}, \\ldots, T_{n}}[\\mathbf{x}]=\\left[\\begin{array}{ccc} F_{T_{1}} & & \\\\ & \\ddots & \\\\ & & F_{T_{n}} \\end{array}\\right] 3D \u4f4d\u7f6e\u4f30\u8ba1\u91c7\u7528\u7684\u662fSFM\u7684formulation d_{i} u_{i}=p_{i}^{1 T} \\mathbf{x}, d_{i} v_{i}=p_{i}^{2 T} \\mathbf{x}, d_{i}=p_{i}^{3 T} \\mathbf{x} \\begin{array}{l} \\left(u_{i} p_{i}^{3 T}-p_{i}^{1 T}\\right) \\mathbf{x}=0 \\\\ \\left(v_{i} p_{i}^{3 T}-p_{i}^{2 T}\\right) \\mathbf{x}=0 \\end{array} \u628a\u540c\u4e00\u4e2a\u5173\u8282\u6240\u6709\u70b9\u653e\u5728\u4e00\u8d77\uff0c A \\mathbf{x}=\\mathbf{0} ,\u539f\u7406\u4e0a\u6765\u8bf4\u9700\u8981\u4f7f\u7528SVD\u627e\u51fa\u6700\u5c0f\u7279\u5f81\u503c\u5bf9\u5e94\u7684\u7279\u5f81\u5411\u91cf\u3002\u4f5c\u8005\u6307\u51fa\u5982\u679c\u53ea\u9700\u8981\u6c42\u6700\u5c0f\u7279\u5f81\u503c\uff0c\u4e0d\u9700\u8981\u4f7f\u7528SVD\uff0c\u4f7f\u7528\u4ee5\u4e0b\u8fed\u4ee3\u7b97\u6cd5\u5373\u53ef Flow2Stereo: Effective Self-Supervised Learning of Optical Flow and Stereo Matching pdf What You See is What You Get: Exploiting Visibility for 3D Object Detection pdf \u672c\u6587\u4e3b\u8981\u9488\u5bf9\u7684\u5c31\u662fNuscene\u573a\u666f\u4e2d\u88ab\u906e\u6321\u6bd4\u8f83\u4e25\u91cd\u7684\u7269\u4f53\u3002\u901a\u8fc7\u7528\u70b9\u4e91\u5efa\u7acb\u7684occupancy map,\u7f51\u7edc\u53ef\u4ee5infer\u4ec0\u4e48\u5730\u65b9\u662f\u53ef\u80fd\u88ab\u906e\u6321\u800c\u53ef\u80fd\u6709\u7269\u4f53\u7684\u3002 \u672c\u6587\u6709\u4e00\u4e2a\u6bd4\u8f83\u597d\u7684 \u4e2d\u6587\u535a\u5ba2 ,\u63d0\u5230\u4e86\u672c\u6587\u51e0\u4e2a\u91cd\u8981\u7684\u6709\u8da3\u7684\u7ec6\u8282\uff0c\u7b2c\u4e00\u4e2a\u662f3D\u4e16\u754c\u7684Fast Voxel Traversal\u751f\u6210occupancy map;\u7b2c\u4e8c\u4e2a\u662f\u6570\u636e\u589e\u5f3a\uff0c\u91c7\u53d6\u7684\u65b9\u6cd5\u4e0eoccupancy map\u8fdb\u884c\u589e\u5f3a\uff1b\u7b2c\u4e09\u4e2a\u662fonline bayesian grid mapping. Instance Shadow Detection pdf code \u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u4efb\u52a1\uff0c\u65b0\u7684dataset\u4ee5\u53cabaseline\u65b9\u6cd5\u3002\u4efb\u52a1\u662f\u7269\u4f53\u4e0e\u5f71\u5b50\u7684instance segmentation\u4ee5\u53ca\u4e00\u4e00\u5bf9\u5e94\u3002 A Model-driven Deep Neural Network for Single Image Rain Removal pdf code Single Image Optical Flow Estimation with an Event Camera pdf \u672c\u6587\u662f\u57fa\u4e8eDAVIS\u7684event + gray scale\u8bbe\u8ba1\u7684\u7b97\u6cd5\uff0c\u4e00\u4e2a\u91cd\u8981\u7684idea\u662fevent\u4fe1\u606f\u672c\u8eab\u53ef\u4ee5\u76f4\u63a5\u5b58\u50a8\u5149\u6d41\u76f8\u5173\u7684\u4fe1\u606f\uff0c\u800c\u7070\u5ea6\u56fe\u7684\u52a8\u6001\u6a21\u7cca\u4e5f\u53ef\u4ee5\u7528\u4e8e\u6307\u5f15\u5149\u6d41\u4f30\u8ba1\u3002\u56e0\u6b64\u672c\u6587\u63d0\u51fa\u540c\u65f6\u4f30\u8ba1\u5149\u6d41\u573a\u4ee5\u53calatent image \\mathcal{L} . \u80fd\u91cf\u51fd\u6570\u8bbe\u8ba1\u4e3a \\min _{\\mathbf{L} . \\mathbf{u}} \\mu_{1} \\phi_{\\mathrm{eve}}(\\mathbf{L}, \\mathbf{u})+\\mu_{2} \\phi_{\\mathrm{blur}}(\\mathbf{L}, \\mathbf{u})+\\phi_{\\mathrm{flow}}(\\nabla \\mathbf{u})+\\phi_{\\mathrm{im}}(\\nabla \\mathbf{L}) \u9996\u5148\u662f\u8003\u8651\u4e86\u5149\u7167\u53d8\u5316\u7684\u5149\u6d41-\u5149\u7167\u4e00\u81f4\u6761\u4ef6 \\begin{aligned} \\phi_{\\mathrm{eve}}(\\mathbf{L}, \\mathbf{u})=\\sum_{\\mathbf{x} \\in \\Omega} \\| &\\mathbf{L}(\\mathbf{x}, f)(\\exp (c \\mathbf{E}(\\mathbf{x}, t))-1) \\\\ &+\\left[u_{\\mathbf{x}}, v_{\\mathbf{x}}\\right]^{\\mathrm{T}} \\nabla \\mathbf{L}(\\mathbf{x}, f) \\|_{1} \\end{aligned} \u6a21\u7cca: \u6a21\u7cca\u540e\u7684\u56fe\u7247 B \u53ef\u4ee5\u7531\u6a21\u7cca\u6838 K \u4ee5\u53calatent \u56fe\u7247 L \u5377\u79ef\u8868\u8fbe: \\begin{aligned} \\mathbf{B}(\\mathbf{x}) &=\\sum_{\\mathbf{y} \\in \\Omega} \\mathbf{k}(\\mathbf{y}) \\mathbf{L}(\\mathbf{x}-\\mathbf{y}) \\\\ &=\\sum_{\\mathbf{y} \\in \\Omega} \\mathbf{k}_{\\mathbf{u}^{\\prime}(\\mathbf{x})}(\\mathbf{y}) \\mathbf{L}(\\mathbf{x}-\\mathbf{y}) \\end{aligned} k_{\\mathbf{u}^{\\prime}(\\mathbf{x})}(\\mathbf{y})=\\left\\{\\begin{array}{ll} \\frac{1}{\\left|\\mathbf{u}^{\\prime}(\\mathbf{x})\\right|}, & \\text { if } \\mathbf{y}=\\alpha \\mathbf{u}^{\\prime}(\\mathbf{x}),|\\alpha| \\leq \\frac{1}{2} \\\\ \\mathbf{0}, & \\text { otherwise } \\end{array}\\right. \u6a21\u7cca\u6761\u4ef6: \\phi_{\\text {blur }}(\\mathbf{L}, \\mathbf{u})=\\sum_{\\mathbf{x}, \\mathbf{y} \\in \\Omega}\\left\\|\\mathbf{k}_{\\mathbf{u}^{\\prime}(\\mathbf{x})}(\\mathbf{y}) \\mathbf{L}(\\mathbf{x}-\\mathbf{y})-\\mathbf{B}(\\mathbf{x})\\right\\|^{2} \u540e\u4e24\u9879\u4e3a\u8fde\u7eed\u6027\u8981\u6c42\uff0c\u6587\u4e2d\u7684\u8bbe\u8ba1\u6bd4\u8f83\u7cbe\u7ec6\u3002 \u4f18\u5316\u65b9\u6cd5\u4e0a\u672c\u6587\u8fed\u4ee3\u8fdb\u884c\u5149\u6d41\u4f30\u8ba1\u4ee5\u53ca\u56fe\u7247\u7684deblur \\Pi - nets: Deep Polynomial Neural Networks pdf \u53ef\u5b66\u4e60\u53c2\u6570\u7684\u591a\u9879\u5f0f\u8ba1\u7b97\u6a21\u5757(\u6700\u7ec8\u8f93\u51fa\u4e3a\u8f93\u5165\u7684\u591a\u9879\u5f0f\u8868\u8fbe)","title":"Summaries for sevearl CVPR 2020 papers"},{"location":"other_categories/Summaries/Summary_of_serveral_cvpr2020/#summaries-for-sevearl-cvpr-2020-papers","text":"","title":"Summaries for sevearl CVPR 2020 papers"},{"location":"other_categories/Summaries/Summary_of_serveral_cvpr2020/#bridging-the-gap-between-anchor-based-and-anchor-free-detection-via-adaptive-training-sample-selection-atss","text":"pdf code_head code_assigner/core \u8fd9\u7bc7paper\u505a\u4e86\u4e00\u4e2a\u76f8\u5f53\u7ec6\u81f4\u5bf9\u6bd4\u5b9e\u9a8c\u6765\u5206\u6790anchor based\u4e0eanchor free\u6a21\u5757\u7684\u533a\u522b\u7ed3\u679c\u3002\u53e6\u5916\u81ea\u5df1\u63d0\u51fa\u4e86\u66f4\u597d\u7684sampling\u65b9\u6cd5 \\rightarrow ATSS \u4f20\u7edf\u7684RetinaNet(32.5%)\u88abanchor free\u7684 FCOS (37.8%)\u6027\u80fd\u5927\u5e45\u8d85\u8d8a\uff0c\u662f\u4ec0\u4e48\u5f15\u8d77\u4e86\u8fd9\u4e9b\u5dee\u8ddd\u5462\uff0c\u662fanchor free\u4e0eanchor based\u672c\u8eab\u5417\uff1f\u4f5c\u8005\u5206\u6790\u6307\u51fa\uff0c\u5bf9\u4e8e\u4e00\u4e2a\u6bcf\u4e00\u4e2ascale\u53ea\u6709\u4e00\u4e2aanchor box\u7684 Retinanet\u6a21\u578b\u4e0eFCOS\u8fdb\u884c\u5bf9\u6bd4\uff0c\u8bad\u7ec3\u7ec6\u8282\u7684\u5dee\u522b:1. GroupNorm 2. GIoU Loss 3. Center point should be in the Box 4. Centerness branch (also helpful in NMS)5. additional trainable scalar, \u8fd9\u91cc\u9762\u6bd4\u8f83\u91cd\u8981\u7684\u662f(1),(2),(4). RetinaNet\u4e0eFCOS\u7684\u672c\u8d28\u533a\u522b\u6709\u4e8c\uff0c\u7b2c\u4e00\u4e2a\u662f\u5206\u7c7b\u65f6\u7ed9\u5b9a\u6b63\u6837\u672c\u7684\u65b9\u6cd5\u3002 \u7b2c\u4e8c\u4e2a\u662f\u56de\u5f52\u65f6\u6846\u5927\u5c0f\u7684\u56de\u5f52\u65b9\u6cd5.\u4f5c\u8005\u5728\u4e0b\u8868\u5b9e\u9a8c\u8bf4\u660e\u4e86\u6b63\u8d1f\u6837\u672c\u7684\u5206\u914d\u7b56\u7565\u624d\u662f\u5f71\u54cd\u70b9\u6570\u7684\u6700\u91cd\u8981\u56e0\u7d20\u3002 \u4f5c\u8005\u63d0\u51fa\u7684ATSS\u7b97\u6cd5. code_assigner/core","title":"Bridging the Gap Between Anchor-based and Anchor-free Detection via Adaptive Training Sample Selection (ATSS)"},{"location":"other_categories/Summaries/Summary_of_serveral_cvpr2020/#depth-sensing-beyond-lidar-range","text":"pdf \u8fd9\u7bc7paper\u662f\u5c5e\u4e8e\u503c\u5f97\u7cbe\u8bfb\u7684\u6587\u7ae0\u4e4b\u4e00\u3002","title":"Depth Sensing Beyond LiDAR Range"},{"location":"other_categories/Summaries/Summary_of_serveral_cvpr2020/#motivation","text":"LiDAR\u4e00\u76f4\u4ee5\u6765\u5b58\u5728\u7740\u65e0\u6cd5\u611f\u77e5\u8db3\u591f\u8fdc\u7684\u7269\u4f53\u7684\u95ee\u9898\uff0c\u5373\u4f7f\u7ebf\u6570\u5f88\u5927\uff0c\u6709\u6548\u7684\u8ddd\u79bb\u53ef\u80fd\u4e5f\u5c31\u53ea\u80fd\u53bb\u523080\u7c73\u3002\u800c\u8fd9\u4e2a\u5bf9\u4e8e\u4e2d\u901f\u884c\u9a76\u7684\u6c7d\u8f66\u6765\u8bf4\u4ec5\u4ec5\u662f\u51e0\u79d2\u5185\u7684\u91cc\u7a0b\uff0c\u56e0\u800c\u5f80\u5f80\u4e0d\u591f\u7528\u3002\u672c\u6587\u8981\u5b9e\u73b0\u8d85\u8fc7\u4e00\u767e\u7c73\u4e43\u81f3\u672c\u6587\u7ed9\u51fa\u7684\u8fd1300\u7c73\u8303\u56f4\u5185\u7684\u6df1\u5ea6\u4f30\u8ba1\uff0c\u4f7f\u7528\u4e86\u7279\u6b8a\u914d\u7f6e\u7684\u591a\u76ee\u6444\u50cf\u673a(\u4e09\u76ee)\u3002\u5bf9\u4e8e\u6444\u50cf\u673a\u53c2\u6570\u6765\u8bf4\uff0c\u5c31\u9700\u8981\u5927\u5206\u8fa8\u7387\uff0c\u5c0f\u611f\u53d7\u91ce\u7528\u4e8e\u4e13\u6ce8\u4e8e\u8fdc\u666f\uff0c\u4f46\u662f\u8fd9\u4e2a\u786c\u4ef6\u914d\u7f6e\u7684\u95ee\u9898\u5728\u4e8e\u5bf9\u5fae\u5c0f\u7684\u5916\u53c2\u6270\u52a8\u975e\u5e38\u654f\u611f\uff0c\u56e0\u800c\u9700\u8981\u9c81\u68d2\u7b97\u6cd5or\u5728\u7ebf\u8865\u507f(\u672c\u6587\u7684\u65b9\u6848)\u3002","title":"Motivation"},{"location":"other_categories/Summaries/Summary_of_serveral_cvpr2020/#_1","text":"\u4f5c\u8005\u6587\u4e2d\u4ee5\u53ca\u540e\u9762\u7684\u8ba1\u7b97\u540c\u65f6\u6307\u51fa\uff0c\u5de6\u53f3\u76ee\u7684\u8ddd\u79bb\u5e94\u8be5\u8db3\u591f\u8fdc\uff0c\u800c\u4e14\u524d\u540e\u76f8\u673a\u8ddd\u79bb\u4e5f\u5e94\u8be5\u5c3d\u53ef\u80fd\u8fdc\uff0c\u8fd9\u4e9b\u90fd\u4ec5\u4ec5\u88ab\u8f66\u8eab\u5927\u5c0f\u6240\u9650\u5236\u3002","title":"\u786c\u4ef6\u914d\u7f6e"},{"location":"other_categories/Summaries/Summary_of_serveral_cvpr2020/#_2","text":"\u7b2c\u4e00\u6b65\u8fdb\u884c\u7684\u662fretification,\u5f97\u5230\u4e24\u4e2a\u76f8\u673a\u4e4b\u95f4\u7684\u4e00\u4e2a\u76f8\u4e92\u8f6c\u6362\uff0c\u4f7f\u5f97Stereo matching\u7684epipolar line\u662f\u6c34\u5e73\u7684\u3002\u4f5c\u8005\u7b80\u5355\u5730\u8bc1\u660e\u4e86\uff0c\u5bf9\u4e8e\u5c0fFOV\u76f8\u673a\u4ee5\u53ca\u5c0f\u6270\u52a8\u6765\u8bf4\uff0c\u5173\u4e8ex/y\u8f74\u7684\u5fae\u5c0f\u65cb\u8f6c\u90fd\u8fd1\u4f3c\u7b49\u540c\u4e8e\u6574\u4e2a\u753b\u9762\u7684\u5e73\u79fb\u3002\u800c\u753b\u9762\u7684\u65cb\u8f6c\u672c\u8eab\u5c31\u662f\u4e00\u4e2aAffine transform.\u56e0\u800c\u5b9e\u9645\u4e0a\u53ef\u4ee5\u7528homography transform matrix(2x3)\uff0c\u5c31\u53ef\u4ee5\u5b8c\u6210\u5bf9\u539f\u6765\u56fe\u7247\u7684\u77eb\u6b63\u3002\u6574\u4e2a\u7b97\u6cd5\u7684\u601d\u8def\u5c31\u662f\u4f7f\u7528RANSAC\uff0c\u51b3\u5b9aH\u77e9\u9635\u5bf9\u5e94\u7684\u53c2\u6570\u3002\u8981\u6c42\u662f\u8ba9\u5c3d\u53ef\u80fd\u591a\u7684matched point\u90fd\u5728\u540c\u4e00\u4e2a\u6c34\u5e73\u7ebf\u4e0a\u3002\u53ef\u4ee5\u60f3\u8c61\u7684\u662f\uff0c\u8fd9\u6837\u7684retification\u65b9\u5f0f\u65e0\u6cd5\u51b3\u5b9a\u76f8\u673a\u5173\u4e8ey\u8f74\u7684\u65cb\u8f6c\uff0c\u56e0\u800cwarped\u540e\u7684\u56fe\u7247\u8ba1\u7b97\u5f97\u5230\u7684\u53cc\u76ee\u5339\u914ddisparity\u4e0e\u6b63\u786e\u7684\u503c\u4e4b\u95f4\u6709\u4e00\u4e2abias(\u53ef\u4ee5\u7406\u89e3\u4e3a\u5bf9\u65cb\u8f6c\u7684\u4f30\u8ba1\u7684bias/ambiguity) Disparity Estimation\u4f7f\u7528\u7684\u662f\u4e00\u4e2apretrained\u7684stereo matching\u7f51\u7edc. \\left\\langle\\mathbf{H}_{2,1: 3}^{(l)}, \\mathbf{x}^{(l)}\\right\\rangle-\\left\\langle\\mathbf{H}_{2,1: 3}^{(r)}, \\mathbf{x}^{(r)}\\right\\rangle=0 \u7b2c\u4e09\u6b65\u662f\u5229\u7528\u524d\u540e\u76f8\u673a\u6d88\u9664\u7b2c\u4e00\u90e8\u5206\u4ea7\u751f\u7684ambiguity.\u5bf9\u4e8e\u5de6\u76ee\u4e0a\u4efb\u610f\u4e24\u4e2a\u5177\u6709\u76f8\u540c\u6df1\u5ea6\u7684pixel x_1^{(l)}, x_2^{(l)} \uff0c\u8fd9\u4e24\u4e2a\u70b9\u57283D\u4e2d\uff0c\u76f8\u5bf9\u4e8e\u524d\u540e\u6444\u50cf\u673a\u7684 x , y \u5750\u6807\u7684\u5dee\u662f\u4e00\u81f4\u7684(\u8fd9\u91cc\u6307\u7684\u662f\u76f8\u673a\u53c2\u8003\u7cfb\u800c\u4e0d\u662f\u56fe\u7247\u53c2\u8003\u7cfb)\uff0c\u8fd9\u91cc\u5f15\u51fa\u4ee5\u4e0b\u63a8\u5bfc\u3002 \\begin{aligned} m_{l}=\\left\\|\\mathbf{x}_{1}^{(l)}-\\mathbf{x}_{2}^{(l)}\\right\\|&=\\frac{f}{z^{(l)}} \\cdot\\left\\|\\mathbf{X}_{1}^{(l)}-\\mathbf{X}_{2}^{(l)}\\right\\| \\\\ m_{b}&=\\frac{f}{z^{(b)}} \\cdot\\left\\|\\mathbf{X}_{1}^{(b)}-\\mathbf{X}_{2}^{(b)}\\right\\| \\\\ \\mathbf{X}_{1}^{(l)}-\\mathbf{X}_{2}^{(l)}&=\\mathbf{X}_{1}^{(b)}-\\mathbf{X}_{2}^{(b)}, z^{(b)}=z^{(l)}+C_{l b} \\\\ \\frac{m_{l}}{m_{b}}&=\\frac{z^{(l)}+C_{l b}}{z^{(l)}}\\\\ z=z^{(l)}&=\\frac{C_{l b}}{\\frac{m_{l}}{m_{b}}-1}\\\\ \\end{aligned} \u5bf9\u4e8e\u4e00\u7ec4\u7b26\u5408 m_l > m_b , m_l > \\delta , |d_1 - d_2| < \\eta \u7684\u70b9\uff0c\u7531\u5b83\u4eec\u7684\u6570\u503c\u53ef\u4ee5\u5f97\u5230\u7684\u5bf9disparity bias\u7684\u4f30\u8ba1\u4e3a: q=f \\cdot \\frac{C_{l r}}{C_{l b}} \\cdot\\left(\\frac{m_{l}}{m_{b}}-1\\right)-\\frac{d_{1}+d_{2}}{2} \u524d\u9762\u63d0\u5230\u7684\u8fd9\u4e09\u4e2a\u6761\u4ef6\u5206\u522b\u8868\u793a (1) \u8fd9\u4e2abatched\u662f\u5426\u4e8b\u5b9e\u4e0a\u771f\u5b9e;\u9760\u524d\u76f8\u673a\u770b\u5230\u7684\u4e24\u70b9\u8ddd\u79bb\u7406\u5e94\u66f4\u5927 (2) \u4e24\u4e2a\u70b9\u7684\u8ddd\u79bb\u5e94\u8be5\u8db3\u591f\u5927\uff0c\u6700\u597d\u4e0d\u8981\u8d34\u5728\u4e00\u8d77 (3) \u4e24\u4e2a\u50cf\u7d20\u4e4b\u95f4\u7684\u8ddd\u79bb\u51e0\u4e4e\u662f\u76f8\u7b49\u7684\u3002 \u4f5c\u8005\u540e\u9762\u7528\uff1a 1. \u7528\u4eff\u771f\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5f88\u5c0f\u7684\u8bef\u5dee\uff0c\u5728\u53cc\u76ee\u957f\u8ddd\u79bb\u5339\u914d\u4e2d\u5c31\u4f1a\u5f88\u5927\u7684\u4f7f\u6027\u80fd\u9000\u5316\u3002 2. \u4ed6\u4eec\u63d0\u51fa\u7684retification\u65b9\u6cd5\u4e0e\u6807\u51c68\u70b9\u6cd5\u5bf9\u6bd4\u5728\u8fd9\u4e2a\u573a\u666f\u4e0b\u6570\u503c\u66f4\u7a33\u5b9a\uff1b\u56e0\u4e3a\u4ed6\u4eec\u5229\u7528\u4e86\u8fd9\u4e2a\u573a\u666f\u4e0b\u7684\u5148\u9a8c\u77e5\u8bc6\u3002 3. \u5b9e\u9a8c\u8bf4\u660e\u4e86ambiguity removal\u7684\u8fc7\u7a0b\uff0c\u4ee5\u53ca\u6700\u540e\u8ba1\u7b97\u7684\u6709\u6548\u6027\u3002","title":"\u7b97\u6cd5\u6d41\u7a0b"},{"location":"other_categories/Summaries/Summary_of_serveral_cvpr2020/#retinatrack","text":"pdf \u7279\u70b9\uff0c\u4e0d\u540canchor\u5728\u66f4\u65e9\u671ffeatures\u5c31\u5f00\u59cb\u5206\u5f00\uff0c\u6bcf\u4e00\u4e2aanchor\u8f93\u51fa\u4e00\u4e2a256\u7ef4\u5ea6\u7684features. \u5bf9 \u5355\u4e00\u56fe\u7247 \u7528triplet loss \\mathcal{L}_{B H}(\\theta ; X)=\\sum_{j=1}^{A} \\text { SoftPlus }\\left(m+\\max _{p=1 \\rightarrow A \\atop t_{j}=t_{p}} D_{j p}-\\min _{\\ell=1 \\ldots A \\atop t_{j} \\neq t_{\\ell}} D_{j \\ell}\\right) \u6838\u5fc3\u601d\u8def\u5c31\u662f\u76f8\u540cinstance\u7684\u4e0d\u540canchor\u8f93\u51fa\u76f8\u4f3c\u7684embedding\uff0c\u4e0d\u540cinstance\u7684\u4e0d\u540canchor\u8f93\u51fa\u4e0d\u540c\u7684embedding\u3002\u672c\u6587\u7528\u57fa\u7840\u7684euclidean distance\u4f5c\u4e3aloss","title":"RetinaTrack"},{"location":"other_categories/Summaries/Summary_of_serveral_cvpr2020/#muxconv-information-multiplexing-in-convolutional-neural-networks","text":"pdf code","title":"MUXConv: Information Multiplexing in Convolutional Neural Networks"},{"location":"other_categories/Summaries/Summary_of_serveral_cvpr2020/#structure-aware-single-stage-3d-object-detection-from-point-cloud","text":"pdf code \u57fa\u4e8eMMdetection\u5f00\u53d1\u7684\u70b9\u4e913D \u68c0\u6d4b\uff0c\u6027\u80fd\u5f88\u9ad8\uff0c\u91cd\u70b9\u5728\u4e8e\u9644\u52a0task\u7684\u8bbe\u8ba1\u7684\uff0c\u80fd\u8ba9\u4e00\u4e2a\u63a5\u8fd1\u4e8eVoxelNet\u7684\u7ed3\u6784\u5f97\u5230\u5f88\u5927\u7684\u63d0\u5347","title":"Structure Aware Single-stage 3D Object Detection from Point Cloud"},{"location":"other_categories/Summaries/Summary_of_serveral_cvpr2020/#camouflaged-object-detection","text":"pdf code \u672c\u95ee\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u95ee\u9898\u4ee5\u53ca\u65b0\u7684\u6570\u636e\u96c6\uff0c\u6709 \u4e2d\u6587paper .","title":"Camouflaged Object Detection"},{"location":"other_categories/Summaries/Summary_of_serveral_cvpr2020/#lightweight-multi-view-3d-pose-estimation-through-camera-disentangled-representation","text":"pdf FTL\u5c42\u4e0d\u662f\u4e00\u4e2a\u5b66\u4e60\u5c42\uff0c\u7528\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42\uff0c\u5c062D\u9884\u6d4b\u7528\u65cb\u8f6c\u53d8\u6362\u8f6c\u6362\u5230\u4e0ecamera\u65b9\u4f4d\u65e0\u5173\u7684\u7ed3\u679c \\mathbf{y}=F_{T_{1}, \\ldots, T_{n}}[\\mathbf{x}]=\\left[\\begin{array}{ccc} F_{T_{1}} & & \\\\ & \\ddots & \\\\ & & F_{T_{n}} \\end{array}\\right] 3D \u4f4d\u7f6e\u4f30\u8ba1\u91c7\u7528\u7684\u662fSFM\u7684formulation d_{i} u_{i}=p_{i}^{1 T} \\mathbf{x}, d_{i} v_{i}=p_{i}^{2 T} \\mathbf{x}, d_{i}=p_{i}^{3 T} \\mathbf{x} \\begin{array}{l} \\left(u_{i} p_{i}^{3 T}-p_{i}^{1 T}\\right) \\mathbf{x}=0 \\\\ \\left(v_{i} p_{i}^{3 T}-p_{i}^{2 T}\\right) \\mathbf{x}=0 \\end{array} \u628a\u540c\u4e00\u4e2a\u5173\u8282\u6240\u6709\u70b9\u653e\u5728\u4e00\u8d77\uff0c A \\mathbf{x}=\\mathbf{0} ,\u539f\u7406\u4e0a\u6765\u8bf4\u9700\u8981\u4f7f\u7528SVD\u627e\u51fa\u6700\u5c0f\u7279\u5f81\u503c\u5bf9\u5e94\u7684\u7279\u5f81\u5411\u91cf\u3002\u4f5c\u8005\u6307\u51fa\u5982\u679c\u53ea\u9700\u8981\u6c42\u6700\u5c0f\u7279\u5f81\u503c\uff0c\u4e0d\u9700\u8981\u4f7f\u7528SVD\uff0c\u4f7f\u7528\u4ee5\u4e0b\u8fed\u4ee3\u7b97\u6cd5\u5373\u53ef","title":"Lightweight Multi-View 3D Pose Estimation through Camera-Disentangled Representation"},{"location":"other_categories/Summaries/Summary_of_serveral_cvpr2020/#flow2stereo-effective-self-supervised-learning-of-optical-flow-and-stereo-matching","text":"pdf","title":"Flow2Stereo: Effective Self-Supervised Learning of Optical Flow and Stereo Matching"},{"location":"other_categories/Summaries/Summary_of_serveral_cvpr2020/#what-you-see-is-what-you-get-exploiting-visibility-for-3d-object-detection","text":"pdf \u672c\u6587\u4e3b\u8981\u9488\u5bf9\u7684\u5c31\u662fNuscene\u573a\u666f\u4e2d\u88ab\u906e\u6321\u6bd4\u8f83\u4e25\u91cd\u7684\u7269\u4f53\u3002\u901a\u8fc7\u7528\u70b9\u4e91\u5efa\u7acb\u7684occupancy map,\u7f51\u7edc\u53ef\u4ee5infer\u4ec0\u4e48\u5730\u65b9\u662f\u53ef\u80fd\u88ab\u906e\u6321\u800c\u53ef\u80fd\u6709\u7269\u4f53\u7684\u3002 \u672c\u6587\u6709\u4e00\u4e2a\u6bd4\u8f83\u597d\u7684 \u4e2d\u6587\u535a\u5ba2 ,\u63d0\u5230\u4e86\u672c\u6587\u51e0\u4e2a\u91cd\u8981\u7684\u6709\u8da3\u7684\u7ec6\u8282\uff0c\u7b2c\u4e00\u4e2a\u662f3D\u4e16\u754c\u7684Fast Voxel Traversal\u751f\u6210occupancy map;\u7b2c\u4e8c\u4e2a\u662f\u6570\u636e\u589e\u5f3a\uff0c\u91c7\u53d6\u7684\u65b9\u6cd5\u4e0eoccupancy map\u8fdb\u884c\u589e\u5f3a\uff1b\u7b2c\u4e09\u4e2a\u662fonline bayesian grid mapping.","title":"What You See is What You Get: Exploiting Visibility for 3D Object Detection"},{"location":"other_categories/Summaries/Summary_of_serveral_cvpr2020/#instance-shadow-detection","text":"pdf code \u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u4efb\u52a1\uff0c\u65b0\u7684dataset\u4ee5\u53cabaseline\u65b9\u6cd5\u3002\u4efb\u52a1\u662f\u7269\u4f53\u4e0e\u5f71\u5b50\u7684instance segmentation\u4ee5\u53ca\u4e00\u4e00\u5bf9\u5e94\u3002","title":"Instance Shadow Detection"},{"location":"other_categories/Summaries/Summary_of_serveral_cvpr2020/#a-model-driven-deep-neural-network-for-single-image-rain-removal","text":"pdf code","title":"A Model-driven Deep Neural Network for Single Image Rain Removal"},{"location":"other_categories/Summaries/Summary_of_serveral_cvpr2020/#single-image-optical-flow-estimation-with-an-event-camera","text":"pdf \u672c\u6587\u662f\u57fa\u4e8eDAVIS\u7684event + gray scale\u8bbe\u8ba1\u7684\u7b97\u6cd5\uff0c\u4e00\u4e2a\u91cd\u8981\u7684idea\u662fevent\u4fe1\u606f\u672c\u8eab\u53ef\u4ee5\u76f4\u63a5\u5b58\u50a8\u5149\u6d41\u76f8\u5173\u7684\u4fe1\u606f\uff0c\u800c\u7070\u5ea6\u56fe\u7684\u52a8\u6001\u6a21\u7cca\u4e5f\u53ef\u4ee5\u7528\u4e8e\u6307\u5f15\u5149\u6d41\u4f30\u8ba1\u3002\u56e0\u6b64\u672c\u6587\u63d0\u51fa\u540c\u65f6\u4f30\u8ba1\u5149\u6d41\u573a\u4ee5\u53calatent image \\mathcal{L} . \u80fd\u91cf\u51fd\u6570\u8bbe\u8ba1\u4e3a \\min _{\\mathbf{L} . \\mathbf{u}} \\mu_{1} \\phi_{\\mathrm{eve}}(\\mathbf{L}, \\mathbf{u})+\\mu_{2} \\phi_{\\mathrm{blur}}(\\mathbf{L}, \\mathbf{u})+\\phi_{\\mathrm{flow}}(\\nabla \\mathbf{u})+\\phi_{\\mathrm{im}}(\\nabla \\mathbf{L}) \u9996\u5148\u662f\u8003\u8651\u4e86\u5149\u7167\u53d8\u5316\u7684\u5149\u6d41-\u5149\u7167\u4e00\u81f4\u6761\u4ef6 \\begin{aligned} \\phi_{\\mathrm{eve}}(\\mathbf{L}, \\mathbf{u})=\\sum_{\\mathbf{x} \\in \\Omega} \\| &\\mathbf{L}(\\mathbf{x}, f)(\\exp (c \\mathbf{E}(\\mathbf{x}, t))-1) \\\\ &+\\left[u_{\\mathbf{x}}, v_{\\mathbf{x}}\\right]^{\\mathrm{T}} \\nabla \\mathbf{L}(\\mathbf{x}, f) \\|_{1} \\end{aligned} \u6a21\u7cca: \u6a21\u7cca\u540e\u7684\u56fe\u7247 B \u53ef\u4ee5\u7531\u6a21\u7cca\u6838 K \u4ee5\u53calatent \u56fe\u7247 L \u5377\u79ef\u8868\u8fbe: \\begin{aligned} \\mathbf{B}(\\mathbf{x}) &=\\sum_{\\mathbf{y} \\in \\Omega} \\mathbf{k}(\\mathbf{y}) \\mathbf{L}(\\mathbf{x}-\\mathbf{y}) \\\\ &=\\sum_{\\mathbf{y} \\in \\Omega} \\mathbf{k}_{\\mathbf{u}^{\\prime}(\\mathbf{x})}(\\mathbf{y}) \\mathbf{L}(\\mathbf{x}-\\mathbf{y}) \\end{aligned} k_{\\mathbf{u}^{\\prime}(\\mathbf{x})}(\\mathbf{y})=\\left\\{\\begin{array}{ll} \\frac{1}{\\left|\\mathbf{u}^{\\prime}(\\mathbf{x})\\right|}, & \\text { if } \\mathbf{y}=\\alpha \\mathbf{u}^{\\prime}(\\mathbf{x}),|\\alpha| \\leq \\frac{1}{2} \\\\ \\mathbf{0}, & \\text { otherwise } \\end{array}\\right. \u6a21\u7cca\u6761\u4ef6: \\phi_{\\text {blur }}(\\mathbf{L}, \\mathbf{u})=\\sum_{\\mathbf{x}, \\mathbf{y} \\in \\Omega}\\left\\|\\mathbf{k}_{\\mathbf{u}^{\\prime}(\\mathbf{x})}(\\mathbf{y}) \\mathbf{L}(\\mathbf{x}-\\mathbf{y})-\\mathbf{B}(\\mathbf{x})\\right\\|^{2} \u540e\u4e24\u9879\u4e3a\u8fde\u7eed\u6027\u8981\u6c42\uff0c\u6587\u4e2d\u7684\u8bbe\u8ba1\u6bd4\u8f83\u7cbe\u7ec6\u3002 \u4f18\u5316\u65b9\u6cd5\u4e0a\u672c\u6587\u8fed\u4ee3\u8fdb\u884c\u5149\u6d41\u4f30\u8ba1\u4ee5\u53ca\u56fe\u7247\u7684deblur","title":"Single Image Optical Flow Estimation with an Event Camera"},{"location":"other_categories/Summaries/Summary_of_serveral_cvpr2020/#pi-nets-deep-polynomial-neural-networks","text":"pdf \u53ef\u5b66\u4e60\u53c2\u6570\u7684\u591a\u9879\u5f0f\u8ba1\u7b97\u6a21\u5757(\u6700\u7ec8\u8f93\u51fa\u4e3a\u8f93\u5165\u7684\u591a\u9879\u5f0f\u8868\u8fbe)","title":"\\Pi - nets: Deep Polynomial Neural Networks"},{"location":"other_categories/Summaries/Summary_of_several_iccv2019/","text":"Summaries for sevearl ICCV 2019 papers Many Task Learning With Task Routing pdf code \u8fd9\u7bc7\u6587\u7ae0\u89e3\u51b3\u591a\u4efb\u52a1\u5b66\u4e60\u7684\u95ee\u9898\uff0c\u89e3\u51b3\u7684\u65b9\u6848\u662f\u4e00\u6b21train\u53eaactivate\u6709\u9650\u4e2a\u4efb\u52a1\uff0c\u7136\u540e\u968f\u673a\u6fc0\u6d3b\u3002\u8fd9\u6269\u5c55\u6210\u4e00\u4e2a\u5e7f\u4e49\u7684\u5c42\uff0ctrain\u65f6\u968f\u673a\u6fc0\u6d3b\u6709\u9650\u4e2a\u8f93\u51fa\u3002 AdaTransform: Adaptive Data Transformation pdf \u8fd9\u7bc7\u6587\u7ae0\u4f5c\u8005\u6709\u7c7b\u4f3c\u4efb\u52a1\u7684 \u65e7repo .\u8fd9\u7bc7\u6587\u7ae0\u8bad\u7ec3\u4e00\u4e2a\u4e13\u6ce8\u4e8e\u6570\u636e\u589e\u5f3a\u7684agent\uff0c\u5728\u7ade\u4e89\u6a21\u5f0f\u4e2d\u80fd\u6311\u6218\u539f\u7f51\u7edc\uff0c\u5728\u5408\u4f5c\u6a21\u5f0f\u4e2d\u80fd\u63d0\u5347\u539f\u7f51\u7edc\u7684Generalization\u80fd\u529b\u3002\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u8fd9\u4e2aagent\uff0c\u53e6\u5916\u4e5f\u9700\u8981\u4e00\u4e2a\u5206\u7c7b\u5668\u7528\u4e8e\u5728\u7ade\u4e89\u6a21\u5f0f\u65f6\u9274\u522bagent\u7684\u7f51\u7edc\u662f\u5426\u8fc7\u4e8e\u504f\u79bb\u539f\u5206\u5e03\u3002 LIP: Local Importance-based Pooling pdf code \u5982\u56fe\u6a21\u5757 Anchor Loss: Modulating Loss Scale based on Prediction Difficulty pdf \\ell(p, q ; \\gamma)=-\\underbrace{(1+\\overbrace{q-q_{*}}^{\\text {predicion difficulty }})}_{\\text {modulator }} \\underbrace{(1-p) \\log (1-q)}_{\\text {cross entropy }} \u8fd9\u7bc7\u6587\u7ae0\u8ba8\u8bba\u4e86\u4e00\u4e2a\u57fa\u4e8eFocal Loss\u5f00\u53d1\u7684\u4e00\u4e2a\u635f\u5931\u51fd\u6570\uff0c\u5982\u4e0a\u516c\u5f0f\u3002\u672c\u6587\u5bf9 q_* \u8fdb\u884c\u4e86\u8ba8\u8bba\uff0c\u5728\u5206\u7c7b\u4ee5\u53ca\u59ff\u6001\u4f30\u8ba1(\u672c\u8d28\u4e0a\u90fd\u662f\u5206\u7c7b\u95ee\u9898)\u4e2d\u5f97\u5230\u4e86SOTA\u7684\u7ed3\u679c\u3002","title":"Summaries for sevearl ICCV 2019 papers"},{"location":"other_categories/Summaries/Summary_of_several_iccv2019/#summaries-for-sevearl-iccv-2019-papers","text":"","title":"Summaries for sevearl ICCV 2019 papers"},{"location":"other_categories/Summaries/Summary_of_several_iccv2019/#many-task-learning-with-task-routing","text":"pdf code \u8fd9\u7bc7\u6587\u7ae0\u89e3\u51b3\u591a\u4efb\u52a1\u5b66\u4e60\u7684\u95ee\u9898\uff0c\u89e3\u51b3\u7684\u65b9\u6848\u662f\u4e00\u6b21train\u53eaactivate\u6709\u9650\u4e2a\u4efb\u52a1\uff0c\u7136\u540e\u968f\u673a\u6fc0\u6d3b\u3002\u8fd9\u6269\u5c55\u6210\u4e00\u4e2a\u5e7f\u4e49\u7684\u5c42\uff0ctrain\u65f6\u968f\u673a\u6fc0\u6d3b\u6709\u9650\u4e2a\u8f93\u51fa\u3002","title":"Many Task Learning With Task Routing"},{"location":"other_categories/Summaries/Summary_of_several_iccv2019/#adatransform-adaptive-data-transformation","text":"pdf \u8fd9\u7bc7\u6587\u7ae0\u4f5c\u8005\u6709\u7c7b\u4f3c\u4efb\u52a1\u7684 \u65e7repo .\u8fd9\u7bc7\u6587\u7ae0\u8bad\u7ec3\u4e00\u4e2a\u4e13\u6ce8\u4e8e\u6570\u636e\u589e\u5f3a\u7684agent\uff0c\u5728\u7ade\u4e89\u6a21\u5f0f\u4e2d\u80fd\u6311\u6218\u539f\u7f51\u7edc\uff0c\u5728\u5408\u4f5c\u6a21\u5f0f\u4e2d\u80fd\u63d0\u5347\u539f\u7f51\u7edc\u7684Generalization\u80fd\u529b\u3002\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u8fd9\u4e2aagent\uff0c\u53e6\u5916\u4e5f\u9700\u8981\u4e00\u4e2a\u5206\u7c7b\u5668\u7528\u4e8e\u5728\u7ade\u4e89\u6a21\u5f0f\u65f6\u9274\u522bagent\u7684\u7f51\u7edc\u662f\u5426\u8fc7\u4e8e\u504f\u79bb\u539f\u5206\u5e03\u3002","title":"AdaTransform: Adaptive Data Transformation"},{"location":"other_categories/Summaries/Summary_of_several_iccv2019/#lip-local-importance-based-pooling","text":"pdf code \u5982\u56fe\u6a21\u5757","title":"LIP: Local Importance-based Pooling"},{"location":"other_categories/Summaries/Summary_of_several_iccv2019/#anchor-loss-modulating-loss-scale-based-on-prediction-difficulty","text":"pdf \\ell(p, q ; \\gamma)=-\\underbrace{(1+\\overbrace{q-q_{*}}^{\\text {predicion difficulty }})}_{\\text {modulator }} \\underbrace{(1-p) \\log (1-q)}_{\\text {cross entropy }} \u8fd9\u7bc7\u6587\u7ae0\u8ba8\u8bba\u4e86\u4e00\u4e2a\u57fa\u4e8eFocal Loss\u5f00\u53d1\u7684\u4e00\u4e2a\u635f\u5931\u51fd\u6570\uff0c\u5982\u4e0a\u516c\u5f0f\u3002\u672c\u6587\u5bf9 q_* \u8fdb\u884c\u4e86\u8ba8\u8bba\uff0c\u5728\u5206\u7c7b\u4ee5\u53ca\u59ff\u6001\u4f30\u8ba1(\u672c\u8d28\u4e0a\u90fd\u662f\u5206\u7c7b\u95ee\u9898)\u4e2d\u5f97\u5230\u4e86SOTA\u7684\u7ed3\u679c\u3002","title":"Anchor Loss: Modulating Loss Scale based on Prediction Difficulty"},{"location":"other_categories/depth_completion/OrdinalRegression/","text":"Soft Labels for Ordinal Regression \u4e0e DORN \u4e00\u6837\u3002\u91c7\u53d6\u5e8f\u6570\u56de\u5f52\u7684\u6982\u5ff5\u5bf9\u6df1\u5ea6\u8fdb\u884c\u56de\u5f52\u3002\u5e8f\u6570\u56de\u5f52\u7684\u6982\u5ff5\u5728\u4e8e\u88ab\u56de\u5f52\u7684\u503c\u6709\u4e00\u5b9a\u7684\u81ea\u7136\u903b\u8f91\u987a\u5e8f\u3002 SORD \u5e8f\u6570\u56de\u5f52\u7684target: y_{i}=\\frac{e^{-\\phi\\left(r_{t}, r_{i}\\right)}}{\\sum_{k=1}^{K} e^{-\\phi\\left(r_{t}, r_{k}\\right)}} \\quad \\forall r_{i} \\in \\mathcal{Y} \u7c7b\u4f3c\u4e8e\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\u7684\u53cd\u4f20: \\frac{\\partial L}{\\partial p_{i}}=-\\frac{e^{-\\phi\\left(r_{t}, r_{i}\\right)}}{e^{o_{i}^{\\prime}}}=-e^{-\\phi\\left(r_{t}, r_{i}\\right)-o_{i}^{\\prime}} \u5bf9\u4e8e\u6df1\u5ea6\u9884\u6d4b\uff0c\u6587\u4e2d\u63d0\u5230\u4e86\u4e09\u79cd\u6838\u51fd\u6570 \\phi Square Difference(SD): \\phi\\left(r_{t}, r_{i}\\right)=\\left\\|r_{t}-r_{i}\\right\\|^{2} Square Log Difference(SL): \\phi\\left(r_{t}, r_{i}\\right)=\\left\\|\\log r_{t}-\\log r_{i}\\right\\|^{2} Square Invariant Logarithmic Error (SI): \\phi\\left(r_{t}, r_{i}\\right)=d_{r_{t}, r_{i}}^{2}-\\frac{d_{r_{t}, r_{i}}}{n}\\left(d_{r_{t}, r_{i}}+\\sum_{p^{\\prime} \\neq p} d_{p^{\\prime}}\\right) SI Loss \u6e90\u81ea\u4e8e\u8fd9\u7bc7 paper.pdf \\begin{aligned} D\\left(y, y^{*}\\right) &=\\frac{1}{n^{2}} \\sum_{i, j}\\left(\\left(\\log y_{i}-\\log y_{j}\\right)-\\left(\\log y_{i}^{*}-\\log y_{j}^{*}\\right)\\right)^{2} \\\\ &=\\frac{1}{n} \\sum_{i} d_{i}^{2}-\\frac{1}{n^{2}} \\sum_{i, j} d_{i} d_{j}=\\frac{1}{n} \\sum_{i} d_{i}^{2}-\\frac{1}{n^{2}}\\left(\\sum_{i} d_{i}\\right)^{2} \\end{aligned} \u90a3\u7bc7paper\u63d0\u51fa\u7684\u4e00\u4e2a\u6df7\u5408\u7684Loss: L\\left(y, y^{*}\\right)=\\frac{1}{n} \\sum_{i} d_{i}^{2}-\\frac{\\lambda}{n^{2}}\\left(\\sum_{i} d_{i}\\right)^{2}","title":"Soft Labels for Ordinal Regression"},{"location":"other_categories/depth_completion/OrdinalRegression/#soft-labels-for-ordinal-regression","text":"\u4e0e DORN \u4e00\u6837\u3002\u91c7\u53d6\u5e8f\u6570\u56de\u5f52\u7684\u6982\u5ff5\u5bf9\u6df1\u5ea6\u8fdb\u884c\u56de\u5f52\u3002\u5e8f\u6570\u56de\u5f52\u7684\u6982\u5ff5\u5728\u4e8e\u88ab\u56de\u5f52\u7684\u503c\u6709\u4e00\u5b9a\u7684\u81ea\u7136\u903b\u8f91\u987a\u5e8f\u3002","title":"Soft Labels for Ordinal Regression"},{"location":"other_categories/depth_completion/OrdinalRegression/#sord","text":"\u5e8f\u6570\u56de\u5f52\u7684target: y_{i}=\\frac{e^{-\\phi\\left(r_{t}, r_{i}\\right)}}{\\sum_{k=1}^{K} e^{-\\phi\\left(r_{t}, r_{k}\\right)}} \\quad \\forall r_{i} \\in \\mathcal{Y} \u7c7b\u4f3c\u4e8e\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\u7684\u53cd\u4f20: \\frac{\\partial L}{\\partial p_{i}}=-\\frac{e^{-\\phi\\left(r_{t}, r_{i}\\right)}}{e^{o_{i}^{\\prime}}}=-e^{-\\phi\\left(r_{t}, r_{i}\\right)-o_{i}^{\\prime}} \u5bf9\u4e8e\u6df1\u5ea6\u9884\u6d4b\uff0c\u6587\u4e2d\u63d0\u5230\u4e86\u4e09\u79cd\u6838\u51fd\u6570 \\phi Square Difference(SD): \\phi\\left(r_{t}, r_{i}\\right)=\\left\\|r_{t}-r_{i}\\right\\|^{2} Square Log Difference(SL): \\phi\\left(r_{t}, r_{i}\\right)=\\left\\|\\log r_{t}-\\log r_{i}\\right\\|^{2} Square Invariant Logarithmic Error (SI): \\phi\\left(r_{t}, r_{i}\\right)=d_{r_{t}, r_{i}}^{2}-\\frac{d_{r_{t}, r_{i}}}{n}\\left(d_{r_{t}, r_{i}}+\\sum_{p^{\\prime} \\neq p} d_{p^{\\prime}}\\right) SI Loss \u6e90\u81ea\u4e8e\u8fd9\u7bc7 paper.pdf \\begin{aligned} D\\left(y, y^{*}\\right) &=\\frac{1}{n^{2}} \\sum_{i, j}\\left(\\left(\\log y_{i}-\\log y_{j}\\right)-\\left(\\log y_{i}^{*}-\\log y_{j}^{*}\\right)\\right)^{2} \\\\ &=\\frac{1}{n} \\sum_{i} d_{i}^{2}-\\frac{1}{n^{2}} \\sum_{i, j} d_{i} d_{j}=\\frac{1}{n} \\sum_{i} d_{i}^{2}-\\frac{1}{n^{2}}\\left(\\sum_{i} d_{i}\\right)^{2} \\end{aligned} \u90a3\u7bc7paper\u63d0\u51fa\u7684\u4e00\u4e2a\u6df7\u5408\u7684Loss: L\\left(y, y^{*}\\right)=\\frac{1}{n} \\sum_{i} d_{i}^{2}-\\frac{\\lambda}{n^{2}}\\left(\\sum_{i} d_{i}\\right)^{2}","title":"SORD"},{"location":"other_categories/depth_completion/Sparse and noisy LiDAR completion with RGB guidance and uncertainty/","text":"Sparse and noisy LiDAR completion with RGB guidance and uncertainty \u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e0d\u7b97\u590d\u6742\u7684\u65b9\u5f0f\uff0c\u572820ms\u949f\u5185\u5b8c\u6210\u5bf9 1256 \\times 256 \u5206\u8fa8\u7387\u7684\u56fe\u50cf\u4e0e\u7a00\u758f\u70b9\u4e91\u8fdb\u884c\u56fe\u50cf\u8865\u5168\u3002 \u603b\u4f53\u6846\u67b6 \u505a\u6cd5\u603b\u4f53\u6bd4\u8f83\u76f4\u89c2\uff0c\u9996\u5148RGB\u56fe\u50cf\u4e0e\u7a00\u758f\u7684\u6295\u5f71\u540e\u7684lidar\u6df1\u5ea6\u56fe\u8fdb\u884cconcat,\u8f93\u5165\u5230\u4ee5 ERFNet \u4e3a\u4e3b\u5e72\u7684encoder-decoder\u7f51\u7edc\u4e2d\uff0c(\u9700\u8981\u6ce8\u610f\u7684\u662f\u6839\u636e ERFNet \u7684github\u7f51\u9875\u663e\u793a\uff0c\u5176\u6a21\u578b\u9700\u8981\u79c1\u804a\u624d\u53ef\u83b7\u5f97),\u8f93\u51fa\u4e09\u4e2a\u90e8\u5206\uff0c\u4e00\u4e2a\u662flidar map\u7684\u5c40\u90e8\u6b8b\u5dee,\u4e00\u4e2a\u662f\u5168\u5c40\u6df1\u5ea6\u9884\u6d4b\uff0c\u4e00\u4e2a\u662f\u5168\u5c40\u6df1\u5ea6\u7684\u7f6e\u4fe1\u5ea6\u3002 \u800c\u7a00\u758f\u7684\u6295\u5f71\u540e\u7684Lidar\u6df1\u5ea6\u56fe\u8865\u4e0a\u6b8b\u5dee\u540e\u540c\u65f6\u8f93\u5165\u5230\u5c40\u90e8\u5206\u652f\u4e2d\uff0c\u4f7f\u7528\u6570\u4e2a\u6b8b\u5dee\u8fde\u63a5\u7684 StackedHourGlass \u6a21\u5757,\u518d\u5377\u79ef\u8f93\u51fa\u4e24\u4e2a\u5206\u652f\uff0c\u4e00\u4e2a\u662f\u5c40\u90e8\u6df1\u5ea6\u9884\u6d4b\uff0c\u4e00\u4e2a\u662f\u5c40\u90e8\u6df1\u5ea6\u7684\u7f6e\u4fe1\u5ea6\u3002 \u5168\u5c40\u5206\u652f\u4e0e\u5c40\u90e8\u5206\u652f\uff0c\u5c06\u4e24\u5206\u652f\u7684\u7f6e\u4fe1\u5ea6\u8fde\u63a5\u5e76\u4f7f\u7528\u4f7f\u7528softmax\u5c42\u5f62\u6210\u5206\u522b\u7684\u6743\u91cd\uff0c\u518d\u5c06\u4e24\u8005\u7684\u6df1\u5ea6\u9884\u6d4b\u503c\u52a0\u6743\u6c42\u548c\u5f97\u5230\u3002 \u672c\u6587\u5177\u4f53\u4f7f\u7528\u7684 StackedHourGlass \u6a21\u5757\u5982\u56fe \u8bad\u7ec3\u7ec6\u8282 \u8bad\u7ec3\u987a\u5e8f\u4e0a\uff0c\u4f5c\u8005\u4f7f\u7528pretrained ERFNet \u5148\u5355\u72ec\u5bf9\u4e24\u4e2a\u5206\u652f\u8fdb\u884c\u8bad\u7ec3\uff0c\u7136\u540e\u518d\u52a0\u5165guidance\u90e8\u5206\u4ee5\u53ca\u52a0\u6743\u90e8\u5206\u8fdb\u884c\u7aef\u5230\u7aef\u8bad\u7ec3. \u635f\u5931\u51fd\u6570\u65b9\u9762\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u6240\u8c13focal-MSE Loss\u3002\u6570\u5b66\u8868\u8fbe\u4e3a: \\lambda(\\hat y, y) = \\frac{1}{n} \\sum^n_{i=1}(1+0.05 * epoch * |y_i - \\hat y_i|) * (y_i - \\hat y_i)^2 \u6700\u7ec8\u635f\u5931\u4e3a \\Lambda=w_{1} \\cdot \\lambda\\left(\\hat{y}_{g l o b a l}, y\\right)+w_{2} \\cdot \\lambda\\left(\\hat{y}_{l o c a l}, y\\right)+w_{3} \\cdot \\lambda\\left(\\hat{y}_{o u t}, y\\right) \u5176\u4e2d\u4e09\u4e2a\u53c2\u6570\u5206\u522b\u4e3a0.1, 0.1, 1","title":"Sparse and noisy LiDAR completion with RGB guidance and uncertainty"},{"location":"other_categories/depth_completion/Sparse and noisy LiDAR completion with RGB guidance and uncertainty/#sparse-and-noisy-lidar-completion-with-rgb-guidance-and-uncertainty","text":"\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e0d\u7b97\u590d\u6742\u7684\u65b9\u5f0f\uff0c\u572820ms\u949f\u5185\u5b8c\u6210\u5bf9 1256 \\times 256 \u5206\u8fa8\u7387\u7684\u56fe\u50cf\u4e0e\u7a00\u758f\u70b9\u4e91\u8fdb\u884c\u56fe\u50cf\u8865\u5168\u3002","title":"Sparse and noisy LiDAR completion with RGB guidance and uncertainty"},{"location":"other_categories/depth_completion/Sparse and noisy LiDAR completion with RGB guidance and uncertainty/#_1","text":"\u505a\u6cd5\u603b\u4f53\u6bd4\u8f83\u76f4\u89c2\uff0c\u9996\u5148RGB\u56fe\u50cf\u4e0e\u7a00\u758f\u7684\u6295\u5f71\u540e\u7684lidar\u6df1\u5ea6\u56fe\u8fdb\u884cconcat,\u8f93\u5165\u5230\u4ee5 ERFNet \u4e3a\u4e3b\u5e72\u7684encoder-decoder\u7f51\u7edc\u4e2d\uff0c(\u9700\u8981\u6ce8\u610f\u7684\u662f\u6839\u636e ERFNet \u7684github\u7f51\u9875\u663e\u793a\uff0c\u5176\u6a21\u578b\u9700\u8981\u79c1\u804a\u624d\u53ef\u83b7\u5f97),\u8f93\u51fa\u4e09\u4e2a\u90e8\u5206\uff0c\u4e00\u4e2a\u662flidar map\u7684\u5c40\u90e8\u6b8b\u5dee,\u4e00\u4e2a\u662f\u5168\u5c40\u6df1\u5ea6\u9884\u6d4b\uff0c\u4e00\u4e2a\u662f\u5168\u5c40\u6df1\u5ea6\u7684\u7f6e\u4fe1\u5ea6\u3002 \u800c\u7a00\u758f\u7684\u6295\u5f71\u540e\u7684Lidar\u6df1\u5ea6\u56fe\u8865\u4e0a\u6b8b\u5dee\u540e\u540c\u65f6\u8f93\u5165\u5230\u5c40\u90e8\u5206\u652f\u4e2d\uff0c\u4f7f\u7528\u6570\u4e2a\u6b8b\u5dee\u8fde\u63a5\u7684 StackedHourGlass \u6a21\u5757,\u518d\u5377\u79ef\u8f93\u51fa\u4e24\u4e2a\u5206\u652f\uff0c\u4e00\u4e2a\u662f\u5c40\u90e8\u6df1\u5ea6\u9884\u6d4b\uff0c\u4e00\u4e2a\u662f\u5c40\u90e8\u6df1\u5ea6\u7684\u7f6e\u4fe1\u5ea6\u3002 \u5168\u5c40\u5206\u652f\u4e0e\u5c40\u90e8\u5206\u652f\uff0c\u5c06\u4e24\u5206\u652f\u7684\u7f6e\u4fe1\u5ea6\u8fde\u63a5\u5e76\u4f7f\u7528\u4f7f\u7528softmax\u5c42\u5f62\u6210\u5206\u522b\u7684\u6743\u91cd\uff0c\u518d\u5c06\u4e24\u8005\u7684\u6df1\u5ea6\u9884\u6d4b\u503c\u52a0\u6743\u6c42\u548c\u5f97\u5230\u3002 \u672c\u6587\u5177\u4f53\u4f7f\u7528\u7684 StackedHourGlass \u6a21\u5757\u5982\u56fe","title":"\u603b\u4f53\u6846\u67b6"},{"location":"other_categories/depth_completion/Sparse and noisy LiDAR completion with RGB guidance and uncertainty/#_2","text":"\u8bad\u7ec3\u987a\u5e8f\u4e0a\uff0c\u4f5c\u8005\u4f7f\u7528pretrained ERFNet \u5148\u5355\u72ec\u5bf9\u4e24\u4e2a\u5206\u652f\u8fdb\u884c\u8bad\u7ec3\uff0c\u7136\u540e\u518d\u52a0\u5165guidance\u90e8\u5206\u4ee5\u53ca\u52a0\u6743\u90e8\u5206\u8fdb\u884c\u7aef\u5230\u7aef\u8bad\u7ec3. \u635f\u5931\u51fd\u6570\u65b9\u9762\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u6240\u8c13focal-MSE Loss\u3002\u6570\u5b66\u8868\u8fbe\u4e3a: \\lambda(\\hat y, y) = \\frac{1}{n} \\sum^n_{i=1}(1+0.05 * epoch * |y_i - \\hat y_i|) * (y_i - \\hat y_i)^2 \u6700\u7ec8\u635f\u5931\u4e3a \\Lambda=w_{1} \\cdot \\lambda\\left(\\hat{y}_{g l o b a l}, y\\right)+w_{2} \\cdot \\lambda\\left(\\hat{y}_{l o c a l}, y\\right)+w_{3} \\cdot \\lambda\\left(\\hat{y}_{o u t}, y\\right) \u5176\u4e2d\u4e09\u4e2a\u53c2\u6570\u5206\u522b\u4e3a0.1, 0.1, 1","title":"\u8bad\u7ec3\u7ec6\u8282"},{"location":"other_categories/depth_completion/depth_pred_before/","text":"Depth Prediction Before Deep Learning \u672c\u6587\u8bb0\u5f55\u51e0\u7bc7\u5728\u6df1\u5ea6\u5b66\u4e60\u65f6\u4ee3\u4e4b\u524d\u7684\u5355\u76ee\u6df1\u5ea6\u76f8\u5173\u7684\u5de5\u4f5c\u3002 Single Image Depth Estimation From Predicted Semantic Labels pdf Semantic Segmentation with MRF MRF\u80fd\u91cf\u5b9a\u4e49\u4e3a: \\mathbf{E}(\\mathbf{L} \\mid \\mathcal{I})=\\sum_{p} \\psi_{p}\\left(L_{p}\\right)+\\lambda \\sum_{p q} \\psi_{p q}\\left(L_{p}, L_{q}\\right) \u5bf9\u4e8e\u5355\u9879\u52bf\u80fd\u9009\u62e9\u7684\u5219\u662f\u4e0e \u8fd9\u7bc7\u6587\u7ae0 \u4e00\u81f4\u768417\u79cd\u5377\u79ef\u6838\u7684\u7279\u5f81\u3002\u8272\u5f69\u7a7a\u95f4\u9009\u62e9 CIE Lab ,\u4e09\u4e2a\u65b9\u5dee\u4e3a1,2,4\u7684\u9ad8\u65af\u6838\u5206\u522b\u7528\u5728\u4e09\u4e2achannel\u4e0a\uff0c\u56db\u4e2aLaplacian Gaussian filters (\u65b9\u5dee\u4e3a1,2,4,8)\u4ec5\u5728L\u9891\u9053\u4e0a\uff0c\u5728x,y\u65b9\u5411\u4e0a\u4ee5\u65b9\u5dee(2, 4)\u5171\u4f5c4\u4e2a\u9ad8\u65af\u4e00\u9636\u5bfc\u7684\u5377\u79ef\u6838(\u4ec5 L\u9891\u9053)\u3002\u517117\u4e2a\u9891\u9053\u3002 Scene Geometry \u5bf9\u6bcf\u4e00\u4e2a p \u70b9\uff0c\u5176\u4e2d g \u4e3a\u56fe\u7247\u4e0a\u540c\u4e00x\u8f74\u4e0a\u6700\u9ad8\u7684\u5730\u9762\u70b9\uff0c b \u70b9\u4e3a\u56fe\u7247\u4e0a\u540c\u4e00x\u8f74\u4e0a\u540c\u4e00instance\u7684\u6700\u4f4e\u70b9\uff0c t \u4e3a\u56fe\u7247\u4e0a\u540c\u4e00x\u8f74\u4e0a\u540c\u4e00instance\u7684\u6700\u9ad8\u70b9\uff0c\u5219\u70b9p\u7684\u6df1\u5ea6\u8303\u56f4\u4e3a: d_{g}\\left(\\frac{r_{g}^{T} e_{3}}{r_{p}^{T} e_{3}}\\right) \\leq d_{p} \\leq d_{g}\\left(\\frac{r_{g}^{T} e_{2}}{r_{b}^{T} e_{2}}\\right)\\left(\\frac{r_{b}^{T} e_{3}}{r_{p}^{T} e_{3}}\\right) \u5bf9\u6bcf\u4e00\u4e2a\u50cf\u7d20\u70b9\uff0c\u4f5c\u8005\u5bf9training set\u4e0a\u6bcf\u4e00\u5f20\u56fe\u6bcf\u4e00\u4e2a\u50cf\u7d20\u70b9\u4f4d\u7f6e(u, v)\u8ba1\u7b97\u4e86\u5176\u5e73\u5747\u7684log-depth.\u540c\u65f6\u7528\u524d\u6587geometric hints\u91cc\u9762\u63d0\u5230\u7684\u51e0\u4e2a\u76f8\u5173pixel\u7684prior depth\u5bf9\u5f53\u524d\u70b9\u6df1\u5ea6\u8fdb\u884c\u4f30\u7b97\uff0c\u4f5c\u4e3a\u7b2c\u4e8c\u4e2aMRF\u7684features\u3002 Learning Depth from Single Monocular Images pdf \u8fd9\u7bc7paper\u4e5f\u662f\u4f7f\u7528MRF\u8fdb\u884c\u5206\u6790\u3002 \u6838\u5fc3\u65b0\u610f\u6709\u4e24\u4e2a\uff0c\u7b2c\u4e00\u4e2a\u662fmulti-scale,\u7b2c\u4e8c\u4e2a\u662f\u8ba1\u7b97\u4e0a\u4e0b\u76f8\u90bb\u7684\u4e24\u4e2afeature\u7684histgram vector\u7684\u5dee\u503c\u6765\u9884\u6d4b\u4e24\u8005\u7684\u6df1\u5ea6\u5dee\u3002","title":"Depth Prediction Before Deep Learning"},{"location":"other_categories/depth_completion/depth_pred_before/#depth-prediction-before-deep-learning","text":"\u672c\u6587\u8bb0\u5f55\u51e0\u7bc7\u5728\u6df1\u5ea6\u5b66\u4e60\u65f6\u4ee3\u4e4b\u524d\u7684\u5355\u76ee\u6df1\u5ea6\u76f8\u5173\u7684\u5de5\u4f5c\u3002","title":"Depth Prediction Before Deep Learning"},{"location":"other_categories/depth_completion/depth_pred_before/#single-image-depth-estimation-from-predicted-semantic-labels","text":"pdf","title":"Single Image Depth Estimation From Predicted Semantic Labels"},{"location":"other_categories/depth_completion/depth_pred_before/#semantic-segmentation-with-mrf","text":"MRF\u80fd\u91cf\u5b9a\u4e49\u4e3a: \\mathbf{E}(\\mathbf{L} \\mid \\mathcal{I})=\\sum_{p} \\psi_{p}\\left(L_{p}\\right)+\\lambda \\sum_{p q} \\psi_{p q}\\left(L_{p}, L_{q}\\right) \u5bf9\u4e8e\u5355\u9879\u52bf\u80fd\u9009\u62e9\u7684\u5219\u662f\u4e0e \u8fd9\u7bc7\u6587\u7ae0 \u4e00\u81f4\u768417\u79cd\u5377\u79ef\u6838\u7684\u7279\u5f81\u3002\u8272\u5f69\u7a7a\u95f4\u9009\u62e9 CIE Lab ,\u4e09\u4e2a\u65b9\u5dee\u4e3a1,2,4\u7684\u9ad8\u65af\u6838\u5206\u522b\u7528\u5728\u4e09\u4e2achannel\u4e0a\uff0c\u56db\u4e2aLaplacian Gaussian filters (\u65b9\u5dee\u4e3a1,2,4,8)\u4ec5\u5728L\u9891\u9053\u4e0a\uff0c\u5728x,y\u65b9\u5411\u4e0a\u4ee5\u65b9\u5dee(2, 4)\u5171\u4f5c4\u4e2a\u9ad8\u65af\u4e00\u9636\u5bfc\u7684\u5377\u79ef\u6838(\u4ec5 L\u9891\u9053)\u3002\u517117\u4e2a\u9891\u9053\u3002","title":"Semantic Segmentation with MRF"},{"location":"other_categories/depth_completion/depth_pred_before/#scene-geometry","text":"\u5bf9\u6bcf\u4e00\u4e2a p \u70b9\uff0c\u5176\u4e2d g \u4e3a\u56fe\u7247\u4e0a\u540c\u4e00x\u8f74\u4e0a\u6700\u9ad8\u7684\u5730\u9762\u70b9\uff0c b \u70b9\u4e3a\u56fe\u7247\u4e0a\u540c\u4e00x\u8f74\u4e0a\u540c\u4e00instance\u7684\u6700\u4f4e\u70b9\uff0c t \u4e3a\u56fe\u7247\u4e0a\u540c\u4e00x\u8f74\u4e0a\u540c\u4e00instance\u7684\u6700\u9ad8\u70b9\uff0c\u5219\u70b9p\u7684\u6df1\u5ea6\u8303\u56f4\u4e3a: d_{g}\\left(\\frac{r_{g}^{T} e_{3}}{r_{p}^{T} e_{3}}\\right) \\leq d_{p} \\leq d_{g}\\left(\\frac{r_{g}^{T} e_{2}}{r_{b}^{T} e_{2}}\\right)\\left(\\frac{r_{b}^{T} e_{3}}{r_{p}^{T} e_{3}}\\right) \u5bf9\u6bcf\u4e00\u4e2a\u50cf\u7d20\u70b9\uff0c\u4f5c\u8005\u5bf9training set\u4e0a\u6bcf\u4e00\u5f20\u56fe\u6bcf\u4e00\u4e2a\u50cf\u7d20\u70b9\u4f4d\u7f6e(u, v)\u8ba1\u7b97\u4e86\u5176\u5e73\u5747\u7684log-depth.\u540c\u65f6\u7528\u524d\u6587geometric hints\u91cc\u9762\u63d0\u5230\u7684\u51e0\u4e2a\u76f8\u5173pixel\u7684prior depth\u5bf9\u5f53\u524d\u70b9\u6df1\u5ea6\u8fdb\u884c\u4f30\u7b97\uff0c\u4f5c\u4e3a\u7b2c\u4e8c\u4e2aMRF\u7684features\u3002","title":"Scene Geometry"},{"location":"other_categories/depth_completion/depth_pred_before/#learning-depth-from-single-monocular-images","text":"pdf \u8fd9\u7bc7paper\u4e5f\u662f\u4f7f\u7528MRF\u8fdb\u884c\u5206\u6790\u3002 \u6838\u5fc3\u65b0\u610f\u6709\u4e24\u4e2a\uff0c\u7b2c\u4e00\u4e2a\u662fmulti-scale,\u7b2c\u4e8c\u4e2a\u662f\u8ba1\u7b97\u4e0a\u4e0b\u76f8\u90bb\u7684\u4e24\u4e2afeature\u7684histgram vector\u7684\u5dee\u503c\u6765\u9884\u6d4b\u4e24\u8005\u7684\u6df1\u5ea6\u5dee\u3002","title":"Learning Depth from Single Monocular Images"},{"location":"other_categories/depth_completion/dorn/","text":"Deep Ordinal Regression Network for Monocular Depth Estimation \u8fd9\u7bc7paper\u65f6\u95f4\u867d\u7136\u6bd4\u8f83\u65e9\uff0c\u4f46\u662f\u662f\u5c5e\u4e8e\u5355\u76ee\u6df1\u5ea6\u4f30\u8ba1\u7684SOTA\u7ed3\u679c\u3002\u91cd\u70b9\u5728\u4e8e\u5982\u4f55\u5bf9\u8de8\u5ea6\u5f88\u5927\u7684\u6df1\u5ea6\u503c\u8fdb\u884c\u56de\u5f52\u8ba1\u7b97\u3002 \u7f51\u7edc\u7ed3\u6784 Ordinal Regression \u635f\u5931\u51fd\u6570\u8ba1\u7b97: \\begin{aligned} \\mathcal{L}(\\chi, \\Theta)=&-\\frac{1}{\\mathcal{N}} \\sum_{w=0}^{W-1} \\sum_{h=0}^{H-1} \\Psi(w, h, \\chi, \\Theta) \\\\ \\Psi(h, w, \\chi, \\Theta)=& \\sum_{k=0}^{l_{(w, h)-1}} \\log \\left(\\mathcal{P}_{(w, h)}^{k}\\right) \\\\ &+\\sum_{k=l_{(w, h)}}^{K-1}\\left(\\log \\left(1-\\mathcal{P}_{(w, h)}^{k}\\right)\\right) \\\\ \\mathcal{P}_{(w, h)}^{k}=& P\\left(\\hat{l}_{(w, h)}>k | \\chi, \\Theta\\right) \\end{aligned} \u63a8\u7406\u65f6\uff1a \\begin{aligned} \\hat{d}_{(w, h)} &=\\frac{t_{\\hat{l}_{(w, h)}}+t_{\\hat{l}_{(w, h)}+1}}{2}-\\xi \\\\ \\hat{l}_{(w, h)} &=\\sum_{k=0}^{K-1} \\eta\\left(\\mathcal{P}_{(w, h)}^{k}>=0.5\\right) \\end{aligned} \u7ffb\u8bd1\u6210\u4e2d\u6587\uff0c\u5c31\u662f\u8bf4\u9996\u5148\u8fd9\u4e2a\u95ee\u9898\u88ab\u8003\u8651\u4e3a\u4e00\u4e2amulti-bin\u5206\u7c7b\u7684\u95ee\u9898\uff0c\u5982\u679c\u7269\u4f53\u5728\u7b2c t \u4e2abin\u91cc\u9762\uff0c\u5219\u524d\u9762t\u4e2a\u8282\u70b9\u7684\u5206\u7c7b\u90fd\u5e94\u8be5\u4e3a\u6b63\uff0c\u63a8\u7406\u7684\u65f6\u5019\u5148\u8ba1\u7b97\u9884\u6d4b\u4e3a\u6b63\u7684\u8282\u70b9\u6709\u591a\u5c11\u4e2a\uff0c\u5224\u65ad\u7269\u4f53\u7684\u6df1\u5ea6\u5728\u54ea\u4e00\u4e2abin\u4e0a\uff0c\u7136\u540e\u8f93\u51fa\u7684target\u503c\u4e3a\u5747\u503c\u3002","title":"Deep Ordinal Regression Network for Monocular Depth Estimation"},{"location":"other_categories/depth_completion/dorn/#deep-ordinal-regression-network-for-monocular-depth-estimation","text":"\u8fd9\u7bc7paper\u65f6\u95f4\u867d\u7136\u6bd4\u8f83\u65e9\uff0c\u4f46\u662f\u662f\u5c5e\u4e8e\u5355\u76ee\u6df1\u5ea6\u4f30\u8ba1\u7684SOTA\u7ed3\u679c\u3002\u91cd\u70b9\u5728\u4e8e\u5982\u4f55\u5bf9\u8de8\u5ea6\u5f88\u5927\u7684\u6df1\u5ea6\u503c\u8fdb\u884c\u56de\u5f52\u8ba1\u7b97\u3002","title":"Deep Ordinal Regression Network for Monocular Depth Estimation"},{"location":"other_categories/depth_completion/dorn/#_1","text":"","title":"\u7f51\u7edc\u7ed3\u6784"},{"location":"other_categories/depth_completion/dorn/#ordinal-regression","text":"\u635f\u5931\u51fd\u6570\u8ba1\u7b97: \\begin{aligned} \\mathcal{L}(\\chi, \\Theta)=&-\\frac{1}{\\mathcal{N}} \\sum_{w=0}^{W-1} \\sum_{h=0}^{H-1} \\Psi(w, h, \\chi, \\Theta) \\\\ \\Psi(h, w, \\chi, \\Theta)=& \\sum_{k=0}^{l_{(w, h)-1}} \\log \\left(\\mathcal{P}_{(w, h)}^{k}\\right) \\\\ &+\\sum_{k=l_{(w, h)}}^{K-1}\\left(\\log \\left(1-\\mathcal{P}_{(w, h)}^{k}\\right)\\right) \\\\ \\mathcal{P}_{(w, h)}^{k}=& P\\left(\\hat{l}_{(w, h)}>k | \\chi, \\Theta\\right) \\end{aligned} \u63a8\u7406\u65f6\uff1a \\begin{aligned} \\hat{d}_{(w, h)} &=\\frac{t_{\\hat{l}_{(w, h)}}+t_{\\hat{l}_{(w, h)}+1}}{2}-\\xi \\\\ \\hat{l}_{(w, h)} &=\\sum_{k=0}^{K-1} \\eta\\left(\\mathcal{P}_{(w, h)}^{k}>=0.5\\right) \\end{aligned} \u7ffb\u8bd1\u6210\u4e2d\u6587\uff0c\u5c31\u662f\u8bf4\u9996\u5148\u8fd9\u4e2a\u95ee\u9898\u88ab\u8003\u8651\u4e3a\u4e00\u4e2amulti-bin\u5206\u7c7b\u7684\u95ee\u9898\uff0c\u5982\u679c\u7269\u4f53\u5728\u7b2c t \u4e2abin\u91cc\u9762\uff0c\u5219\u524d\u9762t\u4e2a\u8282\u70b9\u7684\u5206\u7c7b\u90fd\u5e94\u8be5\u4e3a\u6b63\uff0c\u63a8\u7406\u7684\u65f6\u5019\u5148\u8ba1\u7b97\u9884\u6d4b\u4e3a\u6b63\u7684\u8282\u70b9\u6709\u591a\u5c11\u4e2a\uff0c\u5224\u65ad\u7269\u4f53\u7684\u6df1\u5ea6\u5728\u54ea\u4e00\u4e2abin\u4e0a\uff0c\u7136\u540e\u8f93\u51fa\u7684target\u503c\u4e3a\u5747\u503c\u3002","title":"Ordinal Regression"},{"location":"other_categories/depth_completion/guideNet/","text":"Learning Guided Convolutional Network for Depth Completion \u8fd9\u7bc7\u6587\u7ae0\u57fa\u4e8e Dynamic Filtering Networks \u7684\u7406\u5ff5\u3002 \u603b\u4f53\u7ed3\u6784 \u8f93\u5165\u662fRGB\u56fe\u7247\u4ee5\u53ca\u7a00\u758f\u7684\u6df1\u5ea6\u56fe\uff0c\u6700\u7ec8\u8f93\u51fa\u7684\u662f\u7a20\u5bc6\u7684\u6df1\u5ea6\u56fe\u3002\u6574\u4f53\u7ed3\u6784\u5f88\u7c7b\u4f3c\u4e8e\u57fa\u7840\u7684FPN Guided Convolution Module \u5de6\u56fe\u8868\u8fbe\u4e86\u603b\u4f53\u7684\u601d\u8def\uff0c\u5c31\u662f\u4f7f\u7528RGB image\u7684\u7279\u5f81\u4f5c\u4e3a\u5f15\u5bfc\u5c42\uff0c\u5c40\u90e8\u5730\u751f\u6210\u5377\u79ef\u6838\uff0c\u5bf9\u7a00\u758f\u6df1\u5ea6\u56fe\u8fdb\u884c\u5377\u79ef(\u4e0e DFN \u7684\u7b2c\u4e8c\u79cd\u5b9e\u73b0\u76f8\u4f3c)\u3002 \u4f46\u662f\u8fd9\u79cd\u7c7b\u4f3c\u4e8e\u5c40\u90e8\u5377\u79ef\u7684\u65b9\u5f0f\u5bf9GPU\u663e\u5b58\u6d88\u8017\u5f88\u5927\u3002\u4f5c\u8005\u63d0\u51fa\u6a21\u4effMobile Net\u7684\u601d\u8def\u3002\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528Channel-wise \u5c40\u90e8\u5377\u79ef\uff0c\u7b2c\u4e8c\u9636\u6bb5\u4f7f\u7528Spatial-invariant\u7684\u666e\u901a\u5377\u79ef.","title":"Learning Guided Convolutional Network for Depth Completion"},{"location":"other_categories/depth_completion/guideNet/#learning-guided-convolutional-network-for-depth-completion","text":"\u8fd9\u7bc7\u6587\u7ae0\u57fa\u4e8e Dynamic Filtering Networks \u7684\u7406\u5ff5\u3002","title":"Learning Guided Convolutional Network for Depth Completion"},{"location":"other_categories/depth_completion/guideNet/#_1","text":"\u8f93\u5165\u662fRGB\u56fe\u7247\u4ee5\u53ca\u7a00\u758f\u7684\u6df1\u5ea6\u56fe\uff0c\u6700\u7ec8\u8f93\u51fa\u7684\u662f\u7a20\u5bc6\u7684\u6df1\u5ea6\u56fe\u3002\u6574\u4f53\u7ed3\u6784\u5f88\u7c7b\u4f3c\u4e8e\u57fa\u7840\u7684FPN","title":"\u603b\u4f53\u7ed3\u6784"},{"location":"other_categories/depth_completion/guideNet/#guided-convolution-module","text":"\u5de6\u56fe\u8868\u8fbe\u4e86\u603b\u4f53\u7684\u601d\u8def\uff0c\u5c31\u662f\u4f7f\u7528RGB image\u7684\u7279\u5f81\u4f5c\u4e3a\u5f15\u5bfc\u5c42\uff0c\u5c40\u90e8\u5730\u751f\u6210\u5377\u79ef\u6838\uff0c\u5bf9\u7a00\u758f\u6df1\u5ea6\u56fe\u8fdb\u884c\u5377\u79ef(\u4e0e DFN \u7684\u7b2c\u4e8c\u79cd\u5b9e\u73b0\u76f8\u4f3c)\u3002 \u4f46\u662f\u8fd9\u79cd\u7c7b\u4f3c\u4e8e\u5c40\u90e8\u5377\u79ef\u7684\u65b9\u5f0f\u5bf9GPU\u663e\u5b58\u6d88\u8017\u5f88\u5927\u3002\u4f5c\u8005\u63d0\u51fa\u6a21\u4effMobile Net\u7684\u601d\u8def\u3002\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528Channel-wise \u5c40\u90e8\u5377\u79ef\uff0c\u7b2c\u4e8c\u9636\u6bb5\u4f7f\u7528Spatial-invariant\u7684\u666e\u901a\u5377\u79ef.","title":"Guided Convolution Module"},{"location":"other_categories/object_detection_2D/Associative_Embedding:End-to-End_Learning_for_Joint_Detection_and_Grouping/","text":"Associative Embedding: End-to-End Learning for Joint Detection and Grouping \u8fd9\u7bc7\u8bba\u6587\u5bf9\u6211\u6765\u8bf4\u662f CornerNet \u7684\u524d\u7f6e.\u4e24\u7bc7\u4e5f\u662f\u540c\u4e00\u4e2a\u4f5c\u8005\u3002 Associative Embedding \u7b80\u4ecb \u8fd9\u7bc7\u8bba\u6587\u4f7f\u75281D embedding\uff0c\u76ee\u7684\u662f\u8bad\u7ec3\u7f51\u7edc\u5bf9\u6765\u81ea\u540c\u4e00\u4e2agroup\u7684detection\u8f93\u51fa\u76f8\u4f3c\u7684tags\uff0cdifferent tags for detection\u3002 Stacked Hourglass Architecture hourglass\u7ed3\u6784\u53ef\u4ee5\u5728 \u8fd9\u7bc7\u8bba\u6587 \u770b\u5230\u4e5f\u5728 CornerNet \u8fd9\u7bc7\u8bba\u6587\u7528\u8fc7\uff0c\u5927\u5bb6\u7a0d\u6709\u4e0d\u540c\uff0c\u4e0d\u8fc7\u603b\u4f53\u601d\u8def\u4e00\u81f4\u3002 \u591a\u4eba\u80a2\u4f53\u4f30\u8ba1 \u672c\u6587\u4f7f\u7528\u524d\u9762\u7684backbone\u9884\u6d4b\u6bcf\u4e00\u4e2apixel\u7684detection score for each joint(\"left writst\", \"right shoulder\")\uff0c \u8981\u8fdb\u4e00\u6b65\u5b8c\u6210\u6574\u4e2akeypoint detections\u3002\u5982\u679c\u6709 m \u4e2a\u5173\u8282,\u5219\u8f93\u51fa 2m \u4e2achannel,\u5176\u4e2d m \u4e2a\u4f5c\u4e3adetection\u7684heatmap, m \u4e2a\u4f5c\u4e3agrouping\u7684 tags\u3002 \u6574\u4e2acost: \\begin{aligned} L_{g}(h, T)=& \\frac{1}{N} \\sum_{n} \\sum_{k}\\left(\\bar{h}_{n}-h_{k}\\left(x_{n k},\\right)\\right)^{2} \\\\ &+\\frac{1}{N^{2}} \\sum_{n} \\sum_{n^{\\prime}} \\exp \\left\\{-\\frac{1}{2 \\sigma^{2}}\\left(\\bar{h}_{n}-\\bar{h}_{n^{\\prime}}\\right)^{2}\\right\\} \\end{aligned} \u5176\u4e2d h(x) \u662fpixel x \u5bf9\u5e94\u7684tag value\u3002 T = {(x_{nk})} ,\u5176\u4e2d x_{nk} \u662f\u7b2c n \u4e2a\u4eba\u7684\u7b2c k \u4e2a\u8eab\u4f53\u5173\u8282\u7684pixel\u4f4d\u7f6e. \\bar{h}_{n}=\\frac{1}{K} \\sum_{k} h_{k}\\left(x_{n k}\\right) inference\u65f6\u7684\u6d41\u7a0b \u9996\u5148\u5bf9\u7b2c\u4e00\u4e2a\u5173\u8282\uff0c\u7ed9\u4e00\u4e2a\u9608\u503c\uff0c\u7136\u540e\u505anon-max suppression.\u5f97\u5230\u5404\u4e2a\u4eba\u7269\u7684\u521d\u59cb\u4f30\u8ba1\u3002 \u4e4b\u540e\u5bf9\u5176\u4ed6\u6bcf\u4e00\u4e2a\u5173\u8282\uff0c\u505a\u4e00\u4e2amaximum matching\uff0c\u540c\u65f6\u57fa\u4e8etag value\u4ee5\u53cadetection score\u3002","title":"Associative Embedding: End-to-End Learning for Joint Detection and Grouping"},{"location":"other_categories/object_detection_2D/Associative_Embedding:End-to-End_Learning_for_Joint_Detection_and_Grouping/#associative-embedding-end-to-end-learning-for-joint-detection-and-grouping","text":"\u8fd9\u7bc7\u8bba\u6587\u5bf9\u6211\u6765\u8bf4\u662f CornerNet \u7684\u524d\u7f6e.\u4e24\u7bc7\u4e5f\u662f\u540c\u4e00\u4e2a\u4f5c\u8005\u3002","title":"Associative Embedding: End-to-End Learning for Joint Detection and Grouping"},{"location":"other_categories/object_detection_2D/Associative_Embedding:End-to-End_Learning_for_Joint_Detection_and_Grouping/#associative-embedding","text":"\u8fd9\u7bc7\u8bba\u6587\u4f7f\u75281D embedding\uff0c\u76ee\u7684\u662f\u8bad\u7ec3\u7f51\u7edc\u5bf9\u6765\u81ea\u540c\u4e00\u4e2agroup\u7684detection\u8f93\u51fa\u76f8\u4f3c\u7684tags\uff0cdifferent tags for detection\u3002","title":"Associative Embedding \u7b80\u4ecb"},{"location":"other_categories/object_detection_2D/Associative_Embedding:End-to-End_Learning_for_Joint_Detection_and_Grouping/#stacked-hourglass-architecture","text":"hourglass\u7ed3\u6784\u53ef\u4ee5\u5728 \u8fd9\u7bc7\u8bba\u6587 \u770b\u5230\u4e5f\u5728 CornerNet \u8fd9\u7bc7\u8bba\u6587\u7528\u8fc7\uff0c\u5927\u5bb6\u7a0d\u6709\u4e0d\u540c\uff0c\u4e0d\u8fc7\u603b\u4f53\u601d\u8def\u4e00\u81f4\u3002","title":"Stacked Hourglass Architecture"},{"location":"other_categories/object_detection_2D/Associative_Embedding:End-to-End_Learning_for_Joint_Detection_and_Grouping/#_1","text":"\u672c\u6587\u4f7f\u7528\u524d\u9762\u7684backbone\u9884\u6d4b\u6bcf\u4e00\u4e2apixel\u7684detection score for each joint(\"left writst\", \"right shoulder\")\uff0c \u8981\u8fdb\u4e00\u6b65\u5b8c\u6210\u6574\u4e2akeypoint detections\u3002\u5982\u679c\u6709 m \u4e2a\u5173\u8282,\u5219\u8f93\u51fa 2m \u4e2achannel,\u5176\u4e2d m \u4e2a\u4f5c\u4e3adetection\u7684heatmap, m \u4e2a\u4f5c\u4e3agrouping\u7684 tags\u3002 \u6574\u4e2acost: \\begin{aligned} L_{g}(h, T)=& \\frac{1}{N} \\sum_{n} \\sum_{k}\\left(\\bar{h}_{n}-h_{k}\\left(x_{n k},\\right)\\right)^{2} \\\\ &+\\frac{1}{N^{2}} \\sum_{n} \\sum_{n^{\\prime}} \\exp \\left\\{-\\frac{1}{2 \\sigma^{2}}\\left(\\bar{h}_{n}-\\bar{h}_{n^{\\prime}}\\right)^{2}\\right\\} \\end{aligned} \u5176\u4e2d h(x) \u662fpixel x \u5bf9\u5e94\u7684tag value\u3002 T = {(x_{nk})} ,\u5176\u4e2d x_{nk} \u662f\u7b2c n \u4e2a\u4eba\u7684\u7b2c k \u4e2a\u8eab\u4f53\u5173\u8282\u7684pixel\u4f4d\u7f6e. \\bar{h}_{n}=\\frac{1}{K} \\sum_{k} h_{k}\\left(x_{n k}\\right) inference\u65f6\u7684\u6d41\u7a0b \u9996\u5148\u5bf9\u7b2c\u4e00\u4e2a\u5173\u8282\uff0c\u7ed9\u4e00\u4e2a\u9608\u503c\uff0c\u7136\u540e\u505anon-max suppression.\u5f97\u5230\u5404\u4e2a\u4eba\u7269\u7684\u521d\u59cb\u4f30\u8ba1\u3002 \u4e4b\u540e\u5bf9\u5176\u4ed6\u6bcf\u4e00\u4e2a\u5173\u8282\uff0c\u505a\u4e00\u4e2amaximum matching\uff0c\u540c\u65f6\u57fa\u4e8etag value\u4ee5\u53cadetection score\u3002","title":"\u591a\u4eba\u80a2\u4f53\u4f30\u8ba1"},{"location":"other_categories/object_detection_2D/BoFDetection/","text":"Bag of Freebies for Training Object Detection Neural Networks \u8fd9\u7bc7\u8bba\u6587\u7cfb\u7edf\u6027\u5730\u603b\u7ed3\u6216\u63d0\u51fa\u4e86\u4e00\u7cfb\u5217\u7684\u63d0\u5347\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u7684\u4e00\u4e9b\u8bad\u7ec3\u6280\u5de7\uff0c\u4e0d\u66f4\u6539\u7f51\u7edc\u3001\u66f4\u6539inference\u65f6\u95f4\u7684\u524d\u63d0\u4e0b\uff0c\u80fd\u663e\u8457\u63d0\u5347\u8bad\u7ec3\u7ed3\u679c\u3002\u672c\u7efc\u8ff0\u5728review\u8fd9\u7bc7\u8bba\u6587\u7684\u540c\u65f6\u641c\u96c6\u4e86\u5404\u4e2a\u6a21\u5757\u5178\u578b\u7684pytorch\u5b9e\u73b0. Image Mixup \u5c06\u4e24\u5f20\u56fe\u53eacrop\u4e0d\u6539\u53d8aspect ratio\u5730\u878d\u5408\uff0c\u76ee\u6807\u5e8f\u5217\u5219concat\u5728\u4e00\u8d77 \u5176\u4e2d\u878d\u5408\u7684\u53c2\u6570 \\alpha, \\beta \u7531\u4e00\u4e2a \\Beta \u5206\u5e03\u8fdb\u884c\u62bd\u6837\u3002 \u5173\u4e8eMixup, \u5176\u524d\u7f6e\u8bba\u6587\u6709\u5bf9\u5e94\u7684\u5f88\u7b80\u6d01\u7684 \u4ee3\u7801\u5b9e\u73b0 Classification Head Label Smoothing \u8fd9\u4e2aidea\u6e90\u81ea\u4e8e Inception-V3 \u4e5f\u5c31\u662f\u5f31\u5316CrossEntropy\u4e2d\u7684target q_{i}=\\left\\{\\begin{array}{ll}{1-\\varepsilon} & {\\text { if } i=y} \\\\ {\\varepsilon /(K-1)} & {\\text { otherwise }}\\end{array}\\right. \u4e00\u4e2a\u5178\u578b\u7684pytorch\u5b9e\u73b0\u5728\u8fd9\u91cc \u6570\u636e\u589e\u5f3a \u6570\u636e\u589e\u5f3a\u4e3b\u8981\u5305\u62ec\u4e24\u79cd \u968f\u673a\u51e0\u4f55\u53d8\u6362\uff0c\u5305\u62ec\u968f\u673a\u88c1\u5207\uff0c\u968f\u673a\u6269\u5927\uff0c\u6c34\u5e73\u7ffb\u8f6c\u4ee5\u53ca\u968f\u673aresize \u968f\u673a\u8272\u5f69\u6296\u52a8\uff0c\u5305\u62ec\u4eae\u5ea6\u3001\u8272\u76f8\u3001\u9971\u548c\u5ea6\u548c\u5bf9\u6bd4\u5ea6\u3002 \u4f5c\u8005\u53d1\u73b0one-stage\u68c0\u6d4b\u53d7\u968f\u673a\u51e0\u4f55\u53d8\u6362\u6bd4\u8f83\u654f\u611f\uff0c\u56e0\u800c\u9700\u8981\u4f7f\u7528\u968f\u673a\u51e0\u4f55\u53d8\u6362\u6765\u8fdb\u884c\u6570\u636e\u589e\u5f3a\uff0c\u800ctwo-stage\u68c0\u6d4b\u7531\u4e8eRoIAlign\u6216Pooling\u7684\u6027\u8d28\uff0c\u5bf9\u968f\u673a\u51e0\u4f55\u53d8\u6362\u7684\u654f\u611f\u5ea6\u4e0d\u5927\uff0c\u56e0\u800c\u51e0\u4f55\u53d8\u6362\u6570\u636e\u589e\u5f3a\u5bf9\u5176\u5f71\u54cd\u4e0d\u5927\u3002 \u5b66\u4e60\u7387\u8c03\u6574 \u7ecf\u8fc7\u5927\u91cf\u5b9e\u9a8c\u4f5c\u8005\u53d1\u73b0cosine\u53d8\u5316\u5f88\u597d\uff0c\u540c\u65f6\u8981\u6ce8\u610f\u7684\u662fwarmup learning rate\u5bf9YoLO\u7684\u8bad\u7ec3\u81f3\u5173\u91cd\u8981\u3002 stack-overflow\u4e0a\u9762\u6709\u5bf9\u8fd9\u4e2awarmup\u5728\u673a\u5668\u5b66\u4e60\u65b9\u9762\u7684\u4e00\u4e2a\u76f4\u89c9\u6027\u7684 \u89e3\u7b54 \u8bfb\u61c2\u4e0a\u8ff0\u89e3\u7b54\u4e4b\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528github\u4e0a\u5bf9Warm-up learning rate\u7684 pytorch\u590d\u73b0 Synchronized Batch Normalization \u7531\u4e8ebatch-size\u6bd4\u8f83\u5c0f\uff0c\u6211\u4eec\u9700\u8981synchronized batch-norm\u6765\u8de8GPU\u8bad\u7ec3.\u672c\u8d28\u4e0a\u6765\u8bf4\u5c31\u662f\u5f3a\u5236\u5728batchnorm\u7684\u65f6\u5019\u7b49\u5f85\u6240\u6709\u7684GPU\u4e00\u8d77\u8ba1\u7b97\uff0c\u5e76\u4e14\u5171\u7528\u540c\u4e00\u4e2a\u5f53\u524d\u7684\u5747\u503c\u4e0e\u65b9\u5dee\u3002 \u4e00\u4e2a\u5178\u578b\u7684pytorch\u5b9e\u73b0\u5728\u8fd9\u91cc \u968f\u673a\u5f62\u72b6\u8bad\u7ec3 \u5bf9\u4e8eone-stage\u7684\u7f51\u7edc\uff0c\u4f5c\u8005\u63d0\u51fa\u4fee\u6539\u8f93\u5165\u56fe\u7247\u7684\u5f62\u72b6\uff0c\u968f\u673a\u8f93\u5165\u6765\u8bad\u7ec3 \u4ee5\u4e0a\u6240\u6709tricks\u90fd\u5728\u57fa\u4e8eMXNET\u7684gluon-CV\u4e0a\u6709\u590d\u73b0\uff0c","title":"Bag of Freebies for Training Object Detection Neural Networks"},{"location":"other_categories/object_detection_2D/BoFDetection/#bag-of-freebies-for-training-object-detection-neural-networks","text":"\u8fd9\u7bc7\u8bba\u6587\u7cfb\u7edf\u6027\u5730\u603b\u7ed3\u6216\u63d0\u51fa\u4e86\u4e00\u7cfb\u5217\u7684\u63d0\u5347\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u7684\u4e00\u4e9b\u8bad\u7ec3\u6280\u5de7\uff0c\u4e0d\u66f4\u6539\u7f51\u7edc\u3001\u66f4\u6539inference\u65f6\u95f4\u7684\u524d\u63d0\u4e0b\uff0c\u80fd\u663e\u8457\u63d0\u5347\u8bad\u7ec3\u7ed3\u679c\u3002\u672c\u7efc\u8ff0\u5728review\u8fd9\u7bc7\u8bba\u6587\u7684\u540c\u65f6\u641c\u96c6\u4e86\u5404\u4e2a\u6a21\u5757\u5178\u578b\u7684pytorch\u5b9e\u73b0.","title":"Bag of Freebies for Training Object Detection Neural Networks"},{"location":"other_categories/object_detection_2D/BoFDetection/#image-mixup","text":"\u5c06\u4e24\u5f20\u56fe\u53eacrop\u4e0d\u6539\u53d8aspect ratio\u5730\u878d\u5408\uff0c\u76ee\u6807\u5e8f\u5217\u5219concat\u5728\u4e00\u8d77 \u5176\u4e2d\u878d\u5408\u7684\u53c2\u6570 \\alpha, \\beta \u7531\u4e00\u4e2a \\Beta \u5206\u5e03\u8fdb\u884c\u62bd\u6837\u3002 \u5173\u4e8eMixup, \u5176\u524d\u7f6e\u8bba\u6587\u6709\u5bf9\u5e94\u7684\u5f88\u7b80\u6d01\u7684 \u4ee3\u7801\u5b9e\u73b0","title":"Image Mixup"},{"location":"other_categories/object_detection_2D/BoFDetection/#classification-head-label-smoothing","text":"\u8fd9\u4e2aidea\u6e90\u81ea\u4e8e Inception-V3 \u4e5f\u5c31\u662f\u5f31\u5316CrossEntropy\u4e2d\u7684target q_{i}=\\left\\{\\begin{array}{ll}{1-\\varepsilon} & {\\text { if } i=y} \\\\ {\\varepsilon /(K-1)} & {\\text { otherwise }}\\end{array}\\right. \u4e00\u4e2a\u5178\u578b\u7684pytorch\u5b9e\u73b0\u5728\u8fd9\u91cc","title":"Classification Head Label Smoothing"},{"location":"other_categories/object_detection_2D/BoFDetection/#_1","text":"\u6570\u636e\u589e\u5f3a\u4e3b\u8981\u5305\u62ec\u4e24\u79cd \u968f\u673a\u51e0\u4f55\u53d8\u6362\uff0c\u5305\u62ec\u968f\u673a\u88c1\u5207\uff0c\u968f\u673a\u6269\u5927\uff0c\u6c34\u5e73\u7ffb\u8f6c\u4ee5\u53ca\u968f\u673aresize \u968f\u673a\u8272\u5f69\u6296\u52a8\uff0c\u5305\u62ec\u4eae\u5ea6\u3001\u8272\u76f8\u3001\u9971\u548c\u5ea6\u548c\u5bf9\u6bd4\u5ea6\u3002 \u4f5c\u8005\u53d1\u73b0one-stage\u68c0\u6d4b\u53d7\u968f\u673a\u51e0\u4f55\u53d8\u6362\u6bd4\u8f83\u654f\u611f\uff0c\u56e0\u800c\u9700\u8981\u4f7f\u7528\u968f\u673a\u51e0\u4f55\u53d8\u6362\u6765\u8fdb\u884c\u6570\u636e\u589e\u5f3a\uff0c\u800ctwo-stage\u68c0\u6d4b\u7531\u4e8eRoIAlign\u6216Pooling\u7684\u6027\u8d28\uff0c\u5bf9\u968f\u673a\u51e0\u4f55\u53d8\u6362\u7684\u654f\u611f\u5ea6\u4e0d\u5927\uff0c\u56e0\u800c\u51e0\u4f55\u53d8\u6362\u6570\u636e\u589e\u5f3a\u5bf9\u5176\u5f71\u54cd\u4e0d\u5927\u3002","title":"\u6570\u636e\u589e\u5f3a"},{"location":"other_categories/object_detection_2D/BoFDetection/#_2","text":"\u7ecf\u8fc7\u5927\u91cf\u5b9e\u9a8c\u4f5c\u8005\u53d1\u73b0cosine\u53d8\u5316\u5f88\u597d\uff0c\u540c\u65f6\u8981\u6ce8\u610f\u7684\u662fwarmup learning rate\u5bf9YoLO\u7684\u8bad\u7ec3\u81f3\u5173\u91cd\u8981\u3002 stack-overflow\u4e0a\u9762\u6709\u5bf9\u8fd9\u4e2awarmup\u5728\u673a\u5668\u5b66\u4e60\u65b9\u9762\u7684\u4e00\u4e2a\u76f4\u89c9\u6027\u7684 \u89e3\u7b54 \u8bfb\u61c2\u4e0a\u8ff0\u89e3\u7b54\u4e4b\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528github\u4e0a\u5bf9Warm-up learning rate\u7684 pytorch\u590d\u73b0","title":"\u5b66\u4e60\u7387\u8c03\u6574"},{"location":"other_categories/object_detection_2D/BoFDetection/#synchronized-batch-normalization","text":"\u7531\u4e8ebatch-size\u6bd4\u8f83\u5c0f\uff0c\u6211\u4eec\u9700\u8981synchronized batch-norm\u6765\u8de8GPU\u8bad\u7ec3.\u672c\u8d28\u4e0a\u6765\u8bf4\u5c31\u662f\u5f3a\u5236\u5728batchnorm\u7684\u65f6\u5019\u7b49\u5f85\u6240\u6709\u7684GPU\u4e00\u8d77\u8ba1\u7b97\uff0c\u5e76\u4e14\u5171\u7528\u540c\u4e00\u4e2a\u5f53\u524d\u7684\u5747\u503c\u4e0e\u65b9\u5dee\u3002 \u4e00\u4e2a\u5178\u578b\u7684pytorch\u5b9e\u73b0\u5728\u8fd9\u91cc","title":"Synchronized Batch Normalization"},{"location":"other_categories/object_detection_2D/BoFDetection/#_3","text":"\u5bf9\u4e8eone-stage\u7684\u7f51\u7edc\uff0c\u4f5c\u8005\u63d0\u51fa\u4fee\u6539\u8f93\u5165\u56fe\u7247\u7684\u5f62\u72b6\uff0c\u968f\u673a\u8f93\u5165\u6765\u8bad\u7ec3 \u4ee5\u4e0a\u6240\u6709tricks\u90fd\u5728\u57fa\u4e8eMXNET\u7684gluon-CV\u4e0a\u6709\u590d\u73b0\uff0c","title":"\u968f\u673a\u5f62\u72b6\u8bad\u7ec3"},{"location":"other_categories/object_detection_2D/CPN/","text":"Corner Proposal Network for Anchor-free, Two-stage Object Detection \u672c\u6587\u7684\u4f5c\u8005\u662f\u57fa\u4e8e CornetNet \u5199\u51fa CenterNet \u7684Kaiwen Duan. Main Motivation \u4f5c\u8005\u7ed9\u51fa\u4e00\u4e9b\u4f8b\u5b50\u5e76\u4e14\u4ece\u76f4\u89c9\u4e0a\u6307\u51fa Anchor-based \u7b97\u6cd5\u5bf9\u4e8e\u5f62\u72b6\u590d\u6742\u7684\u7269\u4f53\u6216\u8005\u957f\u5bbd\u6bd4\u6bd4\u8f83\u6781\u7aef\u7684\u7269\u4f53\u53ec\u56de\u7387\u6bd4\u8f83\u4f4e\u3002 Anchor-free \u7b97\u6cd5\u5bb9\u6613\u4ea7\u751f\u5047\u9633\u6837\u672c\uff0c\u5c24\u5176\u662f\u5bb9\u6613\u9519\u8bef\u5730\u5c06\u4e0d\u76f8\u5173\u7684keypoints\u5206\u5728\u4e00\u8d77\u3002 \u4f5c\u8005\u60f3\u51fa\u4e86\u4e00\u4e2atwo-stage\u7684\u65b9\u6848\u878d\u5408\u4e24\u8005\u7684\u601d\u8def\u3002 Architecture \u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528CornerNet\u9884\u6d4b\u89d2\u70b9\uff0c\u5c06\u540c\u7c7b\u7684\u5de6\u4e0a\u70b9\u548c\u53f3\u4e0b\u70b9\u5339\u914d\uff0c\u4ea7\u751f\u5927\u91cf\u7684proposals\u3002 \u7b2c\u4e8c\u9636\u6bb5\u9996\u5148\u5c06\u6bcf\u4e00\u4e2a\u5339\u914d\u5f97\u5230\u7684detector, RoIAlign\u63d0\u53d6\u6846\u5185\u7684\u7279\u5f81\uff0c\u5148\u4f7f\u7528 Focal Loss \u76d1\u7763\u4e00\u4e2a\u8f7b\u91cf\u7684\u4e8c\u5206\u7c7b\u5206\u7c7b\u5668\u3002 \u7136\u540efilter\u6389 objectness\u6bd4\u8f83\u4f4e\u7684\u7269\u4f53\u4e4b\u540e\uff0c\u518d\u4f7f\u7528\u4e00\u4e2a\u66f4\u5927\u7684\u5206\u7c7b\u5668\uff0c\u91cd\u65b0\u786e\u5b9a\u8fd9\u4e2a\u6846\u7684\u5206\u7c7b\u3002 \u6ce8\u610f\u672c\u6587(or reviewers)\u89c9\u5f97\u8fd9\u7bc7paper\u7684\u601d\u8def\u548cDeNet\u5f88\u50cf\uff0c\u4f46\u662f\u672c\u6587\u5728\u6d88\u9664\u8d1f\u6837\u672c\u7684\u6548\u7387\u4e0a\u505a\u7684\u66f4\u597d\uff0c \u6587\u7ae0 \u4e0e \u4ee3\u7801 \u7686\u5f00\u653e\uff0c\u4e0d\u8fc7\u662f\u57fa\u4e8etheano\u7684\u3002","title":"Corner Proposal Network for Anchor-free, Two-stage Object Detection"},{"location":"other_categories/object_detection_2D/CPN/#corner-proposal-network-for-anchor-free-two-stage-object-detection","text":"\u672c\u6587\u7684\u4f5c\u8005\u662f\u57fa\u4e8e CornetNet \u5199\u51fa CenterNet \u7684Kaiwen Duan.","title":"Corner Proposal Network for Anchor-free, Two-stage Object Detection"},{"location":"other_categories/object_detection_2D/CPN/#main-motivation","text":"\u4f5c\u8005\u7ed9\u51fa\u4e00\u4e9b\u4f8b\u5b50\u5e76\u4e14\u4ece\u76f4\u89c9\u4e0a\u6307\u51fa Anchor-based \u7b97\u6cd5\u5bf9\u4e8e\u5f62\u72b6\u590d\u6742\u7684\u7269\u4f53\u6216\u8005\u957f\u5bbd\u6bd4\u6bd4\u8f83\u6781\u7aef\u7684\u7269\u4f53\u53ec\u56de\u7387\u6bd4\u8f83\u4f4e\u3002 Anchor-free \u7b97\u6cd5\u5bb9\u6613\u4ea7\u751f\u5047\u9633\u6837\u672c\uff0c\u5c24\u5176\u662f\u5bb9\u6613\u9519\u8bef\u5730\u5c06\u4e0d\u76f8\u5173\u7684keypoints\u5206\u5728\u4e00\u8d77\u3002 \u4f5c\u8005\u60f3\u51fa\u4e86\u4e00\u4e2atwo-stage\u7684\u65b9\u6848\u878d\u5408\u4e24\u8005\u7684\u601d\u8def\u3002","title":"Main Motivation"},{"location":"other_categories/object_detection_2D/CPN/#architecture","text":"\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528CornerNet\u9884\u6d4b\u89d2\u70b9\uff0c\u5c06\u540c\u7c7b\u7684\u5de6\u4e0a\u70b9\u548c\u53f3\u4e0b\u70b9\u5339\u914d\uff0c\u4ea7\u751f\u5927\u91cf\u7684proposals\u3002 \u7b2c\u4e8c\u9636\u6bb5\u9996\u5148\u5c06\u6bcf\u4e00\u4e2a\u5339\u914d\u5f97\u5230\u7684detector, RoIAlign\u63d0\u53d6\u6846\u5185\u7684\u7279\u5f81\uff0c\u5148\u4f7f\u7528 Focal Loss \u76d1\u7763\u4e00\u4e2a\u8f7b\u91cf\u7684\u4e8c\u5206\u7c7b\u5206\u7c7b\u5668\u3002 \u7136\u540efilter\u6389 objectness\u6bd4\u8f83\u4f4e\u7684\u7269\u4f53\u4e4b\u540e\uff0c\u518d\u4f7f\u7528\u4e00\u4e2a\u66f4\u5927\u7684\u5206\u7c7b\u5668\uff0c\u91cd\u65b0\u786e\u5b9a\u8fd9\u4e2a\u6846\u7684\u5206\u7c7b\u3002 \u6ce8\u610f\u672c\u6587(or reviewers)\u89c9\u5f97\u8fd9\u7bc7paper\u7684\u601d\u8def\u548cDeNet\u5f88\u50cf\uff0c\u4f46\u662f\u672c\u6587\u5728\u6d88\u9664\u8d1f\u6837\u672c\u7684\u6548\u7387\u4e0a\u505a\u7684\u66f4\u597d\uff0c \u6587\u7ae0 \u4e0e \u4ee3\u7801 \u7686\u5f00\u653e\uff0c\u4e0d\u8fc7\u662f\u57fa\u4e8etheano\u7684\u3002","title":"Architecture"},{"location":"other_categories/object_detection_2D/CenterNet:_Keypoint_Triplets_for_Object_Detection/","text":"CenterNet: Keypoint Triplets for Object Detection CenterNet\u4e5f\u5c31\u662f\u901a\u8fc7\u8f93\u51fa\u6bcf\u4e00\u4e2aobject\u4e3a\u5de6\u4e0a\u89d2\u3001\u53f3\u4e0a\u89d2\u4e0e\u4e2d\u5fc3\u70b9\u7684\u4e00\u4e2atriplet,\u8fd9\u4e2a\u601d\u8def\u6e90\u81ea\u4e8e CornerNet \u3002 \u603b\u4f53\u7ed3\u6784\u4e0epipeline \u4e0eCornerNet\u76f8\u4f3c\u7684\uff0cbackbone\u7684\u9009\u62e9\u4e5f\u662f stacked hourglass \u7b2c\u4e00\u5206\u652f\u7ecf\u8fc7\u65b0\u7684Cascade Corner Pooling(\u65b0\u7684\u64cd\u4f5c)\u5f97\u5230Corner Heatmaps\u5e76\u901a\u8fc7 associative embedding \u5f97\u5230\u521d\u59cb2D\u6846\u3002 \u7b2c\u4e8c\u5206\u652f\u7ecf\u8fc7Center Pooling\u5f97\u5230Center Heatmap\u3002 \u6700\u540e\u62fc\u5728\u4e00\u8d77\u5f97\u5230\u8f93\u51fa\u3002 \u878d\u5408\u68c0\u6d4bkeypoints \u7b97\u6cd5 1. \u9009\u62e9top-k\u4e2a\u4e2d\u5fc3keypoints 2. \u4f7f\u7528\u5bf9\u5e94offset\u6295\u5f71\u5230\u8f93\u5165\u56fe\u7247\u4e2d 3. \u5bf9\u6bcf\u4e00\u4e2acorner heatmap\u8f93\u51fa\u76842D box\uff0c\u67e5\u627e\u6709\u4e2d\u5fc3\u70b9\u662f\u5426\u5728\u4e2d\u5fc3\u533a\u57df 4. \u5982\u679c\u6709\u4e2d\u5fc3\u70b9\u5728\u4e2d\u5fc3\u533a\u57df\uff0c\u4fdd\u7559\u8fd9\u4e2a\u6846 \u5bf9\u4e2d\u5fc3\u533a\u57df\u7684\u5b9a\u4e49\uff1a \u6ee1\u8db3: \\left\\{\\begin{array}{l}{\\operatorname{ct} 1_{x}=\\frac{(n+1) \\operatorname{tl}_{x}+(n-1) \\operatorname{br}_{x}}{2 n}} \\\\ {\\operatorname{ct} l_{y}=\\frac{(n+1) \\operatorname{tl}_{y}+(n-1) \\operatorname{br}_{y}}{2 n}} \\\\ {\\operatorname{cbr}_{x}=\\frac{\\left.(n-1) \\operatorname{tl}\\right|_{x}+(n+1) \\operatorname{br}_{x}}{2 n}} \\\\ {\\operatorname{cbr}_{y}=\\frac{(n-1) \\operatorname{tl}_{y}+(n+1) \\operatorname{br}_{y}}{2 n}}\\end{array}\\right. \u672c\u6587\u4e3b\u8981\u6307\u4ee3 n \u4e3a3\u548c5,\u5206\u522b\u5bf9\u5e94scale\u5c0f\u4e8e\u548c\u5927\u4e8e150\u76842Dbox\u3002 Center Pooling \u4e0e Cascade Corner Pooling \u7b80\u5355\u6765\u8bf4\uff0cCenter Pooling\u7684\u7b97\u6cd5\u5c31\u662f\u53d6\u540c\u884c\u3001\u540c\u5217\u7684\u6700\u5927\u503c\u5e76\u7d2f\u52a0\u3002Cascade Corner Pooling\u7684\u7b97\u6cd5\u662f\uff0c\u53d6\u540c\u884c\u3001\u540c\u5217\u7684\u6700\u5927\u503c\uff0c\u518d\u5728\u5bf9\u5e94\u7684\u53d6\u6700\u503c\u7684\u70b9\u5bfb\u627e\u540c\u5217\u3001\u540c\u884c(\u9519\u5f00)\u7684\u6700\u5927\u503c\uff0c\u8f93\u51fa\u4e3a4\u4e2a\u70b9\u7684\u7d2f\u52a0\u3002 \u53ef\u89c6\u5316\u663e\u793a\u5982\u56fe \u90fd\u53ef\u4ee5\u7528 Corner Pooling\u5b9e\u73b0 \u3002\u5982\u56fe","title":"CenterNet: Keypoint Triplets for Object Detection"},{"location":"other_categories/object_detection_2D/CenterNet:_Keypoint_Triplets_for_Object_Detection/#centernet-keypoint-triplets-for-object-detection","text":"CenterNet\u4e5f\u5c31\u662f\u901a\u8fc7\u8f93\u51fa\u6bcf\u4e00\u4e2aobject\u4e3a\u5de6\u4e0a\u89d2\u3001\u53f3\u4e0a\u89d2\u4e0e\u4e2d\u5fc3\u70b9\u7684\u4e00\u4e2atriplet,\u8fd9\u4e2a\u601d\u8def\u6e90\u81ea\u4e8e CornerNet \u3002","title":"CenterNet: Keypoint Triplets for Object Detection"},{"location":"other_categories/object_detection_2D/CenterNet:_Keypoint_Triplets_for_Object_Detection/#pipeline","text":"\u4e0eCornerNet\u76f8\u4f3c\u7684\uff0cbackbone\u7684\u9009\u62e9\u4e5f\u662f stacked hourglass \u7b2c\u4e00\u5206\u652f\u7ecf\u8fc7\u65b0\u7684Cascade Corner Pooling(\u65b0\u7684\u64cd\u4f5c)\u5f97\u5230Corner Heatmaps\u5e76\u901a\u8fc7 associative embedding \u5f97\u5230\u521d\u59cb2D\u6846\u3002 \u7b2c\u4e8c\u5206\u652f\u7ecf\u8fc7Center Pooling\u5f97\u5230Center Heatmap\u3002 \u6700\u540e\u62fc\u5728\u4e00\u8d77\u5f97\u5230\u8f93\u51fa\u3002","title":"\u603b\u4f53\u7ed3\u6784\u4e0epipeline"},{"location":"other_categories/object_detection_2D/CenterNet:_Keypoint_Triplets_for_Object_Detection/#keypoints","text":"\u7b97\u6cd5 1. \u9009\u62e9top-k\u4e2a\u4e2d\u5fc3keypoints 2. \u4f7f\u7528\u5bf9\u5e94offset\u6295\u5f71\u5230\u8f93\u5165\u56fe\u7247\u4e2d 3. \u5bf9\u6bcf\u4e00\u4e2acorner heatmap\u8f93\u51fa\u76842D box\uff0c\u67e5\u627e\u6709\u4e2d\u5fc3\u70b9\u662f\u5426\u5728\u4e2d\u5fc3\u533a\u57df 4. \u5982\u679c\u6709\u4e2d\u5fc3\u70b9\u5728\u4e2d\u5fc3\u533a\u57df\uff0c\u4fdd\u7559\u8fd9\u4e2a\u6846 \u5bf9\u4e2d\u5fc3\u533a\u57df\u7684\u5b9a\u4e49\uff1a \u6ee1\u8db3: \\left\\{\\begin{array}{l}{\\operatorname{ct} 1_{x}=\\frac{(n+1) \\operatorname{tl}_{x}+(n-1) \\operatorname{br}_{x}}{2 n}} \\\\ {\\operatorname{ct} l_{y}=\\frac{(n+1) \\operatorname{tl}_{y}+(n-1) \\operatorname{br}_{y}}{2 n}} \\\\ {\\operatorname{cbr}_{x}=\\frac{\\left.(n-1) \\operatorname{tl}\\right|_{x}+(n+1) \\operatorname{br}_{x}}{2 n}} \\\\ {\\operatorname{cbr}_{y}=\\frac{(n-1) \\operatorname{tl}_{y}+(n+1) \\operatorname{br}_{y}}{2 n}}\\end{array}\\right. \u672c\u6587\u4e3b\u8981\u6307\u4ee3 n \u4e3a3\u548c5,\u5206\u522b\u5bf9\u5e94scale\u5c0f\u4e8e\u548c\u5927\u4e8e150\u76842Dbox\u3002","title":"\u878d\u5408\u68c0\u6d4bkeypoints"},{"location":"other_categories/object_detection_2D/CenterNet:_Keypoint_Triplets_for_Object_Detection/#center-pooling-cascade-corner-pooling","text":"\u7b80\u5355\u6765\u8bf4\uff0cCenter Pooling\u7684\u7b97\u6cd5\u5c31\u662f\u53d6\u540c\u884c\u3001\u540c\u5217\u7684\u6700\u5927\u503c\u5e76\u7d2f\u52a0\u3002Cascade Corner Pooling\u7684\u7b97\u6cd5\u662f\uff0c\u53d6\u540c\u884c\u3001\u540c\u5217\u7684\u6700\u5927\u503c\uff0c\u518d\u5728\u5bf9\u5e94\u7684\u53d6\u6700\u503c\u7684\u70b9\u5bfb\u627e\u540c\u5217\u3001\u540c\u884c(\u9519\u5f00)\u7684\u6700\u5927\u503c\uff0c\u8f93\u51fa\u4e3a4\u4e2a\u70b9\u7684\u7d2f\u52a0\u3002 \u53ef\u89c6\u5316\u663e\u793a\u5982\u56fe \u90fd\u53ef\u4ee5\u7528 Corner Pooling\u5b9e\u73b0 \u3002\u5982\u56fe","title":"Center Pooling \u4e0e Cascade Corner Pooling"},{"location":"other_categories/object_detection_2D/CornerNet-Lite_Efficient_Keypoint_Based_Object_Detection/","text":"CornerNet-Lite: Efficient Keypoint Based Object Detection \u8fd9\u7bc7\u8bba\u6587\u5728\u8fdb\u884cobject detection\u7684\u65f6\u5019\uff0c\u4f7f\u7528\u7684\u662f\u57fa\u4e8ekeypoint\u7684\u65b9\u6cd5\u800c\u4e0d\u662f\u57fa\u4e8eproposal\u7684\u65b9\u6cd5\u3002\u5efa\u8bae\u5148\u9605\u8bfb \u8fd9\u7bc7\u8bba\u6587 \u7f51\u7edc\u7ed3\u6784 \u4f7f\u7528attention map\u9884\u6d4b\u4e00\u7cfb\u5217\u4e0d\u540cscale\u7684keypoint\uff0c\u5728\u8fd9\u4e2akeypoint\u5468\u56f4crop\u51fa\u4e00\u5b9a\u91cf\u7684\u65b9\u5757\u56fe\uff0c\u8fdb\u884c\u5206\u7c7b\u3001\u6c47\u603b\uff0c\u7136\u540e\u8fdb\u884cNMS\u3002","title":"CornerNet-Lite: Efficient Keypoint Based Object Detection"},{"location":"other_categories/object_detection_2D/CornerNet-Lite_Efficient_Keypoint_Based_Object_Detection/#cornernet-lite-efficient-keypoint-based-object-detection","text":"\u8fd9\u7bc7\u8bba\u6587\u5728\u8fdb\u884cobject detection\u7684\u65f6\u5019\uff0c\u4f7f\u7528\u7684\u662f\u57fa\u4e8ekeypoint\u7684\u65b9\u6cd5\u800c\u4e0d\u662f\u57fa\u4e8eproposal\u7684\u65b9\u6cd5\u3002\u5efa\u8bae\u5148\u9605\u8bfb \u8fd9\u7bc7\u8bba\u6587","title":"CornerNet-Lite: Efficient Keypoint Based Object Detection"},{"location":"other_categories/object_detection_2D/CornerNet-Lite_Efficient_Keypoint_Based_Object_Detection/#_1","text":"\u4f7f\u7528attention map\u9884\u6d4b\u4e00\u7cfb\u5217\u4e0d\u540cscale\u7684keypoint\uff0c\u5728\u8fd9\u4e2akeypoint\u5468\u56f4crop\u51fa\u4e00\u5b9a\u91cf\u7684\u65b9\u5757\u56fe\uff0c\u8fdb\u884c\u5206\u7c7b\u3001\u6c47\u603b\uff0c\u7136\u540e\u8fdb\u884cNMS\u3002","title":"\u7f51\u7edc\u7ed3\u6784"},{"location":"other_categories/object_detection_2D/CornerNet_Detecting_Objects_as_Paired_Keypoints/","text":"CornerNet: Detecting Objects as Paired Keypoints \u8fd9\u7bc7\u6587\u7ae0\u662f \u8fd9\u7bc7\u6587\u7ae0 \u7684\u524d\u7f6e,\u5b9e\u9645\u4e0a\u4e5f\u786e\u5b9e\u6709\u66f4\u591a\u7684\u5185\u5bb9,\u5728\u5177\u4f53\u5b9e\u73b0\u4e0a\u6709\u533a\u522b\u3002 \u8fd9\u7bc7\u6587\u7ae0\u7ed9\u51fa\u7684\u601d\u8def\u662f\uff0c\u8ba9\u795e\u7ecf\u7f51\u7edc\u5206\u522b\u7ed9\u51fa\u67d0\u4e00\u7c7b\u522b\u5de6\u4e0a\u89d2\u4e0e\u53f3\u4e0b\u89d2\u7684heatmap\uff0c\u7136\u540e\u901a\u8fc7embedding vector\u7684\u76f8\u4f3c\u6027\u8fdb\u884c\u4e24\u4e2a\u89d2\u843d\u7684\u5339\u914d\u3002\u53e6\u5916\u4e3a\u4e86\u63d0\u9ad8\u6027\u80fd\uff0c\u8fd8\u7ed9\u51fa\u4e86corner pooling\u4ee5\u53ca\u5b83\u7684GPU\u5b9e\u73b0\u3002\u6574\u4e2a\u7f51\u7edc\u6d41\u7a0b\u57fa\u672c\u662fone-stage \u7ed3\u6784overview backbone\u7f51\u7edc\u4f7f\u7528\u7684\u662f hourglass \u4e4b\u540e\u8ddf\u968f\u7684\u662f\u4e24\u4e2a\u9884\u6d4b\u6a21\u5757\uff0c\u4e00\u4e2a\u9884\u6d4b\u8f93\u51fa\u662f\u5de6\u4e0a\u89d2\uff0c\u53e6\u4e00\u4e2a\u7ed9\u51fa\u7684\u662f\u53f3\u4e0b\u89d2\u3002\u8fd9\u4e24\u4e2a\u6a21\u5757\u6709\u5404\u81ea\u7684corner pooling\u3002 \u9884\u6d4b\u89d2\u70b9 \u7f51\u7edc\u6700\u7ec8\u8f93\u51fa\u7684\u662f\u4e24\u7ec4heatmap\uff0c\u4e00\u4e2a\u7ed9\u5de6\u4e0a\u89d2\u4e00\u4e2a\u7ed9\u53f3\u4e0b\u89d2\uff0c\u6bcf\u4e00\u7ec4\u70ed\u56fe\u6709 C \u4e2a\u7279\u5f81\uff0c\u4e0e\u7c7b\u522b\u6570\u4e00\u81f4(\u6bcf\u4e00\u7c7b\u4e00\u4e2achannel\u7684\u70ed\u56fe)\uff0cfeature map\u5f62\u72b6\u662f H\\times W .\u4e0d\u50cfyolo\u6216\u8005SSD\u4e00\u6837\u5e26\u6709background channel\u3002 \u5728\u8bad\u7ec3\u7684\u65f6\u5019\uff0c\u76f4\u89c9\u4e0e\u7ecf\u9a8c\u8868\u793a\u4e0d\u5e94\u8be5\u7b80\u5355\u5730\u60e9\u7f5a\u4e0d\u6b63\u786e\u7684\u89d2\u70b9\u4f4d\u7f6e\u3002\u8fd9\u91cc\u6839\u636e\u7269\u4f53\u7684\u4f53\u79ef\u7684\u8bbe\u5b9a\u4e0d\u540c\u7684radius cost.\u6700\u7ec8\u8bbe\u8ba1\u51fa\u4e00\u4e2afocal loss,\u539f\u7248focal loss\u6e90\u81ea\u4e0e \u8fd9\u7bc7\u6587\u7ae0 ,\u5728 \u8fd9\u91cc \u6709\u7b80\u4ecb\u3002\u8fd9\u91cc\u7684\u5b9a\u4e49\u662f L_{det}=\\frac{-1}{N} \\sum_{c=1}^{C} \\sum_{i=1}^{H} \\sum_{j=1}^{W}\\left\\{\\begin{array}{c}{\\left(1-p_{c i j}\\right)^{\\alpha} \\log \\left(p_{c i j}\\right)} if (y_{cij} == 1) \\\\ {\\left(1-y_{c i j}\\right)^{\\beta}\\left(p_{c i j}\\right)^{\\alpha} \\log \\left(1-p_{c i j}\\right) \\text { otherwise }}\\end{array}\\right. \u5176\u4e2d p_{cij} \u4e3a (i,j) \u4f4d\u7f6e\u4e0a\u7684score\uff0c e^{-\\frac{x^2+y^2}{2\\sigma^2}} ,\u5176\u4e2d \\sigma \u662fradius\u662f 1/3 , N \u662f\u56fe\u7247\u4e2d\u7269\u4f53\u7684\u6570\u76ee\u3002 \\alpha, \\beta \u662f\u53ef\u8c03\u8282\u7684\u8d85\u53c2\u6570\u3002 \u7531\u4e8e\u5377\u79ef\u7f51\u7edc\u91cc\u9762\u6211\u4eec\u9700\u8981\u5bf9\u56fe\u7247\u4e0b\u91c7\u6837\uff0c (x,y) \\rightarrow (\\frac{x}{n}, \\frac{y}{n}) ,\u9700\u8981\u989d\u5916\u5b66\u4e60\u4e00\u4e2aoffsets\u53bb\u8865\u507f \\boldsymbol{o}_{k}=\\left(\\frac{x_{k}}{n}-\\left\\lfloor\\frac{x_{k}}{n}\\right\\rfloor, \\frac{y_{k}}{n}-\\left\\lfloor\\frac{y_{k}}{n}\\right\\rfloor\\right) \u8fd9\u4e2acost\u53ef\u4ee5\u7528 L_{o f f}=\\frac{1}{N} \\sum_{k=1}^{N} \\operatorname{SmoothL} 1 \\operatorname{Loss}\\left(\\boldsymbol{o}_{k}, \\hat{\\boldsymbol{o}}_{k}\\right) \u5c06\u89d2\u70b9\u805a\u56e2 \u56e0\u4e3a\u4e00\u5f20\u56fe\u5982\u679c\u6709\u591a\u4e2a\u7269\u4f53\uff0c\u4e00\u4e2a\u56fe\u4f1a\u6709\u4e0d\u6b62\u4e00\u5bf9\u7684\u5de6\u4e0a\u89d2\u70b9\u548c\u53f3\u4e0b\u70b9\u3002\u672c\u6587\u7684\u505a\u6cd5\u63d0\u5230\u4e86 \u8fd9\u7bc7\u8bba\u6587 , \u7b80\u4ecb \u7f51\u7edc\u7ed9\u6bcf\u4e00\u4e2a\u5de6\u4e0a\u89d2\u4e0e\u53f3\u4e0b\u89d2\u89d2\u9884\u6d4b\u4e00\u4e2aembedding vector\uff0c\u672c\u6587\u8fd9\u91cc\u6a21\u4eff\u524d\u4e00\u7bc7\u8bba\u6587\u7684\u505a\u6cd5\uff0c\u7ef4\u5ea6\u4ec5\u4e3a1\u3002\u5982\u679c\u4ee3\u8868\u7684\u662f\u540c\u4e00\u4e2abounding box\uff0c\u90a3\u4e48\u4e24\u8005\u8ddd\u79bb\u5c31\u4f1a\u6bd4\u8f83\u5c0f\u3002\u5206\u4e3a\u4e24\u4e2aloss\uff0c\u4e00\u4e2a\u662fpull\u4e00\u4e2apush\u3002 L_{p u l l}=\\frac{1}{N} \\sum_{k=1}^{N}\\left[\\left(e_{t_{k}}-e_{k}\\right)^{2}+\\left(e_{b_{k}}-e_{k}\\right)^{2}\\right] L_{p u s h}=\\frac{1}{N(N-1)} \\sum_{k=1}^{N} \\sum_{j=1 \\atop j \\neq k}^{N} \\max \\left(0, \\Delta-\\left|e_{k}-e_{j}\\right|\\right) e_{t_k} \u4f5c\u4e3a\u7b2c k \u4e2a\u7269\u4f53\uff0c\u5de6\u4e0a\u89d2\u7684embedding, e_{b_k} \u4f5c\u4e3a\u53f3\u4e0b\u89d2\u7684\u3002 e_k \u662f e_{t_k}, e_{b_k} \u7684\u5747\u503c\uff0c\u7136\u540e\u8bbe\u5b9a \\Delta=1 \uff0c\u4e0eoffset\u4e00\u6837\uff0c\u8fd9\u4e2aloss\u53ea\u6267\u884c\u5728gt\u7684\u89d2\u843d\u4f4d\u7f6e\u4e0a. Corner Pooling \u7528\u6765\u5141\u8bb8\u6bcf\u4e00\u4e2a\uff0c\u8ba1\u7b97\u65b9\u5f0f\u5982\u56fe t_{i j}=\\left\\{\\begin{array}{cl}{\\max \\left(f_{t_{i j}}, t_{(i+1) j}\\right)} & {\\text { if } i<H} \\\\ {f_{t_{H j}}} & {\\text { otherwise }}\\end{array}\\right. l_{i j}=\\left\\{\\begin{array}{cl}{\\max \\left(f_{l_{i j}}, l_{i(j+1)}\\right)} & {\\text { if } j<W} \\\\ {f_{l_{i W}}} & {\\text { otherwise }}\\end{array}\\right. \u7136\u540e\u5bf9 t_{ij}, l_{ij} \u76f8\u52a0\u5f97\u5230\u7ed3\u679c\u3002\u4e3a\u53f3\u4e0b\u89d2\u7684pooling layer\u53d6max\u7684\u65b9\u5411\u76f8\u53cd\u3002 \u5148\u5c06\u57fa\u7840\u7684resblock\u7684\u7b2c\u4e00\u4e2a 3\\times 3 \u5377\u79ef\u6539\u4e3acorner pooling.","title":"CornerNet: Detecting Objects as Paired Keypoints"},{"location":"other_categories/object_detection_2D/CornerNet_Detecting_Objects_as_Paired_Keypoints/#cornernet-detecting-objects-as-paired-keypoints","text":"\u8fd9\u7bc7\u6587\u7ae0\u662f \u8fd9\u7bc7\u6587\u7ae0 \u7684\u524d\u7f6e,\u5b9e\u9645\u4e0a\u4e5f\u786e\u5b9e\u6709\u66f4\u591a\u7684\u5185\u5bb9,\u5728\u5177\u4f53\u5b9e\u73b0\u4e0a\u6709\u533a\u522b\u3002 \u8fd9\u7bc7\u6587\u7ae0\u7ed9\u51fa\u7684\u601d\u8def\u662f\uff0c\u8ba9\u795e\u7ecf\u7f51\u7edc\u5206\u522b\u7ed9\u51fa\u67d0\u4e00\u7c7b\u522b\u5de6\u4e0a\u89d2\u4e0e\u53f3\u4e0b\u89d2\u7684heatmap\uff0c\u7136\u540e\u901a\u8fc7embedding vector\u7684\u76f8\u4f3c\u6027\u8fdb\u884c\u4e24\u4e2a\u89d2\u843d\u7684\u5339\u914d\u3002\u53e6\u5916\u4e3a\u4e86\u63d0\u9ad8\u6027\u80fd\uff0c\u8fd8\u7ed9\u51fa\u4e86corner pooling\u4ee5\u53ca\u5b83\u7684GPU\u5b9e\u73b0\u3002\u6574\u4e2a\u7f51\u7edc\u6d41\u7a0b\u57fa\u672c\u662fone-stage","title":"CornerNet: Detecting Objects as Paired Keypoints"},{"location":"other_categories/object_detection_2D/CornerNet_Detecting_Objects_as_Paired_Keypoints/#overview","text":"backbone\u7f51\u7edc\u4f7f\u7528\u7684\u662f hourglass \u4e4b\u540e\u8ddf\u968f\u7684\u662f\u4e24\u4e2a\u9884\u6d4b\u6a21\u5757\uff0c\u4e00\u4e2a\u9884\u6d4b\u8f93\u51fa\u662f\u5de6\u4e0a\u89d2\uff0c\u53e6\u4e00\u4e2a\u7ed9\u51fa\u7684\u662f\u53f3\u4e0b\u89d2\u3002\u8fd9\u4e24\u4e2a\u6a21\u5757\u6709\u5404\u81ea\u7684corner pooling\u3002","title":"\u7ed3\u6784overview"},{"location":"other_categories/object_detection_2D/CornerNet_Detecting_Objects_as_Paired_Keypoints/#_1","text":"\u7f51\u7edc\u6700\u7ec8\u8f93\u51fa\u7684\u662f\u4e24\u7ec4heatmap\uff0c\u4e00\u4e2a\u7ed9\u5de6\u4e0a\u89d2\u4e00\u4e2a\u7ed9\u53f3\u4e0b\u89d2\uff0c\u6bcf\u4e00\u7ec4\u70ed\u56fe\u6709 C \u4e2a\u7279\u5f81\uff0c\u4e0e\u7c7b\u522b\u6570\u4e00\u81f4(\u6bcf\u4e00\u7c7b\u4e00\u4e2achannel\u7684\u70ed\u56fe)\uff0cfeature map\u5f62\u72b6\u662f H\\times W .\u4e0d\u50cfyolo\u6216\u8005SSD\u4e00\u6837\u5e26\u6709background channel\u3002 \u5728\u8bad\u7ec3\u7684\u65f6\u5019\uff0c\u76f4\u89c9\u4e0e\u7ecf\u9a8c\u8868\u793a\u4e0d\u5e94\u8be5\u7b80\u5355\u5730\u60e9\u7f5a\u4e0d\u6b63\u786e\u7684\u89d2\u70b9\u4f4d\u7f6e\u3002\u8fd9\u91cc\u6839\u636e\u7269\u4f53\u7684\u4f53\u79ef\u7684\u8bbe\u5b9a\u4e0d\u540c\u7684radius cost.\u6700\u7ec8\u8bbe\u8ba1\u51fa\u4e00\u4e2afocal loss,\u539f\u7248focal loss\u6e90\u81ea\u4e0e \u8fd9\u7bc7\u6587\u7ae0 ,\u5728 \u8fd9\u91cc \u6709\u7b80\u4ecb\u3002\u8fd9\u91cc\u7684\u5b9a\u4e49\u662f L_{det}=\\frac{-1}{N} \\sum_{c=1}^{C} \\sum_{i=1}^{H} \\sum_{j=1}^{W}\\left\\{\\begin{array}{c}{\\left(1-p_{c i j}\\right)^{\\alpha} \\log \\left(p_{c i j}\\right)} if (y_{cij} == 1) \\\\ {\\left(1-y_{c i j}\\right)^{\\beta}\\left(p_{c i j}\\right)^{\\alpha} \\log \\left(1-p_{c i j}\\right) \\text { otherwise }}\\end{array}\\right. \u5176\u4e2d p_{cij} \u4e3a (i,j) \u4f4d\u7f6e\u4e0a\u7684score\uff0c e^{-\\frac{x^2+y^2}{2\\sigma^2}} ,\u5176\u4e2d \\sigma \u662fradius\u662f 1/3 , N \u662f\u56fe\u7247\u4e2d\u7269\u4f53\u7684\u6570\u76ee\u3002 \\alpha, \\beta \u662f\u53ef\u8c03\u8282\u7684\u8d85\u53c2\u6570\u3002 \u7531\u4e8e\u5377\u79ef\u7f51\u7edc\u91cc\u9762\u6211\u4eec\u9700\u8981\u5bf9\u56fe\u7247\u4e0b\u91c7\u6837\uff0c (x,y) \\rightarrow (\\frac{x}{n}, \\frac{y}{n}) ,\u9700\u8981\u989d\u5916\u5b66\u4e60\u4e00\u4e2aoffsets\u53bb\u8865\u507f \\boldsymbol{o}_{k}=\\left(\\frac{x_{k}}{n}-\\left\\lfloor\\frac{x_{k}}{n}\\right\\rfloor, \\frac{y_{k}}{n}-\\left\\lfloor\\frac{y_{k}}{n}\\right\\rfloor\\right) \u8fd9\u4e2acost\u53ef\u4ee5\u7528 L_{o f f}=\\frac{1}{N} \\sum_{k=1}^{N} \\operatorname{SmoothL} 1 \\operatorname{Loss}\\left(\\boldsymbol{o}_{k}, \\hat{\\boldsymbol{o}}_{k}\\right)","title":"\u9884\u6d4b\u89d2\u70b9"},{"location":"other_categories/object_detection_2D/CornerNet_Detecting_Objects_as_Paired_Keypoints/#_2","text":"\u56e0\u4e3a\u4e00\u5f20\u56fe\u5982\u679c\u6709\u591a\u4e2a\u7269\u4f53\uff0c\u4e00\u4e2a\u56fe\u4f1a\u6709\u4e0d\u6b62\u4e00\u5bf9\u7684\u5de6\u4e0a\u89d2\u70b9\u548c\u53f3\u4e0b\u70b9\u3002\u672c\u6587\u7684\u505a\u6cd5\u63d0\u5230\u4e86 \u8fd9\u7bc7\u8bba\u6587 , \u7b80\u4ecb \u7f51\u7edc\u7ed9\u6bcf\u4e00\u4e2a\u5de6\u4e0a\u89d2\u4e0e\u53f3\u4e0b\u89d2\u89d2\u9884\u6d4b\u4e00\u4e2aembedding vector\uff0c\u672c\u6587\u8fd9\u91cc\u6a21\u4eff\u524d\u4e00\u7bc7\u8bba\u6587\u7684\u505a\u6cd5\uff0c\u7ef4\u5ea6\u4ec5\u4e3a1\u3002\u5982\u679c\u4ee3\u8868\u7684\u662f\u540c\u4e00\u4e2abounding box\uff0c\u90a3\u4e48\u4e24\u8005\u8ddd\u79bb\u5c31\u4f1a\u6bd4\u8f83\u5c0f\u3002\u5206\u4e3a\u4e24\u4e2aloss\uff0c\u4e00\u4e2a\u662fpull\u4e00\u4e2apush\u3002 L_{p u l l}=\\frac{1}{N} \\sum_{k=1}^{N}\\left[\\left(e_{t_{k}}-e_{k}\\right)^{2}+\\left(e_{b_{k}}-e_{k}\\right)^{2}\\right] L_{p u s h}=\\frac{1}{N(N-1)} \\sum_{k=1}^{N} \\sum_{j=1 \\atop j \\neq k}^{N} \\max \\left(0, \\Delta-\\left|e_{k}-e_{j}\\right|\\right) e_{t_k} \u4f5c\u4e3a\u7b2c k \u4e2a\u7269\u4f53\uff0c\u5de6\u4e0a\u89d2\u7684embedding, e_{b_k} \u4f5c\u4e3a\u53f3\u4e0b\u89d2\u7684\u3002 e_k \u662f e_{t_k}, e_{b_k} \u7684\u5747\u503c\uff0c\u7136\u540e\u8bbe\u5b9a \\Delta=1 \uff0c\u4e0eoffset\u4e00\u6837\uff0c\u8fd9\u4e2aloss\u53ea\u6267\u884c\u5728gt\u7684\u89d2\u843d\u4f4d\u7f6e\u4e0a.","title":"\u5c06\u89d2\u70b9\u805a\u56e2"},{"location":"other_categories/object_detection_2D/CornerNet_Detecting_Objects_as_Paired_Keypoints/#corner-pooling","text":"\u7528\u6765\u5141\u8bb8\u6bcf\u4e00\u4e2a\uff0c\u8ba1\u7b97\u65b9\u5f0f\u5982\u56fe t_{i j}=\\left\\{\\begin{array}{cl}{\\max \\left(f_{t_{i j}}, t_{(i+1) j}\\right)} & {\\text { if } i<H} \\\\ {f_{t_{H j}}} & {\\text { otherwise }}\\end{array}\\right. l_{i j}=\\left\\{\\begin{array}{cl}{\\max \\left(f_{l_{i j}}, l_{i(j+1)}\\right)} & {\\text { if } j<W} \\\\ {f_{l_{i W}}} & {\\text { otherwise }}\\end{array}\\right. \u7136\u540e\u5bf9 t_{ij}, l_{ij} \u76f8\u52a0\u5f97\u5230\u7ed3\u679c\u3002\u4e3a\u53f3\u4e0b\u89d2\u7684pooling layer\u53d6max\u7684\u65b9\u5411\u76f8\u53cd\u3002 \u5148\u5c06\u57fa\u7840\u7684resblock\u7684\u7b2c\u4e00\u4e2a 3\\times 3 \u5377\u79ef\u6539\u4e3acorner pooling.","title":"Corner Pooling"},{"location":"other_categories/object_detection_2D/DIoULoss/","text":"Distance-IoU Loss: Faster and Better Learning for Bounding Box Regression This paper introduce distance-IoU based on the basic IoU metric and the GIoU . [GIoU]\u7684\u5f15\u51fa\u672c\u6765\u662f\u4e3a\u4e86\u89e3\u51b3\u4e24\u4e2abounding box \u4e0d\u91cd\u5408\u65f6\u635f\u5931\u51fd\u6570\u53ef\u5bfc\u6027\u7684\u95ee\u9898\u3002\u4f46\u662f\u4f5c\u8005\u901a\u8fc7\u4e00\u4e2a\u975e\u5e38\u6709\u542f\u53d1\u6027\u7684\u4eff\u771f\u5b9e\u9a8c\uff0c\u8bf4\u660e\u4e86 GIoU\u7684\u6536\u655b\u6027\u95ee\u9898\u3002 \u7136\u540e\u63d0\u51fa\u4e86\u5c3a\u5ea6\u4e0ainvariant\u4e14\u6536\u655b\u6027\u66f4\u597d\u7684DIoU\u3002 \u4f5c\u8005\u4e4b\u540e\u8fdb\u4e00\u6b65\u8003\u8651\u4e86aspect ratio\u957f\u5bbd\u6bd4\u7684regularization \u95ee\u9898\uff0c\u63d0\u51fa\u4e86CIoU. Update 2020.05.09: CIoU and Cluster-NMS: pdf code Simulation on the convergence of IoU losses \u4f5c\u8005\u4eff\u771f\u4e86\u4e0d\u540c\u8d77\u59cb\u6761\u4ef6\u4e0b\uff0c\u4f7f\u7528\u4e0d\u540c\u7684IoU\u51fd\u6570\u8fdb\u884c\u68af\u5ea6\u4e0b\u964d\uff0c\u89c2\u5bdf\u6536\u655b\u6027\u3002 \u7b97\u6cd5\u5982\u4e0b \u8fd9\u4e2a\u7b97\u6cd5\u6709\u51e0\u4e2a\u503c\u5f97\u6ce8\u610f\u7684\u5730\u65b9\uff0c\u9996\u5148\u662f\u76ee\u6807\u6846\u4ee5\u53ca\u8d77\u59cb\u76f8\u5173\u6570\u636e\u7684\u9009\u62e9\uff0c\u5176\u6b21\u662f\u68af\u5ea6\u4e0b\u964d\u7684\u6a21\u62df\u9000\u706b\uff0c\u6700\u540e\u8981\u5173\u6ce8\u7684\u662f\u68af\u5ea6\u4e0b\u964d\u66f4\u65b0(\u7b2c9\u884c)\u524d\u9762\u7684\u56e0\u5b50. \u6700\u540e\u7684\u6536\u655b\u6548\u679c\u5982\u56fe \u6587\u7ae0\u6307\u51fa\uff0c\u4f7f\u7528GIoU\u4f5c\u8bad\u7ec3\u7684\u65f6\u5019,\u4f1a\u5148\u4f7fprediction\u9762\u79ef\u589e\u5927\uff0c\u5c3d\u53ef\u80fd\u5b9e\u73b0\u76f8\u4ea4\uff0c\u518d\u8fdb\u884c\u62df\u5408\uff0c\u4f18\u5316\u8fc7\u7a0b\u6bd4\u8f83\u626d\u66f2\uff0c\u4e0d\u592a\u597d\uff0c\u5b9e\u9a8c\u7ed3\u679c\u4e5f\u8bc1\u660e\u5176\u6536\u655b\u5f88\u6162\u3002 \u4eff\u771f\u5b9e\u9a8c\u4ee3\u7801\u5728 \u989d\u5916\u7684\u4ed3\u5e93 DIoU\u4e0eCIoU \\mathcal{L}_{D I o U}=1-\\operatorname{IoU}+\\frac{\\rho^{2}\\left(\\mathbf{b}, \\mathbf{b}^{g t}\\right)}{c^{2}} \u5176\u4e2d\u5206\u5b50\u4e0a\u4e3a\u4e24\u4e2abounding box \u4e2d\u5fc3\u70b9\u7684\u76f4\u7ebf\u8ddd\u79bb\uff0c c \u4e3a\u4e24\u4e2abounding box\u6700\u5c0f\u5305\u7edc\u6846\u7684\u5bf9\u89d2\u7ebf\u957f\u5ea6\u3002 CIoU\u5219\u662f: \\mathcal{L}_{C I o U}=1-I o U+\\frac{\\rho^{2}\\left(\\mathbf{b}, \\mathbf{b}^{g t}\\right)}{c^{2}}+\\alpha v v=\\frac{4}{\\pi^{2}}\\left(\\arctan \\frac{w^{g t}}{h^{g t}}-\\arctan \\frac{w}{h}\\right)^{2} \\alpha=\\frac{v}{(1-I o U)+v} \u8fd9\u91cc\u4e00\u4e2a\u4e2a\u5206\u6790\uff0c\u9996\u5148 v \u6307\u4ee3\u7684\u662f\u4e24\u4e2abounding box\u4e4b\u95f4\u7531\u4e8easpect ratio\u4e0d\u540c\u4ea7\u751f\u7684\u8bef\u5dee\uff0c\u8fd9\u91cc\u7528 arctan \u7684\u5dee\u503c\u63cf\u8ff0\u3002 \\alpha \u662f\u4e00\u4e2a\u53c2\u6570\uff0c\u5982\u679cIoU \u63a5\u8fd1\u4e8e1\uff0c\u5219 \\alpha \u63a5\u8fd11\uff0c\u6743\u91cd\u4e3a\u6700\u5927\uff0c\u5982\u679c IoU \u63a5\u8fd1\u4e8e0\uff0c\u5219\u957f\u5bbd\u6bd4\u5bf9\u5e94\u7684\u6743\u91cd\u4e0b\u8c03\u3002 \u4f5c\u8005\u5bf9CIoU\u7684\u53cd\u5411\u4f20\u64ad\u4e5f\u505a\u4e86\u4e00\u4e2a\u8fd1\u4f3c\u4f18\u5316\u6765\u63d0\u5347\u7a33\u5b9a\u6027\uff0c\u5177\u4f53\u770b\u539f\u6587\u4ee5\u53ca\u6e90\u7801\u3002 Cluster NMS (update on 2020.05.09) \u7ffb\u8bd1: 1. \u5047\u8bbe\u6240\u6709bounding box\u90fd\u4fdd\u7559\u4e0b\u6765\uff0c\u4e5f\u90fd\u5bf9\u5176\u4ed6\u6bd4\u5b83score\u4f4e\u7684boxes\u6709\u6291\u5236\u53ef\u80fd\u6027 2. \u7701\u7565\u4e0a\u4e00\u4e2a\u5faa\u73af\u4e2d\u88ab\u6291\u5236\u7684boxes\uff0c\u8fed\u4ee3 FastNMS \u51e0\u4e2a\u5c0f\u7ed3\u8bba\uff1a 1. \u82e5\u8fed\u4ee3\u6b21\u6570\u4e3a1\uff0c\u7b97\u6cd5\u5c31\u7b49\u540c\u4e8eFastNMS 2. \u82e5\u8fed\u4ee3\u6b21\u6570\u4e3aN\uff0c\u7b97\u6cd5\u7ed3\u679c\u4e00\u5b9a\u7b49\u540c\u4e8e\u539f\u59cbNMS(\u4f5c\u8005\u6709\u8bc1\u660e) 3. \u4e00\u822c\u60c5\u51b5\u4e0b\u8fed\u4ee3\u6b21\u6570\u663e\u8457\u5730\u5c0f\u4e8eN 4. torchVision\u7684NMS\u662f\u539f\u7248NMS\uff0c\u4f46\u662f\u901a\u8fc7\u786c\u4ef6\u52a0\u901f\u6bd4\u8fd9\u4e2a\u8fd8\u8981\u5feb...???","title":"Distance-IoU Loss: Faster and Better Learning for Bounding Box Regression"},{"location":"other_categories/object_detection_2D/DIoULoss/#distance-iou-loss-faster-and-better-learning-for-bounding-box-regression","text":"This paper introduce distance-IoU based on the basic IoU metric and the GIoU . [GIoU]\u7684\u5f15\u51fa\u672c\u6765\u662f\u4e3a\u4e86\u89e3\u51b3\u4e24\u4e2abounding box \u4e0d\u91cd\u5408\u65f6\u635f\u5931\u51fd\u6570\u53ef\u5bfc\u6027\u7684\u95ee\u9898\u3002\u4f46\u662f\u4f5c\u8005\u901a\u8fc7\u4e00\u4e2a\u975e\u5e38\u6709\u542f\u53d1\u6027\u7684\u4eff\u771f\u5b9e\u9a8c\uff0c\u8bf4\u660e\u4e86 GIoU\u7684\u6536\u655b\u6027\u95ee\u9898\u3002 \u7136\u540e\u63d0\u51fa\u4e86\u5c3a\u5ea6\u4e0ainvariant\u4e14\u6536\u655b\u6027\u66f4\u597d\u7684DIoU\u3002 \u4f5c\u8005\u4e4b\u540e\u8fdb\u4e00\u6b65\u8003\u8651\u4e86aspect ratio\u957f\u5bbd\u6bd4\u7684regularization \u95ee\u9898\uff0c\u63d0\u51fa\u4e86CIoU. Update 2020.05.09: CIoU and Cluster-NMS: pdf code","title":"Distance-IoU Loss: Faster and Better Learning for Bounding Box Regression"},{"location":"other_categories/object_detection_2D/DIoULoss/#simulation-on-the-convergence-of-iou-losses","text":"\u4f5c\u8005\u4eff\u771f\u4e86\u4e0d\u540c\u8d77\u59cb\u6761\u4ef6\u4e0b\uff0c\u4f7f\u7528\u4e0d\u540c\u7684IoU\u51fd\u6570\u8fdb\u884c\u68af\u5ea6\u4e0b\u964d\uff0c\u89c2\u5bdf\u6536\u655b\u6027\u3002 \u7b97\u6cd5\u5982\u4e0b \u8fd9\u4e2a\u7b97\u6cd5\u6709\u51e0\u4e2a\u503c\u5f97\u6ce8\u610f\u7684\u5730\u65b9\uff0c\u9996\u5148\u662f\u76ee\u6807\u6846\u4ee5\u53ca\u8d77\u59cb\u76f8\u5173\u6570\u636e\u7684\u9009\u62e9\uff0c\u5176\u6b21\u662f\u68af\u5ea6\u4e0b\u964d\u7684\u6a21\u62df\u9000\u706b\uff0c\u6700\u540e\u8981\u5173\u6ce8\u7684\u662f\u68af\u5ea6\u4e0b\u964d\u66f4\u65b0(\u7b2c9\u884c)\u524d\u9762\u7684\u56e0\u5b50. \u6700\u540e\u7684\u6536\u655b\u6548\u679c\u5982\u56fe \u6587\u7ae0\u6307\u51fa\uff0c\u4f7f\u7528GIoU\u4f5c\u8bad\u7ec3\u7684\u65f6\u5019,\u4f1a\u5148\u4f7fprediction\u9762\u79ef\u589e\u5927\uff0c\u5c3d\u53ef\u80fd\u5b9e\u73b0\u76f8\u4ea4\uff0c\u518d\u8fdb\u884c\u62df\u5408\uff0c\u4f18\u5316\u8fc7\u7a0b\u6bd4\u8f83\u626d\u66f2\uff0c\u4e0d\u592a\u597d\uff0c\u5b9e\u9a8c\u7ed3\u679c\u4e5f\u8bc1\u660e\u5176\u6536\u655b\u5f88\u6162\u3002 \u4eff\u771f\u5b9e\u9a8c\u4ee3\u7801\u5728 \u989d\u5916\u7684\u4ed3\u5e93","title":"Simulation on the convergence of IoU losses"},{"location":"other_categories/object_detection_2D/DIoULoss/#diouciou","text":"\\mathcal{L}_{D I o U}=1-\\operatorname{IoU}+\\frac{\\rho^{2}\\left(\\mathbf{b}, \\mathbf{b}^{g t}\\right)}{c^{2}} \u5176\u4e2d\u5206\u5b50\u4e0a\u4e3a\u4e24\u4e2abounding box \u4e2d\u5fc3\u70b9\u7684\u76f4\u7ebf\u8ddd\u79bb\uff0c c \u4e3a\u4e24\u4e2abounding box\u6700\u5c0f\u5305\u7edc\u6846\u7684\u5bf9\u89d2\u7ebf\u957f\u5ea6\u3002 CIoU\u5219\u662f: \\mathcal{L}_{C I o U}=1-I o U+\\frac{\\rho^{2}\\left(\\mathbf{b}, \\mathbf{b}^{g t}\\right)}{c^{2}}+\\alpha v v=\\frac{4}{\\pi^{2}}\\left(\\arctan \\frac{w^{g t}}{h^{g t}}-\\arctan \\frac{w}{h}\\right)^{2} \\alpha=\\frac{v}{(1-I o U)+v} \u8fd9\u91cc\u4e00\u4e2a\u4e2a\u5206\u6790\uff0c\u9996\u5148 v \u6307\u4ee3\u7684\u662f\u4e24\u4e2abounding box\u4e4b\u95f4\u7531\u4e8easpect ratio\u4e0d\u540c\u4ea7\u751f\u7684\u8bef\u5dee\uff0c\u8fd9\u91cc\u7528 arctan \u7684\u5dee\u503c\u63cf\u8ff0\u3002 \\alpha \u662f\u4e00\u4e2a\u53c2\u6570\uff0c\u5982\u679cIoU \u63a5\u8fd1\u4e8e1\uff0c\u5219 \\alpha \u63a5\u8fd11\uff0c\u6743\u91cd\u4e3a\u6700\u5927\uff0c\u5982\u679c IoU \u63a5\u8fd1\u4e8e0\uff0c\u5219\u957f\u5bbd\u6bd4\u5bf9\u5e94\u7684\u6743\u91cd\u4e0b\u8c03\u3002 \u4f5c\u8005\u5bf9CIoU\u7684\u53cd\u5411\u4f20\u64ad\u4e5f\u505a\u4e86\u4e00\u4e2a\u8fd1\u4f3c\u4f18\u5316\u6765\u63d0\u5347\u7a33\u5b9a\u6027\uff0c\u5177\u4f53\u770b\u539f\u6587\u4ee5\u53ca\u6e90\u7801\u3002","title":"DIoU\u4e0eCIoU"},{"location":"other_categories/object_detection_2D/DIoULoss/#cluster-nms-update-on-20200509","text":"\u7ffb\u8bd1: 1. \u5047\u8bbe\u6240\u6709bounding box\u90fd\u4fdd\u7559\u4e0b\u6765\uff0c\u4e5f\u90fd\u5bf9\u5176\u4ed6\u6bd4\u5b83score\u4f4e\u7684boxes\u6709\u6291\u5236\u53ef\u80fd\u6027 2. \u7701\u7565\u4e0a\u4e00\u4e2a\u5faa\u73af\u4e2d\u88ab\u6291\u5236\u7684boxes\uff0c\u8fed\u4ee3 FastNMS \u51e0\u4e2a\u5c0f\u7ed3\u8bba\uff1a 1. \u82e5\u8fed\u4ee3\u6b21\u6570\u4e3a1\uff0c\u7b97\u6cd5\u5c31\u7b49\u540c\u4e8eFastNMS 2. \u82e5\u8fed\u4ee3\u6b21\u6570\u4e3aN\uff0c\u7b97\u6cd5\u7ed3\u679c\u4e00\u5b9a\u7b49\u540c\u4e8e\u539f\u59cbNMS(\u4f5c\u8005\u6709\u8bc1\u660e) 3. \u4e00\u822c\u60c5\u51b5\u4e0b\u8fed\u4ee3\u6b21\u6570\u663e\u8457\u5730\u5c0f\u4e8eN 4. torchVision\u7684NMS\u662f\u539f\u7248NMS\uff0c\u4f46\u662f\u901a\u8fc7\u786c\u4ef6\u52a0\u901f\u6bd4\u8fd9\u4e2a\u8fd8\u8981\u5feb...???","title":"Cluster NMS (update on 2020.05.09)"},{"location":"other_categories/object_detection_2D/DRN_and_SKU110K-R/","text":"Dynamic Refinement Network for Oriented and Densely Packed Object Detection \u8fd9\u7bc7paper\u5904\u7406\u7684\u662fSKU\u6570\u636e\u96c6\uff0c\u7279\u70b9\u662f\u7269\u4f53\u6570\u91cf\u5f88\u5927\uff0c\u5f88\u5bc6\u96c6\uff0c\u4e14\u4f5c\u8005\u8fdb\u4e00\u6b65\u63d0\u51faSKU110K-R\u6570\u636e\u96c6\uff0cbounding box\u5e26\u6709\u65cb\u8f6c\u91cf\uff0c\u8fd9\u4e2a\u6570\u636e\u96c6\u6765\u81ea\u4e8eSKU110K\u76f4\u63a5\u9009\u62e9\uff0c\u63d0\u51fa\u8fd9\u4e2a\u6570\u636e\u96c6\u7684\u610f\u4e49\u5728\u4e8e\u4fc3\u8fdbdensely oriented bounding box\u7684\u7814\u7a76\u3002\u7f51\u7edc\u7ed3\u6784\u4e0a\u63d0\u51fa\u4e86\u51e0\u4e2a\u65b0\u7684\u6a21\u5757\uff0c\u9002\u5e94\u4e0d\u540c\u7684\u7269\u4f53\u5f62\u72b6\u4e0e\u7c7b\u522b\u7279\u5b9a\u7684\u4fe1\u606f\u3002 \u7f51\u7edc\u7ed3\u6784 \u7f51\u7edc\u601d\u8def\u57fa\u4e8e Object as Point . \u7f51\u7edc\u4f1a\u9884\u6d4b \\theta \u89d2\uff0cbounding box\u7531\u65cb\u8f6c\u5f97\u6765 \\begin{array}{l} P_{l t}=M_{r}[-w / 2,-h / 2]^{T}+\\left[c_{x}+\\delta_{x}, c_{y}+\\delta_{y}\\right]^{T} \\\\ P_{r t}=M_{r}[+w / 2,-h / 2]^{T}+\\left[c_{x}+\\delta_{x}, c_{y}+\\delta_{y}\\right]^{T} \\\\ P_{l b}=M_{r}[-w / 2,+h / 2]^{T}+\\left[c_{x}+\\delta_{x}, c_{y}+\\delta_{y}\\right]^{T} \\\\ P_{r b}=M_{r}[+w / 2,+h / 2]^{T}+\\left[c_{x}+\\delta_{x}, c_{y}+\\delta_{y}\\right]^{T} \\end{array} \u503c\u5f97\u6ce8\u610f\u7684\u5730\u65b9\u5728\u4e8e\u7531\u4e8eobject as point\u7684 NMS\u53ea\u662f\u5bf9heatmap\u8fdb\u884c\u7b80\u5355\u7684maxpooling\u8ba1\u7b97\uff0c\u56e0\u800c\u4e0d\u9700\u8981\u8ba1\u7b97rotated IoU\uff0c\u901f\u5ea6\u5feb\u800c\u4e0d\u5bb9\u6613\u6709\u9519\u8bef\uff0c\u800c\u4e14object as point\u7684\u8f93\u51fa\u70b9\u6bd4\u8f83\u5bc6\u96c6\uff0c\u56e0\u800c\u5f88\u9002\u5408\u8fd9\u4e2a\u5bc6\u96c6\u7684\u6570\u636e\u96c6\u3002 \u989d\u5916\u7684\u7f51\u7edc\u6a21\u5757 Feature Selection Module & Rotation Convolution \u8fd9\u91cc\u662f\u501f\u52a9\u4e86deformable convolution\u7684\u601d\u8def\u4e0e\u4ee3\u7801 \u4f7f\u7528\u7f51\u7edc\u8f93\u51fa\u4e00\u4e2a\u8f6c\u89d2 \\theta \uff0c\u4fee\u6539\u539f\u59cbconvolution\u5bf9\u5e94\u7684offset\uff0c \\delta p_{i}=M_{r}(\\theta) \\cdot p_{i}-p_{i} X_{i}\\left(p_{0}\\right)=\\sum_{p_{n} \\in \\mathcal{R}} w\\left(p_{n}\\right) \\cdot X_{c}\\left(p_{0}+p_{n}+\\delta p_{n}\\right) \u7279\u5f81\u9009\u62e9\u4f7f\u7528\u7684\u662f\u7b80\u5355\u7684attention block. A_{i}^{\\prime}=\\operatorname{SoftMax}\\left(\\left[A_{1}, A_{2}, A_{3}\\right]\\right) Y=\\sum_{i} A_{i}^{\\prime} \\cdot X_{i} Dynamic Refinement Head H_{c}=C\\left(\\left(1+\\varepsilon \\cdot F_{\\Delta} /\\left\\|F_{\\Delta}\\right\\|\\right) \\cdot F_{m i d} ; \\Phi\\right) \\begin{array}{l} H_{b}=R\\left(F_{m i d} ; \\Psi\\right) \\\\ H_{r}=\\left(1+\\epsilon \\cdot \\tanh \\left(H_{\\Delta}\\right)\\right) \\cdot H_{b} \\end{array} Dataset","title":"Dynamic Refinement Network for Oriented and Densely Packed Object Detection"},{"location":"other_categories/object_detection_2D/DRN_and_SKU110K-R/#dynamic-refinement-network-for-oriented-and-densely-packed-object-detection","text":"\u8fd9\u7bc7paper\u5904\u7406\u7684\u662fSKU\u6570\u636e\u96c6\uff0c\u7279\u70b9\u662f\u7269\u4f53\u6570\u91cf\u5f88\u5927\uff0c\u5f88\u5bc6\u96c6\uff0c\u4e14\u4f5c\u8005\u8fdb\u4e00\u6b65\u63d0\u51faSKU110K-R\u6570\u636e\u96c6\uff0cbounding box\u5e26\u6709\u65cb\u8f6c\u91cf\uff0c\u8fd9\u4e2a\u6570\u636e\u96c6\u6765\u81ea\u4e8eSKU110K\u76f4\u63a5\u9009\u62e9\uff0c\u63d0\u51fa\u8fd9\u4e2a\u6570\u636e\u96c6\u7684\u610f\u4e49\u5728\u4e8e\u4fc3\u8fdbdensely oriented bounding box\u7684\u7814\u7a76\u3002\u7f51\u7edc\u7ed3\u6784\u4e0a\u63d0\u51fa\u4e86\u51e0\u4e2a\u65b0\u7684\u6a21\u5757\uff0c\u9002\u5e94\u4e0d\u540c\u7684\u7269\u4f53\u5f62\u72b6\u4e0e\u7c7b\u522b\u7279\u5b9a\u7684\u4fe1\u606f\u3002","title":"Dynamic Refinement Network for Oriented and Densely Packed Object Detection"},{"location":"other_categories/object_detection_2D/DRN_and_SKU110K-R/#_1","text":"\u7f51\u7edc\u601d\u8def\u57fa\u4e8e Object as Point . \u7f51\u7edc\u4f1a\u9884\u6d4b \\theta \u89d2\uff0cbounding box\u7531\u65cb\u8f6c\u5f97\u6765 \\begin{array}{l} P_{l t}=M_{r}[-w / 2,-h / 2]^{T}+\\left[c_{x}+\\delta_{x}, c_{y}+\\delta_{y}\\right]^{T} \\\\ P_{r t}=M_{r}[+w / 2,-h / 2]^{T}+\\left[c_{x}+\\delta_{x}, c_{y}+\\delta_{y}\\right]^{T} \\\\ P_{l b}=M_{r}[-w / 2,+h / 2]^{T}+\\left[c_{x}+\\delta_{x}, c_{y}+\\delta_{y}\\right]^{T} \\\\ P_{r b}=M_{r}[+w / 2,+h / 2]^{T}+\\left[c_{x}+\\delta_{x}, c_{y}+\\delta_{y}\\right]^{T} \\end{array} \u503c\u5f97\u6ce8\u610f\u7684\u5730\u65b9\u5728\u4e8e\u7531\u4e8eobject as point\u7684 NMS\u53ea\u662f\u5bf9heatmap\u8fdb\u884c\u7b80\u5355\u7684maxpooling\u8ba1\u7b97\uff0c\u56e0\u800c\u4e0d\u9700\u8981\u8ba1\u7b97rotated IoU\uff0c\u901f\u5ea6\u5feb\u800c\u4e0d\u5bb9\u6613\u6709\u9519\u8bef\uff0c\u800c\u4e14object as point\u7684\u8f93\u51fa\u70b9\u6bd4\u8f83\u5bc6\u96c6\uff0c\u56e0\u800c\u5f88\u9002\u5408\u8fd9\u4e2a\u5bc6\u96c6\u7684\u6570\u636e\u96c6\u3002","title":"\u7f51\u7edc\u7ed3\u6784"},{"location":"other_categories/object_detection_2D/DRN_and_SKU110K-R/#_2","text":"","title":"\u989d\u5916\u7684\u7f51\u7edc\u6a21\u5757"},{"location":"other_categories/object_detection_2D/DRN_and_SKU110K-R/#feature-selection-module-rotation-convolution","text":"\u8fd9\u91cc\u662f\u501f\u52a9\u4e86deformable convolution\u7684\u601d\u8def\u4e0e\u4ee3\u7801 \u4f7f\u7528\u7f51\u7edc\u8f93\u51fa\u4e00\u4e2a\u8f6c\u89d2 \\theta \uff0c\u4fee\u6539\u539f\u59cbconvolution\u5bf9\u5e94\u7684offset\uff0c \\delta p_{i}=M_{r}(\\theta) \\cdot p_{i}-p_{i} X_{i}\\left(p_{0}\\right)=\\sum_{p_{n} \\in \\mathcal{R}} w\\left(p_{n}\\right) \\cdot X_{c}\\left(p_{0}+p_{n}+\\delta p_{n}\\right) \u7279\u5f81\u9009\u62e9\u4f7f\u7528\u7684\u662f\u7b80\u5355\u7684attention block. A_{i}^{\\prime}=\\operatorname{SoftMax}\\left(\\left[A_{1}, A_{2}, A_{3}\\right]\\right) Y=\\sum_{i} A_{i}^{\\prime} \\cdot X_{i}","title":"Feature Selection Module &amp; Rotation Convolution"},{"location":"other_categories/object_detection_2D/DRN_and_SKU110K-R/#dynamic-refinement-head","text":"H_{c}=C\\left(\\left(1+\\varepsilon \\cdot F_{\\Delta} /\\left\\|F_{\\Delta}\\right\\|\\right) \\cdot F_{m i d} ; \\Phi\\right) \\begin{array}{l} H_{b}=R\\left(F_{m i d} ; \\Psi\\right) \\\\ H_{r}=\\left(1+\\epsilon \\cdot \\tanh \\left(H_{\\Delta}\\right)\\right) \\cdot H_{b} \\end{array}","title":"Dynamic Refinement Head"},{"location":"other_categories/object_detection_2D/DRN_and_SKU110K-R/#dataset","text":"","title":"Dataset"},{"location":"other_categories/object_detection_2D/DynamicRCNN/","text":"Dynamic R-CNN: Towards High Quality Object Detection via Dynamic Training \u672c\u6587\u63d0\u4f9b\u4e00\u4e2a\u57fa\u4e8emmdetection\u7684config\u5b9e\u73b0\uff0c\u5df2\u7ecf\u52a0\u5165mmdetection master\u5206\u652f . \u672c\u6587\u7684\u60f3\u6cd5\u662f\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u52a8\u6001\u8c03\u6574Label Assignment\u7684\u65b9\u5f0f\u4ee5\u53ca SmoothL1 Loss\u7684\u53c2\u6570\uff0c\u4f7f\u5f97\u968f\u7740\u8bad\u7ec3\u7684\u8fdb\u6b65.\u8bad\u7ec3\u51fa\u6765\u7684\u7f51\u7edc\u5b9a\u4f4d\u7cbe\u5ea6\u8f83\u5927\u5e45\u5ea6\u63d0\u5347(IoU threshold 0.9\u65f6AP\u63d0\u53475.5%).\u4e14\u4e0d\u589e\u52a0\u63a8\u7406\u6d88\u8d39\u3002 Dynamic Label Assignment \u4f5c\u8005\u6307\u51faanchor-based \u65b9\u6cd5\u5728\u5206\u914danchor\u7684\u65f6\u5019\u4f7f\u7528\u7684IoU threshold\u5c3d\u7ba1\u4e0e\u603b\u4f53\u7684mAP\u6ca1\u6709\u7ebf\u6027\u76f8\u5173\u6027\uff0c\u4f46\u662f\u968f\u7740IoU threshold\u589e\u5927\uff0c\u7f51\u7edc\u5728\u9ad8IoU threshold\u4e0b\u7684AP\u5c31\u8d8a\u9ad8(\u4f4eIoU threshold\u4e0b\u7684AP\u8d8a\u4f4e)\u3002 \u4f5c\u8005\u56e0\u800c\u6307\u51fa\uff0c\u5982\u679cobject detector\u60f3\u5f97\u5230\u66f4\u9ad8\u7684\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u5728\u8bad\u7ec3\u7f51\u7edc\u90fd\u65f6\u5019\u5e94\u8be5\u9700\u8981\u6bd4\u8f83\u8fbe\u5230IoU Threshold. \u4f46\u662f\u76f4\u63a5\u8fd9\u6837\u505a\u4f1a\u4f7f\u5f97\u6b63\u6837\u672c\u90fd\u6ca1\u4e86\uff0c \u4f5c\u8005\u6307\u51fa\uff0c\u968f\u7740\u8bad\u7ec3\u8fc7\u7a0b\u7684\u63a8\u8fdb\uff0c\u56de\u5f52\u6548\u679c\u4e5f\u90fd\u5728\u63d0\u5347\u3002\u56e0\u800c\u76f4\u89c9\u6765\u770b\uff0c\u5728\u8bad\u7ec3\u5f00\u59cb\u7684\u65f6\u5019\uff0c\u4f7f\u7528\u8f83\u4f4e\u7684IoU threshold,\u540e\u9762\u9010\u6e10\u52a0\u5927(\u6307\u5f97\u662f\u7b2c\u4e8c\u9636\u6bb5\u7684Gt assignment) Dynamic Loss","title":"Dynamic R-CNN: Towards High Quality Object Detection via Dynamic Training"},{"location":"other_categories/object_detection_2D/DynamicRCNN/#dynamic-r-cnn-towards-high-quality-object-detection-via-dynamic-training","text":"\u672c\u6587\u63d0\u4f9b\u4e00\u4e2a\u57fa\u4e8emmdetection\u7684config\u5b9e\u73b0\uff0c\u5df2\u7ecf\u52a0\u5165mmdetection master\u5206\u652f . \u672c\u6587\u7684\u60f3\u6cd5\u662f\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u52a8\u6001\u8c03\u6574Label Assignment\u7684\u65b9\u5f0f\u4ee5\u53ca SmoothL1 Loss\u7684\u53c2\u6570\uff0c\u4f7f\u5f97\u968f\u7740\u8bad\u7ec3\u7684\u8fdb\u6b65.\u8bad\u7ec3\u51fa\u6765\u7684\u7f51\u7edc\u5b9a\u4f4d\u7cbe\u5ea6\u8f83\u5927\u5e45\u5ea6\u63d0\u5347(IoU threshold 0.9\u65f6AP\u63d0\u53475.5%).\u4e14\u4e0d\u589e\u52a0\u63a8\u7406\u6d88\u8d39\u3002","title":"Dynamic R-CNN: Towards High Quality Object Detection via Dynamic Training"},{"location":"other_categories/object_detection_2D/DynamicRCNN/#dynamic-label-assignment","text":"\u4f5c\u8005\u6307\u51faanchor-based \u65b9\u6cd5\u5728\u5206\u914danchor\u7684\u65f6\u5019\u4f7f\u7528\u7684IoU threshold\u5c3d\u7ba1\u4e0e\u603b\u4f53\u7684mAP\u6ca1\u6709\u7ebf\u6027\u76f8\u5173\u6027\uff0c\u4f46\u662f\u968f\u7740IoU threshold\u589e\u5927\uff0c\u7f51\u7edc\u5728\u9ad8IoU threshold\u4e0b\u7684AP\u5c31\u8d8a\u9ad8(\u4f4eIoU threshold\u4e0b\u7684AP\u8d8a\u4f4e)\u3002 \u4f5c\u8005\u56e0\u800c\u6307\u51fa\uff0c\u5982\u679cobject detector\u60f3\u5f97\u5230\u66f4\u9ad8\u7684\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u5728\u8bad\u7ec3\u7f51\u7edc\u90fd\u65f6\u5019\u5e94\u8be5\u9700\u8981\u6bd4\u8f83\u8fbe\u5230IoU Threshold. \u4f46\u662f\u76f4\u63a5\u8fd9\u6837\u505a\u4f1a\u4f7f\u5f97\u6b63\u6837\u672c\u90fd\u6ca1\u4e86\uff0c \u4f5c\u8005\u6307\u51fa\uff0c\u968f\u7740\u8bad\u7ec3\u8fc7\u7a0b\u7684\u63a8\u8fdb\uff0c\u56de\u5f52\u6548\u679c\u4e5f\u90fd\u5728\u63d0\u5347\u3002\u56e0\u800c\u76f4\u89c9\u6765\u770b\uff0c\u5728\u8bad\u7ec3\u5f00\u59cb\u7684\u65f6\u5019\uff0c\u4f7f\u7528\u8f83\u4f4e\u7684IoU threshold,\u540e\u9762\u9010\u6e10\u52a0\u5927(\u6307\u5f97\u662f\u7b2c\u4e8c\u9636\u6bb5\u7684Gt assignment)","title":"Dynamic Label Assignment"},{"location":"other_categories/object_detection_2D/DynamicRCNN/#dynamic-loss","text":"","title":"Dynamic Loss"},{"location":"other_categories/object_detection_2D/EfficientDet/","text":"EfficientDet: Scalable and Efficient Object Detection \u8fd9\u7bc7\u6587\u7ae0\u7cfb\u7edf\u5730\u63d0\u51fa\u4e86 BiFPN(weighted bidirectional feature pyramid network),\u5e76\u63d0\u51fa\u4e86\u4e00\u5957scale up\u7684\u65b9\u6cd5\uff0c\u6700\u7ec8\u63d0\u51fa\u4e86EfficientDet,\u6839\u636epaper\u7684\u8bf4\u6cd5\u76f8\u8f83\u4e8e\u73b0\u6709\u7684benchmark\u53ef\u4ee5\u663e\u8457\u5730\u63d0\u5347\u901f\u5ea6\uff0c\u51cf\u5c11\u53c2\u6570\uff0c\u63d0\u5347\u7cbe\u5ea6.\u83dc\u5355\u4e0a\u7684\u4ee3\u7801\u8d85\u94fe\u63a5\u4e3a\u5b98\u65b9\u7684Tensorflow implementation, \u800c\u975e\u5b98\u65b9\u7684 Pytorch implementation \u4e5f\u5df2\u7ecf\u6709\u94fe\u63a5\u4e86.\u8fd9\u7bc7\u6587\u7ae0\u672c\u8d28\u4e0a\u662f EfficientNet \u8fd9\u4e00SOAT\u6a21\u578b\u5728\u68c0\u6d4b\u9886\u57df\u7684\u63a5\u7eed\u3002 BiFPN Block \u4f20\u7edf\u6765\u8bf4FPN\u53ef\u4ee5\u7528\u5982\u4e0b\u7684\u65b9\u7a0b\u5f0f\u8868\u8fbe: \\begin{array}{l}{P_{7}^{o u t}=\\operatorname{Conv}\\left(P_{7}^{i n}\\right)} \\\\ {P_{6}^{o u t}=\\operatorname{Conv}\\left(P_{6}^{i n}+\\operatorname{Resize}\\left(P_{7}^{o u t}\\right)\\right)} \\\\ {\\cdots} \\\\ {P_{3}^{o u t}=\\operatorname{Conv}\\left(P_{3}^{i n}+\\operatorname{Resize}\\left(P_{4}^{o u t}\\right)\\right)}\\end{array} \u5176\u4e2d Resize \u6307\u4ee3\u4e0a\u4e0b\u91c7\u6837\u4ee5\u8fbe\u5230\u76f8\u540c\u7684\u5206\u8fa8\u7387\u3002\u4e0d\u540c\u5206\u8fa8\u7387\u7684\u7279\u5f81\u5728\u878d\u5408\u7684\u65f6\u5019\u662f\u7b49\u6743\u5730\u6c42\u548c\u7684\u3002\u4f46\u662f\uff0c\u53ef\u4ee5\u731c\u6d4b and \u89c2\u6d4b\u5230\u4e0d\u540cscale\u7684\u7279\u5f81\u5bf9\u5f53\u524dscale\u7684\u8f93\u51fa\u7684\u8d21\u732e\u5e94\u8be5\u662f\u4e0d\u540c\u7684\uff0c\u56e0\u6b64\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e09\u79cd\u52a0\u6743\u878d\u5408\u7279\u5f81\u7684\u65b9\u5f0f 1. Unbounded Fusion: O = \\sum_i w_iI_i \u4e5f\u5c31\u662f\u76f4\u63a5\u6c42\u548c\uff0c\u4f5c\u8005\u53d1\u73b0\u8fd9\u79cd\u505a\u6cd5\u4f1a\u4f7f\u5f97\u8bad\u7ec3\u7ed3\u679c\u4e0d\u7a33\u5b9a\u3002\u56e0\u4e3a\u662fUnbounded\u7684\u878d\u5408 2. Softmax Fusion: O = \\sum_i \\frac{e^{w_i}}{\\sum_j e^{w_j}} I_i ,\u4f5c\u8005\u53d1\u73b0\u8fd9\u79cd\u505a\u6cd5\u7684\u8ba1\u7b97\u901f\u5ea6\u592a\u6162\u4e86\u3002 3. Fast-normalized Fusion: O = \\sum_i \\frac{w_i}{\\epsilon + \\sum_j w_j} I_j \u5176\u4e2d\u6bcf\u4e00\u4e2a\u6743\u91cd w_i \u90fd\u662fReLU\u7684\u7ed3\u679c\uff0c\u800c \\epsilon \u662f\u4e00\u4e2a\u5f88\u5c0f\u7684\u503c\u7528\u4e8e\u7a33\u5b9a\u8ba1\u7b97\u3002\u8ba1\u7b97\u901f\u5ea6\u8f83\u5feb\uff0c\u6027\u80fd\u4e0esoftmax\u76f8\u8fd1\u3002 EfficientDet Backbone\u4e3a\u540c\u4e00\u7ec4\u4f5c\u8005\u7684 EfficientNet Scaling Up \u6b63\u5982 EfficientNet \u7684\u505a\u6cd5\uff0c\u4f5c\u8005\u540c\u6837\u575a\u6301\u968f\u7740\u8f93\u5165\u56fe\u7247\u7684\u50cf\u7d20\u589e\u5927\uff0c\u6a21\u578b\u4e5f\u9700\u8981\u53d8\u5927\u3001\u53d8\u6df1\u3001\u53d8\u5bbd\u3002\u5728Detection\u4e2d\uff0cBackbone\u7684Scale Up\u4e0e EfficientNet \u4e2d\u7684\u4e00\u81f4\u3002 BiFPN \u7684channel\u6570,\u6df1\u5ea6\u4e0e\u9884\u6d4b\u7f51\u7edc\u7684\u6df1\u5ea6\u53d8\u5316\u5982\u4e0b W_{b i f p n}=64 \\cdot\\left(1.35^{\\phi}\\right), \\quad D_{b i f p n}=2+\\phi D_{b o x}=D_{c l a s s}=3+\\lfloor\\phi / 3\\rfloor \u8f93\u5165\u7684\u53d8\u5316\u4e3a R_{input} = 512+ \\phi * 128 \u4f5c\u8005\u7684\u5b9e\u9a8c\u5f88\u5b8c\u6574\uff0c\u503c\u5f97\u4e00\u8bfb","title":"EfficientDet: Scalable and Efficient Object Detection"},{"location":"other_categories/object_detection_2D/EfficientDet/#efficientdet-scalable-and-efficient-object-detection","text":"\u8fd9\u7bc7\u6587\u7ae0\u7cfb\u7edf\u5730\u63d0\u51fa\u4e86 BiFPN(weighted bidirectional feature pyramid network),\u5e76\u63d0\u51fa\u4e86\u4e00\u5957scale up\u7684\u65b9\u6cd5\uff0c\u6700\u7ec8\u63d0\u51fa\u4e86EfficientDet,\u6839\u636epaper\u7684\u8bf4\u6cd5\u76f8\u8f83\u4e8e\u73b0\u6709\u7684benchmark\u53ef\u4ee5\u663e\u8457\u5730\u63d0\u5347\u901f\u5ea6\uff0c\u51cf\u5c11\u53c2\u6570\uff0c\u63d0\u5347\u7cbe\u5ea6.\u83dc\u5355\u4e0a\u7684\u4ee3\u7801\u8d85\u94fe\u63a5\u4e3a\u5b98\u65b9\u7684Tensorflow implementation, \u800c\u975e\u5b98\u65b9\u7684 Pytorch implementation \u4e5f\u5df2\u7ecf\u6709\u94fe\u63a5\u4e86.\u8fd9\u7bc7\u6587\u7ae0\u672c\u8d28\u4e0a\u662f EfficientNet \u8fd9\u4e00SOAT\u6a21\u578b\u5728\u68c0\u6d4b\u9886\u57df\u7684\u63a5\u7eed\u3002","title":"EfficientDet: Scalable and Efficient Object Detection"},{"location":"other_categories/object_detection_2D/EfficientDet/#bifpn-block","text":"\u4f20\u7edf\u6765\u8bf4FPN\u53ef\u4ee5\u7528\u5982\u4e0b\u7684\u65b9\u7a0b\u5f0f\u8868\u8fbe: \\begin{array}{l}{P_{7}^{o u t}=\\operatorname{Conv}\\left(P_{7}^{i n}\\right)} \\\\ {P_{6}^{o u t}=\\operatorname{Conv}\\left(P_{6}^{i n}+\\operatorname{Resize}\\left(P_{7}^{o u t}\\right)\\right)} \\\\ {\\cdots} \\\\ {P_{3}^{o u t}=\\operatorname{Conv}\\left(P_{3}^{i n}+\\operatorname{Resize}\\left(P_{4}^{o u t}\\right)\\right)}\\end{array} \u5176\u4e2d Resize \u6307\u4ee3\u4e0a\u4e0b\u91c7\u6837\u4ee5\u8fbe\u5230\u76f8\u540c\u7684\u5206\u8fa8\u7387\u3002\u4e0d\u540c\u5206\u8fa8\u7387\u7684\u7279\u5f81\u5728\u878d\u5408\u7684\u65f6\u5019\u662f\u7b49\u6743\u5730\u6c42\u548c\u7684\u3002\u4f46\u662f\uff0c\u53ef\u4ee5\u731c\u6d4b and \u89c2\u6d4b\u5230\u4e0d\u540cscale\u7684\u7279\u5f81\u5bf9\u5f53\u524dscale\u7684\u8f93\u51fa\u7684\u8d21\u732e\u5e94\u8be5\u662f\u4e0d\u540c\u7684\uff0c\u56e0\u6b64\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e09\u79cd\u52a0\u6743\u878d\u5408\u7279\u5f81\u7684\u65b9\u5f0f 1. Unbounded Fusion: O = \\sum_i w_iI_i \u4e5f\u5c31\u662f\u76f4\u63a5\u6c42\u548c\uff0c\u4f5c\u8005\u53d1\u73b0\u8fd9\u79cd\u505a\u6cd5\u4f1a\u4f7f\u5f97\u8bad\u7ec3\u7ed3\u679c\u4e0d\u7a33\u5b9a\u3002\u56e0\u4e3a\u662fUnbounded\u7684\u878d\u5408 2. Softmax Fusion: O = \\sum_i \\frac{e^{w_i}}{\\sum_j e^{w_j}} I_i ,\u4f5c\u8005\u53d1\u73b0\u8fd9\u79cd\u505a\u6cd5\u7684\u8ba1\u7b97\u901f\u5ea6\u592a\u6162\u4e86\u3002 3. Fast-normalized Fusion: O = \\sum_i \\frac{w_i}{\\epsilon + \\sum_j w_j} I_j \u5176\u4e2d\u6bcf\u4e00\u4e2a\u6743\u91cd w_i \u90fd\u662fReLU\u7684\u7ed3\u679c\uff0c\u800c \\epsilon \u662f\u4e00\u4e2a\u5f88\u5c0f\u7684\u503c\u7528\u4e8e\u7a33\u5b9a\u8ba1\u7b97\u3002\u8ba1\u7b97\u901f\u5ea6\u8f83\u5feb\uff0c\u6027\u80fd\u4e0esoftmax\u76f8\u8fd1\u3002","title":"BiFPN Block"},{"location":"other_categories/object_detection_2D/EfficientDet/#efficientdet","text":"Backbone\u4e3a\u540c\u4e00\u7ec4\u4f5c\u8005\u7684 EfficientNet","title":"EfficientDet"},{"location":"other_categories/object_detection_2D/EfficientDet/#scaling-up","text":"\u6b63\u5982 EfficientNet \u7684\u505a\u6cd5\uff0c\u4f5c\u8005\u540c\u6837\u575a\u6301\u968f\u7740\u8f93\u5165\u56fe\u7247\u7684\u50cf\u7d20\u589e\u5927\uff0c\u6a21\u578b\u4e5f\u9700\u8981\u53d8\u5927\u3001\u53d8\u6df1\u3001\u53d8\u5bbd\u3002\u5728Detection\u4e2d\uff0cBackbone\u7684Scale Up\u4e0e EfficientNet \u4e2d\u7684\u4e00\u81f4\u3002 BiFPN \u7684channel\u6570,\u6df1\u5ea6\u4e0e\u9884\u6d4b\u7f51\u7edc\u7684\u6df1\u5ea6\u53d8\u5316\u5982\u4e0b W_{b i f p n}=64 \\cdot\\left(1.35^{\\phi}\\right), \\quad D_{b i f p n}=2+\\phi D_{b o x}=D_{c l a s s}=3+\\lfloor\\phi / 3\\rfloor \u8f93\u5165\u7684\u53d8\u5316\u4e3a R_{input} = 512+ \\phi * 128 \u4f5c\u8005\u7684\u5b9e\u9a8c\u5f88\u5b8c\u6574\uff0c\u503c\u5f97\u4e00\u8bfb","title":"Scaling Up"},{"location":"other_categories/object_detection_2D/FCOS/","text":"FCOS: Fully Convolutional One-Stage Object Detection \u672c\u6587\u662fanchor-free object detection\u7684\u53c8\u4e00\u4ee3\u8868\u4f5c\u54c1\uff0c\u5176\u6709\u6548\u6027\u5e94\u8be5\u662f\u663e\u8457\uff0c\u56e0\u4e3a\u5728\u540e\u6765\u7684\u5176\u4ed6object detection\u8bba\u6587\u4e2d\u8fdb\u884c\u4e86\u4f7f\u7528\uff0c\u5305\u62ec DSGN . \u672c\u6587\u5728 mmdetection \u4e2d\u4e5f\u6709\u590d\u73b0\uff0c\u6bd4\u5229\u7528maskrcnn-benchmark\u7684\u5b98\u65b9\u4ee3\u7801\u8981\u5bb9\u6613\u8bfb,\u5176\u5728 mmdetection \u4e2d\u7684\u4e3b\u8981\u4ee3\u7801\u5728 fcos_head.py FCOS - Output definition \u5bf9\u4e8e\u56fe\u7247\u4e2d\u7684\u6bcf\u4e00\u4e2a\u70b9\uff0c\u5982\u679c\u5b83\u662f\u6b63\u6837\u672c\uff0c\u90a3\u4e48\u76f4\u63a5\u56de\u5f52\u5b83\u5230\u56db\u4e2a\u8fb9\u754c\u7684\u8ddd\u79bb\u3002\u8fd9\u4e2a\u662fFCOS\u4e3b\u8981\u7684\u56de\u5f52\u5f62\u5f0f\uff0c\u4ee5\u6b64\u6765\u66ff\u4ee3anchor box FCOS - Ground Truth seperation \u8fd9\u4e00\u6bb5\u518d\u8865\u5145\u8bf4\u660e\u57fa\u4e8eretinanet\u7684FCOS\u5728\u65e0anchors\u7684\u60c5\u51b5\u4e0b\u5982\u4f55\u5206\u914dground truth\uff0c\u7531\u4e8eRetinanet\u7684\u7ed3\u6784\u6027\u8d28\uff0c\u4e0d\u540c\u5c42\u88ab\u5206\u914d\u4e0d\u540c\u7684\u611f\u53d7\u91ce\u4efb\u52a1\uff0c\u4f5c\u8005hardcode\u4e86\uff0c\u5bf9\u4e8e\u7b2c i \u5c42\u7684\u7f51\u7edc\uff0c\u53ea\u8d1f\u8d23 m_{i-1}< max(l*, r*, t*, b*) < m_i \u7684object,\u5176\u4e2d m_i \u4e3a\u6839\u636eFPN\u611f\u53d7\u91ce\u7684hardcode\u503c\uff0c\u5177\u4f53\u770b\u8bba\u6587\u3002 \u6bcf\u4e00\u4e2a\u70b9\uff0c\u53ea\u8981\u5b83\u5728\u5bf9\u5e94object\u7684\u6846\u5185\uff0c\u5b83\u5c31\u662f\u6b63\u6837\u672c\uff0c\u5982\u679c\u540c\u4e00\u4e2ascale\u5185\u4e00\u4e2a\u70b9\u4ecd\u5bf9\u5e94\u591a\u4e2agt object\uff0c\u5c31\u4ee5\u9762\u79ef\u6700\u5c0f\u7684\u4e3atarget. FCOS - centerness \u7531\u4e8e\u5206\u914d\u4e86\u5927\u91cf\u7684\u6b63\u6837\u672c\uff0c\u8fd9\u6837\u76f4\u63a5\u8bad\u7ec3\u7684\u7ed3\u679c\u662f\u6709\u5927\u91cf\u7684\u8fb9\u7f18\u70b9\u7ed9\u51fa\u9519\u8bef\u7684bbox\uff0c\u4f5c\u8005\u8fdb\u4e00\u6b65\u8865\u5145\uff0c\u8981\u6c42\u7f51\u7edc\u5bf9\u6bcf\u4e00\u4e2a\u70b9\u7ed9\u51fa\u4e00\u4e2a\"centerness\"\u7684\u4f30\u8ba1\uff0c\u5176\u76ee\u6807\u503c\u4e3a\uff1a \\text { centerness }^{*}=\\sqrt{\\frac{\\min \\left(l^{*}, r^{*}\\right)}{\\max \\left(l^{*}, r^{*}\\right)} \\times \\frac{\\min \\left(t^{*}, b^{*}\\right)}{\\max \\left(t^{*}, b^{*}\\right)}} \u5728inference\u7684\u65f6\u5019\uff0c\u6839\u636ecenterness\u8fdb\u884cNMS\u800c\u975e\u5206\u7c7b\u7f6e\u4fe1\u5ea6\uff0c\u6700\u7ec8\u80fd\u663e\u8457\u7684\u63d0\u5347\u7ed3\u679c\u3002","title":"FCOS: Fully Convolutional One-Stage Object Detection"},{"location":"other_categories/object_detection_2D/FCOS/#fcos-fully-convolutional-one-stage-object-detection","text":"\u672c\u6587\u662fanchor-free object detection\u7684\u53c8\u4e00\u4ee3\u8868\u4f5c\u54c1\uff0c\u5176\u6709\u6548\u6027\u5e94\u8be5\u662f\u663e\u8457\uff0c\u56e0\u4e3a\u5728\u540e\u6765\u7684\u5176\u4ed6object detection\u8bba\u6587\u4e2d\u8fdb\u884c\u4e86\u4f7f\u7528\uff0c\u5305\u62ec DSGN . \u672c\u6587\u5728 mmdetection \u4e2d\u4e5f\u6709\u590d\u73b0\uff0c\u6bd4\u5229\u7528maskrcnn-benchmark\u7684\u5b98\u65b9\u4ee3\u7801\u8981\u5bb9\u6613\u8bfb,\u5176\u5728 mmdetection \u4e2d\u7684\u4e3b\u8981\u4ee3\u7801\u5728 fcos_head.py","title":"FCOS: Fully Convolutional One-Stage Object Detection"},{"location":"other_categories/object_detection_2D/FCOS/#fcos-output-definition","text":"\u5bf9\u4e8e\u56fe\u7247\u4e2d\u7684\u6bcf\u4e00\u4e2a\u70b9\uff0c\u5982\u679c\u5b83\u662f\u6b63\u6837\u672c\uff0c\u90a3\u4e48\u76f4\u63a5\u56de\u5f52\u5b83\u5230\u56db\u4e2a\u8fb9\u754c\u7684\u8ddd\u79bb\u3002\u8fd9\u4e2a\u662fFCOS\u4e3b\u8981\u7684\u56de\u5f52\u5f62\u5f0f\uff0c\u4ee5\u6b64\u6765\u66ff\u4ee3anchor box","title":"FCOS - Output definition"},{"location":"other_categories/object_detection_2D/FCOS/#fcos-ground-truth-seperation","text":"\u8fd9\u4e00\u6bb5\u518d\u8865\u5145\u8bf4\u660e\u57fa\u4e8eretinanet\u7684FCOS\u5728\u65e0anchors\u7684\u60c5\u51b5\u4e0b\u5982\u4f55\u5206\u914dground truth\uff0c\u7531\u4e8eRetinanet\u7684\u7ed3\u6784\u6027\u8d28\uff0c\u4e0d\u540c\u5c42\u88ab\u5206\u914d\u4e0d\u540c\u7684\u611f\u53d7\u91ce\u4efb\u52a1\uff0c\u4f5c\u8005hardcode\u4e86\uff0c\u5bf9\u4e8e\u7b2c i \u5c42\u7684\u7f51\u7edc\uff0c\u53ea\u8d1f\u8d23 m_{i-1}< max(l*, r*, t*, b*) < m_i \u7684object,\u5176\u4e2d m_i \u4e3a\u6839\u636eFPN\u611f\u53d7\u91ce\u7684hardcode\u503c\uff0c\u5177\u4f53\u770b\u8bba\u6587\u3002 \u6bcf\u4e00\u4e2a\u70b9\uff0c\u53ea\u8981\u5b83\u5728\u5bf9\u5e94object\u7684\u6846\u5185\uff0c\u5b83\u5c31\u662f\u6b63\u6837\u672c\uff0c\u5982\u679c\u540c\u4e00\u4e2ascale\u5185\u4e00\u4e2a\u70b9\u4ecd\u5bf9\u5e94\u591a\u4e2agt object\uff0c\u5c31\u4ee5\u9762\u79ef\u6700\u5c0f\u7684\u4e3atarget.","title":"FCOS - Ground Truth seperation"},{"location":"other_categories/object_detection_2D/FCOS/#fcos-centerness","text":"\u7531\u4e8e\u5206\u914d\u4e86\u5927\u91cf\u7684\u6b63\u6837\u672c\uff0c\u8fd9\u6837\u76f4\u63a5\u8bad\u7ec3\u7684\u7ed3\u679c\u662f\u6709\u5927\u91cf\u7684\u8fb9\u7f18\u70b9\u7ed9\u51fa\u9519\u8bef\u7684bbox\uff0c\u4f5c\u8005\u8fdb\u4e00\u6b65\u8865\u5145\uff0c\u8981\u6c42\u7f51\u7edc\u5bf9\u6bcf\u4e00\u4e2a\u70b9\u7ed9\u51fa\u4e00\u4e2a\"centerness\"\u7684\u4f30\u8ba1\uff0c\u5176\u76ee\u6807\u503c\u4e3a\uff1a \\text { centerness }^{*}=\\sqrt{\\frac{\\min \\left(l^{*}, r^{*}\\right)}{\\max \\left(l^{*}, r^{*}\\right)} \\times \\frac{\\min \\left(t^{*}, b^{*}\\right)}{\\max \\left(t^{*}, b^{*}\\right)}} \u5728inference\u7684\u65f6\u5019\uff0c\u6839\u636ecenterness\u8fdb\u884cNMS\u800c\u975e\u5206\u7c7b\u7f6e\u4fe1\u5ea6\uff0c\u6700\u7ec8\u80fd\u663e\u8457\u7684\u63d0\u5347\u7ed3\u679c\u3002","title":"FCOS - centerness"},{"location":"other_categories/object_detection_2D/GFocalLoss/","text":"Generalized Focal Loss: Learning Qualified and Distributed Bounding Boxes for Dense Object Detection \u8fd9\u7bc7paper\u7684\u521d\u8877\u662f\u5206\u6790IoU Centerness\u4e0eclassification loss\u7684\u76f8\u5173\u95ee\u9898\uff0c\u5728NMS\u7684\u65f6\u5019\uff0c\u6211\u4eec\u4f7f\u7528\u7684\u662fIoU Centerness\u548ccls Score\u7684\u4e58\u79ef\uff0c\u4f46\u662f\u8bad\u7ec3\u7684\u65f6\u5019\uff0ccls Score\u4f7f\u7528focal loss\u800cIoU Centerness\u88ab\u89c6\u4e3a\u56de\u5f52\u95ee\u9898\u3002\u8fd9\u5c31\u6784\u6210\u4e86\u4e00\u5b9a\u7684\u4e0d\u5339\u914d\u3002 \u672c\u6587\u501f\u6b64\u9996\u5148\u63d0\u51fa\u4e86 Quality Focal loss,\u4f7f\u5f97focal loss\u53ef\u4ee5\u7edf\u4e00\u5230\"\u8fde\u7eed\u7684\u5206\u7c7b\u95ee\u9898\",\u5176\u4e8c\u672c\u6587\u8fdb\u4e00\u6b65\u8003\u8651\u5c06\u8fd9\u4e2a\u6982\u5ff5\u8fdb\u884c\u6269\u5c55\u5230Distribution Focal Loss\uff0c\u53ef\u4ee5\u62df\u5408\u4efb\u610floss\uff0c\u6700\u540e\u63d0\u51fa\u7684Generalized Focal loss\u878d\u5408\u591a\u79cd\u60c5\u51b5\u3002 Focal loss \\mathbf{F L}(p)=-\\left(1-p_{t}\\right)^{\\gamma} \\log \\left(p_{t}\\right), p_{t}=\\left\\{\\begin{aligned} p, & \\text { when } y=1 \\\\ 1-p, & \\text { when } y=0 \\end{aligned}\\right. Quality Focal Loss \\mathbf{Q} \\mathbf{F} \\mathbf{L}(\\sigma)=-|y-\\sigma|^{\\beta}((1-y) \\log (1-\\sigma)+y \\log (\\sigma)) def quality_focal_loss ( pred , # (n, 80) label , # (n) 0, 1-80: 0 is neg, 1-80 is positive score , # (n) reg target 0-1, only positive is good weight = None , beta = 2.0 , reduction = 'mean' , avg_factor = None ): \"\"\" from https://github.com/implus/GFocal/blob/cc0e72680f16a8abe0770eb531d6baa07a6e511f/mmdet/models/losses/gfocal_loss.py \"\"\" # all goes to 0 pred_sigmoid = pred . sigmoid () pt = pred_sigmoid zerolabel = pt . new_zeros ( pred . shape ) loss = F . binary_cross_entropy_with_logits ( pred , zerolabel , reduction = 'none' ) * pt . pow ( beta ) label = label - 1 pos = ( label >= 0 ) . nonzero () . squeeze ( 1 ) a = pos b = label [ pos ] . long () # positive goes to bbox quality pt = score [ a ] - pred_sigmoid [ a , b ] loss [ a , b ] = F . binary_cross_entropy_with_logits ( pred [ a , b ], score [ a ], reduction = 'none' ) * pt . pow ( beta ) loss = weight_reduce_loss ( loss , weight , reduction , avg_factor ) return loss Distribution Focal Loss (DFL) \u5f53\u6211\u4eec\u4f7f\u7528\u5e8f\u5217\u7684\u591a\u4e2a\u5206\u7c7b\u503c(multi-bin)\u5206\u7c7b\u65f6\uff0cinference\u7684\u65f6\u5019\u6211\u4eec\u4f7f\u7528 \\hat{y}=\\sum_{i=0}^{n} P\\left(y_{i}\\right) y_{i} \u3002 \\mathbf{D F L}\\left(\\mathcal{S}_{i}, \\mathcal{S}_{i+1}\\right)=-\\left(\\left(y_{i+1}-y\\right) \\log \\left(\\mathcal{S}_{i}\\right)+\\left(y-y_{i}\\right) \\log \\left(\\mathcal{S}_{i+1}\\right)\\right) \u5176\u4e2d \\mathcal{S}_{i}=\\frac{y_{i+1}-y}{y_{i+1}-y_{i}}, \\mathcal{S}_{i+1}=\\frac{y-y_{i}}{y_{i+1}-y_{i}} ,\u76f4\u89c9\u5c31\u662f\u6309\u7167\u6743\u91cd\u4f7f\u7528loss\u9f13\u52b1multibin ground truth\u4e34\u8fd1\u7684\u4e24\u4fa7\u5206\u7c7b\u70b9\u7684\u6743\u91cd\u3002 def distribution_focal_loss ( pred , label , weight = None , reduction = 'mean' , avg_factor = None ): \"\"\" from https://github.com/implus/GFocal/blob/cc0e72680f16a8abe0770eb531d6baa07a6e511f/mmdet/models/losses/gfocal_loss.py \"\"\" disl = label . long () disr = disl + 1 wl = disr . float () - label wr = label - disl . float () loss = F . cross_entropy ( pred , disl , reduction = 'none' ) * wl \\ + F . cross_entropy ( pred , disr , reduction = 'none' ) * wr loss = weight_reduce_loss ( loss , weight , reduction , avg_factor ) return loss Generalized Focal Loss (GFL) \\mathbf{G F L}\\left(p_{y_{l}}, p_{y_{r}}\\right)=-\\left|y-\\left(y_{l} p_{y_{l}}+y_{r} p_{y_{r}}\\right)\\right|^{\\beta}\\left(\\left(y_{r}-y\\right) \\log \\left(p_{y_{l}}\\right)+\\left(y-y_{l}\\right) \\log \\left(p_{y_{r}}\\right)\\right) function focal_loss_y(x, gamma){ return - Math.pow(1-x, gamma) * Math.log(x) } function quality_focal_loss_y(x, y){ return - Math.pow(y-x, 2) * ((1-y) * Math.log(1-x) + y * Math.log(x)) } function get_focal_loss_list(p, gamma){ focal = [] for (j = 0; j < 98;j++){ focal.push(focal_loss_y(p[j], gamma)) } return focal } function get_quality_focal_loss_list(p, y){ focal = [] for (j = 0; j < 98;j++){ focal.push(quality_focal_loss_y(p[j], y)) } return focal } focalLoss = document.getElementById('focalLoss'); var p = []; for (i = 1; i < 99;i++){ p.push(i * 0.01); } var focal = get_focal_loss_list(p, 0.2) slider_steps = [] for (i = 0.2; i < 4; i += 0.2){ slider_steps.push( { method: 'animate', label: Math.floor(i * 100) /100, args: [ { data: [{ x:p, y: get_focal_loss_list(p, i)}], }, { transition: {duration: 20}, frame: {duration: 20, redraw: false}, } ] } ) } var qfocal = get_quality_focal_loss_list(p, 0.5) qslider_steps = [] for (i = 0.02; i < 0.98; i += 0.02){ qslider_steps.push( { method: 'animate', label: Math.floor(i * 100) /100, args: [ { data: [{ x:p, y: get_quality_focal_loss_list(p, i)}], }, { transition: {duration: 20}, frame: {duration: 20, redraw: false}, } ] } ) } Plotly.plot(focalLoss, [{ x: p, y: focal, }], { title: 'Focal Loss for positive samples', xaxis: { title: 'p' }, yaxis: { title: 'loss' }, sliders: [{ pad: {t: 30}, currentvalue: { xanchor: 'right', prefix: 'gamma: ', font: { color: '#888', size: 20 } }, steps: slider_steps }] }); Plotly.plot(qfocalLoss, [{ x: p, y: qfocal, }], { title: 'Quality Focal Loss with beta=2', xaxis: { title: 'p' }, yaxis: { title: 'loss' }, sliders: [{ pad: {t: 30}, currentvalue: { xanchor: 'right', prefix: 'gt_y: ', font: { color: '#888', size: 20 } }, steps: qslider_steps }] });","title":"Generalized Focal Loss: Learning Qualified and Distributed Bounding Boxes for Dense Object Detection"},{"location":"other_categories/object_detection_2D/GFocalLoss/#generalized-focal-loss-learning-qualified-and-distributed-bounding-boxes-for-dense-object-detection","text":"\u8fd9\u7bc7paper\u7684\u521d\u8877\u662f\u5206\u6790IoU Centerness\u4e0eclassification loss\u7684\u76f8\u5173\u95ee\u9898\uff0c\u5728NMS\u7684\u65f6\u5019\uff0c\u6211\u4eec\u4f7f\u7528\u7684\u662fIoU Centerness\u548ccls Score\u7684\u4e58\u79ef\uff0c\u4f46\u662f\u8bad\u7ec3\u7684\u65f6\u5019\uff0ccls Score\u4f7f\u7528focal loss\u800cIoU Centerness\u88ab\u89c6\u4e3a\u56de\u5f52\u95ee\u9898\u3002\u8fd9\u5c31\u6784\u6210\u4e86\u4e00\u5b9a\u7684\u4e0d\u5339\u914d\u3002 \u672c\u6587\u501f\u6b64\u9996\u5148\u63d0\u51fa\u4e86 Quality Focal loss,\u4f7f\u5f97focal loss\u53ef\u4ee5\u7edf\u4e00\u5230\"\u8fde\u7eed\u7684\u5206\u7c7b\u95ee\u9898\",\u5176\u4e8c\u672c\u6587\u8fdb\u4e00\u6b65\u8003\u8651\u5c06\u8fd9\u4e2a\u6982\u5ff5\u8fdb\u884c\u6269\u5c55\u5230Distribution Focal Loss\uff0c\u53ef\u4ee5\u62df\u5408\u4efb\u610floss\uff0c\u6700\u540e\u63d0\u51fa\u7684Generalized Focal loss\u878d\u5408\u591a\u79cd\u60c5\u51b5\u3002","title":"Generalized Focal Loss: Learning Qualified and Distributed Bounding Boxes for Dense Object Detection"},{"location":"other_categories/object_detection_2D/GFocalLoss/#focal-loss","text":"\\mathbf{F L}(p)=-\\left(1-p_{t}\\right)^{\\gamma} \\log \\left(p_{t}\\right), p_{t}=\\left\\{\\begin{aligned} p, & \\text { when } y=1 \\\\ 1-p, & \\text { when } y=0 \\end{aligned}\\right.","title":"Focal loss"},{"location":"other_categories/object_detection_2D/GFocalLoss/#quality-focal-loss","text":"\\mathbf{Q} \\mathbf{F} \\mathbf{L}(\\sigma)=-|y-\\sigma|^{\\beta}((1-y) \\log (1-\\sigma)+y \\log (\\sigma)) def quality_focal_loss ( pred , # (n, 80) label , # (n) 0, 1-80: 0 is neg, 1-80 is positive score , # (n) reg target 0-1, only positive is good weight = None , beta = 2.0 , reduction = 'mean' , avg_factor = None ): \"\"\" from https://github.com/implus/GFocal/blob/cc0e72680f16a8abe0770eb531d6baa07a6e511f/mmdet/models/losses/gfocal_loss.py \"\"\" # all goes to 0 pred_sigmoid = pred . sigmoid () pt = pred_sigmoid zerolabel = pt . new_zeros ( pred . shape ) loss = F . binary_cross_entropy_with_logits ( pred , zerolabel , reduction = 'none' ) * pt . pow ( beta ) label = label - 1 pos = ( label >= 0 ) . nonzero () . squeeze ( 1 ) a = pos b = label [ pos ] . long () # positive goes to bbox quality pt = score [ a ] - pred_sigmoid [ a , b ] loss [ a , b ] = F . binary_cross_entropy_with_logits ( pred [ a , b ], score [ a ], reduction = 'none' ) * pt . pow ( beta ) loss = weight_reduce_loss ( loss , weight , reduction , avg_factor ) return loss","title":"Quality Focal Loss"},{"location":"other_categories/object_detection_2D/GFocalLoss/#distribution-focal-loss-dfl","text":"\u5f53\u6211\u4eec\u4f7f\u7528\u5e8f\u5217\u7684\u591a\u4e2a\u5206\u7c7b\u503c(multi-bin)\u5206\u7c7b\u65f6\uff0cinference\u7684\u65f6\u5019\u6211\u4eec\u4f7f\u7528 \\hat{y}=\\sum_{i=0}^{n} P\\left(y_{i}\\right) y_{i} \u3002 \\mathbf{D F L}\\left(\\mathcal{S}_{i}, \\mathcal{S}_{i+1}\\right)=-\\left(\\left(y_{i+1}-y\\right) \\log \\left(\\mathcal{S}_{i}\\right)+\\left(y-y_{i}\\right) \\log \\left(\\mathcal{S}_{i+1}\\right)\\right) \u5176\u4e2d \\mathcal{S}_{i}=\\frac{y_{i+1}-y}{y_{i+1}-y_{i}}, \\mathcal{S}_{i+1}=\\frac{y-y_{i}}{y_{i+1}-y_{i}} ,\u76f4\u89c9\u5c31\u662f\u6309\u7167\u6743\u91cd\u4f7f\u7528loss\u9f13\u52b1multibin ground truth\u4e34\u8fd1\u7684\u4e24\u4fa7\u5206\u7c7b\u70b9\u7684\u6743\u91cd\u3002 def distribution_focal_loss ( pred , label , weight = None , reduction = 'mean' , avg_factor = None ): \"\"\" from https://github.com/implus/GFocal/blob/cc0e72680f16a8abe0770eb531d6baa07a6e511f/mmdet/models/losses/gfocal_loss.py \"\"\" disl = label . long () disr = disl + 1 wl = disr . float () - label wr = label - disl . float () loss = F . cross_entropy ( pred , disl , reduction = 'none' ) * wl \\ + F . cross_entropy ( pred , disr , reduction = 'none' ) * wr loss = weight_reduce_loss ( loss , weight , reduction , avg_factor ) return loss","title":"Distribution Focal Loss (DFL)"},{"location":"other_categories/object_detection_2D/GFocalLoss/#generalized-focal-loss-gfl","text":"\\mathbf{G F L}\\left(p_{y_{l}}, p_{y_{r}}\\right)=-\\left|y-\\left(y_{l} p_{y_{l}}+y_{r} p_{y_{r}}\\right)\\right|^{\\beta}\\left(\\left(y_{r}-y\\right) \\log \\left(p_{y_{l}}\\right)+\\left(y-y_{l}\\right) \\log \\left(p_{y_{r}}\\right)\\right) function focal_loss_y(x, gamma){ return - Math.pow(1-x, gamma) * Math.log(x) } function quality_focal_loss_y(x, y){ return - Math.pow(y-x, 2) * ((1-y) * Math.log(1-x) + y * Math.log(x)) } function get_focal_loss_list(p, gamma){ focal = [] for (j = 0; j < 98;j++){ focal.push(focal_loss_y(p[j], gamma)) } return focal } function get_quality_focal_loss_list(p, y){ focal = [] for (j = 0; j < 98;j++){ focal.push(quality_focal_loss_y(p[j], y)) } return focal } focalLoss = document.getElementById('focalLoss'); var p = []; for (i = 1; i < 99;i++){ p.push(i * 0.01); } var focal = get_focal_loss_list(p, 0.2) slider_steps = [] for (i = 0.2; i < 4; i += 0.2){ slider_steps.push( { method: 'animate', label: Math.floor(i * 100) /100, args: [ { data: [{ x:p, y: get_focal_loss_list(p, i)}], }, { transition: {duration: 20}, frame: {duration: 20, redraw: false}, } ] } ) } var qfocal = get_quality_focal_loss_list(p, 0.5) qslider_steps = [] for (i = 0.02; i < 0.98; i += 0.02){ qslider_steps.push( { method: 'animate', label: Math.floor(i * 100) /100, args: [ { data: [{ x:p, y: get_quality_focal_loss_list(p, i)}], }, { transition: {duration: 20}, frame: {duration: 20, redraw: false}, } ] } ) } Plotly.plot(focalLoss, [{ x: p, y: focal, }], { title: 'Focal Loss for positive samples', xaxis: { title: 'p' }, yaxis: { title: 'loss' }, sliders: [{ pad: {t: 30}, currentvalue: { xanchor: 'right', prefix: 'gamma: ', font: { color: '#888', size: 20 } }, steps: slider_steps }] }); Plotly.plot(qfocalLoss, [{ x: p, y: qfocal, }], { title: 'Quality Focal Loss with beta=2', xaxis: { title: 'p' }, yaxis: { title: 'loss' }, sliders: [{ pad: {t: 30}, currentvalue: { xanchor: 'right', prefix: 'gt_y: ', font: { color: '#888', size: 20 } }, steps: qslider_steps }] });","title":"Generalized Focal Loss (GFL)"},{"location":"other_categories/object_detection_2D/Gaussian_YOLOv3:_An_Accurate_and_Fast_Object_Detector_Using_Localization_Uncertainty_for_Autonomous_Driving/","text":"Gaussian YOLOv3: An Accurate and Fast Object Detector Using Localization Uncertainty for Autonomous Driving \u8fd9\u7bc7\u8bba\u6587\u5f15\u5165\u4e86Gaussian Yolov3,\u5728inference\u4e2d\u9884\u6d4b\u5b9a\u4f4d\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u51cf\u5c11\u4e86False Positive,\u4ee5\u63d0\u5347\u70b9\u6570\u3002\u8fd9\u4e2a\u8bba\u6587\u7684\u4e3b\u8981\u601d\u8def\u8d21\u732e\u5728\u4e8e\uff0c\u5728inference\u7684\u65f6\u5019\u901a\u8fc7\u5bf9\u8fb9\u6846\u7684\u4e0d\u786e\u5b9a\u6027\u7684\u4f30\u8ba1\u4fee\u6b63inference\u65f6\u7684\u4f30\u8ba1\u3002\u4f7f\u5f97NMS\u65f6\u4f1a\u771f\u6b63\u9009\u62e9\u5bf9\u4f4d\u7f6e\u786e\u5b9a\u6027\u6700\u9ad8\u7684\u6846\u3002 Gaussian Yolov3 \u7ed3\u6784 Yolov3\u56de\u5f52\u8f93\u51fa\u7684bbox\u7ed3\u6784\u5305\u62ec t_x, t_y, t_w, t_h ,\u8fd9\u6837\u53ef\u4ee5\u7528\u9ad8\u65af\u6a21\u578b\u6765\u4f30\u8ba1\u3002\u672c\u6587\u7684\u7b97\u6cd5\u8f93\u5165\u5982\u56fe \u8f93\u51fa\u7ed3\u6784 \\begin{aligned} \\mu_{t_{x}}=\\sigma\\left(\\hat{\\mu}_{t_{x}}\\right), \\mu_{t_{y}} &=\\sigma\\left(\\hat{\\mu}_{t_{y}}\\right), \\mu_{t_{w}}=\\hat{\\mu}_{t_{w}}, \\mu_{t_{h}}=\\hat{\\mu}_{t_{h}} \\\\ \\Sigma_{t_{x}} &=\\sigma\\left(\\hat{\\Sigma}_{t_{x}}\\right), \\Sigma_{t_{y}}=\\sigma\\left(\\hat{\\Sigma}_{t_{y}}\\right) \\\\ \\Sigma_{t_{w}} &=\\sigma\\left(\\hat{\\Sigma}_{t_{w}}\\right), \\Sigma_{t_{h}}=\\sigma\\left(\\hat{\\Sigma}_{t_{h}}\\right) \\\\ \\sigma(x) &=\\frac{1}{(1+\\exp (-x))} \\end{aligned} \u635f\u5931\u51fd\u6570 \u8fd9\u91cc\u7528negative log likelihood\u635f\u5931 \\begin{aligned} L_x = - \\sum_{i=1}^W \\sum_{j=1}^H \\sum_{k=1}^K \\gamma_{ijk}log(N&(x^G_{jik}|\\mu_{t_x}(x_{ijk}))),\\\\ &\\sum_{t_x}(x_{ijk})) + \\epsilon) \\end{aligned} \u5176\u4e2dW,H,\u4e3agrids\u8f93\u51fa,K\u662fanchors\u7684\u6570\u91cf. inference \u5f53\u8f93\u51fa\u7684\u65f6\u5019,inference\u65f6\u5c06\u5404\u4e2aindex\u7684\u4e0d\u786e\u5b9a\u6027\u53d6\u5747\u503c\uff0c\u8fd9\u6837\u4f1a\u5bf9\u7c7b\u522b\u7684class score,\u4f1a\u5f62\u6210\u5f71\u54cd. C r .=\\sigma(\\text {Object}) \\times \\sigma\\left(\\text {Class}_{i}\\right) \\times\\left(1-\\text {Uncertainty}_{\\text {aver}}\\right)","title":"Gaussian YOLOv3: An Accurate and Fast Object Detector Using Localization Uncertainty for Autonomous Driving"},{"location":"other_categories/object_detection_2D/Gaussian_YOLOv3:_An_Accurate_and_Fast_Object_Detector_Using_Localization_Uncertainty_for_Autonomous_Driving/#gaussian-yolov3-an-accurate-and-fast-object-detector-using-localization-uncertainty-for-autonomous-driving","text":"\u8fd9\u7bc7\u8bba\u6587\u5f15\u5165\u4e86Gaussian Yolov3,\u5728inference\u4e2d\u9884\u6d4b\u5b9a\u4f4d\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u51cf\u5c11\u4e86False Positive,\u4ee5\u63d0\u5347\u70b9\u6570\u3002\u8fd9\u4e2a\u8bba\u6587\u7684\u4e3b\u8981\u601d\u8def\u8d21\u732e\u5728\u4e8e\uff0c\u5728inference\u7684\u65f6\u5019\u901a\u8fc7\u5bf9\u8fb9\u6846\u7684\u4e0d\u786e\u5b9a\u6027\u7684\u4f30\u8ba1\u4fee\u6b63inference\u65f6\u7684\u4f30\u8ba1\u3002\u4f7f\u5f97NMS\u65f6\u4f1a\u771f\u6b63\u9009\u62e9\u5bf9\u4f4d\u7f6e\u786e\u5b9a\u6027\u6700\u9ad8\u7684\u6846\u3002","title":"Gaussian YOLOv3: An Accurate and Fast Object Detector Using Localization Uncertainty for Autonomous Driving"},{"location":"other_categories/object_detection_2D/Gaussian_YOLOv3:_An_Accurate_and_Fast_Object_Detector_Using_Localization_Uncertainty_for_Autonomous_Driving/#gaussian-yolov3","text":"Yolov3\u56de\u5f52\u8f93\u51fa\u7684bbox\u7ed3\u6784\u5305\u62ec t_x, t_y, t_w, t_h ,\u8fd9\u6837\u53ef\u4ee5\u7528\u9ad8\u65af\u6a21\u578b\u6765\u4f30\u8ba1\u3002\u672c\u6587\u7684\u7b97\u6cd5\u8f93\u5165\u5982\u56fe","title":"Gaussian Yolov3 \u7ed3\u6784"},{"location":"other_categories/object_detection_2D/Gaussian_YOLOv3:_An_Accurate_and_Fast_Object_Detector_Using_Localization_Uncertainty_for_Autonomous_Driving/#_1","text":"\\begin{aligned} \\mu_{t_{x}}=\\sigma\\left(\\hat{\\mu}_{t_{x}}\\right), \\mu_{t_{y}} &=\\sigma\\left(\\hat{\\mu}_{t_{y}}\\right), \\mu_{t_{w}}=\\hat{\\mu}_{t_{w}}, \\mu_{t_{h}}=\\hat{\\mu}_{t_{h}} \\\\ \\Sigma_{t_{x}} &=\\sigma\\left(\\hat{\\Sigma}_{t_{x}}\\right), \\Sigma_{t_{y}}=\\sigma\\left(\\hat{\\Sigma}_{t_{y}}\\right) \\\\ \\Sigma_{t_{w}} &=\\sigma\\left(\\hat{\\Sigma}_{t_{w}}\\right), \\Sigma_{t_{h}}=\\sigma\\left(\\hat{\\Sigma}_{t_{h}}\\right) \\\\ \\sigma(x) &=\\frac{1}{(1+\\exp (-x))} \\end{aligned}","title":"\u8f93\u51fa\u7ed3\u6784"},{"location":"other_categories/object_detection_2D/Gaussian_YOLOv3:_An_Accurate_and_Fast_Object_Detector_Using_Localization_Uncertainty_for_Autonomous_Driving/#_2","text":"\u8fd9\u91cc\u7528negative log likelihood\u635f\u5931 \\begin{aligned} L_x = - \\sum_{i=1}^W \\sum_{j=1}^H \\sum_{k=1}^K \\gamma_{ijk}log(N&(x^G_{jik}|\\mu_{t_x}(x_{ijk}))),\\\\ &\\sum_{t_x}(x_{ijk})) + \\epsilon) \\end{aligned} \u5176\u4e2dW,H,\u4e3agrids\u8f93\u51fa,K\u662fanchors\u7684\u6570\u91cf.","title":"\u635f\u5931\u51fd\u6570"},{"location":"other_categories/object_detection_2D/Gaussian_YOLOv3:_An_Accurate_and_Fast_Object_Detector_Using_Localization_Uncertainty_for_Autonomous_Driving/#inference","text":"\u5f53\u8f93\u51fa\u7684\u65f6\u5019,inference\u65f6\u5c06\u5404\u4e2aindex\u7684\u4e0d\u786e\u5b9a\u6027\u53d6\u5747\u503c\uff0c\u8fd9\u6837\u4f1a\u5bf9\u7c7b\u522b\u7684class score,\u4f1a\u5f62\u6210\u5f71\u54cd. C r .=\\sigma(\\text {Object}) \\times \\sigma\\left(\\text {Class}_{i}\\right) \\times\\left(1-\\text {Uncertainty}_{\\text {aver}}\\right)","title":"inference"},{"location":"other_categories/object_detection_2D/IoU-uniform_R-CNN/","text":"IoU-uniform R-CNN: Breaking Through the Limitations of RPN \u8fd9\u7bc7\u8bba\u6587\u662f\u4e00\u7cfb\u5217\u9488\u5bf9NMS\u6216\u8005region proposal\u8bad\u7ec3\u63d0\u5347\u7684\u8bba\u6587\u4e4b\u4e00\uff0c\u5176\u4e2d\u6d89\u53ca\u4e86\u591a\u4e00\u4e2a\u6709\u610f\u4e49\u7684\u6982\u5ff5\u4e0e\u601d\u8def\u3002\u672c\u6587\u6838\u5fc3\u8d21\u732e\u662f\u5728RCNN(pooling \u6216 align\u540e\u7684\u7f51\u7edc)\u8bad\u7ec3\u8fc7\u7a0b\u4e2d. RPN \u4e0e rCNN \u4e24\u5927\u95ee\u9898 \u7b2c\u4e00\uff0c\u5728\u8bad\u7ec3\u7684\u65f6\u5019\uff0c\u76f8\u5f53\u90e8\u5206\u7684\u63d0\u4f9b\u7ed9RCNN\u8bad\u7ec3\u7528\u7684\u6b63\u6837\u672c\u90fd\u662f\u6765\u81ea\u4e0eground truth\u7684proposal\uff0c\u4f46\u662f\u6d4b\u8bd5\u63a8\u7406\u7684\u65f6\u5019\uff0c\u6211\u4eec\u8981\u6c42RCNN\u7684\u8f93\u5165\u662fRPN\u7ed9\u51fa\u7684proposal\uff0c\u4e0eGT\u76f8\u6bd4\u4f1a\u6709\u4e00\u5b9a\u7684\u8bef\u5dee\uff0c\u8fd9\u5176\u4e2d\u7684misalignment\u5c31\u4f1a\u4f7f\u5f97RCNN\u5728test\u7684\u65f6\u5019\u6027\u80fd\u53d8\u5dee\uff0c\u8bad\u7ec3\u7684\u65f6\u5019\u4e5f\u5bb9\u6613\u8fc7\u62df\u5408\u3002 \u7b2c\u4e8c\uff0cNMS supress\u4e86\u5206\u7c7b\u4efb\u52a1\u4e2d\u786e\u5b9a\u5ea6\u4e0d\u662f\u6700\u9ad8\u7684\u6846\uff0c\u4f46\u662f\u8fd9\u5b8c\u5168\u53ef\u80fd\u538b\u5236\u4e86\u4e8b\u5b9e\u4e0a\u5b9a\u4f4d\u6700\u51c6\u786e\u7684\u5206\u7c7b\u6846\uff0c\u56e0\u800c IoU-Net.pdf ,\u8981\u6c42\u795e\u7ecf\u7f51\u7edc\u8f93\u51fa\u5f53\u524d\u6846\u7684IoU\u4f30\u8ba1\uff0cNMS\u4ee5\u8fd9\u4e2aIoU\u4f30\u8ba1\u4e3a\u57fa\u51c6.\u503c\u5f97\u6ce8\u610f\u7684\u662f gaussian Yolov3(\u7b80\u4ecb) ,\u540c\u6837\u4f7f\u7528\u5b9a\u4f4d\u4e0d\u786e\u5b9a\u5ea6\u6765\u63a7\u5236NMS\uff0c\u53ea\u4e0d\u8fc7\u5b83\u8981\u6c42\u6bcf\u4e00\u5b9a\u4f4d\u7ef4\u5ea6\u7684\u4e0d\u786e\u5b9a\u5ea6\u7684\u603b\u5408\uff0c\u800cIoU-Net\u8981\u6c42\u7f51\u7edc\u76f4\u63a5\u8f93\u51faIoU\u4f30\u8ba1. IoU-uniform sampling \u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u7684\u60f3\u6cd5\u662f\u5982\u4e0a\u56fe\uff0c\u5728\u7ed9RCNN\u63d0\u4f9b\u6b63\u6837\u672c\u65f6\uff0c\u968f\u673a\u6270\u52a8ground truth\u7684ROI\uff0c\u4ee5\u6b64\u5f97\u5230\u591a\u4e2a\u5e26\u6709\u566a\u58f0\u6b63\u6837\u672c\u7528\u4f5ctraining\u3002\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u6837\u53ef\u4ee5\u4f7f\u5f97training phase\u4e0einference phase\u4e2dRCNN\u7684\u8f93\u5165\u5206\u5e03\u66f4\u76f8\u8fd1\u3002 \u5728NMS\u7684\u65f6\u5019\u4f9d\u636e\u4e3aIoU\u4f30\u8ba1\u503c\u4e0eprobs\u7684\u4e58\u79ef\u3002","title":"IoU-uniform R-CNN: Breaking Through the Limitations of RPN"},{"location":"other_categories/object_detection_2D/IoU-uniform_R-CNN/#iou-uniform-r-cnn-breaking-through-the-limitations-of-rpn","text":"\u8fd9\u7bc7\u8bba\u6587\u662f\u4e00\u7cfb\u5217\u9488\u5bf9NMS\u6216\u8005region proposal\u8bad\u7ec3\u63d0\u5347\u7684\u8bba\u6587\u4e4b\u4e00\uff0c\u5176\u4e2d\u6d89\u53ca\u4e86\u591a\u4e00\u4e2a\u6709\u610f\u4e49\u7684\u6982\u5ff5\u4e0e\u601d\u8def\u3002\u672c\u6587\u6838\u5fc3\u8d21\u732e\u662f\u5728RCNN(pooling \u6216 align\u540e\u7684\u7f51\u7edc)\u8bad\u7ec3\u8fc7\u7a0b\u4e2d.","title":"IoU-uniform R-CNN: Breaking Through the Limitations of RPN"},{"location":"other_categories/object_detection_2D/IoU-uniform_R-CNN/#rpn-rcnn","text":"\u7b2c\u4e00\uff0c\u5728\u8bad\u7ec3\u7684\u65f6\u5019\uff0c\u76f8\u5f53\u90e8\u5206\u7684\u63d0\u4f9b\u7ed9RCNN\u8bad\u7ec3\u7528\u7684\u6b63\u6837\u672c\u90fd\u662f\u6765\u81ea\u4e0eground truth\u7684proposal\uff0c\u4f46\u662f\u6d4b\u8bd5\u63a8\u7406\u7684\u65f6\u5019\uff0c\u6211\u4eec\u8981\u6c42RCNN\u7684\u8f93\u5165\u662fRPN\u7ed9\u51fa\u7684proposal\uff0c\u4e0eGT\u76f8\u6bd4\u4f1a\u6709\u4e00\u5b9a\u7684\u8bef\u5dee\uff0c\u8fd9\u5176\u4e2d\u7684misalignment\u5c31\u4f1a\u4f7f\u5f97RCNN\u5728test\u7684\u65f6\u5019\u6027\u80fd\u53d8\u5dee\uff0c\u8bad\u7ec3\u7684\u65f6\u5019\u4e5f\u5bb9\u6613\u8fc7\u62df\u5408\u3002 \u7b2c\u4e8c\uff0cNMS supress\u4e86\u5206\u7c7b\u4efb\u52a1\u4e2d\u786e\u5b9a\u5ea6\u4e0d\u662f\u6700\u9ad8\u7684\u6846\uff0c\u4f46\u662f\u8fd9\u5b8c\u5168\u53ef\u80fd\u538b\u5236\u4e86\u4e8b\u5b9e\u4e0a\u5b9a\u4f4d\u6700\u51c6\u786e\u7684\u5206\u7c7b\u6846\uff0c\u56e0\u800c IoU-Net.pdf ,\u8981\u6c42\u795e\u7ecf\u7f51\u7edc\u8f93\u51fa\u5f53\u524d\u6846\u7684IoU\u4f30\u8ba1\uff0cNMS\u4ee5\u8fd9\u4e2aIoU\u4f30\u8ba1\u4e3a\u57fa\u51c6.\u503c\u5f97\u6ce8\u610f\u7684\u662f gaussian Yolov3(\u7b80\u4ecb) ,\u540c\u6837\u4f7f\u7528\u5b9a\u4f4d\u4e0d\u786e\u5b9a\u5ea6\u6765\u63a7\u5236NMS\uff0c\u53ea\u4e0d\u8fc7\u5b83\u8981\u6c42\u6bcf\u4e00\u5b9a\u4f4d\u7ef4\u5ea6\u7684\u4e0d\u786e\u5b9a\u5ea6\u7684\u603b\u5408\uff0c\u800cIoU-Net\u8981\u6c42\u7f51\u7edc\u76f4\u63a5\u8f93\u51faIoU\u4f30\u8ba1.","title":"RPN \u4e0e rCNN \u4e24\u5927\u95ee\u9898"},{"location":"other_categories/object_detection_2D/IoU-uniform_R-CNN/#iou-uniform-sampling","text":"\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u7684\u60f3\u6cd5\u662f\u5982\u4e0a\u56fe\uff0c\u5728\u7ed9RCNN\u63d0\u4f9b\u6b63\u6837\u672c\u65f6\uff0c\u968f\u673a\u6270\u52a8ground truth\u7684ROI\uff0c\u4ee5\u6b64\u5f97\u5230\u591a\u4e2a\u5e26\u6709\u566a\u58f0\u6b63\u6837\u672c\u7528\u4f5ctraining\u3002\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u6837\u53ef\u4ee5\u4f7f\u5f97training phase\u4e0einference phase\u4e2dRCNN\u7684\u8f93\u5165\u5206\u5e03\u66f4\u76f8\u8fd1\u3002 \u5728NMS\u7684\u65f6\u5019\u4f9d\u636e\u4e3aIoU\u4f30\u8ba1\u503c\u4e0eprobs\u7684\u4e58\u79ef\u3002","title":"IoU-uniform sampling"},{"location":"other_categories/object_detection_2D/IoUNet(s)/","text":"IoU Nets \u672c\u6587\u4f1a\u5c1d\u8bd5\u540c\u65f6\u878d\u5408\u4e24\u7bc7idea\u76f8\u4f3c\u7684\u8bba\u6587\u7684\u60f3\u6cd5\uff0c\u7b2c\u4e00\u4e3a Acquisition of Localization Confidence for Accurate Object Detection \u3002\u7b2c\u4e8c\u7bc7\u4e3a IoU-aware Single-stage Object Detector for Accurate Localization \u5176\u4e2d\u7b2c\u4e00\u7bc7\u8bba\u6587\u7531 Iou-uniform-rcnn \u63d0\u53ca\uff0c\u4e24\u7bc7\u8bba\u6587\u7684\u6838\u5fc3idea\u90fd\u662f\u6d89\u53ca\u5728NMS\u4e2d\u4f7f\u7528IoU\u9884\u6d4b\u503c\u66ff\u4ee3classification score Acquisition of Localization Confidence for Accurate Object Detection \u8fd9\u7bc7\u8bba\u6587\u7684\u5185\u5bb9\u6bd4\u8f83\u591a\uff0c\u9996\u5148\u662fIoU-guided NMS,\u5176\u6b21\u662fIoU-guided optimization,\u6700\u540e\u662fPrROI pooling. \u7b2c\u4e00\u90e8\u5206\u662f\u5728RoI\u540e\u589e\u52a0\u4e00\u4e2a\u5206\u652f\u9884\u6d4bIoU\u503c,\u5728NMS\u65f6\u4ee5IoU\u66ff\u4ee3\u5206\u7c7b\u5206\u6570 IoU-guided optimization \u8fd9\u91cc\u505a\u7684\u662f\u5728\u63d0\u4f9bproposal\u7ed9RCNN\u63d0\u4f9b\u8f93\u5165\u65f6\uff0c\u7528\u68af\u5ea6\u4f18\u5316\u5fae\u8c03FPN\u8f93\u51fa\u7684bounding box\uff0c\u76ee\u6807\u51fd\u6570\u662fRCNN\u8f93\u51fa\u7684IoU,\u76f4\u89c9\u610f\u601d\u662f\u5fae\u8c03FPN\u7684bounding box\uff0c\u6700\u4f18\u5316RCNN\u9884\u6d4b\u7684IoU\u3002\u5728IoU\u9884\u6d4b\u51c6\u786e\u7684\u524d\u63d0\u4e0b\uff0c\u8fd9\u6837\u53ef\u4ee5\u4f18\u5316FPN\u7684proposal\u3002 PrROI pooling PrROI\u5df2\u7ecf \u5f00\u6e90 \u8fd9\u4e2a\u79f0\u4e3aPrecise RoI Pooling \\begin{aligned} f(x, y) &= \\sum_{i,j}IC(x,y,i,j) \\times w_{i,j} \\\\ IC(x,y,i,j) &= max(0, 1-|x-i|) \\times max(0, 1-|y-j|) \\\\ \\end{aligned} \\operatorname{PrPool}(b i n, \\mathcal{F})=\\frac{\\int_{y 1}^{y 2} \\int_{x 1}^{x 2} f(x, y) d x d y}{\\left(x_{2}-x_{1}\\right) \\times\\left(y_{2}-y_{1}\\right)} IoU-aware Single-stage Object Detector for Accurate Localization \u8fd9\u7bc7\u7a0d\u5fae\u7b80\u5355\u5c06IoU NMS\u7528\u5728one-stage\u7684retina net\u4e2d\u3002\u5982\u56fe \u635f\u5931\u51fd\u6570\u5982\u4e0b \\begin{aligned} L_{c l s}=& \\frac{1}{N_{P o s}}\\left(\\sum_{i \\in P o s}^{N} \\mathrm{FL}\\left(p_{i}, \\hat{p}_{i}\\right)+\\sum_{i \\in N e g}^{M} \\mathrm{FL}\\left(p_{i}, \\hat{p}_{i}\\right)\\right) \\\\ L_{l o c}=& \\frac{1}{N_{P o s}} \\sum_{i \\in P o s}^{N} \\sum_{m \\in c x, c y, w, h} \\mathrm{smooth}_{\\mathrm{L} 1}\\left(l_{i}^{m}-\\hat{g}_{i}^{m}\\right) \\\\ & L_{I o U}=\\frac{1}{N_{P o s}} \\sum_{i \\in P o s}^{N} \\mathrm{CE}\\left(I o U_{i}, I \\hat{o} U_{i}\\right) \\\\ & L_{t o t a l}=L_{c l s}+L_{l o c}+L_{I o U} \\end{aligned} \u4e3b\u8981\u5728\u4e8eIoU\u7684\u8bad\u7ec3\u65b9\u5f0f\u7528\u7684\u662fBinary Cross Entropy(\u5e94\u5f53\u5047\u8bbe\u539fIoU\u4e3asigmoid)","title":"IoU Nets"},{"location":"other_categories/object_detection_2D/IoUNet(s)/#iou-nets","text":"\u672c\u6587\u4f1a\u5c1d\u8bd5\u540c\u65f6\u878d\u5408\u4e24\u7bc7idea\u76f8\u4f3c\u7684\u8bba\u6587\u7684\u60f3\u6cd5\uff0c\u7b2c\u4e00\u4e3a Acquisition of Localization Confidence for Accurate Object Detection \u3002\u7b2c\u4e8c\u7bc7\u4e3a IoU-aware Single-stage Object Detector for Accurate Localization \u5176\u4e2d\u7b2c\u4e00\u7bc7\u8bba\u6587\u7531 Iou-uniform-rcnn \u63d0\u53ca\uff0c\u4e24\u7bc7\u8bba\u6587\u7684\u6838\u5fc3idea\u90fd\u662f\u6d89\u53ca\u5728NMS\u4e2d\u4f7f\u7528IoU\u9884\u6d4b\u503c\u66ff\u4ee3classification score","title":"IoU Nets"},{"location":"other_categories/object_detection_2D/IoUNet(s)/#acquisition-of-localization-confidence-for-accurate-object-detection","text":"\u8fd9\u7bc7\u8bba\u6587\u7684\u5185\u5bb9\u6bd4\u8f83\u591a\uff0c\u9996\u5148\u662fIoU-guided NMS,\u5176\u6b21\u662fIoU-guided optimization,\u6700\u540e\u662fPrROI pooling. \u7b2c\u4e00\u90e8\u5206\u662f\u5728RoI\u540e\u589e\u52a0\u4e00\u4e2a\u5206\u652f\u9884\u6d4bIoU\u503c,\u5728NMS\u65f6\u4ee5IoU\u66ff\u4ee3\u5206\u7c7b\u5206\u6570","title":"Acquisition of Localization Confidence for Accurate Object Detection"},{"location":"other_categories/object_detection_2D/IoUNet(s)/#iou-guided-optimization","text":"\u8fd9\u91cc\u505a\u7684\u662f\u5728\u63d0\u4f9bproposal\u7ed9RCNN\u63d0\u4f9b\u8f93\u5165\u65f6\uff0c\u7528\u68af\u5ea6\u4f18\u5316\u5fae\u8c03FPN\u8f93\u51fa\u7684bounding box\uff0c\u76ee\u6807\u51fd\u6570\u662fRCNN\u8f93\u51fa\u7684IoU,\u76f4\u89c9\u610f\u601d\u662f\u5fae\u8c03FPN\u7684bounding box\uff0c\u6700\u4f18\u5316RCNN\u9884\u6d4b\u7684IoU\u3002\u5728IoU\u9884\u6d4b\u51c6\u786e\u7684\u524d\u63d0\u4e0b\uff0c\u8fd9\u6837\u53ef\u4ee5\u4f18\u5316FPN\u7684proposal\u3002","title":"IoU-guided optimization"},{"location":"other_categories/object_detection_2D/IoUNet(s)/#prroi-pooling","text":"PrROI\u5df2\u7ecf \u5f00\u6e90 \u8fd9\u4e2a\u79f0\u4e3aPrecise RoI Pooling \\begin{aligned} f(x, y) &= \\sum_{i,j}IC(x,y,i,j) \\times w_{i,j} \\\\ IC(x,y,i,j) &= max(0, 1-|x-i|) \\times max(0, 1-|y-j|) \\\\ \\end{aligned} \\operatorname{PrPool}(b i n, \\mathcal{F})=\\frac{\\int_{y 1}^{y 2} \\int_{x 1}^{x 2} f(x, y) d x d y}{\\left(x_{2}-x_{1}\\right) \\times\\left(y_{2}-y_{1}\\right)}","title":"PrROI pooling"},{"location":"other_categories/object_detection_2D/IoUNet(s)/#iou-aware-single-stage-object-detector-for-accurate-localization","text":"\u8fd9\u7bc7\u7a0d\u5fae\u7b80\u5355\u5c06IoU NMS\u7528\u5728one-stage\u7684retina net\u4e2d\u3002\u5982\u56fe \u635f\u5931\u51fd\u6570\u5982\u4e0b \\begin{aligned} L_{c l s}=& \\frac{1}{N_{P o s}}\\left(\\sum_{i \\in P o s}^{N} \\mathrm{FL}\\left(p_{i}, \\hat{p}_{i}\\right)+\\sum_{i \\in N e g}^{M} \\mathrm{FL}\\left(p_{i}, \\hat{p}_{i}\\right)\\right) \\\\ L_{l o c}=& \\frac{1}{N_{P o s}} \\sum_{i \\in P o s}^{N} \\sum_{m \\in c x, c y, w, h} \\mathrm{smooth}_{\\mathrm{L} 1}\\left(l_{i}^{m}-\\hat{g}_{i}^{m}\\right) \\\\ & L_{I o U}=\\frac{1}{N_{P o s}} \\sum_{i \\in P o s}^{N} \\mathrm{CE}\\left(I o U_{i}, I \\hat{o} U_{i}\\right) \\\\ & L_{t o t a l}=L_{c l s}+L_{l o c}+L_{I o U} \\end{aligned} \u4e3b\u8981\u5728\u4e8eIoU\u7684\u8bad\u7ec3\u65b9\u5f0f\u7528\u7684\u662fBinary Cross Entropy(\u5e94\u5f53\u5047\u8bbe\u539fIoU\u4e3asigmoid)","title":"IoU-aware Single-stage Object Detector for Accurate Localization"},{"location":"other_categories/object_detection_2D/MMDetection/","text":"Some Collections around MMDetection \u8fd9\u4e00\u9875\u9762\u4e3b\u8981\u4e3a\u4e86\u6536\u96c6mmdetection\u4e2d\u63d0\u4f9b\u5b9e\u73b0\u7684\u8bba\u6587\u3002\u8fd9\u91cc\u6536\u96c6\u6216\u8005\u63d0\u4f9b\u94fe\u63a5\u7684\u4e3b\u8981\u662f\u76f8\u5bf9\u51b7\u95e8\u7684paper\uff0c\u4e3b\u6d41\u7684\u5982Faster-RCNN\u4ee5\u53caRetinanet\u4e0d\u4f1a\u518d\u91cd\u590d\u3002 \u5176\u4f59\u6709\u5b9e\u73b0\uff0c\u5e76\u8bb0\u5f55\u5728\u672c\u7f51\u7ad9\u5176\u4ed6\u5730\u65b9\u7684\u6709 FCOS , FreeAnchor , ATSS , RepPoints Update: 2020/06/04: Updates HTC , DetectoRS Single Stage Methods GHM: Gradient Harmonized Single-stage Detector pdf \u8fd9\u7bc7paper\u4e3b\u8981idea\u662floss function\u5e94\u8be5\u5e73\u8861\u4e0d\u540c\u6837\u672c\u4e4b\u95f4\u7684gradient norm. \u8fc7\u4e8e\u56f0\u96be\u7684instance gradient norm\u8f83\u5927\u800c\u8fc7\u4e8e\u7b80\u5355\u7684\u7684instance gradient\u7406\u5e94\u4f1a\u5f88\u5c0f\uff0c \u4e00\u4e2awell trained detector\u7684gradient norm\u5206\u5e03\u5982\u56fe \u4f5c\u8005\u7684\u60f3\u6cd5\u662f\u5e94\u8be5\u63d0\u5347\u4e2d\u95f4\u5c42\uff0c\u6216\u8005\u8bf4gradient\u5bc6\u5ea6\u6bd4\u8f83\u5c0f\u7684\u90e8\u5206\u7684\u68af\u5ea6\u8d21\u732e\u3002 \u5b9a\u4e49\u68af\u5ea6\u5bc6\u5ea6\u51fd\u6570: G D(g)=\\frac{1}{l_{\\epsilon}(g)} \\sum_{k=1}^{N} \\delta_{\\epsilon}\\left(g_{k}, g\\right) \\begin{aligned} &\\delta_{\\epsilon}(x, y)=\\left\\{\\begin{array}{ll} 1 & \\text { if } y-\\frac{\\epsilon}{2}<=x<y+\\frac{\\epsilon}{2} \\\\ 0 & \\text { otherwise } \\end{array}\\right.\\\\ &l_{\\epsilon}(g)=\\min \\left(g+\\frac{\\epsilon}{2}, 1\\right)-\\max \\left(g-\\frac{\\epsilon}{2}, 0\\right) \\end{aligned} \u7b80\u5355\u800c\u8a00\u5c31\u662f GD(g) \u4e3a\u4e0e\u68af\u5ea6g\u4e34\u8fd1\u7684\u533a\u95f4\u5185\uff0c\u6709\u76f8\u8fd1\u68af\u5ea6norm\u7684example\u7684\u4e2a\u6570/\u68af\u5ea6\u533a\u95f4\u957f\u5ea6\u3002 \\beta_{i}=\\frac{N}{G D\\left(g_{i}\\right)} \\begin{aligned} L_{G H M-C} &=\\frac{1}{N} \\sum_{i=1}^{N} \\beta_{i} L_{C E}\\left(p_{i}, p_{i}^{*}\\right) \\\\ &=\\sum_{i=1}^{N} \\frac{L_{C E}\\left(p_{i}, p_{i}^{*}\\right)}{G D\\left(g_{i}\\right)} \\end{aligned} \u4e5f\u5373\u662f\u7ed9loss\u52a0\u4e0a\u4e0e\u68af\u5ea6example\u5bc6\u5ea6\u6210\u53cd\u6bd4\u7684\u5bf9\u5e94\u7684\u6743\u91cd\u3002 FSAF: Feature Selective Anchor-Free Module for Single-Shot Object Detection pdf \u8fd9\u7bc7paper\u7684idea\u662f\u8ba9RetinaNet\u540c\u65f6\u7ef4\u62a4\u4e00\u4e2aanchor free\u4e00\u4e2aanchor based\u7684\u5206\u652f\uff0canchor_free\u7684\u5206\u652f\u5728\u6bcf\u4e00\u4e2ascale\u4e0a\u90fd\u4f1a\u53d7\u8bad\u7ec3\u3002 \u4f5c\u8005\u7684online selection\u601d\u8def\u662f\u8ba9\u6bcf\u4e00\u4e2ascale\u4e0a\u7684anchor free\u5206\u652f\u90fd\u9884\u6d4b\u4e00\u6b21\uff0c\u7136\u540e\u5f97\u5230\u5bf9\u5e94\u7684loss\uff0c\u5bfb\u627eanchor free loss\u6700\u5c0f\u7684scale\uff0ctrain\u5bf9\u5e94scale\u7684anchor-based\u5206\u652f\u3002 Inference\u7684\u65f6\u5019\u5219\u8ba9\u6240\u67096\u4e2a\u5206\u652f\u5404\u81ea\u8f93\u51fa\uff0c\u76f4\u63a5merge FoveaBox: Beyond Anchor-based Object Detector pdf code \u8fd9\u7bc7paper\u7684\u601d\u8def\u662f\u53d6Retinanet\u6240\u6709\u4e4b\u7cbe\u534e\uff0c\u6307\u51fa\u5728FPN\u7684multi-scale\u652f\u6301\u4e0b\uff0c\u5df2\u7ecf\u4e0d\u9700\u8981anchor\u4e86\uff0c\u5176\u5b9e\u4e5f\u5c31\u662f\u6bcf\u4e00\u4e2ascale\u6709\u4e00\u4e2aanchor\u5c31\u591f\u4e86\u3002 Grid R-CNN pdf code \u8fd9\u7bc7paper\u4ece\u4eca\u65e5\u7684\u89d2\u5ea6\u6765\u8bf4\u53ef\u4ee5\u7406\u89e3\u4e3aRoIPooling\u540e\u7684 keypointNet \uff0c\u5728grid point\u9009\u62e9\u4e0a\u6709\u70b9\u4e0d\u540c\uff0c\u4f46\u662f\u601d\u8def\u662f\u76f8\u4f3c\u7684\u3002 Two Stage Methods HTC pdf code motivation: 1. instance segmentation, detection\u751a\u81f3pixel-wise segmentation\u4e4b\u95f4\u662f\u4e92\u76f8\u8865\u5145\u7684\u3002\u4f46\u662f\u5355\u7eaf\u7684\u8ba9\u7f51\u7edc\u540c\u65f6\u8bad\u7ec3\u8fd9\u51e0\u4e2a\u4efb\u52a1\u5e76\u4e0d\u8db3\u591f\u3002 2. cascade RCNN\u63d0\u51fa\u4e86bounding box\u7684\u8fed\u4ee3\u4f18\u5316 \u672c\u7bc7paper\u5c31\u63d0\u51fa\u8ba9\u7f51\u7edc\u540c\u65f6\u8fed\u4ee3\u7684\u5b66\u4e60\u8fd9\u4e09\u4e2a\u4efb\u52a1(\u8fed\u4ee3\u4e3b\u8981\u53d1\u751f\u5728bounding box\u548cinstance seg\u91cc\u9762)\uff0c\u5728\u6bcf\u6b21\u8fed\u4ee3\u7684\u65f6\u5019\u901a\u8fc7\u5176\u4ed6\u4efb\u52a1\u5f53\u524d\u7684\u9884\u6d4b\u8fdb\u5ea6\u8fdb\u884c\u4fe1\u606f\u8865\u5145\u3002 \u4fe1\u606f\u6d41\u56fe: \u5c06Mask RCNN\u7684\u9884\u6d4b\u5206\u652f\u653e\u5230cascade RCNN\u4e0a\uff0c\u5f97\u5230(a)\u6d41\u56fe: \\begin{aligned} \\mathbf{x}_{t}^{b o x} &=\\mathcal{P}\\left(\\mathbf{x}, \\mathbf{r}_{t-1}\\right), \\quad \\mathbf{r}_{t}=B_{t}\\left(\\mathbf{x}_{t}^{b o x}\\right) \\\\ \\mathbf{x}_{t}^{\\operatorname{mask}} &=\\mathcal{P}\\left(\\mathbf{x}, \\mathbf{r}_{t-1}\\right), \\quad \\mathbf{m}_{t}=M_{t}\\left(\\mathbf{x}_{t}^{\\operatorname{mask} }\\right) \\end{aligned} \u5176\u4e2d \\mathcal{P} \u662fpooling\u64cd\u4f5c\uff0c B, M \u5206\u522b\u662fbbox_head\u4ee5\u53camask_head. \u8fd9\u79cd\u8bbe\u7f6e\u7684\u4e00\u4e2a\u63d0\u5347\u65b9\u5411\u662fbbox\u4ee5\u53camask\u8fd8\u662f\u5e76\u884c\u7684\u3002\u4f5c\u8005\u8ba9\u6700\u65b0\u7684bbox\u9884\u6d4b\u503c\u7528\u4e8emask head\u7684\u8f93\u51fa\uff0c\u5f97\u5230(b) \\begin{array}{ll} \\mathbf{x}_{t}^{b o x}=\\mathcal{P}\\left(\\mathbf{x}, \\mathbf{r}_{t-1}\\right), & \\mathbf{r}_{t}=B_{t}\\left(\\mathbf{x}_{t}^{b o x}\\right) \\\\ \\mathbf{x}_{t}^{\\operatorname{mask}}=\\mathcal{P}\\left(\\mathbf{x}, \\mathbf{r}_{t}\\right), & \\mathbf{m}_{t}=M_{t}\\left(\\mathbf{x}_{t}^{\\operatorname{mask} }\\right) \\end{array} \u4f5c\u8005\u8fdb\u4e00\u6b65\u8003\u8651\u5c06\u524d\u4e00\u6b21\u8fed\u4ee3\u7684mask\u7684\u4fe1\u606f\u6765\u8865\u5145\u65b0mask\u7684\u4fe1\u606f: \\begin{array}{ll} \\mathbf{x}_{t}^{b o x}=\\mathcal{P}\\left(\\mathbf{x}, \\mathbf{r}_{t-1}\\right), & \\mathbf{r}_{t}=B_{t}\\left(\\mathbf{x}_{t}^{b o x}\\right) \\\\ \\mathbf{x}_{t}^{\\operatorname{mask}}=\\mathcal{P}\\left(\\mathbf{x}, \\mathbf{r}_{t}\\right), & \\mathbf{m}_{t}=M_{t}\\left(\\mathcal{F}\\left(\\mathbf{x}_{t}^{\\operatorname{mask}}, \\mathbf{m}_{t-1}^{-}\\right)\\right) \\end{array} \\mathcal{F}\\left(\\mathbf{x}_{t}^{\\operatorname{mask}}, \\mathbf{m}_{t-1}\\right)=\\mathbf{x}_{t}^{\\operatorname{mask}}+\\mathcal{G}_{t}\\left(\\mathbf{m}_{t-1}^{-}\\right) \u4f5c\u8005\u8fdb\u4e00\u6b65\u8003\u8651\u5c06semantic segmentation\u7684\u4fe1\u606f\u52a0\u8fdb\u6765\uff0c\u5f97\u5230: \\begin{aligned} \\mathbf{x}_{t}^{b o x} &=\\mathcal{P}\\left(\\mathbf{x}, \\mathbf{r}_{t-1}\\right)+\\mathcal{P}\\left(S(\\mathbf{x}), \\mathbf{r}_{t-1}\\right) \\\\ \\mathbf{r}_{t} &=B_{t}\\left(\\mathbf{x}_{t}^{b o x}\\right) \\\\ \\mathbf{x}_{t}^{m a s k} &=\\mathcal{P}\\left(\\mathbf{x}, \\mathbf{r}_{t}\\right)+\\mathcal{P}\\left(S(\\mathbf{x}), \\mathbf{r}_{t}\\right) \\\\ \\mathbf{m}_{t} &=M_{t}\\left(\\mathcal{F}\\left(\\mathbf{x}_{t}^{m a s k}, \\mathbf{m}_{t-1}^{-}\\right)\\right) \\end{aligned} \u5176\u4e2d S(x) \u4e3a\u8bed\u4e49\u5206\u5272\u8f93\u51fa DetectoRS pdf code \u672c\u6587\u5728\u66f4\u65b0\u7684\u65f6\u5019\u8fd8\u6ca1\u6709\u653e\u5230mmdetection\u4e3b\u5206\u652f\u4e0a\uff0c\u662f\u57fa\u4e8emmdetection 1.0\u7248\u672c\u8bbe\u8ba1\u7684\u4ee3\u7801\u3002\u540c\u65f6\u66f4\u6539\u4e86backbone,\u4ee3\u7801\u57fa\u4e8eHTC. \u4e3b\u8981\u63d0\u51fa\u7684\u70b9\u662fRecursive Feature Pyramid\u4ee5\u53ca Switchable Atrous Convolution \u70b9\u6570\u63d0\u5347\u8f83\u4e3a\u60ca\u4eba\uff0c\u6a21\u578b\u5927\u5c0f\u4ee5\u53ca\u5185\u5b58\u5360\u7528\u6bd4\u8f83\u5927(\u6ce8\u610f\u7531\u4e8ebackbone\u7684\u6539\u53d8\uff0c\u5176ResNet-50\u6a21\u578b\u7684\u5927\u5c0f\u8fd1\u4e4e\u4e8eHTC ResNeXt-101-64x4d\u7684\u5927\u5c0f\uff0c\u4e14\u7531\u4e8eRFP\u7684\u8fed\u4ee3\u539f\u56e0\uff0c\u5360\u7528\u663e\u5b58\u53ef\u80fd\u66f4\u5927)\u3002","title":"Some Collections around MMDetection"},{"location":"other_categories/object_detection_2D/MMDetection/#some-collections-around-mmdetection","text":"\u8fd9\u4e00\u9875\u9762\u4e3b\u8981\u4e3a\u4e86\u6536\u96c6mmdetection\u4e2d\u63d0\u4f9b\u5b9e\u73b0\u7684\u8bba\u6587\u3002\u8fd9\u91cc\u6536\u96c6\u6216\u8005\u63d0\u4f9b\u94fe\u63a5\u7684\u4e3b\u8981\u662f\u76f8\u5bf9\u51b7\u95e8\u7684paper\uff0c\u4e3b\u6d41\u7684\u5982Faster-RCNN\u4ee5\u53caRetinanet\u4e0d\u4f1a\u518d\u91cd\u590d\u3002 \u5176\u4f59\u6709\u5b9e\u73b0\uff0c\u5e76\u8bb0\u5f55\u5728\u672c\u7f51\u7ad9\u5176\u4ed6\u5730\u65b9\u7684\u6709 FCOS , FreeAnchor , ATSS , RepPoints Update: 2020/06/04: Updates HTC , DetectoRS","title":"Some Collections around MMDetection"},{"location":"other_categories/object_detection_2D/MMDetection/#single-stage-methods","text":"","title":"Single Stage Methods"},{"location":"other_categories/object_detection_2D/MMDetection/#ghm-gradient-harmonized-single-stage-detector","text":"pdf \u8fd9\u7bc7paper\u4e3b\u8981idea\u662floss function\u5e94\u8be5\u5e73\u8861\u4e0d\u540c\u6837\u672c\u4e4b\u95f4\u7684gradient norm. \u8fc7\u4e8e\u56f0\u96be\u7684instance gradient norm\u8f83\u5927\u800c\u8fc7\u4e8e\u7b80\u5355\u7684\u7684instance gradient\u7406\u5e94\u4f1a\u5f88\u5c0f\uff0c \u4e00\u4e2awell trained detector\u7684gradient norm\u5206\u5e03\u5982\u56fe \u4f5c\u8005\u7684\u60f3\u6cd5\u662f\u5e94\u8be5\u63d0\u5347\u4e2d\u95f4\u5c42\uff0c\u6216\u8005\u8bf4gradient\u5bc6\u5ea6\u6bd4\u8f83\u5c0f\u7684\u90e8\u5206\u7684\u68af\u5ea6\u8d21\u732e\u3002 \u5b9a\u4e49\u68af\u5ea6\u5bc6\u5ea6\u51fd\u6570: G D(g)=\\frac{1}{l_{\\epsilon}(g)} \\sum_{k=1}^{N} \\delta_{\\epsilon}\\left(g_{k}, g\\right) \\begin{aligned} &\\delta_{\\epsilon}(x, y)=\\left\\{\\begin{array}{ll} 1 & \\text { if } y-\\frac{\\epsilon}{2}<=x<y+\\frac{\\epsilon}{2} \\\\ 0 & \\text { otherwise } \\end{array}\\right.\\\\ &l_{\\epsilon}(g)=\\min \\left(g+\\frac{\\epsilon}{2}, 1\\right)-\\max \\left(g-\\frac{\\epsilon}{2}, 0\\right) \\end{aligned} \u7b80\u5355\u800c\u8a00\u5c31\u662f GD(g) \u4e3a\u4e0e\u68af\u5ea6g\u4e34\u8fd1\u7684\u533a\u95f4\u5185\uff0c\u6709\u76f8\u8fd1\u68af\u5ea6norm\u7684example\u7684\u4e2a\u6570/\u68af\u5ea6\u533a\u95f4\u957f\u5ea6\u3002 \\beta_{i}=\\frac{N}{G D\\left(g_{i}\\right)} \\begin{aligned} L_{G H M-C} &=\\frac{1}{N} \\sum_{i=1}^{N} \\beta_{i} L_{C E}\\left(p_{i}, p_{i}^{*}\\right) \\\\ &=\\sum_{i=1}^{N} \\frac{L_{C E}\\left(p_{i}, p_{i}^{*}\\right)}{G D\\left(g_{i}\\right)} \\end{aligned} \u4e5f\u5373\u662f\u7ed9loss\u52a0\u4e0a\u4e0e\u68af\u5ea6example\u5bc6\u5ea6\u6210\u53cd\u6bd4\u7684\u5bf9\u5e94\u7684\u6743\u91cd\u3002","title":"GHM: Gradient Harmonized Single-stage Detector"},{"location":"other_categories/object_detection_2D/MMDetection/#fsaf-feature-selective-anchor-free-module-for-single-shot-object-detection","text":"pdf \u8fd9\u7bc7paper\u7684idea\u662f\u8ba9RetinaNet\u540c\u65f6\u7ef4\u62a4\u4e00\u4e2aanchor free\u4e00\u4e2aanchor based\u7684\u5206\u652f\uff0canchor_free\u7684\u5206\u652f\u5728\u6bcf\u4e00\u4e2ascale\u4e0a\u90fd\u4f1a\u53d7\u8bad\u7ec3\u3002 \u4f5c\u8005\u7684online selection\u601d\u8def\u662f\u8ba9\u6bcf\u4e00\u4e2ascale\u4e0a\u7684anchor free\u5206\u652f\u90fd\u9884\u6d4b\u4e00\u6b21\uff0c\u7136\u540e\u5f97\u5230\u5bf9\u5e94\u7684loss\uff0c\u5bfb\u627eanchor free loss\u6700\u5c0f\u7684scale\uff0ctrain\u5bf9\u5e94scale\u7684anchor-based\u5206\u652f\u3002 Inference\u7684\u65f6\u5019\u5219\u8ba9\u6240\u67096\u4e2a\u5206\u652f\u5404\u81ea\u8f93\u51fa\uff0c\u76f4\u63a5merge","title":"FSAF: Feature Selective Anchor-Free Module for Single-Shot Object Detection"},{"location":"other_categories/object_detection_2D/MMDetection/#foveabox-beyond-anchor-based-object-detector","text":"pdf code \u8fd9\u7bc7paper\u7684\u601d\u8def\u662f\u53d6Retinanet\u6240\u6709\u4e4b\u7cbe\u534e\uff0c\u6307\u51fa\u5728FPN\u7684multi-scale\u652f\u6301\u4e0b\uff0c\u5df2\u7ecf\u4e0d\u9700\u8981anchor\u4e86\uff0c\u5176\u5b9e\u4e5f\u5c31\u662f\u6bcf\u4e00\u4e2ascale\u6709\u4e00\u4e2aanchor\u5c31\u591f\u4e86\u3002","title":"FoveaBox: Beyond Anchor-based Object Detector"},{"location":"other_categories/object_detection_2D/MMDetection/#grid-r-cnn","text":"pdf code \u8fd9\u7bc7paper\u4ece\u4eca\u65e5\u7684\u89d2\u5ea6\u6765\u8bf4\u53ef\u4ee5\u7406\u89e3\u4e3aRoIPooling\u540e\u7684 keypointNet \uff0c\u5728grid point\u9009\u62e9\u4e0a\u6709\u70b9\u4e0d\u540c\uff0c\u4f46\u662f\u601d\u8def\u662f\u76f8\u4f3c\u7684\u3002","title":"Grid R-CNN"},{"location":"other_categories/object_detection_2D/MMDetection/#two-stage-methods","text":"","title":"Two Stage Methods"},{"location":"other_categories/object_detection_2D/MMDetection/#htc","text":"pdf code motivation: 1. instance segmentation, detection\u751a\u81f3pixel-wise segmentation\u4e4b\u95f4\u662f\u4e92\u76f8\u8865\u5145\u7684\u3002\u4f46\u662f\u5355\u7eaf\u7684\u8ba9\u7f51\u7edc\u540c\u65f6\u8bad\u7ec3\u8fd9\u51e0\u4e2a\u4efb\u52a1\u5e76\u4e0d\u8db3\u591f\u3002 2. cascade RCNN\u63d0\u51fa\u4e86bounding box\u7684\u8fed\u4ee3\u4f18\u5316 \u672c\u7bc7paper\u5c31\u63d0\u51fa\u8ba9\u7f51\u7edc\u540c\u65f6\u8fed\u4ee3\u7684\u5b66\u4e60\u8fd9\u4e09\u4e2a\u4efb\u52a1(\u8fed\u4ee3\u4e3b\u8981\u53d1\u751f\u5728bounding box\u548cinstance seg\u91cc\u9762)\uff0c\u5728\u6bcf\u6b21\u8fed\u4ee3\u7684\u65f6\u5019\u901a\u8fc7\u5176\u4ed6\u4efb\u52a1\u5f53\u524d\u7684\u9884\u6d4b\u8fdb\u5ea6\u8fdb\u884c\u4fe1\u606f\u8865\u5145\u3002 \u4fe1\u606f\u6d41\u56fe: \u5c06Mask RCNN\u7684\u9884\u6d4b\u5206\u652f\u653e\u5230cascade RCNN\u4e0a\uff0c\u5f97\u5230(a)\u6d41\u56fe: \\begin{aligned} \\mathbf{x}_{t}^{b o x} &=\\mathcal{P}\\left(\\mathbf{x}, \\mathbf{r}_{t-1}\\right), \\quad \\mathbf{r}_{t}=B_{t}\\left(\\mathbf{x}_{t}^{b o x}\\right) \\\\ \\mathbf{x}_{t}^{\\operatorname{mask}} &=\\mathcal{P}\\left(\\mathbf{x}, \\mathbf{r}_{t-1}\\right), \\quad \\mathbf{m}_{t}=M_{t}\\left(\\mathbf{x}_{t}^{\\operatorname{mask} }\\right) \\end{aligned} \u5176\u4e2d \\mathcal{P} \u662fpooling\u64cd\u4f5c\uff0c B, M \u5206\u522b\u662fbbox_head\u4ee5\u53camask_head. \u8fd9\u79cd\u8bbe\u7f6e\u7684\u4e00\u4e2a\u63d0\u5347\u65b9\u5411\u662fbbox\u4ee5\u53camask\u8fd8\u662f\u5e76\u884c\u7684\u3002\u4f5c\u8005\u8ba9\u6700\u65b0\u7684bbox\u9884\u6d4b\u503c\u7528\u4e8emask head\u7684\u8f93\u51fa\uff0c\u5f97\u5230(b) \\begin{array}{ll} \\mathbf{x}_{t}^{b o x}=\\mathcal{P}\\left(\\mathbf{x}, \\mathbf{r}_{t-1}\\right), & \\mathbf{r}_{t}=B_{t}\\left(\\mathbf{x}_{t}^{b o x}\\right) \\\\ \\mathbf{x}_{t}^{\\operatorname{mask}}=\\mathcal{P}\\left(\\mathbf{x}, \\mathbf{r}_{t}\\right), & \\mathbf{m}_{t}=M_{t}\\left(\\mathbf{x}_{t}^{\\operatorname{mask} }\\right) \\end{array} \u4f5c\u8005\u8fdb\u4e00\u6b65\u8003\u8651\u5c06\u524d\u4e00\u6b21\u8fed\u4ee3\u7684mask\u7684\u4fe1\u606f\u6765\u8865\u5145\u65b0mask\u7684\u4fe1\u606f: \\begin{array}{ll} \\mathbf{x}_{t}^{b o x}=\\mathcal{P}\\left(\\mathbf{x}, \\mathbf{r}_{t-1}\\right), & \\mathbf{r}_{t}=B_{t}\\left(\\mathbf{x}_{t}^{b o x}\\right) \\\\ \\mathbf{x}_{t}^{\\operatorname{mask}}=\\mathcal{P}\\left(\\mathbf{x}, \\mathbf{r}_{t}\\right), & \\mathbf{m}_{t}=M_{t}\\left(\\mathcal{F}\\left(\\mathbf{x}_{t}^{\\operatorname{mask}}, \\mathbf{m}_{t-1}^{-}\\right)\\right) \\end{array} \\mathcal{F}\\left(\\mathbf{x}_{t}^{\\operatorname{mask}}, \\mathbf{m}_{t-1}\\right)=\\mathbf{x}_{t}^{\\operatorname{mask}}+\\mathcal{G}_{t}\\left(\\mathbf{m}_{t-1}^{-}\\right) \u4f5c\u8005\u8fdb\u4e00\u6b65\u8003\u8651\u5c06semantic segmentation\u7684\u4fe1\u606f\u52a0\u8fdb\u6765\uff0c\u5f97\u5230: \\begin{aligned} \\mathbf{x}_{t}^{b o x} &=\\mathcal{P}\\left(\\mathbf{x}, \\mathbf{r}_{t-1}\\right)+\\mathcal{P}\\left(S(\\mathbf{x}), \\mathbf{r}_{t-1}\\right) \\\\ \\mathbf{r}_{t} &=B_{t}\\left(\\mathbf{x}_{t}^{b o x}\\right) \\\\ \\mathbf{x}_{t}^{m a s k} &=\\mathcal{P}\\left(\\mathbf{x}, \\mathbf{r}_{t}\\right)+\\mathcal{P}\\left(S(\\mathbf{x}), \\mathbf{r}_{t}\\right) \\\\ \\mathbf{m}_{t} &=M_{t}\\left(\\mathcal{F}\\left(\\mathbf{x}_{t}^{m a s k}, \\mathbf{m}_{t-1}^{-}\\right)\\right) \\end{aligned} \u5176\u4e2d S(x) \u4e3a\u8bed\u4e49\u5206\u5272\u8f93\u51fa","title":"HTC"},{"location":"other_categories/object_detection_2D/MMDetection/#detectors","text":"pdf code \u672c\u6587\u5728\u66f4\u65b0\u7684\u65f6\u5019\u8fd8\u6ca1\u6709\u653e\u5230mmdetection\u4e3b\u5206\u652f\u4e0a\uff0c\u662f\u57fa\u4e8emmdetection 1.0\u7248\u672c\u8bbe\u8ba1\u7684\u4ee3\u7801\u3002\u540c\u65f6\u66f4\u6539\u4e86backbone,\u4ee3\u7801\u57fa\u4e8eHTC. \u4e3b\u8981\u63d0\u51fa\u7684\u70b9\u662fRecursive Feature Pyramid\u4ee5\u53ca Switchable Atrous Convolution \u70b9\u6570\u63d0\u5347\u8f83\u4e3a\u60ca\u4eba\uff0c\u6a21\u578b\u5927\u5c0f\u4ee5\u53ca\u5185\u5b58\u5360\u7528\u6bd4\u8f83\u5927(\u6ce8\u610f\u7531\u4e8ebackbone\u7684\u6539\u53d8\uff0c\u5176ResNet-50\u6a21\u578b\u7684\u5927\u5c0f\u8fd1\u4e4e\u4e8eHTC ResNeXt-101-64x4d\u7684\u5927\u5c0f\uff0c\u4e14\u7531\u4e8eRFP\u7684\u8fed\u4ee3\u539f\u56e0\uff0c\u5360\u7528\u663e\u5b58\u53ef\u80fd\u66f4\u5927)\u3002","title":"DetectoRS"},{"location":"other_categories/object_detection_2D/NGA/","text":"Exploiting Event Cameras by Using a Network Grafting Algorithm \u8fd9\u7bc7paper\u4f7f\u7528\u77e5\u8bc6\u84b8\u998f\u7684\u6982\u5ff5\u5c06RGB\u56fe\u4e2d\u7684\u76ee\u6807\u68c0\u6d4b\u80fd\u529b\u4f20\u9012\u5230event camera\u7684\u68c0\u6d4b\u4e2d\u3002 NGA structure \u7b80\u5355\u6765\u8bf4\u662f\u7528\u5728\u66f4\u5927\u6570\u636e\u96c6\u4e0a\u9884\u8bad\u7ec3\u597d\u7684\u57fa\u4e8eRGB\u76842D object detection\u6765\u8bad\u7ec3\u6570\u636e\u91cf\u66f4\u5c0f\u7684event camera \u7f51\u7edc\u3002 Event Camera \u7684Volume\u8868\u8fbe\u65b9\u5f0f \u5c06\u4e00\u6bb5\u65f6\u95f4\u5185\u7684event \u6d41\u6309\u7167\u65f6\u95f4\u7247\u5747\u5300\u5730\u5206\u5272\u4e3a D \u5757\uff0c\u5f62\u6210D\u4e2achannel\uff0c\u6bcf\u4e00\u4e2achannel\u5c06\u8fd9\u4e2a\u65f6\u95f4\u7247\u5185\u7684\u6240\u6709event\u5728\u5bf9\u5e94\u5750\u6807\u4e0a\u6c42\u548c\u5373\u53ef\u3002 \u672c\u6587\u7684\u65f6\u95f4\u7247\u5212\u5206\u5206\u4e3aD=3\u4e0eD=10\u4e24\u79cd NGA \u8bad\u7ec3 \u9996\u5148\u5c06\u9700\u8981\u8bad\u7ec3\u7684\u524d\u9988\u7f51\u7edc\u5206\u4e3a\u4e24\u5c42\uff0c\u7b2c\u4e00\u5c42\u7684\u8f93\u51fa\u4e3a H_t \uff0c\u7b2c\u4e8c\u5c42\u7684\u8f93\u51fa\u4e3a R_t . \u5bf9\u4e8e\u4e24\u4e2a\u7279\u5f81\u56fe\u7684\u5dee\u7684\u635f\u5931\uff0c\u672c\u6587\u63d0\u51fa\u76f4\u63a5\u4f7f\u7528MSE \\mathcal{L}_{\\text {recon }}=\\operatorname{MSE}(H, \\hat{H}) \\mathcal{L}_{\\mathrm{eval}}=\\operatorname{MSE}(R, \\hat{R}) \\mathcal{L}_{style} is based on Gram Matrix \\begin{array}{l} \\operatorname{Gram}(F)^{(i, j)}=\\sum_{\\forall t} \\tilde{F}_{t}^{(i) \\top} \\tilde{F}_{t}^{(j)}, \\quad \\text { where } \\tilde{F}_{t}=F_{t}-\\operatorname{mean}\\left(F_{t}\\right) \\\\ \\mathcal{L}_{\\text {style }}=\\gamma_{h} \\operatorname{MSE}(\\operatorname{Gram}(H), \\operatorname{Gram}(\\hat{H}))+\\gamma_{r} \\operatorname{MSE}(\\operatorname{Gram}(R), \\operatorname{Gram}(\\hat{R})) \\end{array} \u6700\u7ec8\uff1a \\mathcal{L}_{\\mathrm{tot}}=\\alpha \\mathcal{L}_{\\mathrm{recon}}+\\beta \\mathcal{L}_{\\mathrm{eval}}+\\mathcal{L}_{\\mathrm{style}} Style loss with Gram Matrix review pdf1 pdf2 The description is much clearer in pdf1 . \u8fd9\u91cc C_j, H_j, W_j \u4e3a\u7279\u5f81\u56fe \\phi_j \u7684\u5f62\u72b6, [h, w, c] \u6307indexing, G_j \u4e3a\u7279\u5f81\u56fe\u7684gram\u77e9\u9635\u3002\u4e0b\u5f0f\u8bf4\u660e\u683c\u62c9\u59c6\u77e9\u9635\u6bcf\u4e00\u4e2a\u5143\u7d20\u7684\u8fd0\u7b97\u3002 G_{j}^{\\phi}(x)[c, c^{\\prime}]=\\frac{1}{C_{j} H_{j} W_{j}} \\sum_{h=1}^{H_{j}} \\sum_{w=1}^{W_{j}} \\phi_{j}(x)[h, w, c] \\times \\phi_{j}(x) [h, w, c^{\\prime}] Style Loss\u5c31\u662f\u4e24\u4e2a\u7279\u5f81\u56fe\u683c\u62c9\u59c6\u77e9\u9635\u7684\u5dee\u7684\u4e8c\u8303\u6570 \\ell_{\\text {style}}^{\\phi, j}(\\hat{y}, y)=\\left\\|G_{j}^{\\phi}(\\hat{y})-G_{j}^{\\phi}(y)\\right\\|_{F}^{2} code keras example for style transfer def gram_matrix ( x ): \"\"\" x.shape = [C, H, W] for 'channels_first' \"\"\" assert K . ndim ( x ) == 3 if K . image_data_format () == 'channels_first' : features = K . batch_flatten ( x ) #[C, H*W] else : features = K . batch_flatten ( K . permute_dimensions ( x , ( 2 , 0 , 1 ))) gram = K . dot ( features , K . transpose ( features )) return gram Network seperation \u5bf9\u4e8eYOLOv3\u4e00\u51715\u6b21\u4e0b\u91c7\u6837\uff0c\u5206\u62106\u6bb5\u7f51\u7edc\uff0c\u5c06\u7b2c\u4e8c or \u7b2c\u4e09\u6bb5\u7684\u8f93\u51fa\u4f5c\u4e3a H \uff0c\u5c06\u7b2c\u56db\u6bb5\u7684\u8f93\u51fa\u4f5c\u4e3a R \u5f97\u5230\u7684\u7ed3\u679c\u8f83\u597d\uff08\u91cd\u590d\u5b9e\u9a8c\u7ed3\u679c\uff09 Other Stuffs \u6570\u636e\u96c6\uff1a The MVSEC Dataset,\u5e26\u6709\u6df1\u5ea6\u7684\u53cc\u76eeRGB+\u53cc\u76eeevent stream\u6570\u636e\u96c6\u3002 Event dataset from moving static images: https://www.garrickorchard.com/datasets","title":"Exploiting Event Cameras by Using a Network Grafting Algorithm"},{"location":"other_categories/object_detection_2D/NGA/#exploiting-event-cameras-by-using-a-network-grafting-algorithm","text":"\u8fd9\u7bc7paper\u4f7f\u7528\u77e5\u8bc6\u84b8\u998f\u7684\u6982\u5ff5\u5c06RGB\u56fe\u4e2d\u7684\u76ee\u6807\u68c0\u6d4b\u80fd\u529b\u4f20\u9012\u5230event camera\u7684\u68c0\u6d4b\u4e2d\u3002","title":"Exploiting Event Cameras by Using a Network Grafting Algorithm"},{"location":"other_categories/object_detection_2D/NGA/#nga-structure","text":"\u7b80\u5355\u6765\u8bf4\u662f\u7528\u5728\u66f4\u5927\u6570\u636e\u96c6\u4e0a\u9884\u8bad\u7ec3\u597d\u7684\u57fa\u4e8eRGB\u76842D object detection\u6765\u8bad\u7ec3\u6570\u636e\u91cf\u66f4\u5c0f\u7684event camera \u7f51\u7edc\u3002","title":"NGA structure"},{"location":"other_categories/object_detection_2D/NGA/#event-camera-volume","text":"\u5c06\u4e00\u6bb5\u65f6\u95f4\u5185\u7684event \u6d41\u6309\u7167\u65f6\u95f4\u7247\u5747\u5300\u5730\u5206\u5272\u4e3a D \u5757\uff0c\u5f62\u6210D\u4e2achannel\uff0c\u6bcf\u4e00\u4e2achannel\u5c06\u8fd9\u4e2a\u65f6\u95f4\u7247\u5185\u7684\u6240\u6709event\u5728\u5bf9\u5e94\u5750\u6807\u4e0a\u6c42\u548c\u5373\u53ef\u3002 \u672c\u6587\u7684\u65f6\u95f4\u7247\u5212\u5206\u5206\u4e3aD=3\u4e0eD=10\u4e24\u79cd","title":"Event Camera \u7684Volume\u8868\u8fbe\u65b9\u5f0f"},{"location":"other_categories/object_detection_2D/NGA/#nga","text":"\u9996\u5148\u5c06\u9700\u8981\u8bad\u7ec3\u7684\u524d\u9988\u7f51\u7edc\u5206\u4e3a\u4e24\u5c42\uff0c\u7b2c\u4e00\u5c42\u7684\u8f93\u51fa\u4e3a H_t \uff0c\u7b2c\u4e8c\u5c42\u7684\u8f93\u51fa\u4e3a R_t . \u5bf9\u4e8e\u4e24\u4e2a\u7279\u5f81\u56fe\u7684\u5dee\u7684\u635f\u5931\uff0c\u672c\u6587\u63d0\u51fa\u76f4\u63a5\u4f7f\u7528MSE \\mathcal{L}_{\\text {recon }}=\\operatorname{MSE}(H, \\hat{H}) \\mathcal{L}_{\\mathrm{eval}}=\\operatorname{MSE}(R, \\hat{R}) \\mathcal{L}_{style} is based on Gram Matrix \\begin{array}{l} \\operatorname{Gram}(F)^{(i, j)}=\\sum_{\\forall t} \\tilde{F}_{t}^{(i) \\top} \\tilde{F}_{t}^{(j)}, \\quad \\text { where } \\tilde{F}_{t}=F_{t}-\\operatorname{mean}\\left(F_{t}\\right) \\\\ \\mathcal{L}_{\\text {style }}=\\gamma_{h} \\operatorname{MSE}(\\operatorname{Gram}(H), \\operatorname{Gram}(\\hat{H}))+\\gamma_{r} \\operatorname{MSE}(\\operatorname{Gram}(R), \\operatorname{Gram}(\\hat{R})) \\end{array} \u6700\u7ec8\uff1a \\mathcal{L}_{\\mathrm{tot}}=\\alpha \\mathcal{L}_{\\mathrm{recon}}+\\beta \\mathcal{L}_{\\mathrm{eval}}+\\mathcal{L}_{\\mathrm{style}}","title":"NGA \u8bad\u7ec3"},{"location":"other_categories/object_detection_2D/NGA/#style-loss-with-gram-matrix-review","text":"pdf1 pdf2 The description is much clearer in pdf1 . \u8fd9\u91cc C_j, H_j, W_j \u4e3a\u7279\u5f81\u56fe \\phi_j \u7684\u5f62\u72b6, [h, w, c] \u6307indexing, G_j \u4e3a\u7279\u5f81\u56fe\u7684gram\u77e9\u9635\u3002\u4e0b\u5f0f\u8bf4\u660e\u683c\u62c9\u59c6\u77e9\u9635\u6bcf\u4e00\u4e2a\u5143\u7d20\u7684\u8fd0\u7b97\u3002 G_{j}^{\\phi}(x)[c, c^{\\prime}]=\\frac{1}{C_{j} H_{j} W_{j}} \\sum_{h=1}^{H_{j}} \\sum_{w=1}^{W_{j}} \\phi_{j}(x)[h, w, c] \\times \\phi_{j}(x) [h, w, c^{\\prime}] Style Loss\u5c31\u662f\u4e24\u4e2a\u7279\u5f81\u56fe\u683c\u62c9\u59c6\u77e9\u9635\u7684\u5dee\u7684\u4e8c\u8303\u6570 \\ell_{\\text {style}}^{\\phi, j}(\\hat{y}, y)=\\left\\|G_{j}^{\\phi}(\\hat{y})-G_{j}^{\\phi}(y)\\right\\|_{F}^{2}","title":"Style loss with Gram Matrix review"},{"location":"other_categories/object_detection_2D/NGA/#code","text":"keras example for style transfer def gram_matrix ( x ): \"\"\" x.shape = [C, H, W] for 'channels_first' \"\"\" assert K . ndim ( x ) == 3 if K . image_data_format () == 'channels_first' : features = K . batch_flatten ( x ) #[C, H*W] else : features = K . batch_flatten ( K . permute_dimensions ( x , ( 2 , 0 , 1 ))) gram = K . dot ( features , K . transpose ( features )) return gram","title":"code"},{"location":"other_categories/object_detection_2D/NGA/#network-seperation","text":"\u5bf9\u4e8eYOLOv3\u4e00\u51715\u6b21\u4e0b\u91c7\u6837\uff0c\u5206\u62106\u6bb5\u7f51\u7edc\uff0c\u5c06\u7b2c\u4e8c or \u7b2c\u4e09\u6bb5\u7684\u8f93\u51fa\u4f5c\u4e3a H \uff0c\u5c06\u7b2c\u56db\u6bb5\u7684\u8f93\u51fa\u4f5c\u4e3a R \u5f97\u5230\u7684\u7ed3\u679c\u8f83\u597d\uff08\u91cd\u590d\u5b9e\u9a8c\u7ed3\u679c\uff09","title":"Network seperation"},{"location":"other_categories/object_detection_2D/NGA/#other-stuffs","text":"\u6570\u636e\u96c6\uff1a The MVSEC Dataset,\u5e26\u6709\u6df1\u5ea6\u7684\u53cc\u76eeRGB+\u53cc\u76eeevent stream\u6570\u636e\u96c6\u3002 Event dataset from moving static images: https://www.garrickorchard.com/datasets","title":"Other Stuffs"},{"location":"other_categories/object_detection_2D/Object_as_points/","text":"Detection and Tracking as Point \u672c\u6587\u5f15\u5165\u4e24\u7bc7paper\uff0c\u7b2c\u4e00\u7bc7\u662f\u4e0eCenterNet\u649e\u540d\u7684 Object as Point , \u7b2c\u4e8c\u7bc7\u662f\u4ee5\u6b64\u4e3a\u57fa\u7840\u7684 Tracking as Point ,\u5b83\u662f\u597d\u591a\u7bc72D/3D\u68c0\u6d4b\u7684\u524d\u7f6epaper\uff0c\u5176\u7279\u70b9\u662f\u901f\u5ea6\u5f88\u5feb\uff0c\u4e0d\u9700\u8981\u7279\u6b8a\u7684NMS(\u771f\u6b63\u610f\u4e49\u5730\u629b\u5374NMS)\uff0c\u4e14\u6a21\u578b\u6269\u5c55\u6027\u5f88\u5f3a\u2014\u2014\u5728\u7f51\u7edc\u4e2d\u4e8b\u5b9e\u4e0a\u5f88\u591a\u4e1c\u897f\u90fd\u662f\u4e00\u4e2apoint Object as Point pdf code \u8fd9\u7bc7paper\u7684keypoint\u68c0\u6d4b\u90e8\u5206\u4e0e CornerNet \u662f\u4e00\u81f4\u7684,\u4f46\u662f\u6b63\u6837\u672c\u7684\u5b9a\u4e49\u6709\u533a\u522b\uff0c\u6700\u9760\u8fd1\u7269\u4f53\u4e2d\u5fc3\u7684\u70b9\u4f1a\u88ab\u6807\u8bb0\u4e3a\u6b63\u6837\u672c\uff0c\u4f7f\u7528\u4e00\u4e2a\u9ad8\u65af\u6838\uff0c\u6839\u636e\u7269\u4f53\u5927\u5c0fsmooth out \u5206\u7c7b\u7f51\u7edc\u7684\u8d1f\u6837\u672c\u60e9\u7f5a. L_{k}=\\frac{-1}{N} \\sum_{x y c}\\left\\{\\begin{array}{ll} \\left(1-\\hat{Y}_{x y c}\\right)^{\\alpha} \\log \\left(\\hat{Y}_{x y c}\\right) & \\text { if } Y_{x y c}=1 \\\\ \\left(1-Y_{x y c}\\right)^{\\beta}\\left(\\hat{Y}_{x y c}\\right)^{\\alpha} \\log \\left(1-\\hat{Y}_{x y c}\\right) & \\text { otherwise } \\end{array}\\right. \u6ce8\u610fCenterTrack\u7684\u516c\u5f0f\u662f\u6709bug\u7684\uff0c\u6f0f\u4e00\u4e2a\u4e00\u4e2a\u8d1f\u53f7,\u8840\u6cea\u6559\u8bad \u5bf9\u4e8e2D\u6846\u7684\u957f\u5bbd\u4ee5\u53cacx cy,\u4e0dnormalize,\u76f4\u63a5L1loss\u56de\u5f52raw pixel coordinates,\u9009\u62e9scale loss(\u4e5f\u5c31\u662f\u8bf4\u8f93\u51fa\u7684\u6570\u503c\u4f1a\u5f88\u5927\uff0c\u4f46\u662floss\u4f1a\u6bd4\u8f83\u6b63\u5e38) L_{d e t}=L_{k}+\\lambda_{s i z e} L_{s i z e}+\\lambda_{o f f} L_{o f f} \u8fdb\u884cNMS\u7684\u65f6\u5019\uff0c\u4e0d\u9700\u8981\u4f7f\u7528\u7279\u6b8a\u7684NMS\uff0c\u4f5c\u8005\u91c7\u7528\u7684\u662f\u66f4\u4e3a\u7684Maxpooling def _nms ( heat , kernel = 3 ): pad = ( kernel - 1 ) // 2 hmax = nn . functional . max_pool2d ( heat , ( kernel , kernel ), stride = 1 , padding = pad ) keep = ( hmax == heat ) . float () return heat * keep \u8fdb\u800c\u4f5c\u8005\u5ef6\u4f38\u51fa\u66f4\u591a\u7684application\uff0c\u6bd4\u5982\u6bd4\u5982\u501f\u52a9\u9884\u6d4boffset\u4ee5\u53caheatmap\u7684\u673a\u5236\u8fdb\u884cpose-estimation,\u540c\u65f6\u9884\u6d4b3D\u4fe1\u606f\u5b9e\u73b03D object detection\u3002\u901f\u5ea6\u5feb\u800c\u7cbe\u786e Tracking Objects as Points pdf code \u8fd9\u7bc7paper\u4e5f\u88ab\u79f0\u4f5cCenterTrack. \u601d\u8def\u662f\u5c06\u8fde\u7eed\u4e24\u5e27\u7684\u56fe\u7247\u4ee5\u53ca\u4e0a\u4e00\u5e27\u7684tracking\u7ed3\u679c\u6784\u6210\u7684 heatMap\u4f5c\u4e3a\u8f93\u5165\uff0c\u56e0\u6b64\u7f51\u7edc\u7684\u7ed3\u6784\u4e0e\u524d\u6587\u4e00\u81f4\uff0c\u4ec5\u4ec5\u533a\u522b\u5728\u4e8e\u591a4\u4e2achannel\u7684\u8f93\u5165\u3002\u8f93\u51fa\u989d\u5916\u591a\u4e24\u4e2achannel,\u4e5f\u5c31\u662f\u4e24\u5e27ground truth\u4e4b\u95f4\u7684\u533a\u522b\uff0c L_{o f f}=\\frac{1}{N} \\sum_{i=1}^{N}\\left|\\hat{D}_{\\mathbf{p}_{i}^{(t)}}-\\left(\\mathbf{p}_{i}^{(t-1)}-\\mathbf{p}_{i}^{(t)}\\right)\\right| \u56e0\u800c\u5728tracking\u7684\u65f6\u5019\uff0c\u6309\u7167confidence\u7684\u6392\u5e8f\uff0c\u5c06\u5f53\u524d\u4f4d\u7f6e\u70b9\u4e0e\u6700\u9760\u8fd1 p - D_p \u7684\u524d\u4e00\u5e27\u70b9\u8d2a\u5a6a\u5730\u5339\u914d\uff0c\u5982\u679c\u53d1\u73b0\u5728\u4e00\u5b9a\u8303\u56f4\u5185unmatched\uff0c\u5c31\u8ba4\u4e3a\u4ea7\u751f\u4e86\u4e00\u4e2a\u65b0\u7684\u7269\u4f53\u3002 \u6bd4\u8f83\u795e\u5947\u7684\u662f\uff0c\u672c\u6587\u662f\u53ef\u4ee5\u7528\u9759\u6001\u56fe\u7247\u8fdb\u884c\u8bad\u7ec3\u7684 ,\u968f\u673a\u5c06\u56fe\u7247\u5e73\u79fb\uff0cscale up\uff0c\u7ed3\u679c\u60ca\u4eba\u5730\u597d","title":"Detection and Tracking as Point"},{"location":"other_categories/object_detection_2D/Object_as_points/#detection-and-tracking-as-point","text":"\u672c\u6587\u5f15\u5165\u4e24\u7bc7paper\uff0c\u7b2c\u4e00\u7bc7\u662f\u4e0eCenterNet\u649e\u540d\u7684 Object as Point , \u7b2c\u4e8c\u7bc7\u662f\u4ee5\u6b64\u4e3a\u57fa\u7840\u7684 Tracking as Point ,\u5b83\u662f\u597d\u591a\u7bc72D/3D\u68c0\u6d4b\u7684\u524d\u7f6epaper\uff0c\u5176\u7279\u70b9\u662f\u901f\u5ea6\u5f88\u5feb\uff0c\u4e0d\u9700\u8981\u7279\u6b8a\u7684NMS(\u771f\u6b63\u610f\u4e49\u5730\u629b\u5374NMS)\uff0c\u4e14\u6a21\u578b\u6269\u5c55\u6027\u5f88\u5f3a\u2014\u2014\u5728\u7f51\u7edc\u4e2d\u4e8b\u5b9e\u4e0a\u5f88\u591a\u4e1c\u897f\u90fd\u662f\u4e00\u4e2apoint","title":"Detection and Tracking as Point"},{"location":"other_categories/object_detection_2D/Object_as_points/#object-as-point","text":"pdf code \u8fd9\u7bc7paper\u7684keypoint\u68c0\u6d4b\u90e8\u5206\u4e0e CornerNet \u662f\u4e00\u81f4\u7684,\u4f46\u662f\u6b63\u6837\u672c\u7684\u5b9a\u4e49\u6709\u533a\u522b\uff0c\u6700\u9760\u8fd1\u7269\u4f53\u4e2d\u5fc3\u7684\u70b9\u4f1a\u88ab\u6807\u8bb0\u4e3a\u6b63\u6837\u672c\uff0c\u4f7f\u7528\u4e00\u4e2a\u9ad8\u65af\u6838\uff0c\u6839\u636e\u7269\u4f53\u5927\u5c0fsmooth out \u5206\u7c7b\u7f51\u7edc\u7684\u8d1f\u6837\u672c\u60e9\u7f5a. L_{k}=\\frac{-1}{N} \\sum_{x y c}\\left\\{\\begin{array}{ll} \\left(1-\\hat{Y}_{x y c}\\right)^{\\alpha} \\log \\left(\\hat{Y}_{x y c}\\right) & \\text { if } Y_{x y c}=1 \\\\ \\left(1-Y_{x y c}\\right)^{\\beta}\\left(\\hat{Y}_{x y c}\\right)^{\\alpha} \\log \\left(1-\\hat{Y}_{x y c}\\right) & \\text { otherwise } \\end{array}\\right. \u6ce8\u610fCenterTrack\u7684\u516c\u5f0f\u662f\u6709bug\u7684\uff0c\u6f0f\u4e00\u4e2a\u4e00\u4e2a\u8d1f\u53f7,\u8840\u6cea\u6559\u8bad \u5bf9\u4e8e2D\u6846\u7684\u957f\u5bbd\u4ee5\u53cacx cy,\u4e0dnormalize,\u76f4\u63a5L1loss\u56de\u5f52raw pixel coordinates,\u9009\u62e9scale loss(\u4e5f\u5c31\u662f\u8bf4\u8f93\u51fa\u7684\u6570\u503c\u4f1a\u5f88\u5927\uff0c\u4f46\u662floss\u4f1a\u6bd4\u8f83\u6b63\u5e38) L_{d e t}=L_{k}+\\lambda_{s i z e} L_{s i z e}+\\lambda_{o f f} L_{o f f} \u8fdb\u884cNMS\u7684\u65f6\u5019\uff0c\u4e0d\u9700\u8981\u4f7f\u7528\u7279\u6b8a\u7684NMS\uff0c\u4f5c\u8005\u91c7\u7528\u7684\u662f\u66f4\u4e3a\u7684Maxpooling def _nms ( heat , kernel = 3 ): pad = ( kernel - 1 ) // 2 hmax = nn . functional . max_pool2d ( heat , ( kernel , kernel ), stride = 1 , padding = pad ) keep = ( hmax == heat ) . float () return heat * keep \u8fdb\u800c\u4f5c\u8005\u5ef6\u4f38\u51fa\u66f4\u591a\u7684application\uff0c\u6bd4\u5982\u6bd4\u5982\u501f\u52a9\u9884\u6d4boffset\u4ee5\u53caheatmap\u7684\u673a\u5236\u8fdb\u884cpose-estimation,\u540c\u65f6\u9884\u6d4b3D\u4fe1\u606f\u5b9e\u73b03D object detection\u3002\u901f\u5ea6\u5feb\u800c\u7cbe\u786e","title":"Object as Point"},{"location":"other_categories/object_detection_2D/Object_as_points/#tracking-objects-as-points","text":"pdf code \u8fd9\u7bc7paper\u4e5f\u88ab\u79f0\u4f5cCenterTrack. \u601d\u8def\u662f\u5c06\u8fde\u7eed\u4e24\u5e27\u7684\u56fe\u7247\u4ee5\u53ca\u4e0a\u4e00\u5e27\u7684tracking\u7ed3\u679c\u6784\u6210\u7684 heatMap\u4f5c\u4e3a\u8f93\u5165\uff0c\u56e0\u6b64\u7f51\u7edc\u7684\u7ed3\u6784\u4e0e\u524d\u6587\u4e00\u81f4\uff0c\u4ec5\u4ec5\u533a\u522b\u5728\u4e8e\u591a4\u4e2achannel\u7684\u8f93\u5165\u3002\u8f93\u51fa\u989d\u5916\u591a\u4e24\u4e2achannel,\u4e5f\u5c31\u662f\u4e24\u5e27ground truth\u4e4b\u95f4\u7684\u533a\u522b\uff0c L_{o f f}=\\frac{1}{N} \\sum_{i=1}^{N}\\left|\\hat{D}_{\\mathbf{p}_{i}^{(t)}}-\\left(\\mathbf{p}_{i}^{(t-1)}-\\mathbf{p}_{i}^{(t)}\\right)\\right| \u56e0\u800c\u5728tracking\u7684\u65f6\u5019\uff0c\u6309\u7167confidence\u7684\u6392\u5e8f\uff0c\u5c06\u5f53\u524d\u4f4d\u7f6e\u70b9\u4e0e\u6700\u9760\u8fd1 p - D_p \u7684\u524d\u4e00\u5e27\u70b9\u8d2a\u5a6a\u5730\u5339\u914d\uff0c\u5982\u679c\u53d1\u73b0\u5728\u4e00\u5b9a\u8303\u56f4\u5185unmatched\uff0c\u5c31\u8ba4\u4e3a\u4ea7\u751f\u4e86\u4e00\u4e2a\u65b0\u7684\u7269\u4f53\u3002 \u6bd4\u8f83\u795e\u5947\u7684\u662f\uff0c\u672c\u6587\u662f\u53ef\u4ee5\u7528\u9759\u6001\u56fe\u7247\u8fdb\u884c\u8bad\u7ec3\u7684 ,\u968f\u673a\u5c06\u56fe\u7247\u5e73\u79fb\uff0cscale up\uff0c\u7ed3\u679c\u60ca\u4eba\u5730\u597d","title":"Tracking Objects as Points"},{"location":"other_categories/object_detection_2D/PAA/","text":"Probabilistic Anchor Assignment with IoU Prediction for Object Detection \u8fd9\u7bc7paper\u7684\u63a2\u7d22\u7684\u662fanchor\u5206\u914dground truth\u7684\u7b56\u7565,\u7c7b\u4f3c\u7684\u4efb\u52a1\u672c\u7ad9\u5206\u6790\u7684\u6709 FreeAnchor , \u4ee5\u53ca ATSS Method \u672c\u6587\u7684\u601d\u8def\uff1a \u7528IoU Loss\u4ee5\u53ca\u5206\u7c7bloss\u7684\u7ec4\u5408\u4f5c\u4e3a anchor assignment\u7684\u4f9d\u636e\u3002 \u5bf9\u4e8e\u6bcf\u4e00\u4e2agrount truth\uff0canchors\u4e0e\u5b83\u7684score\u53ef\u4ee5\u7531\u4e24\u4e2a\u5cf0\u503c\u7684\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u8fdb\u884c\u5efa\u6a21\uff0c\u76f4\u89c2\u6765\u8bf4\u4e00\u4e2a\u5bf9\u5e94\u8d1f\u6837\u672c\uff0c\u4e00\u4e2a\u5bf9\u5e94\u6b63\u6837\u672c\u3002 \u7531\u4e8egt assignment\u4ee5Classification\u4ee5\u53caIoU\u4f5c\u4e3a\u57fa\u7840\uff0c\u6240\u6709NMS\u4e5f\u9700\u8981\u8003\u8651IoU\u7ed3\u679c\u3002 Score voting \u5bf9NMS\u540e\u7684bbox \\begin{array}{c} p_{i}=e^{-\\left(1-\\mathrm{IoU}\\left(b, b_{i}\\right)\\right)^{2} / \\sigma_{t}} \\\\ \\hat{b}=\\frac{\\sum_{i} p_{i} s_{i} b_{i}}{\\sum_{i} p_{i} s_{i}} \\text { subject to } \\mathrm{IoU}\\left(b, b_{i}\\right)>0 \\end{array}","title":"Probabilistic Anchor Assignment with IoU Prediction for Object Detection"},{"location":"other_categories/object_detection_2D/PAA/#probabilistic-anchor-assignment-with-iou-prediction-for-object-detection","text":"\u8fd9\u7bc7paper\u7684\u63a2\u7d22\u7684\u662fanchor\u5206\u914dground truth\u7684\u7b56\u7565,\u7c7b\u4f3c\u7684\u4efb\u52a1\u672c\u7ad9\u5206\u6790\u7684\u6709 FreeAnchor , \u4ee5\u53ca ATSS","title":"Probabilistic Anchor Assignment with IoU Prediction for Object Detection"},{"location":"other_categories/object_detection_2D/PAA/#method","text":"\u672c\u6587\u7684\u601d\u8def\uff1a \u7528IoU Loss\u4ee5\u53ca\u5206\u7c7bloss\u7684\u7ec4\u5408\u4f5c\u4e3a anchor assignment\u7684\u4f9d\u636e\u3002 \u5bf9\u4e8e\u6bcf\u4e00\u4e2agrount truth\uff0canchors\u4e0e\u5b83\u7684score\u53ef\u4ee5\u7531\u4e24\u4e2a\u5cf0\u503c\u7684\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u8fdb\u884c\u5efa\u6a21\uff0c\u76f4\u89c2\u6765\u8bf4\u4e00\u4e2a\u5bf9\u5e94\u8d1f\u6837\u672c\uff0c\u4e00\u4e2a\u5bf9\u5e94\u6b63\u6837\u672c\u3002 \u7531\u4e8egt assignment\u4ee5Classification\u4ee5\u53caIoU\u4f5c\u4e3a\u57fa\u7840\uff0c\u6240\u6709NMS\u4e5f\u9700\u8981\u8003\u8651IoU\u7ed3\u679c\u3002","title":"Method"},{"location":"other_categories/object_detection_2D/PAA/#score-voting","text":"\u5bf9NMS\u540e\u7684bbox \\begin{array}{c} p_{i}=e^{-\\left(1-\\mathrm{IoU}\\left(b, b_{i}\\right)\\right)^{2} / \\sigma_{t}} \\\\ \\hat{b}=\\frac{\\sum_{i} p_{i} s_{i} b_{i}}{\\sum_{i} p_{i} s_{i}} \\text { subject to } \\mathrm{IoU}\\left(b, b_{i}\\right)>0 \\end{array}","title":"Score voting"},{"location":"other_categories/object_detection_2D/Reppoints/","text":"RepPoints / Dense RepPoints / RepPointsV2 pdf1 code1 pdf2 code2 pdf3 code-all RepPoints reppoints\u8bba\u6587\u7684\u6838\u5fc3\u601d\u8def\u662f\u8ba9\u7f51\u7edc\u81ea\u9002\u5e94\u5730\u5b66\u4e60keypoints,\u5e76\u5229\u7528keypoints\u5206\u67902D\u6846\u7684\u4f4d\u7f6e\u4e0e\u5927\u5c0f\u3002\u8fd9\u91cc\u7275\u6d89\u7684\u96be\u70b9\u5728\u4e8ebbox detection\u4efb\u52a1\u4e2d\u662f\u6ca1\u6709keypoint\u8bbe\u7f6e\u7684\uff0c\u56e0\u4e3a\u7f51\u7edc\u9700\u8981\u81ea\u5df1\u53bb\u5b66keypoint\u7684\u4f4d\u7f6e\u3002 \u7f51\u7edc\u7ed3\u6784 # pts_out_init -> offsets fields from CNN pts_out_init_grad_mul = ( 1 - self . gradient_mul ) * pts_out_init . detach () + self . gradient_mul * pts_out_init # a trick to wind down the gradient from DCN dcn_offset = pts_out_init_grad_mul - dcn_base_offset cls_out = self . reppoints_cls_out ( self . relu ( self . reppoints_cls_conv ( cls_feat , dcn_offset ))) # conv ( relu (deform_conv)) pts_out_refine = self . reppoints_pts_refine_out ( self . relu ( self . reppoints_pts_refine_conv ( pts_feat , dcn_offset ))) # conv ( relu (deform_conv)) \u8fd9\u91cc\u5b9e\u9645\u4e0a\u6709\u4e24\u6b21Ground Truth Assign\u7684\u8fc7\u7a0b\uff0c\u7b2c\u4e00\u6b21\u91c7\u7528\u7684K\u6700\u8fd1\u70b9\u7684\u5206\u914d,\u9996\u5148\u6839\u636e\u6846\u7684\u5927\u5c0f\u5206\u914d\u5230\u6307\u5b9a\u7684FPN Scale\u4e0a\uff0c\u7136\u540e\u5bfb\u627e\u4e2d\u70b9\u6700\u8fd1\u7684k(\u9ed8\u8ba4\u6b63\u6837\u672c)\u4e2a\u70b9\u7ed9\u6b63\u6837\u672c.\u7b2c\u4e8c\u6b21\u5219\u662f\u6839\u636e\u7b2c\u4e00\u9636\u6bb5\u7684\u9884\u6d4b\u6846\u4f5c\u4e3aanchor(\u8fd9\u6837\u6bcf\u4e00\u4e2ascale\u4e0a\u6bcf\u4e00\u4e2a\u70b9\u90fd\u6709\u4e00\u4e2aanchor),\u9009\u62e9IoU\u8d85\u8d8athreshold\u7684\u4f5c\u4e3a\u6b63\u6837\u672c\u3002\u6700\u540e\u5206\u7c7bloss\u6309\u7167\u5728\u7b2c\u4e8c\u6b21\u5206\u914d\u7684\u7ed3\u679c\u6765\u7b97\u3002 \u800c\u7531\u70b9\u5230bounding box\u7684\u7b97\u6cd5\u4f5c\u8005\u7ed9\u4e86\u4e09\u4e2a\u65b9\u6848\uff0c\u6700\u76f4\u89c2\u7684\u662f\u5176\u4e2d\u7684min-max\u65b9\u6848\u3002\u4f46\u662f\u6700\u540edefault\u7684\u662f\u81ea\u9002\u5e94\u7684 pts_y_mean = pts_y . mean ( dim = 1 , keepdim = True ) pts_x_mean = pts_x . mean ( dim = 1 , keepdim = True ) pts_y_std = torch . std ( pts_y - pts_y_mean , dim = 1 , keepdim = True ) pts_x_std = torch . std ( pts_x - pts_x_mean , dim = 1 , keepdim = True ) moment_transfer = ( self . moment_transfer * self . moment_mul ) + ( self . moment_transfer . detach () * ( 1 - self . moment_mul )) moment_width_transfer = moment_transfer [ 0 ] moment_height_transfer = moment_transfer [ 1 ] half_width = pts_x_std * torch . exp ( moment_width_transfer ) # \\lambda_x in paper, learnable parameters of the module half_height = pts_y_std * torch . exp ( moment_height_transfer ) bbox = torch . cat ([ pts_x_mean - half_width , pts_y_mean - half_height , pts_x_mean + half_width , pts_y_mean + half_height ], dim = 1 ) Dense RepPoints \u8fd9\u7bc7paper\u57282D bounding box detection\u7684\u57fa\u672c\u6982\u5ff5\u662f\u5728RepPoints\u7684\u57fa\u7840\u4e0a\u9884\u6d4b\u66f4\u591a\u7684representation points\uff0c \u540c\u65f6\u63d0\u51fa\u4e86 Group Pooling / Shared offset fields / Shared attribute map. (\u4ee3\u7801\u5b9e\u73b0\u4e0e\u4e0a\u9762\u4e00\u6837\u6bd4\u8f83\u6df7\u4e71, \u4e14Group Pooling\u4e0e\u6587\u4e2d\u56fe\u7247\u5b9e\u73b0\u7684\u6548\u679c\u6709\u5dee\u5f02\uff0c\u4ec5\u4f9b\u53c2\u8003) RepPoint2 v2 \u8fd9\u7bc7paper\u7684\u601d\u8def\u662f\u901a\u8fc7\u989d\u5916\u9884\u6d4b\u524d\u666f\u4ee5\u53ca\u89d2\u70b9\u7684\u9884\u6d4b\u6765\u63d0\u5347\u68c0\u6d4b\u7684\u51c6\u786e\u5ea6","title":"RepPoints / Dense RepPoints / RepPointsV2"},{"location":"other_categories/object_detection_2D/Reppoints/#reppoints-dense-reppoints-reppointsv2","text":"pdf1 code1 pdf2 code2 pdf3 code-all","title":"RepPoints / Dense RepPoints / RepPointsV2"},{"location":"other_categories/object_detection_2D/Reppoints/#reppoints","text":"reppoints\u8bba\u6587\u7684\u6838\u5fc3\u601d\u8def\u662f\u8ba9\u7f51\u7edc\u81ea\u9002\u5e94\u5730\u5b66\u4e60keypoints,\u5e76\u5229\u7528keypoints\u5206\u67902D\u6846\u7684\u4f4d\u7f6e\u4e0e\u5927\u5c0f\u3002\u8fd9\u91cc\u7275\u6d89\u7684\u96be\u70b9\u5728\u4e8ebbox detection\u4efb\u52a1\u4e2d\u662f\u6ca1\u6709keypoint\u8bbe\u7f6e\u7684\uff0c\u56e0\u4e3a\u7f51\u7edc\u9700\u8981\u81ea\u5df1\u53bb\u5b66keypoint\u7684\u4f4d\u7f6e\u3002","title":"RepPoints"},{"location":"other_categories/object_detection_2D/Reppoints/#_1","text":"# pts_out_init -> offsets fields from CNN pts_out_init_grad_mul = ( 1 - self . gradient_mul ) * pts_out_init . detach () + self . gradient_mul * pts_out_init # a trick to wind down the gradient from DCN dcn_offset = pts_out_init_grad_mul - dcn_base_offset cls_out = self . reppoints_cls_out ( self . relu ( self . reppoints_cls_conv ( cls_feat , dcn_offset ))) # conv ( relu (deform_conv)) pts_out_refine = self . reppoints_pts_refine_out ( self . relu ( self . reppoints_pts_refine_conv ( pts_feat , dcn_offset ))) # conv ( relu (deform_conv)) \u8fd9\u91cc\u5b9e\u9645\u4e0a\u6709\u4e24\u6b21Ground Truth Assign\u7684\u8fc7\u7a0b\uff0c\u7b2c\u4e00\u6b21\u91c7\u7528\u7684K\u6700\u8fd1\u70b9\u7684\u5206\u914d,\u9996\u5148\u6839\u636e\u6846\u7684\u5927\u5c0f\u5206\u914d\u5230\u6307\u5b9a\u7684FPN Scale\u4e0a\uff0c\u7136\u540e\u5bfb\u627e\u4e2d\u70b9\u6700\u8fd1\u7684k(\u9ed8\u8ba4\u6b63\u6837\u672c)\u4e2a\u70b9\u7ed9\u6b63\u6837\u672c.\u7b2c\u4e8c\u6b21\u5219\u662f\u6839\u636e\u7b2c\u4e00\u9636\u6bb5\u7684\u9884\u6d4b\u6846\u4f5c\u4e3aanchor(\u8fd9\u6837\u6bcf\u4e00\u4e2ascale\u4e0a\u6bcf\u4e00\u4e2a\u70b9\u90fd\u6709\u4e00\u4e2aanchor),\u9009\u62e9IoU\u8d85\u8d8athreshold\u7684\u4f5c\u4e3a\u6b63\u6837\u672c\u3002\u6700\u540e\u5206\u7c7bloss\u6309\u7167\u5728\u7b2c\u4e8c\u6b21\u5206\u914d\u7684\u7ed3\u679c\u6765\u7b97\u3002 \u800c\u7531\u70b9\u5230bounding box\u7684\u7b97\u6cd5\u4f5c\u8005\u7ed9\u4e86\u4e09\u4e2a\u65b9\u6848\uff0c\u6700\u76f4\u89c2\u7684\u662f\u5176\u4e2d\u7684min-max\u65b9\u6848\u3002\u4f46\u662f\u6700\u540edefault\u7684\u662f\u81ea\u9002\u5e94\u7684 pts_y_mean = pts_y . mean ( dim = 1 , keepdim = True ) pts_x_mean = pts_x . mean ( dim = 1 , keepdim = True ) pts_y_std = torch . std ( pts_y - pts_y_mean , dim = 1 , keepdim = True ) pts_x_std = torch . std ( pts_x - pts_x_mean , dim = 1 , keepdim = True ) moment_transfer = ( self . moment_transfer * self . moment_mul ) + ( self . moment_transfer . detach () * ( 1 - self . moment_mul )) moment_width_transfer = moment_transfer [ 0 ] moment_height_transfer = moment_transfer [ 1 ] half_width = pts_x_std * torch . exp ( moment_width_transfer ) # \\lambda_x in paper, learnable parameters of the module half_height = pts_y_std * torch . exp ( moment_height_transfer ) bbox = torch . cat ([ pts_x_mean - half_width , pts_y_mean - half_height , pts_x_mean + half_width , pts_y_mean + half_height ], dim = 1 )","title":"\u7f51\u7edc\u7ed3\u6784"},{"location":"other_categories/object_detection_2D/Reppoints/#dense-reppoints","text":"\u8fd9\u7bc7paper\u57282D bounding box detection\u7684\u57fa\u672c\u6982\u5ff5\u662f\u5728RepPoints\u7684\u57fa\u7840\u4e0a\u9884\u6d4b\u66f4\u591a\u7684representation points\uff0c \u540c\u65f6\u63d0\u51fa\u4e86 Group Pooling / Shared offset fields / Shared attribute map. (\u4ee3\u7801\u5b9e\u73b0\u4e0e\u4e0a\u9762\u4e00\u6837\u6bd4\u8f83\u6df7\u4e71, \u4e14Group Pooling\u4e0e\u6587\u4e2d\u56fe\u7247\u5b9e\u73b0\u7684\u6548\u679c\u6709\u5dee\u5f02\uff0c\u4ec5\u4f9b\u53c2\u8003)","title":"Dense RepPoints"},{"location":"other_categories/object_detection_2D/Reppoints/#reppoint2-v2","text":"\u8fd9\u7bc7paper\u7684\u601d\u8def\u662f\u901a\u8fc7\u989d\u5916\u9884\u6d4b\u524d\u666f\u4ee5\u53ca\u89d2\u70b9\u7684\u9884\u6d4b\u6765\u63d0\u5347\u68c0\u6d4b\u7684\u51c6\u786e\u5ea6","title":"RepPoint2 v2"},{"location":"other_categories/object_detection_2D/SSD/","text":"SSD: Single Shot MultiBox Detector \u8bad\u7ec3loss\u7531\u5b9a\u4f4d\u4e0e\u5206\u7c7b\u4e24\u4e2a\u90e8\u5206\u7ec4\u6210 \u5173\u4e8e\u5b9a\u4f4dloss: \u5206\u4e3a\u6846\u7684\u4e2d\u70b9\u7684x\uff0cy\u4e0e\u5bbd\u5ea6\u4e0e\u9ad8\u5ea6\u3002 x, y\u7684\u76ee\u6807\u503c\u4e3a(\u6ce8\u610f\u4e0d\u540c\u5206\u8fa8\u7387\u4e2d\u683c\u5b50\u7684\u5bbd\u5ea6\u662f\u4e0d\u540c\u7684) \\frac{\u5b9e\u9645\u4e2d\u70b9\u7684\u4f4d\u7f6e-\u683c\u5b50\u4e2d\u70b9\u7684\u4f4d\u7f6e}{\u683c\u5b50\u5bbd\u5ea6} \u800c\u5bbd\u5ea6\u4e0e\u9ad8\u5ea6\u7684\u76ee\u6807\u503c\u4e3a log\\frac{\u76ee\u6807\u957f\u5bbd}{\u683c\u5b50\u957f\u5bbd}","title":"SSD: Single Shot MultiBox Detector"},{"location":"other_categories/object_detection_2D/SSD/#ssd-single-shot-multibox-detector","text":"","title":"SSD: Single Shot MultiBox Detector"},{"location":"other_categories/object_detection_2D/SSD/#loss","text":"","title":"\u8bad\u7ec3loss\u7531\u5b9a\u4f4d\u4e0e\u5206\u7c7b\u4e24\u4e2a\u90e8\u5206\u7ec4\u6210"},{"location":"other_categories/object_detection_2D/SSD/#loss_1","text":"\u5206\u4e3a\u6846\u7684\u4e2d\u70b9\u7684x\uff0cy\u4e0e\u5bbd\u5ea6\u4e0e\u9ad8\u5ea6\u3002 x, y\u7684\u76ee\u6807\u503c\u4e3a(\u6ce8\u610f\u4e0d\u540c\u5206\u8fa8\u7387\u4e2d\u683c\u5b50\u7684\u5bbd\u5ea6\u662f\u4e0d\u540c\u7684) \\frac{\u5b9e\u9645\u4e2d\u70b9\u7684\u4f4d\u7f6e-\u683c\u5b50\u4e2d\u70b9\u7684\u4f4d\u7f6e}{\u683c\u5b50\u5bbd\u5ea6} \u800c\u5bbd\u5ea6\u4e0e\u9ad8\u5ea6\u7684\u76ee\u6807\u503c\u4e3a log\\frac{\u76ee\u6807\u957f\u5bbd}{\u683c\u5b50\u957f\u5bbd}","title":"\u5173\u4e8e\u5b9a\u4f4dloss:"},{"location":"other_categories/object_detection_2D/ThunderNet:_Towards_Real-time_Generic_Object_Detection_on_Mobile_Devices/","text":"ThunderNet: Towards Real-time Generic Object Detection on Mobile Devices \u8fd9\u7bc7\u8bba\u6587\u5c06\u4e00\u4e2atwo-stage\u7684detection\u7f51\u7edc\u5c3d\u53ef\u80fd\u5730\u8f7b\u91cf\u5316\u4ee5\u5b9e\u73b0\u5b9e\u65f6\u8ba1\u7b97\u7684\u76ee\u6807\uff0c\u8fd9\u7bc7\u6587\u7ae0 \u6709\u4e00\u7bc7\u5bf9\u8bfb\u8005\u5f88\u53cb\u597d\u7684Medieum\u89e3\u8bfb\uff0c\u8fd9\u91cc\u505a\u4e00\u4e2a\u5f15\u7528 . \u4e0e\u672c\u7f51\u9875\u5176\u4ed6\u6587\u7ae0\u4e00\u6837\uff0c\u672c\u6587\u4e0e\u5176\u76f8\u6bd4\u4f1a\u66f4\u6ce8\u91cd\u65b9\u6cd5\u7684\u89e3\u8bfb\u3002 \u603b\u4f53PipeLine \u5176\u4e2dSNet\u7f51\u7edc\u662f\u57fa\u4e8e ShuffleNetV2 .\u9ed8\u8ba4\u7684\u8f93\u5165\u5206\u8fa8\u7387\u662f 320\\times320 ,\u672c\u6587\u5728backbone\u65b9\u9762\u7684\u63d0\u5347\u4e3b\u8981\u662f\u63d0\u5347\u611f\u53d7\u573a\u7684\u5927\u5c0f\u3002 Context Enhancement Module \u8fd9\u4e00\u4e2a\u6a21\u578b\u7684\u8fd0\u7b97\u5728\u56fe\u4e2d\u8f83\u4e3a\u6e05\u695a\uff0c\u5b9e\u8d28\u4e0a\u5c31\u662f\u7528\u5c3d\u53ef\u80fd\u5c11\u7684\u8fd0\u7b97\u91cf\uff0c\u5b9e\u73b0\u8f83\u4e3a\u590d\u6742\u591a\u6837\u7684\u590d\u5408\u611f\u53d7\u91ce\u3002 Spatial Attention Module \u5728RoI resize\u4e4b\u524d\uff0c\u5b9e\u73b0\u5bf9channel\u7684\u4e00\u4e2areweights\u3002 \u5c06\u8fd9\u5f20\u56fe\u653e\u56depipeline\u56fe\u4e2d\u53ef\u4ee5\u770b\u5230\uff0c F^{RPN} \u662fCEM\u8f6c\u6362\u540e\u7684\u8f93\u51fa,\u4f5c\u4e3aRoIAlign\u7684\u6743\u91cd\u4ee5\u53cabase bounding box\u7684\u8f93\u51fa\u6e90\uff0c\u800c\u8fd9\u4e2a\u6a21\u5757\u6700\u540e\u7ed9\u51fa\u7684 F^{SAM} \u662fRoIAlign\u5bf9\u5e94bounding box\u53d6\u5185\u5bb9\u8f93\u5165\u5230\u4e0b\u4e00\u5c42\u7684\u8f93\u51fa\u6e90\u3002 \u5b9e\u9a8c\u7ed3\u679c \u6700\u6d45\u7684\u6a21\u5757\u6700\u7ec8\u80fd\u5728\u9a81\u9f99845\u4e0a\u8dd1\u523025hz\u3002","title":"ThunderNet: Towards Real-time Generic Object Detection on Mobile Devices"},{"location":"other_categories/object_detection_2D/ThunderNet:_Towards_Real-time_Generic_Object_Detection_on_Mobile_Devices/#thundernet-towards-real-time-generic-object-detection-on-mobile-devices","text":"\u8fd9\u7bc7\u8bba\u6587\u5c06\u4e00\u4e2atwo-stage\u7684detection\u7f51\u7edc\u5c3d\u53ef\u80fd\u5730\u8f7b\u91cf\u5316\u4ee5\u5b9e\u73b0\u5b9e\u65f6\u8ba1\u7b97\u7684\u76ee\u6807\uff0c\u8fd9\u7bc7\u6587\u7ae0 \u6709\u4e00\u7bc7\u5bf9\u8bfb\u8005\u5f88\u53cb\u597d\u7684Medieum\u89e3\u8bfb\uff0c\u8fd9\u91cc\u505a\u4e00\u4e2a\u5f15\u7528 . \u4e0e\u672c\u7f51\u9875\u5176\u4ed6\u6587\u7ae0\u4e00\u6837\uff0c\u672c\u6587\u4e0e\u5176\u76f8\u6bd4\u4f1a\u66f4\u6ce8\u91cd\u65b9\u6cd5\u7684\u89e3\u8bfb\u3002","title":"ThunderNet: Towards Real-time Generic Object Detection on Mobile Devices"},{"location":"other_categories/object_detection_2D/ThunderNet:_Towards_Real-time_Generic_Object_Detection_on_Mobile_Devices/#pipeline","text":"\u5176\u4e2dSNet\u7f51\u7edc\u662f\u57fa\u4e8e ShuffleNetV2 .\u9ed8\u8ba4\u7684\u8f93\u5165\u5206\u8fa8\u7387\u662f 320\\times320 ,\u672c\u6587\u5728backbone\u65b9\u9762\u7684\u63d0\u5347\u4e3b\u8981\u662f\u63d0\u5347\u611f\u53d7\u573a\u7684\u5927\u5c0f\u3002","title":"\u603b\u4f53PipeLine"},{"location":"other_categories/object_detection_2D/ThunderNet:_Towards_Real-time_Generic_Object_Detection_on_Mobile_Devices/#context-enhancement-module","text":"\u8fd9\u4e00\u4e2a\u6a21\u578b\u7684\u8fd0\u7b97\u5728\u56fe\u4e2d\u8f83\u4e3a\u6e05\u695a\uff0c\u5b9e\u8d28\u4e0a\u5c31\u662f\u7528\u5c3d\u53ef\u80fd\u5c11\u7684\u8fd0\u7b97\u91cf\uff0c\u5b9e\u73b0\u8f83\u4e3a\u590d\u6742\u591a\u6837\u7684\u590d\u5408\u611f\u53d7\u91ce\u3002","title":"Context Enhancement Module"},{"location":"other_categories/object_detection_2D/ThunderNet:_Towards_Real-time_Generic_Object_Detection_on_Mobile_Devices/#spatial-attention-module","text":"\u5728RoI resize\u4e4b\u524d\uff0c\u5b9e\u73b0\u5bf9channel\u7684\u4e00\u4e2areweights\u3002 \u5c06\u8fd9\u5f20\u56fe\u653e\u56depipeline\u56fe\u4e2d\u53ef\u4ee5\u770b\u5230\uff0c F^{RPN} \u662fCEM\u8f6c\u6362\u540e\u7684\u8f93\u51fa,\u4f5c\u4e3aRoIAlign\u7684\u6743\u91cd\u4ee5\u53cabase bounding box\u7684\u8f93\u51fa\u6e90\uff0c\u800c\u8fd9\u4e2a\u6a21\u5757\u6700\u540e\u7ed9\u51fa\u7684 F^{SAM} \u662fRoIAlign\u5bf9\u5e94bounding box\u53d6\u5185\u5bb9\u8f93\u5165\u5230\u4e0b\u4e00\u5c42\u7684\u8f93\u51fa\u6e90\u3002","title":"Spatial Attention Module"},{"location":"other_categories/object_detection_2D/ThunderNet:_Towards_Real-time_Generic_Object_Detection_on_Mobile_Devices/#_1","text":"\u6700\u6d45\u7684\u6a21\u5757\u6700\u7ec8\u80fd\u5728\u9a81\u9f99845\u4e0a\u8dd1\u523025hz\u3002","title":"\u5b9e\u9a8c\u7ed3\u679c"},{"location":"other_categories/object_detection_2D/YOLOv4/","text":"YOLOv4: Optimal Speed and Accuracy of Object Detection \u8fd9\u7bc7Yolov4\u662f\"\u5b98\u65b9\u7ee7\u627f\u8005\"\u7684\u5b98\u65b9paper,\u5927\u89c4\u6a21\u5730\u96c6\u6210\u4e86\u5404\u79cd\u5404\u6837\u7684trick\uff0c\u4e5f\u8c03\u6574\u4e86\u5f88\u591a\u6a21\u578b\u3002\u503c\u5f97\u5173\u6ce8\u7684\u5730\u65b9\u5728\u4e8e\u4f5c\u8005\u5f88\u4e13\u6ce8\u4e8e\u5728GPU\u4e0a\u7684\u8fd0\u7b97\u901f\u5ea6\u4ee5\u53ca\u5728GPU\u4e0a\u7684\u8bad\u7ec3\u53ef\u80fd\u6027\u3002Paper \u5bf9\u73b0\u6709Tricks\u505a\u4e86\u76f8\u5f53\u591a\u7684Review\u8ddf\u6d4b\u8bd5\u3002\u8fd9\u7bc7paper\u4ee5\u53ca\u8fd9\u4e2a\u9875\u9762\u53ef\u4ee5\u7b97\u662fobject detection tricks\u7684\u4e00\u4e2a\u5c0fWiki\u3002 Related Works Models \u8fd9\u91cc\u63d0\u4f9b\u4e00\u4e9b\u5df2\u6709\u7684\u7b80\u4ecb: Efficient ; SPP in PSM ; RFB ; SAM in CBAM ; SSD ; CornetNet ; CenterNet ; FCOS \u8fd9\u91cc\u8865\u5145\u4e24\u4e2a\u94fe\u63a5,ASPP \u6765\u81ea\u4e8e DeepLabv3 ; CSPNet pdf CSP\u7f51\u7edc\u6765\u81ea\u4e8e\u4f5c\u8005\u7684\u524d\u4e00\u6279\u5de5\u4f5c\u3002 Bag of Freebies \u4e00\u7cfb\u5217\u8bad\u7ec3trick\uff0c\u79f0\u4e3afreebies\u56e0\u4e3a\u4e0d\u589e\u52a0\u63a8\u7406\u6210\u672c. \u5148\u53c2\u8003Amazon\u7684paper\u7684 \u7b80\u4ecb \u4e3b\u8981\u5206\u7c7b\u4e3a input augmentation/feature map dropping; label-softing; Loss(IoU Loss). \u8fd9\u91cc\u8865\u5145\u7ed3\u679ctrick\u7684\u7b80\u4ecb\u7684\u94fe\u63a5\u3002 DropBlock ; MixUp ; label-smoothing ; Focal loss ; GIoU ; DIoU and CIoU \u6570\u636e\u589e\u5f3a\u793a\u4f8b Bag of specials \u4e00\u7cfb\u5217\u63d0\u5347\u7f51\u7edc\u6027\u80fd\u7684Module/necks/activation function/post-processing. \u4f5c\u8005\u8868\u793a\u4e00\u4e2a\u9b54\u6539\u540e\u7684SPP module\u5bf9\u6027\u80fd\u7684\u63d0\u5347\u5f88\u663e\u8457\u4e14\u8fd0\u7b97\u5dee\u8ddd\u4e0d\u5927\u3002 RFB\u539f\u6587\u4e2d\u6027\u80fd\u63d0\u5347\u5c1a\u53ef\uff0c\u4f46\u662f\u8fd0\u7b97\u65f6\u95f4\u7684\u63d0\u5347\u4e5f\u662f\u5f88\u663e\u8457\u7684\u3002 Squeeze-and-Excitation \u5c3d\u7ba1FLOPs\u63d0\u5347\u4e0d\u5927\uff0c\u4f46\u662f\u5728GPU\u63a8\u7406\u65f6\u95f4\u7684\u589e\u52a0\u4e0a\u662f\u76f8\u5bf9\u6bd4\u8f83\u5927\u7684\uff0c\u800c\u53e6\u5916 SAM \u6027\u80fd\u63d0\u5347\u7a0d\u5fae\u6ca1\u90a3\u4e48\u663e\u8457\uff0c\u4f46\u662fGPU\u8fd0\u7b97\u65f6\u95f4\u5dee\u8ddd\u4e0d\u5927\u3002 Mish pdf \u542f\u53d1\u4e0eSwish f(x) = x \\cdot sigmoid(x) Mish\u7684\u8ba1\u7b97 \\begin{aligned} &f(x)=x \\cdot \\tanh (\\zeta(x))\\\\ & \\zeta(x)=\\ln \\left(1+e^{x}\\right) \\rightarrow \\text{softplus} \\end{aligned} Mish\u4f5c\u8005\u6307\u51fa\u5efa\u8bae\u4f7f\u7528\u66f4\u4f4e\u7684learning rate. System Design \u4f5c\u8005\u7ed9\u51fa\u7ed3\u8bba\uff0c\u4e3a\u4e86\u63d0\u5347\u6027\u80fd\uff0c\u9700\u8981: 1. \u8f93\u5165\u56fe\u7247\u5206\u8fa8\u7387\u5e94\u8be5\u6bd4\u8f83\u5927 2. \u7f51\u7edc\u5c42\u6570\u5927\uff0c\u611f\u53d7\u91ce\u5927 3. \u7f51\u7edc\u53c2\u6570\u8981\u8db3\u591f\u591a\u3002 neck\u9009\u62e9\u7684\u662fPANet PANet pdf \u4e00\u4e2a\u6bd4\u8f83\u597d\u7684 \u7b80\u4ecb\u5728CSDN . \u989d\u5916\u63d0\u5347trick Mosaic \u6570\u636e\u589e\u5f3atrick\uff0c\u9576\u5d4c; \u5982\u56fe: Self-Adversarital Training \u65b0\u7684\u8bad\u7ec3\u53ca\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u4e00\u6b21\u8bad\u7ec3\u9700\u8981\u4e24\u6b21Forward backward.\u7b2c\u4e00\u4e2astage\uff0c\u795e\u7ecf\u7f51\u7edc\u4f1a\u4fee\u6539\u539f\u56fe\u800c\u4e0d\u662f\u7f51\u7edc\u6743\u91cd\uff08\u76f8\u5f53\u4e8e\u5bf9\u6297\u6027\u5730\u4fee\u6539\u539f\u56fe\u7247\uff09.\u7b2c\u4e8c\u4e2astage\uff0c\u624d\u6b63\u5e38\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u3002 Cross mini-Batch Normalization CmBN\u542f\u53d1\u4e8eminibatch-Batchnorm(\u4e00\u4e2abatch\u5206\u51e0\u4e2amini-batch)\u4ee5\u53ca Cross iteration BatchNorm Modified SAM and PAN Over all \u8865\u5145\u8bf4\u660e Eliminate grid sensitivity \u5728\u9884\u6d4b2D bounding box\u4e2d\u5fc3\u70b9\u65f6\uff0c\u4e00\u4e2a\u5199\u6cd5\u662f bx=\\sigma(t_x) + cx ,\u5176\u4e2d \\sigma(t_x) \u662f\u9884\u6d4b\u7684\u4e2d\u5fc3\u70b9\u4e0eanchor\u7684\u504f\u79fb\u3002\u5f53 \\sigma(t_x) \u63a5\u8fd10/1\u65f6\uff0c\u7f51\u7edc\u8f93\u51fa\u503c\u4f1a\u5f88\u5927\uff0c\u4e0d\u4fbf\u4e8e\uff0c\u5b66\u4e60\uff0c\u6240\u4ee5\u4f5c\u8005\u5728sigmoid\u524d\u9762\u4e58\u4e86\u4e00\u4e2a\u5927\u4e8e1.0\u7684factor\u3002 Genetic algorithms for optimal hyperparameters \u8fd9\u4e2a\u5b9e\u73b0\u7ec6\u8282\u6709\u5f85\u89c2\u5bdf\uff0c\u610f\u601d\u662f\u5728training\u524d\u671f\uff0c\u4f7f\u7528GA\u9009\u62e9\u6700\u4f18\u7684\u8d85\u53c2\uff0c\u6bd4\u5982\u5b66\u4e60\u7387\u7b49\u3002 \u5b9e\u9a8c\u5bf9\u6bd4\u5404\u4e2atrick Bag of Freebies on Classifier \u6700\u7ec8\u53d1\u73b0CutMix, Mosaic, Label Smoothing, Mish\u6709\u7528\u3002 Bag of Freebies on Detector \u4e2a\u4eba\u89c2\u5bdf\u6765\u6bd4\u8f83\u6709\u6548\u679c\u800c\u4e14\u7279\u6b8a\u7684\u662fMosaic\u6709\u6548\uff0cGA\u6709\u6548\uff0cGIoU\u6216\u8005CIoU\u6709\u6548\u3002 \u6700\u7ec8\u7ecf\u8fc7\u9009\u62e9\u4e0e\u5904\u7406\u540e\uff0c\u5de5\u7a0b\u5ea6\u6781\u9ad8\u7684Yolov4\u5728\u5f88\u9ad8\u7684FPS\u7684\u57fa\u7840\u4e0a\u8dd1\u51fa\u4e86\u6bd4\u8f83\u9ad8\u7684\u7cbe\u786e\u5ea6(\u7cbe\u5ea6\u9ad8\u4e8eYolov3, \u901f\u5ea6\u5feb\u4e8eEfficientDet)","title":"YOLOv4: Optimal Speed and Accuracy of Object Detection"},{"location":"other_categories/object_detection_2D/YOLOv4/#yolov4-optimal-speed-and-accuracy-of-object-detection","text":"\u8fd9\u7bc7Yolov4\u662f\"\u5b98\u65b9\u7ee7\u627f\u8005\"\u7684\u5b98\u65b9paper,\u5927\u89c4\u6a21\u5730\u96c6\u6210\u4e86\u5404\u79cd\u5404\u6837\u7684trick\uff0c\u4e5f\u8c03\u6574\u4e86\u5f88\u591a\u6a21\u578b\u3002\u503c\u5f97\u5173\u6ce8\u7684\u5730\u65b9\u5728\u4e8e\u4f5c\u8005\u5f88\u4e13\u6ce8\u4e8e\u5728GPU\u4e0a\u7684\u8fd0\u7b97\u901f\u5ea6\u4ee5\u53ca\u5728GPU\u4e0a\u7684\u8bad\u7ec3\u53ef\u80fd\u6027\u3002Paper \u5bf9\u73b0\u6709Tricks\u505a\u4e86\u76f8\u5f53\u591a\u7684Review\u8ddf\u6d4b\u8bd5\u3002\u8fd9\u7bc7paper\u4ee5\u53ca\u8fd9\u4e2a\u9875\u9762\u53ef\u4ee5\u7b97\u662fobject detection tricks\u7684\u4e00\u4e2a\u5c0fWiki\u3002","title":"YOLOv4: Optimal Speed and Accuracy of Object Detection"},{"location":"other_categories/object_detection_2D/YOLOv4/#related-works","text":"","title":"Related Works"},{"location":"other_categories/object_detection_2D/YOLOv4/#models","text":"\u8fd9\u91cc\u63d0\u4f9b\u4e00\u4e9b\u5df2\u6709\u7684\u7b80\u4ecb: Efficient ; SPP in PSM ; RFB ; SAM in CBAM ; SSD ; CornetNet ; CenterNet ; FCOS \u8fd9\u91cc\u8865\u5145\u4e24\u4e2a\u94fe\u63a5,ASPP \u6765\u81ea\u4e8e DeepLabv3 ;","title":"Models"},{"location":"other_categories/object_detection_2D/YOLOv4/#cspnet","text":"pdf CSP\u7f51\u7edc\u6765\u81ea\u4e8e\u4f5c\u8005\u7684\u524d\u4e00\u6279\u5de5\u4f5c\u3002","title":"CSPNet"},{"location":"other_categories/object_detection_2D/YOLOv4/#bag-of-freebies","text":"\u4e00\u7cfb\u5217\u8bad\u7ec3trick\uff0c\u79f0\u4e3afreebies\u56e0\u4e3a\u4e0d\u589e\u52a0\u63a8\u7406\u6210\u672c. \u5148\u53c2\u8003Amazon\u7684paper\u7684 \u7b80\u4ecb \u4e3b\u8981\u5206\u7c7b\u4e3a input augmentation/feature map dropping; label-softing; Loss(IoU Loss). \u8fd9\u91cc\u8865\u5145\u7ed3\u679ctrick\u7684\u7b80\u4ecb\u7684\u94fe\u63a5\u3002 DropBlock ; MixUp ; label-smoothing ; Focal loss ; GIoU ; DIoU and CIoU \u6570\u636e\u589e\u5f3a\u793a\u4f8b","title":"Bag of Freebies"},{"location":"other_categories/object_detection_2D/YOLOv4/#bag-of-specials","text":"\u4e00\u7cfb\u5217\u63d0\u5347\u7f51\u7edc\u6027\u80fd\u7684Module/necks/activation function/post-processing. \u4f5c\u8005\u8868\u793a\u4e00\u4e2a\u9b54\u6539\u540e\u7684SPP module\u5bf9\u6027\u80fd\u7684\u63d0\u5347\u5f88\u663e\u8457\u4e14\u8fd0\u7b97\u5dee\u8ddd\u4e0d\u5927\u3002 RFB\u539f\u6587\u4e2d\u6027\u80fd\u63d0\u5347\u5c1a\u53ef\uff0c\u4f46\u662f\u8fd0\u7b97\u65f6\u95f4\u7684\u63d0\u5347\u4e5f\u662f\u5f88\u663e\u8457\u7684\u3002 Squeeze-and-Excitation \u5c3d\u7ba1FLOPs\u63d0\u5347\u4e0d\u5927\uff0c\u4f46\u662f\u5728GPU\u63a8\u7406\u65f6\u95f4\u7684\u589e\u52a0\u4e0a\u662f\u76f8\u5bf9\u6bd4\u8f83\u5927\u7684\uff0c\u800c\u53e6\u5916 SAM \u6027\u80fd\u63d0\u5347\u7a0d\u5fae\u6ca1\u90a3\u4e48\u663e\u8457\uff0c\u4f46\u662fGPU\u8fd0\u7b97\u65f6\u95f4\u5dee\u8ddd\u4e0d\u5927\u3002","title":"Bag of specials"},{"location":"other_categories/object_detection_2D/YOLOv4/#mish","text":"pdf \u542f\u53d1\u4e0eSwish f(x) = x \\cdot sigmoid(x) Mish\u7684\u8ba1\u7b97 \\begin{aligned} &f(x)=x \\cdot \\tanh (\\zeta(x))\\\\ & \\zeta(x)=\\ln \\left(1+e^{x}\\right) \\rightarrow \\text{softplus} \\end{aligned} Mish\u4f5c\u8005\u6307\u51fa\u5efa\u8bae\u4f7f\u7528\u66f4\u4f4e\u7684learning rate.","title":"Mish"},{"location":"other_categories/object_detection_2D/YOLOv4/#system-design","text":"\u4f5c\u8005\u7ed9\u51fa\u7ed3\u8bba\uff0c\u4e3a\u4e86\u63d0\u5347\u6027\u80fd\uff0c\u9700\u8981: 1. \u8f93\u5165\u56fe\u7247\u5206\u8fa8\u7387\u5e94\u8be5\u6bd4\u8f83\u5927 2. \u7f51\u7edc\u5c42\u6570\u5927\uff0c\u611f\u53d7\u91ce\u5927 3. \u7f51\u7edc\u53c2\u6570\u8981\u8db3\u591f\u591a\u3002 neck\u9009\u62e9\u7684\u662fPANet","title":"System Design"},{"location":"other_categories/object_detection_2D/YOLOv4/#panet","text":"pdf \u4e00\u4e2a\u6bd4\u8f83\u597d\u7684 \u7b80\u4ecb\u5728CSDN .","title":"PANet"},{"location":"other_categories/object_detection_2D/YOLOv4/#trick","text":"","title":"\u989d\u5916\u63d0\u5347trick"},{"location":"other_categories/object_detection_2D/YOLOv4/#mosaic","text":"\u6570\u636e\u589e\u5f3atrick\uff0c\u9576\u5d4c; \u5982\u56fe:","title":"Mosaic"},{"location":"other_categories/object_detection_2D/YOLOv4/#self-adversarital-training","text":"\u65b0\u7684\u8bad\u7ec3\u53ca\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u4e00\u6b21\u8bad\u7ec3\u9700\u8981\u4e24\u6b21Forward backward.\u7b2c\u4e00\u4e2astage\uff0c\u795e\u7ecf\u7f51\u7edc\u4f1a\u4fee\u6539\u539f\u56fe\u800c\u4e0d\u662f\u7f51\u7edc\u6743\u91cd\uff08\u76f8\u5f53\u4e8e\u5bf9\u6297\u6027\u5730\u4fee\u6539\u539f\u56fe\u7247\uff09.\u7b2c\u4e8c\u4e2astage\uff0c\u624d\u6b63\u5e38\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u3002","title":"Self-Adversarital Training"},{"location":"other_categories/object_detection_2D/YOLOv4/#cross-mini-batch-normalization","text":"CmBN\u542f\u53d1\u4e8eminibatch-Batchnorm(\u4e00\u4e2abatch\u5206\u51e0\u4e2amini-batch)\u4ee5\u53ca Cross iteration BatchNorm","title":"Cross mini-Batch Normalization"},{"location":"other_categories/object_detection_2D/YOLOv4/#modified-sam-and-pan","text":"","title":"Modified SAM and PAN"},{"location":"other_categories/object_detection_2D/YOLOv4/#over-all","text":"\u8865\u5145\u8bf4\u660e","title":"Over all"},{"location":"other_categories/object_detection_2D/YOLOv4/#eliminate-grid-sensitivity","text":"\u5728\u9884\u6d4b2D bounding box\u4e2d\u5fc3\u70b9\u65f6\uff0c\u4e00\u4e2a\u5199\u6cd5\u662f bx=\\sigma(t_x) + cx ,\u5176\u4e2d \\sigma(t_x) \u662f\u9884\u6d4b\u7684\u4e2d\u5fc3\u70b9\u4e0eanchor\u7684\u504f\u79fb\u3002\u5f53 \\sigma(t_x) \u63a5\u8fd10/1\u65f6\uff0c\u7f51\u7edc\u8f93\u51fa\u503c\u4f1a\u5f88\u5927\uff0c\u4e0d\u4fbf\u4e8e\uff0c\u5b66\u4e60\uff0c\u6240\u4ee5\u4f5c\u8005\u5728sigmoid\u524d\u9762\u4e58\u4e86\u4e00\u4e2a\u5927\u4e8e1.0\u7684factor\u3002","title":"Eliminate grid sensitivity"},{"location":"other_categories/object_detection_2D/YOLOv4/#genetic-algorithms-for-optimal-hyperparameters","text":"\u8fd9\u4e2a\u5b9e\u73b0\u7ec6\u8282\u6709\u5f85\u89c2\u5bdf\uff0c\u610f\u601d\u662f\u5728training\u524d\u671f\uff0c\u4f7f\u7528GA\u9009\u62e9\u6700\u4f18\u7684\u8d85\u53c2\uff0c\u6bd4\u5982\u5b66\u4e60\u7387\u7b49\u3002","title":"Genetic algorithms for optimal hyperparameters"},{"location":"other_categories/object_detection_2D/YOLOv4/#trick_1","text":"","title":"\u5b9e\u9a8c\u5bf9\u6bd4\u5404\u4e2atrick"},{"location":"other_categories/object_detection_2D/YOLOv4/#bag-of-freebies-on-classifier","text":"\u6700\u7ec8\u53d1\u73b0CutMix, Mosaic, Label Smoothing, Mish\u6709\u7528\u3002","title":"Bag of Freebies on Classifier"},{"location":"other_categories/object_detection_2D/YOLOv4/#bag-of-freebies-on-detector","text":"\u4e2a\u4eba\u89c2\u5bdf\u6765\u6bd4\u8f83\u6709\u6548\u679c\u800c\u4e14\u7279\u6b8a\u7684\u662fMosaic\u6709\u6548\uff0cGA\u6709\u6548\uff0cGIoU\u6216\u8005CIoU\u6709\u6548\u3002 \u6700\u7ec8\u7ecf\u8fc7\u9009\u62e9\u4e0e\u5904\u7406\u540e\uff0c\u5de5\u7a0b\u5ea6\u6781\u9ad8\u7684Yolov4\u5728\u5f88\u9ad8\u7684FPS\u7684\u57fa\u7840\u4e0a\u8dd1\u51fa\u4e86\u6bd4\u8f83\u9ad8\u7684\u7cbe\u786e\u5ea6(\u7cbe\u5ea6\u9ad8\u4e8eYolov3, \u901f\u5ea6\u5feb\u4e8eEfficientDet)","title":"Bag of Freebies on Detector"},{"location":"other_categories/object_detection_2D/detr/","text":"End-to-End Object Detection with Transformers \u8fd9\u7bc7paper\u7ed9\u7684\u601d\u8def\u662f\u4e00\u4e2a\u7528\u65b0\u5de5\u5177\u8fdb\u884c\u590d\u53e4\u7684\u601d\u8def\u3002\u5728Yolo\u4e0eRCNN\u7edf\u4e00\u4e4b\u524d\uff0cobject detection\u7684\u4e00\u4e2a\u505a\u6cd5\u662f\u4f7f\u7528RNN\u5e8f\u5217\u5730\u8f93\u51fabounding boxes\uff0c\u5f53\u65f6\u6709\u4e00\u4e2a\u9700\u8981\u6ce8\u610f\u7684trick\u5c31\u662floss function\u5728\u8ba1\u7b97\u7684\u65f6\u5019\u9700\u8981\u5148\u5c06Ground truth\u4e0e\u9884\u6d4b\u6846\u8ba1\u7b97\u4e00\u4e2a\u6700\u4f18\u5339\u914d\uff0c\u7136\u540e\u5bf9\u5e94\u8ba1\u7b97loss. \u672c\u6587\u7684\u65b0\u9896\u4e4b\u5904\u5c31\u662f\u4f7f\u7528transformer\u66ff\u4ee3RNN\u5e76\u884cdecode. \u7f51\u7edc\u7ed3\u6784 \u4e00\u4e9b\u7ec6\u8282: \u5339\u914d\u7684\u65f6\u5019\u4f7f\u7528entropy\u635f\u5931+ giou +L1loss, \u5339\u914d\u5728CPU\u4e0a\u5b9e\u73b0\uff0c\u4f7f\u7528\u7684\u662f scipy.optimize.linear_sum_assignment \u635f\u5931\u51fd\u6570\u4f7f\u7528 giou + L1 Loss. \u8bad\u7ec3epoch\u6570\u6bd4\u8f83\u957f\uff0c\u5728custom dataset\u4e0a\u590d\u73b0\u96be\u5ea6\u633a\u5927","title":"End-to-End Object Detection with Transformers"},{"location":"other_categories/object_detection_2D/detr/#end-to-end-object-detection-with-transformers","text":"\u8fd9\u7bc7paper\u7ed9\u7684\u601d\u8def\u662f\u4e00\u4e2a\u7528\u65b0\u5de5\u5177\u8fdb\u884c\u590d\u53e4\u7684\u601d\u8def\u3002\u5728Yolo\u4e0eRCNN\u7edf\u4e00\u4e4b\u524d\uff0cobject detection\u7684\u4e00\u4e2a\u505a\u6cd5\u662f\u4f7f\u7528RNN\u5e8f\u5217\u5730\u8f93\u51fabounding boxes\uff0c\u5f53\u65f6\u6709\u4e00\u4e2a\u9700\u8981\u6ce8\u610f\u7684trick\u5c31\u662floss function\u5728\u8ba1\u7b97\u7684\u65f6\u5019\u9700\u8981\u5148\u5c06Ground truth\u4e0e\u9884\u6d4b\u6846\u8ba1\u7b97\u4e00\u4e2a\u6700\u4f18\u5339\u914d\uff0c\u7136\u540e\u5bf9\u5e94\u8ba1\u7b97loss. \u672c\u6587\u7684\u65b0\u9896\u4e4b\u5904\u5c31\u662f\u4f7f\u7528transformer\u66ff\u4ee3RNN\u5e76\u884cdecode.","title":"End-to-End Object Detection with Transformers"},{"location":"other_categories/object_detection_2D/detr/#_1","text":"\u4e00\u4e9b\u7ec6\u8282: \u5339\u914d\u7684\u65f6\u5019\u4f7f\u7528entropy\u635f\u5931+ giou +L1loss, \u5339\u914d\u5728CPU\u4e0a\u5b9e\u73b0\uff0c\u4f7f\u7528\u7684\u662f scipy.optimize.linear_sum_assignment \u635f\u5931\u51fd\u6570\u4f7f\u7528 giou + L1 Loss. \u8bad\u7ec3epoch\u6570\u6bd4\u8f83\u957f\uff0c\u5728custom dataset\u4e0a\u590d\u73b0\u96be\u5ea6\u633a\u5927","title":"\u7f51\u7edc\u7ed3\u6784"},{"location":"other_categories/others/Adaptive_Unimodal_Cost_Volume_Filtering_for_Deep_Stereo_Matching/","text":"Adaptive Unimodal Cost Volume Filtering for Deep Stereo Matching \u8fd9\u7bc7paper\u89e3\u51b3\u4e86\u53cc\u76ee\u5339\u914d->Cost Volume->Disparity\u8f93\u51fa\u8fd9\u4e2a\u6d41\u7a0b\u4e2d\u6700\u540e\u4e00\u6b65\u4e0a\u7684\u75db\u70b9\u95ee\u9898\u3002 \u5728 PSMNet \u4e2d\uff0c\u8ba1\u7b97\u5f97\u5230Cost Volume\u540e\uff0c\u4f5c\u8005\u91c7\u7528Soft-min\u7684\u65b9\u5f0f\u5f97\u5230\u5404\u4e2a\u70b9\u5bf9\u5404\u4e2adisparity\u7684\u7f6e\u4fe1\u5ea6\uff0c\u52a0\u6743\u6c42\u5e73\u5747\u540e\u518d\u4e0eground truth\u4f5c\u5dee\u6c42loss\u3002 \u8fd9\u4e2aloss\u7684\u5f62\u6210\u95ee\u9898\u5728\u4e8e\u4e0d\u540c\u4f4d\u7f6e\u7684\u68af\u5ea6\u5e76\u4e0d\u5747\u5300\uff0c\u53d6\u51b3\u4e8e\u5bf9\u5e94\u7684\u5750\u6807\u503c\u3002\u7b80\u5355\u7684\u5b9e\u9a8c\u53ef\u4ee5\u8bc1\u660e\u8fd9\u4e2aloss\u662f\u4e0d\u80fd\u6536\u655b\u5230\u6700\u4f18\u89e3\u7684(TO DO). \u672c\u6587\u63d0\u4f9b\u4e86\u66f4\u597d\u7684disparity encoding \u65b9\u5f0f\uff0c \u63d0\u51fastereo focal loss\u3002 Pipeline \u8fd9\u56fe\u8bf4\u660e\u4e86\u672c\u6587\u4e0e\u57fa\u7840\u7684 PSMNet \u7684\u533a\u522b\u3002 Loss Formulation Probabilistic Encoding \u9996\u5148\u6839\u636econfidence map\uff0c\u4ee5\u53ca\u5404\u4e2adispairty channel\u4f4d\u4e0eground truth dispairty\u7684\u6570\u503c\u5dee\uff0c\u6c42\u51fa\u671f\u671b\u5f97\u5230\u7684\u6982\u7387\u5206\u5e03: \\begin{aligned} P(d) &=\\operatorname{softmax}\\left(-\\frac{\\left|d-d^{g t}\\right|}{\\sigma}\\right) \\\\ &=\\frac{\\exp \\left(-c_{d}^{g t}\\right)}{\\sum_{d^{\\prime}=0}^{D-1} \\exp \\left(-c_{d^{\\prime}}^{g t}\\right)} \\end{aligned} Encoding\u8fd9\u90e8\u5206\u7684\u4ee3\u7801\u4e3b\u8981\u5728 \u8fd9\u91cc Stereo Focal Loss \u63a5\u7740\u9700\u8981\u4e00\u4e2aloss\u6765\u63cf\u8ff0\u4e24\u4e2a\u6982\u7387\u5206\u5e03\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u8fd9\u91cc\u91c7\u7528\u7684\u516c\u5f0f\u5982\u4e0b \\mathcal{L}_{S F}=\\frac{1}{|\\mathcal{P}|} \\sum_{p \\in \\mathcal{P}}\\left(\\sum_{d=0}^{D-1}\\left(1-P_{p}(d)\\right)^{-\\alpha} \\cdot\\left(-P_{p}(d) \\cdot \\log \\hat{P}_{p}(d)\\right)\\right) \u5b9e\u8d28\u4e0a\u662f Cross Entropy\u7684\u5f62\u6001\u3002 Multi-level Stereo Cost\u7684\u4ee3\u7801\u4e3b\u8981\u5728 \u8fd9\u91cc","title":"Adaptive Unimodal Cost Volume Filtering for Deep Stereo Matching"},{"location":"other_categories/others/Adaptive_Unimodal_Cost_Volume_Filtering_for_Deep_Stereo_Matching/#adaptive-unimodal-cost-volume-filtering-for-deep-stereo-matching","text":"\u8fd9\u7bc7paper\u89e3\u51b3\u4e86\u53cc\u76ee\u5339\u914d->Cost Volume->Disparity\u8f93\u51fa\u8fd9\u4e2a\u6d41\u7a0b\u4e2d\u6700\u540e\u4e00\u6b65\u4e0a\u7684\u75db\u70b9\u95ee\u9898\u3002 \u5728 PSMNet \u4e2d\uff0c\u8ba1\u7b97\u5f97\u5230Cost Volume\u540e\uff0c\u4f5c\u8005\u91c7\u7528Soft-min\u7684\u65b9\u5f0f\u5f97\u5230\u5404\u4e2a\u70b9\u5bf9\u5404\u4e2adisparity\u7684\u7f6e\u4fe1\u5ea6\uff0c\u52a0\u6743\u6c42\u5e73\u5747\u540e\u518d\u4e0eground truth\u4f5c\u5dee\u6c42loss\u3002 \u8fd9\u4e2aloss\u7684\u5f62\u6210\u95ee\u9898\u5728\u4e8e\u4e0d\u540c\u4f4d\u7f6e\u7684\u68af\u5ea6\u5e76\u4e0d\u5747\u5300\uff0c\u53d6\u51b3\u4e8e\u5bf9\u5e94\u7684\u5750\u6807\u503c\u3002\u7b80\u5355\u7684\u5b9e\u9a8c\u53ef\u4ee5\u8bc1\u660e\u8fd9\u4e2aloss\u662f\u4e0d\u80fd\u6536\u655b\u5230\u6700\u4f18\u89e3\u7684(TO DO). \u672c\u6587\u63d0\u4f9b\u4e86\u66f4\u597d\u7684disparity encoding \u65b9\u5f0f\uff0c \u63d0\u51fastereo focal loss\u3002","title":"Adaptive Unimodal Cost Volume Filtering for Deep Stereo Matching"},{"location":"other_categories/others/Adaptive_Unimodal_Cost_Volume_Filtering_for_Deep_Stereo_Matching/#pipeline","text":"\u8fd9\u56fe\u8bf4\u660e\u4e86\u672c\u6587\u4e0e\u57fa\u7840\u7684 PSMNet \u7684\u533a\u522b\u3002","title":"Pipeline"},{"location":"other_categories/others/Adaptive_Unimodal_Cost_Volume_Filtering_for_Deep_Stereo_Matching/#loss-formulation","text":"","title":"Loss Formulation"},{"location":"other_categories/others/Adaptive_Unimodal_Cost_Volume_Filtering_for_Deep_Stereo_Matching/#probabilistic-encoding","text":"\u9996\u5148\u6839\u636econfidence map\uff0c\u4ee5\u53ca\u5404\u4e2adispairty channel\u4f4d\u4e0eground truth dispairty\u7684\u6570\u503c\u5dee\uff0c\u6c42\u51fa\u671f\u671b\u5f97\u5230\u7684\u6982\u7387\u5206\u5e03: \\begin{aligned} P(d) &=\\operatorname{softmax}\\left(-\\frac{\\left|d-d^{g t}\\right|}{\\sigma}\\right) \\\\ &=\\frac{\\exp \\left(-c_{d}^{g t}\\right)}{\\sum_{d^{\\prime}=0}^{D-1} \\exp \\left(-c_{d^{\\prime}}^{g t}\\right)} \\end{aligned} Encoding\u8fd9\u90e8\u5206\u7684\u4ee3\u7801\u4e3b\u8981\u5728 \u8fd9\u91cc","title":"Probabilistic Encoding"},{"location":"other_categories/others/Adaptive_Unimodal_Cost_Volume_Filtering_for_Deep_Stereo_Matching/#stereo-focal-loss","text":"\u63a5\u7740\u9700\u8981\u4e00\u4e2aloss\u6765\u63cf\u8ff0\u4e24\u4e2a\u6982\u7387\u5206\u5e03\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u8fd9\u91cc\u91c7\u7528\u7684\u516c\u5f0f\u5982\u4e0b \\mathcal{L}_{S F}=\\frac{1}{|\\mathcal{P}|} \\sum_{p \\in \\mathcal{P}}\\left(\\sum_{d=0}^{D-1}\\left(1-P_{p}(d)\\right)^{-\\alpha} \\cdot\\left(-P_{p}(d) \\cdot \\log \\hat{P}_{p}(d)\\right)\\right) \u5b9e\u8d28\u4e0a\u662f Cross Entropy\u7684\u5f62\u6001\u3002 Multi-level Stereo Cost\u7684\u4ee3\u7801\u4e3b\u8981\u5728 \u8fd9\u91cc","title":"Stereo Focal Loss"},{"location":"other_categories/others/Attacking_Optical_Flow/","text":"Attacking Optical Flow \u8fd9\u7bc7paper follow Adversarial Patch \u7684\u505a\u6cd5\uff0c\u4e0d\u540c\u4e4b\u5904\u5728\u4e8e\u4f7f\u7528patch\u53bb\u653b\u51fboptical flow \u800c\u4e0d\u662f\u5355\u5206\u7c7b\u7f51\u7edc\u3002 Approach \u4f18\u5316\u7684\u6307\u6807\u662f\u6700\u5927\u5316\u88ab\u653b\u51fb\u540e\u7684\u5149\u6d41\u65b9\u5411\u4e0e\u6b63\u786e\u5149\u6d41\u65b9\u5411\u7684\u5939\u89d2\u3002 \u4f5c\u8005\u6307\u51fa\u73b0\u5728\u6ca1\u6709\u8db3\u591f\u5927\u91cf\u7684 dense\u3000\u7684optical flow\u3000\u6570\u636e\u96c6\uff0c\u56e0\u800c\u4f7f\u7528\u73b0\u6210model\u751f\u6210Pseudo Ground Truth.\u8fd9\u4e5f\u6709\u4e00\u4e2a\u597d\u5904\u5728\u4e8e\u4f7f\u5f97\u8fd9\u4e2a\u65b9\u6cd5\u53ef\u4ee5\u5728\u4efb\u610f\u672a\u6807\u6ce8\u7684\u89c6\u9891\u4e0a\u8bad\u7ec3\uff0c\u5e76\u653b\u51fb\u4efb\u610f\u7684\u5149\u6d41\u6a21\u578b\u3002 \\hat{p}=\\underset{p}{\\operatorname{argmin}} \\mathbb{E}_{\\left(I_{t}, I_{t+1}\\right) \\sim \\mathcal{I}, l \\sim \\mathcal{L}, \\delta \\sim \\mathcal{T}} \\frac{(u, v) \\cdot(\\tilde{u}, \\tilde{v})}{\\|(u, v)\\| \\cdot\\|(\\tilde{u}, \\tilde{v})\\|} \u5177\u4f53\u6027\u80fd\u53ef\u4ee5\u89c2\u770b\u89c6\u9891","title":"Attacking Optical Flow"},{"location":"other_categories/others/Attacking_Optical_Flow/#attacking-optical-flow","text":"\u8fd9\u7bc7paper follow Adversarial Patch \u7684\u505a\u6cd5\uff0c\u4e0d\u540c\u4e4b\u5904\u5728\u4e8e\u4f7f\u7528patch\u53bb\u653b\u51fboptical flow \u800c\u4e0d\u662f\u5355\u5206\u7c7b\u7f51\u7edc\u3002","title":"Attacking Optical Flow"},{"location":"other_categories/others/Attacking_Optical_Flow/#approach","text":"\u4f18\u5316\u7684\u6307\u6807\u662f\u6700\u5927\u5316\u88ab\u653b\u51fb\u540e\u7684\u5149\u6d41\u65b9\u5411\u4e0e\u6b63\u786e\u5149\u6d41\u65b9\u5411\u7684\u5939\u89d2\u3002 \u4f5c\u8005\u6307\u51fa\u73b0\u5728\u6ca1\u6709\u8db3\u591f\u5927\u91cf\u7684 dense\u3000\u7684optical flow\u3000\u6570\u636e\u96c6\uff0c\u56e0\u800c\u4f7f\u7528\u73b0\u6210model\u751f\u6210Pseudo Ground Truth.\u8fd9\u4e5f\u6709\u4e00\u4e2a\u597d\u5904\u5728\u4e8e\u4f7f\u5f97\u8fd9\u4e2a\u65b9\u6cd5\u53ef\u4ee5\u5728\u4efb\u610f\u672a\u6807\u6ce8\u7684\u89c6\u9891\u4e0a\u8bad\u7ec3\uff0c\u5e76\u653b\u51fb\u4efb\u610f\u7684\u5149\u6d41\u6a21\u578b\u3002 \\hat{p}=\\underset{p}{\\operatorname{argmin}} \\mathbb{E}_{\\left(I_{t}, I_{t+1}\\right) \\sim \\mathcal{I}, l \\sim \\mathcal{L}, \\delta \\sim \\mathcal{T}} \\frac{(u, v) \\cdot(\\tilde{u}, \\tilde{v})}{\\|(u, v)\\| \\cdot\\|(\\tilde{u}, \\tilde{v})\\|} \u5177\u4f53\u6027\u80fd\u53ef\u4ee5\u89c2\u770b\u89c6\u9891","title":"Approach"},{"location":"other_categories/others/Continuous-time_Intensity_Estimation_Using_Event_Cameras/","text":"Continuous-time Intensity Estimation Using Event Cameras \u8fd9\u7bc7\u6587\u7ae0\u7ed9\u51fa\u4e86\u4e00\u4e2a\u4f7f\u7528event camera\u589e\u5f3a\u666e\u901acamera\u7684\u7b97\u6cd5\u3002 Event Camera \u4e0e\u6570\u5b66\u57fa\u7840 \u8bbe p, t \u4e3a\u5750\u6807\u4e0e\u65f6\u95f4, Y(p,t_j) \u4ee3\u8868\u539f\u7167\u7247\u5bf9\u5e94\u5750\u6807\u3001\u65f6\u95f4\u4e0a\u7684\u5149\u5f3a\u5ea6\u3002 event camera,\u6bcf\u4e00\u4e2a\u50cf\u7d20\u4f1a\u5b58\u50a8\u5149\u5f3a\u7684\u53d8\u5316\uff0c\u8d85\u8fc7\u4e00\u4e2a\u9608\u503c c \u540e\u4f1a\u53d1\u51fa\u4e00\u4e2a\u5bf9\u5e94\u7684\u51b2\u6fc0\uff0c\u4f1a\u5728\u5404\u4e2a\u65f6\u523b\u5728\u5404\u4e2a\u76f8\u673a\u50cf\u7d20stream,\u7ed9\u51fa e_i(p,t)=\\sigma^p_i c \\delta(t-t^p_i) ,\u5176\u4e2d \\delta \u4e3a\u51b2\u6fc0\u51fd\u6570\u3002 \\sigma \u6307\u6b63\u8d1f\u6781\u6027 E(\\boldsymbol{p}, t):=\\sum_{i=1}^{\\infty} e_{i}(\\boldsymbol{p}, t)=\\sum_{i=1}^{\\infty} \\sigma_{i}^{p} c \\delta\\left(t-t_{i}^{p}\\right) \u53d6log\u4e3a: L^{E}(\\boldsymbol{p}, t):=\\int_{0}^{t} E(\\boldsymbol{p}, \\tau) d \\tau=\\int_{0}^{t} \\sum_{i=1}^{\\infty} \\sigma_{i}^{\\boldsymbol{p}} c \\delta\\left(\\tau-t_{i}^{\\boldsymbol{p}}\\right) d \\tau \u4e92\u8865\u6ee4\u6ce2\u5668 \u516c\u5f0fODE\uff1a \\frac{\\partial}{\\partial t} \\hat{L}(\\boldsymbol{p}, t)=E(\\boldsymbol{p}, t)-\\alpha\\left(\\hat{L}(\\boldsymbol{p}, t)-L^{F}(\\boldsymbol{p}, t)\\right) (\u4e2a\u4eba\u7406\u89e3\u5176\u4f20\u9012\u51fd\u6570\u4e3a \\hat L = \\frac{s}{s+\\alpha}L^E + \\frac{\\alpha}{s+\\alpha}L^F ) \u672c\u6587\u63d0\u5230\uff0c\u7528\u4f4e\u901a\u6ee4\u6ce2\u5668\u5904\u7406\u76f8\u673a\u539f\u6570\u636e\uff0c\u7528\u9ad8\u901a\u6ee4\u6ce2\u5668\u5904\u7406event camera\u7684\u6570\u636e. \u5177\u4f53\u7b97\u6cd5: \u7b2c\u516d\u884c\uff1a\u6307\u7684\u662f\u65f6\u95f4\u95f4\u9694\u5185\uff0c\u76f8\u5f53\u4e8e\u524d\u6587\u63d0\u5230\u7684ODE\u53f3\u8fb9\u53ea\u6709\u7b2c\u4e8c\u9879\uff0c\u6c42\u89e3\u8fd9\u4e2a\u5e38\u5fae\u5206\u65b9\u7a0b\u3002 \u7b2c\u516b\u884c\uff1a \\hat{L}\\left(\\boldsymbol{p}, \\hat{t}_{k+1}^{p}\\right)=\\hat{L}\\left(\\boldsymbol{p},\\left(\\hat{t}_{k+1}^{p}\\right)^{-}\\right)+\\sigma_{k+1}^{\\boldsymbol{p}} c \u662f\u5c06\u51b2\u6fc0\u503c\u76f4\u63a5\u52a0\u5230\u5bf9\u5e94\u7684\u5750\u6807\u4e2d \u7b2c\u5341\u884c\uff0c\u6ce8\u610f\u4e0d\u76f4\u63a5\u6539\u53d8\u8f93\u51fa\u7684 \\hat L \uff0c\u4f46\u662f\u4f1a\u6539\u53d8\u540e\u9762\u5faa\u73af\u7684\u7b2c13\u884c \u7b2c\u5341\u4e00\u884c\uff0c\u63cf\u8ff0\u7684\u662f\u6839\u636e\u8fc7\u66dd\u5149\u6216\u8005\u4f4e\u66dd\u5149\u7684\u53ef\u80fd(\u6bcf\u4e2a\u5750\u6807\u70b9\u6709\u5bf9\u5e94\u7684 \\alpha_p \u503c,\u4e0e\u5f53\u524d\u76f8\u673a\u5bf9\u5e94\u5750\u6807\u7684\u5149\u5f3a L^F \u6709\u5173).\u76f4\u89c9\u4e0a\u6765\u8bf4 \\alpha \u8d8a\u5c0f\uff0c\u8d8a\u4fe1\u4efbevent camera,\u5728\u5149\u5f3a\u63a5\u8fd1\u6700\u5927\u6700\u5c0f\u503c\u7684\u65f6\u5019\u4fe1\u4efbevent camera,\u5149\u5f3a\u4e2d\u95f4\u503c\u7684\u65f6\u5019\u76f8\u5bf9\u66f4\u4fe1\u4efb\u57fa\u7840\u76f8\u673a\uff0c\u5176\u516c\u5f0f\u5982\u4e0b: \\alpha(\\boldsymbol{p}, t)=\\left\\{\\begin{array}{ll}{\\lambda \\alpha_{1}+(1-\\lambda) \\alpha_{1} \\frac{\\left(L^{F}(\\boldsymbol{p}, t)-L_{\\min }\\right)}{\\left(L_{1}-L_{\\min }\\right)}} & {L_{\\min } \\leq L^{F}(\\boldsymbol{p}, t)<L_{1}} \\\\ {\\alpha_{1}} & {L_{1} \\leq L^{F}(\\boldsymbol{p}, t) \\leq L_{2}} \\\\ {\\lambda \\alpha_{1}+(1-\\lambda) \\alpha_{1} \\frac{\\left(L^{F}(\\boldsymbol{p}, t)-L_{\\max }\\right)}{\\left(L_{2}-L_{\\max }\\right)}} & {L_{2}<L^{F}(\\boldsymbol{p}, t) \\leq L_{\\max }}\\end{array}\\right. \u672c\u6587 \\alpha_1 = 2 \\pi, \\lambda=0.1 [L_1, L_2] = [L_{min} +k, L_{max} -k], k = 0.05*(L_{max}-L_{min}) \u5728\u672c\u4eba(Owen Liu)\u7535\u8111\u91cc\u9762\u8fd0\u884c\u5f97\u5230\u7684\u7ed3\u679c \u4e0a\u534a\u56fe\u4e3a\u539f\u56fe\uff0c\u4e0b\u534a\u56fe\u4e3a\u589e\u5f3a\u540e\u7684\u56fe.","title":"Continuous-time Intensity Estimation Using Event Cameras"},{"location":"other_categories/others/Continuous-time_Intensity_Estimation_Using_Event_Cameras/#continuous-time-intensity-estimation-using-event-cameras","text":"\u8fd9\u7bc7\u6587\u7ae0\u7ed9\u51fa\u4e86\u4e00\u4e2a\u4f7f\u7528event camera\u589e\u5f3a\u666e\u901acamera\u7684\u7b97\u6cd5\u3002","title":"Continuous-time Intensity Estimation Using Event Cameras"},{"location":"other_categories/others/Continuous-time_Intensity_Estimation_Using_Event_Cameras/#event-camera","text":"\u8bbe p, t \u4e3a\u5750\u6807\u4e0e\u65f6\u95f4, Y(p,t_j) \u4ee3\u8868\u539f\u7167\u7247\u5bf9\u5e94\u5750\u6807\u3001\u65f6\u95f4\u4e0a\u7684\u5149\u5f3a\u5ea6\u3002 event camera,\u6bcf\u4e00\u4e2a\u50cf\u7d20\u4f1a\u5b58\u50a8\u5149\u5f3a\u7684\u53d8\u5316\uff0c\u8d85\u8fc7\u4e00\u4e2a\u9608\u503c c \u540e\u4f1a\u53d1\u51fa\u4e00\u4e2a\u5bf9\u5e94\u7684\u51b2\u6fc0\uff0c\u4f1a\u5728\u5404\u4e2a\u65f6\u523b\u5728\u5404\u4e2a\u76f8\u673a\u50cf\u7d20stream,\u7ed9\u51fa e_i(p,t)=\\sigma^p_i c \\delta(t-t^p_i) ,\u5176\u4e2d \\delta \u4e3a\u51b2\u6fc0\u51fd\u6570\u3002 \\sigma \u6307\u6b63\u8d1f\u6781\u6027 E(\\boldsymbol{p}, t):=\\sum_{i=1}^{\\infty} e_{i}(\\boldsymbol{p}, t)=\\sum_{i=1}^{\\infty} \\sigma_{i}^{p} c \\delta\\left(t-t_{i}^{p}\\right) \u53d6log\u4e3a: L^{E}(\\boldsymbol{p}, t):=\\int_{0}^{t} E(\\boldsymbol{p}, \\tau) d \\tau=\\int_{0}^{t} \\sum_{i=1}^{\\infty} \\sigma_{i}^{\\boldsymbol{p}} c \\delta\\left(\\tau-t_{i}^{\\boldsymbol{p}}\\right) d \\tau","title":"Event Camera \u4e0e\u6570\u5b66\u57fa\u7840"},{"location":"other_categories/others/Continuous-time_Intensity_Estimation_Using_Event_Cameras/#_1","text":"\u516c\u5f0fODE\uff1a \\frac{\\partial}{\\partial t} \\hat{L}(\\boldsymbol{p}, t)=E(\\boldsymbol{p}, t)-\\alpha\\left(\\hat{L}(\\boldsymbol{p}, t)-L^{F}(\\boldsymbol{p}, t)\\right) (\u4e2a\u4eba\u7406\u89e3\u5176\u4f20\u9012\u51fd\u6570\u4e3a \\hat L = \\frac{s}{s+\\alpha}L^E + \\frac{\\alpha}{s+\\alpha}L^F ) \u672c\u6587\u63d0\u5230\uff0c\u7528\u4f4e\u901a\u6ee4\u6ce2\u5668\u5904\u7406\u76f8\u673a\u539f\u6570\u636e\uff0c\u7528\u9ad8\u901a\u6ee4\u6ce2\u5668\u5904\u7406event camera\u7684\u6570\u636e. \u5177\u4f53\u7b97\u6cd5: \u7b2c\u516d\u884c\uff1a\u6307\u7684\u662f\u65f6\u95f4\u95f4\u9694\u5185\uff0c\u76f8\u5f53\u4e8e\u524d\u6587\u63d0\u5230\u7684ODE\u53f3\u8fb9\u53ea\u6709\u7b2c\u4e8c\u9879\uff0c\u6c42\u89e3\u8fd9\u4e2a\u5e38\u5fae\u5206\u65b9\u7a0b\u3002 \u7b2c\u516b\u884c\uff1a \\hat{L}\\left(\\boldsymbol{p}, \\hat{t}_{k+1}^{p}\\right)=\\hat{L}\\left(\\boldsymbol{p},\\left(\\hat{t}_{k+1}^{p}\\right)^{-}\\right)+\\sigma_{k+1}^{\\boldsymbol{p}} c \u662f\u5c06\u51b2\u6fc0\u503c\u76f4\u63a5\u52a0\u5230\u5bf9\u5e94\u7684\u5750\u6807\u4e2d \u7b2c\u5341\u884c\uff0c\u6ce8\u610f\u4e0d\u76f4\u63a5\u6539\u53d8\u8f93\u51fa\u7684 \\hat L \uff0c\u4f46\u662f\u4f1a\u6539\u53d8\u540e\u9762\u5faa\u73af\u7684\u7b2c13\u884c \u7b2c\u5341\u4e00\u884c\uff0c\u63cf\u8ff0\u7684\u662f\u6839\u636e\u8fc7\u66dd\u5149\u6216\u8005\u4f4e\u66dd\u5149\u7684\u53ef\u80fd(\u6bcf\u4e2a\u5750\u6807\u70b9\u6709\u5bf9\u5e94\u7684 \\alpha_p \u503c,\u4e0e\u5f53\u524d\u76f8\u673a\u5bf9\u5e94\u5750\u6807\u7684\u5149\u5f3a L^F \u6709\u5173).\u76f4\u89c9\u4e0a\u6765\u8bf4 \\alpha \u8d8a\u5c0f\uff0c\u8d8a\u4fe1\u4efbevent camera,\u5728\u5149\u5f3a\u63a5\u8fd1\u6700\u5927\u6700\u5c0f\u503c\u7684\u65f6\u5019\u4fe1\u4efbevent camera,\u5149\u5f3a\u4e2d\u95f4\u503c\u7684\u65f6\u5019\u76f8\u5bf9\u66f4\u4fe1\u4efb\u57fa\u7840\u76f8\u673a\uff0c\u5176\u516c\u5f0f\u5982\u4e0b: \\alpha(\\boldsymbol{p}, t)=\\left\\{\\begin{array}{ll}{\\lambda \\alpha_{1}+(1-\\lambda) \\alpha_{1} \\frac{\\left(L^{F}(\\boldsymbol{p}, t)-L_{\\min }\\right)}{\\left(L_{1}-L_{\\min }\\right)}} & {L_{\\min } \\leq L^{F}(\\boldsymbol{p}, t)<L_{1}} \\\\ {\\alpha_{1}} & {L_{1} \\leq L^{F}(\\boldsymbol{p}, t) \\leq L_{2}} \\\\ {\\lambda \\alpha_{1}+(1-\\lambda) \\alpha_{1} \\frac{\\left(L^{F}(\\boldsymbol{p}, t)-L_{\\max }\\right)}{\\left(L_{2}-L_{\\max }\\right)}} & {L_{2}<L^{F}(\\boldsymbol{p}, t) \\leq L_{\\max }}\\end{array}\\right. \u672c\u6587 \\alpha_1 = 2 \\pi, \\lambda=0.1 [L_1, L_2] = [L_{min} +k, L_{max} -k], k = 0.05*(L_{max}-L_{min})","title":"\u4e92\u8865\u6ee4\u6ce2\u5668"},{"location":"other_categories/others/Continuous-time_Intensity_Estimation_Using_Event_Cameras/#owen-liu","text":"\u4e0a\u534a\u56fe\u4e3a\u539f\u56fe\uff0c\u4e0b\u534a\u56fe\u4e3a\u589e\u5f3a\u540e\u7684\u56fe.","title":"\u5728\u672c\u4eba(Owen Liu)\u7535\u8111\u91cc\u9762\u8fd0\u884c\u5f97\u5230\u7684\u7ed3\u679c"},{"location":"other_categories/others/FADNet/","text":"FADNet: A Fast and Accurate Network for Disparity Estimation \u8fd9\u7bc7paper\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u5b9e\u65f6\u7684\u5feb\u901f\u7684disparity estimation\u7f51\u7edc\uff0c\u4e0e PSMNet \u5bf9\u6bd4\uff0c\u663e\u5b58\u6d88\u8017\u663e\u8457\u51cf\u5c0f\uff0c\u540c\u65f6\u4e00\u5e27\u53cc\u76ee\u901f\u5ea6\u8fbe\u523018.7ms\uff0c\u7565\u5fae\u60ca\u4eba\u3002 architecture \u6a21\u4eff\u4e86DispNet\u7684\u7ed3\u6784\uff0cdispnet\u5219\u57fa\u4e8e FlowNet .\u5176\u4e2d\u4f7f\u7528\u4e86correlation \u5c42\uff0c\u5bf9\u53f3\u56fe\u6c34\u5e73\u65b9\u5411\u4e0a\u5e73\u79fbD\u4e2a\u4f4d\u7f6e\uff0c\u4ee5\u6bcf\u4e00\u4e2a\u5de6\u53f3\u56fe\u5bf9\u5e94\u50cf\u7d20\u4e3a\u4e2d\u5fc3\u9644\u8fd1patch\u5404\u81ea\u6c42\u70b9\u4e58\u7684\u7d2f\u52a0 c\\left(\\mathbf{x}_{1}, \\mathbf{x}_{2}\\right)=\\sum_{\\mathbf{o} \\in[-k, k] \\times[-k, k]}\\left\\langle\\mathbf{f}_{1}\\left(\\mathbf{x}_{1}+\\mathbf{o}\\right), \\mathbf{f}_{2}\\left(\\mathbf{x}_{2}+\\mathbf{o}\\right)\\right\\rangle \u4f5c\u8005\u6307\u51fa\u8fd9\u91cc\u6697\u793a\u4e86\u4e00\u4e2apatch\u91cc\u9762\u4e0d\u540c\u4f4d\u7f6e\u7684\u6743\u91cd\u4e00\u81f4\uff0c\u800c\u8fd9\u5e76\u4e0d\u4e00\u5b9a\u6b63\u786e\uff0c\u56e0\u800c\u9009\u62e9\u5148\u5206\u522b\u505a\u4e00\u4e2a 3\\times3 \u7684\u5377\u79ef\u518d\u8fd0\u884c\u70b9\u4e58 c\\left(\\mathbf{x}_{1}, \\mathbf{x}_{2}\\right)=\\sum\\left\\langle\\mathbf{f}_{1}\\left(\\mathbf{x}_{1}\\right), \\mathbf{f}_{2}\\left(\\mathbf{x}_{2}\\right)\\right\\rangle def build_corr ( img_left , img_right , max_disp = 40 ): B , C , H , W = img_left . shape volume = img_left . new_zeros ([ B , max_disp , H , W ]) for i in range ( max_disp ): if i > 0 : volume [:, i , :, i :] = ( img_left [:, :, :, i :] * img_right [:, :, :, : - i ]) . mean ( dim = 1 ) else : volume [:, i , :, :] = ( img_left [:, :, :, :] * img_right [:, :, :, :]) . mean ( dim = 1 ) volume = volume . contiguous () return volume \u7b2c\u4e8c\u90e8\u5206\u91c7\u7528\u7684\u662f\u4e0e FlowNetV2 \u4e00\u81f4\u7684\u601d\u8def\uff0c\u5c06\u53f3\u56fe\u91cd\u91c7\u6837\u5230\u5de6\u56fe. inputs_net2 = torch . cat (( inputs , resampled_img1 , dispnetc_final_flow , norm_diff_img0 ), dim = 1 )","title":"FADNet: A Fast and Accurate Network for Disparity Estimation"},{"location":"other_categories/others/FADNet/#fadnet-a-fast-and-accurate-network-for-disparity-estimation","text":"\u8fd9\u7bc7paper\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u5b9e\u65f6\u7684\u5feb\u901f\u7684disparity estimation\u7f51\u7edc\uff0c\u4e0e PSMNet \u5bf9\u6bd4\uff0c\u663e\u5b58\u6d88\u8017\u663e\u8457\u51cf\u5c0f\uff0c\u540c\u65f6\u4e00\u5e27\u53cc\u76ee\u901f\u5ea6\u8fbe\u523018.7ms\uff0c\u7565\u5fae\u60ca\u4eba\u3002","title":"FADNet: A Fast and Accurate Network for Disparity Estimation"},{"location":"other_categories/others/FADNet/#architecture","text":"\u6a21\u4eff\u4e86DispNet\u7684\u7ed3\u6784\uff0cdispnet\u5219\u57fa\u4e8e FlowNet .\u5176\u4e2d\u4f7f\u7528\u4e86correlation \u5c42\uff0c\u5bf9\u53f3\u56fe\u6c34\u5e73\u65b9\u5411\u4e0a\u5e73\u79fbD\u4e2a\u4f4d\u7f6e\uff0c\u4ee5\u6bcf\u4e00\u4e2a\u5de6\u53f3\u56fe\u5bf9\u5e94\u50cf\u7d20\u4e3a\u4e2d\u5fc3\u9644\u8fd1patch\u5404\u81ea\u6c42\u70b9\u4e58\u7684\u7d2f\u52a0 c\\left(\\mathbf{x}_{1}, \\mathbf{x}_{2}\\right)=\\sum_{\\mathbf{o} \\in[-k, k] \\times[-k, k]}\\left\\langle\\mathbf{f}_{1}\\left(\\mathbf{x}_{1}+\\mathbf{o}\\right), \\mathbf{f}_{2}\\left(\\mathbf{x}_{2}+\\mathbf{o}\\right)\\right\\rangle \u4f5c\u8005\u6307\u51fa\u8fd9\u91cc\u6697\u793a\u4e86\u4e00\u4e2apatch\u91cc\u9762\u4e0d\u540c\u4f4d\u7f6e\u7684\u6743\u91cd\u4e00\u81f4\uff0c\u800c\u8fd9\u5e76\u4e0d\u4e00\u5b9a\u6b63\u786e\uff0c\u56e0\u800c\u9009\u62e9\u5148\u5206\u522b\u505a\u4e00\u4e2a 3\\times3 \u7684\u5377\u79ef\u518d\u8fd0\u884c\u70b9\u4e58 c\\left(\\mathbf{x}_{1}, \\mathbf{x}_{2}\\right)=\\sum\\left\\langle\\mathbf{f}_{1}\\left(\\mathbf{x}_{1}\\right), \\mathbf{f}_{2}\\left(\\mathbf{x}_{2}\\right)\\right\\rangle def build_corr ( img_left , img_right , max_disp = 40 ): B , C , H , W = img_left . shape volume = img_left . new_zeros ([ B , max_disp , H , W ]) for i in range ( max_disp ): if i > 0 : volume [:, i , :, i :] = ( img_left [:, :, :, i :] * img_right [:, :, :, : - i ]) . mean ( dim = 1 ) else : volume [:, i , :, :] = ( img_left [:, :, :, :] * img_right [:, :, :, :]) . mean ( dim = 1 ) volume = volume . contiguous () return volume \u7b2c\u4e8c\u90e8\u5206\u91c7\u7528\u7684\u662f\u4e0e FlowNetV2 \u4e00\u81f4\u7684\u601d\u8def\uff0c\u5c06\u53f3\u56fe\u91cd\u91c7\u6837\u5230\u5de6\u56fe. inputs_net2 = torch . cat (( inputs , resampled_img1 , dispnetc_final_flow , norm_diff_img0 ), dim = 1 )","title":"architecture"},{"location":"other_categories/others/Gated2Depth:_Real-Time_Dense_Lidar_From_Gated_Images/","text":"Gated2Depth: Real-Time Dense Lidar From Gated Images \u8fd9\u7bc7\u8bba\u6587\u4f7f\u7528Gated Image\u4f30\u8ba1\u7a20\u5bc6\u7684\u6df1\u5ea6\u56fe\u3002\u4eae\u70b9\u6709\u51e0\u4e2a\uff0c\u9996\u5148\u662f\u5bf9Gate Imaging\u7684\u539f\u7406\u8ba4\u8bc6\u4ee5\u53ca\u4f7f\u7528\uff0c\u5176\u6b21\u662f\u5176\u7528\u7a00\u758f\u70b9\u4e91\u4f5c\u4e3a\u76d1\u7763\u6765\u6e90\uff0c\u8fdb\u884c\u534a\u76d1\u7763\u7684\u5b66\u4e60. Gated Imaging\u57fa\u672c\u539f\u7406 Gated camera\u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u4e3b\u52a8\u7684TOF\u76f8\u673a\uff0c\u4e0e\u6fc0\u5149\u6e90\u65f6\u95f4\u540c\u6b65\uff0c\u7cfb\u7edf\u53ef\u4ee5\u63a7\u5236\u76f8\u673a\u7684\u5feb\u95e8\u63a5\u53d7\u5149\u7167\u7684\u65f6\u95f4\uff0c\u5982\u4e0a\u56fe\uff0c\u6bcf\u4e00\u5f20\u56fe\u91cc\u9762\u53ea\u4f1a\u663e\u793a\u4e00\u4e2a\u8ddd\u79bb\u533a\u95f4\u5185\u7684\u7269\u4f53\uff0c\u800c\u6bcf\u4e00\u5f20\u56fe\u4e2d\u6bcf\u4e00\u4e2a\u50cf\u7d20\u7684\u6570\u503c\u4ee3\u8868\u5bf9\u5e94\u50cf\u7d20\u7684\u53cd\u5c04\u7684\u6fc0\u5149\u5f3a\u5ea6\u3002 \u66f4\u591a\u4fe1\u606f\u53ef\u4ee5\u770b NIT\u7684\u4ea7\u54c1pdf \u4ee5\u53ca wiki\u9875\u9762 Depth Learning Pipeline \u8f93\u5165\u5230\u7f51\u7edc\u7684\u8f93\u5165\u662f3\u5c42\u7684\u539f\u59cbgated image.\u4f7f\u7528\u751f\u6210\u7f51\u7edc G \u8f93\u51fa\u591a\u5c3a\u5bf8\u7684\u6df1\u5ea6\u4f30\u8ba1\u56fe\uff0c\u7ed3\u6784\u91c7\u7528\u7684\u662f\u7ecf\u5178\u7684 Unet(pdf) \uff0c\u6709\u4e09\u4e2aloss\u51fd\u6570\u3002\u5176\u4e2d\u7b2c\u4e00\u4e2a\u635f\u5931\u662f \\mathcal{L}_{mult} \u662f\u7a00\u758f\u7684\uff0c\u7528\u7a00\u758f\u7684\u6fc0\u5149\u96f7\u8fbe\u70b9\u4e91\u56fe\u8fdb\u884c\u76d1\u7763\u3002\u540e\u4e24\u4e2aloss\u5728\u540e\u6587\u63cf\u8ff0 \u56fe\u4e2d\u6709\u4e00\u4e2a\u5206\u7c7b\u5668D,\u7c7b\u4f3c\u4e8ePathchGAN. \u5728\u7b2c\u4e00\u4e2a\u8bad\u7ec3\u9636\u6bb5\uff0c\u672c\u6587\u7528\u4eff\u771f\u5408\u6210\u7684\u6570\u636e\u7528\u7c7b\u4f3cLeast-square GAN\u7684\u65b9\u5f0f\uff0c\u8ba9\u8fd9\u4e2a\u5206\u7c7b\u5668\u7f51\u7edc\u5224\u65ad\u4e00\u5f20\u6df1\u5ea6\u56fe\u662f\u6765\u81ea\u4e8e\u5408\u6210\u7684\u6b63\u786e\u56fe\u8fd8\u662f\u6765\u81ea\u4e8eGenerator\u7684\u8f93\u51fa\u3002 \u7b2c\u4e8c\u4e2a\u9636\u6bb5\uff0c\u672c\u6587\u7528\u771f\u5b9egated image,\u7136\u540e\u4fdd\u6301\u5206\u7c7b\u5668\u56fa\u5b9a\uff0c\u540c\u65f6\u7528\u6fc0\u5149\u96f7\u8fbe\u70b9\u4e91\u8fdb\u884c\u76d1\u7763\u8bad\u7ec3, \u635f\u5931\u51fd\u6570 \\mathcal{L} = \\mathcal{L}_{mult} + \\lambda_s \\mathcal{L}_{smooth} + \\lambda_a \\mathcal{L}_{adv} \u76f4\u63a5\u76d1\u7763 \\mathcal{L}_{\\mathrm{mult}}(d, \\tilde{d})=\\sum_{i=1}^{M} \\lambda_{m_{i}} \\mathcal{L}_{\\mathrm{Ll}}\\left(d^{(i)}, \\tilde{d}^{(i)}\\right) \u5176\u4e2d d^{(i)} \u8fd8\u6709 \\tilde{d}^{(i)} \u6307\u4ee3\u5728 scale (i), \\mathcal{L}_{L1} \u6307\u5728\u5bf9\u5e94\u5c3a\u5ea6\u4e0a\u7684\u635f\u5931\u3002\u6bcf\u4e00\u4e2a\u5c3a\u5ea6\u90fd\u662f\u4f7f\u7528 L_1 \u635f\u5931 \u5728\u4f7f\u7528\u5408\u6210\u8bad\u7ec3\u96c6\u8bad\u7ec3\u65f6\uff0c\u6240\u6709\u50cf\u7d20\u90fd\u6709\u5bf9\u5e94\u7684\u8bef\u5dee\u503c\u3002\u5728\u4f7f\u7528\u5b9e\u9645\u7684\u635f\u5931\u51fd\u6570\u65f6\uff0c\u53ea\u6709\u90e8\u5206\u50cf\u7d20\u6709\u76d1\u7763\uff0c\u5982\u4e0b \\mathcal{L}_{\\mathrm{LI}}\\left(d^{(i)}, \\tilde{d}^{(i)}\\right)=\\frac{1}{N} \\sum_{j, k}\\left|d_{j k}^{(i)}-\\tilde{d}_{j k}^{(i)}\\right| m_{j k}^{(i)} \u5149\u6ed1\u635f\u5931 \\mathcal{L}_{\\text {smooth }}=\\frac{1}{N} \\sum_{i, j}\\left|\\partial_{x} d_{i, j}\\right| \\epsilon^{-\\left|\\partial_{x} z_{i, j}\\right|}+\\left|\\partial_{y} d_{i, j}\\right| \\epsilon^{-\\left|\\partial_{y} z_{i, j}\\right|} \u5176\u4e2d z \u4e3a\u8f93\u5165\u56fe\u7247\u7684\u5f3a\u5ea6\u503c\uff0c d \u662f\u6df1\u5ea6\u503c\uff0c \u5bf9\u6297\u635f\u5931 \\begin{aligned} \\mathcal{L}_{\\mathrm{adv}}=& \\frac{1}{2} \\mathbb{E}_{y \\sim p_{\\mathrm{depth}}(y)}\\left[(D(y)-1)^{2}\\right]+\\\\ & \\frac{1}{2} \\mathbb{E}_{x \\sim p_{\\mathrm{gated}}(x)}\\left[(D(G(x)))^{2}\\right] \\end{aligned}","title":"Gated2Depth: Real-Time Dense Lidar From Gated Images"},{"location":"other_categories/others/Gated2Depth:_Real-Time_Dense_Lidar_From_Gated_Images/#gated2depth-real-time-dense-lidar-from-gated-images","text":"\u8fd9\u7bc7\u8bba\u6587\u4f7f\u7528Gated Image\u4f30\u8ba1\u7a20\u5bc6\u7684\u6df1\u5ea6\u56fe\u3002\u4eae\u70b9\u6709\u51e0\u4e2a\uff0c\u9996\u5148\u662f\u5bf9Gate Imaging\u7684\u539f\u7406\u8ba4\u8bc6\u4ee5\u53ca\u4f7f\u7528\uff0c\u5176\u6b21\u662f\u5176\u7528\u7a00\u758f\u70b9\u4e91\u4f5c\u4e3a\u76d1\u7763\u6765\u6e90\uff0c\u8fdb\u884c\u534a\u76d1\u7763\u7684\u5b66\u4e60.","title":"Gated2Depth: Real-Time Dense Lidar From Gated Images"},{"location":"other_categories/others/Gated2Depth:_Real-Time_Dense_Lidar_From_Gated_Images/#gated-imaging","text":"Gated camera\u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u4e3b\u52a8\u7684TOF\u76f8\u673a\uff0c\u4e0e\u6fc0\u5149\u6e90\u65f6\u95f4\u540c\u6b65\uff0c\u7cfb\u7edf\u53ef\u4ee5\u63a7\u5236\u76f8\u673a\u7684\u5feb\u95e8\u63a5\u53d7\u5149\u7167\u7684\u65f6\u95f4\uff0c\u5982\u4e0a\u56fe\uff0c\u6bcf\u4e00\u5f20\u56fe\u91cc\u9762\u53ea\u4f1a\u663e\u793a\u4e00\u4e2a\u8ddd\u79bb\u533a\u95f4\u5185\u7684\u7269\u4f53\uff0c\u800c\u6bcf\u4e00\u5f20\u56fe\u4e2d\u6bcf\u4e00\u4e2a\u50cf\u7d20\u7684\u6570\u503c\u4ee3\u8868\u5bf9\u5e94\u50cf\u7d20\u7684\u53cd\u5c04\u7684\u6fc0\u5149\u5f3a\u5ea6\u3002 \u66f4\u591a\u4fe1\u606f\u53ef\u4ee5\u770b NIT\u7684\u4ea7\u54c1pdf \u4ee5\u53ca wiki\u9875\u9762","title":"Gated Imaging\u57fa\u672c\u539f\u7406"},{"location":"other_categories/others/Gated2Depth:_Real-Time_Dense_Lidar_From_Gated_Images/#depth-learning-pipeline","text":"\u8f93\u5165\u5230\u7f51\u7edc\u7684\u8f93\u5165\u662f3\u5c42\u7684\u539f\u59cbgated image.\u4f7f\u7528\u751f\u6210\u7f51\u7edc G \u8f93\u51fa\u591a\u5c3a\u5bf8\u7684\u6df1\u5ea6\u4f30\u8ba1\u56fe\uff0c\u7ed3\u6784\u91c7\u7528\u7684\u662f\u7ecf\u5178\u7684 Unet(pdf) \uff0c\u6709\u4e09\u4e2aloss\u51fd\u6570\u3002\u5176\u4e2d\u7b2c\u4e00\u4e2a\u635f\u5931\u662f \\mathcal{L}_{mult} \u662f\u7a00\u758f\u7684\uff0c\u7528\u7a00\u758f\u7684\u6fc0\u5149\u96f7\u8fbe\u70b9\u4e91\u56fe\u8fdb\u884c\u76d1\u7763\u3002\u540e\u4e24\u4e2aloss\u5728\u540e\u6587\u63cf\u8ff0 \u56fe\u4e2d\u6709\u4e00\u4e2a\u5206\u7c7b\u5668D,\u7c7b\u4f3c\u4e8ePathchGAN. \u5728\u7b2c\u4e00\u4e2a\u8bad\u7ec3\u9636\u6bb5\uff0c\u672c\u6587\u7528\u4eff\u771f\u5408\u6210\u7684\u6570\u636e\u7528\u7c7b\u4f3cLeast-square GAN\u7684\u65b9\u5f0f\uff0c\u8ba9\u8fd9\u4e2a\u5206\u7c7b\u5668\u7f51\u7edc\u5224\u65ad\u4e00\u5f20\u6df1\u5ea6\u56fe\u662f\u6765\u81ea\u4e8e\u5408\u6210\u7684\u6b63\u786e\u56fe\u8fd8\u662f\u6765\u81ea\u4e8eGenerator\u7684\u8f93\u51fa\u3002 \u7b2c\u4e8c\u4e2a\u9636\u6bb5\uff0c\u672c\u6587\u7528\u771f\u5b9egated image,\u7136\u540e\u4fdd\u6301\u5206\u7c7b\u5668\u56fa\u5b9a\uff0c\u540c\u65f6\u7528\u6fc0\u5149\u96f7\u8fbe\u70b9\u4e91\u8fdb\u884c\u76d1\u7763\u8bad\u7ec3,","title":"Depth Learning Pipeline"},{"location":"other_categories/others/Gated2Depth:_Real-Time_Dense_Lidar_From_Gated_Images/#_1","text":"\\mathcal{L} = \\mathcal{L}_{mult} + \\lambda_s \\mathcal{L}_{smooth} + \\lambda_a \\mathcal{L}_{adv}","title":"\u635f\u5931\u51fd\u6570"},{"location":"other_categories/others/Gated2Depth:_Real-Time_Dense_Lidar_From_Gated_Images/#_2","text":"\\mathcal{L}_{\\mathrm{mult}}(d, \\tilde{d})=\\sum_{i=1}^{M} \\lambda_{m_{i}} \\mathcal{L}_{\\mathrm{Ll}}\\left(d^{(i)}, \\tilde{d}^{(i)}\\right) \u5176\u4e2d d^{(i)} \u8fd8\u6709 \\tilde{d}^{(i)} \u6307\u4ee3\u5728 scale (i), \\mathcal{L}_{L1} \u6307\u5728\u5bf9\u5e94\u5c3a\u5ea6\u4e0a\u7684\u635f\u5931\u3002\u6bcf\u4e00\u4e2a\u5c3a\u5ea6\u90fd\u662f\u4f7f\u7528 L_1 \u635f\u5931 \u5728\u4f7f\u7528\u5408\u6210\u8bad\u7ec3\u96c6\u8bad\u7ec3\u65f6\uff0c\u6240\u6709\u50cf\u7d20\u90fd\u6709\u5bf9\u5e94\u7684\u8bef\u5dee\u503c\u3002\u5728\u4f7f\u7528\u5b9e\u9645\u7684\u635f\u5931\u51fd\u6570\u65f6\uff0c\u53ea\u6709\u90e8\u5206\u50cf\u7d20\u6709\u76d1\u7763\uff0c\u5982\u4e0b \\mathcal{L}_{\\mathrm{LI}}\\left(d^{(i)}, \\tilde{d}^{(i)}\\right)=\\frac{1}{N} \\sum_{j, k}\\left|d_{j k}^{(i)}-\\tilde{d}_{j k}^{(i)}\\right| m_{j k}^{(i)}","title":"\u76f4\u63a5\u76d1\u7763"},{"location":"other_categories/others/Gated2Depth:_Real-Time_Dense_Lidar_From_Gated_Images/#_3","text":"\\mathcal{L}_{\\text {smooth }}=\\frac{1}{N} \\sum_{i, j}\\left|\\partial_{x} d_{i, j}\\right| \\epsilon^{-\\left|\\partial_{x} z_{i, j}\\right|}+\\left|\\partial_{y} d_{i, j}\\right| \\epsilon^{-\\left|\\partial_{y} z_{i, j}\\right|} \u5176\u4e2d z \u4e3a\u8f93\u5165\u56fe\u7247\u7684\u5f3a\u5ea6\u503c\uff0c d \u662f\u6df1\u5ea6\u503c\uff0c","title":"\u5149\u6ed1\u635f\u5931"},{"location":"other_categories/others/Gated2Depth:_Real-Time_Dense_Lidar_From_Gated_Images/#_4","text":"\\begin{aligned} \\mathcal{L}_{\\mathrm{adv}}=& \\frac{1}{2} \\mathbb{E}_{y \\sim p_{\\mathrm{depth}}(y)}\\left[(D(y)-1)^{2}\\right]+\\\\ & \\frac{1}{2} \\mathbb{E}_{x \\sim p_{\\mathrm{gated}}(x)}\\left[(D(G(x)))^{2}\\right] \\end{aligned}","title":"\u5bf9\u6297\u635f\u5931"},{"location":"other_categories/others/In_Defense_of_Classical_Image_Processing_Fast_Depth_Completion_on_the_CPU/","text":"In Defense of Classical Image Processing: Fast Depth Completion on the CPU \u8fd9\u7bc7\u6587\u7ae0\u89e3\u51b3\u7684\u95ee\u9898\u662f\u4eceCPU\u5b9e\u73b0\u6df1\u5ea6\u8865\u5168\uff0c\u8fd9\u7bc7\u662fAVOD(\u6682\u672a\u6709\u7b80\u4ecb)\u4ee5\u53ca Syn-Multi-view \u7684\u524d\u7f6e. \u5e76\u4e0d\u662f\u6700\u597d\u7684\u7b97\u6cd5\uff0c\u4e0d\u8fc7\u662f\u4e00\u4e2a\u4ee3\u7801\u4f7f\u7528\u96be\u5ea6\u4e0d\u9ad8(\u57fa\u672c\u53ea\u6709\u57fa\u672c\u7684numpy \u4e0e opencv\u8fd0\u7b97)\uff0c\u901f\u5ea6\u5feb(90HZ)\u4e14\u7cbe\u786e\u5ea6\u5c1a\u53ef\u7684\u7b97\u6cd5.\u66f4\u5173\u952e\u662f\u5b8c\u5168\u6ca1\u6709\u4f7f\u7528\u56fe\u50cf\u6570\u636e \u603b\u4f53\u6d41\u7a0b \u6b64\u56fe\u603b\u89c8\u4e86\u6574\u4e2a\u7b97\u6cd5\u7684\u5b8c\u6574\u6d41\u7a0b\uff0c\u4e0b\u9762\u4ece\u95ee\u9898\u7684\u6570\u5b66\u5b9a\u4e49\u4ee5\u53ca\u7b97\u6cd5\u6b65\u9aa4\u8fdb\u884c\u4ecb\u7ecd\u3002 \u95ee\u9898\u6570\u5b66\u5b9a\u4e49 \u5bf9\u4e8e\u4e00\u5f20\u56fe\u7247 I ,\u4e00\u4e2a\u7a00\u758f\u7684\u6df1\u5ea6\u56fe D_{sparse} ,\u627e\u5230\u4e00\u4e2a \\hat f , \u5176\u4e2d f(I,D_{sparse}) = D_{dense} ,\u95ee\u9898\u53ef\u4ee5\u63cf\u8ff0\u4e3a: \\min .\\left\\|\\hat{f}\\left(I, D_{s p a r s e}\\right)-f\\left(I, D_{s p a r s e}\\right)\\right\\|_{F}^{2}=0 \u6d41\u7a0b\u4ecb\u7ecd Depth Inversion \u4ece\u6570\u636e\u7279\u6027\u4e0a\uff0ckitti\u4e2d\u7684\u70b9\u7684\u8ddd\u79bb\u4ece0\u523080m\uff0c\u4e0d\u8fc7\uff0c\u7a7a\u50cf\u7d20\u540c\u6837\u4e3a0\uff0c\u8fd9\u4e0d\u5229\u4e8e\u57fa\u7840OpenCV\u7684\u8ba1\u7b97\u3002\u56e0\u6b64\u8fdb\u884c\u4e00\u4e2a\u64cd\u4f5c\uff0c\u5bf9\u975e\u7a7a\u50cf\u7d20\u8ba1\u7b97 D_{inverted} = 100.0 - D_{input} \uff0c\u4f1a\u5f62\u621020m\u7684\u7f13\u51b2\u533a\u3002\u65b9\u4fbf\u5f62\u6210\u4e00\u4e2avalid or not \u7684mask. \u81ea\u5b9a\u4e49Dilation \u9996\u5148\u5c1d\u8bd5\u8ba9\u7a7a\u50cf\u7d20\u88ab\u9644\u8fd1\u7684\u6709\u6548\u50cf\u7d20\u8986\u76d6(dilation),\u6700\u7ec8\u91c7\u7528\u7684\u662fdiamand kernel \u5c0f\u6d1e\u586b\u8865 \u5148\u8ba1\u7b97\u4e00\u4e2anon-empty mask,\u4f7f\u7528 7\\times 7 full \u6838\u8fdb\u884cdilation,non-empth\u7684\u70b9\u4e0d\u6539\u53d8\u3002 Extension \u4e3a\u4e86\u8865\u5145\u6bd4\u8f83\u9ad8\u7684\u7269\u4f53\uff0c\u6bd4\u5982\u6811\u548c\u5929\u7a7a\uff0c\u5c06\u6bcf\u5217\u6700\u9ad8\u7684\u6709\u6548\u70b9\u76f4\u63a5\u8fde\u63a5\u5230\u6700\u5916\u90e8\u3002 \u5927\u6d1e\u8865\u5145 \u6700\u540e\u4e00\u6b65\u586b\u8865\u524d\u6587\u5b8c\u5168\u6ca1\u6709\u8865\u5145\u7684\u70b9,\u7531\u4e8e\u6ca1\u6709\u56fe\u7247\u6570\u636e\uff0c\u4f7f\u7528\u4e00\u4e2a 31 \\times 31 \u7684\u6838\uff0c\u5bfb\u627e\u6700\u9760\u8fd1\u7684\u672a\u586b\u8865\u70b9\u3002 Blur \u8fde\u7eed\u4f7f\u7528\u4e00\u4e2a 5\\times 5 \u4e2d\u4f4d\u6570\u6a21\u7cca,\u4ee5\u53ca\u4e00\u4e2a 5\\times 5 \u9ad8\u65af\u6a21\u7cca\u3002 Depth Inversion \u5c06\u7b2c\u4e00\u6b65\u7684\u6df1\u5ea6\u8f6c\u56de\u6765\u3002","title":"In Defense of Classical Image Processing: Fast Depth Completion on the CPU"},{"location":"other_categories/others/In_Defense_of_Classical_Image_Processing_Fast_Depth_Completion_on_the_CPU/#in-defense-of-classical-image-processing-fast-depth-completion-on-the-cpu","text":"\u8fd9\u7bc7\u6587\u7ae0\u89e3\u51b3\u7684\u95ee\u9898\u662f\u4eceCPU\u5b9e\u73b0\u6df1\u5ea6\u8865\u5168\uff0c\u8fd9\u7bc7\u662fAVOD(\u6682\u672a\u6709\u7b80\u4ecb)\u4ee5\u53ca Syn-Multi-view \u7684\u524d\u7f6e. \u5e76\u4e0d\u662f\u6700\u597d\u7684\u7b97\u6cd5\uff0c\u4e0d\u8fc7\u662f\u4e00\u4e2a\u4ee3\u7801\u4f7f\u7528\u96be\u5ea6\u4e0d\u9ad8(\u57fa\u672c\u53ea\u6709\u57fa\u672c\u7684numpy \u4e0e opencv\u8fd0\u7b97)\uff0c\u901f\u5ea6\u5feb(90HZ)\u4e14\u7cbe\u786e\u5ea6\u5c1a\u53ef\u7684\u7b97\u6cd5.\u66f4\u5173\u952e\u662f\u5b8c\u5168\u6ca1\u6709\u4f7f\u7528\u56fe\u50cf\u6570\u636e","title":"In Defense of Classical Image Processing: Fast Depth Completion on the CPU"},{"location":"other_categories/others/In_Defense_of_Classical_Image_Processing_Fast_Depth_Completion_on_the_CPU/#_1","text":"\u6b64\u56fe\u603b\u89c8\u4e86\u6574\u4e2a\u7b97\u6cd5\u7684\u5b8c\u6574\u6d41\u7a0b\uff0c\u4e0b\u9762\u4ece\u95ee\u9898\u7684\u6570\u5b66\u5b9a\u4e49\u4ee5\u53ca\u7b97\u6cd5\u6b65\u9aa4\u8fdb\u884c\u4ecb\u7ecd\u3002","title":"\u603b\u4f53\u6d41\u7a0b"},{"location":"other_categories/others/In_Defense_of_Classical_Image_Processing_Fast_Depth_Completion_on_the_CPU/#_2","text":"\u5bf9\u4e8e\u4e00\u5f20\u56fe\u7247 I ,\u4e00\u4e2a\u7a00\u758f\u7684\u6df1\u5ea6\u56fe D_{sparse} ,\u627e\u5230\u4e00\u4e2a \\hat f , \u5176\u4e2d f(I,D_{sparse}) = D_{dense} ,\u95ee\u9898\u53ef\u4ee5\u63cf\u8ff0\u4e3a: \\min .\\left\\|\\hat{f}\\left(I, D_{s p a r s e}\\right)-f\\left(I, D_{s p a r s e}\\right)\\right\\|_{F}^{2}=0","title":"\u95ee\u9898\u6570\u5b66\u5b9a\u4e49"},{"location":"other_categories/others/In_Defense_of_Classical_Image_Processing_Fast_Depth_Completion_on_the_CPU/#_3","text":"","title":"\u6d41\u7a0b\u4ecb\u7ecd"},{"location":"other_categories/others/In_Defense_of_Classical_Image_Processing_Fast_Depth_Completion_on_the_CPU/#depth-inversion","text":"\u4ece\u6570\u636e\u7279\u6027\u4e0a\uff0ckitti\u4e2d\u7684\u70b9\u7684\u8ddd\u79bb\u4ece0\u523080m\uff0c\u4e0d\u8fc7\uff0c\u7a7a\u50cf\u7d20\u540c\u6837\u4e3a0\uff0c\u8fd9\u4e0d\u5229\u4e8e\u57fa\u7840OpenCV\u7684\u8ba1\u7b97\u3002\u56e0\u6b64\u8fdb\u884c\u4e00\u4e2a\u64cd\u4f5c\uff0c\u5bf9\u975e\u7a7a\u50cf\u7d20\u8ba1\u7b97 D_{inverted} = 100.0 - D_{input} \uff0c\u4f1a\u5f62\u621020m\u7684\u7f13\u51b2\u533a\u3002\u65b9\u4fbf\u5f62\u6210\u4e00\u4e2avalid or not \u7684mask.","title":"Depth Inversion"},{"location":"other_categories/others/In_Defense_of_Classical_Image_Processing_Fast_Depth_Completion_on_the_CPU/#dilation","text":"\u9996\u5148\u5c1d\u8bd5\u8ba9\u7a7a\u50cf\u7d20\u88ab\u9644\u8fd1\u7684\u6709\u6548\u50cf\u7d20\u8986\u76d6(dilation),\u6700\u7ec8\u91c7\u7528\u7684\u662fdiamand kernel","title":"\u81ea\u5b9a\u4e49Dilation"},{"location":"other_categories/others/In_Defense_of_Classical_Image_Processing_Fast_Depth_Completion_on_the_CPU/#_4","text":"\u5148\u8ba1\u7b97\u4e00\u4e2anon-empty mask,\u4f7f\u7528 7\\times 7 full \u6838\u8fdb\u884cdilation,non-empth\u7684\u70b9\u4e0d\u6539\u53d8\u3002","title":"\u5c0f\u6d1e\u586b\u8865"},{"location":"other_categories/others/In_Defense_of_Classical_Image_Processing_Fast_Depth_Completion_on_the_CPU/#extension","text":"\u4e3a\u4e86\u8865\u5145\u6bd4\u8f83\u9ad8\u7684\u7269\u4f53\uff0c\u6bd4\u5982\u6811\u548c\u5929\u7a7a\uff0c\u5c06\u6bcf\u5217\u6700\u9ad8\u7684\u6709\u6548\u70b9\u76f4\u63a5\u8fde\u63a5\u5230\u6700\u5916\u90e8\u3002","title":"Extension"},{"location":"other_categories/others/In_Defense_of_Classical_Image_Processing_Fast_Depth_Completion_on_the_CPU/#_5","text":"\u6700\u540e\u4e00\u6b65\u586b\u8865\u524d\u6587\u5b8c\u5168\u6ca1\u6709\u8865\u5145\u7684\u70b9,\u7531\u4e8e\u6ca1\u6709\u56fe\u7247\u6570\u636e\uff0c\u4f7f\u7528\u4e00\u4e2a 31 \\times 31 \u7684\u6838\uff0c\u5bfb\u627e\u6700\u9760\u8fd1\u7684\u672a\u586b\u8865\u70b9\u3002","title":"\u5927\u6d1e\u8865\u5145"},{"location":"other_categories/others/In_Defense_of_Classical_Image_Processing_Fast_Depth_Completion_on_the_CPU/#blur","text":"\u8fde\u7eed\u4f7f\u7528\u4e00\u4e2a 5\\times 5 \u4e2d\u4f4d\u6570\u6a21\u7cca,\u4ee5\u53ca\u4e00\u4e2a 5\\times 5 \u9ad8\u65af\u6a21\u7cca\u3002","title":"Blur"},{"location":"other_categories/others/In_Defense_of_Classical_Image_Processing_Fast_Depth_Completion_on_the_CPU/#depth-inversion_1","text":"\u5c06\u7b2c\u4e00\u6b65\u7684\u6df1\u5ea6\u8f6c\u56de\u6765\u3002","title":"Depth Inversion"},{"location":"other_categories/others/Jointly_derain_dehaze/","text":"A Convolutional Network for Joint Deraining and Dehazing from A Single Image for Autonomous Driving in Rain \u8fd9\u7bc7\u8bba\u6587\u662firos2019\u7684\u8bba\u6587\uff0c\u5728\u5b9e\u9a8c\u5ba4\u7684NAS\u4e0a\u6709PDF\u7248\u672c\u3002\u8fd9\u7bc7\u8bba\u6587\u5728\u4eba\u5de5\u5408\u6210\u7684city-scape\u6570\u636e\u96c6\u4e0a\u5bf9\u5355\u4e2a\u56fe\u7247\u8fdb\u884cderain\u4e0edehaze\u3002\u5c06\u8fd9\u4e24\u4e2a\u95ee\u9898\u4e00\u8d77\u7814\u7a76\u7684motivation\u662f\u96e8\u6ef4\u672c\u8eab\u4f1a\u4f7f\u5f97\u573a\u666f\u4e2d\u5e26\u6709\u5149\u7684\u6563\u5c04\uff0c\u5f62\u6210\u96fe\u7b49\u626d\u66f2\u7684\u5149\u6548\u679c\uff0c\u6240\u4ee5\u5728\u96e8\u5929\u81ea\u52a8\u9a7e\u9a76\u573a\u666f\u4e2d\u5e94\u8be5\u5bf9\u4e24\u4e2a\u90e8\u5206\u540c\u65f6\u8fdb\u884c\u77eb\u6b63\u3002\u672c\u6587\u63d0\u51fa\u7684\u6a21\u578b\u901f\u5ea6\u5f88\u5feb\uff0c\u5bf9 1024\\times 512 \u7684\u56fe\u7247\u5904\u7406\u65f6\u95f4\u4ec5\u4ec5\u53ea\u67090.05s. \u6570\u5b66\u6a21\u578b \u7ecf\u5178\u7684\u6a21\u578b\u4e2d\u96e8\u5929\u56fe\u50cf\u7684\u5f62\u6210\u53ef\u4ee5\u7528\u4e0b\u5f0f\u7684\u6a21\u578b\u63cf\u8ff0\uff1a I(x) = (J(x) + R(x))t(x) + A(1 - t(x)) \u5176\u4e2d I(x) \u4e3a\u4e0b\u96e8\u56fe\u7247, J(x) \u4e3a\u76ee\u6807\u8fd8\u539f\u56fe\u7247, R(x) \u4e3a\u76f8\u673a\u9644\u8fd1\u7684\u96e8\u6ef4, t(x) = e^{-\\beta d(x)} \u4e3a\u4e0e\u56fe\u7247\u4e2d\u7269\u4f53\u4e0e\u76f8\u673a\u8ddd\u79bb d(x) \u6709\u5173\u7684\u4e0d\u88ab\u5e72\u6270\u7684\u5149\u7684\u6bd4\u4f8b,A\u662f\u8868\u8fbe\u96fe\u7684\u6a21\u7cca\u4eae\u5ea6\u7684\u4e00\u4e2a\u5168\u5c40\u503c\uff0c\u5f88\u591a\u6a21\u578b\u5c1d\u8bd5\u5bf9 R(x), t(x) \u5efa\u6a21\uff0c\u628a A \u8bbe\u7f6e\u4e3a\u4e00\u4e2a\u56fa\u5b9a\u503c\uff0c\u4f46\u662f\u6211\u4eec\u4f1a\u53d1\u73b0 A \u4e0e t(x) \u8fd8\u662f\u6709\u76f8\u5173\u6027\u7684\u3002\u8fd9\u91cc\u5bf9\u539f\u6765\u7684\u516c\u5f0f\u8fdb\u884c\u91cd\u65b0\u8868\u8fbe\u3002 \\begin{aligned} J(x) &= \\frac{1}{t(x)} I(x) - A\\frac{1}{t(x)} + A - R(x) \\\\ J(x) &= (K_1(x) - K_2(x)) I(x) - (K_1(x) - K_2(x)) \\end{aligned} \u5176\u4e2d K_1(x) = \\frac{\\frac{1}{t(x)}(I(x)-A) + A}{I(x) - 1}, K_2{x} = \\frac{R(x)}{I(x)-1} \u5982\u6b64\u6211\u4eec\u5bf9\u6bcf\u4e00\u4e2a\u50cf\u7d20\u70b9\u76f4\u63a5\u4f30\u8ba1 K_1(x), K_2(x) \u672c\u8d28\u4e0a\u5c31\u662f\u5b8c\u6210\u4e86\u4e00\u5f0f\u7684\uff0c\u8fd9\u91cc\u7684\u7ecf\u9a8c\u662f\u5bf9 K_2(x) \u5b66\u4e60\u7684\u65f6\u5019\u76f4\u63a5\u5b66\u4e60 R(x) \u7f51\u7edc\u6a21\u578b \u6570\u636e\u7684\u4ea7\u751f \u4e8b\u5b9e\u4e0a\u6211\u4eec\u5f88\u96be\u5f97\u5230\u4e0b\u96e8\u3001\u4e0d\u4e0b\u96e8\u7684\u6570\u636e\u5bf9(\u51e0\u4e4e\u4e0d\u53ef\u80fd\uff0c\u53ea\u80fd\u4f9d\u9760\u5b9a\u70b9\u62cd\u6444\uff0c\u8fd9\u79cd\u91c7\u96c6\u65b9\u5f0f\u4f7f\u5f97\u573a\u666f\u6bd4\u8f83\u5c11)\uff0c\u8fd9\u91cc\u6700\u540e\u9009\u62e9\u7684\u662f\u4f7f\u7528\u5408\u6210\u6570\u636e\u96c6\u3002\u9996\u5148\u6709CityScapes\u6570\u636e\u96c6\uff0c\u7136\u540e\u6709foggy-Cityscapes\u5408\u6210\u6570\u636e\u96c6(\u8fd9\u4e2a\u6570\u636e\u96c6\u5176\u5b9e\u5f88\u6709\u610f\u601d\uff0c\u5176\u751f\u6210\u65b9\u5f0f\u53ef\u4ee5\u4e00\u8bfb)\uff0c\u8fd9\u4e2a\u6570\u636e\u96c6\u57fa\u4e8eCityScapes\u5e76\u52a0\u4e0a\u4e86\u96fe\u5316\u7684\u6548\u679c\u3002\u7136\u540e\u4f5c\u8005\u4ee5\u6b64\u4e3a\u57fa\u7840\uff0c\u5bf9\u6bcf\u4e00\u5f20\u56fe\u6839\u636e\u4e00\u4e2a \u6559\u7a0b \u52a0\u4e0a\u4e86\u4e0d\u540c\u65b9\u5411\u4e0d\u540c\u5f3a\u5ea6\u7684\u96e8\u6c34\u6548\u679c\uff0c\u5f62\u6210\u65b0\u7684\u6570\u636e\u96c6\u3002 \u5b9e\u9a8c \u8fd9\u91cc\u8c08\u53ca\u5b9e\u9a8c\u7684\u539f\u56e0\uff0c\u4e3b\u8981\u662f\u56e0\u4e3a\u672c\u6587\u5728\u9a8c\u8bc1\u81ea\u5df1\u7684\u91cd\u5efa\u6027\u80fd\u7684\u65f6\u5019\uff0c\u9664\u4e86\u5728\u7f51\u7edc\u4e2d\u9a8c\u8bc1\u91cd\u5efa\u8bef\u5dee\uff0c\u8fd8\u8fdb\u884c\u4e86\u9ad8\u9636\u4efb\u52a1\u7684\u5b9e\u9a8c\uff0c\u4e5f\u5c31\u662f\u8ba9\u7269\u4f53\u68c0\u6d4b\u4ee5\u53ca\u8bed\u4e49\u5206\u5272\u9884\u8bad\u7ec3\u7f51\u7edc\u5728\u539f\u56fe\u3001\u5408\u6210\u56fe\u3001\u8fd8\u539f\u56fe\u4e0a\u5206\u522b\u8fd0\u884c\u6d4b\u8bd5\uff0c\u5b9e\u9a8c\u53d1\u73b0\u5728\u8fd8\u539f\u56fe\u4e0a\u5f97\u5230\u7684\u6027\u80fd\u70b9\u6570\u4e00\u822c\u90fd\u6bd4\u5408\u6210\u56fe\u4e0a\u7684\u9ad8\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\u672c\u6587\u5e76\u6ca1\u6709\u8fdb\u884cfine-tune\u3002","title":"A Convolutional Network for Joint Deraining and Dehazing from A Single Image for Autonomous Driving in Rain"},{"location":"other_categories/others/Jointly_derain_dehaze/#a-convolutional-network-for-joint-deraining-and-dehazing-from-a-single-image-for-autonomous-driving-in-rain","text":"\u8fd9\u7bc7\u8bba\u6587\u662firos2019\u7684\u8bba\u6587\uff0c\u5728\u5b9e\u9a8c\u5ba4\u7684NAS\u4e0a\u6709PDF\u7248\u672c\u3002\u8fd9\u7bc7\u8bba\u6587\u5728\u4eba\u5de5\u5408\u6210\u7684city-scape\u6570\u636e\u96c6\u4e0a\u5bf9\u5355\u4e2a\u56fe\u7247\u8fdb\u884cderain\u4e0edehaze\u3002\u5c06\u8fd9\u4e24\u4e2a\u95ee\u9898\u4e00\u8d77\u7814\u7a76\u7684motivation\u662f\u96e8\u6ef4\u672c\u8eab\u4f1a\u4f7f\u5f97\u573a\u666f\u4e2d\u5e26\u6709\u5149\u7684\u6563\u5c04\uff0c\u5f62\u6210\u96fe\u7b49\u626d\u66f2\u7684\u5149\u6548\u679c\uff0c\u6240\u4ee5\u5728\u96e8\u5929\u81ea\u52a8\u9a7e\u9a76\u573a\u666f\u4e2d\u5e94\u8be5\u5bf9\u4e24\u4e2a\u90e8\u5206\u540c\u65f6\u8fdb\u884c\u77eb\u6b63\u3002\u672c\u6587\u63d0\u51fa\u7684\u6a21\u578b\u901f\u5ea6\u5f88\u5feb\uff0c\u5bf9 1024\\times 512 \u7684\u56fe\u7247\u5904\u7406\u65f6\u95f4\u4ec5\u4ec5\u53ea\u67090.05s.","title":"A Convolutional Network for Joint Deraining and Dehazing from A Single Image for Autonomous Driving in Rain"},{"location":"other_categories/others/Jointly_derain_dehaze/#_1","text":"\u7ecf\u5178\u7684\u6a21\u578b\u4e2d\u96e8\u5929\u56fe\u50cf\u7684\u5f62\u6210\u53ef\u4ee5\u7528\u4e0b\u5f0f\u7684\u6a21\u578b\u63cf\u8ff0\uff1a I(x) = (J(x) + R(x))t(x) + A(1 - t(x)) \u5176\u4e2d I(x) \u4e3a\u4e0b\u96e8\u56fe\u7247, J(x) \u4e3a\u76ee\u6807\u8fd8\u539f\u56fe\u7247, R(x) \u4e3a\u76f8\u673a\u9644\u8fd1\u7684\u96e8\u6ef4, t(x) = e^{-\\beta d(x)} \u4e3a\u4e0e\u56fe\u7247\u4e2d\u7269\u4f53\u4e0e\u76f8\u673a\u8ddd\u79bb d(x) \u6709\u5173\u7684\u4e0d\u88ab\u5e72\u6270\u7684\u5149\u7684\u6bd4\u4f8b,A\u662f\u8868\u8fbe\u96fe\u7684\u6a21\u7cca\u4eae\u5ea6\u7684\u4e00\u4e2a\u5168\u5c40\u503c\uff0c\u5f88\u591a\u6a21\u578b\u5c1d\u8bd5\u5bf9 R(x), t(x) \u5efa\u6a21\uff0c\u628a A \u8bbe\u7f6e\u4e3a\u4e00\u4e2a\u56fa\u5b9a\u503c\uff0c\u4f46\u662f\u6211\u4eec\u4f1a\u53d1\u73b0 A \u4e0e t(x) \u8fd8\u662f\u6709\u76f8\u5173\u6027\u7684\u3002\u8fd9\u91cc\u5bf9\u539f\u6765\u7684\u516c\u5f0f\u8fdb\u884c\u91cd\u65b0\u8868\u8fbe\u3002 \\begin{aligned} J(x) &= \\frac{1}{t(x)} I(x) - A\\frac{1}{t(x)} + A - R(x) \\\\ J(x) &= (K_1(x) - K_2(x)) I(x) - (K_1(x) - K_2(x)) \\end{aligned} \u5176\u4e2d K_1(x) = \\frac{\\frac{1}{t(x)}(I(x)-A) + A}{I(x) - 1}, K_2{x} = \\frac{R(x)}{I(x)-1} \u5982\u6b64\u6211\u4eec\u5bf9\u6bcf\u4e00\u4e2a\u50cf\u7d20\u70b9\u76f4\u63a5\u4f30\u8ba1 K_1(x), K_2(x) \u672c\u8d28\u4e0a\u5c31\u662f\u5b8c\u6210\u4e86\u4e00\u5f0f\u7684\uff0c\u8fd9\u91cc\u7684\u7ecf\u9a8c\u662f\u5bf9 K_2(x) \u5b66\u4e60\u7684\u65f6\u5019\u76f4\u63a5\u5b66\u4e60 R(x)","title":"\u6570\u5b66\u6a21\u578b"},{"location":"other_categories/others/Jointly_derain_dehaze/#_2","text":"","title":"\u7f51\u7edc\u6a21\u578b"},{"location":"other_categories/others/Jointly_derain_dehaze/#_3","text":"\u4e8b\u5b9e\u4e0a\u6211\u4eec\u5f88\u96be\u5f97\u5230\u4e0b\u96e8\u3001\u4e0d\u4e0b\u96e8\u7684\u6570\u636e\u5bf9(\u51e0\u4e4e\u4e0d\u53ef\u80fd\uff0c\u53ea\u80fd\u4f9d\u9760\u5b9a\u70b9\u62cd\u6444\uff0c\u8fd9\u79cd\u91c7\u96c6\u65b9\u5f0f\u4f7f\u5f97\u573a\u666f\u6bd4\u8f83\u5c11)\uff0c\u8fd9\u91cc\u6700\u540e\u9009\u62e9\u7684\u662f\u4f7f\u7528\u5408\u6210\u6570\u636e\u96c6\u3002\u9996\u5148\u6709CityScapes\u6570\u636e\u96c6\uff0c\u7136\u540e\u6709foggy-Cityscapes\u5408\u6210\u6570\u636e\u96c6(\u8fd9\u4e2a\u6570\u636e\u96c6\u5176\u5b9e\u5f88\u6709\u610f\u601d\uff0c\u5176\u751f\u6210\u65b9\u5f0f\u53ef\u4ee5\u4e00\u8bfb)\uff0c\u8fd9\u4e2a\u6570\u636e\u96c6\u57fa\u4e8eCityScapes\u5e76\u52a0\u4e0a\u4e86\u96fe\u5316\u7684\u6548\u679c\u3002\u7136\u540e\u4f5c\u8005\u4ee5\u6b64\u4e3a\u57fa\u7840\uff0c\u5bf9\u6bcf\u4e00\u5f20\u56fe\u6839\u636e\u4e00\u4e2a \u6559\u7a0b \u52a0\u4e0a\u4e86\u4e0d\u540c\u65b9\u5411\u4e0d\u540c\u5f3a\u5ea6\u7684\u96e8\u6c34\u6548\u679c\uff0c\u5f62\u6210\u65b0\u7684\u6570\u636e\u96c6\u3002","title":"\u6570\u636e\u7684\u4ea7\u751f"},{"location":"other_categories/others/Jointly_derain_dehaze/#_4","text":"\u8fd9\u91cc\u8c08\u53ca\u5b9e\u9a8c\u7684\u539f\u56e0\uff0c\u4e3b\u8981\u662f\u56e0\u4e3a\u672c\u6587\u5728\u9a8c\u8bc1\u81ea\u5df1\u7684\u91cd\u5efa\u6027\u80fd\u7684\u65f6\u5019\uff0c\u9664\u4e86\u5728\u7f51\u7edc\u4e2d\u9a8c\u8bc1\u91cd\u5efa\u8bef\u5dee\uff0c\u8fd8\u8fdb\u884c\u4e86\u9ad8\u9636\u4efb\u52a1\u7684\u5b9e\u9a8c\uff0c\u4e5f\u5c31\u662f\u8ba9\u7269\u4f53\u68c0\u6d4b\u4ee5\u53ca\u8bed\u4e49\u5206\u5272\u9884\u8bad\u7ec3\u7f51\u7edc\u5728\u539f\u56fe\u3001\u5408\u6210\u56fe\u3001\u8fd8\u539f\u56fe\u4e0a\u5206\u522b\u8fd0\u884c\u6d4b\u8bd5\uff0c\u5b9e\u9a8c\u53d1\u73b0\u5728\u8fd8\u539f\u56fe\u4e0a\u5f97\u5230\u7684\u6027\u80fd\u70b9\u6570\u4e00\u822c\u90fd\u6bd4\u5408\u6210\u56fe\u4e0a\u7684\u9ad8\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\u672c\u6587\u5e76\u6ca1\u6709\u8fdb\u884cfine-tune\u3002","title":"\u5b9e\u9a8c"},{"location":"other_categories/others/OptNet_Differentiable_Optimization_as_a_Layer_in_Neural_Networks/","text":"OptNet: Differentiable Optimization as a Layer in Neural Networks \u8fd9\u7bc7\u8bba\u6587\u5b9a\u4e49\u4e86\u4e00\u4e2a\u57fa\u4e8e\u7ebf\u6027\u4e8c\u6b21\u4f18\u5316\u7684\u65b0\u7684\u795e\u7ecf\u7f51\u7edc\u5c42 \u8fd9\u4e2a\u5c42\u5bf9\u5e94\u7684\u4f18\u5316\u95ee\u9898\u5982\u4e0b z_{i+1} = argmin(frac{1}{2} z^T Q(z_i) z + q(z_i) z) \u7b26\u5408\u7ea6\u675f A(z_i)z = b(z_i) \u4e0e G(z_i)z <= h(z_i) \u5176\u4e2d Q,q,A,b,G,h \u90fd\u662f\u53ef\u4ee5\u8ddf\u968f\u8f93\u5165 z \u53d8\u5316\u7684\u503c\uff0c\u8bba\u6587\u63d0\u51fa\u4e86\u6c42\u89e3\u8fd9\u4e2a\u4f18\u5316\u95ee\u9898\u4ee5\u53ca\u6c42\u51fa\u8fd9\u4e2a\u4f18\u5316\u95ee\u9898\u5bf9\u5e94\u7684\u68af\u5ea6\u7684\u5feb\u901f\u65b9\u5f0f\u3002 \u6838\u5fc3\u601d\u8def\u4e0e\u516c\u5f0f \u6838\u5fc3\u601d\u8def\u662f\u5728\u53cd\u4f20\u7684\u65f6\u5019\u4f7f\u7528KKT condition\uff0c\u4e5f\u5c31\u662f\u5047\u8bbe\u4f18\u5316\u95ee\u9898\u5df2\u7ecf\u5f97\u5230\u4e86\u6700\u4f18\u89e3\uff0c\u5bf9KKT condition\u8fdb\u884c\u6c42\u5fae\u5206\u5f97\u5230\u5404\u4e2a\u5143\u7d20\u4e4b\u95f4\u7684\u5fae\u5206\u5173\u7cfb\uff08\u8bba\u6587\u516c\u5f0f6-8\uff09 \u53e6\u5916\u9700\u8981\u5728GPU\u4e0a\u5b9e\u73b0\u5b8c\u6574\u7684\u4f18\u5316\u7b97\u6cd5\uff0c\u4f5c\u8005\u4f7f\u7528\u4e86\u516c\u5f0f(9-10)\uff08\u66f4\u591a\u7684\u516c\u5f0f\u5efa\u8bae\u67e5\u770bgithub\uff0cqpth\u5e93\uff09","title":"OptNet: Differentiable Optimization as a Layer in Neural Networks"},{"location":"other_categories/others/OptNet_Differentiable_Optimization_as_a_Layer_in_Neural_Networks/#optnet-differentiable-optimization-as-a-layer-in-neural-networks","text":"\u8fd9\u7bc7\u8bba\u6587\u5b9a\u4e49\u4e86\u4e00\u4e2a\u57fa\u4e8e\u7ebf\u6027\u4e8c\u6b21\u4f18\u5316\u7684\u65b0\u7684\u795e\u7ecf\u7f51\u7edc\u5c42 \u8fd9\u4e2a\u5c42\u5bf9\u5e94\u7684\u4f18\u5316\u95ee\u9898\u5982\u4e0b z_{i+1} = argmin(frac{1}{2} z^T Q(z_i) z + q(z_i) z) \u7b26\u5408\u7ea6\u675f A(z_i)z = b(z_i) \u4e0e G(z_i)z <= h(z_i) \u5176\u4e2d Q,q,A,b,G,h \u90fd\u662f\u53ef\u4ee5\u8ddf\u968f\u8f93\u5165 z \u53d8\u5316\u7684\u503c\uff0c\u8bba\u6587\u63d0\u51fa\u4e86\u6c42\u89e3\u8fd9\u4e2a\u4f18\u5316\u95ee\u9898\u4ee5\u53ca\u6c42\u51fa\u8fd9\u4e2a\u4f18\u5316\u95ee\u9898\u5bf9\u5e94\u7684\u68af\u5ea6\u7684\u5feb\u901f\u65b9\u5f0f\u3002","title":"OptNet: Differentiable Optimization as a Layer in Neural Networks"},{"location":"other_categories/others/OptNet_Differentiable_Optimization_as_a_Layer_in_Neural_Networks/#_1","text":"\u6838\u5fc3\u601d\u8def\u662f\u5728\u53cd\u4f20\u7684\u65f6\u5019\u4f7f\u7528KKT condition\uff0c\u4e5f\u5c31\u662f\u5047\u8bbe\u4f18\u5316\u95ee\u9898\u5df2\u7ecf\u5f97\u5230\u4e86\u6700\u4f18\u89e3\uff0c\u5bf9KKT condition\u8fdb\u884c\u6c42\u5fae\u5206\u5f97\u5230\u5404\u4e2a\u5143\u7d20\u4e4b\u95f4\u7684\u5fae\u5206\u5173\u7cfb\uff08\u8bba\u6587\u516c\u5f0f6-8\uff09 \u53e6\u5916\u9700\u8981\u5728GPU\u4e0a\u5b9e\u73b0\u5b8c\u6574\u7684\u4f18\u5316\u7b97\u6cd5\uff0c\u4f5c\u8005\u4f7f\u7528\u4e86\u516c\u5f0f(9-10)\uff08\u66f4\u591a\u7684\u516c\u5f0f\u5efa\u8bae\u67e5\u770bgithub\uff0cqpth\u5e93\uff09","title":"\u6838\u5fc3\u601d\u8def\u4e0e\u516c\u5f0f"},{"location":"other_categories/others/PHOTOREALISTIC IMAGE RECONSTRUCTION FROM_HYBRID_INTENSITY_AND_EVENT_BASED_SENSOR/","text":"Photorealistic Image Reconstruction From Hybrid Intensity and Event Based Sensor \u8fd9\u7bc7\u8bba\u6587\u89e3\u51b3\u7684\u4efb\u52a1\u5982\u4e0b\uff0c\u8f93\u5165\u8fde\u7eed\u7684\u666e\u901a\u56fe\u7247\u4ee5\u53ca\u4e00\u7cfb\u5217\u5bc6\u96c6\u7684event camera\u4fe1\u606f\uff0c\u8fd8\u539f\u51fa\u66f4\u52a0\u771f\u5b9e\u7684\u539f\u59cb\u56fe\u7247,\u5173\u4e8eevent camera\u7684\u57fa\u7840\u539f\u7406\u4ee5\u53ca\u5bf9\u56fe\u7247\u7684\u589e\u5f3a\uff0c\u8fd9\u91cc\u53ef\u53c2\u8003 \u8fd9\u7bc7\u8bba\u6587 \u5de5\u4f5c\u6d41\u7a0b \u8fd9\u91cc\u5206\u4e3a\u56db\u4e2a\u6b65\u9aa4\uff0c\u7b2c\u4e00\u6b65\u662f\u901a\u8fc7\u4e24\u5f20\u57fa\u7840\u56fe\u7247\u5f97\u5230\u6df1\u5ea6\u4f30\u8ba1\u3002\u7b2c\u4e8c\u6b65\u662f\u4f7f\u7528event frames\u5b9e\u73b0\u5bf9\u4e2d\u95f4\u5e27\u7684\u63d2\u503c\uff0c\u7b2c\u4e09\u6b65\u662f\u5bf9\u63d2\u503c\u7ed3\u679c\u4f7f\u7528VO\u5f97\u5230\u4e00\u4e2a\u4f4d\u59ff\u4f30\u8ba1\uff0c\u7b2c\u56db\u6b65\u662f\u6839\u636e\u6df1\u5ea6\u4e0e\u59ff\u6001\u5f97\u5230\u8f6c\u6362\u540e\u7684\u5f3a\u5ea6\u56fe\u3002 \u6df1\u5ea6\u4f30\u8ba1 \u901a\u8fc7\u5149\u6d41\u521d\u59cb\u5316\u6df1\u5ea6\u4f30\u8ba1 d_k, d_{k+1} \uff0c\u5c06\u76f8\u5bf9\u4f4d\u79fb\u4e0e\u65cb\u8f6c\u521d\u59cb\u5316\u4e3a0,\u6839\u636e\u6df1\u5ea6\u4ee5\u53ca\u4f4d\u79fb\uff0c\u53ef\u4ee5\u8ba9\u4e24\u5f20\u56fe\u76f8\u4e92\u8f6c\u6362\uff0c\u8fd9\u91cc\u5b9a\u4e49\u91cd\u6784\u635f\u5931 \\mathcal{L}_{p h}\\left(d_{k}, d_{k+1}, \\xi\\right)=\\left\\|\\left(\\hat{I}_{k}-I_{k}\\right)\\right\\|_{1}+\\left\\|\\left(\\hat{I}_{k+1}-I_{k+1}\\right)\\right\\|_{1} \u8fdb\u4e00\u6b65\u5b9a\u4e49\u4e00\u4e2a\u4e0eedge\u6709\u5173\u7684\u635f\u5931 \\mathcal{L}_{s m}(d)=\\sum\\left\\|\\nabla_{x} d\\right\\| e^{-\\beta\\left\\|\\nabla_{x} I\\right\\|}+\\left\\|\\nabla_{y} d\\right\\| e^{-\\beta\\left\\|\\nabla_{y} I\\right\\|} \u5176\u4e2d d \u4e3a\u6df1\u5ea6\u56fe \\nabla_x, \\nabla_y \u6307\u7684\u662fx,y\u65b9\u5411\u7684\u8fd0\u7b97\u7b26, \u4f18\u5316\u4ee5\u4e0a\u4e24\u4e2a\u635f\u5931\u51fd\u6570\u7684\u52a0\u6743\u6c42\u548c\u662f\u4e00\u4e2a\u975e\u51f8\u95ee\u9898\uff0c\u6211\u4eec\u9700\u8981\u4e00\u4e2a\u597d\u7684\u5c40\u90e8\u89e3\u4f5c\u4e3a\u521d\u59cb\u89e3\u3002\u8fd9\u91cc\u4f7f\u7528 PWC-Net \u751f\u6210\u521d\u59cb\u5149\u6d41\uff0c\u8fd9\u91cc\u4f7f\u7528\u5149\u6d41\u7684inverse\u76f4\u63a5\u5f97\u5230\u6df1\u5ea6\u521d\u59cb\u503c\u3002 \u76f8\u5bf9\u4f4d\u79fb\u4f30\u8ba1 \u8fd9\u91cc\u4f7f\u7528event camera\u5bf9\u4e24\u5e27\u4e4b\u95f4\u7684\u56fe\u50cf\u8fdb\u884c\u63d2\u503c\uff0c\u751f\u6210\u4e00\u7cfb\u5217\u7684\u4e2d\u95f4\u56fe\u50cf\u3002 \\begin{aligned} \\mathcal{L}_{p}\\left(\\xi_{k}^{j}\\right) &=\\left\\|E_{k}^{0}-\\hat{E}_{k}^{0}\\right\\|_{1} \\\\ \\mathcal{L}_{p}\\left(\\xi_{k+1}^{j}\\right) &=\\left\\|E_{k+1}^{0}-\\hat{E}_{k+1}^{0}\\right\\|_{1} \\end{aligned} \\xi_{k}^{j}, \\xi_{k+1}^{j}=\\underset{\\xi_{k}^{j}, \\xi_{k+1}^{j}}{\\arg \\min } \\mathcal{L}_{p}\\left(\\xi_{k}^{j}\\right)+\\mathcal{L}_{p}\\left(\\xi_{k+1}^{j}\\right)+\\lambda_{r} \\mathcal{L}_{p}\\left(\\xi_{k}^{j}, \\xi_{k+1}^{j}\\right) \u5176\u4e2d \\xi^j_k,\\xi^j_{k+1} \u5206\u522b\u6307\u4ee3\u7b2c j \u5f20\u4e2d\u95f4\u56fe\u76f8\u5bf9\u4e8e\u7b2c\u4e00\u5e27\u3001\u4e0b\u4e00\u5e27\u4e4b\u95f4\u7684\u76f8\u5bf9\u4f4d\u59ff\u53d8\u5316\uff0c \u878d\u5408 \u6839\u636e\u6df1\u5ea6\u3001\u591a\u4e2a\u4e2d\u95f4\u503c\u7684\u4f4d\u59ff\uff0c\u5c06\u7b2c\u4e00\u5e27\u4e0e\u7b2c\u4e8c\u5e27\u5206\u522b\u5411\u540e\u3001\u5411\u524dwarp\uff0calpha-blend\u4e24\u6b21\u7684\u7ed3\u679c\uff0c\u5f97\u5230\u4e00\u7cfb\u5217\u66f4\u7cbe\u786e\u7684\u9996\u5c3e\u4e0e\u4e2d\u95f4\u56fe\u3002","title":"Photorealistic Image Reconstruction From Hybrid Intensity and Event Based Sensor"},{"location":"other_categories/others/PHOTOREALISTIC IMAGE RECONSTRUCTION FROM_HYBRID_INTENSITY_AND_EVENT_BASED_SENSOR/#photorealistic-image-reconstruction-from-hybrid-intensity-and-event-based-sensor","text":"\u8fd9\u7bc7\u8bba\u6587\u89e3\u51b3\u7684\u4efb\u52a1\u5982\u4e0b\uff0c\u8f93\u5165\u8fde\u7eed\u7684\u666e\u901a\u56fe\u7247\u4ee5\u53ca\u4e00\u7cfb\u5217\u5bc6\u96c6\u7684event camera\u4fe1\u606f\uff0c\u8fd8\u539f\u51fa\u66f4\u52a0\u771f\u5b9e\u7684\u539f\u59cb\u56fe\u7247,\u5173\u4e8eevent camera\u7684\u57fa\u7840\u539f\u7406\u4ee5\u53ca\u5bf9\u56fe\u7247\u7684\u589e\u5f3a\uff0c\u8fd9\u91cc\u53ef\u53c2\u8003 \u8fd9\u7bc7\u8bba\u6587","title":"Photorealistic Image Reconstruction From Hybrid Intensity and Event Based Sensor"},{"location":"other_categories/others/PHOTOREALISTIC IMAGE RECONSTRUCTION FROM_HYBRID_INTENSITY_AND_EVENT_BASED_SENSOR/#_1","text":"\u8fd9\u91cc\u5206\u4e3a\u56db\u4e2a\u6b65\u9aa4\uff0c\u7b2c\u4e00\u6b65\u662f\u901a\u8fc7\u4e24\u5f20\u57fa\u7840\u56fe\u7247\u5f97\u5230\u6df1\u5ea6\u4f30\u8ba1\u3002\u7b2c\u4e8c\u6b65\u662f\u4f7f\u7528event frames\u5b9e\u73b0\u5bf9\u4e2d\u95f4\u5e27\u7684\u63d2\u503c\uff0c\u7b2c\u4e09\u6b65\u662f\u5bf9\u63d2\u503c\u7ed3\u679c\u4f7f\u7528VO\u5f97\u5230\u4e00\u4e2a\u4f4d\u59ff\u4f30\u8ba1\uff0c\u7b2c\u56db\u6b65\u662f\u6839\u636e\u6df1\u5ea6\u4e0e\u59ff\u6001\u5f97\u5230\u8f6c\u6362\u540e\u7684\u5f3a\u5ea6\u56fe\u3002","title":"\u5de5\u4f5c\u6d41\u7a0b"},{"location":"other_categories/others/PHOTOREALISTIC IMAGE RECONSTRUCTION FROM_HYBRID_INTENSITY_AND_EVENT_BASED_SENSOR/#_2","text":"\u901a\u8fc7\u5149\u6d41\u521d\u59cb\u5316\u6df1\u5ea6\u4f30\u8ba1 d_k, d_{k+1} \uff0c\u5c06\u76f8\u5bf9\u4f4d\u79fb\u4e0e\u65cb\u8f6c\u521d\u59cb\u5316\u4e3a0,\u6839\u636e\u6df1\u5ea6\u4ee5\u53ca\u4f4d\u79fb\uff0c\u53ef\u4ee5\u8ba9\u4e24\u5f20\u56fe\u76f8\u4e92\u8f6c\u6362\uff0c\u8fd9\u91cc\u5b9a\u4e49\u91cd\u6784\u635f\u5931 \\mathcal{L}_{p h}\\left(d_{k}, d_{k+1}, \\xi\\right)=\\left\\|\\left(\\hat{I}_{k}-I_{k}\\right)\\right\\|_{1}+\\left\\|\\left(\\hat{I}_{k+1}-I_{k+1}\\right)\\right\\|_{1} \u8fdb\u4e00\u6b65\u5b9a\u4e49\u4e00\u4e2a\u4e0eedge\u6709\u5173\u7684\u635f\u5931 \\mathcal{L}_{s m}(d)=\\sum\\left\\|\\nabla_{x} d\\right\\| e^{-\\beta\\left\\|\\nabla_{x} I\\right\\|}+\\left\\|\\nabla_{y} d\\right\\| e^{-\\beta\\left\\|\\nabla_{y} I\\right\\|} \u5176\u4e2d d \u4e3a\u6df1\u5ea6\u56fe \\nabla_x, \\nabla_y \u6307\u7684\u662fx,y\u65b9\u5411\u7684\u8fd0\u7b97\u7b26, \u4f18\u5316\u4ee5\u4e0a\u4e24\u4e2a\u635f\u5931\u51fd\u6570\u7684\u52a0\u6743\u6c42\u548c\u662f\u4e00\u4e2a\u975e\u51f8\u95ee\u9898\uff0c\u6211\u4eec\u9700\u8981\u4e00\u4e2a\u597d\u7684\u5c40\u90e8\u89e3\u4f5c\u4e3a\u521d\u59cb\u89e3\u3002\u8fd9\u91cc\u4f7f\u7528 PWC-Net \u751f\u6210\u521d\u59cb\u5149\u6d41\uff0c\u8fd9\u91cc\u4f7f\u7528\u5149\u6d41\u7684inverse\u76f4\u63a5\u5f97\u5230\u6df1\u5ea6\u521d\u59cb\u503c\u3002","title":"\u6df1\u5ea6\u4f30\u8ba1"},{"location":"other_categories/others/PHOTOREALISTIC IMAGE RECONSTRUCTION FROM_HYBRID_INTENSITY_AND_EVENT_BASED_SENSOR/#_3","text":"\u8fd9\u91cc\u4f7f\u7528event camera\u5bf9\u4e24\u5e27\u4e4b\u95f4\u7684\u56fe\u50cf\u8fdb\u884c\u63d2\u503c\uff0c\u751f\u6210\u4e00\u7cfb\u5217\u7684\u4e2d\u95f4\u56fe\u50cf\u3002 \\begin{aligned} \\mathcal{L}_{p}\\left(\\xi_{k}^{j}\\right) &=\\left\\|E_{k}^{0}-\\hat{E}_{k}^{0}\\right\\|_{1} \\\\ \\mathcal{L}_{p}\\left(\\xi_{k+1}^{j}\\right) &=\\left\\|E_{k+1}^{0}-\\hat{E}_{k+1}^{0}\\right\\|_{1} \\end{aligned} \\xi_{k}^{j}, \\xi_{k+1}^{j}=\\underset{\\xi_{k}^{j}, \\xi_{k+1}^{j}}{\\arg \\min } \\mathcal{L}_{p}\\left(\\xi_{k}^{j}\\right)+\\mathcal{L}_{p}\\left(\\xi_{k+1}^{j}\\right)+\\lambda_{r} \\mathcal{L}_{p}\\left(\\xi_{k}^{j}, \\xi_{k+1}^{j}\\right) \u5176\u4e2d \\xi^j_k,\\xi^j_{k+1} \u5206\u522b\u6307\u4ee3\u7b2c j \u5f20\u4e2d\u95f4\u56fe\u76f8\u5bf9\u4e8e\u7b2c\u4e00\u5e27\u3001\u4e0b\u4e00\u5e27\u4e4b\u95f4\u7684\u76f8\u5bf9\u4f4d\u59ff\u53d8\u5316\uff0c","title":"\u76f8\u5bf9\u4f4d\u79fb\u4f30\u8ba1"},{"location":"other_categories/others/PHOTOREALISTIC IMAGE RECONSTRUCTION FROM_HYBRID_INTENSITY_AND_EVENT_BASED_SENSOR/#_4","text":"\u6839\u636e\u6df1\u5ea6\u3001\u591a\u4e2a\u4e2d\u95f4\u503c\u7684\u4f4d\u59ff\uff0c\u5c06\u7b2c\u4e00\u5e27\u4e0e\u7b2c\u4e8c\u5e27\u5206\u522b\u5411\u540e\u3001\u5411\u524dwarp\uff0calpha-blend\u4e24\u6b21\u7684\u7ed3\u679c\uff0c\u5f97\u5230\u4e00\u7cfb\u5217\u66f4\u7cbe\u786e\u7684\u9996\u5c3e\u4e0e\u4e2d\u95f4\u56fe\u3002","title":"\u878d\u5408"},{"location":"other_categories/others/PSMNet/","text":"Pyramid Stereo Matching Network PSM \u7f51\u7edc\u662f\u76ee\u524d\u975e\u5e38\u5e38\u7528\u7684\u4e00\u4e2a\u53cc\u76ee\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\uff0c\u5728\u53cc\u76ee\u6df1\u5ea6\u4f30\u8ba1\uff0c\u53cc\u76ee\u68c0\u6d4b\uff0c\u53cc\u76ee\u5149\u6d41\u7b49\u4efb\u52a1\u4e2d\u90fd\u6709\u5e7f\u6cdb\u5e94\u7528 PSM\u603b\u4f53\u7ed3\u6784 \u56fe\u4e2dSPP\u6a21\u5757\uff0c\u672c\u8d28\u4e0a\u5c31\u662f\u4e00\u4e2a\u5927\u611f\u53d7\u91ce\u7684CNN\u6a21\u5757\uff0c\u8fd9\u4e2abackbone\u5728\u5f88\u591a\u7f51\u7edc\u4e2d\u90fd\u88ab\u91cd\u590d\u4f7f\u7528\u3002 \u56fe\u4e2d\u7684Cost volume \u6765\u81ea\u4e8e \u53e6\u4e00\u7bc7\u6587\u7ae0.pdf \uff0c \u4e0e PSV \u4e0d\u540c\u7684\u5730\u65b9\u5728\u4e8e\uff0c\u4e0e\u5176\u662f\u5728\u5b9e\u9645\u7684\u8ddd\u79bb\u5355\u4f4d\u4e0a\u5747\u5300\u53d6Z\u8f74\u518d\u8c03\u7528\u8f83\u4e3a\u8017\u8d39\u8d44\u6e90\u7684grid_sample\u51fd\u6570\uff0c\u8fd9\u91cc\u9009\u62e9\u7684\u662f\u5c06\u6df1\u5ea6\u8f74\u76f4\u63a5\u7406\u89e3\u4e3a\u79bb\u6563\u7684disparity\uff0c\u4f7f\u5f97grid_sample\u53ef\u4ee5\u7528\u8f7b\u4fbf\u7684indexing\u4ee3\u66ff\uff0c\u901f\u5ea6\u66f4\u5feb\uff0c\u6548\u679c\u5dee\u8ddd\u4e0d\u7b97\u5927,\u53ea\u4e0d\u8fc7\u662f\u6839\u636e\u56fe\u7247\u672c\u8eab\u7684\u5927\u5c0fdisparity\u503c\u7684\u5f71\u54cd\u4f1a\u76f4\u63a5\u5f71\u54cd\u5230\u6a21\u578b\u7684\u5927\u5c0f\u6216\u8005\u8bf4\u901f\u5ea6\u3002 \u5982\u679c\u4f7f\u7528 stacked-hourglass\u4f5c\u4e3a inference\u7684\u65f6\u5019\uff0c\u5c31\u4f1a\u5728\u540c\u4e00\u5927\u5c0f\u7684\u8f93\u51fa\u5c42\u4e0a\u591a\u6b21\u505a\u51faprediction\u3002 \u6838\u5fc3\u5728\u4e8e\u5b9e\u73b0\u4ee5\u53ca\u8bad\u7ec3\u7ec6\u8282\uff0c\u8fd9\u4e9b\u90fd\u5728\u4ee3\u7801\u4e2d\u6709\u4ea4\u4ee3\u3002Cost volume\u7684\u5b9e\u73b0\u5df2\u7ecf\u5728\u5c1d\u8bd5\u8fc1\u79fb\u4f7f\u7528\u3002","title":"Pyramid Stereo Matching Network"},{"location":"other_categories/others/PSMNet/#pyramid-stereo-matching-network","text":"PSM \u7f51\u7edc\u662f\u76ee\u524d\u975e\u5e38\u5e38\u7528\u7684\u4e00\u4e2a\u53cc\u76ee\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\uff0c\u5728\u53cc\u76ee\u6df1\u5ea6\u4f30\u8ba1\uff0c\u53cc\u76ee\u68c0\u6d4b\uff0c\u53cc\u76ee\u5149\u6d41\u7b49\u4efb\u52a1\u4e2d\u90fd\u6709\u5e7f\u6cdb\u5e94\u7528","title":"Pyramid Stereo Matching Network"},{"location":"other_categories/others/PSMNet/#psm","text":"\u56fe\u4e2dSPP\u6a21\u5757\uff0c\u672c\u8d28\u4e0a\u5c31\u662f\u4e00\u4e2a\u5927\u611f\u53d7\u91ce\u7684CNN\u6a21\u5757\uff0c\u8fd9\u4e2abackbone\u5728\u5f88\u591a\u7f51\u7edc\u4e2d\u90fd\u88ab\u91cd\u590d\u4f7f\u7528\u3002 \u56fe\u4e2d\u7684Cost volume \u6765\u81ea\u4e8e \u53e6\u4e00\u7bc7\u6587\u7ae0.pdf \uff0c \u4e0e PSV \u4e0d\u540c\u7684\u5730\u65b9\u5728\u4e8e\uff0c\u4e0e\u5176\u662f\u5728\u5b9e\u9645\u7684\u8ddd\u79bb\u5355\u4f4d\u4e0a\u5747\u5300\u53d6Z\u8f74\u518d\u8c03\u7528\u8f83\u4e3a\u8017\u8d39\u8d44\u6e90\u7684grid_sample\u51fd\u6570\uff0c\u8fd9\u91cc\u9009\u62e9\u7684\u662f\u5c06\u6df1\u5ea6\u8f74\u76f4\u63a5\u7406\u89e3\u4e3a\u79bb\u6563\u7684disparity\uff0c\u4f7f\u5f97grid_sample\u53ef\u4ee5\u7528\u8f7b\u4fbf\u7684indexing\u4ee3\u66ff\uff0c\u901f\u5ea6\u66f4\u5feb\uff0c\u6548\u679c\u5dee\u8ddd\u4e0d\u7b97\u5927,\u53ea\u4e0d\u8fc7\u662f\u6839\u636e\u56fe\u7247\u672c\u8eab\u7684\u5927\u5c0fdisparity\u503c\u7684\u5f71\u54cd\u4f1a\u76f4\u63a5\u5f71\u54cd\u5230\u6a21\u578b\u7684\u5927\u5c0f\u6216\u8005\u8bf4\u901f\u5ea6\u3002 \u5982\u679c\u4f7f\u7528 stacked-hourglass\u4f5c\u4e3a inference\u7684\u65f6\u5019\uff0c\u5c31\u4f1a\u5728\u540c\u4e00\u5927\u5c0f\u7684\u8f93\u51fa\u5c42\u4e0a\u591a\u6b21\u505a\u51faprediction\u3002 \u6838\u5fc3\u5728\u4e8e\u5b9e\u73b0\u4ee5\u53ca\u8bad\u7ec3\u7ec6\u8282\uff0c\u8fd9\u4e9b\u90fd\u5728\u4ee3\u7801\u4e2d\u6709\u4ea4\u4ee3\u3002Cost volume\u7684\u5b9e\u73b0\u5df2\u7ecf\u5728\u5c1d\u8bd5\u8fc1\u79fb\u4f7f\u7528\u3002","title":"PSM\u603b\u4f53\u7ed3\u6784"},{"location":"other_categories/others/PointFlow : 3D Point Cloud Generation with Continuous Normalizing Flows/","text":"PointFlow : 3D Point Cloud Generation with Continuous Normalizing Flows \u8fd9\u7bc7\u8bba\u6587\u6709\u4e00\u4e2a project page \uff0c\u6839\u636e \u89c6\u9891 \u5b8c\u6210\u7684\u4e00\u4e2a\u4efb\u52a1\u53ef\u4ee5\u8fd9\u6837\u63cf\u8ff0\u3002\u6bcf\u4e00\u4e2a\u7269\u4f53\u7684\u4e00\u79cd\u70b9\u4e91\u8868\u8fbe\u53ef\u4ee5\u7406\u89e3\u4e3a\u4ece\u4e00\u4e2a\u7531\u5f62\u72b6\u51b3\u5b9a\u7684\u6982\u7387\u5206\u5e03\u91c7\u6837\u70b9\u3002\u6211\u4eec\u53ef\u4ee5\u5229\u7528\u4e00\u4e2a\u5750\u6807\u8f6c\u6362\u51fd\u6570\uff0c\u5c06\u9ad8\u65af\u91c7\u6837\u70b9\u4e91\u8f6c\u6362\u4e3a\u6700\u540e\u7684\u8f93\u51fa\u3002\u672c\u6587\u7ed9\u51fa\u7684\u7f51\u7edc\u53ef\u4ee5\u6839\u636e\u7c7b\u522b\uff0c\u4ee5\u53ca\u4e00\u4e9b\u968f\u673a\u6570\uff0c\u91c7\u6837\u51fa\u4e0d\u540c\u5f62\u72b6\u7684\u4e00\u4e2a\u5750\u6807\u8f6c\u6362\u51fd\u6570\u3002 Background: Continuous normalizing flow \u5b9a\u4e49 f_1,...,f_n \u6307\u4ee3\u4e00\u7cfb\u5217\u7684\u53ef\u9006\u53d8\u6362\u3002\u8f93\u5165\u9690\u53d8\u91cf y \u7684\u6982\u7387\u5206\u5e03\u4e3a P(y) . x=f_{n} \\circ f_{n-1} \\circ \\cdots \\circ f_{1}(y) \u4f5c\u4e3a\u8f93\u51fa\u3002\u8f93\u51fa\u53d8\u91cf\u7684\u6982\u7387\u5bc6\u5ea6\u5219\u53d8\u4e3a \\log P(x)=\\log P(y)-\\sum_{k=1}^{n} \\log \\left|\\operatorname{det} \\frac{\\partial f_{k}}{\\partial y_{k-1}}\\right| \u8fd9\u6837 y \u53ef\u4ee5\u4ece x \u4f7f\u7528inverse flow\u8ba1\u7b97: y=f_{1}^{-1} \\circ \\cdots \\circ f_{n}^{-1}(x) . \u8fd9\u91cc f_1,...,f_n \u5728\u8fd9\u91cc\u5b9e\u4f53\u5316\u4f5c\u4e3a\u795e\u7ecf\u7f51\u7edc\uff0c\u8fd9\u6837\u5bfc\u6570\u7684\u884c\u5217\u5f0f\u8ba1\u7b97\u96be\u5ea6\u4e0d\u5927\u3002 continuous normalizing flow(CNF) for P(x) \u5c31\u662f x=y\\left(t_{0}\\right)+\\int_{t_{0}}^{t_{1}} f(y(t), t) d t, \\quad y\\left(t_{0}\\right) \\sim P(y) \\log P(x)=\\log P\\left(y\\left(t_{0}\\right)\\right)-\\int_{t_{0}}^{t_{1}} \\operatorname{Tr}\\left(\\frac{\\partial f}{\\partial y(t)}\\right) d t inverse flow y(t_0) = x + \\int^{t_0}_{t_1}f(y(t),t)dt .\u8fd9\u91cc\u7684 f \u4ecd\u7136\u662f\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc,\u7528ODE\u6c42\u89e3\u5668\u4f5c\u4e3a\u8f93\u51fa\u3002\u8fd9\u91cc\u7684\u5173\u952e\u601d\u7ef4\u8f6c\u53d8\u662f\u5229\u7528\u4e86\uff0c Neural Ordinary Equation \u7684\u601d\u8def\uff0c\u5c06\u8fde\u7eed\u53e0\u5c42\u7684\u5171\u4eab\u6743\u91cd\u7684\u795e\u7ecf\u7f51\u7edc\u7528\u5e38\u5fae\u5206\u65b9\u7a0b\u4ee3\u66ff.\u7528\u8fd9\u4e2aneural ODE\u7684\u4e00\u4e2a\u91cd\u70b9\u662f\u4f7f\u5f97\u9006\u53d8\u6362\u53ef\u4ee5\u540c\u6837\u901a\u8fc7ODE\u65f6\u95f4\u4e0a\u76f8\u53cd\u7684\u4e00\u4e2aforward pass\u5b9e\u73b0\u3002 Variational auto-encoder \u539f\u6587 .VAE\u4e2d\uff0c z \u662flatent space,\u5305\u542b\u4e00\u4e2a\u63cf\u8ff0 P_\\theta(X|z) \u4f5c\u4e3adecoder,\u8fd8\u5b66\u4e60\u4e00\u4e2aencoder Q_\\phi(z|X) ,\u5b83\u4eec\u5171\u540c\u8bad\u7ec3\u53bb\u6700\u5927\u5316\u89c2\u5bdf\u5668\u7684log-likelihood \\begin{aligned} \\log P_{\\theta}(X) & \\geq \\log P_{\\theta}(X)-D_{K L}\\left(Q_{\\phi}(z | X) \\| P_{\\theta}(z | X)\\right) \\\\ &=\\mathbb{E}_{Q_{\\phi}(z | x)}\\left[\\log P_{\\theta}(X | z)\\right]-D_{K L}\\left(Q_{\\phi}(z | X) \\| P_{\\psi}(z)\\right) \\\\ & \\triangleq \\mathcal{L}(X ; \\phi, \\psi, \\theta) \\end{aligned} z = \\mu_phi(X) + \\sigma_\\phi(X) \\epsilon .\u8fd9\u4e2a\u5747\u503c\u4e0e\u65b9\u5dee\u90fd\u662f\u7f51\u7edc\u76f4\u63a5\u7684\u8f93\u51fa\u3002 \u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5 \u9996\u5148\u5305\u542b\u4e09\u4e2a\u6a21\u5757\uff0c\u7b2c\u4e00\u4e2a\u662fencoder\uff0c Q_\\phi(z|X) ,\u5c06\u70b9\u4e91\u7f16\u7801\u4e3a\u4e00\u4e2a\u9690\u53d8\u91cf z ,\u4e00\u4e2a\u5148\u9a8c P\\psi(z) over shapes.\u7136\u540e\u4e00\u4e2adecoder, P_\\theta(X|z) . point generation from shape representations \\log P_{\\theta}(X | z)=\\sum_{x \\in X} \\log P_{\\theta}(x | z) \u5177\u4f53\u6765\u8bf4\uff0c\u4e00\u4e2a\u5728\u96c6\u5408 X \u4e2d\u7684\u70b9 x \uff0c\u662f\u4f7f\u7528CNF conditioned on z ,\u8f6c\u6362 y(t_0) \u7684\u7ed3\u679c,\u4e5f\u5c31\u662fneural ODE\u7684forward pass\u3002 x=G_{\\theta}\\left(y\\left(t_{0}\\right) ; z\\right) \\triangleq y\\left(t_{0}\\right)+\\int_{t_{0}}^{t_{1}} g_{\\theta}(y(t), t, z) d t, y\\left(t_{0}\\right) \\sim P(y) \u8fd9\u91cc g_\\theta \u5b9a\u4e49\u4e3aflow G_\\theta \u7684\u8fde\u7eed\u52a8\u529b\u5b66\u3002 G_{\\theta}^{-1}(x ; z)=x+\\int_{t_{1}}^{t_{0}} g_{\\theta}(y(t), t, z) d t with y(t_1)=x Flow-based \u5148\u9a8c over shapes \u56de\u987eKL-divergence(\u76f8\u5bf9\u71b5)\uff0c D_{KL}(p||q) = H(p, q) - H(p) forward\u65f6: z=F_{\\psi}\\left(w\\left(t_{0}\\right)\\right) \\triangleq w\\left(t_{0}\\right)+\\int_{t_{0}}^{t_{1}} f_{\\psi}(w(t), t) d t, w\\left(t_{0}\\right) \\sim P(w) \u6700\u7ec8training \u76ee\u6807 ELBO:VAE\u76ee\u6807 \\begin{aligned} \\mathcal{L}(X ; \\phi, \\psi, \\theta) &=\\mathbb{E}_{Q_{\\phi}(z | x)}\\left[\\log P_{\\psi}(z)+\\log P_{\\theta}(X | z)\\right]+H\\left[Q_{\\phi}(z | X)\\right] \\\\ &=\\mathbb{E}_{Q_{\\phi}(z | X)}\\left[\\log P\\left(F_{\\psi}^{-1}(z)\\right)-\\int_{t_{0}}^{t_{1}} \\operatorname{Tr}\\left(\\frac{\\partial f_{\\psi}}{\\partial w(t)}\\right) d t\\right.\\\\ &\\left.+\\sum_{x \\in X}\\left(\\log P\\left(G_{\\theta}^{-1}(x ; z)\\right)-\\int_{t_{0}}^{t_{1}} \\operatorname{Tr}\\left(\\frac{\\partial g_{\\theta}}{\\partial y(t)}\\right) d t\\right)\\right] \\\\ &+H\\left[Q_{\\phi}(z | X)\\right] \\end{aligned} \u53ef\u4ee5\u5206\u89e3\u4e3a\u4e09\u4e2a\u90e8\u5206 Prior:\u9f13\u52b1\u5927\u6982\u7387\uff0c\u8f83\u786e\u5b9a\u7684\u7ed3\u679c(\u8fd9\u91cc\u7528\u5355\u6b21\u8499\u7279\u5361\u6d1b\u91c7\u6837\u5bf9\u90a3\u4e2a\u671f\u671b\u8fdb\u884c\u4f30\u8ba1) \\mathbb{E}_{Q_{\\phi}(z | x)}\\left[\\log P_{\\psi}(z)\\right] \\approx \\frac{1}{L} \\sum_{l=1}^{L} \\log P_{\\psi}\\left(\\mu+\\epsilon_{l} \\odot \\sigma\\right) Reconstruction: \\mathcal{L}_{\\mathrm{recon}}(X ; \\theta, \\phi) \\triangleq \\mathbb{E}_{Q_{\\phi}}(z | x)\\left[\\log P_{\\theta}(X | z)\\right] Posterior Entropy: \\mathcal{L}_{\\mathrm{ent}}(X ; \\phi) \\triangleq H\\left[Q_{\\phi}(z | X)\\right]=\\frac{d}{2}(1+\\ln (2 \\pi))+\\sum_{i=1}^{d} \\ln \\sigma_{i} \u672c\u6587\u6a21\u578b\u9700\u8981\u6700\u5927\u5316\u8fd9\u4e2a\u76ee\u6807\u3002 \u603b\u89c8 \u8fdb\u4e00\u6b65\u7ec6\u8282\u89e3\u91ca\uff1a \u56fe\u4e2d\u7684 Q_\\phi \u4e3a\u7c7b\u4f3cpointNet\u7ed3\u6784\u7684\uff0cencoder\uff0c\u662f\u4e00\u7ef4\u5377\u79ef\uff0c\u6700\u540e\u5168\u8fde\u63a5\u8f93\u51fa\u4e24\u4e2a D_z \u7ef4\u5ea6\u7684\u5747\u503c\u4e0e\u65b9\u5dee\u9884\u6d4b f_\\phi \u4f7f\u7528\u7684\u662f FFJORD ,\u91cc\u9762\u4f7f\u7528\u4e86\u4e09\u4e2aconcatsquash\u5c42 \\mathrm{CS}(x, t)=\\left(W_{x} x+b_{x}\\right) \\sigma\\left(W_{t} t+b_{t}\\right)+\\left(W_{b} t+b_{b} t\\right) g_\\theta \u5904\u62d3\u5c55\u4e86concatsquash\u5c42\u4ee5\u4f7f\u5f97\u7ed3\u679c\u4e0ez\u76f8\u5173 \\begin{aligned} \\operatorname{CCS}(x, z, t)=&\\left(W_{x} x+b_{x}\\right) \\sigma\\left(W_{t t} t+W_{t z} z+b_{t}\\right) \\\\ &+\\left(W_{b t} t+W_{b z} z+b_{b} t\\right) \\end{aligned}","title":"PointFlow : 3D Point Cloud Generation with Continuous Normalizing Flows"},{"location":"other_categories/others/PointFlow : 3D Point Cloud Generation with Continuous Normalizing Flows/#pointflow-3d-point-cloud-generation-with-continuous-normalizing-flows","text":"\u8fd9\u7bc7\u8bba\u6587\u6709\u4e00\u4e2a project page \uff0c\u6839\u636e \u89c6\u9891 \u5b8c\u6210\u7684\u4e00\u4e2a\u4efb\u52a1\u53ef\u4ee5\u8fd9\u6837\u63cf\u8ff0\u3002\u6bcf\u4e00\u4e2a\u7269\u4f53\u7684\u4e00\u79cd\u70b9\u4e91\u8868\u8fbe\u53ef\u4ee5\u7406\u89e3\u4e3a\u4ece\u4e00\u4e2a\u7531\u5f62\u72b6\u51b3\u5b9a\u7684\u6982\u7387\u5206\u5e03\u91c7\u6837\u70b9\u3002\u6211\u4eec\u53ef\u4ee5\u5229\u7528\u4e00\u4e2a\u5750\u6807\u8f6c\u6362\u51fd\u6570\uff0c\u5c06\u9ad8\u65af\u91c7\u6837\u70b9\u4e91\u8f6c\u6362\u4e3a\u6700\u540e\u7684\u8f93\u51fa\u3002\u672c\u6587\u7ed9\u51fa\u7684\u7f51\u7edc\u53ef\u4ee5\u6839\u636e\u7c7b\u522b\uff0c\u4ee5\u53ca\u4e00\u4e9b\u968f\u673a\u6570\uff0c\u91c7\u6837\u51fa\u4e0d\u540c\u5f62\u72b6\u7684\u4e00\u4e2a\u5750\u6807\u8f6c\u6362\u51fd\u6570\u3002","title":"PointFlow : 3D Point Cloud Generation with Continuous Normalizing Flows"},{"location":"other_categories/others/PointFlow : 3D Point Cloud Generation with Continuous Normalizing Flows/#background-continuous-normalizing-flow","text":"\u5b9a\u4e49 f_1,...,f_n \u6307\u4ee3\u4e00\u7cfb\u5217\u7684\u53ef\u9006\u53d8\u6362\u3002\u8f93\u5165\u9690\u53d8\u91cf y \u7684\u6982\u7387\u5206\u5e03\u4e3a P(y) . x=f_{n} \\circ f_{n-1} \\circ \\cdots \\circ f_{1}(y) \u4f5c\u4e3a\u8f93\u51fa\u3002\u8f93\u51fa\u53d8\u91cf\u7684\u6982\u7387\u5bc6\u5ea6\u5219\u53d8\u4e3a \\log P(x)=\\log P(y)-\\sum_{k=1}^{n} \\log \\left|\\operatorname{det} \\frac{\\partial f_{k}}{\\partial y_{k-1}}\\right| \u8fd9\u6837 y \u53ef\u4ee5\u4ece x \u4f7f\u7528inverse flow\u8ba1\u7b97: y=f_{1}^{-1} \\circ \\cdots \\circ f_{n}^{-1}(x) . \u8fd9\u91cc f_1,...,f_n \u5728\u8fd9\u91cc\u5b9e\u4f53\u5316\u4f5c\u4e3a\u795e\u7ecf\u7f51\u7edc\uff0c\u8fd9\u6837\u5bfc\u6570\u7684\u884c\u5217\u5f0f\u8ba1\u7b97\u96be\u5ea6\u4e0d\u5927\u3002 continuous normalizing flow(CNF) for P(x) \u5c31\u662f x=y\\left(t_{0}\\right)+\\int_{t_{0}}^{t_{1}} f(y(t), t) d t, \\quad y\\left(t_{0}\\right) \\sim P(y) \\log P(x)=\\log P\\left(y\\left(t_{0}\\right)\\right)-\\int_{t_{0}}^{t_{1}} \\operatorname{Tr}\\left(\\frac{\\partial f}{\\partial y(t)}\\right) d t inverse flow y(t_0) = x + \\int^{t_0}_{t_1}f(y(t),t)dt .\u8fd9\u91cc\u7684 f \u4ecd\u7136\u662f\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc,\u7528ODE\u6c42\u89e3\u5668\u4f5c\u4e3a\u8f93\u51fa\u3002\u8fd9\u91cc\u7684\u5173\u952e\u601d\u7ef4\u8f6c\u53d8\u662f\u5229\u7528\u4e86\uff0c Neural Ordinary Equation \u7684\u601d\u8def\uff0c\u5c06\u8fde\u7eed\u53e0\u5c42\u7684\u5171\u4eab\u6743\u91cd\u7684\u795e\u7ecf\u7f51\u7edc\u7528\u5e38\u5fae\u5206\u65b9\u7a0b\u4ee3\u66ff.\u7528\u8fd9\u4e2aneural ODE\u7684\u4e00\u4e2a\u91cd\u70b9\u662f\u4f7f\u5f97\u9006\u53d8\u6362\u53ef\u4ee5\u540c\u6837\u901a\u8fc7ODE\u65f6\u95f4\u4e0a\u76f8\u53cd\u7684\u4e00\u4e2aforward pass\u5b9e\u73b0\u3002","title":"Background: Continuous normalizing flow"},{"location":"other_categories/others/PointFlow : 3D Point Cloud Generation with Continuous Normalizing Flows/#variational-auto-encoder","text":"\u539f\u6587 .VAE\u4e2d\uff0c z \u662flatent space,\u5305\u542b\u4e00\u4e2a\u63cf\u8ff0 P_\\theta(X|z) \u4f5c\u4e3adecoder,\u8fd8\u5b66\u4e60\u4e00\u4e2aencoder Q_\\phi(z|X) ,\u5b83\u4eec\u5171\u540c\u8bad\u7ec3\u53bb\u6700\u5927\u5316\u89c2\u5bdf\u5668\u7684log-likelihood \\begin{aligned} \\log P_{\\theta}(X) & \\geq \\log P_{\\theta}(X)-D_{K L}\\left(Q_{\\phi}(z | X) \\| P_{\\theta}(z | X)\\right) \\\\ &=\\mathbb{E}_{Q_{\\phi}(z | x)}\\left[\\log P_{\\theta}(X | z)\\right]-D_{K L}\\left(Q_{\\phi}(z | X) \\| P_{\\psi}(z)\\right) \\\\ & \\triangleq \\mathcal{L}(X ; \\phi, \\psi, \\theta) \\end{aligned} z = \\mu_phi(X) + \\sigma_\\phi(X) \\epsilon .\u8fd9\u4e2a\u5747\u503c\u4e0e\u65b9\u5dee\u90fd\u662f\u7f51\u7edc\u76f4\u63a5\u7684\u8f93\u51fa\u3002","title":"Variational auto-encoder"},{"location":"other_categories/others/PointFlow : 3D Point Cloud Generation with Continuous Normalizing Flows/#_1","text":"\u9996\u5148\u5305\u542b\u4e09\u4e2a\u6a21\u5757\uff0c\u7b2c\u4e00\u4e2a\u662fencoder\uff0c Q_\\phi(z|X) ,\u5c06\u70b9\u4e91\u7f16\u7801\u4e3a\u4e00\u4e2a\u9690\u53d8\u91cf z ,\u4e00\u4e2a\u5148\u9a8c P\\psi(z) over shapes.\u7136\u540e\u4e00\u4e2adecoder, P_\\theta(X|z) .","title":"\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5"},{"location":"other_categories/others/PointFlow : 3D Point Cloud Generation with Continuous Normalizing Flows/#point-generation-from-shape-representations","text":"\\log P_{\\theta}(X | z)=\\sum_{x \\in X} \\log P_{\\theta}(x | z) \u5177\u4f53\u6765\u8bf4\uff0c\u4e00\u4e2a\u5728\u96c6\u5408 X \u4e2d\u7684\u70b9 x \uff0c\u662f\u4f7f\u7528CNF conditioned on z ,\u8f6c\u6362 y(t_0) \u7684\u7ed3\u679c,\u4e5f\u5c31\u662fneural ODE\u7684forward pass\u3002 x=G_{\\theta}\\left(y\\left(t_{0}\\right) ; z\\right) \\triangleq y\\left(t_{0}\\right)+\\int_{t_{0}}^{t_{1}} g_{\\theta}(y(t), t, z) d t, y\\left(t_{0}\\right) \\sim P(y) \u8fd9\u91cc g_\\theta \u5b9a\u4e49\u4e3aflow G_\\theta \u7684\u8fde\u7eed\u52a8\u529b\u5b66\u3002 G_{\\theta}^{-1}(x ; z)=x+\\int_{t_{1}}^{t_{0}} g_{\\theta}(y(t), t, z) d t with y(t_1)=x","title":"point generation from shape representations"},{"location":"other_categories/others/PointFlow : 3D Point Cloud Generation with Continuous Normalizing Flows/#flow-based-over-shapes","text":"\u56de\u987eKL-divergence(\u76f8\u5bf9\u71b5)\uff0c D_{KL}(p||q) = H(p, q) - H(p) forward\u65f6: z=F_{\\psi}\\left(w\\left(t_{0}\\right)\\right) \\triangleq w\\left(t_{0}\\right)+\\int_{t_{0}}^{t_{1}} f_{\\psi}(w(t), t) d t, w\\left(t_{0}\\right) \\sim P(w)","title":"Flow-based \u5148\u9a8c over shapes"},{"location":"other_categories/others/PointFlow : 3D Point Cloud Generation with Continuous Normalizing Flows/#training","text":"ELBO:VAE\u76ee\u6807 \\begin{aligned} \\mathcal{L}(X ; \\phi, \\psi, \\theta) &=\\mathbb{E}_{Q_{\\phi}(z | x)}\\left[\\log P_{\\psi}(z)+\\log P_{\\theta}(X | z)\\right]+H\\left[Q_{\\phi}(z | X)\\right] \\\\ &=\\mathbb{E}_{Q_{\\phi}(z | X)}\\left[\\log P\\left(F_{\\psi}^{-1}(z)\\right)-\\int_{t_{0}}^{t_{1}} \\operatorname{Tr}\\left(\\frac{\\partial f_{\\psi}}{\\partial w(t)}\\right) d t\\right.\\\\ &\\left.+\\sum_{x \\in X}\\left(\\log P\\left(G_{\\theta}^{-1}(x ; z)\\right)-\\int_{t_{0}}^{t_{1}} \\operatorname{Tr}\\left(\\frac{\\partial g_{\\theta}}{\\partial y(t)}\\right) d t\\right)\\right] \\\\ &+H\\left[Q_{\\phi}(z | X)\\right] \\end{aligned} \u53ef\u4ee5\u5206\u89e3\u4e3a\u4e09\u4e2a\u90e8\u5206 Prior:\u9f13\u52b1\u5927\u6982\u7387\uff0c\u8f83\u786e\u5b9a\u7684\u7ed3\u679c(\u8fd9\u91cc\u7528\u5355\u6b21\u8499\u7279\u5361\u6d1b\u91c7\u6837\u5bf9\u90a3\u4e2a\u671f\u671b\u8fdb\u884c\u4f30\u8ba1) \\mathbb{E}_{Q_{\\phi}(z | x)}\\left[\\log P_{\\psi}(z)\\right] \\approx \\frac{1}{L} \\sum_{l=1}^{L} \\log P_{\\psi}\\left(\\mu+\\epsilon_{l} \\odot \\sigma\\right) Reconstruction: \\mathcal{L}_{\\mathrm{recon}}(X ; \\theta, \\phi) \\triangleq \\mathbb{E}_{Q_{\\phi}}(z | x)\\left[\\log P_{\\theta}(X | z)\\right] Posterior Entropy: \\mathcal{L}_{\\mathrm{ent}}(X ; \\phi) \\triangleq H\\left[Q_{\\phi}(z | X)\\right]=\\frac{d}{2}(1+\\ln (2 \\pi))+\\sum_{i=1}^{d} \\ln \\sigma_{i} \u672c\u6587\u6a21\u578b\u9700\u8981\u6700\u5927\u5316\u8fd9\u4e2a\u76ee\u6807\u3002","title":"\u6700\u7ec8training \u76ee\u6807"},{"location":"other_categories/others/PointFlow : 3D Point Cloud Generation with Continuous Normalizing Flows/#_2","text":"\u8fdb\u4e00\u6b65\u7ec6\u8282\u89e3\u91ca\uff1a \u56fe\u4e2d\u7684 Q_\\phi \u4e3a\u7c7b\u4f3cpointNet\u7ed3\u6784\u7684\uff0cencoder\uff0c\u662f\u4e00\u7ef4\u5377\u79ef\uff0c\u6700\u540e\u5168\u8fde\u63a5\u8f93\u51fa\u4e24\u4e2a D_z \u7ef4\u5ea6\u7684\u5747\u503c\u4e0e\u65b9\u5dee\u9884\u6d4b f_\\phi \u4f7f\u7528\u7684\u662f FFJORD ,\u91cc\u9762\u4f7f\u7528\u4e86\u4e09\u4e2aconcatsquash\u5c42 \\mathrm{CS}(x, t)=\\left(W_{x} x+b_{x}\\right) \\sigma\\left(W_{t} t+b_{t}\\right)+\\left(W_{b} t+b_{b} t\\right) g_\\theta \u5904\u62d3\u5c55\u4e86concatsquash\u5c42\u4ee5\u4f7f\u5f97\u7ed3\u679c\u4e0ez\u76f8\u5173 \\begin{aligned} \\operatorname{CCS}(x, z, t)=&\\left(W_{x} x+b_{x}\\right) \\sigma\\left(W_{t t} t+W_{t z} z+b_{t}\\right) \\\\ &+\\left(W_{b t} t+W_{b z} z+b_{b} t\\right) \\end{aligned}","title":"\u603b\u89c8"},{"location":"other_categories/others/R2D2/","text":"R2D2: Repeatable and Reliable Detector and Descriptor \u8fd9\u7bc7paper\u5728\u8f93\u51fakeypoints\u7684\u65f6\u5019\u8f93\u51fa\u4e24\u4e2a\u5206\u652f\u9884\u6d4b\u5176\u91cd\u590d\u6027\u4ee5\u53ca\u53ef\u9760\u6027\u3002paper\u7684\u4e3b\u8981\u8d21\u732e\u6709\u4e24\u70b9\uff0c\u7b2c\u4e00\u5728\u4e8e\u5224\u65ad\u8ba4\u4e3a\u6709\u5fc5\u8981\u5c06\u53ef\u9760\u6027\u4e0e\u53ef\u91cd\u590d\u6027\u5206\u6210\u4e24\u4e2a\u5355\u72ec\u7684metrics\u8fdb\u884c\u9884\u6d4b\uff0c\u4e14\u4f7f\u7528\u4e0d\u540c\u7684\u8bad\u7ec3\u65b9\u5f0f\u3002\u7b2c\u4e8c\u5728\u4e8e\u4f7f\u7528metric learning\u8bad\u7ec3\u53ef\u9760\u6027\u4e0e\u51c6\u786e\u5ea6(\u4e0d\u7b97\u72ec\u521b\u4f46\u662f\u5c5e\u4e8e\u6709\u6548\u7684\u878d\u5408) \u7f51\u7edc\u7ed3\u6784 \u53ef\u91cd\u590d\u6027 \u53ef\u91cd\u590d\u6027\u8fd9\u91cc\u4e0e\u5176\u4ed6\u505a\u6cd5\u76f8\u4f3c\uff0c\u9009\u62e9\u7684\u662f\u81ea\u76d1\u7763\u5b66\u4e60\u7684\u65b9\u6cd5\u3002 \u5bf9\u4e8e\u4e24\u5f20\u5df2\u77e5correspondence\u7684\u56fe\uff0c\u635f\u5931\u7684\u76ee\u7684\u662f\u8ba9\u4e24\u5f20\u56fe\u5bf9\u5e94\u7684\u90e8\u5206\u6709\u8f83\u9ad8\u7684\u76f8\u4f3c\u5ea6(cosine similarity)\uff0c \\mathcal{L}_{\\operatorname{cosim}}\\left(I, I^{\\prime}, U\\right)=1-\\frac{1}{|\\mathcal{P}|} \\sum_{p \\in \\mathcal{P}} \\operatorname{cosim}\\left(\\boldsymbol{S}[p], \\boldsymbol{S}_{U}^{\\prime}[p]\\right) \u8fd9\u4f1a\u6709\u4e00\u4e2atrivial\u7684\u89e3\u5c31\u662f\u6240\u6709\u503c\u4e3a\u5e38\u6570\uff0c\u6240\u4ee5\u7ed9\u51fa\u4e00\u4e2a\u8865\u5145\u7684\u635f\u5931\u51fd\u6570\u8981\u6c42\u63d0\u5347\u533a\u57df\u5185\u6700\u5927\u503c\u4e0e\u5747\u503c\u7684\u5dee \\mathcal{L}_{\\text {peaky}}(I)=1-\\frac{1}{|\\mathcal{P}|} \\sum_{p \\in \\mathcal{P}}\\left(\\max _{(i, j) \\in p} \\boldsymbol{S}_{i j}-\\operatorname{mean}_{(i, j) \\in p} \\boldsymbol{S}_{i j}\\right) \u53ef\u9760\u6027 \u5373\u8981\u6c42\u5339\u914d\u7684\u51c6\u786e\u5ea6\u63d0\u5347\uff0c\u8fd9\u91cc\u5f15\u7528\u4e86 Local Descriptors Optimized for Average Precision.pdf \u7684\u505a\u6cd5\u3002\u5176\u4e2d\u4e24\u4e2ahistogram\u4e4b\u95f4\u7684loss\u6765\u81ea\u4e8e Learning Deep Embeddings with Histogram Loss.pdf code in here","title":"R2D2: Repeatable and Reliable Detector and Descriptor"},{"location":"other_categories/others/R2D2/#r2d2-repeatable-and-reliable-detector-and-descriptor","text":"\u8fd9\u7bc7paper\u5728\u8f93\u51fakeypoints\u7684\u65f6\u5019\u8f93\u51fa\u4e24\u4e2a\u5206\u652f\u9884\u6d4b\u5176\u91cd\u590d\u6027\u4ee5\u53ca\u53ef\u9760\u6027\u3002paper\u7684\u4e3b\u8981\u8d21\u732e\u6709\u4e24\u70b9\uff0c\u7b2c\u4e00\u5728\u4e8e\u5224\u65ad\u8ba4\u4e3a\u6709\u5fc5\u8981\u5c06\u53ef\u9760\u6027\u4e0e\u53ef\u91cd\u590d\u6027\u5206\u6210\u4e24\u4e2a\u5355\u72ec\u7684metrics\u8fdb\u884c\u9884\u6d4b\uff0c\u4e14\u4f7f\u7528\u4e0d\u540c\u7684\u8bad\u7ec3\u65b9\u5f0f\u3002\u7b2c\u4e8c\u5728\u4e8e\u4f7f\u7528metric learning\u8bad\u7ec3\u53ef\u9760\u6027\u4e0e\u51c6\u786e\u5ea6(\u4e0d\u7b97\u72ec\u521b\u4f46\u662f\u5c5e\u4e8e\u6709\u6548\u7684\u878d\u5408)","title":"R2D2: Repeatable and Reliable Detector and Descriptor"},{"location":"other_categories/others/R2D2/#_1","text":"","title":"\u7f51\u7edc\u7ed3\u6784"},{"location":"other_categories/others/R2D2/#_2","text":"\u53ef\u91cd\u590d\u6027\u8fd9\u91cc\u4e0e\u5176\u4ed6\u505a\u6cd5\u76f8\u4f3c\uff0c\u9009\u62e9\u7684\u662f\u81ea\u76d1\u7763\u5b66\u4e60\u7684\u65b9\u6cd5\u3002 \u5bf9\u4e8e\u4e24\u5f20\u5df2\u77e5correspondence\u7684\u56fe\uff0c\u635f\u5931\u7684\u76ee\u7684\u662f\u8ba9\u4e24\u5f20\u56fe\u5bf9\u5e94\u7684\u90e8\u5206\u6709\u8f83\u9ad8\u7684\u76f8\u4f3c\u5ea6(cosine similarity)\uff0c \\mathcal{L}_{\\operatorname{cosim}}\\left(I, I^{\\prime}, U\\right)=1-\\frac{1}{|\\mathcal{P}|} \\sum_{p \\in \\mathcal{P}} \\operatorname{cosim}\\left(\\boldsymbol{S}[p], \\boldsymbol{S}_{U}^{\\prime}[p]\\right) \u8fd9\u4f1a\u6709\u4e00\u4e2atrivial\u7684\u89e3\u5c31\u662f\u6240\u6709\u503c\u4e3a\u5e38\u6570\uff0c\u6240\u4ee5\u7ed9\u51fa\u4e00\u4e2a\u8865\u5145\u7684\u635f\u5931\u51fd\u6570\u8981\u6c42\u63d0\u5347\u533a\u57df\u5185\u6700\u5927\u503c\u4e0e\u5747\u503c\u7684\u5dee \\mathcal{L}_{\\text {peaky}}(I)=1-\\frac{1}{|\\mathcal{P}|} \\sum_{p \\in \\mathcal{P}}\\left(\\max _{(i, j) \\in p} \\boldsymbol{S}_{i j}-\\operatorname{mean}_{(i, j) \\in p} \\boldsymbol{S}_{i j}\\right)","title":"\u53ef\u91cd\u590d\u6027"},{"location":"other_categories/others/R2D2/#_3","text":"\u5373\u8981\u6c42\u5339\u914d\u7684\u51c6\u786e\u5ea6\u63d0\u5347\uff0c\u8fd9\u91cc\u5f15\u7528\u4e86 Local Descriptors Optimized for Average Precision.pdf \u7684\u505a\u6cd5\u3002\u5176\u4e2d\u4e24\u4e2ahistogram\u4e4b\u95f4\u7684loss\u6765\u81ea\u4e8e Learning Deep Embeddings with Histogram Loss.pdf code in here","title":"\u53ef\u9760\u6027"},{"location":"other_categories/others/SPM_SPR/","text":"Single-Stage Multi-Person Pose Machines \u4e0a\u9762\u7ed9\u51fa\u7684\u5f00\u6e90\u4ee3\u7801\u662f\u975e\u5b98\u65b9\uff0c\u4f5c\u8005\u7ed9\u51fa\u4e86\u89e3\u8bfb\u8fd9\u7bc7paper\u7684 csdn blog , \u6838\u5fc3\u601d\u8def\u5c31\u662f\u5c06\u80a2\u4f53\u5173\u8282\u7684\u56de\u5f52\u5206\u6210\u4e24\u90e8\u5206\uff0c\u4e00\u4e2a\u662froot\uff0c\u4e5f\u5c31\u662f\u4e2d\u5fc3\u70b9\u7684\u4f30\u8ba1\uff0c\u8fd9\u4e2a\u7528heat-map regression\u5b9e\u73b0\u3002\u53e6\u4e00\u4e2a\u662f\u6811\u72b6\u7684\uff0c\u5404\u4e2a\u80a2\u4f53\u5173\u8282\u70b9\u4e0e\u5176\u76f8\u90bb\u7236\u5173\u8282\u70b9\u7684\u76f8\u5bf9\u4f4d\u79fb\u3002\u4f5c\u8005\u603b\u5171\u5206\u4e3a5\u4e2a\u6811\uff0c root->neck->head root->left/right shoulder->left/right elbow->left/right wrist root->left/right hip->left/right knee->left/right ankle \u63a8\u65ad\u7684\u65f6\u5019\u4ec5\u9700\u8981\u9884\u6d4broot\uff0c\u5e76\u901a\u8fc7\u76f8\u5bf9\u4f4d\u79fb\u5904\u7406\u5373\u53ef\u3002\u6700\u7ec8\u7f51\u7edc\u662f\u5355\u9636\u6bb5\u7684\u63a8\u7406\u3002","title":"Single-Stage Multi-Person Pose Machines"},{"location":"other_categories/others/SPM_SPR/#single-stage-multi-person-pose-machines","text":"\u4e0a\u9762\u7ed9\u51fa\u7684\u5f00\u6e90\u4ee3\u7801\u662f\u975e\u5b98\u65b9\uff0c\u4f5c\u8005\u7ed9\u51fa\u4e86\u89e3\u8bfb\u8fd9\u7bc7paper\u7684 csdn blog , \u6838\u5fc3\u601d\u8def\u5c31\u662f\u5c06\u80a2\u4f53\u5173\u8282\u7684\u56de\u5f52\u5206\u6210\u4e24\u90e8\u5206\uff0c\u4e00\u4e2a\u662froot\uff0c\u4e5f\u5c31\u662f\u4e2d\u5fc3\u70b9\u7684\u4f30\u8ba1\uff0c\u8fd9\u4e2a\u7528heat-map regression\u5b9e\u73b0\u3002\u53e6\u4e00\u4e2a\u662f\u6811\u72b6\u7684\uff0c\u5404\u4e2a\u80a2\u4f53\u5173\u8282\u70b9\u4e0e\u5176\u76f8\u90bb\u7236\u5173\u8282\u70b9\u7684\u76f8\u5bf9\u4f4d\u79fb\u3002\u4f5c\u8005\u603b\u5171\u5206\u4e3a5\u4e2a\u6811\uff0c root->neck->head root->left/right shoulder->left/right elbow->left/right wrist root->left/right hip->left/right knee->left/right ankle \u63a8\u65ad\u7684\u65f6\u5019\u4ec5\u9700\u8981\u9884\u6d4broot\uff0c\u5e76\u901a\u8fc7\u76f8\u5bf9\u4f4d\u79fb\u5904\u7406\u5373\u53ef\u3002\u6700\u7ec8\u7f51\u7edc\u662f\u5355\u9636\u6bb5\u7684\u63a8\u7406\u3002","title":"Single-Stage Multi-Person Pose Machines"},{"location":"other_categories/others/SomePapersOnDifferentiableCvxOpt/","text":"Some Papers on Differentiable Convex Optimization \u5728\u8fd9\u4e2a\u9875\u9762\u8ba1\u5212\u8bb0\u5f55\u4e24\u7bc7\u5173\u4e8e\u53ef\u5fae\u5206\u51f8\u4f18\u5316\u7684\u7b97\u6cd5\u7684\u8bb0\u5f55.\u672c\u6587\u6b64\u5904\u4f1a\u5927\u81f4\u8bb0\u5f55\u4e09\u7bc7\u6587\u7ae0\u544a\u8bc9\u6211\u7684\u4e00\u4e9b\u65b0\u7684\u6982\u5ff5,\u5206\u522b\u662f\u4e00\u7bc7\u5173\u4e8e\u51f8\u4f18\u5316\u4ee5\u53caDisciplined convex programming\u7684\u7efc\u8ff0 (1) ,\u4e00\u7bc7\u5173\u4e8e\u51f8\u4f18\u5316\u7684\u5bfc\u6570\u7684paper (2) ,\u4e00\u7bc7\u4ecb\u7ecd[cvxlayers]\u7684paper (3) .\u5b83\u4eec\u90fd\u6765\u81ea\u4e8eStanford Boyd\u5927\u4f6c\u7684\u7ec4\u3002 Convex optimization and Disciplined Convex Programming \u4e00\u822c\u51f8\u4f18\u5316\u95ee\u9898\u5b9a\u4e49\uff1a \\begin{aligned} \\text { minimize } & f_{0}(x, \\theta) \\\\ & f(x, \\theta) \\preceq 0 \\\\ & h(x, \\theta)=0 \\end{aligned} \u7efc\u8ff0 (1) \u5bf9\u51f8\u4f18\u5316\u95ee\u9898\u7684\u7279\u6b8a\u60c5\u51b5(\u7ebf\u6027\u6700\u4f18\uff0c\u4e8c\u6b21\u6700\u4f18\uff0c\u6700\u5c0f\u4e8c\u4e58)\u8fdb\u884c\u5206\u7c7b\uff0c\u540c\u65f6\u6307\u51fa\u4e86\u4e13\u7528\u95ee\u9898\u4e13\u7528\u7b97\u6cd5\u4ee5\u53ca\u975e\u7ebf\u6027\u51f8\u4f18\u5316\u666e\u904d\u65b9\u6cd5\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u6307\u51fa\u4e86\u975e\u7ebf\u6027\u51f8\u4f18\u5316\u4e00\u822c\u65b9\u6cd5\u6bd4\u5982\u5185\u70b9\u6cd5\u5728\u6548\u7387\u4e0a\u5f80\u5f80\u4f1a\u548c\u7ebf\u6027\u6216\u4e8c\u6b21\u51f8\u4f18\u5316\u7b97\u6cd5\u76f8\u8fd1\uff0c\u539f\u56e0\u662f\u90fd\u5229\u7528\u4e86\u5c40\u90e8\u7684convexity. Disciplined Convex Programming\u5305\u542b\u4e24\u4e2a\u5185\u5bb9\uff0c\u4e00\u4e2a\u662f\u5c06\u7b26\u5408\u8981\u6c42\u7684\u51f8\u4f18\u5316\u95ee\u9898\u901a\u8fc7\u4e00\u7cfb\u5217\u539f\u5b50\u64cd\u4f5c\u5e76\u8f6c\u6362\u4e3a\u6807\u51c6\u95ee\u9898\uff0c\u53e6\u4e00\u4e2a\u662f\u4e00\u5957\u7528\u4e8e\u5224\u65ad\u7528\u6237\u8f93\u5165\u7684\u95ee\u9898\u662f\u5426\u4e3a\u7b26\u5408\u8981\u6c42\u7684DCP\u7684\u89c4\u5219\u7cfb\u7edf\u3002\u5728\u672c\u6587\u4f5c\u8005\u8be6\u7ec6\u63cf\u8ff0\u4e86DCP\u89c4\u5219\u7cfb\u7edf\u7684\u7b97\u6cd5\uff0c\u5e76\u63d0\u4f9b\u4e86\u51b3\u7b56\u6811\u4f8b\u5b50\u3002\u5728[cvxlayers]\u7684paper (3) \u4e2d\u4ee5\u53ca\u4ee3\u7801\u6587\u6863\u4e2d,\u6211\u4eec\u53ef\u4ee5\u77e5\u6653\u76ee\u524d\u5e93\u4e2d\u652f\u6301\u7684\u539f\u5b50\u64cd\u4f5c(\u7edd\u5927\u591a\u6570\u7684\u5355\u8c03\u51fd\u6570\u4ee5\u53ca\u591a\u9879\u5f0f\u51fd\u6570) \u57fa\u4e8eKKT condition\u7684 Convex optimization \u5bfc\u6570\u4f20\u9012 \u8fd9\u91cc\u91c7\u7528\u7684\u601d\u8def\u5f88\u63a5\u8fd1\u4e0e OptNet ,paper (2) \u5c06\u8fd9\u4e2a\u95ee\u9898\u7684\u89e3\u7b54\u62d3\u5c55\u5230\u8fd1\u4e4e\u4efb\u610f\u51f8\u4f18\u5316\u95ee\u9898\uff0c\u5728\u63a5\u8fd1\u6700\u4f18\u7684\u60c5\u51b5\u4e0b\uff0c\u4f7f\u7528KKT condition\u8fdb\u884c\u53cd\u4f20\u3002 KKT\u6761\u4ef6: \\begin{aligned} f(\\tilde{x}, \\theta) & \\preceq 0 \\\\ h(\\tilde{x}, \\theta) &=0 \\\\ \\tilde{\\lambda}_{i} & \\geq 0, \\quad i=1, \\ldots, m \\\\ \\tilde{\\lambda}_{i} f_{i}(\\tilde{x}, \\theta) &=0, \\quad i=1, \\ldots, m \\\\ \\nabla_{x} L(\\tilde{x}, \\tilde{\\lambda}, \\tilde{\\nu}, \\theta) &=0 \\end{aligned} \u5176\u4e2d \\mathcal{L} \u4e3a\u539f\u51fd\u6570\u52a0\u4e0a\u62c9\u683c\u6717\u65e5\u4e58\u5b50\uff0c\u4e3a: L(x, \\lambda, \\nu, \\theta)=f_{0}(x, \\theta)+\\lambda^{T} f(x, \\theta)+\\nu^{T} h(x, \\theta) \u518d\u5b9a\u4e49 g(z, \\theta)=\\left[\\begin{array}{c} {\\nabla_{x} L(x, \\lambda, \\nu, \\theta)} \\\\ {\\operatorname{diag}(\\lambda) f(x, \\theta)} \\\\ {h(x, \\theta)} \\end{array}\\right] \u4f5c\u8005\u6700\u7ec8\u7ed9\u51fa\u7684\u5bfc\u6570\u516c\u5f0f \\mathrm{D}_{z} g(\\tilde{z}, \\theta)=\\left[\\begin{array}{ccc} {\\mathrm{D}_{x} \\nabla_{x} L(\\tilde{x}, \\tilde{\\lambda}, \\tilde{\\nu}, \\theta)} & {\\mathrm{D}_{x} f(\\tilde{x}, \\theta)^{T}} & {\\mathrm{D}_{x} h(\\tilde{x}, \\theta)^{T}} \\\\ {\\operatorname{diag}(\\tilde{\\lambda}) \\mathrm{D}_{x} f(\\tilde{x}, \\theta)} & {\\operatorname{diag}(f(\\tilde{x}, \\theta))} & {0} \\\\ {\\mathrm{D}_{x} h(\\tilde{x}, \\theta)} & {0} & {0} \\end{array}\\right] \\mathrm{D}_{\\theta} g(\\tilde{z}, \\theta)=\\left[\\begin{array}{c} {\\mathrm{D}_{\\theta} \\nabla_{x} L(\\tilde{x}, \\tilde{\\lambda}, \\tilde{\\nu}, \\theta)} \\\\ {\\operatorname{diag}(\\tilde{\\lambda}) \\mathrm{D}_{\\theta} f(\\tilde{x}, \\theta)} \\\\ {\\mathrm{D}_{\\theta} h(\\tilde{x}, \\theta)} \\end{array}\\right] \\mathrm{D}_{\\theta} s(\\theta)=-\\mathrm{D}_{z} g(\\tilde{x}, \\tilde{\\lambda}, \\tilde{\\nu}, \\theta)^{-1} \\mathrm{D}_{\\theta} g(\\tilde{x}, \\tilde{\\lambda}, \\tilde{\\nu}, \\theta) \\text { for every } \\theta \\in Q \u8003\u8651\u4e8c\u6b21\u89c4\u5212\u4f5c\u4e3a\u672c\u6587\u7684\u7279\u6b8a\u60c5\u51b5\uff0c\u5e26\u5165\u516c\u5f0f\u6709 \\mathrm{D}_{x} g(\\tilde{x}, \\tilde{\\lambda}, \\tilde{\\nu}, \\theta)=\\left[\\begin{array}{ccc} {Q} & {G^{T}} & {A^{T}} \\\\ {\\operatorname{diag}(\\tilde{\\lambda}) G} & {\\operatorname{diag}(G \\tilde{x}-h)} & {0} \\\\ {A} & {0} & {0} \\end{array}\\right] \\mathrm{D}_{\\theta} g(\\dot{x}, \\tilde{\\lambda}, \\tilde{\\nu}, \\theta)=\\left[\\begin{array}{c} {\\mathrm{d} Q \\tilde{x}+\\mathrm{D}_{\\theta} q+\\mathrm{d} G^{T} \\tilde{\\lambda}+\\mathrm{d} A^{T} \\tilde{\\nu}} \\\\ {\\operatorname{diag}(\\lambda)\\left(\\mathrm{d} G \\tilde{x}-\\mathrm{D}_{\\theta} h\\right)} \\\\ {\\mathrm{d} A \\tilde{x}-\\mathrm{D}_{\\theta} b} \\end{array}\\right] \u6700\u7ec8\u7684\u516c\u5f0f\u4e0e OptNet \u662f\u4e00\u81f4\u7684 Convex Optimization as a Differentiable learnable layer \u57282019 NeurIPS\u7684paper (3) \u4e2d, \u4f5c\u8005\u5c06\u521d\u59cb\u89e3 x_0 ,\u6700\u4f18\u5316\u95ee\u9898\u53c2\u6570 \\theta ,\u6700\u7ec8\u8f93\u51fa s \u7406\u89e3\u4e3a\u795e\u7ecf\u7f51\u7edc\u5c42\u7684\u8f93\u5165\u3001\u53c2\u6570\u4ee5\u53ca\u8f93\u51fa\u3002\u8fdb\u4e00\u6b65\u5730\uff0c\u4f5c\u8005\u7cc5\u5408\u524d\u4e24\u4e2a\u7ae0\u8282\u7684idea,\u4f7f\u7528 Disciplined Convex Programming\u4f7f\u5f97\u7528\u6237\u5728\u8bbe\u8ba1\u4f18\u5316\u5c42\u7684\u65f6\u5019\u6709\u66f4\u9ad8\u7684\u81ea\u7531\u5ea6(\u4e0d\u518d\u53ea\u5c40\u9650\u4e8e\u4e00\u6b21\u6216\u4e8c\u6b21\u578b\u7b49\u7279\u6027)\uff0c\u8f93\u5165\u4e0e\u53c2\u6570\u5728\u5f62\u6210\u6210\u672c\u51fd\u6570\u4e0e\u7ea6\u675f\u7684\u8ba1\u7b97\u8fc7\u7a0b\u4e2d\u5141\u8bb8\u6309\u7167DCP\u89c4\u5219\u94fe\u63a5\u5927\u91cf\u7684\u539f\u5b50\u64cd\u4f5c\uff0c\u5f62\u6210\u66f4\u4e3a\u590d\u6742\u800c\u81ea\u7136\u7684\"\u4e00\u822c\"\u4f18\u5316\u95ee\u9898\u8f93\u5165(\u6ce8: cvxpylayers \u867d\u7136\u652f\u6301\u5f88\u591a\u522b\u7684\u51fd\u6570\uff0c\u4f46\u662f\u4e0d\u652f\u6301\u6b63\u4f59\u5f26\u51fd\u6570)\u3002\u4f7f\u7528KKT\u5f53\u4f18\u5316\u7ed3\u679c\u6536\u655b\u65f6\u5feb\u901f\u5730\u5b9e\u73b0\u53cd\u5411\u4f20\u64ad\u3002 \u4f5c\u8005\u5728 (3) \u7684\u9644\u5f55\u4e2d\u7ed9\u51fa\u4e86\u4f7f\u7528cvxpylayers\u7528\u6700\u4f18\u5316\u95ee\u9898\u5b9e\u73b0ReLU,Softmax\uff0cQP\u7b49\u95ee\u9898\u7684\u4ee3\u7801\u3002 cvxpylayers \u7684\u4ee3\u7801\u540c\u6837\u4e5f\u6709\u5f88\u591a\u7684\u4f8b\u7a0b,\u5728RL\u3001\u63a7\u5236\u3001\u7f51\u7edc\u540e\u4f18\u5316\u9886\u57df\u6709\u8f83\u5f3a\u7684\u4f7f\u7528\u7a7a\u95f4\u3002","title":"Some Papers on Differentiable Convex Optimization"},{"location":"other_categories/others/SomePapersOnDifferentiableCvxOpt/#some-papers-on-differentiable-convex-optimization","text":"\u5728\u8fd9\u4e2a\u9875\u9762\u8ba1\u5212\u8bb0\u5f55\u4e24\u7bc7\u5173\u4e8e\u53ef\u5fae\u5206\u51f8\u4f18\u5316\u7684\u7b97\u6cd5\u7684\u8bb0\u5f55.\u672c\u6587\u6b64\u5904\u4f1a\u5927\u81f4\u8bb0\u5f55\u4e09\u7bc7\u6587\u7ae0\u544a\u8bc9\u6211\u7684\u4e00\u4e9b\u65b0\u7684\u6982\u5ff5,\u5206\u522b\u662f\u4e00\u7bc7\u5173\u4e8e\u51f8\u4f18\u5316\u4ee5\u53caDisciplined convex programming\u7684\u7efc\u8ff0 (1) ,\u4e00\u7bc7\u5173\u4e8e\u51f8\u4f18\u5316\u7684\u5bfc\u6570\u7684paper (2) ,\u4e00\u7bc7\u4ecb\u7ecd[cvxlayers]\u7684paper (3) .\u5b83\u4eec\u90fd\u6765\u81ea\u4e8eStanford Boyd\u5927\u4f6c\u7684\u7ec4\u3002","title":"Some Papers on Differentiable Convex Optimization"},{"location":"other_categories/others/SomePapersOnDifferentiableCvxOpt/#convex-optimization-and-disciplined-convex-programming","text":"\u4e00\u822c\u51f8\u4f18\u5316\u95ee\u9898\u5b9a\u4e49\uff1a \\begin{aligned} \\text { minimize } & f_{0}(x, \\theta) \\\\ & f(x, \\theta) \\preceq 0 \\\\ & h(x, \\theta)=0 \\end{aligned} \u7efc\u8ff0 (1) \u5bf9\u51f8\u4f18\u5316\u95ee\u9898\u7684\u7279\u6b8a\u60c5\u51b5(\u7ebf\u6027\u6700\u4f18\uff0c\u4e8c\u6b21\u6700\u4f18\uff0c\u6700\u5c0f\u4e8c\u4e58)\u8fdb\u884c\u5206\u7c7b\uff0c\u540c\u65f6\u6307\u51fa\u4e86\u4e13\u7528\u95ee\u9898\u4e13\u7528\u7b97\u6cd5\u4ee5\u53ca\u975e\u7ebf\u6027\u51f8\u4f18\u5316\u666e\u904d\u65b9\u6cd5\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u6307\u51fa\u4e86\u975e\u7ebf\u6027\u51f8\u4f18\u5316\u4e00\u822c\u65b9\u6cd5\u6bd4\u5982\u5185\u70b9\u6cd5\u5728\u6548\u7387\u4e0a\u5f80\u5f80\u4f1a\u548c\u7ebf\u6027\u6216\u4e8c\u6b21\u51f8\u4f18\u5316\u7b97\u6cd5\u76f8\u8fd1\uff0c\u539f\u56e0\u662f\u90fd\u5229\u7528\u4e86\u5c40\u90e8\u7684convexity. Disciplined Convex Programming\u5305\u542b\u4e24\u4e2a\u5185\u5bb9\uff0c\u4e00\u4e2a\u662f\u5c06\u7b26\u5408\u8981\u6c42\u7684\u51f8\u4f18\u5316\u95ee\u9898\u901a\u8fc7\u4e00\u7cfb\u5217\u539f\u5b50\u64cd\u4f5c\u5e76\u8f6c\u6362\u4e3a\u6807\u51c6\u95ee\u9898\uff0c\u53e6\u4e00\u4e2a\u662f\u4e00\u5957\u7528\u4e8e\u5224\u65ad\u7528\u6237\u8f93\u5165\u7684\u95ee\u9898\u662f\u5426\u4e3a\u7b26\u5408\u8981\u6c42\u7684DCP\u7684\u89c4\u5219\u7cfb\u7edf\u3002\u5728\u672c\u6587\u4f5c\u8005\u8be6\u7ec6\u63cf\u8ff0\u4e86DCP\u89c4\u5219\u7cfb\u7edf\u7684\u7b97\u6cd5\uff0c\u5e76\u63d0\u4f9b\u4e86\u51b3\u7b56\u6811\u4f8b\u5b50\u3002\u5728[cvxlayers]\u7684paper (3) \u4e2d\u4ee5\u53ca\u4ee3\u7801\u6587\u6863\u4e2d,\u6211\u4eec\u53ef\u4ee5\u77e5\u6653\u76ee\u524d\u5e93\u4e2d\u652f\u6301\u7684\u539f\u5b50\u64cd\u4f5c(\u7edd\u5927\u591a\u6570\u7684\u5355\u8c03\u51fd\u6570\u4ee5\u53ca\u591a\u9879\u5f0f\u51fd\u6570)","title":"Convex optimization and Disciplined Convex Programming"},{"location":"other_categories/others/SomePapersOnDifferentiableCvxOpt/#kkt-condition-convex-optimization","text":"\u8fd9\u91cc\u91c7\u7528\u7684\u601d\u8def\u5f88\u63a5\u8fd1\u4e0e OptNet ,paper (2) \u5c06\u8fd9\u4e2a\u95ee\u9898\u7684\u89e3\u7b54\u62d3\u5c55\u5230\u8fd1\u4e4e\u4efb\u610f\u51f8\u4f18\u5316\u95ee\u9898\uff0c\u5728\u63a5\u8fd1\u6700\u4f18\u7684\u60c5\u51b5\u4e0b\uff0c\u4f7f\u7528KKT condition\u8fdb\u884c\u53cd\u4f20\u3002 KKT\u6761\u4ef6: \\begin{aligned} f(\\tilde{x}, \\theta) & \\preceq 0 \\\\ h(\\tilde{x}, \\theta) &=0 \\\\ \\tilde{\\lambda}_{i} & \\geq 0, \\quad i=1, \\ldots, m \\\\ \\tilde{\\lambda}_{i} f_{i}(\\tilde{x}, \\theta) &=0, \\quad i=1, \\ldots, m \\\\ \\nabla_{x} L(\\tilde{x}, \\tilde{\\lambda}, \\tilde{\\nu}, \\theta) &=0 \\end{aligned} \u5176\u4e2d \\mathcal{L} \u4e3a\u539f\u51fd\u6570\u52a0\u4e0a\u62c9\u683c\u6717\u65e5\u4e58\u5b50\uff0c\u4e3a: L(x, \\lambda, \\nu, \\theta)=f_{0}(x, \\theta)+\\lambda^{T} f(x, \\theta)+\\nu^{T} h(x, \\theta) \u518d\u5b9a\u4e49 g(z, \\theta)=\\left[\\begin{array}{c} {\\nabla_{x} L(x, \\lambda, \\nu, \\theta)} \\\\ {\\operatorname{diag}(\\lambda) f(x, \\theta)} \\\\ {h(x, \\theta)} \\end{array}\\right] \u4f5c\u8005\u6700\u7ec8\u7ed9\u51fa\u7684\u5bfc\u6570\u516c\u5f0f \\mathrm{D}_{z} g(\\tilde{z}, \\theta)=\\left[\\begin{array}{ccc} {\\mathrm{D}_{x} \\nabla_{x} L(\\tilde{x}, \\tilde{\\lambda}, \\tilde{\\nu}, \\theta)} & {\\mathrm{D}_{x} f(\\tilde{x}, \\theta)^{T}} & {\\mathrm{D}_{x} h(\\tilde{x}, \\theta)^{T}} \\\\ {\\operatorname{diag}(\\tilde{\\lambda}) \\mathrm{D}_{x} f(\\tilde{x}, \\theta)} & {\\operatorname{diag}(f(\\tilde{x}, \\theta))} & {0} \\\\ {\\mathrm{D}_{x} h(\\tilde{x}, \\theta)} & {0} & {0} \\end{array}\\right] \\mathrm{D}_{\\theta} g(\\tilde{z}, \\theta)=\\left[\\begin{array}{c} {\\mathrm{D}_{\\theta} \\nabla_{x} L(\\tilde{x}, \\tilde{\\lambda}, \\tilde{\\nu}, \\theta)} \\\\ {\\operatorname{diag}(\\tilde{\\lambda}) \\mathrm{D}_{\\theta} f(\\tilde{x}, \\theta)} \\\\ {\\mathrm{D}_{\\theta} h(\\tilde{x}, \\theta)} \\end{array}\\right] \\mathrm{D}_{\\theta} s(\\theta)=-\\mathrm{D}_{z} g(\\tilde{x}, \\tilde{\\lambda}, \\tilde{\\nu}, \\theta)^{-1} \\mathrm{D}_{\\theta} g(\\tilde{x}, \\tilde{\\lambda}, \\tilde{\\nu}, \\theta) \\text { for every } \\theta \\in Q \u8003\u8651\u4e8c\u6b21\u89c4\u5212\u4f5c\u4e3a\u672c\u6587\u7684\u7279\u6b8a\u60c5\u51b5\uff0c\u5e26\u5165\u516c\u5f0f\u6709 \\mathrm{D}_{x} g(\\tilde{x}, \\tilde{\\lambda}, \\tilde{\\nu}, \\theta)=\\left[\\begin{array}{ccc} {Q} & {G^{T}} & {A^{T}} \\\\ {\\operatorname{diag}(\\tilde{\\lambda}) G} & {\\operatorname{diag}(G \\tilde{x}-h)} & {0} \\\\ {A} & {0} & {0} \\end{array}\\right] \\mathrm{D}_{\\theta} g(\\dot{x}, \\tilde{\\lambda}, \\tilde{\\nu}, \\theta)=\\left[\\begin{array}{c} {\\mathrm{d} Q \\tilde{x}+\\mathrm{D}_{\\theta} q+\\mathrm{d} G^{T} \\tilde{\\lambda}+\\mathrm{d} A^{T} \\tilde{\\nu}} \\\\ {\\operatorname{diag}(\\lambda)\\left(\\mathrm{d} G \\tilde{x}-\\mathrm{D}_{\\theta} h\\right)} \\\\ {\\mathrm{d} A \\tilde{x}-\\mathrm{D}_{\\theta} b} \\end{array}\\right] \u6700\u7ec8\u7684\u516c\u5f0f\u4e0e OptNet \u662f\u4e00\u81f4\u7684","title":"\u57fa\u4e8eKKT condition\u7684 Convex optimization \u5bfc\u6570\u4f20\u9012"},{"location":"other_categories/others/SomePapersOnDifferentiableCvxOpt/#convex-optimization-as-a-differentiable-learnable-layer","text":"\u57282019 NeurIPS\u7684paper (3) \u4e2d, \u4f5c\u8005\u5c06\u521d\u59cb\u89e3 x_0 ,\u6700\u4f18\u5316\u95ee\u9898\u53c2\u6570 \\theta ,\u6700\u7ec8\u8f93\u51fa s \u7406\u89e3\u4e3a\u795e\u7ecf\u7f51\u7edc\u5c42\u7684\u8f93\u5165\u3001\u53c2\u6570\u4ee5\u53ca\u8f93\u51fa\u3002\u8fdb\u4e00\u6b65\u5730\uff0c\u4f5c\u8005\u7cc5\u5408\u524d\u4e24\u4e2a\u7ae0\u8282\u7684idea,\u4f7f\u7528 Disciplined Convex Programming\u4f7f\u5f97\u7528\u6237\u5728\u8bbe\u8ba1\u4f18\u5316\u5c42\u7684\u65f6\u5019\u6709\u66f4\u9ad8\u7684\u81ea\u7531\u5ea6(\u4e0d\u518d\u53ea\u5c40\u9650\u4e8e\u4e00\u6b21\u6216\u4e8c\u6b21\u578b\u7b49\u7279\u6027)\uff0c\u8f93\u5165\u4e0e\u53c2\u6570\u5728\u5f62\u6210\u6210\u672c\u51fd\u6570\u4e0e\u7ea6\u675f\u7684\u8ba1\u7b97\u8fc7\u7a0b\u4e2d\u5141\u8bb8\u6309\u7167DCP\u89c4\u5219\u94fe\u63a5\u5927\u91cf\u7684\u539f\u5b50\u64cd\u4f5c\uff0c\u5f62\u6210\u66f4\u4e3a\u590d\u6742\u800c\u81ea\u7136\u7684\"\u4e00\u822c\"\u4f18\u5316\u95ee\u9898\u8f93\u5165(\u6ce8: cvxpylayers \u867d\u7136\u652f\u6301\u5f88\u591a\u522b\u7684\u51fd\u6570\uff0c\u4f46\u662f\u4e0d\u652f\u6301\u6b63\u4f59\u5f26\u51fd\u6570)\u3002\u4f7f\u7528KKT\u5f53\u4f18\u5316\u7ed3\u679c\u6536\u655b\u65f6\u5feb\u901f\u5730\u5b9e\u73b0\u53cd\u5411\u4f20\u64ad\u3002 \u4f5c\u8005\u5728 (3) \u7684\u9644\u5f55\u4e2d\u7ed9\u51fa\u4e86\u4f7f\u7528cvxpylayers\u7528\u6700\u4f18\u5316\u95ee\u9898\u5b9e\u73b0ReLU,Softmax\uff0cQP\u7b49\u95ee\u9898\u7684\u4ee3\u7801\u3002 cvxpylayers \u7684\u4ee3\u7801\u540c\u6837\u4e5f\u6709\u5f88\u591a\u7684\u4f8b\u7a0b,\u5728RL\u3001\u63a7\u5236\u3001\u7f51\u7edc\u540e\u4f18\u5316\u9886\u57df\u6709\u8f83\u5f3a\u7684\u4f7f\u7528\u7a7a\u95f4\u3002","title":"Convex Optimization as a Differentiable learnable layer"},{"location":"other_categories/others/TRPO/","text":"Trust Region Policy Optimization \u8fd9\u7bc7\u8bba\u6587\u662f\u7ecf\u5178\u7684\u5f3a\u5316\u5b66\u4e60\u8bba\u6587\uff0c\u76f4\u89c9\u7684motivation\u6765\u8bf4\u5c31\u662f\u5728\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7684\u8fc7\u7a0b\u4e2d\u566a\u97f3\u5f88\u5927\uff0c\u5f88\u5bb9\u6613\u5d29\u6e83\uff0c\u6240\u4ee5\u8fd9\u91cc\u4f1a\u5c1d\u8bd5\u9650\u5236\u4e00\u4e2aTrust Region\uff0c\u6a21\u4eff\u76f8\u5173\u4f18\u5316\u95ee\u9898\u7684\u601d\u8def\u8fdb\u884c\u63a7\u5236\u3002\u5176\u5b9e\u672c\u6587\u540e\u7eed\u6709\u4e00\u7bc7implementation\u66f4intuitive\u7684 PPO . \u672c\u6587\u5728Spinningup\u4e0a\u6709\u5f88\u4f18\u79c0\u7684 \u5b98\u65b9\u4ecb\u7ecd \uff0c\u672c\u9875\u4e3b\u8981\u901a\u8fc7\u4e2d\u6587\u7ffb\u8bd1+\u7ed3\u5408\u8bba\u6587\u4e0e\u5176\u4ed6\u8d44\u6599\u8fdb\u884c\u8865\u5145\u3002 \u672c\u6587\u6709\u5bf9\u5e94\u7684pytorch\u5f00\u6e90\u4ee3\u7801, \u94fe\u63a5 \u6570\u5b66\u4e0a\u7684Motivation \u4e3a\u4ec0\u4e48\u5f3a\u5316\u5b66\u4e60\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u566a\u97f3\u8fd9\u4e48\u4e25\u91cd\uff1f\u6570\u5b66\u4e0a\u53ef\u4ee5\u5f52\u7eb3\u4e3a\u4ee5\u4e0b\u7684\u516c\u5f0f\u8bf4\u660e\u3002\u5bf9\u4e8e\u5f53\u524d\u4ee5\u53ca\u6700\u4f18\u7684policy\u4e4b\u95f4\u7684expected cost\u7684\u5dee\u522b\uff0c\u51c6\u786e\u7684\u516c\u5f0f\u662f: \\eta(\\tilde\\pi) = \\eta(\\pi) + \\sum_s\\rho_{\\tilde\\pi}(s)\\sum_s\\tilde\\pi(a|s)A_\\pi(s,a) \u4f46\u662f\u7531\u4e8e\u6ca1\u6709\u529e\u6cd5\u7528optimal policy\u8fdb\u884csample.\u6240\u4ee5\u4e00\u822c\u5b9e\u9645\u64cd\u4f5c\u7684\u65f6\u5019\u53ea\u80fd\u7528\u5f53\u524d\u7684policy\u5bf9\u8def\u5f84\u8fdb\u884c\u91c7\u6837\uff0c\u5f97\u5230 L_\\pi(\\tilde\\pi) = \\eta(\\pi) + \\sum_s\\rho_{\\pi}(s)\\sum_s\\tilde\\pi(a|s)A_\\pi(s,a) \u7b97\u6cd5\u6570\u5b66\u63cf\u8ff0 \u4f18\u5316\u95ee\u9898\u63cf\u8ff0: \\begin{aligned} \\theta_{k+1} = &\\argmax_\\theta \\mathcal{L}(\\theta_k,\\theta) \\\\ &s.t. D_{KL}(\\theta||\\theta_k) \\le \\delta \\end{aligned} \u5176\u4e2d \\mathcal{L}(\\theta_k,\\theta) \u542b\u4e49\u4e0e\u524d\u6587\u57fa\u672c\u4e00\u81f4\uff0c\u5177\u4f53\u6765\u8bf4\u662f \\mathcal{L}(\\theta_k,\\theta) = E_{s,a~\\pi_{\\theta_k}}[\\frac{\\pi_\\theta(a|s)}{\\pi_{\\theta_k}(a|s)}A^{\\pi_{\\theta_k}}(s,a)] D_{KL}(\\theta||\\theta_k) = E_{s~\\pi_{\\theta_k}}[D_{KL}(\\pi_\\theta(\u00b7|s) ||\\pi_{\\theta_k}(\u00b7|s) )] \u5176\u4e2dKL divergence\u7684\u5b9a\u4e49\u8bf7\u67e5\u9605 wiki D_{KL}(P||Q) = \\sum_P P(x) ln(\\frac{P(x)}{Q(x)}) \u5bf9\u4e0a\u9762\u7684\u95ee\u9898\u53d6\u6cf0\u52d2\u8fd1\u4f3c\uff0c\u4f18\u5316\u95ee\u9898\u53d8\u4e3a\u4e00\u4e2a\u5e26\u7ea6\u675f\u7684\u4e8c\u6b21\u65b9\u7a0b\uff0c\u8bbe g \u4e3a L \u5173\u4e8e\u7f51\u7edc\u53c2\u6570 \\theta \u7684\u68af\u5ea6. \\begin{aligned} \\theta_{k+1} = \\argmax_\\theta &g^T(\\theta - \\theta_k) \\\\ s.t. &\\frac{1}{2}(\\theta - \\theta_k)^TH(\\theta - \\theta_k) \\le\\delta \\end{aligned} \u6839\u636e\u51f8\u4f18\u5316\u7684\u6700\u4f18\u89e3\u662f \\theta_{k+1} = \\theta_k + \\sqrt{\\frac{2\\delta}{g^TH^{-1}g}}H^{-1}g \u5bf9\u4e8e\u53c2\u6570\u6570\u91cf\u5f88\u5927\u7684 \\theta \u7f51\u7edc\uff0chessian\u77e9\u9635\u7684\u8ba1\u7b97\uff0c\u5c24\u5176\u662f\u9006\u7684\u77e9\u9635\u8fd0\u7b97\u91cf\u5f88\u5927\uff0c\u8fd9\u91cc\u4f7f\u7528\u7684\u662f conjugate gradient\u7b97\u6cd5 \uff0c\u8fd9\u662f\u4e00\u4e2a\u6c42\u89e3\u5bf9\u79f0\u77e9\u9635\u7684\u9006\u6216\u8005\u6c42\u89e3\u7a00\u758f\u7ebf\u6027\u65b9\u7a0b\u7684\u8fed\u4ee3\u7b97\u6cd5\u3002 \u4e0b\u6587\u6765\u81eawiki\u94fe\u63a5\u4e2d\u7684\u662f\u6c42\u89e3\u7ebf\u6027\u65b9\u7a0b Ax = b \u7684\u7b97\u6cd5 \u6700\u540eopenai spinningup\u603b\u7ed3\u4e86\u7b97\u6cd5\u5982\u4e0b\u56fe \u8865\u5145\u63cf\u8ff0\uff1a \u5173\u4e8estep 9 line search: \u5c31\u662f\u9010\u4e2a\u67e5\u770b\u9009\u62e9\u5b9e\u9645\u80fd\u53d6\u7684\u6700\u957f\u7684\u6b65\u957f(\u56e0\u4e3a\u524d\u9762\u6709\u505a\u4e8c\u6b21\u8fd1\u4f3c) \u5173\u4e8estep 10: \u5e38\u89c4policy gradient \u7b97\u6cd5\u4e2d\u5bf9value\u7f51\u7edc\u7684\u62df\u5408.","title":"Trust Region Policy Optimization"},{"location":"other_categories/others/TRPO/#trust-region-policy-optimization","text":"\u8fd9\u7bc7\u8bba\u6587\u662f\u7ecf\u5178\u7684\u5f3a\u5316\u5b66\u4e60\u8bba\u6587\uff0c\u76f4\u89c9\u7684motivation\u6765\u8bf4\u5c31\u662f\u5728\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7684\u8fc7\u7a0b\u4e2d\u566a\u97f3\u5f88\u5927\uff0c\u5f88\u5bb9\u6613\u5d29\u6e83\uff0c\u6240\u4ee5\u8fd9\u91cc\u4f1a\u5c1d\u8bd5\u9650\u5236\u4e00\u4e2aTrust Region\uff0c\u6a21\u4eff\u76f8\u5173\u4f18\u5316\u95ee\u9898\u7684\u601d\u8def\u8fdb\u884c\u63a7\u5236\u3002\u5176\u5b9e\u672c\u6587\u540e\u7eed\u6709\u4e00\u7bc7implementation\u66f4intuitive\u7684 PPO . \u672c\u6587\u5728Spinningup\u4e0a\u6709\u5f88\u4f18\u79c0\u7684 \u5b98\u65b9\u4ecb\u7ecd \uff0c\u672c\u9875\u4e3b\u8981\u901a\u8fc7\u4e2d\u6587\u7ffb\u8bd1+\u7ed3\u5408\u8bba\u6587\u4e0e\u5176\u4ed6\u8d44\u6599\u8fdb\u884c\u8865\u5145\u3002 \u672c\u6587\u6709\u5bf9\u5e94\u7684pytorch\u5f00\u6e90\u4ee3\u7801, \u94fe\u63a5","title":"Trust Region Policy Optimization"},{"location":"other_categories/others/TRPO/#motivation","text":"\u4e3a\u4ec0\u4e48\u5f3a\u5316\u5b66\u4e60\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u566a\u97f3\u8fd9\u4e48\u4e25\u91cd\uff1f\u6570\u5b66\u4e0a\u53ef\u4ee5\u5f52\u7eb3\u4e3a\u4ee5\u4e0b\u7684\u516c\u5f0f\u8bf4\u660e\u3002\u5bf9\u4e8e\u5f53\u524d\u4ee5\u53ca\u6700\u4f18\u7684policy\u4e4b\u95f4\u7684expected cost\u7684\u5dee\u522b\uff0c\u51c6\u786e\u7684\u516c\u5f0f\u662f: \\eta(\\tilde\\pi) = \\eta(\\pi) + \\sum_s\\rho_{\\tilde\\pi}(s)\\sum_s\\tilde\\pi(a|s)A_\\pi(s,a) \u4f46\u662f\u7531\u4e8e\u6ca1\u6709\u529e\u6cd5\u7528optimal policy\u8fdb\u884csample.\u6240\u4ee5\u4e00\u822c\u5b9e\u9645\u64cd\u4f5c\u7684\u65f6\u5019\u53ea\u80fd\u7528\u5f53\u524d\u7684policy\u5bf9\u8def\u5f84\u8fdb\u884c\u91c7\u6837\uff0c\u5f97\u5230 L_\\pi(\\tilde\\pi) = \\eta(\\pi) + \\sum_s\\rho_{\\pi}(s)\\sum_s\\tilde\\pi(a|s)A_\\pi(s,a)","title":"\u6570\u5b66\u4e0a\u7684Motivation"},{"location":"other_categories/others/TRPO/#_1","text":"\u4f18\u5316\u95ee\u9898\u63cf\u8ff0: \\begin{aligned} \\theta_{k+1} = &\\argmax_\\theta \\mathcal{L}(\\theta_k,\\theta) \\\\ &s.t. D_{KL}(\\theta||\\theta_k) \\le \\delta \\end{aligned} \u5176\u4e2d \\mathcal{L}(\\theta_k,\\theta) \u542b\u4e49\u4e0e\u524d\u6587\u57fa\u672c\u4e00\u81f4\uff0c\u5177\u4f53\u6765\u8bf4\u662f \\mathcal{L}(\\theta_k,\\theta) = E_{s,a~\\pi_{\\theta_k}}[\\frac{\\pi_\\theta(a|s)}{\\pi_{\\theta_k}(a|s)}A^{\\pi_{\\theta_k}}(s,a)] D_{KL}(\\theta||\\theta_k) = E_{s~\\pi_{\\theta_k}}[D_{KL}(\\pi_\\theta(\u00b7|s) ||\\pi_{\\theta_k}(\u00b7|s) )] \u5176\u4e2dKL divergence\u7684\u5b9a\u4e49\u8bf7\u67e5\u9605 wiki D_{KL}(P||Q) = \\sum_P P(x) ln(\\frac{P(x)}{Q(x)}) \u5bf9\u4e0a\u9762\u7684\u95ee\u9898\u53d6\u6cf0\u52d2\u8fd1\u4f3c\uff0c\u4f18\u5316\u95ee\u9898\u53d8\u4e3a\u4e00\u4e2a\u5e26\u7ea6\u675f\u7684\u4e8c\u6b21\u65b9\u7a0b\uff0c\u8bbe g \u4e3a L \u5173\u4e8e\u7f51\u7edc\u53c2\u6570 \\theta \u7684\u68af\u5ea6. \\begin{aligned} \\theta_{k+1} = \\argmax_\\theta &g^T(\\theta - \\theta_k) \\\\ s.t. &\\frac{1}{2}(\\theta - \\theta_k)^TH(\\theta - \\theta_k) \\le\\delta \\end{aligned} \u6839\u636e\u51f8\u4f18\u5316\u7684\u6700\u4f18\u89e3\u662f \\theta_{k+1} = \\theta_k + \\sqrt{\\frac{2\\delta}{g^TH^{-1}g}}H^{-1}g \u5bf9\u4e8e\u53c2\u6570\u6570\u91cf\u5f88\u5927\u7684 \\theta \u7f51\u7edc\uff0chessian\u77e9\u9635\u7684\u8ba1\u7b97\uff0c\u5c24\u5176\u662f\u9006\u7684\u77e9\u9635\u8fd0\u7b97\u91cf\u5f88\u5927\uff0c\u8fd9\u91cc\u4f7f\u7528\u7684\u662f conjugate gradient\u7b97\u6cd5 \uff0c\u8fd9\u662f\u4e00\u4e2a\u6c42\u89e3\u5bf9\u79f0\u77e9\u9635\u7684\u9006\u6216\u8005\u6c42\u89e3\u7a00\u758f\u7ebf\u6027\u65b9\u7a0b\u7684\u8fed\u4ee3\u7b97\u6cd5\u3002 \u4e0b\u6587\u6765\u81eawiki\u94fe\u63a5\u4e2d\u7684\u662f\u6c42\u89e3\u7ebf\u6027\u65b9\u7a0b Ax = b \u7684\u7b97\u6cd5 \u6700\u540eopenai spinningup\u603b\u7ed3\u4e86\u7b97\u6cd5\u5982\u4e0b\u56fe","title":"\u7b97\u6cd5\u6570\u5b66\u63cf\u8ff0"},{"location":"other_categories/others/TRPO/#_2","text":"\u5173\u4e8estep 9 line search: \u5c31\u662f\u9010\u4e2a\u67e5\u770b\u9009\u62e9\u5b9e\u9645\u80fd\u53d6\u7684\u6700\u957f\u7684\u6b65\u957f(\u56e0\u4e3a\u524d\u9762\u6709\u505a\u4e8c\u6b21\u8fd1\u4f3c) \u5173\u4e8estep 10: \u5e38\u89c4policy gradient \u7b97\u6cd5\u4e2d\u5bf9value\u7f51\u7edc\u7684\u62df\u5408.","title":"\u8865\u5145\u63cf\u8ff0\uff1a"},{"location":"other_categories/others/Unsupervised_depth_prediction/","text":"Unsupervised Monocular Depth Estimation with Left-Right Consistency \u8fd9\u7bc7\u8bba\u6587\u89e3\u51b3\u7684\u95ee\u9898\u662f\u65e0\u76d1\u7763\u6761\u4ef6\u4e0b\uff0c\u4ec5\u4f7f\u7528\u5355\u4e2a\u76f8\u673a\u5355\u6b21\u7684\u62cd\u6444\u56fe\uff0c\u5f97\u5230\u5bf9\u6df1\u5ea6\u7684\u4f30\u8ba1\u3002\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u9700\u8981\u7b2c\u4e8c\u4e2a\u76f8\u673a\u540c\u65f6\u62cd\u6444\u7684\u7ed3\u679c\u6765\u6784\u9020\u635f\u5931\u51fd\u6570\u7528\u4e8e\u8bad\u7ec3\u3002\u53ef\u4ee5\u7406\u89e3\u4e3a\u662f\u4f7f\u7528\u7b2c\u4e8c\u4e2a\u76f8\u673a\u4f5c\u4e3a\u76d1\u7763\u8f93\u5165\uff0c\u4f46\u662f\u8fd9\u4e5f\u8282\u7701\u4e86\u6570\u636e\u6807\u5b9a\u7684\u96be\u5ea6\u3002\u672c\u6587\u540c\u65f6\u6709\u975e\u5b98\u65b9\u7684 pytorch\u5b9e\u73b0 inference\u7ed3\u6784 \u672c\u6587\u795e\u7ecf\u7f51\u7edc\u7684\u8f93\u5165\u662f\u5355\u5f20RGB\u56fe\u7247\uff0c\u8f93\u51fa\u662fmulti-scale\u7684disparity,\u5e76\u4e14\u5728\u6bcf\u4e2ascale\u662f\u540c\u65f6\u8f93\u51fa\u5de6\u56fe->\u53f3\u56fe\u7684disparity\u4ee5\u53ca\u53f3\u56fe->\u5de6\u56fe\u7684disparity.\u4f5c\u8005\u7684\u601d\u8def\u662f\u5728\u591a\u4e2ascale\u4e0a\u540c\u65f6\u5bf9\u4e24\u4e2adisparity\u68c0\u6d4b\u7684\u6b63\u786e\u6027\u3001\u7edf\u4e00\u6027\u8fdb\u884c\u68c0\u9a8c\u3002 Loss\u7ed3\u6784 \u5b9a\u4e49\u5728scale s \u4e0a\u7684\u635f\u5931\u503c\u4e3a C_s , \u635f\u5931\u51fd\u6570\u4e3a C_{s}=\\alpha_{a p}\\left(C_{a p}^{l}+C_{a p}^{r}\\right)+\\alpha_{d s}\\left(C_{d s}^{l}+C_{d s}^{r}\\right)+\\alpha_{l r}\\left(C_{l r}^{l}+C_{l r}^{r}\\right) \u91cd\u6784\u635f\u5931 C_{ap} \u6307\u7684\u662f\u5de6\u53f3\u56fe\u76f8\u4e92\u91cd\u6784\u65f6\u7684\u8bef\u5dee\u635f\u5931\uff0c\u672c\u6587\u540c\u65f6\u91c7\u7528naive\u7684 L1 \u8ddd\u79bb\u4ee5\u53ca SSIM\u8ddd\u79bb \u7684\u52a0\u6743\u6c42\u548c\uff0c\u4ee3\u7801\u4e2d\u53ef\u4ee5\u6e05\u695a\u5730\u7559\u610f\u5230\u4f5c\u8005\u662f\u5982\u4f55\u4f7f\u7528Pytorch\u539f\u751f\u5c42\u4ee5\u53ca\u57fa\u672c\u64cd\u4f5c\u5b9e\u73b0SSIM\u7684\u8ba1\u7b97\uff0c\u5e76\u4e14\u5141\u8bb8\u53cd\u4f20\u3002 C_{a p}^{l}=\\frac{1}{N} \\sum_{i, j} \\alpha \\frac{1-\\operatorname{SSIM}\\left(I_{i j}^{l}, \\tilde{I}_{i j}^{l}\\right)}{2}+(1-\\alpha)\\left\\|I_{i j}^{l}-\\tilde{I}_{i j}^{l}\\right\\| def SSIM ( self , x , y ): C1 = 0.01 ** 2 C2 = 0.03 ** 2 mu_x = nn . AvgPool2d ( 3 , 1 )( x ) mu_y = nn . AvgPool2d ( 3 , 1 )( y ) mu_x_mu_y = mu_x * mu_y mu_x_sq = mu_x . pow ( 2 ) mu_y_sq = mu_y . pow ( 2 ) sigma_x = nn . AvgPool2d ( 3 , 1 )( x * x ) - mu_x_sq sigma_y = nn . AvgPool2d ( 3 , 1 )( y * y ) - mu_y_sq sigma_xy = nn . AvgPool2d ( 3 , 1 )( x * y ) - mu_x_mu_y SSIM_n = ( 2 * mu_x_mu_y + C1 ) * ( 2 * sigma_xy + C2 ) SSIM_d = ( mu_x_sq + mu_y_sq + C1 ) * ( sigma_x + sigma_y + C2 ) SSIM = SSIM_n / SSIM_d return torch . clamp (( 1 - SSIM ) / 2 , 0 , 1 ) \u5149\u6ed1\u635f\u5931 C_{ds} \u4ee3\u8868\u7684\u662fdisparity-smoothness loss\uff0c\u8fd9\u91cc\u7684\u505a\u6cd5\u662f\u5bf9disparity map\u7684\u68af\u5ea6\u8fdb\u884c\u60e9\u7f5a. C_{d s}^{l}=\\frac{1}{N} \\sum_{i, j}\\left|\\partial_{x} d_{i j}^{l}\\right| e^{-\\left\\|\\partial_{x} I_{i j}^{l}\\right\\|}+\\left|\\partial_{y} d_{i j}^{l}\\right| e^{-\\left\\|\\partial_{y} I_{i j}^{l}\\right\\|} \u5de6\u53f3\u5dee\u503c\u635f\u5931 C_{lr} \u7528\u6765\u8868\u5f81\u4e24\u4e2adisparity map\u7684\u81ea\u6d3d\u6027\u3002\u6839\u636e\u5de6\u56fe\u7684disparity\uff0c\u5c06\u5de6\u56fe\u7684\u70b9\u6295\u5230\u53f3\u56fe\uff0c\u8fd9\u4e24\u4e2a\u5bf9\u5e94\u70b9\u7684disparity\u5e94\u8be5\u662f\u4e00\u81f4\u7684\u3002 C_{l r}^{l}=\\frac{1}{N} \\sum_{i, j}\\left|d_{i j}^{l}-d_{i j+d_{i j}^{l}}^{r}\\right|","title":"Unsupervised Monocular Depth Estimation with Left-Right Consistency"},{"location":"other_categories/others/Unsupervised_depth_prediction/#unsupervised-monocular-depth-estimation-with-left-right-consistency","text":"\u8fd9\u7bc7\u8bba\u6587\u89e3\u51b3\u7684\u95ee\u9898\u662f\u65e0\u76d1\u7763\u6761\u4ef6\u4e0b\uff0c\u4ec5\u4f7f\u7528\u5355\u4e2a\u76f8\u673a\u5355\u6b21\u7684\u62cd\u6444\u56fe\uff0c\u5f97\u5230\u5bf9\u6df1\u5ea6\u7684\u4f30\u8ba1\u3002\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u9700\u8981\u7b2c\u4e8c\u4e2a\u76f8\u673a\u540c\u65f6\u62cd\u6444\u7684\u7ed3\u679c\u6765\u6784\u9020\u635f\u5931\u51fd\u6570\u7528\u4e8e\u8bad\u7ec3\u3002\u53ef\u4ee5\u7406\u89e3\u4e3a\u662f\u4f7f\u7528\u7b2c\u4e8c\u4e2a\u76f8\u673a\u4f5c\u4e3a\u76d1\u7763\u8f93\u5165\uff0c\u4f46\u662f\u8fd9\u4e5f\u8282\u7701\u4e86\u6570\u636e\u6807\u5b9a\u7684\u96be\u5ea6\u3002\u672c\u6587\u540c\u65f6\u6709\u975e\u5b98\u65b9\u7684 pytorch\u5b9e\u73b0","title":"Unsupervised Monocular Depth Estimation with Left-Right Consistency"},{"location":"other_categories/others/Unsupervised_depth_prediction/#inference","text":"\u672c\u6587\u795e\u7ecf\u7f51\u7edc\u7684\u8f93\u5165\u662f\u5355\u5f20RGB\u56fe\u7247\uff0c\u8f93\u51fa\u662fmulti-scale\u7684disparity,\u5e76\u4e14\u5728\u6bcf\u4e2ascale\u662f\u540c\u65f6\u8f93\u51fa\u5de6\u56fe->\u53f3\u56fe\u7684disparity\u4ee5\u53ca\u53f3\u56fe->\u5de6\u56fe\u7684disparity.\u4f5c\u8005\u7684\u601d\u8def\u662f\u5728\u591a\u4e2ascale\u4e0a\u540c\u65f6\u5bf9\u4e24\u4e2adisparity\u68c0\u6d4b\u7684\u6b63\u786e\u6027\u3001\u7edf\u4e00\u6027\u8fdb\u884c\u68c0\u9a8c\u3002","title":"inference\u7ed3\u6784"},{"location":"other_categories/others/Unsupervised_depth_prediction/#loss","text":"\u5b9a\u4e49\u5728scale s \u4e0a\u7684\u635f\u5931\u503c\u4e3a C_s , \u635f\u5931\u51fd\u6570\u4e3a C_{s}=\\alpha_{a p}\\left(C_{a p}^{l}+C_{a p}^{r}\\right)+\\alpha_{d s}\\left(C_{d s}^{l}+C_{d s}^{r}\\right)+\\alpha_{l r}\\left(C_{l r}^{l}+C_{l r}^{r}\\right)","title":"Loss\u7ed3\u6784"},{"location":"other_categories/others/Unsupervised_depth_prediction/#_1","text":"C_{ap} \u6307\u7684\u662f\u5de6\u53f3\u56fe\u76f8\u4e92\u91cd\u6784\u65f6\u7684\u8bef\u5dee\u635f\u5931\uff0c\u672c\u6587\u540c\u65f6\u91c7\u7528naive\u7684 L1 \u8ddd\u79bb\u4ee5\u53ca SSIM\u8ddd\u79bb \u7684\u52a0\u6743\u6c42\u548c\uff0c\u4ee3\u7801\u4e2d\u53ef\u4ee5\u6e05\u695a\u5730\u7559\u610f\u5230\u4f5c\u8005\u662f\u5982\u4f55\u4f7f\u7528Pytorch\u539f\u751f\u5c42\u4ee5\u53ca\u57fa\u672c\u64cd\u4f5c\u5b9e\u73b0SSIM\u7684\u8ba1\u7b97\uff0c\u5e76\u4e14\u5141\u8bb8\u53cd\u4f20\u3002 C_{a p}^{l}=\\frac{1}{N} \\sum_{i, j} \\alpha \\frac{1-\\operatorname{SSIM}\\left(I_{i j}^{l}, \\tilde{I}_{i j}^{l}\\right)}{2}+(1-\\alpha)\\left\\|I_{i j}^{l}-\\tilde{I}_{i j}^{l}\\right\\| def SSIM ( self , x , y ): C1 = 0.01 ** 2 C2 = 0.03 ** 2 mu_x = nn . AvgPool2d ( 3 , 1 )( x ) mu_y = nn . AvgPool2d ( 3 , 1 )( y ) mu_x_mu_y = mu_x * mu_y mu_x_sq = mu_x . pow ( 2 ) mu_y_sq = mu_y . pow ( 2 ) sigma_x = nn . AvgPool2d ( 3 , 1 )( x * x ) - mu_x_sq sigma_y = nn . AvgPool2d ( 3 , 1 )( y * y ) - mu_y_sq sigma_xy = nn . AvgPool2d ( 3 , 1 )( x * y ) - mu_x_mu_y SSIM_n = ( 2 * mu_x_mu_y + C1 ) * ( 2 * sigma_xy + C2 ) SSIM_d = ( mu_x_sq + mu_y_sq + C1 ) * ( sigma_x + sigma_y + C2 ) SSIM = SSIM_n / SSIM_d return torch . clamp (( 1 - SSIM ) / 2 , 0 , 1 )","title":"\u91cd\u6784\u635f\u5931"},{"location":"other_categories/others/Unsupervised_depth_prediction/#_2","text":"C_{ds} \u4ee3\u8868\u7684\u662fdisparity-smoothness loss\uff0c\u8fd9\u91cc\u7684\u505a\u6cd5\u662f\u5bf9disparity map\u7684\u68af\u5ea6\u8fdb\u884c\u60e9\u7f5a. C_{d s}^{l}=\\frac{1}{N} \\sum_{i, j}\\left|\\partial_{x} d_{i j}^{l}\\right| e^{-\\left\\|\\partial_{x} I_{i j}^{l}\\right\\|}+\\left|\\partial_{y} d_{i j}^{l}\\right| e^{-\\left\\|\\partial_{y} I_{i j}^{l}\\right\\|}","title":"\u5149\u6ed1\u635f\u5931"},{"location":"other_categories/others/Unsupervised_depth_prediction/#_3","text":"C_{lr} \u7528\u6765\u8868\u5f81\u4e24\u4e2adisparity map\u7684\u81ea\u6d3d\u6027\u3002\u6839\u636e\u5de6\u56fe\u7684disparity\uff0c\u5c06\u5de6\u56fe\u7684\u70b9\u6295\u5230\u53f3\u56fe\uff0c\u8fd9\u4e24\u4e2a\u5bf9\u5e94\u70b9\u7684disparity\u5e94\u8be5\u662f\u4e00\u81f4\u7684\u3002 C_{l r}^{l}=\\frac{1}{N} \\sum_{i, j}\\left|d_{i j}^{l}-d_{i j+d_{i j}^{l}}^{r}\\right|","title":"\u5de6\u53f3\u5dee\u503c\u635f\u5931"},{"location":"other_categories/others/adversarialPatch/","text":"Adversarial Patch \u8fd9\u7bc7paper\u505a\u5de5\u4f5c\u5982\u56fe. \u5176\u4e0e\u4e00\u822c\u7684\u5bf9\u6297\u6027\u653b\u51fb\u4e0d\u540c\u7684\u5730\u65b9\u5728\u4e8e\uff1a 1. \u7406\u8bba\u4e0a\u6765\u8bf4\u53ef\u4ee5\u5bf9\u6297\u5728ImageNet\u4e0a\u8bad\u7ec3\u7684\u4e0d\u540cmodel\u7684\u6240\u6709image\u3002 2. \u53ef\u4ee5\u6253\u5370\u51fa\u6765\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u653e\u7f6e\u3002\u5f62\u6210\u5b9e\u65f6\u653b\u51fb Approach \u65b9\u6cd5\u9700\u6c42, \u4e00\u4e2aimage patch(\u6bd4\u5982\u672c\u6587\u7684\u4e00\u5c0f\u4e2a toaster), \u4e00\u4e2a\u6216\u591a\u4e2a\u5df2\u7ecf\u8bad\u7ec3\u597d\u7684\u5206\u7c7b\u7f51\u7edc\uff0c\u4e00\u4e2a\u5206\u7c7b\u6570\u636e\u96c6(\u4e0d\u9700\u8981target)\uff0c\u4e00\u4e2a\u76ee\u6807\u7c7b\u522b(\u8981\u6c42\u88ab\u653b\u51fb\u7684\u7f51\u7edc\u8f93\u51fa\u7684\u7ed3\u679c)\u3002 \u6bcf\u4e00\u4e2a\u5faa\u73af\u4e2d\uff0c\u968f\u673a\u5730\u5c06\u5f53\u524d\u7684image patch\u66ff\u6362\u56fe\u7247\u7684\u4e00\u4e2a\u90e8\u5206\uff0c\u4f4d\u7f6e\u65cb\u8f6c\u4ee5\u53cascale\u6709\u4e00\u5b9a\u968f\u673a\u6027\uff0c\u7136\u540e\u4f7f\u7528\u68af\u5ea6\u4f18\u5316\uff0cupdate\u8f93\u5165\u7684image patch\uff0c\u4f7f\u5f97\u7f51\u7edc\u5bf9\u76ee\u6807\u7c7b\u522b\u9884\u6d4b\u7684\u6982\u7387\u503c\u6700\u5927\u5316\u3002 \\widehat{p}=\\arg \\max _{p} \\mathbb{E}_{x \\sim X, t \\sim T, l \\sim L}[\\log \\operatorname{Pr}(\\widehat{y} | A(p, x, l, t)] \u7ed3\u679c \u5982\u679c\u7f51\u662f\u5df2\u77e5\u7684\uff0c\u4f7f\u7528white box (\u8bad\u7ec3\u65f6\u7f51\u7edc\u4e0e\u6d4b\u8bd5\u7f51\u7edc\u4e00\u81f4)\uff0c\u8fd9\u4e2apatch\u53ea\u9700\u8981\u5360\u636e\u56fe\u7247\u768410%\u4e0d\u5230\u7684\u5927\u5c0f\u5c31\u53ef\u4ee5\u5927\u6982\u7387\u8ff7\u60d1\u7f51\u7edc\u3002 \u5982\u679c\u7f51\u7edc\u662f\u672a\u77e5\u7684\uff0c\u4f7f\u7528 black box(\u672c\u6587\u7684\u5b9e\u9a8c\u662f\u4f7f\u75284\u4e2a\u4e0d\u540c\u7684\u7f51\u7edctrain\u8fd9\u4e2abatch\uff0c\u4f7f\u7528\u53e6\u5916\u4e00\u4e2a\u7f51\u7edc\u8fdb\u884c\u6d4b\u8bd5)\uff0c\u8fd9\u4e2apatch\u53ea\u8981\u5360\u636e\u539f\u56fe\u7247\u768410%-20%\u5c31\u53ef\u4ee5\u5927\u6982\u7387\u8ff7\u60d1\u8fd9\u4e2a\u672a\u77e5\u7684\u7f51\u7edc\u3002","title":"Adversarial Patch"},{"location":"other_categories/others/adversarialPatch/#adversarial-patch","text":"\u8fd9\u7bc7paper\u505a\u5de5\u4f5c\u5982\u56fe. \u5176\u4e0e\u4e00\u822c\u7684\u5bf9\u6297\u6027\u653b\u51fb\u4e0d\u540c\u7684\u5730\u65b9\u5728\u4e8e\uff1a 1. \u7406\u8bba\u4e0a\u6765\u8bf4\u53ef\u4ee5\u5bf9\u6297\u5728ImageNet\u4e0a\u8bad\u7ec3\u7684\u4e0d\u540cmodel\u7684\u6240\u6709image\u3002 2. \u53ef\u4ee5\u6253\u5370\u51fa\u6765\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u653e\u7f6e\u3002\u5f62\u6210\u5b9e\u65f6\u653b\u51fb","title":"Adversarial Patch"},{"location":"other_categories/others/adversarialPatch/#approach","text":"\u65b9\u6cd5\u9700\u6c42, \u4e00\u4e2aimage patch(\u6bd4\u5982\u672c\u6587\u7684\u4e00\u5c0f\u4e2a toaster), \u4e00\u4e2a\u6216\u591a\u4e2a\u5df2\u7ecf\u8bad\u7ec3\u597d\u7684\u5206\u7c7b\u7f51\u7edc\uff0c\u4e00\u4e2a\u5206\u7c7b\u6570\u636e\u96c6(\u4e0d\u9700\u8981target)\uff0c\u4e00\u4e2a\u76ee\u6807\u7c7b\u522b(\u8981\u6c42\u88ab\u653b\u51fb\u7684\u7f51\u7edc\u8f93\u51fa\u7684\u7ed3\u679c)\u3002 \u6bcf\u4e00\u4e2a\u5faa\u73af\u4e2d\uff0c\u968f\u673a\u5730\u5c06\u5f53\u524d\u7684image patch\u66ff\u6362\u56fe\u7247\u7684\u4e00\u4e2a\u90e8\u5206\uff0c\u4f4d\u7f6e\u65cb\u8f6c\u4ee5\u53cascale\u6709\u4e00\u5b9a\u968f\u673a\u6027\uff0c\u7136\u540e\u4f7f\u7528\u68af\u5ea6\u4f18\u5316\uff0cupdate\u8f93\u5165\u7684image patch\uff0c\u4f7f\u5f97\u7f51\u7edc\u5bf9\u76ee\u6807\u7c7b\u522b\u9884\u6d4b\u7684\u6982\u7387\u503c\u6700\u5927\u5316\u3002 \\widehat{p}=\\arg \\max _{p} \\mathbb{E}_{x \\sim X, t \\sim T, l \\sim L}[\\log \\operatorname{Pr}(\\widehat{y} | A(p, x, l, t)]","title":"Approach"},{"location":"other_categories/others/adversarialPatch/#_1","text":"\u5982\u679c\u7f51\u662f\u5df2\u77e5\u7684\uff0c\u4f7f\u7528white box (\u8bad\u7ec3\u65f6\u7f51\u7edc\u4e0e\u6d4b\u8bd5\u7f51\u7edc\u4e00\u81f4)\uff0c\u8fd9\u4e2apatch\u53ea\u9700\u8981\u5360\u636e\u56fe\u7247\u768410%\u4e0d\u5230\u7684\u5927\u5c0f\u5c31\u53ef\u4ee5\u5927\u6982\u7387\u8ff7\u60d1\u7f51\u7edc\u3002 \u5982\u679c\u7f51\u7edc\u662f\u672a\u77e5\u7684\uff0c\u4f7f\u7528 black box(\u672c\u6587\u7684\u5b9e\u9a8c\u662f\u4f7f\u75284\u4e2a\u4e0d\u540c\u7684\u7f51\u7edctrain\u8fd9\u4e2abatch\uff0c\u4f7f\u7528\u53e6\u5916\u4e00\u4e2a\u7f51\u7edc\u8fdb\u884c\u6d4b\u8bd5)\uff0c\u8fd9\u4e2apatch\u53ea\u8981\u5360\u636e\u539f\u56fe\u7247\u768410%-20%\u5c31\u53ef\u4ee5\u5927\u6982\u7387\u8ff7\u60d1\u8fd9\u4e2a\u672a\u77e5\u7684\u7f51\u7edc\u3002","title":"\u7ed3\u679c"},{"location":"other_categories/others/flownet/","text":"FlowNet and Variants \u8fd9\u91cc\u7efc\u5408\u8bb0\u5f55FlowNet\u4ee5\u53ca\u5b83\u7684\u4e00\u4e9b\u53d8\u4f53 FlowNet Base pdf \u8fd9\u7bc7paper\u662fflownet\u7684\u7b2c\u4e00\u7bc7\u3002\u63d0\u51fa\u4f7f\u7528sliding disparity \u4ee5\u53cacorrelation. c\\left(\\mathbf{x}_{1}, \\mathbf{x}_{2}\\right)=\\sum_{\\mathbf{o} \\in[-k, k] \\times[-k, k]}\\left\\langle\\mathbf{f}_{1}\\left(\\mathbf{x}_{1}+\\mathbf{o}\\right), \\mathbf{f}_{2}\\left(\\mathbf{x}_{2}+\\mathbf{o}\\right)\\right\\rangle FlowNet 2 pdf FlowNetC\u4e0e\u7b2c\u4e00paper\u7684\u4e00\u81f4\u3002\u800cFlowNetS\u5219\u4e3a\u76f4\u63a5\u7684encoder-decoder. \u672c\u6587\u4ee3\u7801 \u6709 channelnorm, correlation, resample_2d\u7684cuda\u5b9e\u73b0\u3002","title":"FlowNet and Variants"},{"location":"other_categories/others/flownet/#flownet-and-variants","text":"\u8fd9\u91cc\u7efc\u5408\u8bb0\u5f55FlowNet\u4ee5\u53ca\u5b83\u7684\u4e00\u4e9b\u53d8\u4f53","title":"FlowNet and Variants"},{"location":"other_categories/others/flownet/#flownet-base","text":"pdf \u8fd9\u7bc7paper\u662fflownet\u7684\u7b2c\u4e00\u7bc7\u3002\u63d0\u51fa\u4f7f\u7528sliding disparity \u4ee5\u53cacorrelation. c\\left(\\mathbf{x}_{1}, \\mathbf{x}_{2}\\right)=\\sum_{\\mathbf{o} \\in[-k, k] \\times[-k, k]}\\left\\langle\\mathbf{f}_{1}\\left(\\mathbf{x}_{1}+\\mathbf{o}\\right), \\mathbf{f}_{2}\\left(\\mathbf{x}_{2}+\\mathbf{o}\\right)\\right\\rangle","title":"FlowNet Base"},{"location":"other_categories/others/flownet/#flownet-2","text":"pdf FlowNetC\u4e0e\u7b2c\u4e00paper\u7684\u4e00\u81f4\u3002\u800cFlowNetS\u5219\u4e3a\u76f4\u63a5\u7684encoder-decoder. \u672c\u6587\u4ee3\u7801 \u6709 channelnorm, correlation, resample_2d\u7684cuda\u5b9e\u73b0\u3002","title":"FlowNet 2"},{"location":"other_categories/others/openpose_part_afinity_fileds/","text":"Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields \u8fd9\u7bc7\u8bba\u6587\u662f Open Pose\u5e93 \u8fc8\u5411\u5b9e\u65f6\u591a\u4eba\u80a2\u4f53\u4f30\u8ba1\u7684\u7b2c\u4e00\u7bc7\u8bba\u6587\uff0c\u4e3b\u8981\u662f\u89e3\u51b3\u80a2\u4f53\u4f30\u8ba1\u4e2d\u7684\u5339\u914d\u95ee\u9898\u3002 Pose Estimation pipeline \u603b\u4f53\u6846\u67b6\u5982\u56fe\uff0cCNN\u4f1a\u8f93\u51fa\u4e24\u4e2a\u5206\u652f\uff0c\u4e00\u4e2a\u5206\u652f\u662f\u5173\u8282\u4f4d\u7f6e\u70ed\u56fe\uff0c\u4e00\u4e2a\u5206\u652f\u662f\u5c40\u90e8\u80a2\u4f53\u77e2\u91cf\u56fe(Part Affinity Fields, PAF)\u3002\u901a\u8fc7NMS\u5f97\u5230\u56fe\u4e2d\u6240\u6709\u4eba\u5404\u4e2a\u5173\u8282\u7684\u4f4d\u7f6e\u3002\u518d\u901a\u8fc7PAF\u63a8\u7406\u3001\u5206\u7ec4\u51fa\u5404\u4e2a\u4eba\u5404\u81ea\u7684\u5173\u8282\u3002 \u7f51\u7edc\u7ed3\u6784 \u5148\u4f7f\u7528VGG backbone\u63d0\u51fa feature map F , \u518d\u591a\u4e2astage \u5206\u522b\u8f93\u51fa S \\in R^{w\\times h}, L \\in R^{w\\times h \\times 2} \uff0c\u4e0d\u540c\u5c42\u4e4b\u95f4\u7528concat\u94fe\u63a5 \\begin{aligned} S^t &= \\rho^t(F, S^{t-1}, L^{t-1}) \\\\ L^t &= \\phi^t(F, S^{t-1}, L^{t-1}) \\end{aligned} S Confidence map training \u6bcf\u4e00\u4e2a\u6709\u6807\u6ce8\u7684\u5173\u8282\uff0c\u4ee5\u5176\u5750\u6807\u4e3a\u4e2d\u5fc3\uff0c\u8ba1\u7b97\u4e00\u4e2aGaussian heat map, S \u7531\u4e0d\u540c\u4eba\u540c\u4e00\u5173\u8282\u7684heat map\u7684\u6700\u5927\u503c\u7ec4\u6210\u3002 \u5728\u63a8\u7406\u7684\u65f6\u5019\uff0c\u4f7f\u7528NMS\u5254\u9664\u4e0d\u5728\u6700\u9ad8\u70b9\u7684\u70b9 PAF for part association pipeline\u4e2d\u63d0\u5230\u8fc7 PAF( L )\u662f\u4e00\u4e2a2\u7ef4\u7684\u5411\u91cf\u573a\u56fe,\u8fd9\u91cc\u6709\u4e00\u4e2a\"limb\"(\u80a2\u4f53)\u7684\u6982\u5ff5\uff0c\u5b9a\u4e49\u4e3a\u4e24\u4e2a\u76f8\u90bb\u5173\u8282\u4e4b\u95f4\u7684\u8fde\u63a5\uff0c\u4f5c\u8005\u6839\u636e\u4eba\u4f53\u7279\u5f81\u9884\u5b9a\u4e49\u4e86\u4e00\u7cfb\u5217\u7684\"limb\". \u8ddd\u79bb\u76f8\u90bb\u5173\u8282\u7ebf\u6bb5\u6700\u77ed\u8ddd\u79bb\u5c0f\u4e8e\u4e00\u4e2a\u9608\u503c\uff0c\u540c\u65f6\u6295\u5f71\u5728\u7ebf\u6bb5\u5185\u7684\u70b9\uff0c\u4f1a\u5e26\u4e0a\u4e00\u4e2a\u6807\u6ce8\uff0c\u5176\u6807\u6ce8\u503c\u4e3a\u8fd9\u4e24\u4e2a\u5173\u8282\u4e4b\u95f4\u7684\u5355\u4f4d\u76f4\u7ebf\u77e2\u91cf,\u76ee\u6807\u7684PAF\u5219\u662f\u540c\u4e00\u56fe\u4e2d\u6240\u6709\u4eba\u540c\u4e00limb\u7684\u5747\u503c\u3002 \u5728inference\u7684\u65f6\u5019\uff0c\u88ab\u4e00\u4e2alimb\u6240\u8fde\u63a5\u7684\u4e24\u4e2a\u5173\u8282\u4e4b\u95f4\u76f8\u4e92\u5339\u914d\u7684\u6743\u91cd\u4e3a\u5982\u4e0b\u7684\u79ef\u5206 E = \\int^{u=1}_{u=0}L_c(p(u)) \\frac{d_{j2} - d_{j1}}{||d_{j2} - d_{j1}||_2} du \u5176\u4e2d p(u) \u7531\u53cc\u7ebf\u6027\u63d2\u503c\u5f97\u5230\uff0c\u800c\u5b9e\u9645\u4e0a\u7684\u79ef\u5206\u4e5f\u6709\u5747\u5300\u91c7\u6837\u4e2d\u95f4\u70b9\u5f97\u5230\u3002 \u5339\u914d\u95ee\u9898 \u4ecepartition graph\u7684\u70b9\u5339\u914d\u95ee\u9898\u7684\u89d2\u5ea6,\u56de\u987e\u4e00\u4e0b\u5173\u8282\u70b9\u7684\u5339\u914d\u95ee\u9898 \u4e25\u683c\u6765\u8bf4\uff0c\u6211\u4eec\u9700\u8981\u8ba1\u7b97\u7684\u662f\u5982 b \u56fe\u4e00\u6837\u7684\u4ece K \u4e2a\u5206\u79bb\u56fe\u4e2d\u5f97\u5230 N \u7ec4\u6700\u4f18\u7684\u7531 K \u4e2a\u5173\u8282\u7ec4\u6210\u7684\u5339\u914d\u7ec4\uff0c\u4f5c\u8005\u6307\u51fa\u8fd9\u662f\u4e00\u4e2aNP\u96be\u95ee\u9898.\u4e3a\u4e86\u5728\u80a2\u4f53\u4f30\u8ba1\u8fd9\u4e2a\u9886\u57df\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u4f5c\u8005\u505a\u4e86\u4e00\u5b9a\u7684\u7b80\u5316\uff0c\u4e5f\u5c31\u662f\u53ea\u5b8c\u6210\u5bf9 \u76f8\u90bb\u5173\u8282 \u4e4b\u95f4\u7684\u76f8\u4e92\u6700\u4f18\u5339\u914d\u800c\u4e0d\u505a \u5168\u5c40 \u7684\u6700\u4f18\u5339\u914d. \u76f8\u90bb\u7684\u4e8c\u5206\u79bb\u7684\u5339\u914d\u95ee\u9898\uff0c\u5176\u6743\u91cd\u7531\u524d\u6587\u7684PAF\u8ba1\u7b97\u5f97\u5230\uff0c\u518d\u7528 \u5308\u7259\u5229\u7b97\u6cd5 \u5b8c\u6210\u5339\u914d\u3002\u5982\u6b64\u7b80\u5316\u53ef\u4ee5\u6307\u6570\u7ea7\u5730\u51cf\u5c11\u8fd0\u7b97\u91cf\uff0c\u4f7f\u5f97\u7b97\u6cd5\u53ef\u4f7f\u7528\u3002","title":"Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields"},{"location":"other_categories/others/openpose_part_afinity_fileds/#realtime-multi-person-2d-pose-estimation-using-part-affinity-fields","text":"\u8fd9\u7bc7\u8bba\u6587\u662f Open Pose\u5e93 \u8fc8\u5411\u5b9e\u65f6\u591a\u4eba\u80a2\u4f53\u4f30\u8ba1\u7684\u7b2c\u4e00\u7bc7\u8bba\u6587\uff0c\u4e3b\u8981\u662f\u89e3\u51b3\u80a2\u4f53\u4f30\u8ba1\u4e2d\u7684\u5339\u914d\u95ee\u9898\u3002","title":"Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields"},{"location":"other_categories/others/openpose_part_afinity_fileds/#pose-estimation-pipeline","text":"\u603b\u4f53\u6846\u67b6\u5982\u56fe\uff0cCNN\u4f1a\u8f93\u51fa\u4e24\u4e2a\u5206\u652f\uff0c\u4e00\u4e2a\u5206\u652f\u662f\u5173\u8282\u4f4d\u7f6e\u70ed\u56fe\uff0c\u4e00\u4e2a\u5206\u652f\u662f\u5c40\u90e8\u80a2\u4f53\u77e2\u91cf\u56fe(Part Affinity Fields, PAF)\u3002\u901a\u8fc7NMS\u5f97\u5230\u56fe\u4e2d\u6240\u6709\u4eba\u5404\u4e2a\u5173\u8282\u7684\u4f4d\u7f6e\u3002\u518d\u901a\u8fc7PAF\u63a8\u7406\u3001\u5206\u7ec4\u51fa\u5404\u4e2a\u4eba\u5404\u81ea\u7684\u5173\u8282\u3002","title":"Pose Estimation pipeline"},{"location":"other_categories/others/openpose_part_afinity_fileds/#_1","text":"\u5148\u4f7f\u7528VGG backbone\u63d0\u51fa feature map F , \u518d\u591a\u4e2astage \u5206\u522b\u8f93\u51fa S \\in R^{w\\times h}, L \\in R^{w\\times h \\times 2} \uff0c\u4e0d\u540c\u5c42\u4e4b\u95f4\u7528concat\u94fe\u63a5 \\begin{aligned} S^t &= \\rho^t(F, S^{t-1}, L^{t-1}) \\\\ L^t &= \\phi^t(F, S^{t-1}, L^{t-1}) \\end{aligned}","title":"\u7f51\u7edc\u7ed3\u6784"},{"location":"other_categories/others/openpose_part_afinity_fileds/#s-confidence-map-training","text":"\u6bcf\u4e00\u4e2a\u6709\u6807\u6ce8\u7684\u5173\u8282\uff0c\u4ee5\u5176\u5750\u6807\u4e3a\u4e2d\u5fc3\uff0c\u8ba1\u7b97\u4e00\u4e2aGaussian heat map, S \u7531\u4e0d\u540c\u4eba\u540c\u4e00\u5173\u8282\u7684heat map\u7684\u6700\u5927\u503c\u7ec4\u6210\u3002 \u5728\u63a8\u7406\u7684\u65f6\u5019\uff0c\u4f7f\u7528NMS\u5254\u9664\u4e0d\u5728\u6700\u9ad8\u70b9\u7684\u70b9","title":"S Confidence map training"},{"location":"other_categories/others/openpose_part_afinity_fileds/#paf-for-part-association","text":"pipeline\u4e2d\u63d0\u5230\u8fc7 PAF( L )\u662f\u4e00\u4e2a2\u7ef4\u7684\u5411\u91cf\u573a\u56fe,\u8fd9\u91cc\u6709\u4e00\u4e2a\"limb\"(\u80a2\u4f53)\u7684\u6982\u5ff5\uff0c\u5b9a\u4e49\u4e3a\u4e24\u4e2a\u76f8\u90bb\u5173\u8282\u4e4b\u95f4\u7684\u8fde\u63a5\uff0c\u4f5c\u8005\u6839\u636e\u4eba\u4f53\u7279\u5f81\u9884\u5b9a\u4e49\u4e86\u4e00\u7cfb\u5217\u7684\"limb\". \u8ddd\u79bb\u76f8\u90bb\u5173\u8282\u7ebf\u6bb5\u6700\u77ed\u8ddd\u79bb\u5c0f\u4e8e\u4e00\u4e2a\u9608\u503c\uff0c\u540c\u65f6\u6295\u5f71\u5728\u7ebf\u6bb5\u5185\u7684\u70b9\uff0c\u4f1a\u5e26\u4e0a\u4e00\u4e2a\u6807\u6ce8\uff0c\u5176\u6807\u6ce8\u503c\u4e3a\u8fd9\u4e24\u4e2a\u5173\u8282\u4e4b\u95f4\u7684\u5355\u4f4d\u76f4\u7ebf\u77e2\u91cf,\u76ee\u6807\u7684PAF\u5219\u662f\u540c\u4e00\u56fe\u4e2d\u6240\u6709\u4eba\u540c\u4e00limb\u7684\u5747\u503c\u3002 \u5728inference\u7684\u65f6\u5019\uff0c\u88ab\u4e00\u4e2alimb\u6240\u8fde\u63a5\u7684\u4e24\u4e2a\u5173\u8282\u4e4b\u95f4\u76f8\u4e92\u5339\u914d\u7684\u6743\u91cd\u4e3a\u5982\u4e0b\u7684\u79ef\u5206 E = \\int^{u=1}_{u=0}L_c(p(u)) \\frac{d_{j2} - d_{j1}}{||d_{j2} - d_{j1}||_2} du \u5176\u4e2d p(u) \u7531\u53cc\u7ebf\u6027\u63d2\u503c\u5f97\u5230\uff0c\u800c\u5b9e\u9645\u4e0a\u7684\u79ef\u5206\u4e5f\u6709\u5747\u5300\u91c7\u6837\u4e2d\u95f4\u70b9\u5f97\u5230\u3002","title":"PAF for part association"},{"location":"other_categories/others/openpose_part_afinity_fileds/#_2","text":"\u4ecepartition graph\u7684\u70b9\u5339\u914d\u95ee\u9898\u7684\u89d2\u5ea6,\u56de\u987e\u4e00\u4e0b\u5173\u8282\u70b9\u7684\u5339\u914d\u95ee\u9898 \u4e25\u683c\u6765\u8bf4\uff0c\u6211\u4eec\u9700\u8981\u8ba1\u7b97\u7684\u662f\u5982 b \u56fe\u4e00\u6837\u7684\u4ece K \u4e2a\u5206\u79bb\u56fe\u4e2d\u5f97\u5230 N \u7ec4\u6700\u4f18\u7684\u7531 K \u4e2a\u5173\u8282\u7ec4\u6210\u7684\u5339\u914d\u7ec4\uff0c\u4f5c\u8005\u6307\u51fa\u8fd9\u662f\u4e00\u4e2aNP\u96be\u95ee\u9898.\u4e3a\u4e86\u5728\u80a2\u4f53\u4f30\u8ba1\u8fd9\u4e2a\u9886\u57df\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u4f5c\u8005\u505a\u4e86\u4e00\u5b9a\u7684\u7b80\u5316\uff0c\u4e5f\u5c31\u662f\u53ea\u5b8c\u6210\u5bf9 \u76f8\u90bb\u5173\u8282 \u4e4b\u95f4\u7684\u76f8\u4e92\u6700\u4f18\u5339\u914d\u800c\u4e0d\u505a \u5168\u5c40 \u7684\u6700\u4f18\u5339\u914d. \u76f8\u90bb\u7684\u4e8c\u5206\u79bb\u7684\u5339\u914d\u95ee\u9898\uff0c\u5176\u6743\u91cd\u7531\u524d\u6587\u7684PAF\u8ba1\u7b97\u5f97\u5230\uff0c\u518d\u7528 \u5308\u7259\u5229\u7b97\u6cd5 \u5b8c\u6210\u5339\u914d\u3002\u5982\u6b64\u7b80\u5316\u53ef\u4ee5\u6307\u6570\u7ea7\u5730\u51cf\u5c11\u8fd0\u7b97\u91cf\uff0c\u4f7f\u5f97\u7b97\u6cd5\u53ef\u4f7f\u7528\u3002","title":"\u5339\u914d\u95ee\u9898"},{"location":"other_categories/others/self_supervised_stereo/","text":"Self-Supervised Learning for Stereo Matching with Self-Improving Ability \u8fd9\u7bc7paper\u5173\u6ce8\u7684\u662f\u81ea\u76d1\u7763\u53cc\u76ee\u5339\u914d\u3002\u91cd\u70b9\u5728\u4e8e\u4e0d\u9700\u8981\u70b9\u4e91\u76d1\u7763\uff0c\u800c\u4e14\u5728\u65b0\u573a\u666f\u6d4b\u8bd5\u7684\u65f6\u5019\u53ef\u4ee5\u91cd\u65b0\u8fed\u4ee3\u8fdb\u6b65\u3002 \u7f51\u7edc\u7ed3\u6784 \u5176\u4e2d\u7684feature mapping \u5de6\u53f3\u76ee\u5206\u522b\u8fd0\u884c\u5bf9\u79f0\u7684\u7f51\u7edc\u3002 \u635f\u5931\u51fd\u6570 \u5de6\u53f3\u56fe\u751f\u6210\u4e00\u81f4\u6027 \\begin{aligned} \\mathcal{L}_{u}^{l}\\left(I_{L}, I_{L}^{\\prime}\\right) &=\\frac{1}{N} \\sum \\lambda_{1} \\frac{1-\\mathcal{S}\\left(I_{L}, I_{L}^{\\prime}\\right)}{2} \\\\ &+\\lambda_{2}\\left|I_{L}-I_{L}^{\\prime}\\right|+\\lambda_{3}\\left|\\nabla I_{L}-\\nabla I_{L}^{\\prime}\\right| \\end{aligned} \u5206\u4e09\u9879\uff0c\u5206\u522b\u662fSSIM,\u5de6\u56fe\uff0c\u56fe\u7247\u68af\u5ea6\u3002 def SSIM ( self , x , y ): C1 = 0.01 ** 2 C2 = 0.03 ** 2 mu_x = nn . AvgPool2d ( 3 , 1 )( x ) mu_y = nn . AvgPool2d ( 3 , 1 )( y ) mu_x_mu_y = mu_x * mu_y mu_x_sq = mu_x . pow ( 2 ) mu_y_sq = mu_y . pow ( 2 ) sigma_x = nn . AvgPool2d ( 3 , 1 )( x * x ) - mu_x_sq sigma_y = nn . AvgPool2d ( 3 , 1 )( y * y ) - mu_y_sq sigma_xy = nn . AvgPool2d ( 3 , 1 )( x * y ) - mu_x_mu_y SSIM_n = ( 2 * mu_x_mu_y + C1 ) * ( 2 * sigma_xy + C2 ) SSIM_d = ( mu_x_sq + mu_y_sq + C1 ) * ( sigma_x + sigma_y + C2 ) SSIM = SSIM_n / SSIM_d return torch . clamp (( 1 - SSIM ) / 2 , 0 , 1 ) \u89c4\u8303\u5316 \u5e73\u7a33\u6027,\u56fe\u7247\u4e8c\u6b21\u68af\u5ea6 \\mathcal{L}_{s}^{l}=\\frac{1}{N} \\sum\\left|\\nabla_{u}^{2} d_{L}\\right| e^{-\\left|\\nabla_{u}^{2} I_{L}\\right|}+\\left|\\nabla_{v}^{2} d_{L}\\right| e^{-\\left|\\nabla_{v}^{2} I_{L}\\right|} \u5faa\u73af\u4e00\u81f4\u6027 \\mathcal{L}_{c}^{L}=\\left|I_{L}-I_{L}^{\\prime \\prime}\\right| Maximum-Depth Heuristic \u6700\u5c0f\u5316dispairty\u7684\u603b\u548c\u3002 \\mathcal{L}_{m}^{L}=\\frac{1}{N} \\sum\\left|d^{L}\\right| \u81ea\u63d0\u5347 \u5728\u6d4b\u8bd5\u7684\u65f6\u5019\u53ef\u4ee5\u8fdb\u4e00\u6b65fine-tune\u7f51\u7edc\u3002\u6027\u80fd\u8fd8\u80fd\u63d0\u5347","title":"Self-Supervised Learning for Stereo Matching with Self-Improving Ability"},{"location":"other_categories/others/self_supervised_stereo/#self-supervised-learning-for-stereo-matching-with-self-improving-ability","text":"\u8fd9\u7bc7paper\u5173\u6ce8\u7684\u662f\u81ea\u76d1\u7763\u53cc\u76ee\u5339\u914d\u3002\u91cd\u70b9\u5728\u4e8e\u4e0d\u9700\u8981\u70b9\u4e91\u76d1\u7763\uff0c\u800c\u4e14\u5728\u65b0\u573a\u666f\u6d4b\u8bd5\u7684\u65f6\u5019\u53ef\u4ee5\u91cd\u65b0\u8fed\u4ee3\u8fdb\u6b65\u3002","title":"Self-Supervised Learning for Stereo Matching with Self-Improving Ability"},{"location":"other_categories/others/self_supervised_stereo/#_1","text":"\u5176\u4e2d\u7684feature mapping \u5de6\u53f3\u76ee\u5206\u522b\u8fd0\u884c\u5bf9\u79f0\u7684\u7f51\u7edc\u3002","title":"\u7f51\u7edc\u7ed3\u6784"},{"location":"other_categories/others/self_supervised_stereo/#_2","text":"","title":"\u635f\u5931\u51fd\u6570"},{"location":"other_categories/others/self_supervised_stereo/#_3","text":"\\begin{aligned} \\mathcal{L}_{u}^{l}\\left(I_{L}, I_{L}^{\\prime}\\right) &=\\frac{1}{N} \\sum \\lambda_{1} \\frac{1-\\mathcal{S}\\left(I_{L}, I_{L}^{\\prime}\\right)}{2} \\\\ &+\\lambda_{2}\\left|I_{L}-I_{L}^{\\prime}\\right|+\\lambda_{3}\\left|\\nabla I_{L}-\\nabla I_{L}^{\\prime}\\right| \\end{aligned} \u5206\u4e09\u9879\uff0c\u5206\u522b\u662fSSIM,\u5de6\u56fe\uff0c\u56fe\u7247\u68af\u5ea6\u3002 def SSIM ( self , x , y ): C1 = 0.01 ** 2 C2 = 0.03 ** 2 mu_x = nn . AvgPool2d ( 3 , 1 )( x ) mu_y = nn . AvgPool2d ( 3 , 1 )( y ) mu_x_mu_y = mu_x * mu_y mu_x_sq = mu_x . pow ( 2 ) mu_y_sq = mu_y . pow ( 2 ) sigma_x = nn . AvgPool2d ( 3 , 1 )( x * x ) - mu_x_sq sigma_y = nn . AvgPool2d ( 3 , 1 )( y * y ) - mu_y_sq sigma_xy = nn . AvgPool2d ( 3 , 1 )( x * y ) - mu_x_mu_y SSIM_n = ( 2 * mu_x_mu_y + C1 ) * ( 2 * sigma_xy + C2 ) SSIM_d = ( mu_x_sq + mu_y_sq + C1 ) * ( sigma_x + sigma_y + C2 ) SSIM = SSIM_n / SSIM_d return torch . clamp (( 1 - SSIM ) / 2 , 0 , 1 )","title":"\u5de6\u53f3\u56fe\u751f\u6210\u4e00\u81f4\u6027"},{"location":"other_categories/others/self_supervised_stereo/#_4","text":"\u5e73\u7a33\u6027,\u56fe\u7247\u4e8c\u6b21\u68af\u5ea6 \\mathcal{L}_{s}^{l}=\\frac{1}{N} \\sum\\left|\\nabla_{u}^{2} d_{L}\\right| e^{-\\left|\\nabla_{u}^{2} I_{L}\\right|}+\\left|\\nabla_{v}^{2} d_{L}\\right| e^{-\\left|\\nabla_{v}^{2} I_{L}\\right|}","title":"\u89c4\u8303\u5316"},{"location":"other_categories/others/self_supervised_stereo/#_5","text":"\\mathcal{L}_{c}^{L}=\\left|I_{L}-I_{L}^{\\prime \\prime}\\right|","title":"\u5faa\u73af\u4e00\u81f4\u6027"},{"location":"other_categories/others/self_supervised_stereo/#maximum-depth-heuristic","text":"\u6700\u5c0f\u5316dispairty\u7684\u603b\u548c\u3002 \\mathcal{L}_{m}^{L}=\\frac{1}{N} \\sum\\left|d^{L}\\right|","title":"Maximum-Depth Heuristic"},{"location":"other_categories/others/self_supervised_stereo/#_6","text":"\u5728\u6d4b\u8bd5\u7684\u65f6\u5019\u53ef\u4ee5\u8fdb\u4e00\u6b65fine-tune\u7f51\u7edc\u3002\u6027\u80fd\u8fd8\u80fd\u63d0\u5347","title":"\u81ea\u63d0\u5347"},{"location":"other_categories/others/space_sweep/","text":"A Space-Sweep Approach to True Multi-Image Matching \u8fd9\u7bc7\u4f5c\u8005\u63d0\u51fa\u4f7f\u7528 plane sweeping algorithm\u53bb\u5904\u7406\u591a\u56fe\u7247matching\u7684\u95ee\u9898\u3002 \u9996\u5148\u4f5c\u8005\u6307\u660e\uff0c\u6240\u8c13\"True Multi-Image Matching\"\uff0c\u9700\u8981\u6ee1\u8db3\u4e09\u4e2a\u6761\u4ef6 1. \u8be5\u65b9\u6cd5\u53ef\u4ee5\u7528\u5728\u4efb\u610f\u591a\u7684\u76f8\u673a\u4e2d\u3002 2. \u7b97\u6cd5\u7684\u590d\u6742\u5ea6\u6b63\u6bd4\u4e8e\u76f8\u673a\u7684\u4e2a\u6570\u3002 3. \u6240\u6709\u56fe\u7247\u5728\u8ba1\u7b97\u4e0a\u7684\u5904\u7406\u662f\u4e00\u81f4\u7684\u3002 Plane sweeping \u603b\u4f53\u6846\u67b6\u4e0a\u6765\u8bf4\uff0cspace sweep\u7684\u7b97\u6cd5\u63cf\u8ff0\u7684\u662f\u9009\u53d6\u4e00\u7cfb\u5217\u5e73\u884c\u7684\u5e73\u9762\u3002\u5c06\u6bcf\u4e00\u4e2aimage\u4e0a\u7684\u6bcf\u4e00\u4e2akeypoint\u6295\u5f71\u5230\u6bcf\u4e00\u4e2a\u5e73\u9762\u4e0a\u3002\u5728\u6bcf\u4e00\u4e2a\u5e73\u9762\u4e0a\u7684\u6240\u6709keypoint\u8fdb\u884ccelluar voting\uff0c\u786e\u5b9akeypoint\u805a\u96c6\u76843D\u4f4d\u7f6e\u5e76\u5224\u65ad\u6b64\u5904\u786e\u5b9e\u6709\u4e00\u4e2a\u70b9\u3002 \u6240\u4ee5\u4e3a\u4e86\u9ad8\u6548\u7387\u5730\u8ba1\u7b97\uff0c\u8fd9\u91cc\u9700\u8981\u5206\u522b\u8ba8\u8bba\u8fd9\u4e24\u4e2a\u6b65\u9aa4\u7684\u5b9e\u73b0\u65b9\u6cd5\u3002 \u6295\u5f71 \u6807\u51c6\u7684\u601d\u8def\u662f\u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u5e73\u9762 z_i ,\u56fe\u7247\u4e0a\u7684\u6bcf\u4e00\u4e2akeypoint\u90fd\u9700\u8981\u8fd0\u884c\u4e00\u4e2a\u9006\u6295\u5f71\uff0c\u8fd9\u4e2a\u65b9\u6cd5\u6bd4\u8f83\u6162\uff0c\u4f5c\u8005\u63d0\u51fa\uff0c\u53ef\u4ee5\u5148\u5c06\u56fe\u50cf\u70b9\u6295\u5f71\u5230\u67d0\u4e00\u4e2a\u5e73\u9762 z_0 \u5904\uff0c\u7136\u540e\u518d\u5e73\u884c\u7684\u5176\u4ed6\u5e73\u9762\u4e0a\u7684\u6295\u5f71\u53ef\u4ee5\u7531\u4e24\u4e2a\u5355\u5e94\u6027\u77e9\u9635 H \u53d8\u6362\u800c\u5f97. \\begin{array}{l} {x_{i}=\\delta x_{0}+(1-\\delta) C_{x}} \\\\ {y_{i}=\\delta y_{0}+(1-\\delta) C_{y}} \\end{array} \\delta = (z_i - C_z)/(z_0 - C_z) C_x, C_y, C_z = -r_{1} \\cdot t, -r_{2} \\cdot t, -r_{3} \\cdot t \u76f8\u5f53\u4e8e\u662f\u4f7f\u7528\u76f8\u4f3c\u4e09\u89d2\u5f62\u5728\u8fdb\u884c\u8ba1\u7b97\u3002 voting \u4e25\u8c28\u6765\u8bf4\uff0c\u540c\u4e00\u4e2apoint\u53ef\u4ee5\u7ed9\u6295\u5f71\u70b9\u9644\u4ef6\u4e00\u4e2a\u533a\u57df\u7684cell\u8fdb\u884c\u6295\u7968\uff0c\u7406\u8bba\u4e0a\u6765\u8bf4\u9700\u8981\u6c42jacobian\u3002\u672c\u6587\u6700\u7ec8\u91c7\u53d6\u7684\u65b9\u5f0f\u662f\u8ba9\u8ddd\u79bb\u76f8\u540c\u7684\u70b9\u6295\u7968\u8303\u56f4\u76f8\u540c\uff0c\u5e76\u4e14\u4e3a\u4e00\u4e2aconstant\u3002\u4e5f\u5c31\u662f\u8bf4\u6295\u7968\u7684\u8303\u56f4\u3001\u91c7\u6837\u6982\u7387\u4ec5\u4e0e\u8ddd\u79bb\u6210\u6b63\u6bd4\u5373\u53ef\u3002 \u6700\u7ec8\u901a\u8fc7\u9608\u503c\u8bbe\u7f6e\u5f97\u5230solid 3D point.","title":"A Space-Sweep Approach to True Multi-Image Matching"},{"location":"other_categories/others/space_sweep/#a-space-sweep-approach-to-true-multi-image-matching","text":"\u8fd9\u7bc7\u4f5c\u8005\u63d0\u51fa\u4f7f\u7528 plane sweeping algorithm\u53bb\u5904\u7406\u591a\u56fe\u7247matching\u7684\u95ee\u9898\u3002 \u9996\u5148\u4f5c\u8005\u6307\u660e\uff0c\u6240\u8c13\"True Multi-Image Matching\"\uff0c\u9700\u8981\u6ee1\u8db3\u4e09\u4e2a\u6761\u4ef6 1. \u8be5\u65b9\u6cd5\u53ef\u4ee5\u7528\u5728\u4efb\u610f\u591a\u7684\u76f8\u673a\u4e2d\u3002 2. \u7b97\u6cd5\u7684\u590d\u6742\u5ea6\u6b63\u6bd4\u4e8e\u76f8\u673a\u7684\u4e2a\u6570\u3002 3. \u6240\u6709\u56fe\u7247\u5728\u8ba1\u7b97\u4e0a\u7684\u5904\u7406\u662f\u4e00\u81f4\u7684\u3002","title":"A Space-Sweep Approach to True Multi-Image Matching"},{"location":"other_categories/others/space_sweep/#plane-sweeping","text":"\u603b\u4f53\u6846\u67b6\u4e0a\u6765\u8bf4\uff0cspace sweep\u7684\u7b97\u6cd5\u63cf\u8ff0\u7684\u662f\u9009\u53d6\u4e00\u7cfb\u5217\u5e73\u884c\u7684\u5e73\u9762\u3002\u5c06\u6bcf\u4e00\u4e2aimage\u4e0a\u7684\u6bcf\u4e00\u4e2akeypoint\u6295\u5f71\u5230\u6bcf\u4e00\u4e2a\u5e73\u9762\u4e0a\u3002\u5728\u6bcf\u4e00\u4e2a\u5e73\u9762\u4e0a\u7684\u6240\u6709keypoint\u8fdb\u884ccelluar voting\uff0c\u786e\u5b9akeypoint\u805a\u96c6\u76843D\u4f4d\u7f6e\u5e76\u5224\u65ad\u6b64\u5904\u786e\u5b9e\u6709\u4e00\u4e2a\u70b9\u3002 \u6240\u4ee5\u4e3a\u4e86\u9ad8\u6548\u7387\u5730\u8ba1\u7b97\uff0c\u8fd9\u91cc\u9700\u8981\u5206\u522b\u8ba8\u8bba\u8fd9\u4e24\u4e2a\u6b65\u9aa4\u7684\u5b9e\u73b0\u65b9\u6cd5\u3002","title":"Plane sweeping"},{"location":"other_categories/others/space_sweep/#_1","text":"\u6807\u51c6\u7684\u601d\u8def\u662f\u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u5e73\u9762 z_i ,\u56fe\u7247\u4e0a\u7684\u6bcf\u4e00\u4e2akeypoint\u90fd\u9700\u8981\u8fd0\u884c\u4e00\u4e2a\u9006\u6295\u5f71\uff0c\u8fd9\u4e2a\u65b9\u6cd5\u6bd4\u8f83\u6162\uff0c\u4f5c\u8005\u63d0\u51fa\uff0c\u53ef\u4ee5\u5148\u5c06\u56fe\u50cf\u70b9\u6295\u5f71\u5230\u67d0\u4e00\u4e2a\u5e73\u9762 z_0 \u5904\uff0c\u7136\u540e\u518d\u5e73\u884c\u7684\u5176\u4ed6\u5e73\u9762\u4e0a\u7684\u6295\u5f71\u53ef\u4ee5\u7531\u4e24\u4e2a\u5355\u5e94\u6027\u77e9\u9635 H \u53d8\u6362\u800c\u5f97. \\begin{array}{l} {x_{i}=\\delta x_{0}+(1-\\delta) C_{x}} \\\\ {y_{i}=\\delta y_{0}+(1-\\delta) C_{y}} \\end{array} \\delta = (z_i - C_z)/(z_0 - C_z) C_x, C_y, C_z = -r_{1} \\cdot t, -r_{2} \\cdot t, -r_{3} \\cdot t \u76f8\u5f53\u4e8e\u662f\u4f7f\u7528\u76f8\u4f3c\u4e09\u89d2\u5f62\u5728\u8fdb\u884c\u8ba1\u7b97\u3002","title":"\u6295\u5f71"},{"location":"other_categories/others/space_sweep/#voting","text":"\u4e25\u8c28\u6765\u8bf4\uff0c\u540c\u4e00\u4e2apoint\u53ef\u4ee5\u7ed9\u6295\u5f71\u70b9\u9644\u4ef6\u4e00\u4e2a\u533a\u57df\u7684cell\u8fdb\u884c\u6295\u7968\uff0c\u7406\u8bba\u4e0a\u6765\u8bf4\u9700\u8981\u6c42jacobian\u3002\u672c\u6587\u6700\u7ec8\u91c7\u53d6\u7684\u65b9\u5f0f\u662f\u8ba9\u8ddd\u79bb\u76f8\u540c\u7684\u70b9\u6295\u7968\u8303\u56f4\u76f8\u540c\uff0c\u5e76\u4e14\u4e3a\u4e00\u4e2aconstant\u3002\u4e5f\u5c31\u662f\u8bf4\u6295\u7968\u7684\u8303\u56f4\u3001\u91c7\u6837\u6982\u7387\u4ec5\u4e0e\u8ddd\u79bb\u6210\u6b63\u6bd4\u5373\u53ef\u3002 \u6700\u7ec8\u901a\u8fc7\u9608\u503c\u8bbe\u7f6e\u5f97\u5230solid 3D point.","title":"voting"},{"location":"other_categories/undone/ApplicationofHDRalgorithmstosolvedirectsunlightproblemswhenautonomousvehiclesusingmachinevisionsystemsaredrivingintosun/","text":"Application of HDR algorithms to solve direct sunlight problems when autonomous vehicles using machine vision systems are driving into sun","title":"Application of HDR algorithms to solve direct sunlight problems when autonomous vehicles using machine vision systems are driving into sun"},{"location":"other_categories/undone/ApplicationofHDRalgorithmstosolvedirectsunlightproblemswhenautonomousvehiclesusingmachinevisionsystemsaredrivingintosun/#application-of-hdr-algorithms-to-solve-direct-sunlight-problems-when-autonomous-vehicles-using-machine-vision-systems-are-driving-into-sun","text":"","title":"Application of HDR algorithms to solve direct sunlight problems when autonomous vehicles using machine vision systems are driving into sun"},{"location":"other_categories/undone/Autonomous  Racing  using  Learning  Model  Predictive  Control/","text":"Autonomous Racing using Learning Model Predictive Control","title":"Autonomous  Racing  using  Learning  Model  Predictive  Control"},{"location":"other_categories/undone/Autonomous  Racing  using  Learning  Model  Predictive  Control/#autonomous-racing-using-learning-model-predictive-control","text":"","title":"Autonomous  Racing  using  Learning  Model  Predictive  Control"},{"location":"other_categories/undone/BeliefPropagationLayer/","text":"Belief Propagation Reloaded: Learning BP-Layers for Labeling Problems","title":"Belief Propagation Reloaded: Learning BP-Layers for Labeling Problems"},{"location":"other_categories/undone/BeliefPropagationLayer/#belief-propagation-reloaded-learning-bp-layers-for-labeling-problems","text":"","title":"Belief Propagation Reloaded: Learning BP-Layers for Labeling Problems"},{"location":"other_categories/undone/Beyond Pixels Leveraging Geometry and Shape Cues for OnlineMulti-Object Tracking/","text":"Beyond Pixels: Leveraging Geometry and Shape Cues for OnlineMulti-Object Tracking","title":"Beyond Pixels: Leveraging Geometry and Shape Cues for OnlineMulti-Object Tracking"},{"location":"other_categories/undone/Beyond Pixels Leveraging Geometry and Shape Cues for OnlineMulti-Object Tracking/#beyond-pixels-leveraging-geometry-and-shape-cues-for-onlinemulti-object-tracking","text":"","title":"Beyond Pixels: Leveraging Geometry and Shape Cues for OnlineMulti-Object Tracking"},{"location":"other_categories/undone/Data-Driven Modeling and Control of an Autonomous Race Car/","text":"Data-Driven Modeling and Control of an Autonomous Race Car","title":"Data-Driven Modeling and Control of an Autonomous Race Car"},{"location":"other_categories/undone/Data-Driven Modeling and Control of an Autonomous Race Car/#data-driven-modeling-and-control-of-an-autonomous-race-car","text":"","title":"Data-Driven Modeling and Control of an Autonomous Race Car"},{"location":"other_categories/undone/Deep Hough Voting for 3D Object Detection in Point Clouds/","text":"Deep Hough Voting for 3D Object Detection in Point Clouds","title":"Deep Hough Voting for 3D Object Detection in Point Clouds"},{"location":"other_categories/undone/Deep Hough Voting for 3D Object Detection in Point Clouds/#deep-hough-voting-for-3d-object-detection-in-point-clouds","text":"","title":"Deep Hough Voting for 3D Object Detection in Point Clouds"},{"location":"other_categories/undone/Deep Imitative Models for Flexible Inference,Planning, and Control/","text":"Deep Imitative Models for Flexible Inference,Planning, and Control","title":"Deep Imitative Models for Flexible Inference,Planning, and Control"},{"location":"other_categories/undone/Deep Imitative Models for Flexible Inference,Planning, and Control/#deep-imitative-models-for-flexible-inferenceplanning-and-control","text":"","title":"Deep Imitative Models for Flexible Inference,Planning, and Control"},{"location":"other_categories/undone/END-TO-END LEARNABLE HISTOGRAM FILTERS/","text":"END-TO-END LEARNABLE HISTOGRAM FILTERS","title":"END-TO-END LEARNABLE HISTOGRAM FILTERS"},{"location":"other_categories/undone/END-TO-END LEARNABLE HISTOGRAM FILTERS/#end-to-end-learnable-histogram-filters","text":"","title":"END-TO-END LEARNABLE HISTOGRAM FILTERS"},{"location":"other_categories/undone/End-To-End Multi-Modal Sensors Fusion System ForUrban Automated Driving/","text":"End-To-End Multi-Modal Sensors Fusion System For Urban Automated Driving","title":"End-To-End Multi-Modal Sensors Fusion System For Urban Automated Driving"},{"location":"other_categories/undone/End-To-End Multi-Modal Sensors Fusion System ForUrban Automated Driving/#end-to-end-multi-modal-sensors-fusion-system-for-urban-automated-driving","text":"","title":"End-To-End Multi-Modal Sensors Fusion System For Urban Automated Driving"},{"location":"other_categories/undone/Enhanced  free  space  detection  in  multiple  lanes  based  on  single  CNNwith  scene  identification/","text":"Enhanced free space detection in multiple lanes based on single CNN with scene identification","title":"Enhanced  free  space  detection  in  multiple  lanes  based  on  single  CNN with  scene  identification"},{"location":"other_categories/undone/Enhanced  free  space  detection  in  multiple  lanes  based  on  single  CNNwith  scene  identification/#enhanced-free-space-detection-in-multiple-lanes-based-on-single-cnn-with-scene-identification","text":"","title":"Enhanced  free  space  detection  in  multiple  lanes  based  on  single  CNN with  scene  identification"},{"location":"other_categories/undone/Exploring the structure of a real-time, arbitrary neuralartistic stylization network/","text":"Exploring the structure of a real-time, arbitrary neuralartistic stylization network","title":"Exploring the structure of a real-time, arbitrary neuralartistic stylization network"},{"location":"other_categories/undone/Exploring the structure of a real-time, arbitrary neuralartistic stylization network/#exploring-the-structure-of-a-real-time-arbitrary-neuralartistic-stylization-network","text":"","title":"Exploring the structure of a real-time, arbitrary neuralartistic stylization network"},{"location":"other_categories/undone/From Perception to Decision A Data-driven Approach to End-to-endMotion Planning for Autonomous Ground Robots/","text":"From Perception to Decision: A Data-driven Approach to End-to-end Motion Planning for Autonomous Ground Robots","title":"From Perception to Decision: A Data-driven Approach to End-to-end Motion Planning for Autonomous Ground Robots"},{"location":"other_categories/undone/From Perception to Decision A Data-driven Approach to End-to-endMotion Planning for Autonomous Ground Robots/#from-perception-to-decision-a-data-driven-approach-to-end-to-end-motion-planning-for-autonomous-ground-robots","text":"","title":"From Perception to Decision: A Data-driven Approach to End-to-end Motion Planning for Autonomous Ground Robots"},{"location":"other_categories/undone/IMAGENET-TRAINEDCNNS   ARE   BIASED   TOWARDSTEXTURE;INCREASING SHAPE BIAS IMPROVESACCURACY AND ROBUSTNESS/","text":"IMAGENET-TRAINEDCNNS ARE BIASED TOWARDS TEXTURE;INCREASING SHAPE BIAS IMPROVES ACCURACY AND ROBUSTNESS","title":"IMAGENET-TRAINEDCNNS   ARE   BIASED   TOWARDS TEXTURE;INCREASING SHAPE BIAS IMPROVES ACCURACY AND ROBUSTNESS"},{"location":"other_categories/undone/IMAGENET-TRAINEDCNNS   ARE   BIASED   TOWARDSTEXTURE;INCREASING SHAPE BIAS IMPROVESACCURACY AND ROBUSTNESS/#imagenet-trainedcnns-are-biased-towards-textureincreasing-shape-bias-improves-accuracy-and-robustness","text":"","title":"IMAGENET-TRAINEDCNNS   ARE   BIASED   TOWARDS TEXTURE;INCREASING SHAPE BIAS IMPROVES ACCURACY AND ROBUSTNESS"},{"location":"other_categories/undone/InfoGAN Interpretable Representation Learning byInformation Maximizing Generative Adversarial Nets/","text":"InfoGAN: Interpretable Representation Learning byInformation Maximizing Generative Adversarial Nets","title":"InfoGAN: Interpretable Representation Learning byInformation Maximizing Generative Adversarial Nets"},{"location":"other_categories/undone/InfoGAN Interpretable Representation Learning byInformation Maximizing Generative Adversarial Nets/#infogan-interpretable-representation-learning-byinformation-maximizing-generative-adversarial-nets","text":"","title":"InfoGAN: Interpretable Representation Learning byInformation Maximizing Generative Adversarial Nets"},{"location":"other_categories/undone/LP-3DCNN Unveiling Local Phase in 3D Convolutional Neural Networks/","text":"LP-3DCNN: Unveiling Local Phase in 3D Convolutional Neural Networks","title":"LP-3DCNN: Unveiling Local Phase in 3D Convolutional Neural Networks"},{"location":"other_categories/undone/LP-3DCNN Unveiling Local Phase in 3D Convolutional Neural Networks/#lp-3dcnn-unveiling-local-phase-in-3d-convolutional-neural-networks","text":"","title":"LP-3DCNN: Unveiling Local Phase in 3D Convolutional Neural Networks"},{"location":"other_categories/undone/LiDAR Sensor modeling and Data augmentationwith GANs for Autonomous driving/","text":"LiDAR Sensor modeling and Data augmentationwith GANs for Autonomous driving","title":"LiDAR Sensor modeling and Data augmentationwith GANs for Autonomous driving"},{"location":"other_categories/undone/LiDAR Sensor modeling and Data augmentationwith GANs for Autonomous driving/#lidar-sensor-modeling-and-data-augmentationwith-gans-for-autonomous-driving","text":"","title":"LiDAR Sensor modeling and Data augmentationwith GANs for Autonomous driving"},{"location":"other_categories/undone/Libra R-CNN Towards Balanced Learning for Object Detection/","text":"Libra R-CNN: Towards Balanced Learning for Object Detection","title":"Libra R-CNN: Towards Balanced Learning for Object Detection"},{"location":"other_categories/undone/Libra R-CNN Towards Balanced Learning for Object Detection/#libra-r-cnn-towards-balanced-learning-for-object-detection","text":"","title":"Libra R-CNN: Towards Balanced Learning for Object Detection"},{"location":"other_categories/undone/MPC-Inspired Neural Network Policies for Sequential Decision Making/","text":"MPC-Inspired Neural Network Policies for Sequential Decision Making","title":"MPC-Inspired Neural Network Policies for Sequential Decision Making"},{"location":"other_categories/undone/MPC-Inspired Neural Network Policies for Sequential Decision Making/#mpc-inspired-neural-network-policies-for-sequential-decision-making","text":"","title":"MPC-Inspired Neural Network Policies for Sequential Decision Making"},{"location":"other_categories/undone/MULTI-SCALEDENSENETWORKSFORRESOURCEEFFICIENTIMAGECLASSIFICATION/","text":"MULTI-SCALE DENSE NETWORKS FOR RESOURCE EFFICIENT IMAGE CLASSIFICATION","title":"MULTI-SCALE DENSE NETWORKS FOR RESOURCE EFFICIENT IMAGE CLASSIFICATION"},{"location":"other_categories/undone/MULTI-SCALEDENSENETWORKSFORRESOURCEEFFICIENTIMAGECLASSIFICATION/#multi-scale-dense-networks-for-resource-efficient-image-classification","text":"","title":"MULTI-SCALE DENSE NETWORKS FOR RESOURCE EFFICIENT IMAGE CLASSIFICATION"},{"location":"other_categories/undone/Motion Planning for Autonomous Driving with a Conformal Spatiotemporal Lattice/","text":"Motion Planning for Autonomous Driving with a Conformal Spatiotemporal Lattice","title":"Motion Planning for Autonomous Driving with a Conformal Spatiotemporal Lattice"},{"location":"other_categories/undone/Motion Planning for Autonomous Driving with a Conformal Spatiotemporal Lattice/#motion-planning-for-autonomous-driving-with-a-conformal-spatiotemporal-lattice","text":"","title":"Motion Planning for Autonomous Driving with a Conformal Spatiotemporal Lattice"},{"location":"other_categories/undone/Optimization Beyond the Convolution Generalizing Spatial Relationswith End-to-End Metric Learning/","text":"Optimization Beyond the Convolution: Generalizing Spatial Relationswith End-to-End Metric Learning","title":"Optimization Beyond the Convolution: Generalizing Spatial Relationswith End-to-End Metric Learning"},{"location":"other_categories/undone/Optimization Beyond the Convolution Generalizing Spatial Relationswith End-to-End Metric Learning/#optimization-beyond-the-convolution-generalizing-spatial-relationswith-end-to-end-metric-learning","text":"","title":"Optimization Beyond the Convolution: Generalizing Spatial Relationswith End-to-End Metric Learning"},{"location":"other_categories/undone/POI Multiple Object Tracking with HighPerformance Detection and Appearance Feature/","text":"POI: Multiple Object Tracking with HighPerformance Detection and Appearance Feature","title":"POI: Multiple Object Tracking with HighPerformance Detection and Appearance Feature"},{"location":"other_categories/undone/POI Multiple Object Tracking with HighPerformance Detection and Appearance Feature/#poi-multiple-object-tracking-with-highperformance-detection-and-appearance-feature","text":"","title":"POI: Multiple Object Tracking with HighPerformance Detection and Appearance Feature"},{"location":"other_categories/undone/Probabilistic Decision-Making under Uncertainty for AutonomousDriving using Continuous POMDPs/","text":"Probabilistic Decision-Making under Uncertainty for AutonomousDriving using Continuous POMDPs","title":"Probabilistic Decision-Making under Uncertainty for AutonomousDriving using Continuous POMDPs"},{"location":"other_categories/undone/Probabilistic Decision-Making under Uncertainty for AutonomousDriving using Continuous POMDPs/#probabilistic-decision-making-under-uncertainty-for-autonomousdriving-using-continuous-pomdps","text":"","title":"Probabilistic Decision-Making under Uncertainty for AutonomousDriving using Continuous POMDPs"},{"location":"other_categories/undone/RETHINKINGSELF-DRIVING  MULTI-TASKKNOWL-EDGE  FORBETTERGENERALIZATION  ANDACCIDENTEXPLANATIONABILITY/","text":"RETHINKING SELF-DRIVING: MULTI-TASK KNOWLEDGE FOR BETTER GENERALIZATION AND ACCIDENT EXPLANATIONABILITY","title":"RETHINKING SELF-DRIVING:   MULTI-TASK KNOWLEDGE  FOR BETTER GENERALIZATION  AND ACCIDENT EXPLANATIONABILITY"},{"location":"other_categories/undone/RETHINKINGSELF-DRIVING  MULTI-TASKKNOWL-EDGE  FORBETTERGENERALIZATION  ANDACCIDENTEXPLANATIONABILITY/#rethinking-self-driving-multi-task-knowledge-for-better-generalization-and-accident-explanationability","text":"","title":"RETHINKING SELF-DRIVING:   MULTI-TASK KNOWLEDGE  FOR BETTER GENERALIZATION  AND ACCIDENT EXPLANATIONABILITY"},{"location":"other_categories/undone/Real-Time Freespace Segmentation on AutonomousRobots for Detection of Obstacles and Drop-Offs/","text":"Real-Time Freespace Segmentation on AutonomousRobots for Detection of Obstacles and Drop-Offs","title":"Real-Time Freespace Segmentation on AutonomousRobots for Detection of Obstacles and Drop-Offs"},{"location":"other_categories/undone/Real-Time Freespace Segmentation on AutonomousRobots for Detection of Obstacles and Drop-Offs/#real-time-freespace-segmentation-on-autonomousrobots-for-detection-of-obstacles-and-drop-offs","text":"","title":"Real-Time Freespace Segmentation on AutonomousRobots for Detection of Obstacles and Drop-Offs"},{"location":"other_categories/undone/Restricted Deformable Convolution basedRoad Scene Semantic SegmentationUsing Surround View Cameras/","text":"Restricted Deformable Convolution based Road Scene Semantic Segmentation Using Surround View Cameras","title":"Restricted Deformable Convolution based Road Scene Semantic Segmentation Using Surround View Cameras"},{"location":"other_categories/undone/Restricted Deformable Convolution basedRoad Scene Semantic SegmentationUsing Surround View Cameras/#restricted-deformable-convolution-based-road-scene-semantic-segmentation-using-surround-view-cameras","text":"","title":"Restricted Deformable Convolution based Road Scene Semantic Segmentation Using Surround View Cameras"},{"location":"other_categories/undone/Semantic Image Synthesis with Spatially-Adaptive Normalization/","text":"Semantic Image Synthesis with Spatially-Adaptive Normalization","title":"Semantic Image Synthesis with Spatially-Adaptive Normalization"},{"location":"other_categories/undone/Semantic Image Synthesis with Spatially-Adaptive Normalization/#semantic-image-synthesis-with-spatially-adaptive-normalization","text":"","title":"Semantic Image Synthesis with Spatially-Adaptive Normalization"},{"location":"other_categories/undone/Style Augmentation Data Augmentation via StyleRandomization/","text":"Style Augmentation: Data Augmentation via StyleRandomization","title":"Style Augmentation: Data Augmentation via StyleRandomization"},{"location":"other_categories/undone/Style Augmentation Data Augmentation via StyleRandomization/#style-augmentation-data-augmentation-via-stylerandomization","text":"","title":"Style Augmentation: Data Augmentation via StyleRandomization"},{"location":"other_categories/undone/TossingBot Learning to Throw Arbitrary Objectswith Residual Physics/","text":"TossingBot: Learning to Throw Arbitrary Objectswith Residual Physics","title":"TossingBot: Learning to Throw Arbitrary Objectswith Residual Physics"},{"location":"other_categories/undone/TossingBot Learning to Throw Arbitrary Objectswith Residual Physics/#tossingbot-learning-to-throw-arbitrary-objectswith-residual-physics","text":"","title":"TossingBot: Learning to Throw Arbitrary Objectswith Residual Physics"},{"location":"other_categories/undone/Toward Driving Scene Understanding A Dataset for Learning Driver Behavior and Causal Reasoning/","text":"Toward Driving Scene Understanding:A Dataset for Learning Driver Behavior and Causal Reasoning","title":"Toward Driving Scene Understanding:A Dataset for Learning Driver Behavior and Causal Reasoning"},{"location":"other_categories/undone/Toward Driving Scene Understanding A Dataset for Learning Driver Behavior and Causal Reasoning/#toward-driving-scene-understandinga-dataset-for-learning-driver-behavior-and-causal-reasoning","text":"","title":"Toward Driving Scene Understanding:A Dataset for Learning Driver Behavior and Causal Reasoning"},{"location":"other_categories/undone/Towards Practical Hierarchical ReinforcementLearning for Multi-lane Autonomous Driving/","text":"Towards Practical Hierarchical ReinforcementLearning for Multi-lane Autonomous Driving","title":"Towards Practical Hierarchical ReinforcementLearning for Multi-lane Autonomous Driving"},{"location":"other_categories/undone/Towards Practical Hierarchical ReinforcementLearning for Multi-lane Autonomous Driving/#towards-practical-hierarchical-reinforcementlearning-for-multi-lane-autonomous-driving","text":"","title":"Towards Practical Hierarchical ReinforcementLearning for Multi-lane Autonomous Driving"},{"location":"other_categories/undone/Unsupervised Learning of Depth and Ego-Motion from Monocular VideoUsing 3D Geometric Constraints/","text":"Unsupervised Learning of Depth and Ego-Motion from Monocular VideoUsing 3D Geometric Constraints","title":"Unsupervised Learning of Depth and Ego-Motion from Monocular VideoUsing 3D Geometric Constraints"},{"location":"other_categories/undone/Unsupervised Learning of Depth and Ego-Motion from Monocular VideoUsing 3D Geometric Constraints/#unsupervised-learning-of-depth-and-ego-motion-from-monocular-videousing-3d-geometric-constraints","text":"","title":"Unsupervised Learning of Depth and Ego-Motion from Monocular VideoUsing 3D Geometric Constraints"},{"location":"other_categories/undone/Virtual-to-real  Deep  Reinforcement  Learning Continuous  Control  of  Mobile  Robots  for  Mapless  Navigation/","text":"Virtual-to-real Deep Reinforcement Learning:Continuous Control of Mobile Robots for Mapless Navigation","title":"Virtual-to-real  Deep  Reinforcement  Learning:Continuous  Control  of  Mobile  Robots  for  Mapless  Navigation"},{"location":"other_categories/undone/Virtual-to-real  Deep  Reinforcement  Learning Continuous  Control  of  Mobile  Robots  for  Mapless  Navigation/#virtual-to-real-deep-reinforcement-learningcontinuous-control-of-mobile-robots-for-mapless-navigation","text":"","title":"Virtual-to-real  Deep  Reinforcement  Learning:Continuous  Control  of  Mobile  Robots  for  Mapless  Navigation"},{"location":"other_categories/undone/Visual-based Autonomous Driving Deployment from a Stochastic andUncertainty-aware Perspective/","text":"Visual-based Autonomous Driving Deployment from a Stochastic andUncertainty-aware Perspective","title":"Visual-based Autonomous Driving Deployment from a Stochastic andUncertainty-aware Perspective"},{"location":"other_categories/undone/Visual-based Autonomous Driving Deployment from a Stochastic andUncertainty-aware Perspective/#visual-based-autonomous-driving-deployment-from-a-stochastic-anduncertainty-aware-perspective","text":"","title":"Visual-based Autonomous Driving Deployment from a Stochastic andUncertainty-aware Perspective"},{"location":"other_categories/undone/aaaaa/","text":"\u6536\u96c6\u4e86\u672a\u5b8c\u6210\u7684\u624b\u7a3f\uff0c\u4f46\u662f\u5f88\u591a\u6807\u9898\u5bf9\u5e94\u7684\u8bba\u6587\u90fd\u503c\u5f97\u4e00\u770b","title":"Aaaaa"},{"location":"other_categories/undone/depth_prediction_citation/","text":"Single Image Depth Estimation From Predicted Semantic Labels pdf \u8fd9\u7bc7paper\u7ed9\u51fa\u4e86look ground\u7684intuition. @INPROCEEDINGS{5539823, author={B. {Liu} and S. {Gould} and D. {Koller}}, booktitle={2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition}, title={Single image depth estimation from predicted semantic labels}, year={2010}, volume={}, number={}, pages={1253-1260},}","title":"Single Image Depth Estimation From Predicted Semantic Labels"},{"location":"other_categories/undone/depth_prediction_citation/#single-image-depth-estimation-from-predicted-semantic-labels","text":"pdf \u8fd9\u7bc7paper\u7ed9\u51fa\u4e86look ground\u7684intuition. @INPROCEEDINGS{5539823, author={B. {Liu} and S. {Gould} and D. {Koller}}, booktitle={2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition}, title={Single image depth estimation from predicted semantic labels}, year={2010}, volume={}, number={}, pages={1253-1260},}","title":"Single Image Depth Estimation From Predicted Semantic Labels"}]}