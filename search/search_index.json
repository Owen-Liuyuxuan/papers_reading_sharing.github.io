{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-\\.]+$"},"docs":[{"location":"","text":"\u8bba\u6587\u9605\u8bfb \u5bf9\u8fdb\u884c\u7684\u8bba\u6587\u9605\u8bfb\u8fdb\u884c\u8bb0\u5f55\u3002 \u6ce8\u610f\u7531\u4e8e\u76ee\u524d\u5b58\u50a8\u7684\u8bba\u6587\u6570\u91cf\u8d8a\u6765\u8d8a\u591a\uff0c\u5982\u679c\u60f3\u8981\u67e5\u627e\u67d0\u4e9b\u7279\u5b9a\u7684\u8bba\u6587\u5efa\u8bae\u6309's'\u952e\u6216\u8005\u70b9\u51fb\u53f3\u4e0a\u65b9\u7684\"search\"\u6309\u94ae\uff0c\u8f93\u5165\u5bf9\u5e94\u82f1\u6587\u9898\u76ee\u8fdb\u884c\u641c\u7d22\u3002 \u6587\u7ae0\u5404\u81ea\u7684\u76ee\u5f55\u4e2d\u4f1a\u8868\u660epdf\u4ee5\u53ca\u5f00\u6e90\u4ee3\u7801(\u5982\u6709)\u7684\u5916\u94fe\u3002 This volume will be basically written in Chinese. The target is to provide fast reference. Papers are now sorted in FIVE categories 3D object detection. mainly on monocular detection and also many papers in sensor fusion. Building Blocks for neural networks that boost performance Robotics with DL: using deep learning related technology to boost robotics algorithms The Theory: General advices for understanding and boosting the performance of deep learning other interesting or useful papers Github Github \u7f51\u9875 \u6b22\u8fce\u5171\u540c\u8bb0\u5f55\u8bba\u6587\u9605\u8bfb\u3001","title":"\u8bba\u6587\u9605\u8bfb"},{"location":"#_1","text":"\u5bf9\u8fdb\u884c\u7684\u8bba\u6587\u9605\u8bfb\u8fdb\u884c\u8bb0\u5f55\u3002 \u6ce8\u610f\u7531\u4e8e\u76ee\u524d\u5b58\u50a8\u7684\u8bba\u6587\u6570\u91cf\u8d8a\u6765\u8d8a\u591a\uff0c\u5982\u679c\u60f3\u8981\u67e5\u627e\u67d0\u4e9b\u7279\u5b9a\u7684\u8bba\u6587\u5efa\u8bae\u6309's'\u952e\u6216\u8005\u70b9\u51fb\u53f3\u4e0a\u65b9\u7684\"search\"\u6309\u94ae\uff0c\u8f93\u5165\u5bf9\u5e94\u82f1\u6587\u9898\u76ee\u8fdb\u884c\u641c\u7d22\u3002 \u6587\u7ae0\u5404\u81ea\u7684\u76ee\u5f55\u4e2d\u4f1a\u8868\u660epdf\u4ee5\u53ca\u5f00\u6e90\u4ee3\u7801(\u5982\u6709)\u7684\u5916\u94fe\u3002 This volume will be basically written in Chinese. The target is to provide fast reference. Papers are now sorted in FIVE categories 3D object detection. mainly on monocular detection and also many papers in sensor fusion. Building Blocks for neural networks that boost performance Robotics with DL: using deep learning related technology to boost robotics algorithms The Theory: General advices for understanding and boosting the performance of deep learning other interesting or useful papers","title":"\u8bba\u6587\u9605\u8bfb"},{"location":"#github","text":"Github \u7f51\u9875 \u6b22\u8fce\u5171\u540c\u8bb0\u5f55\u8bba\u6587\u9605\u8bfb\u3001","title":"Github"},{"location":"3dDetection/Accurate Monocular Object Detection via Color-Embedded 3D Reconstruction for Autonomous Driving/","text":"Accurate Monocular Object Detection via Color-Embedded 3D Reconstruction for Autonomous Driving \u8fd9\u7bc7\u6587\u7ae0\u5229\u7528\u4e86depth estimation\u4ee5\u53caPseudo lidar\u7684\u601d\u8def\uff0c\u662f\u76ee\u524d\u5355\u76ee\u89c6\u89c93D\u68c0\u6d4b\u7684SOTA,\u4f46\u662f\u989d\u5916\u51fa\u5f69\u7684\u5730\u65b9\u5728\u4e8e\u5176\u5bf9RGB\u4fe1\u606f\u4ee5\u53ca\u6df1\u5ea6\u4fe1\u606f\u878d\u5408\u65f6\u7684\u505a\u6cd5\u3002 \u4e3b\u8981\u7ed3\u6784\u4e0e\u6d41\u7a0b\u56fe \u5bf9\u5355\u4e00\u56fe\u50cf\u5206\u522b\u4f7f\u7528RPN\u63d0\u53d6RoI\u4ee5\u53ca\u4f7f\u7528\u6df1\u5ea6\u7f51\u7edc\u751f\u6210\u6df1\u5ea6\u4fe1\u606f\uff0c\u7136\u540e\u5bf9\u63d0\u53d6\u51fa\u6765\u7684\u533a\u57df\uff0c\u8fdb\u884c\u7b80\u5355\u7684\u6570\u636e\u8f6c\u6362\u3001\u5206\u5272\u3001\u878d\u5408\u68c0\u6d4b\u56de\u5f52 \u5c40\u90e8\u8be6\u89e3 \u6570\u636e\u8f6c\u6362 \u5df2\u77e5\u6df1\u5ea6d\uff0c\u4f7f\u7528 \\left\\{\\begin{array}{l}{z=d} \\\\ {x=\\left(u-C_{x}\\right) * z / f} \\\\ {y=\\left(v-C_{y}\\right) * z / f}\\end{array}\\right. \u5c06RoI\u533a\u57df\u8f6c\u6362\u4e3a\u76ee\u6807\u70b9\u4e91(\u5bc6\u96c6\u8868\u8fbe)\u3002 \u70b9\u4e91\u5206\u5272 \u65b9\u6cd5\u7b80\u5355\uff0c\u5728RoI\u533a\u57df\u5185\uff0c\u6c42\u51fa\u6df1\u5ea6\u5e73\u5747\u503c\uff0c\u6bd4\u5747\u503c\u9ad8\u51fa\u4e00\u4e2a\u9608\u503c\u4ee5\u4e0a\u7684\u5224\u65ad\u4e3a\u80cc\u666f\u70b9 S^{\\prime}=\\left\\{p | p_{v} \\leq \\frac{\\sum_{p \\in S} p_{v}}{|S|}+r, p \\in S\\right\\} \u5e76\u4ece\u4e2d\u968f\u673a\u9009\u53d6\u4e00\u5b9a\u91cf\u7684\u70b9\u4f5c\u4e3a\u8f93\u51fa\u70b9\uff0c\u5927\u5c0f\u4e00\u81f4\u4fbf\u4e8e\u540e\u671f\u5904\u7406 \u5750\u6807\u8f6c\u6362 \u7528\u4e00\u4e2a\u7ecf\u5178 \u6587\u7ae0 \u7684\u65b9\u6cd5\uff0c\u5229\u7528\u4e00\u4e2a\u5c0f\u7f51\u7edc\u4f30\u8ba1\u51faRoI\u7684\u4e2d\u5fc3\uff0c\u7136\u540e\u5c06\u6240\u6709\u70b9\u8f6c\u5230\u76f8\u5bf9\u5750\u6807\u7cfb\u4e2d S^{\\prime \\prime}=\\left\\{p | p-\\delta, p \\in S^{\\prime}\\right\\} \u7136\u540e\u7528pointnet\u9884\u6d4b \u878d\u5408 \u7528\u5982\u56fe\u65b9\u5f0f\u878d\u5408\u70b9\u4e91\u4ee5\u53ca\u5f69\u8272\u70b9\u3002 G \u662f\u4e00\u4e2a\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u5f97\u5230\u5b83\u7684\u516c\u5f0f\u662f G = \\sigma(f([F^{xyz}_{max}, F^{xyz}_{avg}])) ,\u6709\u4e00\u70b9 CBAM \u7684\u6548\u679c\uff0c \u540e\u9762\u7684\u70b9\u4e58\u4e0e\u76f8\u52a0\u53ef\u4ee5\u5199\u6210 \\mathbf{F}^{x y z} \\leftarrow \\mathbf{F}^{x y z}+\\mathbf{G} \\odot \\mathbf{F}^{r g b} \u53e6\u4e00\u65b9\u9762\uff0c\u4ece\u56fe\u4e2d\u76842D RoI\u4e2d\uff0c\u4f7f\u7528RoIAlign\u8c03\u5230 128\\times 128 \uff0c\u7528CNN\u63d0\u53d6\u4e00\u4e2a\u7279\u5f81\u5411\u91cf\uff0c\u5e76\u8054 \u8bad\u7ec3\u7ec6\u8282 \u4e24\u9636\u6bb5\u8bad\u7ec3\uff0c\u5148\u8bad\u7ec3\u4e24\u4e2a\u4e2d\u95f4\u7f51\u7edc\uff0c\u7136\u540e\u53ea\u75283D\u4fe1\u606f\u8bad\u7ec3\u6574\u4e2a\u7f51\u7edc \u635f\u5931\u51fd\u6570\u5305\u62ec\uff0c\u4e2d\u95f4\u8f7b\u91cf\u7ea7\u7684\u5bf9center\u7684\u4f30\u8ba1\uff0c\u9884\u6d4b\u8f93\u51fa\u7684corner loss(8\u4e2a\u89d2)","title":"Accurate Monocular Object Detection via Color-Embedded 3D Reconstruction for Autonomous Driving"},{"location":"3dDetection/Accurate Monocular Object Detection via Color-Embedded 3D Reconstruction for Autonomous Driving/#accurate-monocular-object-detection-via-color-embedded-3d-reconstruction-for-autonomous-driving","text":"\u8fd9\u7bc7\u6587\u7ae0\u5229\u7528\u4e86depth estimation\u4ee5\u53caPseudo lidar\u7684\u601d\u8def\uff0c\u662f\u76ee\u524d\u5355\u76ee\u89c6\u89c93D\u68c0\u6d4b\u7684SOTA,\u4f46\u662f\u989d\u5916\u51fa\u5f69\u7684\u5730\u65b9\u5728\u4e8e\u5176\u5bf9RGB\u4fe1\u606f\u4ee5\u53ca\u6df1\u5ea6\u4fe1\u606f\u878d\u5408\u65f6\u7684\u505a\u6cd5\u3002","title":"Accurate Monocular Object Detection via Color-Embedded 3D Reconstruction for Autonomous Driving"},{"location":"3dDetection/Accurate Monocular Object Detection via Color-Embedded 3D Reconstruction for Autonomous Driving/#_1","text":"\u5bf9\u5355\u4e00\u56fe\u50cf\u5206\u522b\u4f7f\u7528RPN\u63d0\u53d6RoI\u4ee5\u53ca\u4f7f\u7528\u6df1\u5ea6\u7f51\u7edc\u751f\u6210\u6df1\u5ea6\u4fe1\u606f\uff0c\u7136\u540e\u5bf9\u63d0\u53d6\u51fa\u6765\u7684\u533a\u57df\uff0c\u8fdb\u884c\u7b80\u5355\u7684\u6570\u636e\u8f6c\u6362\u3001\u5206\u5272\u3001\u878d\u5408\u68c0\u6d4b\u56de\u5f52","title":"\u4e3b\u8981\u7ed3\u6784\u4e0e\u6d41\u7a0b\u56fe"},{"location":"3dDetection/Accurate Monocular Object Detection via Color-Embedded 3D Reconstruction for Autonomous Driving/#_2","text":"","title":"\u5c40\u90e8\u8be6\u89e3"},{"location":"3dDetection/Accurate Monocular Object Detection via Color-Embedded 3D Reconstruction for Autonomous Driving/#_3","text":"\u5df2\u77e5\u6df1\u5ea6d\uff0c\u4f7f\u7528 \\left\\{\\begin{array}{l}{z=d} \\\\ {x=\\left(u-C_{x}\\right) * z / f} \\\\ {y=\\left(v-C_{y}\\right) * z / f}\\end{array}\\right. \u5c06RoI\u533a\u57df\u8f6c\u6362\u4e3a\u76ee\u6807\u70b9\u4e91(\u5bc6\u96c6\u8868\u8fbe)\u3002","title":"\u6570\u636e\u8f6c\u6362"},{"location":"3dDetection/Accurate Monocular Object Detection via Color-Embedded 3D Reconstruction for Autonomous Driving/#_4","text":"\u65b9\u6cd5\u7b80\u5355\uff0c\u5728RoI\u533a\u57df\u5185\uff0c\u6c42\u51fa\u6df1\u5ea6\u5e73\u5747\u503c\uff0c\u6bd4\u5747\u503c\u9ad8\u51fa\u4e00\u4e2a\u9608\u503c\u4ee5\u4e0a\u7684\u5224\u65ad\u4e3a\u80cc\u666f\u70b9 S^{\\prime}=\\left\\{p | p_{v} \\leq \\frac{\\sum_{p \\in S} p_{v}}{|S|}+r, p \\in S\\right\\} \u5e76\u4ece\u4e2d\u968f\u673a\u9009\u53d6\u4e00\u5b9a\u91cf\u7684\u70b9\u4f5c\u4e3a\u8f93\u51fa\u70b9\uff0c\u5927\u5c0f\u4e00\u81f4\u4fbf\u4e8e\u540e\u671f\u5904\u7406","title":"\u70b9\u4e91\u5206\u5272"},{"location":"3dDetection/Accurate Monocular Object Detection via Color-Embedded 3D Reconstruction for Autonomous Driving/#_6","text":"\u7528\u4e00\u4e2a\u7ecf\u5178 \u6587\u7ae0 \u7684\u65b9\u6cd5\uff0c\u5229\u7528\u4e00\u4e2a\u5c0f\u7f51\u7edc\u4f30\u8ba1\u51faRoI\u7684\u4e2d\u5fc3\uff0c\u7136\u540e\u5c06\u6240\u6709\u70b9\u8f6c\u5230\u76f8\u5bf9\u5750\u6807\u7cfb\u4e2d S^{\\prime \\prime}=\\left\\{p | p-\\delta, p \\in S^{\\prime}\\right\\} \u7136\u540e\u7528pointnet\u9884\u6d4b","title":"\u5750\u6807\u8f6c\u6362"},{"location":"3dDetection/Accurate Monocular Object Detection via Color-Embedded 3D Reconstruction for Autonomous Driving/#_7","text":"\u7528\u5982\u56fe\u65b9\u5f0f\u878d\u5408\u70b9\u4e91\u4ee5\u53ca\u5f69\u8272\u70b9\u3002 G \u662f\u4e00\u4e2a\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u5f97\u5230\u5b83\u7684\u516c\u5f0f\u662f G = \\sigma(f([F^{xyz}_{max}, F^{xyz}_{avg}])) ,\u6709\u4e00\u70b9 CBAM \u7684\u6548\u679c\uff0c \u540e\u9762\u7684\u70b9\u4e58\u4e0e\u76f8\u52a0\u53ef\u4ee5\u5199\u6210 \\mathbf{F}^{x y z} \\leftarrow \\mathbf{F}^{x y z}+\\mathbf{G} \\odot \\mathbf{F}^{r g b} \u53e6\u4e00\u65b9\u9762\uff0c\u4ece\u56fe\u4e2d\u76842D RoI\u4e2d\uff0c\u4f7f\u7528RoIAlign\u8c03\u5230 128\\times 128 \uff0c\u7528CNN\u63d0\u53d6\u4e00\u4e2a\u7279\u5f81\u5411\u91cf\uff0c\u5e76\u8054","title":"\u878d\u5408"},{"location":"3dDetection/Accurate Monocular Object Detection via Color-Embedded 3D Reconstruction for Autonomous Driving/#_8","text":"\u4e24\u9636\u6bb5\u8bad\u7ec3\uff0c\u5148\u8bad\u7ec3\u4e24\u4e2a\u4e2d\u95f4\u7f51\u7edc\uff0c\u7136\u540e\u53ea\u75283D\u4fe1\u606f\u8bad\u7ec3\u6574\u4e2a\u7f51\u7edc \u635f\u5931\u51fd\u6570\u5305\u62ec\uff0c\u4e2d\u95f4\u8f7b\u91cf\u7ea7\u7684\u5bf9center\u7684\u4f30\u8ba1\uff0c\u9884\u6d4b\u8f93\u51fa\u7684corner loss(8\u4e2a\u89d2)","title":"\u8bad\u7ec3\u7ec6\u8282"},{"location":"3dDetection/Disentangling_Monocular_3D_Object_Detection/","text":"Disentangling Monocular 3D Object Detection \u8fd9\u7bc7\u8bba\u6587\u76ee\u524d\u5728nuScene\u4ee5\u53caKitti\u4e0a\u5b9e\u73b0\u4e86\u5355\u76ee\u89c6\u89c9\u4e09\u7ef4\u68c0\u6d4b\u7684SOTA\u7684\u6027\u80fd\u3002 \u4f7f\u7528Two Stage\u7684\u68c0\u6d4b\u65b9\u5f0f\uff0c\u4e0eM3D-RPN\u7c7b\u4f3c\uff0c\u5229\u7528\u4e86\u591a\u5c3a\u5ea6\u7279\u5f81\uff0c\u589e\u52a0\u4e86\u591a\u4e2a\u7279\u6b8a\u8bbe\u8ba1\u7684Loss function \u6574\u4f53\u7ed3\u6784 \u7f51\u7edc\u5206\u4e3abackbone, 2D head, 3d head\u4e09\u4e2a\u90e8\u5206\uff0c\u7ed3\u6784\u5206\u522b\u4e3a \u76f4\u89c9\u4e0a\u6765\u8bf4\uff0c\u5c31\u662f\u4f7f\u7528Res34\u4ee5\u53cafeature pyramid network(FPN)\u63d0\u53d6\u591a\u5c3a\u5ea6\u7279\u5f81\uff0c\u8f93\u51fa\u591a\u4e2afeature map\uff0c\u6bcf\u4e00\u4e2afeature map\u8f93\u51fa2D detection Output.\u5bf9\u6bcf\u4e00\u4e2aProposal\uff0c\u4f7f\u7528ROIAlign\u5c42\u5c06\u5bf9\u5e94\u6846resize\u4e3a14*14\uff0c\u63d0\u53d6\u51fa\u7279\u5f81\u540e\u4e0e2D\u8f93\u51fa\u8fde\u63a5\u518d\u8f93\u5165\u5230\u5168\u8fde\u63a5\u5c42\uff0c\u6700\u7ec8\u8f93\u51fa3D output \u5176\u8f93\u51fa\u5b9a\u4e49: \u6ce8\u610f\u65cb\u8f6c\u8f93\u51fa\u7684\u662f\u56db\u5143\u6570 \u635f\u5931\u51fd\u6570 2D Loss Focal loss \u6e90\u81ea\u4e0e \u8fd9\u7bc7\u6587\u7ae0 L_{2 \\mathrm{D}}^{\\mathrm{conf}}\\left(p_{2 \\mathrm{D}}, y\\right)=-\\alpha y\\left(1-p_{2 \\mathrm{D}}\\right)^{\\gamma} \\log p_{2 \\mathrm{D}}-\\overline{\\alpha} \\overline{y} p_{2 \\mathrm{D}}^{\\gamma} \\log \\left(1-p_{2 \\mathrm{D}}\\right) Loss based on sIoU L_{2 \\mathrm{D}}^{\\mathrm{bb}}(\\boldsymbol{b}, \\hat{\\boldsymbol{b}})=1-\\operatorname{sIoU}(\\boldsymbol{b}, \\hat{\\boldsymbol{b}}) sIoU\u7684\u8ba1\u7b97\u516c\u5f0f\u4e3a\uff1a \u5b9e\u9645\u4e0a\u6709\u4ee5\u4e0b\u4e94\u79cd\u60c5\u51b5\uff0csIoU\u4f1a\u5728[-1, 1]\u4e4b\u95f4\uff0c 3D Loss Regression \u7f51\u7edc\u8f93\u51fa10\u4e2a\u53c2\u6570x,y,z,w,h,l,quarternion,\u4f7f\u7528lifting transformation \u5c06\u8fd9\u7ec4\u53c2\u6570\u8f6c\u6362\u4e3a\u76ee\u6807\u53c2\u65708\u4e2a\uff0c\u5bf98\u4e2a\u53c2\u6570\u8fdb\u884c\u56de\u5f52 Classification Focal loss lifting transform \u5b9e\u9645\u4e0a\u5c31\u662f\u5c06\u9884\u6d4b\u70b9\u63d0\u5347\u4e3a8\u4e2a\u89d2\u70b9 \u4ee4 z, c = (u_c, v_c), s = (W,H,D), q \u4e3a\u9884\u6d4b\u7684\u4e2d\u5fc3\u70b9\u6df1\u5ea6\u3001\u5728\u56fe\u4e2d\u6295\u5f71\u7684\u5750\u6807\uff0c\u8f66\u8f86\u4e09\u7ef4\u4ee5\u53ca\u56db\u5143\u6570\u3002K\u4e3a\u76f8\u673a\u5185\u53c2 K=\\left[\\begin{array}{ccc}{f_{x}} & {0} & {c_{x}} \\\\ {0} & {f_{y}} & {c_{y}} \\\\ {0} & {0} & {1}\\end{array}\\right] \u4ee4 C=\\left(\\begin{array}{cc}{\\frac{u_{c}-c_{x}}{f_{x}} z,} & {\\left.\\frac{v_{c}-c_{y}}{f_{y}} z, \\quad z\\right)^{\\top}=\\left(C_{x}, C_{y}, C_{z}\\right)^{\\top}}\\end{array}\\right. \u8fd9\u4e2a\u662f\u4e2d\u5fc3\u70b9\u662f\u5b9e\u9645\u5750\u6807 lifting transform \\mathcal{F} \u4e3a \\mathcal{F}(\\boldsymbol{\\theta})=\\frac{1}{2} R_{\\boldsymbol{q}_{\\mathrm{c}}} S B_{0}+\\boldsymbol{C} Disentangling 2D and 3D Detection Losses \u76f4\u89c9\u6765\u8bf4\uff0c\u4e8c\u7ef4Regression loss\u4e0e\u4e09\u7ef4Regression loss,\u76f4\u63a5\u53e0\u52a0\u7684\u597d\u5904\u662f\u4e24\u8005\u4e0d\u4f1a\u76f8\u4e92\u5f71\u54cd\uff0c\u4f46\u662f\u5b83\u4eec\u4f1a\u4ea7\u751f\u4e0d\u5e73\u8861\uff0c\u5f71\u54cd\u4f18\u5316\u7684\u8fc7\u7a0b \u6bd4\u5982\u5bf9\u4e8e\u672c\u6587\u7684\u4e09\u7ef4\u56de\u5f52\u6765\u8bf4\uff0c\u539f\u59cb\u53c2\u6570\u5206\u4e3a\u56db\u7ec4\uff0c\u4e5f\u5c31\u662f\u6df1\u5ea6\u3001\u76f8\u673a\u5750\u6807\u3001\u4e09\u7ef4\u4ee5\u53ca\u89d2\u5ea6\uff0c\u56de\u5f52\u65f6\u9700\u8981\u8ba1\u7b97\u7684\u53c2\u6570\u662f\u516b\u4e2a\u89d2\u70b9\u7684\u5750\u6807\uff0c\u5176\u4e2d\u9700\u8981\u4e00\u4e2a\u8f6c\u6362\u3002 \u5728\u8ba1\u7b97loss\u65f6\uff0c\u5206\u6210\u56db\u7ec4\u3002\u5176\u4e2d\u7b2c i \u7ec4\u8ba1\u7b97loss\u65f6\uff0c\u7b2c i \u7ec4\u53c2\u6570\u7528\u9884\u6d4b\u503c\uff0c\u5176\u4f59\u7528ground_truth\uff0c\u5982\u6b64\u6bcf\u4e00\u7ec4\u90fd\u4f1a\u5206\u5f00\u4f18\u5316\u3002 \u5177\u4f53\u76f4\u89c9\u770b\u539f\u6587","title":"Disentangling Monocular 3D Object Detection"},{"location":"3dDetection/Disentangling_Monocular_3D_Object_Detection/#disentangling-monocular-3d-object-detection","text":"\u8fd9\u7bc7\u8bba\u6587\u76ee\u524d\u5728nuScene\u4ee5\u53caKitti\u4e0a\u5b9e\u73b0\u4e86\u5355\u76ee\u89c6\u89c9\u4e09\u7ef4\u68c0\u6d4b\u7684SOTA\u7684\u6027\u80fd\u3002 \u4f7f\u7528Two Stage\u7684\u68c0\u6d4b\u65b9\u5f0f\uff0c\u4e0eM3D-RPN\u7c7b\u4f3c\uff0c\u5229\u7528\u4e86\u591a\u5c3a\u5ea6\u7279\u5f81\uff0c\u589e\u52a0\u4e86\u591a\u4e2a\u7279\u6b8a\u8bbe\u8ba1\u7684Loss function","title":"Disentangling Monocular 3D Object Detection"},{"location":"3dDetection/Disentangling_Monocular_3D_Object_Detection/#_1","text":"\u7f51\u7edc\u5206\u4e3abackbone, 2D head, 3d head\u4e09\u4e2a\u90e8\u5206\uff0c\u7ed3\u6784\u5206\u522b\u4e3a \u76f4\u89c9\u4e0a\u6765\u8bf4\uff0c\u5c31\u662f\u4f7f\u7528Res34\u4ee5\u53cafeature pyramid network(FPN)\u63d0\u53d6\u591a\u5c3a\u5ea6\u7279\u5f81\uff0c\u8f93\u51fa\u591a\u4e2afeature map\uff0c\u6bcf\u4e00\u4e2afeature map\u8f93\u51fa2D detection Output.\u5bf9\u6bcf\u4e00\u4e2aProposal\uff0c\u4f7f\u7528ROIAlign\u5c42\u5c06\u5bf9\u5e94\u6846resize\u4e3a14*14\uff0c\u63d0\u53d6\u51fa\u7279\u5f81\u540e\u4e0e2D\u8f93\u51fa\u8fde\u63a5\u518d\u8f93\u5165\u5230\u5168\u8fde\u63a5\u5c42\uff0c\u6700\u7ec8\u8f93\u51fa3D output \u5176\u8f93\u51fa\u5b9a\u4e49: \u6ce8\u610f\u65cb\u8f6c\u8f93\u51fa\u7684\u662f\u56db\u5143\u6570","title":"\u6574\u4f53\u7ed3\u6784"},{"location":"3dDetection/Disentangling_Monocular_3D_Object_Detection/#_2","text":"","title":"\u635f\u5931\u51fd\u6570"},{"location":"3dDetection/Disentangling_Monocular_3D_Object_Detection/#2d-loss","text":"Focal loss \u6e90\u81ea\u4e0e \u8fd9\u7bc7\u6587\u7ae0 L_{2 \\mathrm{D}}^{\\mathrm{conf}}\\left(p_{2 \\mathrm{D}}, y\\right)=-\\alpha y\\left(1-p_{2 \\mathrm{D}}\\right)^{\\gamma} \\log p_{2 \\mathrm{D}}-\\overline{\\alpha} \\overline{y} p_{2 \\mathrm{D}}^{\\gamma} \\log \\left(1-p_{2 \\mathrm{D}}\\right) Loss based on sIoU L_{2 \\mathrm{D}}^{\\mathrm{bb}}(\\boldsymbol{b}, \\hat{\\boldsymbol{b}})=1-\\operatorname{sIoU}(\\boldsymbol{b}, \\hat{\\boldsymbol{b}}) sIoU\u7684\u8ba1\u7b97\u516c\u5f0f\u4e3a\uff1a \u5b9e\u9645\u4e0a\u6709\u4ee5\u4e0b\u4e94\u79cd\u60c5\u51b5\uff0csIoU\u4f1a\u5728[-1, 1]\u4e4b\u95f4\uff0c","title":"2D Loss"},{"location":"3dDetection/Disentangling_Monocular_3D_Object_Detection/#3d-loss","text":"Regression \u7f51\u7edc\u8f93\u51fa10\u4e2a\u53c2\u6570x,y,z,w,h,l,quarternion,\u4f7f\u7528lifting transformation \u5c06\u8fd9\u7ec4\u53c2\u6570\u8f6c\u6362\u4e3a\u76ee\u6807\u53c2\u65708\u4e2a\uff0c\u5bf98\u4e2a\u53c2\u6570\u8fdb\u884c\u56de\u5f52 Classification Focal loss","title":"3D Loss"},{"location":"3dDetection/Disentangling_Monocular_3D_Object_Detection/#lifting-transform","text":"\u5b9e\u9645\u4e0a\u5c31\u662f\u5c06\u9884\u6d4b\u70b9\u63d0\u5347\u4e3a8\u4e2a\u89d2\u70b9 \u4ee4 z, c = (u_c, v_c), s = (W,H,D), q \u4e3a\u9884\u6d4b\u7684\u4e2d\u5fc3\u70b9\u6df1\u5ea6\u3001\u5728\u56fe\u4e2d\u6295\u5f71\u7684\u5750\u6807\uff0c\u8f66\u8f86\u4e09\u7ef4\u4ee5\u53ca\u56db\u5143\u6570\u3002K\u4e3a\u76f8\u673a\u5185\u53c2 K=\\left[\\begin{array}{ccc}{f_{x}} & {0} & {c_{x}} \\\\ {0} & {f_{y}} & {c_{y}} \\\\ {0} & {0} & {1}\\end{array}\\right] \u4ee4 C=\\left(\\begin{array}{cc}{\\frac{u_{c}-c_{x}}{f_{x}} z,} & {\\left.\\frac{v_{c}-c_{y}}{f_{y}} z, \\quad z\\right)^{\\top}=\\left(C_{x}, C_{y}, C_{z}\\right)^{\\top}}\\end{array}\\right. \u8fd9\u4e2a\u662f\u4e2d\u5fc3\u70b9\u662f\u5b9e\u9645\u5750\u6807 lifting transform \\mathcal{F} \u4e3a \\mathcal{F}(\\boldsymbol{\\theta})=\\frac{1}{2} R_{\\boldsymbol{q}_{\\mathrm{c}}} S B_{0}+\\boldsymbol{C}","title":"lifting transform"},{"location":"3dDetection/Disentangling_Monocular_3D_Object_Detection/#disentangling-2d-and-3d-detection-losses","text":"\u76f4\u89c9\u6765\u8bf4\uff0c\u4e8c\u7ef4Regression loss\u4e0e\u4e09\u7ef4Regression loss,\u76f4\u63a5\u53e0\u52a0\u7684\u597d\u5904\u662f\u4e24\u8005\u4e0d\u4f1a\u76f8\u4e92\u5f71\u54cd\uff0c\u4f46\u662f\u5b83\u4eec\u4f1a\u4ea7\u751f\u4e0d\u5e73\u8861\uff0c\u5f71\u54cd\u4f18\u5316\u7684\u8fc7\u7a0b \u6bd4\u5982\u5bf9\u4e8e\u672c\u6587\u7684\u4e09\u7ef4\u56de\u5f52\u6765\u8bf4\uff0c\u539f\u59cb\u53c2\u6570\u5206\u4e3a\u56db\u7ec4\uff0c\u4e5f\u5c31\u662f\u6df1\u5ea6\u3001\u76f8\u673a\u5750\u6807\u3001\u4e09\u7ef4\u4ee5\u53ca\u89d2\u5ea6\uff0c\u56de\u5f52\u65f6\u9700\u8981\u8ba1\u7b97\u7684\u53c2\u6570\u662f\u516b\u4e2a\u89d2\u70b9\u7684\u5750\u6807\uff0c\u5176\u4e2d\u9700\u8981\u4e00\u4e2a\u8f6c\u6362\u3002 \u5728\u8ba1\u7b97loss\u65f6\uff0c\u5206\u6210\u56db\u7ec4\u3002\u5176\u4e2d\u7b2c i \u7ec4\u8ba1\u7b97loss\u65f6\uff0c\u7b2c i \u7ec4\u53c2\u6570\u7528\u9884\u6d4b\u503c\uff0c\u5176\u4f59\u7528ground_truth\uff0c\u5982\u6b64\u6bcf\u4e00\u7ec4\u90fd\u4f1a\u5206\u5f00\u4f18\u5316\u3002 \u5177\u4f53\u76f4\u89c9\u770b\u539f\u6587","title":"Disentangling 2D and 3D Detection Losses"},{"location":"3dDetection/End-to-end Learning of Multi-sensor 3D Tracking by Detection/","text":"End-to-end Learning of Multi-sensor 3D Tracking by Detection \u8fd9\u7bc7\u8bba\u6587\u4e3b\u8981\u8ba8\u8bba\u7684\u662f\u4e00\u4e2atracking\u95ee\u9898\uff0c\u7a81\u51fa\u8d21\u732e\u662f\u4f7f\u7528\u4e86\u79bb\u6563\u4f18\u5316\u7684\u6982\u5ff5(\u5728\u6c42\u89e3\u65f6\u8f6c\u6362\u4e3a\u4e86\u7ebf\u6027\u4f18\u5316\u95ee\u9898)\uff0c\u5e76\u89e3\u51b3\u4e86\u5982\u4f55\u8bad\u7ec3\u8fd9\u4e2a\u95ee\u9898\uff0c\u8fc7\u7a0b\u4e2d\u6709\u8f83\u591a\u7684\u6570\u5b66\u5de7\u5408\uff0c\u4f46\u662f\u5176\u5b9e\u8fd9\u662f\u4e00\u7c7b\u95ee\u9898\u7684\u89e3\u51b3\u65b9\u6cd5,\u8fd9\u4e2a\u95ee\u9898\u79f0\u4e3ageneral matching problem,\u53ef\u4ee5 \u53c2\u8003\u5f15\u65876 \u7684\u95ee\u9898\u9610\u8ff0\u4ee5\u53ca\u9644\u5f551\u3002 \u63a8\u65ad\u7ed3\u6784 \u9010\u4e2a\u5206\u6790\uff1a Detection Net\u7528\u7684\u662f MV3D Scoring Net\uff0c\u5c06\u6bcf\u4e00\u4e2a3D\u6846\u6295\u5f71\u56de\u56fe\u7247\u4e2d\uff0c\u7528VGG\u603b\u7ed3\uff0c\u7ed9\u51fa\u8fd9\u4e2a\u56fe\u7247\u662ftrue positive\u7684cost Matching Net\uff0c\u5206\u4e24\u652f\uff0c\u4e00\u4e2a\u662fSiamese Network\uff0c\u5c06\u4e24\u4e2a3D\u6846\u5bf9\u5e94\u7684\u56fe\u7247\u9001\u5230network\u4e2d\u63d0\u53d6\u5171\u540c\u4fe1\u606f\uff0c\u7b2c\u4e8c\u4e2a\u662f\u8fd0\u52a8\u77eb\u6b63\u540e\u76843D\u6295\u5f71\u56fe\uff0c\u9001\u5230network\u4e2d\u63d0\u53d6\u4fe1\u606f\u3002\u7136\u540e\u6700\u540e\u7531FC Net\u5f97\u5230\u9884\u6d4b\u3002\u8fd9\u4e2anetwork\u9700\u8981\u5bf9\u6bcf\u4e00\u5bf9\u53ef\u80fd\u7684\u5339\u914d\u8ba1\u7b97\u3002 new cost and end cost:\u5bf9\u4e00\u4e2adetection\u662f\u65b0\u7684\u6216\u662f\u6700\u7ec8\u51fa\u73b0\u7684\u9884\u6d4b\uff0c\u662f\u4e00\u4e2a\u5e38\u91cf\uff0c\u53ef\u5b66\u4e60\u3002 \u8fc7\u7a0b\u7b80\u4ecb \u4e24\u4e2aLinear\u3001Integer Programming\u7684\u5b9a\u4e49 \u7ea6\u675f\u77e9\u9635 y_j^{new} + \\sum_{k of last frame}y^{link}_{j,k} = y^{end}_{j} + \\sum_{k of next frame} y_{j,k}^{link} = y_j^{det} \u7b80\u5355\u5730\u8bf4\u5c31\u662f\u65b0\u751f\u7684or\u4ece\u4e0a\u4e00\u5e27\u6765\u7684object = \u7ed3\u675f\u7684or\u53bb\u5f80\u4e0b\u4e00\u5e27\u7684object = \u8fd9\u4e00\u5e27\u8fd9\u4e2aobject\u662f\u5426\u662ftrue positive \u5728\u7eaf\u7cb9inference\u7684\u65f6\u5019\uff0c\u4f18\u5316\u76ee\u6807\u5c31\u662f \\theta_{\\bold w}(\\bold x) y ,\u6bcf\u4e00\u4e2a\u5e03\u5c14\u51b3\u7b56y\u524d\u7684cost\u7531\u524d\u6587\u7684Matching Net\uff0c scoring net\uff0c\u4ee5\u53ca\u53ef\u5b66\u4e60\u5e38\u91cf\u7ed9\u51fa\u3002\u76f4\u63a5\u7528OR-tools\u6c42\u89e3,\u76f8\u5f53\u4e8e\u5df2\u77e5reward\u53c2\u6570\u627e\u51fa\u6700\u597d\u7684\u89e3 \u5728\u9700\u8981train\u7684\u65f6\u5019\uff0c\u4f18\u5316\u76ee\u6807\u5c31\u662f L(x, y, W) = \\sum_x[\\max_{y}(\\Delta(y, \\hat y) + \\theta_{\\bold w}(\\bold x) (y-\\hat y)))] \u91cc\u9762\u7684 \\max_{y}(\\Delta(y, \\hat y) + \\theta_{\\bold w}(\\bold x) (y-\\hat y)) \u4f5c\u4e3ainference\u65f6\u5019\u9700\u8981\u6c42\u89e3\u7684LP\u51fd\u6570\u3002\u601d\u8def\u7c7b\u4f3c\u4e8eSVM\u4e2d\u7684\u5bf9\u5076\u4f18\u5316\u95ee\u9898\uff0c\u5728\u8bad\u7ec3\u7684\u65f6\u5019\uff0c\u6211\u4eec\u9700\u8981\u627e\u5230 w \uff0c\u4f7f\u5f97,worst case\u7684\u4e00\u4e2a\"\u9519\u5224loss\"\u6700\u5c0f\uff0c\u800c\u8fd9\u4e2aworst case\u7684\u9519\u5224loss\uff0c\u9996\u5148\u8981\u5b9a\u4e49\u9519\u5224loss\uff0c\u5176\u6b21\u662f\u7528max\u627e\u51faworst case(\u7b80\u5355).\u800c\u9519\u5224loss\u8fd9\u91cc\u7528\u6c49\u660e\u8ddd\u79bb+reward difference,\u7406\u60f3\u60c5\u51b5\u4e0b\uff0c\u6c49\u660e\u8ddd\u79bb\u8d8a\u5927\uff0creward difference\u5c31\u5e94\u8be5\u8d8a\u5c0f,\u53cd\u4e4b\u4ea6\u7136\uff0c\u5e76\u6700\u597d\u4fdd\u6301\u4e3a\u4e00\u4e2a\u5e38\u6570 \u5bf9\u4e8e\u9519\u5224loss\uff0c\u9996\u5148\u6c49\u660e\u8ddd\u79bb\u5c0f\u65f6reward difference\u81ea\u7136\u4e5f\u4f1a\u5c0f\uff0c\u800c\u6c49\u660e\u8ddd\u79bb\u5927\u65f6reward difference\u4e5f\u5e94\u8be5\u4e3a\u4e00\u4e2a\u5927\u7684\u8d1f\u6570\u4ee5\u62b5\u6d88\uff0c\u5982\u679c\u51fa\u73b0\u6c49\u660e\u8ddd\u79bb\u5927\u800creward difference\u4e0d\u591f\u5c0f\uff0c\u5219\u8fd9\u4e2aworst case\u9700\u8981\u88ab\u4fee\u6b63\uff0c\u4e5f\u5c31\u662f\u8fd9\u4e2a\u73a9\u610f\u513f\u7684intuition\u3002 \u5173\u4e8e\u5176\u68af\u5ea6\uff0c\u5efa\u8bae\u53c2\u8003 \u8fd9\u7bc7 \u3002\u5f97\u5230\u7684\u7ed3\u679c\u662f \u5173\u952e\u662f\u6839\u636e\u5f15\u65876\uff0c\u8fd9\u4e2a\u7ea6\u675f\u77e9\u9635A\u662f\u4e00\u4e2a\u5355\u6a21\u77e9\u9635\uff0c\u6240\u4ee5\u5176\u9006\u77e9\u9635\u7684\u89e3\u90fd\u662f\u6574\u6570\uff0c\u6240\u4ee5Integer programming\u88ab\u8f6c\u6362\u4e3aLinear Programming\u5e76\u540c\u65f6\u4fdd\u8bc1\u4e86\u6700\u4f18\u89e3\u4e00\u5b9a\u662f\u6574\u6570\u3002","title":"End-to-end Learning of Multi-sensor 3D Tracking by Detection"},{"location":"3dDetection/End-to-end Learning of Multi-sensor 3D Tracking by Detection/#end-to-end-learning-of-multi-sensor-3d-tracking-by-detection","text":"\u8fd9\u7bc7\u8bba\u6587\u4e3b\u8981\u8ba8\u8bba\u7684\u662f\u4e00\u4e2atracking\u95ee\u9898\uff0c\u7a81\u51fa\u8d21\u732e\u662f\u4f7f\u7528\u4e86\u79bb\u6563\u4f18\u5316\u7684\u6982\u5ff5(\u5728\u6c42\u89e3\u65f6\u8f6c\u6362\u4e3a\u4e86\u7ebf\u6027\u4f18\u5316\u95ee\u9898)\uff0c\u5e76\u89e3\u51b3\u4e86\u5982\u4f55\u8bad\u7ec3\u8fd9\u4e2a\u95ee\u9898\uff0c\u8fc7\u7a0b\u4e2d\u6709\u8f83\u591a\u7684\u6570\u5b66\u5de7\u5408\uff0c\u4f46\u662f\u5176\u5b9e\u8fd9\u662f\u4e00\u7c7b\u95ee\u9898\u7684\u89e3\u51b3\u65b9\u6cd5,\u8fd9\u4e2a\u95ee\u9898\u79f0\u4e3ageneral matching problem,\u53ef\u4ee5 \u53c2\u8003\u5f15\u65876 \u7684\u95ee\u9898\u9610\u8ff0\u4ee5\u53ca\u9644\u5f551\u3002","title":"End-to-end Learning of Multi-sensor 3D Tracking by Detection"},{"location":"3dDetection/End-to-end Learning of Multi-sensor 3D Tracking by Detection/#_1","text":"\u9010\u4e2a\u5206\u6790\uff1a Detection Net\u7528\u7684\u662f MV3D Scoring Net\uff0c\u5c06\u6bcf\u4e00\u4e2a3D\u6846\u6295\u5f71\u56de\u56fe\u7247\u4e2d\uff0c\u7528VGG\u603b\u7ed3\uff0c\u7ed9\u51fa\u8fd9\u4e2a\u56fe\u7247\u662ftrue positive\u7684cost Matching Net\uff0c\u5206\u4e24\u652f\uff0c\u4e00\u4e2a\u662fSiamese Network\uff0c\u5c06\u4e24\u4e2a3D\u6846\u5bf9\u5e94\u7684\u56fe\u7247\u9001\u5230network\u4e2d\u63d0\u53d6\u5171\u540c\u4fe1\u606f\uff0c\u7b2c\u4e8c\u4e2a\u662f\u8fd0\u52a8\u77eb\u6b63\u540e\u76843D\u6295\u5f71\u56fe\uff0c\u9001\u5230network\u4e2d\u63d0\u53d6\u4fe1\u606f\u3002\u7136\u540e\u6700\u540e\u7531FC Net\u5f97\u5230\u9884\u6d4b\u3002\u8fd9\u4e2anetwork\u9700\u8981\u5bf9\u6bcf\u4e00\u5bf9\u53ef\u80fd\u7684\u5339\u914d\u8ba1\u7b97\u3002 new cost and end cost:\u5bf9\u4e00\u4e2adetection\u662f\u65b0\u7684\u6216\u662f\u6700\u7ec8\u51fa\u73b0\u7684\u9884\u6d4b\uff0c\u662f\u4e00\u4e2a\u5e38\u91cf\uff0c\u53ef\u5b66\u4e60\u3002","title":"\u63a8\u65ad\u7ed3\u6784"},{"location":"3dDetection/End-to-end Learning of Multi-sensor 3D Tracking by Detection/#_2","text":"","title":"\u8fc7\u7a0b\u7b80\u4ecb"},{"location":"3dDetection/End-to-end Learning of Multi-sensor 3D Tracking by Detection/#linearinteger-programming","text":"\u7ea6\u675f\u77e9\u9635 y_j^{new} + \\sum_{k of last frame}y^{link}_{j,k} = y^{end}_{j} + \\sum_{k of next frame} y_{j,k}^{link} = y_j^{det} \u7b80\u5355\u5730\u8bf4\u5c31\u662f\u65b0\u751f\u7684or\u4ece\u4e0a\u4e00\u5e27\u6765\u7684object = \u7ed3\u675f\u7684or\u53bb\u5f80\u4e0b\u4e00\u5e27\u7684object = \u8fd9\u4e00\u5e27\u8fd9\u4e2aobject\u662f\u5426\u662ftrue positive \u5728\u7eaf\u7cb9inference\u7684\u65f6\u5019\uff0c\u4f18\u5316\u76ee\u6807\u5c31\u662f \\theta_{\\bold w}(\\bold x) y ,\u6bcf\u4e00\u4e2a\u5e03\u5c14\u51b3\u7b56y\u524d\u7684cost\u7531\u524d\u6587\u7684Matching Net\uff0c scoring net\uff0c\u4ee5\u53ca\u53ef\u5b66\u4e60\u5e38\u91cf\u7ed9\u51fa\u3002\u76f4\u63a5\u7528OR-tools\u6c42\u89e3,\u76f8\u5f53\u4e8e\u5df2\u77e5reward\u53c2\u6570\u627e\u51fa\u6700\u597d\u7684\u89e3 \u5728\u9700\u8981train\u7684\u65f6\u5019\uff0c\u4f18\u5316\u76ee\u6807\u5c31\u662f L(x, y, W) = \\sum_x[\\max_{y}(\\Delta(y, \\hat y) + \\theta_{\\bold w}(\\bold x) (y-\\hat y)))] \u91cc\u9762\u7684 \\max_{y}(\\Delta(y, \\hat y) + \\theta_{\\bold w}(\\bold x) (y-\\hat y)) \u4f5c\u4e3ainference\u65f6\u5019\u9700\u8981\u6c42\u89e3\u7684LP\u51fd\u6570\u3002\u601d\u8def\u7c7b\u4f3c\u4e8eSVM\u4e2d\u7684\u5bf9\u5076\u4f18\u5316\u95ee\u9898\uff0c\u5728\u8bad\u7ec3\u7684\u65f6\u5019\uff0c\u6211\u4eec\u9700\u8981\u627e\u5230 w \uff0c\u4f7f\u5f97,worst case\u7684\u4e00\u4e2a\"\u9519\u5224loss\"\u6700\u5c0f\uff0c\u800c\u8fd9\u4e2aworst case\u7684\u9519\u5224loss\uff0c\u9996\u5148\u8981\u5b9a\u4e49\u9519\u5224loss\uff0c\u5176\u6b21\u662f\u7528max\u627e\u51faworst case(\u7b80\u5355).\u800c\u9519\u5224loss\u8fd9\u91cc\u7528\u6c49\u660e\u8ddd\u79bb+reward difference,\u7406\u60f3\u60c5\u51b5\u4e0b\uff0c\u6c49\u660e\u8ddd\u79bb\u8d8a\u5927\uff0creward difference\u5c31\u5e94\u8be5\u8d8a\u5c0f,\u53cd\u4e4b\u4ea6\u7136\uff0c\u5e76\u6700\u597d\u4fdd\u6301\u4e3a\u4e00\u4e2a\u5e38\u6570 \u5bf9\u4e8e\u9519\u5224loss\uff0c\u9996\u5148\u6c49\u660e\u8ddd\u79bb\u5c0f\u65f6reward difference\u81ea\u7136\u4e5f\u4f1a\u5c0f\uff0c\u800c\u6c49\u660e\u8ddd\u79bb\u5927\u65f6reward difference\u4e5f\u5e94\u8be5\u4e3a\u4e00\u4e2a\u5927\u7684\u8d1f\u6570\u4ee5\u62b5\u6d88\uff0c\u5982\u679c\u51fa\u73b0\u6c49\u660e\u8ddd\u79bb\u5927\u800creward difference\u4e0d\u591f\u5c0f\uff0c\u5219\u8fd9\u4e2aworst case\u9700\u8981\u88ab\u4fee\u6b63\uff0c\u4e5f\u5c31\u662f\u8fd9\u4e2a\u73a9\u610f\u513f\u7684intuition\u3002 \u5173\u4e8e\u5176\u68af\u5ea6\uff0c\u5efa\u8bae\u53c2\u8003 \u8fd9\u7bc7 \u3002\u5f97\u5230\u7684\u7ed3\u679c\u662f \u5173\u952e\u662f\u6839\u636e\u5f15\u65876\uff0c\u8fd9\u4e2a\u7ea6\u675f\u77e9\u9635A\u662f\u4e00\u4e2a\u5355\u6a21\u77e9\u9635\uff0c\u6240\u4ee5\u5176\u9006\u77e9\u9635\u7684\u89e3\u90fd\u662f\u6574\u6570\uff0c\u6240\u4ee5Integer programming\u88ab\u8f6c\u6362\u4e3aLinear Programming\u5e76\u540c\u65f6\u4fdd\u8bc1\u4e86\u6700\u4f18\u89e3\u4e00\u5b9a\u662f\u6574\u6570\u3002","title":"\u4e24\u4e2aLinear\u3001Integer Programming\u7684\u5b9a\u4e49"},{"location":"3dDetection/Frustum_PointNets_for_3D_Object_Detection_from_RGB-D_Data/","text":"Frustum PointNets for 3D Object Detection from RGB-D Data \u8fd9\u7bc7\u8bba\u6587\u7ed9\u51fa\u4e86\u4f7f\u7528RGB-D\u6570\u636e\u8fdb\u884c3D\u68c0\u6d4b\u7684baseline pipeline. \u7f51\u7edc\u7ed3\u6784 \u5bf9RGB\u56fe\u7247\u6267\u884c2D detection\uff0c\u7ed9\u51fa2D proposal\u4ee5\u53ca\u5206\u7c7bone-hot\u77e2\u91cf,\u4eceproposal\u4e2d\u91c7\u6837\u51fan\u4e2a\u70b9\uff0c\u4f7f\u7528pointnet\u8fdb\u884cInstance Segmentation\u533a\u5206\u80cc\u666f\u4ee5\u53caforeground,\u6267\u884cmasking\u518d\u91c7\u6837m\u4e2a\u70b9\uff0c\u4f7f\u7528T-Net\u7b49\u56de\u5f52\u4f30\u8ba1\u4e09\u7ef4\u6846\u7ed3\u679c \u4ee3\u7801\u4e2d\u4f7f\u7528\u7684\u5750\u6807\u7cfb\u793a\u610f\u56fe PointNet\u4f7f\u7528\u7684\u7ed3\u6784 \u70b9\u4e91\u8bed\u4e49\u5206\u5272\u4e2d\uff0c\u9664\u4e86\u4f7f\u7528pointnet\u4e4b\u5916\uff0c\u5728\u8f93\u5165\u7279\u5f81\u4e2d\u8fd8concat\u4e86\u8bed\u4e49\u5206\u7c7b\u7684category\u3002 \u5728\u70b9\u4e91\u56de\u5f52\u65f6\uff0c\u5148\u7528T-Net\u6c42\u51fa\u4e2d\u5fc3\u70b9\u5750\u6807\uff0c\u5c06\u5269\u4f59\u70b9\u8f6c\u6362\u4e3a\u4ee5\u4e2d\u5fc3\u70b9\u4e3a\u4e2d\u5fc3\u7684\u4f4d\u7f6e\u4e0a\u5728\u4f30\u8ba1box size Loss Multitask Loss Corner Loss","title":"Frustum PointNets for 3D Object Detection from RGB-D Data"},{"location":"3dDetection/Frustum_PointNets_for_3D_Object_Detection_from_RGB-D_Data/#frustum-pointnets-for-3d-object-detection-from-rgb-d-data","text":"\u8fd9\u7bc7\u8bba\u6587\u7ed9\u51fa\u4e86\u4f7f\u7528RGB-D\u6570\u636e\u8fdb\u884c3D\u68c0\u6d4b\u7684baseline pipeline.","title":"Frustum PointNets for 3D Object Detection from RGB-D Data"},{"location":"3dDetection/Frustum_PointNets_for_3D_Object_Detection_from_RGB-D_Data/#_1","text":"\u5bf9RGB\u56fe\u7247\u6267\u884c2D detection\uff0c\u7ed9\u51fa2D proposal\u4ee5\u53ca\u5206\u7c7bone-hot\u77e2\u91cf,\u4eceproposal\u4e2d\u91c7\u6837\u51fan\u4e2a\u70b9\uff0c\u4f7f\u7528pointnet\u8fdb\u884cInstance Segmentation\u533a\u5206\u80cc\u666f\u4ee5\u53caforeground,\u6267\u884cmasking\u518d\u91c7\u6837m\u4e2a\u70b9\uff0c\u4f7f\u7528T-Net\u7b49\u56de\u5f52\u4f30\u8ba1\u4e09\u7ef4\u6846\u7ed3\u679c \u4ee3\u7801\u4e2d\u4f7f\u7528\u7684\u5750\u6807\u7cfb\u793a\u610f\u56fe PointNet\u4f7f\u7528\u7684\u7ed3\u6784 \u70b9\u4e91\u8bed\u4e49\u5206\u5272\u4e2d\uff0c\u9664\u4e86\u4f7f\u7528pointnet\u4e4b\u5916\uff0c\u5728\u8f93\u5165\u7279\u5f81\u4e2d\u8fd8concat\u4e86\u8bed\u4e49\u5206\u7c7b\u7684category\u3002 \u5728\u70b9\u4e91\u56de\u5f52\u65f6\uff0c\u5148\u7528T-Net\u6c42\u51fa\u4e2d\u5fc3\u70b9\u5750\u6807\uff0c\u5c06\u5269\u4f59\u70b9\u8f6c\u6362\u4e3a\u4ee5\u4e2d\u5fc3\u70b9\u4e3a\u4e2d\u5fc3\u7684\u4f4d\u7f6e\u4e0a\u5728\u4f30\u8ba1box size","title":"\u7f51\u7edc\u7ed3\u6784"},{"location":"3dDetection/Frustum_PointNets_for_3D_Object_Detection_from_RGB-D_Data/#loss","text":"Multitask Loss Corner Loss","title":"Loss"},{"location":"3dDetection/IoU Loss for 2D/","text":"IoU Loss for 2D/3D Object Detection \u8fd9\u7bc7\u8bba\u6587\u7684\u6838\u5fc3\u8d21\u732e\u662f\u7ed9\u51fa\u4e86\u6240\u8c13\u7684IoU Loss,\u56e0\u4e3a\u62fc\u70b9\u7684\u8fc7\u7a0b\u4e2d\u5173\u952e\u70b9\u5728\u4e8e\u63d0\u5347IoU\u7684\u503c\uff0c\u4f46\u662f\u6211\u4eec\u76ee\u524d\u6ca1\u6709\u76f4\u63a5\u68af\u5ea6\u4f18\u5316IoU\u7684\u65b9\u6cd5\uff0c\u8fd9\u7bc7\u6587\u7ae0\u7ed9\u51fa\u7684IoU Loss\u5c31\u662f\u7ed9\u51fa\u4e00\u4e2a\u53ef\u5fae\u5206\u7684\u635f\u5931\u51fd\u6570\uff0c\u901a\u8fc7\u76f4\u63a5\u4f18\u5316IoU\u63d0\u9ad8\u5206\u6570 \u4e00\u822c\u5e26\u6709\u65cb\u8f6c\u76842D IoU\u7b97\u6cd5 \u8ba1\u7b97\u4e24\u4e2a\u5e73\u9762\u533a\u57df\u7684\u9762\u79ef \u627e\u51fa\u4e24\u4e2a\u533a\u57df\u76f8\u4ea4\u5f97\u5230\u7684\u51f8\u591a\u8fb9\u5f62\u7684\u70b9\uff0c\u8fd9\u4e9b\u70b9\u6709\u4e24\u79cd\u6765\u6e90\u53ef\u80fd\uff0c\u4e00\u4e2a\u662f\u4e24\u4e2abox\u8fb9\u7f18\u7684\u4ea4\u70b9\uff0c\u4e00\u4e2a\u662f\u51fa\u73b0\u5728\u53e6\u4e00\u4e2abbox\u533a\u57df\u4e2d\u7684\u539f\u6765box\u7684\u70b9 \u5c06\u8fd9\u4e9b\u51f8\u591a\u8fb9\u5f62\u7684\u8fb9\u7f18\u70b9\u9006\u65f6\u9488\u6216\u8005\u987a\u65f6\u9488\u6392\u5e8f\uff0c\u7b97\u6cd5\u662f\uff1a\u5148\u6c42\u51fa\u51f8\u591a\u8fb9\u5f62\u7684\u4e2d\u5fc3\u70b9\uff0c\u7136\u540e\u9010\u4e2a\u6c42\u51fa\u65cb\u8f6c\u89d2\u5ea6\uff0c\u7136\u540e\u5c06\u8fd9\u4e2a\u65cb\u8f6c\u89d2\u5ea6\u6392\u5e8f \u5c06\u51f8\u591a\u8fb9\u5f62\u5206\u89e3\u4e3a\u591a\u4e2a\u5c0f\u4e09\u89d2\u5f62\uff0c\u5e76\u6c42\u51fa\u603b\u5408\u9762\u79ef \u5f97\u5230overlap\u9762\u79ef\u540e\u6c42\u51faIoU 3D IoU \u53ea\u9700\u8981\u5728\u6c42\u51faover lap\u7684\u57fa\u7840\u4e0a\uff0c\u5728\u9ad8\u5ea6\u4e0a\u8865\u5145\u4e00\u4e9b\u53c2\u6570\u5373\u53ef\uff1a IoU_{3D} = \\frac{Area_{overlap} \\times h_{overlap}} {Area_g \\times h_g + Area_d \\times h_d - Area_{overlap} \\times h_{overlap}}","title":"IoU Loss for 2D/3D Object Detection"},{"location":"3dDetection/IoU Loss for 2D/#iou-loss-for-2d3d-object-detection","text":"\u8fd9\u7bc7\u8bba\u6587\u7684\u6838\u5fc3\u8d21\u732e\u662f\u7ed9\u51fa\u4e86\u6240\u8c13\u7684IoU Loss,\u56e0\u4e3a\u62fc\u70b9\u7684\u8fc7\u7a0b\u4e2d\u5173\u952e\u70b9\u5728\u4e8e\u63d0\u5347IoU\u7684\u503c\uff0c\u4f46\u662f\u6211\u4eec\u76ee\u524d\u6ca1\u6709\u76f4\u63a5\u68af\u5ea6\u4f18\u5316IoU\u7684\u65b9\u6cd5\uff0c\u8fd9\u7bc7\u6587\u7ae0\u7ed9\u51fa\u7684IoU Loss\u5c31\u662f\u7ed9\u51fa\u4e00\u4e2a\u53ef\u5fae\u5206\u7684\u635f\u5931\u51fd\u6570\uff0c\u901a\u8fc7\u76f4\u63a5\u4f18\u5316IoU\u63d0\u9ad8\u5206\u6570","title":"IoU Loss for 2D/3D Object Detection"},{"location":"3dDetection/IoU Loss for 2D/#2d-iou","text":"\u8ba1\u7b97\u4e24\u4e2a\u5e73\u9762\u533a\u57df\u7684\u9762\u79ef \u627e\u51fa\u4e24\u4e2a\u533a\u57df\u76f8\u4ea4\u5f97\u5230\u7684\u51f8\u591a\u8fb9\u5f62\u7684\u70b9\uff0c\u8fd9\u4e9b\u70b9\u6709\u4e24\u79cd\u6765\u6e90\u53ef\u80fd\uff0c\u4e00\u4e2a\u662f\u4e24\u4e2abox\u8fb9\u7f18\u7684\u4ea4\u70b9\uff0c\u4e00\u4e2a\u662f\u51fa\u73b0\u5728\u53e6\u4e00\u4e2abbox\u533a\u57df\u4e2d\u7684\u539f\u6765box\u7684\u70b9 \u5c06\u8fd9\u4e9b\u51f8\u591a\u8fb9\u5f62\u7684\u8fb9\u7f18\u70b9\u9006\u65f6\u9488\u6216\u8005\u987a\u65f6\u9488\u6392\u5e8f\uff0c\u7b97\u6cd5\u662f\uff1a\u5148\u6c42\u51fa\u51f8\u591a\u8fb9\u5f62\u7684\u4e2d\u5fc3\u70b9\uff0c\u7136\u540e\u9010\u4e2a\u6c42\u51fa\u65cb\u8f6c\u89d2\u5ea6\uff0c\u7136\u540e\u5c06\u8fd9\u4e2a\u65cb\u8f6c\u89d2\u5ea6\u6392\u5e8f \u5c06\u51f8\u591a\u8fb9\u5f62\u5206\u89e3\u4e3a\u591a\u4e2a\u5c0f\u4e09\u89d2\u5f62\uff0c\u5e76\u6c42\u51fa\u603b\u5408\u9762\u79ef \u5f97\u5230overlap\u9762\u79ef\u540e\u6c42\u51faIoU","title":"\u4e00\u822c\u5e26\u6709\u65cb\u8f6c\u76842D IoU\u7b97\u6cd5"},{"location":"3dDetection/IoU Loss for 2D/#3d-iou","text":"\u53ea\u9700\u8981\u5728\u6c42\u51faover lap\u7684\u57fa\u7840\u4e0a\uff0c\u5728\u9ad8\u5ea6\u4e0a\u8865\u5145\u4e00\u4e9b\u53c2\u6570\u5373\u53ef\uff1a IoU_{3D} = \\frac{Area_{overlap} \\times h_{overlap}} {Area_g \\times h_g + Area_d \\times h_d - Area_{overlap} \\times h_{overlap}}","title":"3D IoU"},{"location":"3dDetection/M3D-RPN: Monocular 3D Region Proposal Network for Object Detection/","text":"M3D-RPN: Monocular 3D Region Proposal Network for Object Detection \u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u4f7f\u7528\u5355\u76ee\u76f8\u673a\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528\u4e86\u878d\u54082D-3D proposal\u7684\u65b9\u5f0f\uff0cuse depth-aware convolution,\u540e\u7aef\u4f18\u5316\u7ed3\u5408\u5404\u79cd\u4fe1\u606f\uff0c\u63d0\u5347\u5bf9 \\theta \u7684\u9884\u6d4b\u6027\u80fd \u603b\u4f53\u601d\u8def \u8fd9\u4e2a\u7f51\u7edc\u88ab\u8981\u6c42\u540c\u65f6\u8f93\u51fa2D\u4e0e3D\u9884\u6d4b\uff0ccost function\u540c\u65f6\u67093D\u6846\u4ee5\u53ca2D\u6846 depth-aware convolution\u5982\u56fe\uff0c\u5c31\u662f\u5728\u4e0d\u540c\u7684\u9ad8\u5ea6\u4e0a\u4f7f\u7528\u4e0d\u540c\u7684\u5377\u79ef\u6838\uff0c\u4e3a\u4e86\u4f7f\u5f97\u8fd0\u7b97\u5feb\uff0cpytorch implementation\u4e0a\u4f5c\u8005\u5c06\u5176reshape\uff0c\u7136\u540e\u4f7f\u7528depth-wise convolution(channel\u7ef4\u5ea6\u5206\u7ec4convolution) \u5176\u540e\u4f7f\u7528\u7684\u662f\u9010\u6b65\u4fee\u6539 \\theta \u4f7f\u5f97\u4e09\u7ef4\u5750\u6807\u4e0e\u4e8c\u7ef4\u6846\u5bf9\u9f50\uff0c\u7c7b\u4f3c\u4e8e\u6a21\u62df\u9000\u706b \u5177\u4f53\u7b97\u4e0a\u6765\u8bf4\u5c31\u662f\u6bcf\u4e00\u6b65\u8ba1\u7b973D\u5bf9\u5e942D\u6846\u4e0e\u9884\u6d4b2D\u6846\u7684L1-loss\uff0c\u4ece\u800c\u6765\u7ed9\u9884\u6d4b\u7684 \\theta \u6253\u5206","title":"M3D-RPN: Monocular 3D Region Proposal Network for Object Detection"},{"location":"3dDetection/M3D-RPN: Monocular 3D Region Proposal Network for Object Detection/#m3d-rpn-monocular-3d-region-proposal-network-for-object-detection","text":"\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u4f7f\u7528\u5355\u76ee\u76f8\u673a\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528\u4e86\u878d\u54082D-3D proposal\u7684\u65b9\u5f0f\uff0cuse depth-aware convolution,\u540e\u7aef\u4f18\u5316\u7ed3\u5408\u5404\u79cd\u4fe1\u606f\uff0c\u63d0\u5347\u5bf9 \\theta \u7684\u9884\u6d4b\u6027\u80fd","title":"M3D-RPN: Monocular 3D Region Proposal Network for Object Detection"},{"location":"3dDetection/M3D-RPN: Monocular 3D Region Proposal Network for Object Detection/#_1","text":"\u8fd9\u4e2a\u7f51\u7edc\u88ab\u8981\u6c42\u540c\u65f6\u8f93\u51fa2D\u4e0e3D\u9884\u6d4b\uff0ccost function\u540c\u65f6\u67093D\u6846\u4ee5\u53ca2D\u6846 depth-aware convolution\u5982\u56fe\uff0c\u5c31\u662f\u5728\u4e0d\u540c\u7684\u9ad8\u5ea6\u4e0a\u4f7f\u7528\u4e0d\u540c\u7684\u5377\u79ef\u6838\uff0c\u4e3a\u4e86\u4f7f\u5f97\u8fd0\u7b97\u5feb\uff0cpytorch implementation\u4e0a\u4f5c\u8005\u5c06\u5176reshape\uff0c\u7136\u540e\u4f7f\u7528depth-wise convolution(channel\u7ef4\u5ea6\u5206\u7ec4convolution) \u5176\u540e\u4f7f\u7528\u7684\u662f\u9010\u6b65\u4fee\u6539 \\theta \u4f7f\u5f97\u4e09\u7ef4\u5750\u6807\u4e0e\u4e8c\u7ef4\u6846\u5bf9\u9f50\uff0c\u7c7b\u4f3c\u4e8e\u6a21\u62df\u9000\u706b \u5177\u4f53\u7b97\u4e0a\u6765\u8bf4\u5c31\u662f\u6bcf\u4e00\u6b65\u8ba1\u7b973D\u5bf9\u5e942D\u6846\u4e0e\u9884\u6d4b2D\u6846\u7684L1-loss\uff0c\u4ece\u800c\u6765\u7ed9\u9884\u6d4b\u7684 \\theta \u6253\u5206","title":"\u603b\u4f53\u601d\u8def"},{"location":"3dDetection/MonoGRNet: A Geometric Reasoning Network for Monocular 3D Object Localization/","text":"MonoGRNet: A Geometric Reasoning Network for Monocular 3D Object Localization \u672c\u6587\u63d0\u51fa\u7684\u7f51\u7edc\u7ed3\u6784\u53ef\u4ee5\u57280.06s\u79d2\u5185\u5b8c\u6210\u4e00\u5f20\u56fe\u7247\u7684inference","title":"MonoGRNet: A Geometric Reasoning Network for Monocular 3D Object Localization"},{"location":"3dDetection/MonoGRNet: A Geometric Reasoning Network for Monocular 3D Object Localization/#monogrnet-a-geometric-reasoning-network-for-monocular-3d-object-localization","text":"\u672c\u6587\u63d0\u51fa\u7684\u7f51\u7edc\u7ed3\u6784\u53ef\u4ee5\u57280.06s\u79d2\u5185\u5b8c\u6210\u4e00\u5f20\u56fe\u7247\u7684inference","title":"MonoGRNet: A Geometric Reasoning Network for Monocular 3D Object Localization"},{"location":"3dDetection/Monocular_3D_Object_Detection_and_Box_Fitting_Trained_End-to-End_Using_Intersection-over-Union_Loss/","text":"Monocular 3D Object Detection and Box Fitting Trained End-to-End Using Intersection-over-Union Loss \u672c\u6587\u63d0\u51fa\u4e86\u5728\u5355\u76ee3D\u68c0\u6d4b\u4e2d\u8003\u8651\u5f02\u8d28\u566a\u58f0\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2abackprop through optimization\u7684\u65b9\u6cd5\u3002 \u6d41\u7a0b\u603b\u89c8 \u9996\u5148\u4e00\u4e2aCNN\u8fdb\u884cobject detection\uff0c\u8f93\u51fa\u7c7b\u522bscore\u4ee5\u53ca2D bounding box\uff0c\u6267\u884cNMS\u5220\u9664\u90e8\u5206\u5197\u4f59\uff0c\u6700\u540e\u4f7f\u7528\u4e00\u4e2a\u975e\u7ebf\u6027\u4f18\u5316\u3002 \u7f51\u7edc\u8f93\u51fa \u7f51\u7edc\u8f93\u51fa\u7ed3\u679c\u9664\u4e86\u5206\u7c7b\u7ed3\u679c\u4e4b\u5916\u8fd8\u670926\u7ef4\u3002 2D bounding box\u5bf9\u5e94\u4e24\u4e2a\u89d2\u70b94\u4e2a\u503c\u3002 \u7269\u4f53\u4e2d\u5fc3\u4e0e\u76f8\u673a\u7684\u8ddd\u79bb(\u4e5f\u53ef\u4ee5\u7528Z\u8f74\u8ddd\u79bb\uff0c\u6027\u80fd\u5dee\u8ddd\u4e0d\u5927)\uff0c\u4e00\u4e2a\u503c \u89c2\u5bdf\u89d2 \\alpha \u9884\u6d4b\u5176sin\u4e0ecos\u503c\uff0c\u51712\u4e2a\u503c \u7269\u4f53\u5c3a\u5ea6\u957f\u5bbd\u9ad8\uff0c\u7528log\u503c\u4ee3\u8868\uff0c\u51713\u4e2a\u503c\u3002 3D bounding box\u76848\u4e2a\u70b9\u5728\u76f8\u673a\u5750\u6807\u7cfb\u7684\u6295\u5f71\uff0c\u517116\u4e2a\u503c\u3002 \u5bf93Dbox\u7684\u521d\u59cb\u89e3,\u4ee52D\u6846\u7684\u4e2d\u5fc3\u4f5c\u4e3a\u7269\u4f533D\u4e2d\u5fc3\u5728\u56fe\u7247\u7684\u6295\u5f71,\u5c31\u53ef\u4ee5\u5f97\u5230\u5bf93Dbox\u7684\u521d\u59cb\u4f30\u8ba1. taskNet\u4f7f\u5f97\u6bcf\u4e00\u4e2a\u8f93\u51fa\u4f1a\u540c\u65f6\u5e26\u4e0a\u4e86\u5bf9\u4e0d\u786e\u5b9a\u6027\u7684\u4f30\u8ba1 \u4e09\u79cdLoss\u8bad\u7ec3\u65b9\u6cd5 \u7b2c\u4e00\u79cd\u4f20\u7edf\u5b9a\u4e49\u662f\u5e73\u7a33\u566a\u58f0 Loss\u51fd\u6570\u5b9a\u4e49\u5982\u4e0b: \\begin{aligned} \\mathcal{L}_{1} &=\\mathcal{L}_{c l s} \\\\ &+\\frac{1}{N} \\sum_{j=1}^{N} \\sum_{k=1}^{26}\\left(\\frac{\\left\\|\\mathbf{y}_{k}^{(j)}-f_{k}\\left(\\mathbf{b}^{(j)}\\right)\\right\\|^{2}}{2 \\sigma_{k}^{2}}+\\log \\sigma_{k}\\right) \\end{aligned} \u672c\u8d28\u4e0a\u5c31\u662f Multi Task Learning \uff0c \u4e5f\u5c31\u662f\u8bf4\u6bcf\u4e00\u4e2aloss\u7c7b\u522b\u4f1a\u6709\u4e00\u4e2a\u5355\u72ec\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1. \u7b2c\u4e8c\u79cd\u5b9a\u4e49\u662f\u5f02\u65b9\u5dee\u566a\u58f0 \\begin{aligned} \\mathcal{L}_{2} &=\\mathcal{L}_{c l s} \\\\ &+\\frac{1}{N} \\sum_{i}\\left(\\frac{\\left(y_{i}-f_{i}\\left(\\mathbf{b}_{i}\\right)^{2}\\right)}{2 \\sigma_{i}^{2}}+\\log \\sigma_{i}-\\log P_{\\text {prior }}\\left(\\sigma_{i}^{-2}\\right)\\right) \\end{aligned} \u4e5f\u5c31\u662f\u9700\u8981tasknet\u8ddf\u968f\u6bcf\u4e00\u4e2a\u8f93\u51fa\u8f93\u51fa\u4e00\u4e2a\u8bef\u5dee\u503c \u5176\u4e2d P_{prior} \u5728\u8fd9\u91cc\u88ab\u5b9a\u4e49\u4e3a (\\alpha, \\beta) = (1, 0.5) \u7684 \u4f3d\u9a6c\u5206\u5e03 \u4ee5\u4e0a\u4e24\u79cd\u65b9\u5f0f\u5f97\u5230\u7684variance\u90fd\u53ef\u4ee5\u5728inference\u7684\u65f6\u5019\u4f5c\u4e3a\u5bf9\u4e0d\u786e\u5b9a\u6027\u7684\u4f30\u8ba1\uff0c\u4e5f\u5c31\u4fbf\u4e8e\u5bf9\u540e\u7aef\u4f18\u5316 \u7b2c\u4e09\u79cd\u8bad\u7ec3\u65b9\u5f0f\u662fbackprop through optimization \u9996\u5148\u4f18\u5316\u95ee\u9898\u7684\u5b9a\u4e49\u6765\u81ea\u4e8e E(\\mathbf{b} ; \\mathbf{y})=\\sum_{i=1}^{26} r_{i}(\\mathbf{b} ; \\mathbf{y})^{2}=\\sum_{i=1}^{26}\\left(w_{i}\\left(y_{i}-f_{i}(\\mathbf{b})\\right)\\right)^{2} \u524d\u4e24\u79cd\u65b9\u5f0f\u7684\u903b\u8f91\u5c31\u662f\u5728\u8bad\u7ec3\u7684\u65f6\u5019\u901a\u8fc7loss\u5b66\u4e60variance\uff0c\u7136\u540e\u76f4\u63a5\u7528\u4e8einference\u3002\u800c\u7b2c\u4e09\u79cd\u8bad\u7ec3\u65b9\u5f0f\u5c31\u662f\u628aoptimization\u653e\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u4e5f\u5c31\u80fd\u76f4\u63a5\u8bad\u7ec3\u8bef\u5deevariance. \u8fd9\u91cc\u5b83\u5728\u8bad\u7ec3\u7684\u65f6\u5019\u4f7f\u75283D IoU\u635f\u5931\u3002\u5728\u53cd\u4f20\u7684\u65f6\u5019\uff0c\u6839\u636e \\hat b = argmin_bE(b,y,\\sigma) \u4ee5\u53ca \\nabla_bE(b, y, \\sigma) = 0 \u4f7f\u7528 \u9690\u51fd\u6570\u5b9a\u7406 (\u4e2a\u4eba\u6682\u65f6\u672a\u80fd\u7406\u89e3) \u5f97\u5230 \\frac{\\partial \\hat{\\mathbf{b}}}{\\partial \\mathbf{y}}=-\\left[\\frac{\\partial^{2} E}{\\partial \\hat{\\mathbf{b}}^{2}}\\right]^{-1}\\left[\\frac{\\partial^{2} E}{\\partial \\mathbf{y} \\partial \\hat{\\mathbf{b}}}\\right] \\approx-\\left[\\frac{\\partial \\mathbf{r}}{\\partial \\hat{\\mathbf{b}}}\\right]^{+}\\left[\\frac{\\partial \\mathbf{r}}{\\partial \\mathbf{y}}\\right]","title":"Monocular 3D Object Detection and Box Fitting Trained End-to-End Using Intersection-over-Union Loss"},{"location":"3dDetection/Monocular_3D_Object_Detection_and_Box_Fitting_Trained_End-to-End_Using_Intersection-over-Union_Loss/#monocular-3d-object-detection-and-box-fitting-trained-end-to-end-using-intersection-over-union-loss","text":"\u672c\u6587\u63d0\u51fa\u4e86\u5728\u5355\u76ee3D\u68c0\u6d4b\u4e2d\u8003\u8651\u5f02\u8d28\u566a\u58f0\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2abackprop through optimization\u7684\u65b9\u6cd5\u3002","title":"Monocular 3D Object Detection and Box Fitting Trained End-to-End Using Intersection-over-Union Loss"},{"location":"3dDetection/Monocular_3D_Object_Detection_and_Box_Fitting_Trained_End-to-End_Using_Intersection-over-Union_Loss/#_1","text":"\u9996\u5148\u4e00\u4e2aCNN\u8fdb\u884cobject detection\uff0c\u8f93\u51fa\u7c7b\u522bscore\u4ee5\u53ca2D bounding box\uff0c\u6267\u884cNMS\u5220\u9664\u90e8\u5206\u5197\u4f59\uff0c\u6700\u540e\u4f7f\u7528\u4e00\u4e2a\u975e\u7ebf\u6027\u4f18\u5316\u3002","title":"\u6d41\u7a0b\u603b\u89c8"},{"location":"3dDetection/Monocular_3D_Object_Detection_and_Box_Fitting_Trained_End-to-End_Using_Intersection-over-Union_Loss/#_2","text":"\u7f51\u7edc\u8f93\u51fa\u7ed3\u679c\u9664\u4e86\u5206\u7c7b\u7ed3\u679c\u4e4b\u5916\u8fd8\u670926\u7ef4\u3002 2D bounding box\u5bf9\u5e94\u4e24\u4e2a\u89d2\u70b94\u4e2a\u503c\u3002 \u7269\u4f53\u4e2d\u5fc3\u4e0e\u76f8\u673a\u7684\u8ddd\u79bb(\u4e5f\u53ef\u4ee5\u7528Z\u8f74\u8ddd\u79bb\uff0c\u6027\u80fd\u5dee\u8ddd\u4e0d\u5927)\uff0c\u4e00\u4e2a\u503c \u89c2\u5bdf\u89d2 \\alpha \u9884\u6d4b\u5176sin\u4e0ecos\u503c\uff0c\u51712\u4e2a\u503c \u7269\u4f53\u5c3a\u5ea6\u957f\u5bbd\u9ad8\uff0c\u7528log\u503c\u4ee3\u8868\uff0c\u51713\u4e2a\u503c\u3002 3D bounding box\u76848\u4e2a\u70b9\u5728\u76f8\u673a\u5750\u6807\u7cfb\u7684\u6295\u5f71\uff0c\u517116\u4e2a\u503c\u3002 \u5bf93Dbox\u7684\u521d\u59cb\u89e3,\u4ee52D\u6846\u7684\u4e2d\u5fc3\u4f5c\u4e3a\u7269\u4f533D\u4e2d\u5fc3\u5728\u56fe\u7247\u7684\u6295\u5f71,\u5c31\u53ef\u4ee5\u5f97\u5230\u5bf93Dbox\u7684\u521d\u59cb\u4f30\u8ba1. taskNet\u4f7f\u5f97\u6bcf\u4e00\u4e2a\u8f93\u51fa\u4f1a\u540c\u65f6\u5e26\u4e0a\u4e86\u5bf9\u4e0d\u786e\u5b9a\u6027\u7684\u4f30\u8ba1","title":"\u7f51\u7edc\u8f93\u51fa"},{"location":"3dDetection/Monocular_3D_Object_Detection_and_Box_Fitting_Trained_End-to-End_Using_Intersection-over-Union_Loss/#loss","text":"\u7b2c\u4e00\u79cd\u4f20\u7edf\u5b9a\u4e49\u662f\u5e73\u7a33\u566a\u58f0 Loss\u51fd\u6570\u5b9a\u4e49\u5982\u4e0b: \\begin{aligned} \\mathcal{L}_{1} &=\\mathcal{L}_{c l s} \\\\ &+\\frac{1}{N} \\sum_{j=1}^{N} \\sum_{k=1}^{26}\\left(\\frac{\\left\\|\\mathbf{y}_{k}^{(j)}-f_{k}\\left(\\mathbf{b}^{(j)}\\right)\\right\\|^{2}}{2 \\sigma_{k}^{2}}+\\log \\sigma_{k}\\right) \\end{aligned} \u672c\u8d28\u4e0a\u5c31\u662f Multi Task Learning \uff0c \u4e5f\u5c31\u662f\u8bf4\u6bcf\u4e00\u4e2aloss\u7c7b\u522b\u4f1a\u6709\u4e00\u4e2a\u5355\u72ec\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1. \u7b2c\u4e8c\u79cd\u5b9a\u4e49\u662f\u5f02\u65b9\u5dee\u566a\u58f0 \\begin{aligned} \\mathcal{L}_{2} &=\\mathcal{L}_{c l s} \\\\ &+\\frac{1}{N} \\sum_{i}\\left(\\frac{\\left(y_{i}-f_{i}\\left(\\mathbf{b}_{i}\\right)^{2}\\right)}{2 \\sigma_{i}^{2}}+\\log \\sigma_{i}-\\log P_{\\text {prior }}\\left(\\sigma_{i}^{-2}\\right)\\right) \\end{aligned} \u4e5f\u5c31\u662f\u9700\u8981tasknet\u8ddf\u968f\u6bcf\u4e00\u4e2a\u8f93\u51fa\u8f93\u51fa\u4e00\u4e2a\u8bef\u5dee\u503c \u5176\u4e2d P_{prior} \u5728\u8fd9\u91cc\u88ab\u5b9a\u4e49\u4e3a (\\alpha, \\beta) = (1, 0.5) \u7684 \u4f3d\u9a6c\u5206\u5e03 \u4ee5\u4e0a\u4e24\u79cd\u65b9\u5f0f\u5f97\u5230\u7684variance\u90fd\u53ef\u4ee5\u5728inference\u7684\u65f6\u5019\u4f5c\u4e3a\u5bf9\u4e0d\u786e\u5b9a\u6027\u7684\u4f30\u8ba1\uff0c\u4e5f\u5c31\u4fbf\u4e8e\u5bf9\u540e\u7aef\u4f18\u5316 \u7b2c\u4e09\u79cd\u8bad\u7ec3\u65b9\u5f0f\u662fbackprop through optimization \u9996\u5148\u4f18\u5316\u95ee\u9898\u7684\u5b9a\u4e49\u6765\u81ea\u4e8e E(\\mathbf{b} ; \\mathbf{y})=\\sum_{i=1}^{26} r_{i}(\\mathbf{b} ; \\mathbf{y})^{2}=\\sum_{i=1}^{26}\\left(w_{i}\\left(y_{i}-f_{i}(\\mathbf{b})\\right)\\right)^{2} \u524d\u4e24\u79cd\u65b9\u5f0f\u7684\u903b\u8f91\u5c31\u662f\u5728\u8bad\u7ec3\u7684\u65f6\u5019\u901a\u8fc7loss\u5b66\u4e60variance\uff0c\u7136\u540e\u76f4\u63a5\u7528\u4e8einference\u3002\u800c\u7b2c\u4e09\u79cd\u8bad\u7ec3\u65b9\u5f0f\u5c31\u662f\u628aoptimization\u653e\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u4e5f\u5c31\u80fd\u76f4\u63a5\u8bad\u7ec3\u8bef\u5deevariance. \u8fd9\u91cc\u5b83\u5728\u8bad\u7ec3\u7684\u65f6\u5019\u4f7f\u75283D IoU\u635f\u5931\u3002\u5728\u53cd\u4f20\u7684\u65f6\u5019\uff0c\u6839\u636e \\hat b = argmin_bE(b,y,\\sigma) \u4ee5\u53ca \\nabla_bE(b, y, \\sigma) = 0 \u4f7f\u7528 \u9690\u51fd\u6570\u5b9a\u7406 (\u4e2a\u4eba\u6682\u65f6\u672a\u80fd\u7406\u89e3) \u5f97\u5230 \\frac{\\partial \\hat{\\mathbf{b}}}{\\partial \\mathbf{y}}=-\\left[\\frac{\\partial^{2} E}{\\partial \\hat{\\mathbf{b}}^{2}}\\right]^{-1}\\left[\\frac{\\partial^{2} E}{\\partial \\mathbf{y} \\partial \\hat{\\mathbf{b}}}\\right] \\approx-\\left[\\frac{\\partial \\mathbf{r}}{\\partial \\hat{\\mathbf{b}}}\\right]^{+}\\left[\\frac{\\partial \\mathbf{r}}{\\partial \\mathbf{y}}\\right]","title":"\u4e09\u79cdLoss\u8bad\u7ec3\u65b9\u6cd5"},{"location":"3dDetection/Multi-Sensor 3D Object Box Refinement for Autonomous Driving/","text":"Multi-Sensor 3D Object Box Refinement for Autonomous Driving \u8fd9\u7bc7\u8bba\u6587\u6e90\u81ea\u4e8e\u6c88\u5c11\u6770\u5b9e\u9a8c\u5ba4\u7684\u5b66\u957f\uff0c\u975e\u5e38\u503c\u5f97\u6ce8\u610f\u7684\u662f\u8fd9\u7bc7\u8bba\u6587\u4ece\u5355\u76ee\u89c6\u89c93D\u68c0\u6d4b\u51fa\u53d1\uff0c\u901a\u8fc7\u4e0d\u540c\u7684trick\u878d\u5408\u53cc\u76ee\u4ee5\u53ca\u70b9\u4e91\u4fe1\u606f(\u4e5f\u5c31\u662f\u8bf4\u5728\u6dfb\u52a0\u53cc\u76ee\u4ee5\u53ca\u6dfb\u52a0\u70b9\u4e91\u7684\u65f6\u5019\u4e0d\u9700\u8981\u91cd\u65b0train\u5168\u65b0\u7684\u7f51\u7edc\uff0c\u53ea\u9700\u8981train\u5c0f\u7f51\u7edc\u6216\u8005\u66f4\u6539post-opimization),\u662f\u4e00\u5957\u975e\u5e38\u79d1\u5b66\u53ef\u7528\u7684\u65b9\u6848\u3002 \u7ed3\u679c\u6765\u770b\uff0c\u5728\u5355\u76ee\u4e0a\u521b\u65b0\u6709\u9650\uff0c\u5728\u5355\u76ee-\u53cc\u76ee\u8054\u5408\u4e0a\u7528\u5904\u5f88\u5927\uff0c\u4e5f\u8fbe\u5230\u4e86\u53cc\u76ee\u7684SOTA(\u4ec5\u6b21\u4e8e\u8fd0\u7b97\u91cf\u66f4\u591a\u7684pseudo lidar)\uff0c\u53ef\u60dc\u5728lidar\u878d\u5408\u4e0a\u6570\u636e\u7ed3\u679c\u5e76\u6ca1\u6709\u663e\u8457\u9ad8\u4e8e\u7eafLidar\u7684SOTA\u65b9\u6848\u3002 \u6574\u4f53\u7ed3\u6784 \u4ece\u4e2d\u53ef\u77e5\u4e2d\u95f4\u4e00\u6761pipeline\u662f\u5b8c\u6574\u7684\u5355\u76ee\u9884\u6d4b\u8fc7\u7a0b\uff0c\u53cc\u76ee\u4ee5\u53ca\u70b9\u4e91\u5728\u8fd9\u91cc\u4e3b\u8981\u4f5c\u4e3a\u8f85\u52a9 \u5355\u76ee\u68c0\u6d4b\u505a\u6cd5 \u7b97\u662f\u6bd4\u8f83\u5e38\u89c1\u7684\u7ed3\u6784\uff0cFaster RCNN->RoI Align->residual prediction \u5bf9\u4e8e\u6df1\u5ea6\uff0c\u7f51\u7edc\u8f93\u51fa\u7684\u4e5f\u662f\u6b8b\u5dee\uff0c\u5bf9\u9ad8\u5ea6\u5176\u6b8b\u5dee\u7684base\u4f30\u8ba1\u4e3a z_{roi}=f_y\\frac{h}{h_{roio}} \u5176\u4e2d h \u4e3a3D\u7269\u4f53\u7684\u9ad8\u5ea6\uff0c h_{roi} \u4e3a2D RoI\u9ad8\u5ea6\uff0c\u5b9a\u4e49\u7684\u7f51\u7edc\u8f93\u51fa\u7684\u957f\u5bbd\u9ad8\u6b8b\u5dee \\Delta d = log\\frac{d-p_d}{\\sigma_d} d \uff0c\u5176\u4e2d d \u4e3a (w,h,l) \u6700\u7ec8\u7684\u8f93\u51fa\u4e3a\u4e2d\u5fc3\u5728\u76f8\u673a\u4e2d\u7684\u6295\u5f71,\u6df1\u5ea6,\u957f\u5bbd\u9ad8\u7684\u6b8b\u5dee\uff0c\u4ee5\u53ca\u76f8\u5bf9\u89c2\u5bdf\u89d2\u7684sin,cos\u503c(\u89c2\u5bdf\u89d2\u7528multi-bin\u56de\u5f52) \u53cc\u76eeRefinement \u7a0d\u5fae\u6709\u70b9\u50cf Stereo RCNN \u7684\u60f3\u6cd5,\u901a\u8fc7\u5728\u5c40\u90e8\u56fe\u50cf\u4ece\u53f3\u76eewarp\u5230\u5de6\u76ee\u4e0aminimizing\u4e00\u4e2a\u5339\u914derror\u6765\u4f30\u8ba1\u6df1\u5ea6\u3002 \u8fd9\u91cc\u7684\u7b97\u6cd5\uff1a \u5728RoI\u4e2d\u7c7b\u4f3cSegmentation\u8f93\u51fa28*28 * 4 * classs\u7684sigmoid\u7ed3\u679c\uff0c\u5305\u542b\u4e00\u4e2a\u5206\u7c7b\u5668+\u4e09\u4e2a\u56de\u5f52\u5668,\u56de\u5f52\u90e8\u5206\u8868\u660e\u56fe\u50cf\u8fd9\u4e2a\u70b9\u5bf9\u5e94\u5750\u6807(normalized to [0,1] for each dimensions) \u6839\u636e\u5de6\u56fe\u8fd9\u4e2a\u533a\u57df\u6bcf\u4e00\u4e2a\u70b9\u9884\u6d4b\u7684normalized\u5750\u6807\u4ee5\u53ca\u9884\u6d4b\u7684\u5c3a\u5bf8\uff0c\u5c06\u8be5\u70b9\u5728\u56fe\u4e2d\u7684\u4f4d\u7f6e\u8f6c\u6362\u5230\u4e16\u754c\u5750\u6807\uff0c\u518d\u6295\u5f71\u5230\u7b2c\u4e8c\u5f20\u56fe\u4e2d\u3002 \u6211\u4eec\u9700\u8981\u51cf\u5c11\u5bf9\u5e94\u70b9\u4e4b\u95f4\u7684\u539f\u56fe\u5dee\u503c \u4f18\u5316\u6df1\u5ea6\u503c \u5b50\u7f51\u7edc\u7684label\u6765\u6e90\uff1a\u501f\u52a9\u70b9\u4e91\uff0c\u5148\u5f97\u5230\u8be5\u70b9\u4e91\u7684\u5b9e\u9645 instance vector\u503c\uff0c\u7136\u540e\u6295\u5f71\u56de\u56fe\u7247\u4e2d\u5f97\u5230\u50cf\u7d20\u7ea7label \u70b9\u4e91Refinement \u4f7f\u75282D detection\u7ed3\u679c\u7684 RoI\u63d0\u53d6\u51fa\u90e8\u5206\u70b9\u4e91\uff0c \u91cd\u91c7\u6837\u56fa\u5b9an\u4e2a\u70b9 point-wise instance seg\u7528\u4e8e\u533a\u5206foreground \u6839\u636eforeground\u7684probability,\u91cd\u91c7\u6837m\u4e2a\u70b9 T-Net\u7528\u4e8e\u4f30\u8ba1\u7269\u4f53\u4e2d\u5fc3\u4e0e\u51e0\u4f55\u3001\u65b9\u5411\u4fe1\u606f\uff0c\u8fd8\u8981\u505a\u4e00\u4e2ainstance vector\u7684\u4f30\u8ba1(\u7c7b\u4f3c\u4e8e\u53cc\u76ee\u7684\u7ed3\u679c) \u4f18\u5316\u8fd9\u4e2a\u51fd\u6570,\u5176\u4e2d ^cp_i \u4e3alidar\u70b9\u7684\u5750\u6807\uff0c ^c\\hat p_i \u4e3a\u6839\u636e\u4e2d\u5fc3\u70b9\u3001pose\u3001\u5f62\u72b6\u3001instsance vector\u4f30\u8ba1\u7684\u5750\u6807\u503c\uff0c\u7531\u4e8e\u53ea\u9700\u8981\u4f18\u5316\u6df1\u5ea6\u503c\uff0c\u6240\u4ee5\u53ef\u4ee5\u7ebf\u6027\u6c42\u89e3 \\mathbf{E}_{p} :=\\sum_{i=0}^{m}\\left\\|^{c} \\mathbf{p}_{i}-^{c} \\hat{\\mathbf{p}}_{i}\\right\\|, \\text { with } \\quad^{c} \\hat{\\mathbf{p}}_{i}=\\hat{\\mathbf{p}}_{o}+\\mathbf{R}(\\theta)^{o} \\mathbf{p}_{i} \u66f4\u591a\u4f20\u611f\u5668\u7684\u878d\u5408 \\begin{aligned} \\mathbf{p}_{o}=\\underset{\\mathbf{p}_{o}}{\\arg \\min } & \\sum_{i=0}^{n}\\left\\|I_{l}\\left(\\mathbf{u}_{i}\\right)-I_{r}\\left(\\pi\\left(^{c} \\hat{\\mathbf{p}}_{i}-\\mathbf{b}\\right)\\right)\\right\\|_{\\sum_{s}}+\\\\ & \\sum_{j=0}^{m}\\left\\|^{c} \\mathbf{p}_{j}-^{c} \\hat{\\mathbf{p}}_{j}\\right\\|_{\\Sigma_{p}} \\end{aligned} \u4e24\u9879\u5206\u522b\u5904\u7406\u76f8\u673a\u4ee5\u53ca\u70b9\u4e91\u6570\u636e\u3002 \u5176\u4ed6\u8bad\u7ec3\u7ec6\u8282 \u635f\u5931\u51fd\u6570\u5305\u62ecRPN, 2D\u68c0\u6d4b\uff0c\u89d2\u5ea6\uff0c\u4f4d\u7f6e\uff0c\u7ef4\u5ea6\u3002\u7528 multi-loss \u7ed3\u5408 \u4e3a\u4e86\u7ed9\u56fe\u7247\u7f51\u8def\u63d0\u4f9b\u4f4d\u7f6e\uff0c\u5728\u8f93\u51fa\u7aef\u52a0\u5165u,v\u5750\u6807(grid channels),\u7b2c\u4e00\u4e2aConv\u7684\u6743\u91cd\u88ab\u590d\u5236\u91cd\u7528\u7ed9\u8fd9\u65b0\u7684channel.","title":"Multi-Sensor 3D Object Box Refinement for Autonomous Driving"},{"location":"3dDetection/Multi-Sensor 3D Object Box Refinement for Autonomous Driving/#multi-sensor-3d-object-box-refinement-for-autonomous-driving","text":"\u8fd9\u7bc7\u8bba\u6587\u6e90\u81ea\u4e8e\u6c88\u5c11\u6770\u5b9e\u9a8c\u5ba4\u7684\u5b66\u957f\uff0c\u975e\u5e38\u503c\u5f97\u6ce8\u610f\u7684\u662f\u8fd9\u7bc7\u8bba\u6587\u4ece\u5355\u76ee\u89c6\u89c93D\u68c0\u6d4b\u51fa\u53d1\uff0c\u901a\u8fc7\u4e0d\u540c\u7684trick\u878d\u5408\u53cc\u76ee\u4ee5\u53ca\u70b9\u4e91\u4fe1\u606f(\u4e5f\u5c31\u662f\u8bf4\u5728\u6dfb\u52a0\u53cc\u76ee\u4ee5\u53ca\u6dfb\u52a0\u70b9\u4e91\u7684\u65f6\u5019\u4e0d\u9700\u8981\u91cd\u65b0train\u5168\u65b0\u7684\u7f51\u7edc\uff0c\u53ea\u9700\u8981train\u5c0f\u7f51\u7edc\u6216\u8005\u66f4\u6539post-opimization),\u662f\u4e00\u5957\u975e\u5e38\u79d1\u5b66\u53ef\u7528\u7684\u65b9\u6848\u3002 \u7ed3\u679c\u6765\u770b\uff0c\u5728\u5355\u76ee\u4e0a\u521b\u65b0\u6709\u9650\uff0c\u5728\u5355\u76ee-\u53cc\u76ee\u8054\u5408\u4e0a\u7528\u5904\u5f88\u5927\uff0c\u4e5f\u8fbe\u5230\u4e86\u53cc\u76ee\u7684SOTA(\u4ec5\u6b21\u4e8e\u8fd0\u7b97\u91cf\u66f4\u591a\u7684pseudo lidar)\uff0c\u53ef\u60dc\u5728lidar\u878d\u5408\u4e0a\u6570\u636e\u7ed3\u679c\u5e76\u6ca1\u6709\u663e\u8457\u9ad8\u4e8e\u7eafLidar\u7684SOTA\u65b9\u6848\u3002","title":"Multi-Sensor 3D Object Box Refinement for Autonomous Driving"},{"location":"3dDetection/Multi-Sensor 3D Object Box Refinement for Autonomous Driving/#_1","text":"\u4ece\u4e2d\u53ef\u77e5\u4e2d\u95f4\u4e00\u6761pipeline\u662f\u5b8c\u6574\u7684\u5355\u76ee\u9884\u6d4b\u8fc7\u7a0b\uff0c\u53cc\u76ee\u4ee5\u53ca\u70b9\u4e91\u5728\u8fd9\u91cc\u4e3b\u8981\u4f5c\u4e3a\u8f85\u52a9","title":"\u6574\u4f53\u7ed3\u6784"},{"location":"3dDetection/Multi-Sensor 3D Object Box Refinement for Autonomous Driving/#_2","text":"\u7b97\u662f\u6bd4\u8f83\u5e38\u89c1\u7684\u7ed3\u6784\uff0cFaster RCNN->RoI Align->residual prediction \u5bf9\u4e8e\u6df1\u5ea6\uff0c\u7f51\u7edc\u8f93\u51fa\u7684\u4e5f\u662f\u6b8b\u5dee\uff0c\u5bf9\u9ad8\u5ea6\u5176\u6b8b\u5dee\u7684base\u4f30\u8ba1\u4e3a z_{roi}=f_y\\frac{h}{h_{roio}} \u5176\u4e2d h \u4e3a3D\u7269\u4f53\u7684\u9ad8\u5ea6\uff0c h_{roi} \u4e3a2D RoI\u9ad8\u5ea6\uff0c\u5b9a\u4e49\u7684\u7f51\u7edc\u8f93\u51fa\u7684\u957f\u5bbd\u9ad8\u6b8b\u5dee \\Delta d = log\\frac{d-p_d}{\\sigma_d} d \uff0c\u5176\u4e2d d \u4e3a (w,h,l) \u6700\u7ec8\u7684\u8f93\u51fa\u4e3a\u4e2d\u5fc3\u5728\u76f8\u673a\u4e2d\u7684\u6295\u5f71,\u6df1\u5ea6,\u957f\u5bbd\u9ad8\u7684\u6b8b\u5dee\uff0c\u4ee5\u53ca\u76f8\u5bf9\u89c2\u5bdf\u89d2\u7684sin,cos\u503c(\u89c2\u5bdf\u89d2\u7528multi-bin\u56de\u5f52)","title":"\u5355\u76ee\u68c0\u6d4b\u505a\u6cd5"},{"location":"3dDetection/Multi-Sensor 3D Object Box Refinement for Autonomous Driving/#refinement","text":"\u7a0d\u5fae\u6709\u70b9\u50cf Stereo RCNN \u7684\u60f3\u6cd5,\u901a\u8fc7\u5728\u5c40\u90e8\u56fe\u50cf\u4ece\u53f3\u76eewarp\u5230\u5de6\u76ee\u4e0aminimizing\u4e00\u4e2a\u5339\u914derror\u6765\u4f30\u8ba1\u6df1\u5ea6\u3002 \u8fd9\u91cc\u7684\u7b97\u6cd5\uff1a \u5728RoI\u4e2d\u7c7b\u4f3cSegmentation\u8f93\u51fa28*28 * 4 * classs\u7684sigmoid\u7ed3\u679c\uff0c\u5305\u542b\u4e00\u4e2a\u5206\u7c7b\u5668+\u4e09\u4e2a\u56de\u5f52\u5668,\u56de\u5f52\u90e8\u5206\u8868\u660e\u56fe\u50cf\u8fd9\u4e2a\u70b9\u5bf9\u5e94\u5750\u6807(normalized to [0,1] for each dimensions) \u6839\u636e\u5de6\u56fe\u8fd9\u4e2a\u533a\u57df\u6bcf\u4e00\u4e2a\u70b9\u9884\u6d4b\u7684normalized\u5750\u6807\u4ee5\u53ca\u9884\u6d4b\u7684\u5c3a\u5bf8\uff0c\u5c06\u8be5\u70b9\u5728\u56fe\u4e2d\u7684\u4f4d\u7f6e\u8f6c\u6362\u5230\u4e16\u754c\u5750\u6807\uff0c\u518d\u6295\u5f71\u5230\u7b2c\u4e8c\u5f20\u56fe\u4e2d\u3002 \u6211\u4eec\u9700\u8981\u51cf\u5c11\u5bf9\u5e94\u70b9\u4e4b\u95f4\u7684\u539f\u56fe\u5dee\u503c \u4f18\u5316\u6df1\u5ea6\u503c \u5b50\u7f51\u7edc\u7684label\u6765\u6e90\uff1a\u501f\u52a9\u70b9\u4e91\uff0c\u5148\u5f97\u5230\u8be5\u70b9\u4e91\u7684\u5b9e\u9645 instance vector\u503c\uff0c\u7136\u540e\u6295\u5f71\u56de\u56fe\u7247\u4e2d\u5f97\u5230\u50cf\u7d20\u7ea7label","title":"\u53cc\u76eeRefinement"},{"location":"3dDetection/Multi-Sensor 3D Object Box Refinement for Autonomous Driving/#refinement_1","text":"\u4f7f\u75282D detection\u7ed3\u679c\u7684 RoI\u63d0\u53d6\u51fa\u90e8\u5206\u70b9\u4e91\uff0c \u91cd\u91c7\u6837\u56fa\u5b9an\u4e2a\u70b9 point-wise instance seg\u7528\u4e8e\u533a\u5206foreground \u6839\u636eforeground\u7684probability,\u91cd\u91c7\u6837m\u4e2a\u70b9 T-Net\u7528\u4e8e\u4f30\u8ba1\u7269\u4f53\u4e2d\u5fc3\u4e0e\u51e0\u4f55\u3001\u65b9\u5411\u4fe1\u606f\uff0c\u8fd8\u8981\u505a\u4e00\u4e2ainstance vector\u7684\u4f30\u8ba1(\u7c7b\u4f3c\u4e8e\u53cc\u76ee\u7684\u7ed3\u679c) \u4f18\u5316\u8fd9\u4e2a\u51fd\u6570,\u5176\u4e2d ^cp_i \u4e3alidar\u70b9\u7684\u5750\u6807\uff0c ^c\\hat p_i \u4e3a\u6839\u636e\u4e2d\u5fc3\u70b9\u3001pose\u3001\u5f62\u72b6\u3001instsance vector\u4f30\u8ba1\u7684\u5750\u6807\u503c\uff0c\u7531\u4e8e\u53ea\u9700\u8981\u4f18\u5316\u6df1\u5ea6\u503c\uff0c\u6240\u4ee5\u53ef\u4ee5\u7ebf\u6027\u6c42\u89e3 \\mathbf{E}_{p} :=\\sum_{i=0}^{m}\\left\\|^{c} \\mathbf{p}_{i}-^{c} \\hat{\\mathbf{p}}_{i}\\right\\|, \\text { with } \\quad^{c} \\hat{\\mathbf{p}}_{i}=\\hat{\\mathbf{p}}_{o}+\\mathbf{R}(\\theta)^{o} \\mathbf{p}_{i}","title":"\u70b9\u4e91Refinement"},{"location":"3dDetection/Multi-Sensor 3D Object Box Refinement for Autonomous Driving/#_3","text":"\\begin{aligned} \\mathbf{p}_{o}=\\underset{\\mathbf{p}_{o}}{\\arg \\min } & \\sum_{i=0}^{n}\\left\\|I_{l}\\left(\\mathbf{u}_{i}\\right)-I_{r}\\left(\\pi\\left(^{c} \\hat{\\mathbf{p}}_{i}-\\mathbf{b}\\right)\\right)\\right\\|_{\\sum_{s}}+\\\\ & \\sum_{j=0}^{m}\\left\\|^{c} \\mathbf{p}_{j}-^{c} \\hat{\\mathbf{p}}_{j}\\right\\|_{\\Sigma_{p}} \\end{aligned} \u4e24\u9879\u5206\u522b\u5904\u7406\u76f8\u673a\u4ee5\u53ca\u70b9\u4e91\u6570\u636e\u3002","title":"\u66f4\u591a\u4f20\u611f\u5668\u7684\u878d\u5408"},{"location":"3dDetection/Multi-Sensor 3D Object Box Refinement for Autonomous Driving/#_4","text":"\u635f\u5931\u51fd\u6570\u5305\u62ecRPN, 2D\u68c0\u6d4b\uff0c\u89d2\u5ea6\uff0c\u4f4d\u7f6e\uff0c\u7ef4\u5ea6\u3002\u7528 multi-loss \u7ed3\u5408 \u4e3a\u4e86\u7ed9\u56fe\u7247\u7f51\u8def\u63d0\u4f9b\u4f4d\u7f6e\uff0c\u5728\u8f93\u51fa\u7aef\u52a0\u5165u,v\u5750\u6807(grid channels),\u7b2c\u4e00\u4e2aConv\u7684\u6743\u91cd\u88ab\u590d\u5236\u91cd\u7528\u7ed9\u8fd9\u65b0\u7684channel.","title":"\u5176\u4ed6\u8bad\u7ec3\u7ec6\u8282"},{"location":"3dDetection/Multi-View_3D_Detection_Network_for_autonomous_Driving/","text":"Multi-View 3D Detection Network for autonomous Driving \u8fd9\u7bc7\u8bba\u6587\u7ed3\u5408\u4e86\u591a\u89c6\u89d2\uff0c\u878d\u5408Lidar\u548ccamera\u8fdb\u884c\u4e09\u7ef4\u68c0\u6d4b\u3002 \u7f51\u7edc\u7ed3\u6784 \u6570\u636e\u51c6\u5907 \u6fc0\u5149\u96f7\u8fbe\u9e1f\u77b0\u56fe\uff1a \u9e1f\u77b0\u56fe\u5206\u4e3a\u9ad8\u5ea6\u56fe\u3001\u5f3a\u5ea6\u56fe\u4ee5\u53ca\u5bc6\u5ea6\u56fe\u3002\u90fd\u5148\u5c06\u9e1f\u77b0\u56fe\u5206\u62102D\u7f51\u683c \u9ad8\u5ea6\u56fe\uff1a\u5c06\u70b9\u4e91\u968f\u673a\u5206\u6210M\u4efd\uff0c\u6bcf\u4e00\u4efd\u4e2d\uff0c2D\u7f51\u683c\u4e2d\u7684\u6bcf\u4e00\u4e2a\u7f51\u683c\u53d6\u8be5\u5904\u7684\u6700\u9ad8\u70b9\u7684\u9ad8\u5ea6\uff0c\u6700\u7ec8\u5f97\u5230M-channel\u7684\u9ad8\u5ea6\u56fe \u5f3a\u5ea6\u56fe\uff1a\u4e0d\u5206\u62c6\uff0c\u6bcf\u4e00\u7f51\u683c\u53d6\u8be5\u5904\u6700\u9ad8\u70b9\u7684\u53cd\u5c04\u5f3a\u5ea6 \u5bc6\u5ea6\u56fe\uff1a\u4e0d\u5206\u62c6\uff0c\u6bcf\u4e00\u4e2a\u7f51\u683c\u53d6\u8be5\u5904\u70b9\u7684\u5bc6\u5ea6\uff0c\u7528\u4e00\u4e2alog\u51fd\u6570\u89c4\u8303\u5316 \u6fc0\u5149\u96f7\u8fbe\u524d\u89c6\u56fe\uff1a \u524d\u89c6\u56fe\u4e0d\u5206\u62c6\uff0c\u5c06\u70b9\u4e91\u6295\u5f71\u5230\u5706\u67f1\u9762\u4e0a\uff0c\u7528\u6781\u5750\u6807 (r, c) \u8868\u793a\u6295\u5f71\u56fe\u7684 (x, y) \uff0c\u5e76\u540c\u6837\u7ed9\u51fa\u9ad8\u5ea6\u56fe\uff0c\u5f3a\u5ea6\u56fe\uff0c\u5bc6\u5ea6\u56fe RGB\u56fe\u7247\uff1a\u6b63\u5e38\u4f7f\u7528 \u6570\u636e\u878d\u5408\u64cd\u4f5c \u56fe\u4e2d\u9009\u62e9\u7684M\u4e3aelemental\u2014\u2014mean\u64cd\u4f5c \u5b9e\u9a8c\u4e2d\u91cd\u70b9\u8fd8\u662f\u8981\u641e\u597dablation study","title":"Multi-View 3D Detection Network for autonomous Driving"},{"location":"3dDetection/Multi-View_3D_Detection_Network_for_autonomous_Driving/#multi-view-3d-detection-network-for-autonomous-driving","text":"\u8fd9\u7bc7\u8bba\u6587\u7ed3\u5408\u4e86\u591a\u89c6\u89d2\uff0c\u878d\u5408Lidar\u548ccamera\u8fdb\u884c\u4e09\u7ef4\u68c0\u6d4b\u3002","title":"Multi-View 3D Detection Network for autonomous Driving"},{"location":"3dDetection/Multi-View_3D_Detection_Network_for_autonomous_Driving/#_1","text":"","title":"\u7f51\u7edc\u7ed3\u6784"},{"location":"3dDetection/Multi-View_3D_Detection_Network_for_autonomous_Driving/#_2","text":"\u6fc0\u5149\u96f7\u8fbe\u9e1f\u77b0\u56fe\uff1a \u9e1f\u77b0\u56fe\u5206\u4e3a\u9ad8\u5ea6\u56fe\u3001\u5f3a\u5ea6\u56fe\u4ee5\u53ca\u5bc6\u5ea6\u56fe\u3002\u90fd\u5148\u5c06\u9e1f\u77b0\u56fe\u5206\u62102D\u7f51\u683c \u9ad8\u5ea6\u56fe\uff1a\u5c06\u70b9\u4e91\u968f\u673a\u5206\u6210M\u4efd\uff0c\u6bcf\u4e00\u4efd\u4e2d\uff0c2D\u7f51\u683c\u4e2d\u7684\u6bcf\u4e00\u4e2a\u7f51\u683c\u53d6\u8be5\u5904\u7684\u6700\u9ad8\u70b9\u7684\u9ad8\u5ea6\uff0c\u6700\u7ec8\u5f97\u5230M-channel\u7684\u9ad8\u5ea6\u56fe \u5f3a\u5ea6\u56fe\uff1a\u4e0d\u5206\u62c6\uff0c\u6bcf\u4e00\u7f51\u683c\u53d6\u8be5\u5904\u6700\u9ad8\u70b9\u7684\u53cd\u5c04\u5f3a\u5ea6 \u5bc6\u5ea6\u56fe\uff1a\u4e0d\u5206\u62c6\uff0c\u6bcf\u4e00\u4e2a\u7f51\u683c\u53d6\u8be5\u5904\u70b9\u7684\u5bc6\u5ea6\uff0c\u7528\u4e00\u4e2alog\u51fd\u6570\u89c4\u8303\u5316 \u6fc0\u5149\u96f7\u8fbe\u524d\u89c6\u56fe\uff1a \u524d\u89c6\u56fe\u4e0d\u5206\u62c6\uff0c\u5c06\u70b9\u4e91\u6295\u5f71\u5230\u5706\u67f1\u9762\u4e0a\uff0c\u7528\u6781\u5750\u6807 (r, c) \u8868\u793a\u6295\u5f71\u56fe\u7684 (x, y) \uff0c\u5e76\u540c\u6837\u7ed9\u51fa\u9ad8\u5ea6\u56fe\uff0c\u5f3a\u5ea6\u56fe\uff0c\u5bc6\u5ea6\u56fe RGB\u56fe\u7247\uff1a\u6b63\u5e38\u4f7f\u7528","title":"\u6570\u636e\u51c6\u5907"},{"location":"3dDetection/Multi-View_3D_Detection_Network_for_autonomous_Driving/#_3","text":"\u56fe\u4e2d\u9009\u62e9\u7684M\u4e3aelemental\u2014\u2014mean\u64cd\u4f5c \u5b9e\u9a8c\u4e2d\u91cd\u70b9\u8fd8\u662f\u8981\u641e\u597dablation study","title":"\u6570\u636e\u878d\u5408\u64cd\u4f5c"},{"location":"3dDetection/Orthographic_Feature_Transform_3D_detection/","text":"Orthographic Feature Transform for Monocular 3D Object Detection \u8fd9\u7bc7\u8bba\u6587\u8ba4\u4e3a\u5bf9\u5355\u4e2a\u6444\u50cf\u5934\u5f97\u5230\u7684\u6444\u50cf\u5934\u8fdb\u884c3D detection\u7684\u65f6\u5019\uff0c\u8fd8\u662f\u9700\u8981\u8003\u8651\u6574\u4e2a\u573a\u666f\u7684\u4e09\u7ef4\u7ed3\u6784\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u5728\u56fe\u50cf\u5750\u6807\u7cfb\u8fdb\u884c\u7814\u7a76\u3002 \u5728\u65e0\u4eba\u8f66\u7684\u4f20\u7edf\u89c6\u89c9\u7b97\u6cd5\u4e2d\uff0c\u5728\u5355\u76ee\u89c6\u89c9\u6761\u4ef6\u4e0b\uff0c\u5982\u679c\u8981\u6d4b\u5f97\u8ddd\u79bb\uff0c\u9700\u8981\u77e5\u9053\u6444\u50cf\u5934\u7684 pitch\u89d2\u5ea6\u4ee5\u53ca\u6240\u63cf\u8ff0\u7684\u70b9\u5230\u6444\u50cf\u5934\u7684Z\u8f74\u8ddd\u79bb ( \u7ecf\u5e38\u662f\u6444\u50cf\u5934\u76f8\u5bf9\u5730\u9762\u7684\u9ad8\u5ea6 ) \u3002\u56e0\u6b64\u8fd9\u4e2a\u76f4\u89c9\u5c31\u662f 3 d detection\u9700\u8981\u6444\u50cf\u5934\u7684\u5916\u53c2 \u4e3b\u8981\u7b97\u6cd5\u8d21\u732e \u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u5982\u4e0a\u56fe\u3002\u4ee5\u4e0b\u4e3a\u5177\u4f53\u4ecb\u7ecd\uff1a 1. \u524d\u7279\u5f81\u63d0\u53d6 \u8fd9\u4e2a\u7ed3\u6784\u91c7\u7528\u7684\u662fResNet18 \u4f5c\u4e3a\u524d\u7aef\u7684\u7279\u5f81\u63d0\u53d6\uff0c\u540c\u65f6\u5c06\u4e0d\u540cscale\u7684feature maps\u540c\u65f6\u4f20\u7ed9\u4e0b\u4e00\u6b65\u7684\u6b63\u4ea4\u53d8\u6362\u3002\u8fd9\u4e2a\u8f83\u4e3a\u5e38\u89c4\u3002 2. \u6b63\u4ea4\u53d8\u6362 \u8fd9\u4e2a\u662f\u672c\u6587\u7684\u7b2c\u4e00\u4e2a\u4e3b\u8981\u8d21\u732e\uff0c\u7528\u5982\u56fe\u7684\u65b9\u5f0f\u5c06\u56fe\u50cf\u5750\u6807\u7cfb\u7684feature map\u8f6c\u6362\u4e3abird eye view\u89c6\u89d2\u7684feature map \u8ba1\u7b97\u8fc7\u7a0b\uff1a 1. \u9884\u5b9a\u4e49\u4e09\u7ef4\u7684\u65b9\u5757\u7a7a\u95f4\uff0c\u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u5927\u5c0f\u4e3ar\u7684\u683c\u5b50\uff0c\u6839\u636e\u5176\u4e2d\u5fc3\u70b9\u7684\u5750\u6807\u9006\u6295\u5f71\u5230\u56fe\u50cf\u7a7a\u95f4\u4e2d\uff0c\u6295\u5f71\u7ed3\u679c\u518d\u8fd1\u4f3c\u4e3a\u4e00\u4e2a\u77e9\u5f62\uff0c\u56fe\u7247\u5750\u6807\u7684\u5de6\u4e0a\u89d2\u4e0e\u53f3\u4e0a\u89d2\u5750\u6807\u7531\u4ee5\u4e0b\u516c\u5f0f\u51b3\u5b9a 2. \u5bf9\u4e8e\u70b9 (x, y, z) \u5bf9\u5e94\u7684\u7ed3\u679c g(x, y, z) \u4e3a\u9006\u6295\u5f71\u4e0a\u7684\u77e9\u5f62\u6846\u5185\u7684\u6240\u6709feature map\u7684\u6570\u503c\u5747\u503c\u3002 3. \u5bf9\u4e8e\u4fef\u77b0\u56fe(\u6ca1\u6709Z)\u4e0a\u6bcf\u4e00\u4e2a\u70b9\u7684\u8f93\u51fa\u7ed3\u679c\u4e3a\u5bf9\u5e94 (x, y) \u7ad6\u76f4\u65b9\u5411\u4e0a\u6240\u6709 g(x, y, z) \u7684\u52a0\u6743\u6c42\u548c\uff0c\u5176\u6743\u91cd\u4e3a\u53ef\u5b66\u4e60\u7684\u53c2\u6570\u3002 3. Topdown network \u7528\u4e00\u822c\u7684\u4e8c\u7ef4\u5377\u79ef\u4ee5\u53caResNet\u98ce\u683c\u7684skip-connection\u8fdb\u884c\u5904\u7406\uff0c\u5f97\u5230\u8f93\u51fa 4. output \u7f6e\u4fe1\u5ea6map(\u6982\u7387\u56fe)\uff0c\u8bad\u7ec3\u65f6\u5176\u771f\u503c\u7531\u771f\u5b9eobject\u4e3a\u4e2d\u5fc3\u7684\u9ad8\u65af\u51fd\u6570\u5f97\u5230( \\sigma \u672a\u7ed9\u51fa\uff0c\u591a\u4e2a\u969c\u788d\u7269\u7684\u8bdd\u53d6\u5404\u4e2a\u9ad8\u65af\u51fd\u6570\u7684\u6700\u5927\u503c) position offset \u548cdimension offset\uff0c\u672c\u6765\u6bcf\u4e00\u4e2a\u65b9\u5757\u7684\u7f6e\u4fe1\u5ea6map\u5df2\u7ecf\u9884\u6d4b\u4e86\u5728resolution\u4e3ar\u7684\u5730\u56fe\u4e2d\u6bcf\u4e00\u4e2a\u70b9\u662f\u969c\u788d\u7684\u6982\u7387\uff0c\u8fd9\u91cc\u518d\u8865\u5145\u4e86\u76f8\u5bf9\u4e8e\u65b9\u5757\u4e2d\u5fc3\u7684\u504f\u79fb\u9884\u6d4b\u3002 \u89d2\u5ea6vector map \u6709\u7528\u7684\u5b9e\u8df5\u7ec6\u8282 Integral Feature Map \u5728\u8fdb\u884c\u6b63\u4ea4\u53d8\u6362\u7684\u65f6\u5019\uff0c\u7531\u4e8e\u9700\u8981\u591a\u6b21\u6c42\u56fe\u50cf\u4e2d\u4e00\u4e2a\u4e2a\u77e9\u5f62\u6846\u5185\u6570\u503c\u7684\u548c\uff0c\u8fd9\u91cc\u4f7f\u7528\u52a8\u6001\u89c4\u5212\u7684\u7b97\u6cd5\uff0c\u5148\u6c42\u51faintegral feature map\uff0c F \u3002\u5176\u4e2d F(u,v) \u4e3a (u,v) \u70b9\u5de6\u4e0a\u89d2\u6574\u4e2a\u77e9\u5f62\u7684\u6570\u503c\u6c42\u548c\u3002\u4e4b\u540e\u6bcf\u4e00\u6b21\u6c42 g(x, y, z) \u65f6\u9700\u8981\u505a\u6c42\u548c\u7684\u65f6\u5019\uff0c\u53ea\u9700\u8981\u505a\u4e00\u4e2a\u5229\u7528 F \u505a\u4e00\u4e2aO(1)\u7684\u8fd0\u7b97\u5373\u53ef\u3002 Skew Loss Function \u5728\u505aobject detection\u65f6\u7531\u4e8e\u6b63\u8d1f\u6837\u672c\u7684\u95ee\u9898\uff0c\u4e00\u822c\u90fd\u9700\u8981\u5bf9\u8d1f\u6837\u672c\u7ed9\u4e88\u6bd4\u8f83\u5c11\u7684\u60e9\u7f5a\uff0c\u6587\u4e2d\u5728\u8bad\u7ec3confidence map prediction\u65f6\uff0c\u5bf9\u8bad\u7ec3\u76ee\u6807 S<0.05 \u7684\u4f4d\u7f6e\uff0c\u7ed9\u4e88\u4e00\u4e2a0.01\u7684\u56e0\u5b50\u3002 Normalizing Dimension and Angle Prediction \u5bf9\u4e8e\u4e00\u4e2a\u7279\u5b9a\u7684class\uff0c\u5df2\u77e5\u5b83\u7684\u5e73\u5747\u957f\u5bbd\u9ad8\uff0c\u5219\u9700\u8981\u9884\u6d4b\u7684\u957f\u5bbd\u9ad8\u53d8\u5316\u4e3a \\Delta_{dim}(x, z) = [log \\frac{w_i}{w},log \\frac{h_i}{h} ,log \\frac{l_i}{l}] \u89d2\u5ea6\u8f93\u51fa\u7528 sin\uff0ccos \u3002 \\Delta_{ang}(x,z) = [sin\\theta_i, cos\\theta_i] \u53e6\u5916\u672c\u6587\u7684regression\u90fd\u662f\u7528 l_1 loss. NMS(non max suppression) \u5148\u5c06\u7f6e\u4fe1\u5ea6map\u505a\u4e00\u4e2a\u9ad8\u65af\u5e73\u6ed1\uff0c\u7136\u540e\u627e\u5176\u4e2d\u5c40\u90e8\u6700\u5927\u503c\u70b9\u4f5c\u4e3a\u8f93\u51fa","title":"Orthographic Feature Transform for Monocular 3D Object Detection"},{"location":"3dDetection/Orthographic_Feature_Transform_3D_detection/#orthographic-feature-transform-for-monocular-3d-object-detection","text":"\u8fd9\u7bc7\u8bba\u6587\u8ba4\u4e3a\u5bf9\u5355\u4e2a\u6444\u50cf\u5934\u5f97\u5230\u7684\u6444\u50cf\u5934\u8fdb\u884c3D detection\u7684\u65f6\u5019\uff0c\u8fd8\u662f\u9700\u8981\u8003\u8651\u6574\u4e2a\u573a\u666f\u7684\u4e09\u7ef4\u7ed3\u6784\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u5728\u56fe\u50cf\u5750\u6807\u7cfb\u8fdb\u884c\u7814\u7a76\u3002 \u5728\u65e0\u4eba\u8f66\u7684\u4f20\u7edf\u89c6\u89c9\u7b97\u6cd5\u4e2d\uff0c\u5728\u5355\u76ee\u89c6\u89c9\u6761\u4ef6\u4e0b\uff0c\u5982\u679c\u8981\u6d4b\u5f97\u8ddd\u79bb\uff0c\u9700\u8981\u77e5\u9053\u6444\u50cf\u5934\u7684 pitch\u89d2\u5ea6\u4ee5\u53ca\u6240\u63cf\u8ff0\u7684\u70b9\u5230\u6444\u50cf\u5934\u7684Z\u8f74\u8ddd\u79bb ( \u7ecf\u5e38\u662f\u6444\u50cf\u5934\u76f8\u5bf9\u5730\u9762\u7684\u9ad8\u5ea6 ) \u3002\u56e0\u6b64\u8fd9\u4e2a\u76f4\u89c9\u5c31\u662f 3 d detection\u9700\u8981\u6444\u50cf\u5934\u7684\u5916\u53c2","title":"Orthographic Feature Transform for Monocular 3D Object Detection"},{"location":"3dDetection/Orthographic_Feature_Transform_3D_detection/#_1","text":"\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u5982\u4e0a\u56fe\u3002\u4ee5\u4e0b\u4e3a\u5177\u4f53\u4ecb\u7ecd\uff1a","title":"\u4e3b\u8981\u7b97\u6cd5\u8d21\u732e"},{"location":"3dDetection/Orthographic_Feature_Transform_3D_detection/#1","text":"\u8fd9\u4e2a\u7ed3\u6784\u91c7\u7528\u7684\u662fResNet18 \u4f5c\u4e3a\u524d\u7aef\u7684\u7279\u5f81\u63d0\u53d6\uff0c\u540c\u65f6\u5c06\u4e0d\u540cscale\u7684feature maps\u540c\u65f6\u4f20\u7ed9\u4e0b\u4e00\u6b65\u7684\u6b63\u4ea4\u53d8\u6362\u3002\u8fd9\u4e2a\u8f83\u4e3a\u5e38\u89c4\u3002","title":"1. \u524d\u7279\u5f81\u63d0\u53d6"},{"location":"3dDetection/Orthographic_Feature_Transform_3D_detection/#2","text":"\u8fd9\u4e2a\u662f\u672c\u6587\u7684\u7b2c\u4e00\u4e2a\u4e3b\u8981\u8d21\u732e\uff0c\u7528\u5982\u56fe\u7684\u65b9\u5f0f\u5c06\u56fe\u50cf\u5750\u6807\u7cfb\u7684feature map\u8f6c\u6362\u4e3abird eye view\u89c6\u89d2\u7684feature map \u8ba1\u7b97\u8fc7\u7a0b\uff1a 1. \u9884\u5b9a\u4e49\u4e09\u7ef4\u7684\u65b9\u5757\u7a7a\u95f4\uff0c\u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u5927\u5c0f\u4e3ar\u7684\u683c\u5b50\uff0c\u6839\u636e\u5176\u4e2d\u5fc3\u70b9\u7684\u5750\u6807\u9006\u6295\u5f71\u5230\u56fe\u50cf\u7a7a\u95f4\u4e2d\uff0c\u6295\u5f71\u7ed3\u679c\u518d\u8fd1\u4f3c\u4e3a\u4e00\u4e2a\u77e9\u5f62\uff0c\u56fe\u7247\u5750\u6807\u7684\u5de6\u4e0a\u89d2\u4e0e\u53f3\u4e0a\u89d2\u5750\u6807\u7531\u4ee5\u4e0b\u516c\u5f0f\u51b3\u5b9a 2. \u5bf9\u4e8e\u70b9 (x, y, z) \u5bf9\u5e94\u7684\u7ed3\u679c g(x, y, z) \u4e3a\u9006\u6295\u5f71\u4e0a\u7684\u77e9\u5f62\u6846\u5185\u7684\u6240\u6709feature map\u7684\u6570\u503c\u5747\u503c\u3002 3. \u5bf9\u4e8e\u4fef\u77b0\u56fe(\u6ca1\u6709Z)\u4e0a\u6bcf\u4e00\u4e2a\u70b9\u7684\u8f93\u51fa\u7ed3\u679c\u4e3a\u5bf9\u5e94 (x, y) \u7ad6\u76f4\u65b9\u5411\u4e0a\u6240\u6709 g(x, y, z) \u7684\u52a0\u6743\u6c42\u548c\uff0c\u5176\u6743\u91cd\u4e3a\u53ef\u5b66\u4e60\u7684\u53c2\u6570\u3002","title":"2. \u6b63\u4ea4\u53d8\u6362"},{"location":"3dDetection/Orthographic_Feature_Transform_3D_detection/#3-topdown-network","text":"\u7528\u4e00\u822c\u7684\u4e8c\u7ef4\u5377\u79ef\u4ee5\u53caResNet\u98ce\u683c\u7684skip-connection\u8fdb\u884c\u5904\u7406\uff0c\u5f97\u5230\u8f93\u51fa","title":"3. Topdown network"},{"location":"3dDetection/Orthographic_Feature_Transform_3D_detection/#4-output","text":"\u7f6e\u4fe1\u5ea6map(\u6982\u7387\u56fe)\uff0c\u8bad\u7ec3\u65f6\u5176\u771f\u503c\u7531\u771f\u5b9eobject\u4e3a\u4e2d\u5fc3\u7684\u9ad8\u65af\u51fd\u6570\u5f97\u5230( \\sigma \u672a\u7ed9\u51fa\uff0c\u591a\u4e2a\u969c\u788d\u7269\u7684\u8bdd\u53d6\u5404\u4e2a\u9ad8\u65af\u51fd\u6570\u7684\u6700\u5927\u503c) position offset \u548cdimension offset\uff0c\u672c\u6765\u6bcf\u4e00\u4e2a\u65b9\u5757\u7684\u7f6e\u4fe1\u5ea6map\u5df2\u7ecf\u9884\u6d4b\u4e86\u5728resolution\u4e3ar\u7684\u5730\u56fe\u4e2d\u6bcf\u4e00\u4e2a\u70b9\u662f\u969c\u788d\u7684\u6982\u7387\uff0c\u8fd9\u91cc\u518d\u8865\u5145\u4e86\u76f8\u5bf9\u4e8e\u65b9\u5757\u4e2d\u5fc3\u7684\u504f\u79fb\u9884\u6d4b\u3002 \u89d2\u5ea6vector map","title":"4. output"},{"location":"3dDetection/Orthographic_Feature_Transform_3D_detection/#_2","text":"","title":"\u6709\u7528\u7684\u5b9e\u8df5\u7ec6\u8282"},{"location":"3dDetection/Orthographic_Feature_Transform_3D_detection/#integral-feature-map","text":"\u5728\u8fdb\u884c\u6b63\u4ea4\u53d8\u6362\u7684\u65f6\u5019\uff0c\u7531\u4e8e\u9700\u8981\u591a\u6b21\u6c42\u56fe\u50cf\u4e2d\u4e00\u4e2a\u4e2a\u77e9\u5f62\u6846\u5185\u6570\u503c\u7684\u548c\uff0c\u8fd9\u91cc\u4f7f\u7528\u52a8\u6001\u89c4\u5212\u7684\u7b97\u6cd5\uff0c\u5148\u6c42\u51faintegral feature map\uff0c F \u3002\u5176\u4e2d F(u,v) \u4e3a (u,v) \u70b9\u5de6\u4e0a\u89d2\u6574\u4e2a\u77e9\u5f62\u7684\u6570\u503c\u6c42\u548c\u3002\u4e4b\u540e\u6bcf\u4e00\u6b21\u6c42 g(x, y, z) \u65f6\u9700\u8981\u505a\u6c42\u548c\u7684\u65f6\u5019\uff0c\u53ea\u9700\u8981\u505a\u4e00\u4e2a\u5229\u7528 F \u505a\u4e00\u4e2aO(1)\u7684\u8fd0\u7b97\u5373\u53ef\u3002","title":"Integral Feature Map"},{"location":"3dDetection/Orthographic_Feature_Transform_3D_detection/#skew-loss-function","text":"\u5728\u505aobject detection\u65f6\u7531\u4e8e\u6b63\u8d1f\u6837\u672c\u7684\u95ee\u9898\uff0c\u4e00\u822c\u90fd\u9700\u8981\u5bf9\u8d1f\u6837\u672c\u7ed9\u4e88\u6bd4\u8f83\u5c11\u7684\u60e9\u7f5a\uff0c\u6587\u4e2d\u5728\u8bad\u7ec3confidence map prediction\u65f6\uff0c\u5bf9\u8bad\u7ec3\u76ee\u6807 S<0.05 \u7684\u4f4d\u7f6e\uff0c\u7ed9\u4e88\u4e00\u4e2a0.01\u7684\u56e0\u5b50\u3002","title":"Skew Loss Function"},{"location":"3dDetection/Orthographic_Feature_Transform_3D_detection/#normalizing-dimension-and-angle-prediction","text":"\u5bf9\u4e8e\u4e00\u4e2a\u7279\u5b9a\u7684class\uff0c\u5df2\u77e5\u5b83\u7684\u5e73\u5747\u957f\u5bbd\u9ad8\uff0c\u5219\u9700\u8981\u9884\u6d4b\u7684\u957f\u5bbd\u9ad8\u53d8\u5316\u4e3a \\Delta_{dim}(x, z) = [log \\frac{w_i}{w},log \\frac{h_i}{h} ,log \\frac{l_i}{l}] \u89d2\u5ea6\u8f93\u51fa\u7528 sin\uff0ccos \u3002 \\Delta_{ang}(x,z) = [sin\\theta_i, cos\\theta_i] \u53e6\u5916\u672c\u6587\u7684regression\u90fd\u662f\u7528 l_1 loss.","title":"Normalizing Dimension and Angle Prediction"},{"location":"3dDetection/Orthographic_Feature_Transform_3D_detection/#nmsnon-max-suppression","text":"\u5148\u5c06\u7f6e\u4fe1\u5ea6map\u505a\u4e00\u4e2a\u9ad8\u65af\u5e73\u6ed1\uff0c\u7136\u540e\u627e\u5176\u4e2d\u5c40\u90e8\u6700\u5927\u503c\u70b9\u4f5c\u4e3a\u8f93\u51fa","title":"NMS(non max suppression)"},{"location":"3dDetection/Pseudo-Lidar/","text":"Monocular 3D Object Detection with Pseudo-LiDAR Point Cloud \u8fd9\u7bc7\u8bba\u6587\u6709\u591a\u4e2a\u91cd\u8981\u8d21\u732e\uff0c\u4e00\u662f\u4f7f\u7528\u5355\u76ee\u9884\u6d4b\u6df1\u5ea6\u56fe\uff0c\u5f62\u6210\u5047Lidar\u6570\u636e\uff0c\u5e76\u5f97\u5230\u4eba\u5de5\u7535\u4e91\uff0c\u7136\u540e\u4f7f\u7528 Frustum Pointnet \u3002\u5bf9\u5f97\u5230\u4e00\u4e2a\u53ef\u9760\u7684\u521d\u59cb\u89e3\u3002 \u7b2c\u4e8c\u7531\u4e8e\u5047Lidar\u6709\u5f88\u591a\u566a\u70b9\uff0c\u566a\u97f3\u4f53\u73b0\u5728\u4e24\u4e2a\u65b9\u9762\uff0c\u4e00\u4e2a\u662f\u6709\u504f\u79fb\uff0c\u5f71\u54cd\u5bf9\u8ddd\u79bb\u7684\u4f30\u8ba1\uff0c\u4e00\u4e2a\u662f\u6709\u957f\u5c3e\u2014\u2014\u7269\u4f53\u8fb9\u7f18\u7684\u4e00\u4e9b\u70b9\u4e91\u4f1a\u62c9\u5f97\u5f88\u957f\uff0c\u539f\u56e0\u662f\u7269\u4f53\u8fb9\u7f18\u5904\u7684\u6df1\u5ea6\u4f30\u8ba1\u4e0d\u51c6\u786e\u3002 \u4e3a\u4e86\u7f13\u89e3\u7b2c\u4e00\u4e2a\u95ee\u9898\uff0c\u4f7f\u75282D-3D box\u7ea6\u675f\u8c03\u65743D box\u7684\u4f4d\u7f6e\uff0c\u8fd9\u91cc\u5f15\u5165\u4e86\u4e00\u4e2aloss\u51fd\u6570\u5728training\u8fc7\u7a0b\u4e2d\u5904\u7406\u8fd9\u4e2a\u95ee\u9898\uff0c\u5728inference\u7684\u65f6\u5019\u5c06\u95ee\u9898\u8f6c\u4e3a\u4f18\u5316\u518d\u63d0\u9ad8\u6027\u80fd\u3002 \u4e3a\u4e86\u7f13\u89e3\u7b2c\u4e8c\u4e2a\u95ee\u9898\uff0c\u4f7f\u7528instance mask\u6765\u4ee3\u88682D proposal\u800c\u4e0d\u662fbounding box\u3002\u76f8\u5f53\u4e8e\u7528segmentation\u7684\u50cf\u7d20\u70b9\u7ea7\u7684\u7ed3\u679c\u8f93\u51fa 2D 3D\u7ea6\u675f \u5c063D\u6846\u8f6c\u6362\u4e3a8\u4e2a\u5750\u6807\u70b9\uff0c\u7136\u540e\u8f6c\u6362\u4e3a\u56fe\u7247\u5750\u6807\uff0c\u6c42\u51fa\u6700\u5c0fbounding rectangle\u5bf9\u5e94\u7684\u56db\u4e2a\u5750\u6807\u3002BBCL\u5c31\u662f\u8fd9\u56db\u4e2a\u5750\u6807\u4e0e2Dbounding box\u7684L1\u8ddd\u79bb\u3002BBCO\u5219\u662f\u5728inference\u7684\u65f6\u5019\u4f7f\u7528global search\u7684\u65b9\u5f0f(\u591a\u534a\u662f\u6a21\u62df\u9000\u706b)\u6709\u8d27\u5bf9\u5e94\u7684L1\u8ddd\u79bb\u3002 \u8fd9\u662f\u4e00\u5e74\u524d\u7684SOTA","title":"Monocular 3D Object Detection with Pseudo-LiDAR Point Cloud"},{"location":"3dDetection/Pseudo-Lidar/#monocular-3d-object-detection-with-pseudo-lidar-point-cloud","text":"\u8fd9\u7bc7\u8bba\u6587\u6709\u591a\u4e2a\u91cd\u8981\u8d21\u732e\uff0c\u4e00\u662f\u4f7f\u7528\u5355\u76ee\u9884\u6d4b\u6df1\u5ea6\u56fe\uff0c\u5f62\u6210\u5047Lidar\u6570\u636e\uff0c\u5e76\u5f97\u5230\u4eba\u5de5\u7535\u4e91\uff0c\u7136\u540e\u4f7f\u7528 Frustum Pointnet \u3002\u5bf9\u5f97\u5230\u4e00\u4e2a\u53ef\u9760\u7684\u521d\u59cb\u89e3\u3002 \u7b2c\u4e8c\u7531\u4e8e\u5047Lidar\u6709\u5f88\u591a\u566a\u70b9\uff0c\u566a\u97f3\u4f53\u73b0\u5728\u4e24\u4e2a\u65b9\u9762\uff0c\u4e00\u4e2a\u662f\u6709\u504f\u79fb\uff0c\u5f71\u54cd\u5bf9\u8ddd\u79bb\u7684\u4f30\u8ba1\uff0c\u4e00\u4e2a\u662f\u6709\u957f\u5c3e\u2014\u2014\u7269\u4f53\u8fb9\u7f18\u7684\u4e00\u4e9b\u70b9\u4e91\u4f1a\u62c9\u5f97\u5f88\u957f\uff0c\u539f\u56e0\u662f\u7269\u4f53\u8fb9\u7f18\u5904\u7684\u6df1\u5ea6\u4f30\u8ba1\u4e0d\u51c6\u786e\u3002 \u4e3a\u4e86\u7f13\u89e3\u7b2c\u4e00\u4e2a\u95ee\u9898\uff0c\u4f7f\u75282D-3D box\u7ea6\u675f\u8c03\u65743D box\u7684\u4f4d\u7f6e\uff0c\u8fd9\u91cc\u5f15\u5165\u4e86\u4e00\u4e2aloss\u51fd\u6570\u5728training\u8fc7\u7a0b\u4e2d\u5904\u7406\u8fd9\u4e2a\u95ee\u9898\uff0c\u5728inference\u7684\u65f6\u5019\u5c06\u95ee\u9898\u8f6c\u4e3a\u4f18\u5316\u518d\u63d0\u9ad8\u6027\u80fd\u3002 \u4e3a\u4e86\u7f13\u89e3\u7b2c\u4e8c\u4e2a\u95ee\u9898\uff0c\u4f7f\u7528instance mask\u6765\u4ee3\u88682D proposal\u800c\u4e0d\u662fbounding box\u3002\u76f8\u5f53\u4e8e\u7528segmentation\u7684\u50cf\u7d20\u70b9\u7ea7\u7684\u7ed3\u679c\u8f93\u51fa","title":"Monocular 3D Object Detection with Pseudo-LiDAR Point Cloud"},{"location":"3dDetection/Pseudo-Lidar/#2d-3d","text":"\u5c063D\u6846\u8f6c\u6362\u4e3a8\u4e2a\u5750\u6807\u70b9\uff0c\u7136\u540e\u8f6c\u6362\u4e3a\u56fe\u7247\u5750\u6807\uff0c\u6c42\u51fa\u6700\u5c0fbounding rectangle\u5bf9\u5e94\u7684\u56db\u4e2a\u5750\u6807\u3002BBCL\u5c31\u662f\u8fd9\u56db\u4e2a\u5750\u6807\u4e0e2Dbounding box\u7684L1\u8ddd\u79bb\u3002BBCO\u5219\u662f\u5728inference\u7684\u65f6\u5019\u4f7f\u7528global search\u7684\u65b9\u5f0f(\u591a\u534a\u662f\u6a21\u62df\u9000\u706b)\u6709\u8d27\u5bf9\u5e94\u7684L1\u8ddd\u79bb\u3002 \u8fd9\u662f\u4e00\u5e74\u524d\u7684SOTA","title":"2D 3D\u7ea6\u675f"},{"location":"3dDetection/SHIFT R-CNN: DEEP MONOCULAR 3D OBJECT DETECTION WITH CLOSED-FORM GEOMETRIC CONSTRAINTS/","text":"SHIFT R-CNN: DEEP MONOCULAR 3D OBJECT DETECTION WITH CLOSED-FORM GEOMETRIC CONSTRAINTS \u8fd9\u7bc7\u8bba\u6587\u7684\u5728\u7406\u8bba\u4e0a\u4e3b\u8981\u662f\u4e09\u5927\u8d21\u732e\uff0c\u7b2c\u4e00\u662f\u4e09\u6b65\u8d70\u7684\u57fa\u4e8eFaster-RCNN\u7684 Shift R-CNN\uff0c\u7b2c\u4e8c\u662fVolume Displacement Loss (VDL)\u7528\u4e8e\u8bad\u7ec3\u7f51\u7edc\u3002 \u5de5\u4f5c\u6d41\u7a0b 2D \u68c0\u6d4b\u4e0e3D\u7ed3\u6784\u53c2\u6570\u4f30\u8ba1 \u4f7f\u7528Faster-RCNN\u7684RPN\u8f93\u51faProposal\u4ee5\u53ca2D\u6846\u9884\u6d4b\uff0c\u540e\u7eed\u5168\u8fde\u63a5\u5c42\u8f93\u51fa\u5206\u7c7b\u3001\u7269\u4f53\u5927\u5c0f\u4ee5\u53ca\u7269\u4f53\u65b9\u5411\u3002 \u7269\u4f53\u65b9\u5411\u56de\u5f52\u540c\u6837\u5f97\u9009\u62e9\u56de\u5f52 sin , cos \u503c\uff0c\u540c\u65f6\u591a\u4e00\u4e2a L_1 cost\u8981\u6c42 sin^2 + cos^2 = 1 \uff0c\u8fd9\u91cc\u53ea\u8981\u6c42\u8f93\u51fa\u89c2\u6d4b\u89d2\\alpht_L \u4e5f\u5c31\u662f \\alpha_G - \\theta_{ray}$ \u7269\u4f53\u5927\u5c0f\u56de\u5f52\u540c\u6837\u9009\u62e9\u56de\u5f52 log \u503c\uff0c \u6700\u7ec8\u52a0\u6743\u8f93\u51fa\u603b\u548c \u95ed\u73af\u7ea6\u675f\u6c42\u51fa\u76f8\u5bf9\u4f4d\u7f6e \u8fd9\u4e2a\u95ee\u9898\u6700\u7ec8\u80fd\u8f6c\u6362\u4e3a\u4e00\u4e2a\u6700\u5c0f\u4e8c\u4e58\u7684\u95ee\u9898 ShiftNet\u8fdb\u4e00\u6b65\u4f18\u5316 \u628a\u4e0a\u4e00\u90e8\u5206\u4ee5\u53ca\u7b2c\u4e00\u90e8\u5206\u7684\u4fe1\u606f\uff0c\u5305\u62ec t, \\bold b_{2D}\uff0c \\bold d, (sin(\\alpha_L), cos(\\alpha_L)), (sin(\\alpha_G), cos(\\alpha_G)) ,\u8f93\u5165\u5230\u4e24\u5c42\u5168\u8fde\u63a5\u5c42\u4e2d\u7136\u540e\u8f93\u51fa\u6700\u7ec8\u76ee\u6807\u3002 Volume Displacement Loss \u76ee\u7684\u662f\u6b63\u786e\u5730\u63d0\u53473D IOU,\u4f46\u662f3D IOU\u76f4\u63a5\u641e\u5e76\u4e0d\u53ef\u5bfc\u3002\u8fd9\u91cc\u7ed9\u51fa\u65b0\u7684\u601d\u8def, \\Delta t \u4e3a\u4e16\u754c\u5750\u6807\u4e2d\u7684 x, y, z \u5dee\u503c \\Delta t_{\\alpha G} = R_y(\\alpha G) \\Delta t L = w \\times h \\times |\\Delta x_{\\alpha G}| + w \\times l \\times |\\Delta y_{\\alpha G}| + h \\times l \\times |\\Delta z_{\\alpha G}|","title":"SHIFT R-CNN: DEEP MONOCULAR 3D OBJECT DETECTION WITH CLOSED-FORM GEOMETRIC CONSTRAINTS"},{"location":"3dDetection/SHIFT R-CNN: DEEP MONOCULAR 3D OBJECT DETECTION WITH CLOSED-FORM GEOMETRIC CONSTRAINTS/#shift-r-cnn-deep-monocular-3d-object-detection-with-closed-form-geometric-constraints","text":"\u8fd9\u7bc7\u8bba\u6587\u7684\u5728\u7406\u8bba\u4e0a\u4e3b\u8981\u662f\u4e09\u5927\u8d21\u732e\uff0c\u7b2c\u4e00\u662f\u4e09\u6b65\u8d70\u7684\u57fa\u4e8eFaster-RCNN\u7684 Shift R-CNN\uff0c\u7b2c\u4e8c\u662fVolume Displacement Loss (VDL)\u7528\u4e8e\u8bad\u7ec3\u7f51\u7edc\u3002","title":"SHIFT R-CNN: DEEP MONOCULAR 3D OBJECT DETECTION WITH CLOSED-FORM GEOMETRIC CONSTRAINTS"},{"location":"3dDetection/SHIFT R-CNN: DEEP MONOCULAR 3D OBJECT DETECTION WITH CLOSED-FORM GEOMETRIC CONSTRAINTS/#_1","text":"","title":"\u5de5\u4f5c\u6d41\u7a0b"},{"location":"3dDetection/SHIFT R-CNN: DEEP MONOCULAR 3D OBJECT DETECTION WITH CLOSED-FORM GEOMETRIC CONSTRAINTS/#2d-3d","text":"\u4f7f\u7528Faster-RCNN\u7684RPN\u8f93\u51faProposal\u4ee5\u53ca2D\u6846\u9884\u6d4b\uff0c\u540e\u7eed\u5168\u8fde\u63a5\u5c42\u8f93\u51fa\u5206\u7c7b\u3001\u7269\u4f53\u5927\u5c0f\u4ee5\u53ca\u7269\u4f53\u65b9\u5411\u3002 \u7269\u4f53\u65b9\u5411\u56de\u5f52\u540c\u6837\u5f97\u9009\u62e9\u56de\u5f52 sin , cos \u503c\uff0c\u540c\u65f6\u591a\u4e00\u4e2a L_1 cost\u8981\u6c42 sin^2 + cos^2 = 1 \uff0c\u8fd9\u91cc\u53ea\u8981\u6c42\u8f93\u51fa\u89c2\u6d4b\u89d2\\alpht_L \u4e5f\u5c31\u662f \\alpha_G - \\theta_{ray}$ \u7269\u4f53\u5927\u5c0f\u56de\u5f52\u540c\u6837\u9009\u62e9\u56de\u5f52 log \u503c\uff0c \u6700\u7ec8\u52a0\u6743\u8f93\u51fa\u603b\u548c","title":"2D \u68c0\u6d4b\u4e0e3D\u7ed3\u6784\u53c2\u6570\u4f30\u8ba1"},{"location":"3dDetection/SHIFT R-CNN: DEEP MONOCULAR 3D OBJECT DETECTION WITH CLOSED-FORM GEOMETRIC CONSTRAINTS/#_2","text":"\u8fd9\u4e2a\u95ee\u9898\u6700\u7ec8\u80fd\u8f6c\u6362\u4e3a\u4e00\u4e2a\u6700\u5c0f\u4e8c\u4e58\u7684\u95ee\u9898","title":"\u95ed\u73af\u7ea6\u675f\u6c42\u51fa\u76f8\u5bf9\u4f4d\u7f6e"},{"location":"3dDetection/SHIFT R-CNN: DEEP MONOCULAR 3D OBJECT DETECTION WITH CLOSED-FORM GEOMETRIC CONSTRAINTS/#shiftnet","text":"\u628a\u4e0a\u4e00\u90e8\u5206\u4ee5\u53ca\u7b2c\u4e00\u90e8\u5206\u7684\u4fe1\u606f\uff0c\u5305\u62ec t, \\bold b_{2D}\uff0c \\bold d, (sin(\\alpha_L), cos(\\alpha_L)), (sin(\\alpha_G), cos(\\alpha_G)) ,\u8f93\u5165\u5230\u4e24\u5c42\u5168\u8fde\u63a5\u5c42\u4e2d\u7136\u540e\u8f93\u51fa\u6700\u7ec8\u76ee\u6807\u3002","title":"ShiftNet\u8fdb\u4e00\u6b65\u4f18\u5316"},{"location":"3dDetection/SHIFT R-CNN: DEEP MONOCULAR 3D OBJECT DETECTION WITH CLOSED-FORM GEOMETRIC CONSTRAINTS/#volume-displacement-loss","text":"\u76ee\u7684\u662f\u6b63\u786e\u5730\u63d0\u53473D IOU,\u4f46\u662f3D IOU\u76f4\u63a5\u641e\u5e76\u4e0d\u53ef\u5bfc\u3002\u8fd9\u91cc\u7ed9\u51fa\u65b0\u7684\u601d\u8def, \\Delta t \u4e3a\u4e16\u754c\u5750\u6807\u4e2d\u7684 x, y, z \u5dee\u503c \\Delta t_{\\alpha G} = R_y(\\alpha G) \\Delta t L = w \\times h \\times |\\Delta x_{\\alpha G}| + w \\times l \\times |\\Delta y_{\\alpha G}| + h \\times l \\times |\\Delta z_{\\alpha G}|","title":"Volume Displacement Loss"},{"location":"3dDetection/Triangulation Learning Network: from Monocular to Stereo 3D Object Detection/","text":"Triangulation Learning Network: from Monocular to Stereo 3D Object Detection \u8fd9\u7bc7\u8bba\u6587\u7684\u4e3b\u8981contribution\u662f\u4e09\u90e8\u5206\uff0c\u7b2c\u4e00\u90e8\u5206\u662f\u4e00\u4e2a\u53ef\u9760\u7684\u5355\u76ee3D detector baseline\uff1b\u7b2c\u4e8c\u90e8\u5206\u662fTriangulation Learning\uff1b\u7b2c\u4e09\u90e8\u5206\u662ffeature reweighting strategy\u3002 Baseline Monocular Network\u5355\u76eebaseline \u6b63\u9762\u89c6\u89d2 Anchor Generation \u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u4e0b\u91c7\u6837\uff0c\u5f97\u5230\u4e00\u4e2a G_x \\times G_y \u7684\u7f51\u683c,\u6bcf\u4e00\u4e2a\u7f51\u683c\u91cc\u9762\u7684\u503c\u4ee3\u8868\u8fd9\u4e2a\u7f51\u683c\u6709\u76ee\u6807\u7684\u6982\u7387\uff0c\u4ece\u8fd9\u4e9bpotential cells\u51fa\u53d1\u5c04\u51fa\u4e00\u4e2a\u5706\u53f0\uff0c\u5728\u53f0\u4f53\u4e2d\u5747\u5300\u53d6\u6837\u5f62\u62103D anchors proposals\u3002 3D \u76d2\u4f53proposal\u4ee5\u53carefinement \u4f7f\u7528 RoIAlign\uff0c\u4e5f\u5c31\u662f\u4f20\u7edf\u7684RCNN\u65b9\u5f0f\u505a Triangulation Learning Network TL-Net:Object level triangulation \u8f93\u5165\u662f\u4e00\u5bf9ROI\uff0c\u4e00\u81f4\u6027\u8bc4\u5206 Pairwise Coherence Score\u662f\u4e00\u4e2a 1 \\times 1 \\times C_{roi} \u7684\u6743\u91cd\u5f20\u91cf\uff0c\u7136\u540e\u5206\u522b\u6539\u53d8\u4e24\u4e2a\u56fe\u4e2d\u5404\u4e2a\u7279\u5f81\u901a\u9053\u7684\u6743\u91cd\uff0c\u7136\u540e\u76f8\u52a0\uff0c\u518d\u5168\u8fde\u63a5\u8f93\u51fa\u3002 \u8fd9\u4e2aCoherence Score\u662f\u4e24\u4e2a\u7279\u5f81feature map\u7684\u4f59\u5f26\u8ddd\u79bb\uff0c\u4f5c\u8005\u7684\u8bba\u70b9\u662f\u5982\u679c3D\u4f4d\u7f6e\u6b63\u786e\uff0c\u90a3\u4e48anchor box\u6295\u5f71\u5230\u5de6\u53f3\u76f8\u673a\u4e2d\u7684\u7279\u5f81\u4f1a\u76f8\u4f3c\uff0c\u4e5f\u90fd\u662f\u7269\u4f53\u7684feature\uff0c \u82e5\u504f\u4e86\u5219\u5dee\u8ddd\u4f1a\u5f88\u5927\uff0c\u968f\u673a\u3001\u5b8c\u5168\u65e0\u5173\u7684\u6761\u4ef6\u4e0breweight \u6743\u91cd\u4f1a\u4e3a0\uff0c\u6700\u7ec8\u8f93\u51fa\u7684confidence\u4e5f\u4f1a\u6709\u6240\u5f71\u54cd\u3002","title":"Triangulation Learning Network: from Monocular to Stereo 3D Object Detection"},{"location":"3dDetection/Triangulation Learning Network: from Monocular to Stereo 3D Object Detection/#triangulation-learning-network-from-monocular-to-stereo-3d-object-detection","text":"\u8fd9\u7bc7\u8bba\u6587\u7684\u4e3b\u8981contribution\u662f\u4e09\u90e8\u5206\uff0c\u7b2c\u4e00\u90e8\u5206\u662f\u4e00\u4e2a\u53ef\u9760\u7684\u5355\u76ee3D detector baseline\uff1b\u7b2c\u4e8c\u90e8\u5206\u662fTriangulation Learning\uff1b\u7b2c\u4e09\u90e8\u5206\u662ffeature reweighting strategy\u3002","title":"Triangulation Learning Network: from Monocular to Stereo 3D Object Detection"},{"location":"3dDetection/Triangulation Learning Network: from Monocular to Stereo 3D Object Detection/#baseline-monocular-networkbaseline","text":"","title":"Baseline Monocular Network\u5355\u76eebaseline"},{"location":"3dDetection/Triangulation Learning Network: from Monocular to Stereo 3D Object Detection/#anchor-generation","text":"\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u4e0b\u91c7\u6837\uff0c\u5f97\u5230\u4e00\u4e2a G_x \\times G_y \u7684\u7f51\u683c,\u6bcf\u4e00\u4e2a\u7f51\u683c\u91cc\u9762\u7684\u503c\u4ee3\u8868\u8fd9\u4e2a\u7f51\u683c\u6709\u76ee\u6807\u7684\u6982\u7387\uff0c\u4ece\u8fd9\u4e9bpotential cells\u51fa\u53d1\u5c04\u51fa\u4e00\u4e2a\u5706\u53f0\uff0c\u5728\u53f0\u4f53\u4e2d\u5747\u5300\u53d6\u6837\u5f62\u62103D anchors proposals\u3002","title":"\u6b63\u9762\u89c6\u89d2 Anchor Generation"},{"location":"3dDetection/Triangulation Learning Network: from Monocular to Stereo 3D Object Detection/#3d-proposalrefinement","text":"\u4f7f\u7528 RoIAlign\uff0c\u4e5f\u5c31\u662f\u4f20\u7edf\u7684RCNN\u65b9\u5f0f\u505a","title":"3D \u76d2\u4f53proposal\u4ee5\u53carefinement"},{"location":"3dDetection/Triangulation Learning Network: from Monocular to Stereo 3D Object Detection/#triangulation-learning-network","text":"","title":"Triangulation Learning Network"},{"location":"3dDetection/Triangulation Learning Network: from Monocular to Stereo 3D Object Detection/#tl-netobject-level-triangulation","text":"\u8f93\u5165\u662f\u4e00\u5bf9ROI\uff0c\u4e00\u81f4\u6027\u8bc4\u5206 Pairwise Coherence Score\u662f\u4e00\u4e2a 1 \\times 1 \\times C_{roi} \u7684\u6743\u91cd\u5f20\u91cf\uff0c\u7136\u540e\u5206\u522b\u6539\u53d8\u4e24\u4e2a\u56fe\u4e2d\u5404\u4e2a\u7279\u5f81\u901a\u9053\u7684\u6743\u91cd\uff0c\u7136\u540e\u76f8\u52a0\uff0c\u518d\u5168\u8fde\u63a5\u8f93\u51fa\u3002 \u8fd9\u4e2aCoherence Score\u662f\u4e24\u4e2a\u7279\u5f81feature map\u7684\u4f59\u5f26\u8ddd\u79bb\uff0c\u4f5c\u8005\u7684\u8bba\u70b9\u662f\u5982\u679c3D\u4f4d\u7f6e\u6b63\u786e\uff0c\u90a3\u4e48anchor box\u6295\u5f71\u5230\u5de6\u53f3\u76f8\u673a\u4e2d\u7684\u7279\u5f81\u4f1a\u76f8\u4f3c\uff0c\u4e5f\u90fd\u662f\u7269\u4f53\u7684feature\uff0c \u82e5\u504f\u4e86\u5219\u5dee\u8ddd\u4f1a\u5f88\u5927\uff0c\u968f\u673a\u3001\u5b8c\u5168\u65e0\u5173\u7684\u6761\u4ef6\u4e0breweight \u6743\u91cd\u4f1a\u4e3a0\uff0c\u6700\u7ec8\u8f93\u51fa\u7684confidence\u4e5f\u4f1a\u6709\u6240\u5f71\u54cd\u3002","title":"TL-Net:Object level triangulation"},{"location":"3dDetection/voxelNet/","text":"VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection \u70b9\u4e91\u6295\u5f71\u5230\u4e09\u7ef4\u7f51\u683c\uff0c\u6bcf\u4e00\u4e2a\u7f51\u683c\u5185\u901a\u8fc7\u968f\u673a\u53d6\u70b9\u52a0\u5168\u8fde\u63a5\u4f20\u64ad\uff0c\u5f97\u5230\u4e00\u4e2a\u5355\u4e00\u7684feature-vector\u3002\u5173\u952e\u662f\u5bf9\u4e8e\u8fd9\u6837\u4e00\u4e2a\u7a00\u758f\u76844D\u77e9\u9635\uff0c\u5728\u540e\u9762\u5982\u4f55\u5feb\u901f\u8fdb\u884c\u77e2\u91cf\u8fd0\u7b97\uff0c\u8fd9\u91cc\u4f7f\u7528\u7a00\u758f\u8868\u8fbe\uff0c\u7528hash table\u5efa\u7acb\u5feb\u901findex\u3002","title":"VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection"},{"location":"3dDetection/voxelNet/#voxelnet-end-to-end-learning-for-point-cloud-based-3d-object-detection","text":"\u70b9\u4e91\u6295\u5f71\u5230\u4e09\u7ef4\u7f51\u683c\uff0c\u6bcf\u4e00\u4e2a\u7f51\u683c\u5185\u901a\u8fc7\u968f\u673a\u53d6\u70b9\u52a0\u5168\u8fde\u63a5\u4f20\u64ad\uff0c\u5f97\u5230\u4e00\u4e2a\u5355\u4e00\u7684feature-vector\u3002\u5173\u952e\u662f\u5bf9\u4e8e\u8fd9\u6837\u4e00\u4e2a\u7a00\u758f\u76844D\u77e9\u9635\uff0c\u5728\u540e\u9762\u5982\u4f55\u5feb\u901f\u8fdb\u884c\u77e2\u91cf\u8fd0\u7b97\uff0c\u8fd9\u91cc\u4f7f\u7528\u7a00\u758f\u8868\u8fbe\uff0c\u7528hash table\u5efa\u7acb\u5feb\u901findex\u3002","title":"VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection"},{"location":"Building_Blocks/Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization/","text":"Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization \u8fd9\u7bc7\u6587\u7ae0\u63d0\u51fa\u4e86Style Transfer\u76f8\u5f53\u957f\u4e00\u6bb5\u65f6\u95f4\u7684SOTA\u6216\u8005baseline\uff0c\u4e5f\u5c31\u662fAdaIN\u6a21\u5757\u3002 \u80cc\u666f\u77e5\u8bc6 Normalization \u56de\u987e \u672c\u6587\u9664\u4e86\u57fa\u7840\u7684BatchNorm(\u5b8c\u6574batch)\u4ee5\u53caInstanceNorm(\u4e0d\u8003\u8651batch)\u8fd8\u56de\u987e\u4e86Conditional Instance Normalization(CIN). CIN\u5c42\u4e3a\u6bcf\u4e00\u4e2astyle\u5b66\u4e60\u4e00\u5957InstanceNorm\u7684\u53c2\u6570 \\gamma^s, \\beta^s \\operatorname{CIN}(x ; s)=\\gamma^{s}\\left(\\frac{x-\\mu(x)}{\\sigma(x)}\\right)+\\beta^{s} \u5b9e\u9a8c\u53ef\u77e5\u5bf9CIN\u7f51\u7edc\u800c\u8a00\uff0cBN\u7684\u7ed3\u679c\u603b\u4f53\u4e0d\u5982IN\u7684\u7ed3\u679c Adaptive Instance Normalization AdaIN\u516c\u5f0f: \\operatorname{AdaIN}(x, y)=\\sigma(y)\\left(\\frac{x-\\mu(x)}{\\sigma(x)}\\right)+\\mu(y) \u5176\u4e2d x \u4e3acontent input\u800c y \u4e3astyle input.\u672c\u8d28\u4e0a\u6765\u8bf4\u5c31\u662f\u5bf9content instance\u4f7f\u7528instance normalization \u8f6c\u6362\u4e3astyle instance\u7684\u5747\u503c\u4e0e\u65b9\u5dee. \u7f51\u7edc\u7ed3\u6784\u4e0e\u8bad\u7ec3\u65b9\u6cd5 \u7f51\u7edc\u7ed3\u6784\u5982\u56fe \u5c06\u4e24\u5f20\u56fe\u540c\u65f6\u8f93\u5165\u5230VGG encoder\u4e2d\uff0c\u6267\u884cAdaIN\uff0c\u5bf9content\u7ed3\u679cdecode\u5f97\u5230\u8f93\u51fa\u56fe Content Loss \u5229\u7528VGG encode style-transfered picture, \\mathcal{L_c} = ||f(g(t)) - t||_2 \u5176\u4e2d f \u4e3aencoder, g \u4e3adecoder\uff0c t \u4e3aAdaIN\u5904\u7684\u8f93\u51fa\uff0c\u4e5f\u5c31\u662f\u5bf9\u7279\u5f81\u5411\u91cf\u53d6L2\u8bef\u5dee Style Loss \u4ee5\u524d\u6709\u4f7f\u7528 \u683c\u62c9\u59c6\u77e9\u9635\u7684\u76f8\u5173\u6027\u8bef\u5dee\u7684 ,\u8fd9\u91cc\u8d85\u94fe\u63a5\u7ed9\u7684\u4f8b\u5b50\u6765\u81ea\u4e8ekeras\u7684\u4f8b\u5b50\u3002\u672c\u6587\u8fd9\u91cc\u4f7f\u7528\u53e6\u4e00\u4e2a \u522b\u4eba \u63d0\u51fa\u7684\u8bef\u5dee \\begin{array}{c}{\\mathcal{L}_{s}=\\sum_{i=1}^{L}\\left\\|\\mu\\left(\\phi_{i}(g(t))\\right)-\\mu\\left(\\phi_{i}(s)\\right)\\right\\|_{2}+} \\\\ {\\sum_{i=1}^{L}\\left\\|\\sigma\\left(\\phi_{i}(g(t))\\right)-\\sigma\\left(\\phi_{i}(s)\\right)\\right\\|_{2}}\\end{array} \u5176\u4e2d \\mu, \\sigma \u6307\u6c42\u5747\u503c\u4e0e\u65b9\u5dee, \\phi_i \u6307VGG-19\u4e2d\u7684\u67d0\u4e00\u5c42\u7684\u8f93\u51fa\u3002","title":"Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization"},{"location":"Building_Blocks/Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization/#arbitrary-style-transfer-in-real-time-with-adaptive-instance-normalization","text":"\u8fd9\u7bc7\u6587\u7ae0\u63d0\u51fa\u4e86Style Transfer\u76f8\u5f53\u957f\u4e00\u6bb5\u65f6\u95f4\u7684SOTA\u6216\u8005baseline\uff0c\u4e5f\u5c31\u662fAdaIN\u6a21\u5757\u3002","title":"Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization"},{"location":"Building_Blocks/Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization/#normalization","text":"\u672c\u6587\u9664\u4e86\u57fa\u7840\u7684BatchNorm(\u5b8c\u6574batch)\u4ee5\u53caInstanceNorm(\u4e0d\u8003\u8651batch)\u8fd8\u56de\u987e\u4e86Conditional Instance Normalization(CIN). CIN\u5c42\u4e3a\u6bcf\u4e00\u4e2astyle\u5b66\u4e60\u4e00\u5957InstanceNorm\u7684\u53c2\u6570 \\gamma^s, \\beta^s \\operatorname{CIN}(x ; s)=\\gamma^{s}\\left(\\frac{x-\\mu(x)}{\\sigma(x)}\\right)+\\beta^{s} \u5b9e\u9a8c\u53ef\u77e5\u5bf9CIN\u7f51\u7edc\u800c\u8a00\uff0cBN\u7684\u7ed3\u679c\u603b\u4f53\u4e0d\u5982IN\u7684\u7ed3\u679c","title":"\u80cc\u666f\u77e5\u8bc6 Normalization \u56de\u987e"},{"location":"Building_Blocks/Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization/#adaptive-instance-normalization","text":"AdaIN\u516c\u5f0f: \\operatorname{AdaIN}(x, y)=\\sigma(y)\\left(\\frac{x-\\mu(x)}{\\sigma(x)}\\right)+\\mu(y) \u5176\u4e2d x \u4e3acontent input\u800c y \u4e3astyle input.\u672c\u8d28\u4e0a\u6765\u8bf4\u5c31\u662f\u5bf9content instance\u4f7f\u7528instance normalization \u8f6c\u6362\u4e3astyle instance\u7684\u5747\u503c\u4e0e\u65b9\u5dee.","title":"Adaptive Instance Normalization"},{"location":"Building_Blocks/Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization/#_1","text":"\u7f51\u7edc\u7ed3\u6784\u5982\u56fe \u5c06\u4e24\u5f20\u56fe\u540c\u65f6\u8f93\u5165\u5230VGG encoder\u4e2d\uff0c\u6267\u884cAdaIN\uff0c\u5bf9content\u7ed3\u679cdecode\u5f97\u5230\u8f93\u51fa\u56fe","title":"\u7f51\u7edc\u7ed3\u6784\u4e0e\u8bad\u7ec3\u65b9\u6cd5"},{"location":"Building_Blocks/Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization/#content-loss","text":"\u5229\u7528VGG encode style-transfered picture, \\mathcal{L_c} = ||f(g(t)) - t||_2 \u5176\u4e2d f \u4e3aencoder, g \u4e3adecoder\uff0c t \u4e3aAdaIN\u5904\u7684\u8f93\u51fa\uff0c\u4e5f\u5c31\u662f\u5bf9\u7279\u5f81\u5411\u91cf\u53d6L2\u8bef\u5dee","title":"Content Loss"},{"location":"Building_Blocks/Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization/#style-loss","text":"\u4ee5\u524d\u6709\u4f7f\u7528 \u683c\u62c9\u59c6\u77e9\u9635\u7684\u76f8\u5173\u6027\u8bef\u5dee\u7684 ,\u8fd9\u91cc\u8d85\u94fe\u63a5\u7ed9\u7684\u4f8b\u5b50\u6765\u81ea\u4e8ekeras\u7684\u4f8b\u5b50\u3002\u672c\u6587\u8fd9\u91cc\u4f7f\u7528\u53e6\u4e00\u4e2a \u522b\u4eba \u63d0\u51fa\u7684\u8bef\u5dee \\begin{array}{c}{\\mathcal{L}_{s}=\\sum_{i=1}^{L}\\left\\|\\mu\\left(\\phi_{i}(g(t))\\right)-\\mu\\left(\\phi_{i}(s)\\right)\\right\\|_{2}+} \\\\ {\\sum_{i=1}^{L}\\left\\|\\sigma\\left(\\phi_{i}(g(t))\\right)-\\sigma\\left(\\phi_{i}(s)\\right)\\right\\|_{2}}\\end{array} \u5176\u4e2d \\mu, \\sigma \u6307\u6c42\u5747\u503c\u4e0e\u65b9\u5dee, \\phi_i \u6307VGG-19\u4e2d\u7684\u67d0\u4e00\u5c42\u7684\u8f93\u51fa\u3002","title":"Style Loss"},{"location":"Building_Blocks/CBAM:Convolutional_Block_Attention_Module/","text":"CBAM: Convolutional Block Attention Module","title":"CBAM: Convolutional Block Attention Module"},{"location":"Building_Blocks/CBAM:Convolutional_Block_Attention_Module/#cbam-convolutional-block-attention-module","text":"","title":"CBAM: Convolutional Block Attention Module"},{"location":"Building_Blocks/Can GCNs Go as Deep as CNNs/","text":"Can GCNs Go as Deep as CNNs \u8fd9\u7bc7\u8bba\u6587\u662f\u8fd1\u671f\u56fe\u5377\u79ef\u7f51\u7edc\u7684\u91cd\u8981\u7a81\u7834\u4e4b\u4e00\u3002\u610f\u4e49\u5728\u4e8e\u5bf9\u57fa\u672c\u5377\u79ef\u7684\u4e00\u4e2a\u590d\u5236\uff0c\u5c06\u57fa\u7840\u5377\u79ef\u76f8\u5173\u7684\u8fde\u63a5\u7b97\u6cd5\u79fb\u690d\u5230\u56fe\u5377\u79ef\u4e2d\u3002 \u56fe\u5377\u79ef\u7f51\u7edc\u7684Res\u8fde\u63a5\u4ee5\u53caDense\u8fde\u63a5 \u4e0e\u57fa\u7840\u7684ResNet\u548cDenseNet\u4e00\u81f4\uff0cRes\u4ee3\u8868\u5c42\u8f93\u5165\u4e0e\u5c42\u8f93\u51fa\u76f8\u52a0\u3002Dense\u5219\u662f\u591a\u5c42\u8f93\u5165\u3001\u8f93\u51fa\u7684Concatenation\u3002 \u56fe\u5377\u79ef\u7f51\u7edc\u7684Dilated Convolution \u672c\u6587\u5377\u79ef\u91c7\u53d6\u7684\u65b9\u6848\u662fK-nearest-neighbor\u7684\u65b9\u6848\uff0c\u5bfb\u627e\u4e0e\u5f53\u524d\u70b9\u8ddd\u79bb\u6700\u8fd1\u7684k\u4e2a\u70b9\u8fdb\u884c\u5377\u79ef\uff0c\u82e5\u6269\u5c55\u4e3adilatedConv\uff0c\u5219\u8ddd\u79bb\u6700\u8fd1\u7684\u70b9\u8fdb\u884c\u6392\u5e8f\uff0c\u6bcf\u9694\u51e0\u4e2a\u70b9\u627e\u51fa\u4e00\u4e2a\u5377\u79ef\u70b9\u3002 \u4ece\u5b9e\u65f6\u8fd0\u7b97\u7684\u89d2\u5ea6\u6765\u770b\uff0c\u9700\u8981\u5efa\u7acb\u4e00\u4e2aKDtree\uff0c \u5bf9\u4e8e\u6bcf\u4e00\u5c42\u7684\u7f51\u7edc\u90fd\u8981\u5bf9\u6bcf\u4e00\u4e2a\u70b9\u8fdb\u884cKNN\u7684\u641c\u7d22\u3002\u5b9e\u65f6\u8fd0\u7b97\u901f\u7387\u4e00\u822c\uff0c\u4f46\u662f\u80fd\u5f97\u5230\u66f4\u597d\u7684\u7ed3\u679c\u3002","title":"Can GCNs Go as Deep as CNNs"},{"location":"Building_Blocks/Can GCNs Go as Deep as CNNs/#can-gcns-go-as-deep-as-cnns","text":"\u8fd9\u7bc7\u8bba\u6587\u662f\u8fd1\u671f\u56fe\u5377\u79ef\u7f51\u7edc\u7684\u91cd\u8981\u7a81\u7834\u4e4b\u4e00\u3002\u610f\u4e49\u5728\u4e8e\u5bf9\u57fa\u672c\u5377\u79ef\u7684\u4e00\u4e2a\u590d\u5236\uff0c\u5c06\u57fa\u7840\u5377\u79ef\u76f8\u5173\u7684\u8fde\u63a5\u7b97\u6cd5\u79fb\u690d\u5230\u56fe\u5377\u79ef\u4e2d\u3002","title":"Can GCNs Go as Deep as CNNs"},{"location":"Building_Blocks/Can GCNs Go as Deep as CNNs/#resdense","text":"\u4e0e\u57fa\u7840\u7684ResNet\u548cDenseNet\u4e00\u81f4\uff0cRes\u4ee3\u8868\u5c42\u8f93\u5165\u4e0e\u5c42\u8f93\u51fa\u76f8\u52a0\u3002Dense\u5219\u662f\u591a\u5c42\u8f93\u5165\u3001\u8f93\u51fa\u7684Concatenation\u3002","title":"\u56fe\u5377\u79ef\u7f51\u7edc\u7684Res\u8fde\u63a5\u4ee5\u53caDense\u8fde\u63a5"},{"location":"Building_Blocks/Can GCNs Go as Deep as CNNs/#dilated-convolution","text":"\u672c\u6587\u5377\u79ef\u91c7\u53d6\u7684\u65b9\u6848\u662fK-nearest-neighbor\u7684\u65b9\u6848\uff0c\u5bfb\u627e\u4e0e\u5f53\u524d\u70b9\u8ddd\u79bb\u6700\u8fd1\u7684k\u4e2a\u70b9\u8fdb\u884c\u5377\u79ef\uff0c\u82e5\u6269\u5c55\u4e3adilatedConv\uff0c\u5219\u8ddd\u79bb\u6700\u8fd1\u7684\u70b9\u8fdb\u884c\u6392\u5e8f\uff0c\u6bcf\u9694\u51e0\u4e2a\u70b9\u627e\u51fa\u4e00\u4e2a\u5377\u79ef\u70b9\u3002 \u4ece\u5b9e\u65f6\u8fd0\u7b97\u7684\u89d2\u5ea6\u6765\u770b\uff0c\u9700\u8981\u5efa\u7acb\u4e00\u4e2aKDtree\uff0c \u5bf9\u4e8e\u6bcf\u4e00\u5c42\u7684\u7f51\u7edc\u90fd\u8981\u5bf9\u6bcf\u4e00\u4e2a\u70b9\u8fdb\u884cKNN\u7684\u641c\u7d22\u3002\u5b9e\u65f6\u8fd0\u7b97\u901f\u7387\u4e00\u822c\uff0c\u4f46\u662f\u80fd\u5f97\u5230\u66f4\u597d\u7684\u7ed3\u679c\u3002","title":"\u56fe\u5377\u79ef\u7f51\u7edc\u7684Dilated Convolution"},{"location":"Building_Blocks/CornerNet_Detecting_Objects_as_Paired_Keypoints/","text":"CornerNet: Detecting Objects as Paired Keypoints \u8fd9\u7bc7\u6587\u7ae0\u662f \u8fd9\u7bc7\u6587\u7ae0 \u7684\u524d\u7f6e,\u5b9e\u9645\u4e0a\u4e5f\u786e\u5b9e\u6709\u66f4\u591a\u7684\u5185\u5bb9,\u5728\u5177\u4f53\u5b9e\u73b0\u4e0a\u6709\u533a\u522b\u3002 \u8fd9\u7bc7\u6587\u7ae0\u7ed9\u51fa\u7684\u601d\u8def\u662f\uff0c\u8ba9\u795e\u7ecf\u7f51\u7edc\u5206\u522b\u7ed9\u51fa\u67d0\u4e00\u7c7b\u522b\u5de6\u4e0a\u89d2\u4e0e\u53f3\u4e0b\u89d2\u7684heatmap\uff0c\u7136\u540e\u901a\u8fc7embedding vector\u7684\u76f8\u4f3c\u6027\u8fdb\u884c\u4e24\u4e2a\u89d2\u843d\u7684\u5339\u914d\u3002\u53e6\u5916\u4e3a\u4e86\u63d0\u9ad8\u6027\u80fd\uff0c\u8fd8\u7ed9\u51fa\u4e86corner pooling\u4ee5\u53ca\u5b83\u7684GPU\u5b9e\u73b0\u3002\u6574\u4e2a\u7f51\u7edc\u6d41\u7a0b\u57fa\u672c\u662fone-stage \u7ed3\u6784overview backbone\u7f51\u7edc\u4f7f\u7528\u7684\u662f hourglass \u4e4b\u540e\u8ddf\u968f\u7684\u662f\u4e24\u4e2a\u9884\u6d4b\u6a21\u5757\uff0c\u4e00\u4e2a\u9884\u6d4b\u8f93\u51fa\u662f\u5de6\u4e0a\u89d2\uff0c\u53e6\u4e00\u4e2a\u7ed9\u51fa\u7684\u662f\u53f3\u4e0b\u89d2\u3002\u8fd9\u4e24\u4e2a\u6a21\u5757\u6709\u5404\u81ea\u7684corner pooling\u3002 \u9884\u6d4b\u89d2\u70b9 \u7f51\u7edc\u6700\u7ec8\u8f93\u51fa\u7684\u662f\u4e24\u7ec4heatmap\uff0c\u4e00\u4e2a\u7ed9\u5de6\u4e0a\u89d2\u4e00\u4e2a\u7ed9\u53f3\u4e0b\u89d2\uff0c\u6bcf\u4e00\u7ec4\u70ed\u56fe\u6709 C \u4e2a\u7279\u5f81\uff0c\u4e0e\u7c7b\u522b\u6570\u4e00\u81f4(\u6bcf\u4e00\u7c7b\u4e00\u4e2achannel\u7684\u70ed\u56fe)\uff0cfeature map\u5f62\u72b6\u662f H\\times W .\u4e0d\u50cfyolo\u6216\u8005SSD\u4e00\u6837\u5e26\u6709background channel\u3002 \u5728\u8bad\u7ec3\u7684\u65f6\u5019\uff0c\u76f4\u89c9\u4e0e\u7ecf\u9a8c\u8868\u793a\u4e0d\u5e94\u8be5\u7b80\u5355\u5730\u60e9\u7f5a\u4e0d\u6b63\u786e\u7684\u89d2\u70b9\u4f4d\u7f6e\u3002\u8fd9\u91cc\u6839\u636e\u7269\u4f53\u7684\u4f53\u79ef\u7684\u8bbe\u5b9a\u4e0d\u540c\u7684radius cost.\u6700\u7ec8\u8bbe\u8ba1\u51fa\u4e00\u4e2afocal loss,\u539f\u7248focal loss\u6e90\u81ea\u4e0e \u8fd9\u7bc7\u6587\u7ae0 ,\u5728 \u8fd9\u91cc \u6709\u7b80\u4ecb\u3002\u8fd9\u91cc\u7684\u5b9a\u4e49\u662f L_{det}=\\frac{-1}{N} \\sum_{c=1}^{C} \\sum_{i=1}^{H} \\sum_{j=1}^{W}\\left\\{\\begin{array}{c}{\\left(1-p_{c i j}\\right)^{\\alpha} \\log \\left(p_{c i j}\\right)} if (y_{cij} == 1) \\\\ {\\left(1-y_{c i j}\\right)^{\\beta}\\left(p_{c i j}\\right)^{\\alpha} \\log \\left(1-p_{c i j}\\right) \\text { otherwise }}\\end{array}\\right. \u5176\u4e2d p_{cij} \u4e3a (i,j) \u4f4d\u7f6e\u4e0a\u7684score\uff0c e^{-\\frac{x^2+y^2}{2\\sigma^2}} ,\u5176\u4e2d \\sigma \u662fradius\u662f 1/3 , N \u662f\u56fe\u7247\u4e2d\u7269\u4f53\u7684\u6570\u76ee\u3002 \\alpha, \\beta \u662f\u53ef\u8c03\u8282\u7684\u8d85\u53c2\u6570\u3002 \u7531\u4e8e\u5377\u79ef\u7f51\u7edc\u91cc\u9762\u6211\u4eec\u9700\u8981\u5bf9\u56fe\u7247\u4e0b\u91c7\u6837\uff0c (x,y) \\rightarrow (\\frac{x}{n}, \\frac{y}{n}) ,\u9700\u8981\u989d\u5916\u5b66\u4e60\u4e00\u4e2aoffsets\u53bb\u8865\u507f \\boldsymbol{o}_{k}=\\left(\\frac{x_{k}}{n}-\\left\\lfloor\\frac{x_{k}}{n}\\right\\rfloor, \\frac{y_{k}}{n}-\\left\\lfloor\\frac{y_{k}}{n}\\right\\rfloor\\right) \u8fd9\u4e2acost\u53ef\u4ee5\u7528 L_{o f f}=\\frac{1}{N} \\sum_{k=1}^{N} \\operatorname{SmoothL} 1 \\operatorname{Loss}\\left(\\boldsymbol{o}_{k}, \\hat{\\boldsymbol{o}}_{k}\\right) \u5c06\u89d2\u70b9\u805a\u56e2 \u56e0\u4e3a\u4e00\u5f20\u56fe\u5982\u679c\u6709\u591a\u4e2a\u7269\u4f53\uff0c\u4e00\u4e2a\u56fe\u4f1a\u6709\u4e0d\u6b62\u4e00\u5bf9\u7684\u5de6\u4e0a\u89d2\u70b9\u548c\u53f3\u4e0b\u70b9\u3002\u672c\u6587\u7684\u505a\u6cd5\u63d0\u5230\u4e86 \u8fd9\u7bc7\u8bba\u6587 , \u7b80\u4ecb \u7f51\u7edc\u7ed9\u6bcf\u4e00\u4e2a\u5de6\u4e0a\u89d2\u4e0e\u53f3\u4e0b\u89d2\u89d2\u9884\u6d4b\u4e00\u4e2aembedding vector\uff0c\u672c\u6587\u8fd9\u91cc\u6a21\u4eff\u524d\u4e00\u7bc7\u8bba\u6587\u7684\u505a\u6cd5\uff0c\u7ef4\u5ea6\u4ec5\u4e3a1\u3002\u5982\u679c\u4ee3\u8868\u7684\u662f\u540c\u4e00\u4e2abounding box\uff0c\u90a3\u4e48\u4e24\u8005\u8ddd\u79bb\u5c31\u4f1a\u6bd4\u8f83\u5c0f\u3002\u5206\u4e3a\u4e24\u4e2aloss\uff0c\u4e00\u4e2a\u662fpull\u4e00\u4e2apush\u3002 L_{p u l l}=\\frac{1}{N} \\sum_{k=1}^{N}\\left[\\left(e_{t_{k}}-e_{k}\\right)^{2}+\\left(e_{b_{k}}-e_{k}\\right)^{2}\\right] L_{p u s h}=\\frac{1}{N(N-1)} \\sum_{k=1}^{N} \\sum_{j=1 \\atop j \\neq k}^{N} \\max \\left(0, \\Delta-\\left|e_{k}-e_{j}\\right|\\right) e_{t_k} \u4f5c\u4e3a\u7b2c k \u4e2a\u7269\u4f53\uff0c\u5de6\u4e0a\u89d2\u7684embedding, e_b_k \u4f5c\u4e3a\u53f3\u4e0b\u89d2\u7684\u3002 e_k \u662f e_t_k, e_b_k \u7684\u5747\u503c\uff0c\u7136\u540e\u8bbe\u5b9a \\Delta=1 \uff0c\u4e0eoffset\u4e00\u6837\uff0c\u8fd9\u4e2aloss\u53ea\u6267\u884c\u5728gt\u7684\u89d2\u843d\u4f4d\u7f6e\u4e0a. Corner Pooling \u7528\u6765\u5141\u8bb8\u6bcf\u4e00\u4e2a\uff0c\u8ba1\u7b97\u65b9\u5f0f\u5982\u56fe t_{i j}=\\left\\{\\begin{array}{cl}{\\max \\left(f_{t_{i j}}, t_{(i+1) j}\\right)} & {\\text { if } i<H} \\\\ {f_{t_{H j}}} & {\\text { otherwise }}\\end{array}\\right. l_{i j}=\\left\\{\\begin{array}{cl}{\\max \\left(f_{l_{i j}}, l_{i(j+1)}\\right)} & {\\text { if } j<W} \\\\ {f_{l_{i W}}} & {\\text { otherwise }}\\end{array}\\right. \u7136\u540e\u5bf9 t_{ij}, l_{ij} \u76f8\u52a0\u5f97\u5230\u7ed3\u679c\u3002\u4e3a\u53f3\u4e0b\u89d2\u7684pooling layer\u53d6max\u7684\u65b9\u5411\u76f8\u53cd\u3002 \u5148\u5c06\u57fa\u7840\u7684resblock\u7684\u7b2c\u4e00\u4e2a 3\\times 3 \u5377\u79ef\u6539\u4e3acorner pooling.","title":"CornerNet: Detecting Objects as Paired Keypoints"},{"location":"Building_Blocks/CornerNet_Detecting_Objects_as_Paired_Keypoints/#cornernet-detecting-objects-as-paired-keypoints","text":"\u8fd9\u7bc7\u6587\u7ae0\u662f \u8fd9\u7bc7\u6587\u7ae0 \u7684\u524d\u7f6e,\u5b9e\u9645\u4e0a\u4e5f\u786e\u5b9e\u6709\u66f4\u591a\u7684\u5185\u5bb9,\u5728\u5177\u4f53\u5b9e\u73b0\u4e0a\u6709\u533a\u522b\u3002 \u8fd9\u7bc7\u6587\u7ae0\u7ed9\u51fa\u7684\u601d\u8def\u662f\uff0c\u8ba9\u795e\u7ecf\u7f51\u7edc\u5206\u522b\u7ed9\u51fa\u67d0\u4e00\u7c7b\u522b\u5de6\u4e0a\u89d2\u4e0e\u53f3\u4e0b\u89d2\u7684heatmap\uff0c\u7136\u540e\u901a\u8fc7embedding vector\u7684\u76f8\u4f3c\u6027\u8fdb\u884c\u4e24\u4e2a\u89d2\u843d\u7684\u5339\u914d\u3002\u53e6\u5916\u4e3a\u4e86\u63d0\u9ad8\u6027\u80fd\uff0c\u8fd8\u7ed9\u51fa\u4e86corner pooling\u4ee5\u53ca\u5b83\u7684GPU\u5b9e\u73b0\u3002\u6574\u4e2a\u7f51\u7edc\u6d41\u7a0b\u57fa\u672c\u662fone-stage","title":"CornerNet: Detecting Objects as Paired Keypoints"},{"location":"Building_Blocks/CornerNet_Detecting_Objects_as_Paired_Keypoints/#overview","text":"backbone\u7f51\u7edc\u4f7f\u7528\u7684\u662f hourglass \u4e4b\u540e\u8ddf\u968f\u7684\u662f\u4e24\u4e2a\u9884\u6d4b\u6a21\u5757\uff0c\u4e00\u4e2a\u9884\u6d4b\u8f93\u51fa\u662f\u5de6\u4e0a\u89d2\uff0c\u53e6\u4e00\u4e2a\u7ed9\u51fa\u7684\u662f\u53f3\u4e0b\u89d2\u3002\u8fd9\u4e24\u4e2a\u6a21\u5757\u6709\u5404\u81ea\u7684corner pooling\u3002","title":"\u7ed3\u6784overview"},{"location":"Building_Blocks/CornerNet_Detecting_Objects_as_Paired_Keypoints/#_1","text":"\u7f51\u7edc\u6700\u7ec8\u8f93\u51fa\u7684\u662f\u4e24\u7ec4heatmap\uff0c\u4e00\u4e2a\u7ed9\u5de6\u4e0a\u89d2\u4e00\u4e2a\u7ed9\u53f3\u4e0b\u89d2\uff0c\u6bcf\u4e00\u7ec4\u70ed\u56fe\u6709 C \u4e2a\u7279\u5f81\uff0c\u4e0e\u7c7b\u522b\u6570\u4e00\u81f4(\u6bcf\u4e00\u7c7b\u4e00\u4e2achannel\u7684\u70ed\u56fe)\uff0cfeature map\u5f62\u72b6\u662f H\\times W .\u4e0d\u50cfyolo\u6216\u8005SSD\u4e00\u6837\u5e26\u6709background channel\u3002 \u5728\u8bad\u7ec3\u7684\u65f6\u5019\uff0c\u76f4\u89c9\u4e0e\u7ecf\u9a8c\u8868\u793a\u4e0d\u5e94\u8be5\u7b80\u5355\u5730\u60e9\u7f5a\u4e0d\u6b63\u786e\u7684\u89d2\u70b9\u4f4d\u7f6e\u3002\u8fd9\u91cc\u6839\u636e\u7269\u4f53\u7684\u4f53\u79ef\u7684\u8bbe\u5b9a\u4e0d\u540c\u7684radius cost.\u6700\u7ec8\u8bbe\u8ba1\u51fa\u4e00\u4e2afocal loss,\u539f\u7248focal loss\u6e90\u81ea\u4e0e \u8fd9\u7bc7\u6587\u7ae0 ,\u5728 \u8fd9\u91cc \u6709\u7b80\u4ecb\u3002\u8fd9\u91cc\u7684\u5b9a\u4e49\u662f L_{det}=\\frac{-1}{N} \\sum_{c=1}^{C} \\sum_{i=1}^{H} \\sum_{j=1}^{W}\\left\\{\\begin{array}{c}{\\left(1-p_{c i j}\\right)^{\\alpha} \\log \\left(p_{c i j}\\right)} if (y_{cij} == 1) \\\\ {\\left(1-y_{c i j}\\right)^{\\beta}\\left(p_{c i j}\\right)^{\\alpha} \\log \\left(1-p_{c i j}\\right) \\text { otherwise }}\\end{array}\\right. \u5176\u4e2d p_{cij} \u4e3a (i,j) \u4f4d\u7f6e\u4e0a\u7684score\uff0c e^{-\\frac{x^2+y^2}{2\\sigma^2}} ,\u5176\u4e2d \\sigma \u662fradius\u662f 1/3 , N \u662f\u56fe\u7247\u4e2d\u7269\u4f53\u7684\u6570\u76ee\u3002 \\alpha, \\beta \u662f\u53ef\u8c03\u8282\u7684\u8d85\u53c2\u6570\u3002 \u7531\u4e8e\u5377\u79ef\u7f51\u7edc\u91cc\u9762\u6211\u4eec\u9700\u8981\u5bf9\u56fe\u7247\u4e0b\u91c7\u6837\uff0c (x,y) \\rightarrow (\\frac{x}{n}, \\frac{y}{n}) ,\u9700\u8981\u989d\u5916\u5b66\u4e60\u4e00\u4e2aoffsets\u53bb\u8865\u507f \\boldsymbol{o}_{k}=\\left(\\frac{x_{k}}{n}-\\left\\lfloor\\frac{x_{k}}{n}\\right\\rfloor, \\frac{y_{k}}{n}-\\left\\lfloor\\frac{y_{k}}{n}\\right\\rfloor\\right) \u8fd9\u4e2acost\u53ef\u4ee5\u7528 L_{o f f}=\\frac{1}{N} \\sum_{k=1}^{N} \\operatorname{SmoothL} 1 \\operatorname{Loss}\\left(\\boldsymbol{o}_{k}, \\hat{\\boldsymbol{o}}_{k}\\right)","title":"\u9884\u6d4b\u89d2\u70b9"},{"location":"Building_Blocks/CornerNet_Detecting_Objects_as_Paired_Keypoints/#_2","text":"\u56e0\u4e3a\u4e00\u5f20\u56fe\u5982\u679c\u6709\u591a\u4e2a\u7269\u4f53\uff0c\u4e00\u4e2a\u56fe\u4f1a\u6709\u4e0d\u6b62\u4e00\u5bf9\u7684\u5de6\u4e0a\u89d2\u70b9\u548c\u53f3\u4e0b\u70b9\u3002\u672c\u6587\u7684\u505a\u6cd5\u63d0\u5230\u4e86 \u8fd9\u7bc7\u8bba\u6587 , \u7b80\u4ecb \u7f51\u7edc\u7ed9\u6bcf\u4e00\u4e2a\u5de6\u4e0a\u89d2\u4e0e\u53f3\u4e0b\u89d2\u89d2\u9884\u6d4b\u4e00\u4e2aembedding vector\uff0c\u672c\u6587\u8fd9\u91cc\u6a21\u4eff\u524d\u4e00\u7bc7\u8bba\u6587\u7684\u505a\u6cd5\uff0c\u7ef4\u5ea6\u4ec5\u4e3a1\u3002\u5982\u679c\u4ee3\u8868\u7684\u662f\u540c\u4e00\u4e2abounding box\uff0c\u90a3\u4e48\u4e24\u8005\u8ddd\u79bb\u5c31\u4f1a\u6bd4\u8f83\u5c0f\u3002\u5206\u4e3a\u4e24\u4e2aloss\uff0c\u4e00\u4e2a\u662fpull\u4e00\u4e2apush\u3002 L_{p u l l}=\\frac{1}{N} \\sum_{k=1}^{N}\\left[\\left(e_{t_{k}}-e_{k}\\right)^{2}+\\left(e_{b_{k}}-e_{k}\\right)^{2}\\right] L_{p u s h}=\\frac{1}{N(N-1)} \\sum_{k=1}^{N} \\sum_{j=1 \\atop j \\neq k}^{N} \\max \\left(0, \\Delta-\\left|e_{k}-e_{j}\\right|\\right) e_{t_k} \u4f5c\u4e3a\u7b2c k \u4e2a\u7269\u4f53\uff0c\u5de6\u4e0a\u89d2\u7684embedding, e_b_k \u4f5c\u4e3a\u53f3\u4e0b\u89d2\u7684\u3002 e_k \u662f e_t_k, e_b_k \u7684\u5747\u503c\uff0c\u7136\u540e\u8bbe\u5b9a \\Delta=1 \uff0c\u4e0eoffset\u4e00\u6837\uff0c\u8fd9\u4e2aloss\u53ea\u6267\u884c\u5728gt\u7684\u89d2\u843d\u4f4d\u7f6e\u4e0a.","title":"\u5c06\u89d2\u70b9\u805a\u56e2"},{"location":"Building_Blocks/CornerNet_Detecting_Objects_as_Paired_Keypoints/#corner-pooling","text":"\u7528\u6765\u5141\u8bb8\u6bcf\u4e00\u4e2a\uff0c\u8ba1\u7b97\u65b9\u5f0f\u5982\u56fe t_{i j}=\\left\\{\\begin{array}{cl}{\\max \\left(f_{t_{i j}}, t_{(i+1) j}\\right)} & {\\text { if } i<H} \\\\ {f_{t_{H j}}} & {\\text { otherwise }}\\end{array}\\right. l_{i j}=\\left\\{\\begin{array}{cl}{\\max \\left(f_{l_{i j}}, l_{i(j+1)}\\right)} & {\\text { if } j<W} \\\\ {f_{l_{i W}}} & {\\text { otherwise }}\\end{array}\\right. \u7136\u540e\u5bf9 t_{ij}, l_{ij} \u76f8\u52a0\u5f97\u5230\u7ed3\u679c\u3002\u4e3a\u53f3\u4e0b\u89d2\u7684pooling layer\u53d6max\u7684\u65b9\u5411\u76f8\u53cd\u3002 \u5148\u5c06\u57fa\u7840\u7684resblock\u7684\u7b2c\u4e00\u4e2a 3\\times 3 \u5377\u79ef\u6539\u4e3acorner pooling.","title":"Corner Pooling"},{"location":"Building_Blocks/Discovery_of_Latent_3D_Keypoints_via_End-to-end_Geometric_Reasoning/","text":"Discovery of Latent 3D Keypoints via End-to-end Geometric Reasoning \u8fd9\u7bc7\u8bba\u6587\u5b8c\u6210\u7684\u4efb\u52a1\u662f\uff0c\u5bf9\u5355\u5f20\u56fe\u7247\u8f93\u51fa\u4e00\u7cfb\u5217\u6709\u5e8f\u7684keypoints\uff0c\u8fd9\u4e9bkeypoints\u5728\u4e0d\u540c\u89c6\u89d2\u4e0b\u6709\u76f8\u540c\u7684\u8868\u8fbe\u3002\u8bad\u7ec3\u65f6\u5219\u901a\u8fc7\u540c\u4e00\u7269\u4f53\u4e0d\u540c\u89c6\u89d2\u7684\u4e00\u5bf9\u56fe\u7247\u8fdb\u884c\u8bad\u7ec3\u3002 \u4e3b\u4f53Pipeline \u5df2\u77e5\u7684\u76f8\u5bf9\u521a\u4f53\u8fd0\u52a8\u4f5c\u4e3a\u76d1\u7763\u4fe1\u53f7\u3002inference\u7684\u65f6\u5019\uff0cKeypointNet\u4ece\u5355\u4e2a\u8f93\u5165\u56fe\u4e2d\u8f93\u51fa3D\u5173\u952e\u70b9 \u5177\u4f53\u4ecb\u7ecd \u4e00\u4e2a3D keypoint\u88ab\u5b9a\u4e49\u4e3a\u50cf\u7d20\u5750\u6807\u52a0\u4e0a\u5bf9\u5e94\u7684\u6df1\u5ea6\u503c\u3002\u7f51\u7edc\u8f93\u51fa N\u4e2a\u5206\u652f\uff0c\u9884\u6d4bN\u4e2a\u5173\u952e\u70b9\u3002 \u76ee\u6807\u51fd\u6570\u7531\u4e24\u4e2a\u90e8\u5206\u7ec4\u6210 Multi-view Consistency \u63cf\u8ff0\u4e24\u7ec4\u70b9\u5728ground truth\u8f6c\u6362\u524d\u540e\u70b9\u7684\u8ddd\u79bb \\begin{aligned}[\\hat{u}, \\hat{v}, \\hat{z}, 1]^{\\top} & \\sim \\pi T \\pi^{-1}\\left([u, v, z, 1]^{\\top}\\right) \\\\\\left[\\hat{u}^{\\prime}, \\hat{v}^{\\prime}, \\hat{z}^{\\prime}, 1\\right]^{\\top} & \\sim \\pi T^{-1} \\pi^{-1}\\left(\\left[u^{\\prime}, v^{\\prime}, z^{\\prime}, 1\\right]^{\\top}\\right) \\end{aligned} \\pi\\left([x, y, z, 1]^{\\top}\\right)=\\left[\\frac{f x}{z}, \\frac{f y}{z}, z, 1\\right]^{\\top}=[u, v, z, 1]^{\\top} L_{\\mathrm{con}}=\\frac{1}{2 N} \\sum_{i=1}^{N}\\left\\|\\left[u_{i}, v_{i}, u_{i}^{\\prime}, v_{i}^{\\prime}\\right]^{\\top}-\\left[\\hat{u}_{i}^{\\prime}, \\hat{v}_{i}^{\\prime}, \\hat{u}_{i}, \\hat{v}_{i}\\right]^{\\top}\\right\\|^{2} \u672c\u8d28\u4e0a\u5c31\u662f\u5c06A\u56fe\u4e0a\u7684\u70b9\u8f6c\u6362\u5230B\u56fe\u4e0a\u6c42\u5dee\u503c\uff0c\u518d\u5c06B\u56fe\u4e0a\u7684\u70b9\u8f6c\u6362\u5230A\u56fe\u4e0a\u6c42\u5dee\u503c\uff0c\u6c42\u548c\u3002 \u76f8\u5bf9\u59ff\u6001\u4f30\u8ba1\u3002 \u8fd9\u91cc\u53ea\u8981\u6c42\u5bf9\u4f30\u8ba1\u7684\u65cb\u8f6c\u77e9\u9635\u8ba1\u7b97loss L_{\\mathrm{pose}}=2 \\arcsin \\left(\\frac{1}{2 \\sqrt{2}}\\|\\hat{R}-R\\|_{F}\\right) \u5176\u4e2d\u4f30\u8ba1 \\hat R ,\u4ee4 X \u548c X' \u6307\u4ee3\u4e24\u4e2a\u56fe\u8ba1\u7b97\u51fa\u6765\u7684keypoints\u7684 X \\equiv\\left[X_{1}, \\ldots, X_{N}\\right] and X_{i} \\equiv\\left(\\pi^{-1} p_{i}\\right)[: 3] \\hat{R}=V \\operatorname{diag}\\left(1,1, \\ldots, \\operatorname{det}\\left(V U^{\\top}\\right)\\right) U^{\\top} U, \\Sigma, V^{\\top}=\\operatorname{SVD}\\left(\\tilde{X} \\tilde{X}^{\\prime \\top}\\right) \u8fd9\u4e2a\u65b9\u6cd5\u88ab\u79f0\u4e3a Procrustes problem SVD\u662f\u53ef\u4ee5backprob\u7684\u5b9e\u73b0\u7684(\u540c\u6837\u4f7f\u7528\u53ef\u5fae\u5206SVD\u7684 \u8fd9\u7bc7\u6587\u7ae0 \u4e5f\u63d0\u5230tensorflow\u6709\u53ef\u5fae\u5206SVD) KeypointNet \u7ed3\u6784 \u672c\u6587\u4f7f\u7528\u7684KeypointNet,\u4e00\u4e2a\u91cd\u8981\u7684\u6027\u8d28\u5728\u4e8e\u5e73\u79fb\u7b49\u4ef7\uff0c\u4e5f\u5c31\u662f\u8bf4\u5e73\u79fb\u4e00\u4e2a\u50cf\u7d20\uff0c\u8f93\u51fa\u4f4d\u7f6e\u4e5f\u4f1a\u79fb\u52a8\u4e00\u4e2a\u5355\u4f4d\u3002\u8981\u6c42\u8f93\u51faheatmap g_i(u,v) \u4ee3\u8868\u7b2c i \u4e2akeypoint\u51fa\u73b0\u5728 (u,v) ,\u8981\u6c42 \\sum_{u,v}g_i(u,v)=1 \u4f7f\u7528spatial softmax\u53bb\u5b9e\u73b0\u3002 \u7528\u52a0\u6743\u5e73\u5747\u6c42\u51fa\u5bf9\u5e94keypoint\u7684\u4f4d\u7f6e\u4ee5\u53ca\u6df1\u5ea6 [u_i,v_i]^T = \\sum_{u,v}[u * g_i(u,v), v * g_i(u,v)]^T z_i = \\sum_{u,v}d_i(u,v)g_i(u,v) \u8f85\u52a9training \u5206\u79bbloss:\u5bf9\u8fc7\u4e8e\u9760\u8fd1\u7684keypoints\u7ed9\u4e00\u4e2aloss L_{\\mathrm{sep}}=\\frac{1}{N^{2}} \\sum_{i=1}^{N} \\sum_{j \\neq i}^{N} \\max \\left(0, \\delta^{2}-\\left\\|X_{i}-X_{j}\\right\\|^{2}\\right) \u8f6e\u5ed3\u4e00\u81f4\u6027:\u9f13\u52b1keypoints\u5728\u7269\u4f53\u5185\u90e8\uff0c\u539f\u56e0\u662ftraining\u7684\u65f6\u5019\u80fd\u5f97\u5230\u56fe\u7247\u6bcf\u4e00\u4e2a\u5750\u6807\u662f\u5426\u5bf9\u5e94\u4e00\u4e2aobject\uff0c\u8fd9\u4e2amask\u6807\u8bb0\u4e3a b(u,v)\\in{0,1} L_{obj} = \\frac{1}{N}\\sum^N_{i=1} - log\\sum_{u,v}b(u,v)g_i(u,v)","title":"Discovery of Latent 3D Keypoints via End-to-end Geometric Reasoning"},{"location":"Building_Blocks/Discovery_of_Latent_3D_Keypoints_via_End-to-end_Geometric_Reasoning/#discovery-of-latent-3d-keypoints-via-end-to-end-geometric-reasoning","text":"\u8fd9\u7bc7\u8bba\u6587\u5b8c\u6210\u7684\u4efb\u52a1\u662f\uff0c\u5bf9\u5355\u5f20\u56fe\u7247\u8f93\u51fa\u4e00\u7cfb\u5217\u6709\u5e8f\u7684keypoints\uff0c\u8fd9\u4e9bkeypoints\u5728\u4e0d\u540c\u89c6\u89d2\u4e0b\u6709\u76f8\u540c\u7684\u8868\u8fbe\u3002\u8bad\u7ec3\u65f6\u5219\u901a\u8fc7\u540c\u4e00\u7269\u4f53\u4e0d\u540c\u89c6\u89d2\u7684\u4e00\u5bf9\u56fe\u7247\u8fdb\u884c\u8bad\u7ec3\u3002","title":"Discovery of Latent 3D Keypoints via End-to-end Geometric Reasoning"},{"location":"Building_Blocks/Discovery_of_Latent_3D_Keypoints_via_End-to-end_Geometric_Reasoning/#pipeline","text":"\u5df2\u77e5\u7684\u76f8\u5bf9\u521a\u4f53\u8fd0\u52a8\u4f5c\u4e3a\u76d1\u7763\u4fe1\u53f7\u3002inference\u7684\u65f6\u5019\uff0cKeypointNet\u4ece\u5355\u4e2a\u8f93\u5165\u56fe\u4e2d\u8f93\u51fa3D\u5173\u952e\u70b9","title":"\u4e3b\u4f53Pipeline"},{"location":"Building_Blocks/Discovery_of_Latent_3D_Keypoints_via_End-to-end_Geometric_Reasoning/#_1","text":"\u4e00\u4e2a3D keypoint\u88ab\u5b9a\u4e49\u4e3a\u50cf\u7d20\u5750\u6807\u52a0\u4e0a\u5bf9\u5e94\u7684\u6df1\u5ea6\u503c\u3002\u7f51\u7edc\u8f93\u51fa N\u4e2a\u5206\u652f\uff0c\u9884\u6d4bN\u4e2a\u5173\u952e\u70b9\u3002 \u76ee\u6807\u51fd\u6570\u7531\u4e24\u4e2a\u90e8\u5206\u7ec4\u6210","title":"\u5177\u4f53\u4ecb\u7ecd"},{"location":"Building_Blocks/Discovery_of_Latent_3D_Keypoints_via_End-to-end_Geometric_Reasoning/#multi-view-consistency","text":"\u63cf\u8ff0\u4e24\u7ec4\u70b9\u5728ground truth\u8f6c\u6362\u524d\u540e\u70b9\u7684\u8ddd\u79bb \\begin{aligned}[\\hat{u}, \\hat{v}, \\hat{z}, 1]^{\\top} & \\sim \\pi T \\pi^{-1}\\left([u, v, z, 1]^{\\top}\\right) \\\\\\left[\\hat{u}^{\\prime}, \\hat{v}^{\\prime}, \\hat{z}^{\\prime}, 1\\right]^{\\top} & \\sim \\pi T^{-1} \\pi^{-1}\\left(\\left[u^{\\prime}, v^{\\prime}, z^{\\prime}, 1\\right]^{\\top}\\right) \\end{aligned} \\pi\\left([x, y, z, 1]^{\\top}\\right)=\\left[\\frac{f x}{z}, \\frac{f y}{z}, z, 1\\right]^{\\top}=[u, v, z, 1]^{\\top} L_{\\mathrm{con}}=\\frac{1}{2 N} \\sum_{i=1}^{N}\\left\\|\\left[u_{i}, v_{i}, u_{i}^{\\prime}, v_{i}^{\\prime}\\right]^{\\top}-\\left[\\hat{u}_{i}^{\\prime}, \\hat{v}_{i}^{\\prime}, \\hat{u}_{i}, \\hat{v}_{i}\\right]^{\\top}\\right\\|^{2} \u672c\u8d28\u4e0a\u5c31\u662f\u5c06A\u56fe\u4e0a\u7684\u70b9\u8f6c\u6362\u5230B\u56fe\u4e0a\u6c42\u5dee\u503c\uff0c\u518d\u5c06B\u56fe\u4e0a\u7684\u70b9\u8f6c\u6362\u5230A\u56fe\u4e0a\u6c42\u5dee\u503c\uff0c\u6c42\u548c\u3002","title":"Multi-view Consistency"},{"location":"Building_Blocks/Discovery_of_Latent_3D_Keypoints_via_End-to-end_Geometric_Reasoning/#_2","text":"\u8fd9\u91cc\u53ea\u8981\u6c42\u5bf9\u4f30\u8ba1\u7684\u65cb\u8f6c\u77e9\u9635\u8ba1\u7b97loss L_{\\mathrm{pose}}=2 \\arcsin \\left(\\frac{1}{2 \\sqrt{2}}\\|\\hat{R}-R\\|_{F}\\right) \u5176\u4e2d\u4f30\u8ba1 \\hat R ,\u4ee4 X \u548c X' \u6307\u4ee3\u4e24\u4e2a\u56fe\u8ba1\u7b97\u51fa\u6765\u7684keypoints\u7684 X \\equiv\\left[X_{1}, \\ldots, X_{N}\\right] and X_{i} \\equiv\\left(\\pi^{-1} p_{i}\\right)[: 3] \\hat{R}=V \\operatorname{diag}\\left(1,1, \\ldots, \\operatorname{det}\\left(V U^{\\top}\\right)\\right) U^{\\top} U, \\Sigma, V^{\\top}=\\operatorname{SVD}\\left(\\tilde{X} \\tilde{X}^{\\prime \\top}\\right) \u8fd9\u4e2a\u65b9\u6cd5\u88ab\u79f0\u4e3a Procrustes problem SVD\u662f\u53ef\u4ee5backprob\u7684\u5b9e\u73b0\u7684(\u540c\u6837\u4f7f\u7528\u53ef\u5fae\u5206SVD\u7684 \u8fd9\u7bc7\u6587\u7ae0 \u4e5f\u63d0\u5230tensorflow\u6709\u53ef\u5fae\u5206SVD)","title":"\u76f8\u5bf9\u59ff\u6001\u4f30\u8ba1\u3002"},{"location":"Building_Blocks/Discovery_of_Latent_3D_Keypoints_via_End-to-end_Geometric_Reasoning/#keypointnet","text":"\u672c\u6587\u4f7f\u7528\u7684KeypointNet,\u4e00\u4e2a\u91cd\u8981\u7684\u6027\u8d28\u5728\u4e8e\u5e73\u79fb\u7b49\u4ef7\uff0c\u4e5f\u5c31\u662f\u8bf4\u5e73\u79fb\u4e00\u4e2a\u50cf\u7d20\uff0c\u8f93\u51fa\u4f4d\u7f6e\u4e5f\u4f1a\u79fb\u52a8\u4e00\u4e2a\u5355\u4f4d\u3002\u8981\u6c42\u8f93\u51faheatmap g_i(u,v) \u4ee3\u8868\u7b2c i \u4e2akeypoint\u51fa\u73b0\u5728 (u,v) ,\u8981\u6c42 \\sum_{u,v}g_i(u,v)=1 \u4f7f\u7528spatial softmax\u53bb\u5b9e\u73b0\u3002 \u7528\u52a0\u6743\u5e73\u5747\u6c42\u51fa\u5bf9\u5e94keypoint\u7684\u4f4d\u7f6e\u4ee5\u53ca\u6df1\u5ea6 [u_i,v_i]^T = \\sum_{u,v}[u * g_i(u,v), v * g_i(u,v)]^T z_i = \\sum_{u,v}d_i(u,v)g_i(u,v)","title":"KeypointNet \u7ed3\u6784"},{"location":"Building_Blocks/Discovery_of_Latent_3D_Keypoints_via_End-to-end_Geometric_Reasoning/#training","text":"\u5206\u79bbloss:\u5bf9\u8fc7\u4e8e\u9760\u8fd1\u7684keypoints\u7ed9\u4e00\u4e2aloss L_{\\mathrm{sep}}=\\frac{1}{N^{2}} \\sum_{i=1}^{N} \\sum_{j \\neq i}^{N} \\max \\left(0, \\delta^{2}-\\left\\|X_{i}-X_{j}\\right\\|^{2}\\right) \u8f6e\u5ed3\u4e00\u81f4\u6027:\u9f13\u52b1keypoints\u5728\u7269\u4f53\u5185\u90e8\uff0c\u539f\u56e0\u662ftraining\u7684\u65f6\u5019\u80fd\u5f97\u5230\u56fe\u7247\u6bcf\u4e00\u4e2a\u5750\u6807\u662f\u5426\u5bf9\u5e94\u4e00\u4e2aobject\uff0c\u8fd9\u4e2amask\u6807\u8bb0\u4e3a b(u,v)\\in{0,1} L_{obj} = \\frac{1}{N}\\sum^N_{i=1} - log\\sum_{u,v}b(u,v)g_i(u,v)","title":"\u8f85\u52a9training"},{"location":"Building_Blocks/ELASTIC/","text":"ELASTIC Improving CNNs With Dynamic Scaling Policies \u8fd9\u7bc7\u8bba\u6587\u7684\u60f3\u6cd5\u975e\u5e38\u7b80\u5355\uff0c\u7b80\u5355\u6765\u8bf4\u5c31\u662f\u8981\u8ba9\u7f51\u7edc\u80fd\u591f\u81ea\u4e3b\u5b66\u4e60\u5728inference\u8fc7\u7a0b\u4e2d\u91c7\u53d6\u600e\u6837\u7684scale\uff0c\u505a\u6cd5\u662f\u5728Resnet\u7684\u4e00\u4e2a\u5206\u652f\u4e2d\uff0c\u5148downsample\uff0c\u505a\u5377\u79ef\uff0c\u518dupsample\u3002\u540c\u65f6\u4fdd\u7559\u539fscale\u7684\u901a\u8def\uff0c\u7531\u8bad\u7ec3\u8fc7\u7a0b\u6765\u8ba9\u7f51\u7edc\u51b3\u5b9a\u5e94\u8be5\u5982\u4f55\u914d\u7f6e\u4e24\u4e2a\u901a\u8def\u7684\u53c2\u6570\uff0c\u4ee5\u6b64\u51b3\u5b9ascale. \u672c\u6587\u8fdb\u4e00\u6b65\u8fd8\u7ed9\u51fa\u4e86\u76ee\u524d\u591a\u79cdmultiscale model\u7684\u7ed3\u6784\uff0c\u56fe\u975e\u5e38\u7684\u597d\u770b\u4e14inspiring","title":"ELASTIC Improving CNNs With Dynamic Scaling Policies"},{"location":"Building_Blocks/ELASTIC/#elastic-improving-cnns-with-dynamic-scaling-policies","text":"\u8fd9\u7bc7\u8bba\u6587\u7684\u60f3\u6cd5\u975e\u5e38\u7b80\u5355\uff0c\u7b80\u5355\u6765\u8bf4\u5c31\u662f\u8981\u8ba9\u7f51\u7edc\u80fd\u591f\u81ea\u4e3b\u5b66\u4e60\u5728inference\u8fc7\u7a0b\u4e2d\u91c7\u53d6\u600e\u6837\u7684scale\uff0c\u505a\u6cd5\u662f\u5728Resnet\u7684\u4e00\u4e2a\u5206\u652f\u4e2d\uff0c\u5148downsample\uff0c\u505a\u5377\u79ef\uff0c\u518dupsample\u3002\u540c\u65f6\u4fdd\u7559\u539fscale\u7684\u901a\u8def\uff0c\u7531\u8bad\u7ec3\u8fc7\u7a0b\u6765\u8ba9\u7f51\u7edc\u51b3\u5b9a\u5e94\u8be5\u5982\u4f55\u914d\u7f6e\u4e24\u4e2a\u901a\u8def\u7684\u53c2\u6570\uff0c\u4ee5\u6b64\u51b3\u5b9ascale. \u672c\u6587\u8fdb\u4e00\u6b65\u8fd8\u7ed9\u51fa\u4e86\u76ee\u524d\u591a\u79cdmultiscale model\u7684\u7ed3\u6784\uff0c\u56fe\u975e\u5e38\u7684\u597d\u770b\u4e14inspiring","title":"ELASTIC Improving CNNs With Dynamic Scaling Policies"},{"location":"Building_Blocks/EfficientNet:_Rethinking_Model_Scaling_for_Convolutional_Neural_Network/","text":"EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks \u8fd9\u7bc7\u6587\u7ae0\u5206\u6790\u4e86CNN Scale Up\u7684\u76f8\u5173\u539f\u7406\uff0c\u7136\u540e\u7ed9\u51faEfficientNet.\u80cc\u540e\u7684\u903b\u8f91\u662f\u8fd9\u6837\u7684\uff0c\u9996\u5148\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7Neural Architecture Search\u5f97\u5230\u4e00\u4e2a\u4f4e\u5206\u8fa8\u7387\u56fe\u7247\u7684\u9ad8\u6548\u7387\u6a21\u578b\uff0c\u7136\u540e\u4f9d\u636e\u5b83\u5bf9\u5e94\u7684Scale Up\u539f\u7406\u8fdb\u884c\u6269\u5c55\u3002\u672c\u6587\u7528\u5230\u7684baseline\u51fa\u81ea MnasNet(pdf) ,\u5c31\u662f\u901a\u8fc7NAS\u5f97\u5230\u7684\u3002\u672c\u6587\u7684 \u4ee3\u7801 \u63d0\u4f9b\u4e86keras\u4ee5\u53caTensorflow\u5b9e\u73b0\u3002\u8fd9\u4e2a repo\u63d0\u4f9b\u4e86pytorch\u5b9e\u73b0 \u8fd9\u91cc\u6dfb\u52a0\u4e00\u4e2a medium\u4e0a\u7684\u89e3\u8bfb . Model Scaling Observation \u4e0a\u56fe\u5c55\u793a\u7684\u662f\u4e0d\u540c\u7684scale up\u4e00\u4e2a\u6a21\u578b\u7684\u65b9\u5f0f\u3002\u672c\u6587\u7684\u7ed3\u8bba\u662f\u5e94\u8be5\u6839\u636e\u8f93\u5165\u56fe\u7247\u7684\u5206\u8fa8\u7387\u3001channel\u6570\u76ee\u4ee5\u53ca\u7f51\u7edc\u6df1\u5ea6\u7efc\u5408Scale Up\u5f97\u5230\u7684\u63d0\u5347\u624d\u662f\u6700\u660e\u663e\u7684\u3002 \u4e0a\u56fe\u5c55\u793a\u7684\u662f\u5206\u522b\u53eaScale Up\u7f51\u7edcchannel\u6570,\u7f51\u7edc\u6df1\u5ea6,\u4ee5\u53ca\u56fe\u7247\u5206\u8fa8\u7387\u5f97\u5230\u7684\u3002\u4f5c\u8005\u7684\u7ed3\u8bba\u662f\u53eaScale Up\u4e00\u4e2a\u56e0\u5b50\u5f88\u5bb9\u6613\u5f97\u5230Saturation\uff0c\u901a\u8fc7\u53e6\u4e00\u4e2a\u5b9e\u9a8c\u53d1\u73b0\u603b\u5408\u4e00\u8d77Scale Up\u80fd\u5f97\u5230\u66f4\u597d\u7684\u7ed3\u679c\u3002 Compound Scaling Method \\begin{aligned} \\text { depth: } d &=\\alpha^{\\phi} \\\\ \\text { width: } w &=\\beta^{\\phi} \\\\ \\text { resolution: } r &=\\gamma^{\\phi} \\\\ \\text { s.t. } \\alpha & \\cdot \\beta^{2} \\cdot \\gamma^{2} \\approx 2 \\\\ \\alpha & \\geq 1, \\beta \\geq 1, \\gamma \\geq 1 \\end{aligned} \u4f5c\u8005\u9009\u62e9\u8fd9\u4e2a\u7684\u539f\u56e0\u662f\u56e0\u4e3aFLOPS(\u6d6e\u70b9\u8fd0\u7b97\u6570)\u6b63\u6bd4\u4e8e\u6df1\u5ea6,\u9891\u9053\u6570\u7684\u5e73\u65b9\u4ee5\u53ca\u5206\u8fa8\u7387\u7684\u5e73\u65b9\u3002 Efficient Net EfficientNet\u7684\u57fa\u672c\u5355\u5143\u7531 Mobile Conv(pdf) \u7ec4\u6210\u3002 \u4ece\u8fd9\u4e2aBaseLine\u5f00\u59cb\uff0c\u901a\u8fc7\u5c0fgrid-search\u5f97\u5230 \\alpha, \\beta, \\gamma \u7684\u521d\u59cb\u503c,\u66f4\u6539 \\phi \u5f97\u5230\u4e0d\u540c\u7684channel\u6570,\u5206\u8fa8\u7387\u4ee5\u53ca\u7f51\u7edc\u5c42\u6570(\u7f51\u7edc\u5c42\u6570\u7684\u66f4\u6539\u662f\u901a\u8fc7\u66f4\u6539\u5806\u53e0MBConv\u7684\u4e00\u4e2afor\u5faa\u73af\u7684\u5faa\u73af\u6b21\u6570\u5b9e\u73b0\u7684) \u5b9e\u9a8c\u4e0e\u7ed3\u679c \u672c\u6587\u9996\u5148\u5c1d\u8bd5Scale Up\u4e86MobileNet\u4ee5\u53caResNet\u7684\u5230\u597d\u7684\u7ed3\u679c\uff0c\u7136\u540e\u5f00\u59cbScale Up EfficientNet, \u4ee5\u4e0b\u56fe\u4e2d\u5404\u4e2a\u7f51\u7edc\u7684\u51c6\u786e\u7387\u3001\u53c2\u6570\u4ee5\u53caFLOPS\u662f\u4e00\u4e2a\u5f88\u597d\u7684\u53c2\u8003.","title":"EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"},{"location":"Building_Blocks/EfficientNet:_Rethinking_Model_Scaling_for_Convolutional_Neural_Network/#efficientnet-rethinking-model-scaling-for-convolutional-neural-networks","text":"\u8fd9\u7bc7\u6587\u7ae0\u5206\u6790\u4e86CNN Scale Up\u7684\u76f8\u5173\u539f\u7406\uff0c\u7136\u540e\u7ed9\u51faEfficientNet.\u80cc\u540e\u7684\u903b\u8f91\u662f\u8fd9\u6837\u7684\uff0c\u9996\u5148\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7Neural Architecture Search\u5f97\u5230\u4e00\u4e2a\u4f4e\u5206\u8fa8\u7387\u56fe\u7247\u7684\u9ad8\u6548\u7387\u6a21\u578b\uff0c\u7136\u540e\u4f9d\u636e\u5b83\u5bf9\u5e94\u7684Scale Up\u539f\u7406\u8fdb\u884c\u6269\u5c55\u3002\u672c\u6587\u7528\u5230\u7684baseline\u51fa\u81ea MnasNet(pdf) ,\u5c31\u662f\u901a\u8fc7NAS\u5f97\u5230\u7684\u3002\u672c\u6587\u7684 \u4ee3\u7801 \u63d0\u4f9b\u4e86keras\u4ee5\u53caTensorflow\u5b9e\u73b0\u3002\u8fd9\u4e2a repo\u63d0\u4f9b\u4e86pytorch\u5b9e\u73b0 \u8fd9\u91cc\u6dfb\u52a0\u4e00\u4e2a medium\u4e0a\u7684\u89e3\u8bfb .","title":"EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"},{"location":"Building_Blocks/EfficientNet:_Rethinking_Model_Scaling_for_Convolutional_Neural_Network/#model-scaling-observation","text":"\u4e0a\u56fe\u5c55\u793a\u7684\u662f\u4e0d\u540c\u7684scale up\u4e00\u4e2a\u6a21\u578b\u7684\u65b9\u5f0f\u3002\u672c\u6587\u7684\u7ed3\u8bba\u662f\u5e94\u8be5\u6839\u636e\u8f93\u5165\u56fe\u7247\u7684\u5206\u8fa8\u7387\u3001channel\u6570\u76ee\u4ee5\u53ca\u7f51\u7edc\u6df1\u5ea6\u7efc\u5408Scale Up\u5f97\u5230\u7684\u63d0\u5347\u624d\u662f\u6700\u660e\u663e\u7684\u3002 \u4e0a\u56fe\u5c55\u793a\u7684\u662f\u5206\u522b\u53eaScale Up\u7f51\u7edcchannel\u6570,\u7f51\u7edc\u6df1\u5ea6,\u4ee5\u53ca\u56fe\u7247\u5206\u8fa8\u7387\u5f97\u5230\u7684\u3002\u4f5c\u8005\u7684\u7ed3\u8bba\u662f\u53eaScale Up\u4e00\u4e2a\u56e0\u5b50\u5f88\u5bb9\u6613\u5f97\u5230Saturation\uff0c\u901a\u8fc7\u53e6\u4e00\u4e2a\u5b9e\u9a8c\u53d1\u73b0\u603b\u5408\u4e00\u8d77Scale Up\u80fd\u5f97\u5230\u66f4\u597d\u7684\u7ed3\u679c\u3002","title":"Model Scaling Observation"},{"location":"Building_Blocks/EfficientNet:_Rethinking_Model_Scaling_for_Convolutional_Neural_Network/#compound-scaling-method","text":"\\begin{aligned} \\text { depth: } d &=\\alpha^{\\phi} \\\\ \\text { width: } w &=\\beta^{\\phi} \\\\ \\text { resolution: } r &=\\gamma^{\\phi} \\\\ \\text { s.t. } \\alpha & \\cdot \\beta^{2} \\cdot \\gamma^{2} \\approx 2 \\\\ \\alpha & \\geq 1, \\beta \\geq 1, \\gamma \\geq 1 \\end{aligned} \u4f5c\u8005\u9009\u62e9\u8fd9\u4e2a\u7684\u539f\u56e0\u662f\u56e0\u4e3aFLOPS(\u6d6e\u70b9\u8fd0\u7b97\u6570)\u6b63\u6bd4\u4e8e\u6df1\u5ea6,\u9891\u9053\u6570\u7684\u5e73\u65b9\u4ee5\u53ca\u5206\u8fa8\u7387\u7684\u5e73\u65b9\u3002","title":"Compound Scaling Method"},{"location":"Building_Blocks/EfficientNet:_Rethinking_Model_Scaling_for_Convolutional_Neural_Network/#efficient-net","text":"EfficientNet\u7684\u57fa\u672c\u5355\u5143\u7531 Mobile Conv(pdf) \u7ec4\u6210\u3002 \u4ece\u8fd9\u4e2aBaseLine\u5f00\u59cb\uff0c\u901a\u8fc7\u5c0fgrid-search\u5f97\u5230 \\alpha, \\beta, \\gamma \u7684\u521d\u59cb\u503c,\u66f4\u6539 \\phi \u5f97\u5230\u4e0d\u540c\u7684channel\u6570,\u5206\u8fa8\u7387\u4ee5\u53ca\u7f51\u7edc\u5c42\u6570(\u7f51\u7edc\u5c42\u6570\u7684\u66f4\u6539\u662f\u901a\u8fc7\u66f4\u6539\u5806\u53e0MBConv\u7684\u4e00\u4e2afor\u5faa\u73af\u7684\u5faa\u73af\u6b21\u6570\u5b9e\u73b0\u7684)","title":"Efficient Net"},{"location":"Building_Blocks/EfficientNet:_Rethinking_Model_Scaling_for_Convolutional_Neural_Network/#_1","text":"\u672c\u6587\u9996\u5148\u5c1d\u8bd5Scale Up\u4e86MobileNet\u4ee5\u53caResNet\u7684\u5230\u597d\u7684\u7ed3\u679c\uff0c\u7136\u540e\u5f00\u59cbScale Up EfficientNet, \u4ee5\u4e0b\u56fe\u4e2d\u5404\u4e2a\u7f51\u7edc\u7684\u51c6\u786e\u7387\u3001\u53c2\u6570\u4ee5\u53caFLOPS\u662f\u4e00\u4e2a\u5f88\u597d\u7684\u53c2\u8003.","title":"\u5b9e\u9a8c\u4e0e\u7ed3\u679c"},{"location":"Building_Blocks/Lookahead Optimizer ksteps forward, 1 step back/","text":"Lookahead Optimizer:ksteps forward, 1 step back \u672c\u8d28\u4e0a\u6765\u8bf4\u5c31\u662f\u4fdd\u5b58\u4e24\u5957\u53c2\u6570\u503c\uff0c\u7528\u4e00\u5957\u53c2\u6570\u503c\u6b63\u5e38\u66f4\u65b0N\u6b65(\u6bcf\u53d8\u4e00\u6b21\u9700\u8981\u4f7f\u7528\u65b0\u7684\u6743\u503c\u8ba1\u7b97\u66f4\u65b0\u65b9\u5411)\uff0c\u7136\u540e\u7528\u7b2c\u4e8c\u5957\u53c2\u6570\u5f80\u6700\u7ec8\u8fd9N\u6b65\u7684\u603b\u66f4\u65b0\u65b9\u5411\u8d70\u4e00\u6b65","title":"Lookahead Optimizer:ksteps forward, 1 step back"},{"location":"Building_Blocks/Lookahead Optimizer ksteps forward, 1 step back/#lookahead-optimizerksteps-forward-1-step-back","text":"\u672c\u8d28\u4e0a\u6765\u8bf4\u5c31\u662f\u4fdd\u5b58\u4e24\u5957\u53c2\u6570\u503c\uff0c\u7528\u4e00\u5957\u53c2\u6570\u503c\u6b63\u5e38\u66f4\u65b0N\u6b65(\u6bcf\u53d8\u4e00\u6b21\u9700\u8981\u4f7f\u7528\u65b0\u7684\u6743\u503c\u8ba1\u7b97\u66f4\u65b0\u65b9\u5411)\uff0c\u7136\u540e\u7528\u7b2c\u4e8c\u5957\u53c2\u6570\u5f80\u6700\u7ec8\u8fd9N\u6b65\u7684\u603b\u66f4\u65b0\u65b9\u5411\u8d70\u4e00\u6b65","title":"Lookahead Optimizer:ksteps forward, 1 step back"},{"location":"Building_Blocks/Non-local Neural Networks/","text":"Non-local Neural Networks non-local\u5355\u5143\u662f\u53e6\u4e00\u4e2a\u53ef\u4ee5\u663e\u8457\u63d0\u9ad83D,2D\u5377\u79ef\u7f51\u7edc\u7684\u611f\u53d7\u91ce \u6a21\u5757\u7ed3\u6784 \u56fe\u4e2d\u7ed9\u51fa\u7684\u662f\u7b80\u6d01\u660e\u4e86\u7684non-local\u6a21\u5757\u7684\u5177\u4f53\u7b97\u6cd5\u3002\u6bcf\u4e00\u4e2a\u84dd\u8272\u7684[1x1x1]\u8868\u660e\u4e00\u6b21channel-wise Conv\u3002 \u4ee5\u4e0b\u4e3a\u51e0\u4e2a\u76f4\u89c9\u4ee5\u53ca\u5f15\u7533 1. \u5728\u56fe\u4e2d\u5220\u9664T\u7ef4\u5ea6\u4e0d\u5f71\u54cd\u5168\u56fe\u7ed3\u6784\u4e0e\u53ef\u884c\u6027\uff0c\u4e5f\u4e0d\u5f71\u54cd\u6548\u679c\uff0c\u56e0\u800cnon-local\u4e5f\u53ef\u4ee5\u7528\u4e8e\u56fe\u7247\u3002 2. non_local\u6838\u5fc3\u662f f(x_i,x_j) = e^{x_i^T x_j} ,\u76f4\u89c9\u4e0a\u6765\u8bf4\uff0c\u4f1a\u8ba9\u4e0d\u540c\u65f6\u7a7a\u4f4d\u7f6e\u4e0a\u76f8\u4f3c\u7684\u7279\u5f81\u5f97\u5230\u8f83\u9ad8\u7684\u6fc0\u6d3b\u503c\uff0c\u5728\u540e\u9762\u4e5f\u5c31\u4f7f\u5f97\u56fe\u50cf\u4e0a\u4e00\u4e2a\u70b9\u7684feature map\u53ef\u4ee5\u878d\u5408\u4e0e\u5b83\u76f8\u4f3c\u7684\u5730\u65b9\u7684\u4fe1\u606f\u3002\u5728\u89c6\u9891\u5904\u7406\u4e2d\u6709\u4e00\u4e2a\u8f85\u52a9\u7269\u4f53\u8ddf\u8e2a\u7684\u6548\u679c\u3002 3. \u5f53feature map\u957f\u5bbd\u6bd4\u8f83\u5c0f\u7684\u65f6\u5019\u6548\u679c\u597d\u4e14\u8fd0\u7b97\u901f\u5ea6\u5feb\uff0c\u4f46\u662f\u5f53\u957f\u5bbd\u5f88\u5927\u7684\u65f6\u5019\u8fd0\u7b97\u4f1a\u5f88\u6162\uff0c\u56e0\u4e3a\u4f1a\u6709\u6570\u4e07\u7ef4\u7684\u77e9\u9635\u76f8\u4e58\uff0c\u8fd0\u7b97\u56fe\u4e5f\u4f1a\u590d\u6742\u3002 4. \u53ef\u4ee5\u9002\u5f53\u5220\u6539\u91cc\u9762\u51e0\u4e2a\u5377\u79ef\u64cd\u4f5c\u4ee5\u53casoftmax\u64cd\u4f5c\u3002","title":"Non-local Neural Networks"},{"location":"Building_Blocks/Non-local Neural Networks/#non-local-neural-networks","text":"non-local\u5355\u5143\u662f\u53e6\u4e00\u4e2a\u53ef\u4ee5\u663e\u8457\u63d0\u9ad83D,2D\u5377\u79ef\u7f51\u7edc\u7684\u611f\u53d7\u91ce","title":"Non-local Neural Networks"},{"location":"Building_Blocks/Non-local Neural Networks/#_1","text":"\u56fe\u4e2d\u7ed9\u51fa\u7684\u662f\u7b80\u6d01\u660e\u4e86\u7684non-local\u6a21\u5757\u7684\u5177\u4f53\u7b97\u6cd5\u3002\u6bcf\u4e00\u4e2a\u84dd\u8272\u7684[1x1x1]\u8868\u660e\u4e00\u6b21channel-wise Conv\u3002 \u4ee5\u4e0b\u4e3a\u51e0\u4e2a\u76f4\u89c9\u4ee5\u53ca\u5f15\u7533 1. \u5728\u56fe\u4e2d\u5220\u9664T\u7ef4\u5ea6\u4e0d\u5f71\u54cd\u5168\u56fe\u7ed3\u6784\u4e0e\u53ef\u884c\u6027\uff0c\u4e5f\u4e0d\u5f71\u54cd\u6548\u679c\uff0c\u56e0\u800cnon-local\u4e5f\u53ef\u4ee5\u7528\u4e8e\u56fe\u7247\u3002 2. non_local\u6838\u5fc3\u662f f(x_i,x_j) = e^{x_i^T x_j} ,\u76f4\u89c9\u4e0a\u6765\u8bf4\uff0c\u4f1a\u8ba9\u4e0d\u540c\u65f6\u7a7a\u4f4d\u7f6e\u4e0a\u76f8\u4f3c\u7684\u7279\u5f81\u5f97\u5230\u8f83\u9ad8\u7684\u6fc0\u6d3b\u503c\uff0c\u5728\u540e\u9762\u4e5f\u5c31\u4f7f\u5f97\u56fe\u50cf\u4e0a\u4e00\u4e2a\u70b9\u7684feature map\u53ef\u4ee5\u878d\u5408\u4e0e\u5b83\u76f8\u4f3c\u7684\u5730\u65b9\u7684\u4fe1\u606f\u3002\u5728\u89c6\u9891\u5904\u7406\u4e2d\u6709\u4e00\u4e2a\u8f85\u52a9\u7269\u4f53\u8ddf\u8e2a\u7684\u6548\u679c\u3002 3. \u5f53feature map\u957f\u5bbd\u6bd4\u8f83\u5c0f\u7684\u65f6\u5019\u6548\u679c\u597d\u4e14\u8fd0\u7b97\u901f\u5ea6\u5feb\uff0c\u4f46\u662f\u5f53\u957f\u5bbd\u5f88\u5927\u7684\u65f6\u5019\u8fd0\u7b97\u4f1a\u5f88\u6162\uff0c\u56e0\u4e3a\u4f1a\u6709\u6570\u4e07\u7ef4\u7684\u77e9\u9635\u76f8\u4e58\uff0c\u8fd0\u7b97\u56fe\u4e5f\u4f1a\u590d\u6742\u3002 4. \u53ef\u4ee5\u9002\u5f53\u5220\u6539\u91cc\u9762\u51e0\u4e2a\u5377\u79ef\u64cd\u4f5c\u4ee5\u53casoftmax\u64cd\u4f5c\u3002","title":"\u6a21\u5757\u7ed3\u6784"},{"location":"Building_Blocks/On_Multiplicative_Integration_with_Recurrent_Neural_Networks/","text":"On Multiplicative Integration with Recurrent Neural Networks \u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e00\u4e2a\u5728CAPs\u6a21\u578b\u63d0\u51fa\u7684 \u6587\u7ae0 \u4e2d\u4f7f\u7528\u7684Multiplicative Integration RNN(LSTM, GRU) \u672c\u8d28\u516c\u5f0f\u5c31\u662f \\phi\\left(\\boldsymbol{\\alpha} \\odot \\mathbf{W} \\boldsymbol{x} \\odot \\mathbf{U} \\boldsymbol{z}+\\boldsymbol{\\beta}_{1} \\odot \\mathbf{U} \\boldsymbol{z}+\\boldsymbol{\\beta}_{2} \\odot \\mathbf{W} \\boldsymbol{x}+\\boldsymbol{b}\\right) \u5176\u4e2d \\odot \u8868\u793a\u7684\u662f\u76f8\u540c\u5f62\u72b6\u7684\u77e9\u9635\u4e4b\u95f4\u7684\u5143\u7d20\u5bf9\u5e94\u4e58\u79ef\uff0c\u79f0\u4e3aHadamard product\u3002 \u76f4\u89c9\u662f\u4fc3\u8fdb\u4e86\u4e24\u4e2a\u4fe1\u606f\u6e90 x, z \u7684\u4fe1\u606f\u4ea4\u6d41\uff0c\u540c\u65f6\u4f18\u5316 Uz \u7684\u68af\u5ea6\u6d41\u901a,\u8fd9\u4e2a\u5728\u65f6\u5e8f\u6a21\u578b\u4e2d\u8f83\u4e3a\u91cd\u8981\u3002 \u8fd9\u4e2a github repo\u63d0\u4f9b\u4e86keras\u7684\u6267\u884c\u3002 \u5177\u4f53\u516c\u5f0f\u7684\u66ff\u6362\u5982\u4e0b:","title":"On Multiplicative Integration with Recurrent Neural Networks"},{"location":"Building_Blocks/On_Multiplicative_Integration_with_Recurrent_Neural_Networks/#on-multiplicative-integration-with-recurrent-neural-networks","text":"\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e00\u4e2a\u5728CAPs\u6a21\u578b\u63d0\u51fa\u7684 \u6587\u7ae0 \u4e2d\u4f7f\u7528\u7684Multiplicative Integration RNN(LSTM, GRU) \u672c\u8d28\u516c\u5f0f\u5c31\u662f \\phi\\left(\\boldsymbol{\\alpha} \\odot \\mathbf{W} \\boldsymbol{x} \\odot \\mathbf{U} \\boldsymbol{z}+\\boldsymbol{\\beta}_{1} \\odot \\mathbf{U} \\boldsymbol{z}+\\boldsymbol{\\beta}_{2} \\odot \\mathbf{W} \\boldsymbol{x}+\\boldsymbol{b}\\right) \u5176\u4e2d \\odot \u8868\u793a\u7684\u662f\u76f8\u540c\u5f62\u72b6\u7684\u77e9\u9635\u4e4b\u95f4\u7684\u5143\u7d20\u5bf9\u5e94\u4e58\u79ef\uff0c\u79f0\u4e3aHadamard product\u3002 \u76f4\u89c9\u662f\u4fc3\u8fdb\u4e86\u4e24\u4e2a\u4fe1\u606f\u6e90 x, z \u7684\u4fe1\u606f\u4ea4\u6d41\uff0c\u540c\u65f6\u4f18\u5316 Uz \u7684\u68af\u5ea6\u6d41\u901a,\u8fd9\u4e2a\u5728\u65f6\u5e8f\u6a21\u578b\u4e2d\u8f83\u4e3a\u91cd\u8981\u3002 \u8fd9\u4e2a github repo\u63d0\u4f9b\u4e86keras\u7684\u6267\u884c\u3002 \u5177\u4f53\u516c\u5f0f\u7684\u66ff\u6362\u5982\u4e0b:","title":"On Multiplicative Integration with Recurrent Neural Networks"},{"location":"Building_Blocks/SQUEEZENET_ALEXNET-LEVEL_ACCURACY_WITH_50X_FEWER_PARAMETERS_AND_0.5MB_MODEL_SIZE/","text":"SQUEEZENET: ALEXNET-LEVEL ACCURACY WITH 50X FEWER PARAMETERS AND <0.5MB MODEL SIZE \u672c\u6587\u63d0\u51fa\u4e86\u4f53\u79ef\u5c0f\u7684\u7f51\u7edc\u6709\u4ec0\u4e48\u597d\u5904\uff0c\u5e76\u4e14\u7ed9\u51fa\u4e86SqueezeNet\u7684\u5177\u4f53\u7ed3\u6784\u4ee5\u53ca\u76f8\u5173\u8ba8\u8bba \u7f51\u7edc\u7ed3\u6784\u8bbe\u8ba1\u7b56\u7565 \u5c06 3\\times 3 \u5377\u79ef\u6838\u8f6c\u6362\u4e3a 1\\times 1 \u964d\u4f4e\u8f93\u5165\u5230 3\\times 3 \u5377\u79ef\u7684\u7f51\u7edc\u8f93\u5165channel\u6570 \u5728\u8f83\u540e\u7684\u4f4d\u7f6e\u518d\u8fdb\u884c\u4e0b\u91c7\u6837\uff0c\u4ee5\u6b64\u63d0\u5347\u5377\u79ef\u5c42\u7684FOV Fire Module \u4e00\u4e2afire module\u7531: 1. squeeze layer(\u4ec5\u6709 1\\times 1 \u5377\u79ef\u7ec4\u6210) 2. expand layer(\u6df7\u5408 1\\times 1 \u5377\u79ef\u4e0e 3\\times 3 \u5377\u79ef) \u7b80\u5355\u6765\u8bf4\u5c31\u662f\u5148\u7528 1\\times 1 \u5377\u79ef\u964d\u4f4e\u8f93\u5165\u7684channel\u6570\uff0c\u7136\u540e\u5c06\u4e3b\u8f93\u51fa\u7684\u5c42\u90e8\u5206\u7528 1\\times 1 \u66ff\u4ee3\u3002 SqueezeNet\u7ed3\u6784 \u672c\u6587\u7b2c5\u7ae0\u8fd8\u8fdb\u4e00\u6b65\u8ba8\u8bba\u4e86Fire Module\u8fd8\u6709\u5b8f\u89c2\u7ed3\u6784\u4e2d\u7684\u4e00\u7cfb\u5217\u5177\u4f53\u53c2\u6570\u3002","title":"SQUEEZENET: ALEXNET-LEVEL ACCURACY WITH 50X FEWER PARAMETERS AND <0.5MB MODEL SIZE"},{"location":"Building_Blocks/SQUEEZENET_ALEXNET-LEVEL_ACCURACY_WITH_50X_FEWER_PARAMETERS_AND_0.5MB_MODEL_SIZE/#squeezenet-alexnet-level-accuracy-with-50x-fewer-parameters-and-05mb-model-size","text":"\u672c\u6587\u63d0\u51fa\u4e86\u4f53\u79ef\u5c0f\u7684\u7f51\u7edc\u6709\u4ec0\u4e48\u597d\u5904\uff0c\u5e76\u4e14\u7ed9\u51fa\u4e86SqueezeNet\u7684\u5177\u4f53\u7ed3\u6784\u4ee5\u53ca\u76f8\u5173\u8ba8\u8bba","title":"SQUEEZENET: ALEXNET-LEVEL ACCURACY WITH 50X FEWER PARAMETERS AND &lt;0.5MB MODEL SIZE"},{"location":"Building_Blocks/SQUEEZENET_ALEXNET-LEVEL_ACCURACY_WITH_50X_FEWER_PARAMETERS_AND_0.5MB_MODEL_SIZE/#_1","text":"\u5c06 3\\times 3 \u5377\u79ef\u6838\u8f6c\u6362\u4e3a 1\\times 1 \u964d\u4f4e\u8f93\u5165\u5230 3\\times 3 \u5377\u79ef\u7684\u7f51\u7edc\u8f93\u5165channel\u6570 \u5728\u8f83\u540e\u7684\u4f4d\u7f6e\u518d\u8fdb\u884c\u4e0b\u91c7\u6837\uff0c\u4ee5\u6b64\u63d0\u5347\u5377\u79ef\u5c42\u7684FOV","title":"\u7f51\u7edc\u7ed3\u6784\u8bbe\u8ba1\u7b56\u7565"},{"location":"Building_Blocks/SQUEEZENET_ALEXNET-LEVEL_ACCURACY_WITH_50X_FEWER_PARAMETERS_AND_0.5MB_MODEL_SIZE/#fire-module","text":"\u4e00\u4e2afire module\u7531: 1. squeeze layer(\u4ec5\u6709 1\\times 1 \u5377\u79ef\u7ec4\u6210) 2. expand layer(\u6df7\u5408 1\\times 1 \u5377\u79ef\u4e0e 3\\times 3 \u5377\u79ef) \u7b80\u5355\u6765\u8bf4\u5c31\u662f\u5148\u7528 1\\times 1 \u5377\u79ef\u964d\u4f4e\u8f93\u5165\u7684channel\u6570\uff0c\u7136\u540e\u5c06\u4e3b\u8f93\u51fa\u7684\u5c42\u90e8\u5206\u7528 1\\times 1 \u66ff\u4ee3\u3002","title":"Fire Module"},{"location":"Building_Blocks/SQUEEZENET_ALEXNET-LEVEL_ACCURACY_WITH_50X_FEWER_PARAMETERS_AND_0.5MB_MODEL_SIZE/#squeezenet","text":"\u672c\u6587\u7b2c5\u7ae0\u8fd8\u8fdb\u4e00\u6b65\u8ba8\u8bba\u4e86Fire Module\u8fd8\u6709\u5b8f\u89c2\u7ed3\u6784\u4e2d\u7684\u4e00\u7cfb\u5217\u5177\u4f53\u53c2\u6570\u3002","title":"SqueezeNet\u7ed3\u6784"},{"location":"Building_Blocks/Squeeze-and-Excitation Networks/","text":"Squeeze-and-Excitation Networks \u8fd9\u7bc7\u8bba\u6587\u7ed9\u51fa\u4e86squeeze-and-excitation\u65b9\u6cd5\u6765\u63d0\u9ad8\u5377\u79ef\u7684\u611f\u53d7\u573a\u5927\u5c0f\u3002 \u8ba1\u7b97\u5355\u5143\u7ed3\u6784 F_{tr} \u4e3a\u57fa\u7840\u5377\u79ef\u64cd\u4f5c\uff0c F_{sq} \u4e3a\u4e00\u4e2a\u5168\u56fe(H*W)\u7684average pool. F_{ex} = \\sigma(W_2\\sigma(W_1z)) \uff0c\u5c31\u662f\u4e00\u4e2aencoder\u3001decoder\u7684\u7ed3\u6784\uff0c F_{scale} \u5219\u662f\u4e00\u4e2achannel-wise\u7684\u70b9\u4e58(scalar and a H\\times W feature map) \u4f5c\u8005\u8868\u793a\u8fd9\u53ef\u4ee5\u7406\u89e3\u4e3a\u4e00\u4e2a\u81ea\u6ce8\u610f\u529b\u51fd\u6570","title":"Squeeze-and-Excitation Networks"},{"location":"Building_Blocks/Squeeze-and-Excitation Networks/#squeeze-and-excitation-networks","text":"\u8fd9\u7bc7\u8bba\u6587\u7ed9\u51fa\u4e86squeeze-and-excitation\u65b9\u6cd5\u6765\u63d0\u9ad8\u5377\u79ef\u7684\u611f\u53d7\u573a\u5927\u5c0f\u3002","title":"Squeeze-and-Excitation Networks"},{"location":"Building_Blocks/Squeeze-and-Excitation Networks/#_1","text":"F_{tr} \u4e3a\u57fa\u7840\u5377\u79ef\u64cd\u4f5c\uff0c F_{sq} \u4e3a\u4e00\u4e2a\u5168\u56fe(H*W)\u7684average pool. F_{ex} = \\sigma(W_2\\sigma(W_1z)) \uff0c\u5c31\u662f\u4e00\u4e2aencoder\u3001decoder\u7684\u7ed3\u6784\uff0c F_{scale} \u5219\u662f\u4e00\u4e2achannel-wise\u7684\u70b9\u4e58(scalar and a H\\times W feature map) \u4f5c\u8005\u8868\u793a\u8fd9\u53ef\u4ee5\u7406\u89e3\u4e3a\u4e00\u4e2a\u81ea\u6ce8\u610f\u529b\u51fd\u6570","title":"\u8ba1\u7b97\u5355\u5143\u7ed3\u6784"},{"location":"Building_Blocks/Stacked_Hourglass_Networks_for_Human_Pose_Estimation/","text":"Stacked Hourglass Networks for Human Pose Estimation \u8fd9\u7bc7\u6587\u7ae0\u76ee\u524d\u5bf9\u4e8e\u672c\u4eba\u6765\u8bf4\u662f \u8fd9\u7bc7\u6587\u7ae0 \u7684\u524d\u7f6e. \u76ee\u524d(2019-10-13)\uff0c\u6211\u4eec\u4e3b\u8981\u8ba8\u8bba\u672c\u6587\u63d0\u5230\u7684HourGlass \u6a21\u5757 HourGlass \u8fd9\u4e2a\u6a21\u5757\u7684\u8bbe\u8ba1\u8d77\u6e90\u4e8e\u5bf9\u591ascale\u7279\u5f81\u8f93\u51fa\u63d0\u53d6\u7684\u9700\u6c42\u3002\u7b80\u5355\u800c\u8a00\u5c31\u662f\u5728\u6bcf\u4e00\u4e2ascale\uff0c\u8fdb\u884c\u5206\u652f\uff0c\u4e00\u90e8\u5206\u6267\u884c\u4e00\u6b21\u5377\u79ef\u7b49\u5f85\u8fdb\u4e00\u6b65\u4f7f\u7528\u3002\u53e6\u4e00\u90e8\u5206\u6267\u884cmax-pooling\u4e0b\u91c7\u6837\u3002\u53bb\u5230\u6700\u5c0ffeatrue maps\u540e\uff0c\u4f7f\u7528Neareast pooling\u4e0a\u91c7\u6837\uff0c\u4e0e\u540cscale\u7684\u5148\u524d\u7559\u4e0b\u7684\u6b8b\u5dee\u8fdb\u884celement-wise\u76f8\u52a0 \u672c\u6587\u540e\u9762\u63d0\u5230\u8fd9\u91cc\u7684\u5377\u79ef\u53ef\u4ee5\u4f7f\u7528\u4e0d\u540c\u7684\u65b9\u5f0f\u5b9e\u73b0\uff0c\u6bd4\u5982\u672c\u6587\u4f3c\u4e4e\u5c31\u662f\u4f7f\u7528\u4e00\u4e2a\u590d\u6742\u7684Res\u7ed3\u6784\u5b9e\u73b0\u7684\u3002\u5177\u4f53\u8fd8\u9700\u8981\u770b\u4ee3\u7801\u3002","title":"Stacked Hourglass Networks for Human Pose Estimation"},{"location":"Building_Blocks/Stacked_Hourglass_Networks_for_Human_Pose_Estimation/#stacked-hourglass-networks-for-human-pose-estimation","text":"\u8fd9\u7bc7\u6587\u7ae0\u76ee\u524d\u5bf9\u4e8e\u672c\u4eba\u6765\u8bf4\u662f \u8fd9\u7bc7\u6587\u7ae0 \u7684\u524d\u7f6e. \u76ee\u524d(2019-10-13)\uff0c\u6211\u4eec\u4e3b\u8981\u8ba8\u8bba\u672c\u6587\u63d0\u5230\u7684HourGlass \u6a21\u5757","title":"Stacked Hourglass Networks for Human Pose Estimation"},{"location":"Building_Blocks/Stacked_Hourglass_Networks_for_Human_Pose_Estimation/#hourglass","text":"\u8fd9\u4e2a\u6a21\u5757\u7684\u8bbe\u8ba1\u8d77\u6e90\u4e8e\u5bf9\u591ascale\u7279\u5f81\u8f93\u51fa\u63d0\u53d6\u7684\u9700\u6c42\u3002\u7b80\u5355\u800c\u8a00\u5c31\u662f\u5728\u6bcf\u4e00\u4e2ascale\uff0c\u8fdb\u884c\u5206\u652f\uff0c\u4e00\u90e8\u5206\u6267\u884c\u4e00\u6b21\u5377\u79ef\u7b49\u5f85\u8fdb\u4e00\u6b65\u4f7f\u7528\u3002\u53e6\u4e00\u90e8\u5206\u6267\u884cmax-pooling\u4e0b\u91c7\u6837\u3002\u53bb\u5230\u6700\u5c0ffeatrue maps\u540e\uff0c\u4f7f\u7528Neareast pooling\u4e0a\u91c7\u6837\uff0c\u4e0e\u540cscale\u7684\u5148\u524d\u7559\u4e0b\u7684\u6b8b\u5dee\u8fdb\u884celement-wise\u76f8\u52a0 \u672c\u6587\u540e\u9762\u63d0\u5230\u8fd9\u91cc\u7684\u5377\u79ef\u53ef\u4ee5\u4f7f\u7528\u4e0d\u540c\u7684\u65b9\u5f0f\u5b9e\u73b0\uff0c\u6bd4\u5982\u672c\u6587\u4f3c\u4e4e\u5c31\u662f\u4f7f\u7528\u4e00\u4e2a\u590d\u6742\u7684Res\u7ed3\u6784\u5b9e\u73b0\u7684\u3002\u5177\u4f53\u8fd8\u9700\u8981\u770b\u4ee3\u7801\u3002","title":"HourGlass"},{"location":"Building_Blocks/TensorMask:_A_Foundation_for_Dense_Object_Segmentation/","text":"TensorMask: A Foundation for Dense Object Segmentation \u8fd9\u7bc7\u6587\u7ae0\u63d0\u51fa\u4e86one-stage instance segmentation\u7684\u7b97\u6cd5\u3002\u4f20\u7edf\u6765\u8bf4\uff0cstate of the art \u7684instance segmentation\u7684\u505a\u6cd5\u57fa\u672c\u4e0a\u662f\u5148\u8fdb\u884cobject detection\u5f97\u52302D\u6846\uff0c\u7136\u540e\u5728\u6846\u5185\u8fdb\u884cSemantic Segmentation\u3002\u8fd9\u6837\u7684two-stage\u751a\u81f3\u662fMulti-stage\u7684\u505a\u6cd5(object detection\u53ef\u80fd\u5c31two-stage).\u8fd8\u6709\u4e00\u79cd\u505a\u6cd5\u662f\u5148\u751f\u6210label pixel\u7136\u540e\u8fdb\u884c\u805a\u7c7b\u3002 \u672c\u6587\u6838\u5fc3\u601d\u8def\u5c31\u662f\u5c06\u6574\u4e2a\u95ee\u9898\u8f6c\u6362\u4e3a\u4e00\u4e2a\u56db\u7ef4\u5f20\u91cf (V, U, H, W) \u7684\u56de\u5f52or\u5206\u7c7b\u95ee\u9898\u3002\u5bf9\u6bcf\u4e00\u4e2a\u5750\u6807\u70b9 (h, w) \u5bf9\u5e94\u4e00\u4e2a\u77e9\u9635 (V, U) \uff0c\u8bbe \\alpha \u4e3a\u5355\u4f4d\u8f6c\u6362\u6bd4\u4f8b\uff0c\u5219\u77e9\u9635\u4e2d\u7684\u5143\u7d20 (v, u) \u6307\u4ee3\u539f\u56fe (h + \\alpha v, w + \\alpha u) \u662fmask\u7684\u6982\u7387\uff0c\u6216\u5176\u4ed6\u53c2\u6570\u3002\u8fd9\u6837\u6574\u4e2a\u7f51\u7edc\u7684\u8bad\u7ec3\u76ee\u6807\u5c31\u548c\u4e00\u4e2a SSD \u6216\u8005\u8bf4Yolo\u5dee\u4e0d\u591a\u4e86,\u8fd9\u540c\u65f6\u53c8\u548cDeepMask\u4e0d\u540c\uff0c\u663e\u5f0f\u5730\u8868\u8fbe U, V \u5750\u6807\uff0c\u5e76\u4e3a\u6b64\u9002\u914d\u66f4\u591a\u7684\u8fd0\u7b97\u65b9\u5f0f. \u4e3b\u8981\u8868\u8fbe\u65b9\u5f0f\u7684\u5b9a\u4e49 Natural Representation \u8868\u8fbe\u4e3a (V, U, H, W) ,\u5bf9\u4e8e\u4e00\u4e2a4D (V,U,H,W) \u7684\u5f20\u91cf\uff0c\u5b83\u5728 (v, u, y, x) \u7684\u503c\u4ee3\u8868\u5728\u4e00\u4e2a\u4e2d\u5fc3\u5728 (y,x) \u7684\u5927\u5c0f\u4e3a \\alpha V \\times \\alpha U \u7a97\u53e3\u7684\u70b9 (y + \\alpha v, x + \\alpha u) \u7684mask\u503c\u3002 Aligned Representation \u5bf9\u4e00\u4e2a4D (\\hat V, \\hat U, \\hat H, \\hat W) \u7684\u5f20\u91cf\uff0c\u5b83\u5728 (\\hat v, \\hat u, \\hat y, \\hat x) \u7684\u503c\u4ee3\u8868\u5728\u4e00\u4e2a\u4e2d\u5fc3\u5728 (\\hat y, \\hat x) \u7684\u5927\u5c0f\u4e3a \\hat\\alpha \\hat V \\times \\hat\\alpha \\hat U \u7a97\u53e3\u7684\u70b9 (\\hat y - \\hat\\alpha \\hat v, \\hat x - \\hat\\alpha \\hat u) \u7684mask\u503c\u3002 \u5173\u952e\u7684\u7406\u89e3\u662f\u5728\u5750\u6807 (\\hat y, \\hat x) \u4e0a\u7684\u5b50\u77e9\u9635 (\\hat V, \\hat U) \uff0c\u4e0a\u7684\u6240\u6709\u503c\u90fd\u662f\u5728\u63cf\u8ff0\u8fd9\u4e2a\u5750\u6807 (\\hat y, \\hat x) \u7684\uff0c\u6240\u4ee5\u79f0\u4e3a\u4e3a aligned \u4e24\u8005\u7684\u5b9a\u4e49\u53ef\u4ee5\u7531\u8fd9\u5f20\u56fe\u663e\u793a \u4e24\u8005\u7684\u8f6c\u6362\uff1a \\begin{aligned} \\mathcal{F}(v, u, y, x) &= \\hat\\mathcal{F}(v, u, y+\\alpha v, x + \\alpha u) \\\\ \\hat\\mathcal{F}(\\hat v, \\hat u, \\hat y, \\hat x) &= \\mathcal{F}(\\hat v, \\hat u, \\hat y - \\alpha\\hat v, \\hat x- \\alpha\\hat u) \\end{aligned} \u7f51\u7edc\u7ed3\u6784, \u8f93\u51faHead, \u7ec6\u8282\u7ed3\u6784, \u8bad\u7ec3\u7ec6\u8282 \u7f51\u7edc\u91c7\u7528FPN\u8f93\u51fa\u591a\u4e2a\u4e0d\u540c\u5c3a\u5ea6\u7684feature maps,\u5f62\u72b6 (C, \\frac{1}{2^k} H, \\frac{1}{2^k}W \u8f93\u51faHead \u672c\u6587\u6bd4\u8f83\u4e865\u79cd\u8f93\u51faHead. 4\u79cd\u662fbaseline, \u533a\u522b\u5728\u4e8e\u4e0d\u540cScale\u4e0a\u7684\u56fe\uff0c\u7b2c\u4e94\u4e2ahead\u4f1a\u8f93\u51fa\u76f8\u540c\u7cbe\u786e\u5ea6\u7684\u7f51\u683c \u5176\u4e2d\u7684\u7ec6\u8282\u8fd0\u7b97\u5982\u56fe \u8fd9\u4e9b\u7ec6\u8282\u8fd0\u7b97\u672c\u8d28\u4e0a\u90fd\u662f\u5750\u6807\u53d8\u6362\u4ee5\u53ca\u91c7\u6837 \u8bad\u7ec3\u7ec6\u8282 \u5bf9FPN\u7684\u5fae\u8c03 Label\u5206\u914d Fully Contain center of m is close to center of windows unique","title":"TensorMask: A Foundation for Dense Object Segmentation"},{"location":"Building_Blocks/TensorMask:_A_Foundation_for_Dense_Object_Segmentation/#tensormask-a-foundation-for-dense-object-segmentation","text":"\u8fd9\u7bc7\u6587\u7ae0\u63d0\u51fa\u4e86one-stage instance segmentation\u7684\u7b97\u6cd5\u3002\u4f20\u7edf\u6765\u8bf4\uff0cstate of the art \u7684instance segmentation\u7684\u505a\u6cd5\u57fa\u672c\u4e0a\u662f\u5148\u8fdb\u884cobject detection\u5f97\u52302D\u6846\uff0c\u7136\u540e\u5728\u6846\u5185\u8fdb\u884cSemantic Segmentation\u3002\u8fd9\u6837\u7684two-stage\u751a\u81f3\u662fMulti-stage\u7684\u505a\u6cd5(object detection\u53ef\u80fd\u5c31two-stage).\u8fd8\u6709\u4e00\u79cd\u505a\u6cd5\u662f\u5148\u751f\u6210label pixel\u7136\u540e\u8fdb\u884c\u805a\u7c7b\u3002 \u672c\u6587\u6838\u5fc3\u601d\u8def\u5c31\u662f\u5c06\u6574\u4e2a\u95ee\u9898\u8f6c\u6362\u4e3a\u4e00\u4e2a\u56db\u7ef4\u5f20\u91cf (V, U, H, W) \u7684\u56de\u5f52or\u5206\u7c7b\u95ee\u9898\u3002\u5bf9\u6bcf\u4e00\u4e2a\u5750\u6807\u70b9 (h, w) \u5bf9\u5e94\u4e00\u4e2a\u77e9\u9635 (V, U) \uff0c\u8bbe \\alpha \u4e3a\u5355\u4f4d\u8f6c\u6362\u6bd4\u4f8b\uff0c\u5219\u77e9\u9635\u4e2d\u7684\u5143\u7d20 (v, u) \u6307\u4ee3\u539f\u56fe (h + \\alpha v, w + \\alpha u) \u662fmask\u7684\u6982\u7387\uff0c\u6216\u5176\u4ed6\u53c2\u6570\u3002\u8fd9\u6837\u6574\u4e2a\u7f51\u7edc\u7684\u8bad\u7ec3\u76ee\u6807\u5c31\u548c\u4e00\u4e2a SSD \u6216\u8005\u8bf4Yolo\u5dee\u4e0d\u591a\u4e86,\u8fd9\u540c\u65f6\u53c8\u548cDeepMask\u4e0d\u540c\uff0c\u663e\u5f0f\u5730\u8868\u8fbe U, V \u5750\u6807\uff0c\u5e76\u4e3a\u6b64\u9002\u914d\u66f4\u591a\u7684\u8fd0\u7b97\u65b9\u5f0f.","title":"TensorMask: A Foundation for Dense Object Segmentation"},{"location":"Building_Blocks/TensorMask:_A_Foundation_for_Dense_Object_Segmentation/#_1","text":"","title":"\u4e3b\u8981\u8868\u8fbe\u65b9\u5f0f\u7684\u5b9a\u4e49"},{"location":"Building_Blocks/TensorMask:_A_Foundation_for_Dense_Object_Segmentation/#natural-representation","text":"\u8868\u8fbe\u4e3a (V, U, H, W) ,\u5bf9\u4e8e\u4e00\u4e2a4D (V,U,H,W) \u7684\u5f20\u91cf\uff0c\u5b83\u5728 (v, u, y, x) \u7684\u503c\u4ee3\u8868\u5728\u4e00\u4e2a\u4e2d\u5fc3\u5728 (y,x) \u7684\u5927\u5c0f\u4e3a \\alpha V \\times \\alpha U \u7a97\u53e3\u7684\u70b9 (y + \\alpha v, x + \\alpha u) \u7684mask\u503c\u3002","title":"Natural Representation"},{"location":"Building_Blocks/TensorMask:_A_Foundation_for_Dense_Object_Segmentation/#aligned-representation","text":"\u5bf9\u4e00\u4e2a4D (\\hat V, \\hat U, \\hat H, \\hat W) \u7684\u5f20\u91cf\uff0c\u5b83\u5728 (\\hat v, \\hat u, \\hat y, \\hat x) \u7684\u503c\u4ee3\u8868\u5728\u4e00\u4e2a\u4e2d\u5fc3\u5728 (\\hat y, \\hat x) \u7684\u5927\u5c0f\u4e3a \\hat\\alpha \\hat V \\times \\hat\\alpha \\hat U \u7a97\u53e3\u7684\u70b9 (\\hat y - \\hat\\alpha \\hat v, \\hat x - \\hat\\alpha \\hat u) \u7684mask\u503c\u3002 \u5173\u952e\u7684\u7406\u89e3\u662f\u5728\u5750\u6807 (\\hat y, \\hat x) \u4e0a\u7684\u5b50\u77e9\u9635 (\\hat V, \\hat U) \uff0c\u4e0a\u7684\u6240\u6709\u503c\u90fd\u662f\u5728\u63cf\u8ff0\u8fd9\u4e2a\u5750\u6807 (\\hat y, \\hat x) \u7684\uff0c\u6240\u4ee5\u79f0\u4e3a\u4e3a aligned \u4e24\u8005\u7684\u5b9a\u4e49\u53ef\u4ee5\u7531\u8fd9\u5f20\u56fe\u663e\u793a \u4e24\u8005\u7684\u8f6c\u6362\uff1a \\begin{aligned} \\mathcal{F}(v, u, y, x) &= \\hat\\mathcal{F}(v, u, y+\\alpha v, x + \\alpha u) \\\\ \\hat\\mathcal{F}(\\hat v, \\hat u, \\hat y, \\hat x) &= \\mathcal{F}(\\hat v, \\hat u, \\hat y - \\alpha\\hat v, \\hat x- \\alpha\\hat u) \\end{aligned}","title":"Aligned Representation"},{"location":"Building_Blocks/TensorMask:_A_Foundation_for_Dense_Object_Segmentation/#head","text":"\u7f51\u7edc\u91c7\u7528FPN\u8f93\u51fa\u591a\u4e2a\u4e0d\u540c\u5c3a\u5ea6\u7684feature maps,\u5f62\u72b6 (C, \\frac{1}{2^k} H, \\frac{1}{2^k}W","title":"\u7f51\u7edc\u7ed3\u6784, \u8f93\u51faHead, \u7ec6\u8282\u7ed3\u6784, \u8bad\u7ec3\u7ec6\u8282"},{"location":"Building_Blocks/TensorMask:_A_Foundation_for_Dense_Object_Segmentation/#head_1","text":"\u672c\u6587\u6bd4\u8f83\u4e865\u79cd\u8f93\u51faHead. 4\u79cd\u662fbaseline, \u533a\u522b\u5728\u4e8e\u4e0d\u540cScale\u4e0a\u7684\u56fe\uff0c\u7b2c\u4e94\u4e2ahead\u4f1a\u8f93\u51fa\u76f8\u540c\u7cbe\u786e\u5ea6\u7684\u7f51\u683c \u5176\u4e2d\u7684\u7ec6\u8282\u8fd0\u7b97\u5982\u56fe \u8fd9\u4e9b\u7ec6\u8282\u8fd0\u7b97\u672c\u8d28\u4e0a\u90fd\u662f\u5750\u6807\u53d8\u6362\u4ee5\u53ca\u91c7\u6837","title":"\u8f93\u51faHead"},{"location":"Building_Blocks/TensorMask:_A_Foundation_for_Dense_Object_Segmentation/#_2","text":"\u5bf9FPN\u7684\u5fae\u8c03 Label\u5206\u914d Fully Contain center of m is close to center of windows unique","title":"\u8bad\u7ec3\u7ec6\u8282"},{"location":"Building_Blocks/ThunderNet:_Towards_Real-time_Generic_Object_Detection_on_Mobile_Devices/","text":"ThunderNet: Towards Real-time Generic Object Detection on Mobile Devices \u8fd9\u7bc7\u8bba\u6587\u5c06\u4e00\u4e2atwo-stage\u7684detection\u7f51\u7edc\u5c3d\u53ef\u80fd\u5730\u8f7b\u91cf\u5316\u4ee5\u5b9e\u73b0\u5b9e\u65f6\u8ba1\u7b97\u7684\u76ee\u6807\uff0c\u8fd9\u7bc7\u6587\u7ae0 \u6709\u4e00\u7bc7\u5bf9\u8bfb\u8005\u5f88\u53cb\u597d\u7684Medieum\u89e3\u8bfb\uff0c\u8fd9\u91cc\u505a\u4e00\u4e2a\u5f15\u7528 . \u4e0e\u672c\u7f51\u9875\u5176\u4ed6\u6587\u7ae0\u4e00\u6837\uff0c\u672c\u6587\u4e0e\u5176\u76f8\u6bd4\u4f1a\u66f4\u6ce8\u91cd\u65b9\u6cd5\u7684\u89e3\u8bfb\u3002 \u603b\u4f53PipeLine \u5176\u4e2dSNet\u7f51\u7edc\u662f\u57fa\u4e8e ShuffleNetV2 .\u9ed8\u8ba4\u7684\u8f93\u5165\u5206\u8fa8\u7387\u662f 320\\times320 ,\u672c\u6587\u5728backbone\u65b9\u9762\u7684\u63d0\u5347\u4e3b\u8981\u662f\u63d0\u5347\u611f\u53d7\u573a\u7684\u5927\u5c0f\u3002 Context Enhancement Module \u8fd9\u4e00\u4e2a\u6a21\u578b\u7684\u8fd0\u7b97\u5728\u56fe\u4e2d\u8f83\u4e3a\u6e05\u695a\uff0c\u5b9e\u8d28\u4e0a\u5c31\u662f\u7528\u5c3d\u53ef\u80fd\u5c11\u7684\u8fd0\u7b97\u91cf\uff0c\u5b9e\u73b0\u8f83\u4e3a\u590d\u6742\u591a\u6837\u7684\u590d\u5408\u611f\u53d7\u91ce\u3002 Spatial Attention Module \u5728RoI resize\u4e4b\u524d\uff0c\u5b9e\u73b0\u5bf9channel\u7684\u4e00\u4e2areweights\u3002 \u5c06\u8fd9\u5f20\u56fe\u653e\u56depipeline\u56fe\u4e2d\u53ef\u4ee5\u770b\u5230\uff0c F^{RPN} \u662fCEM\u8f6c\u6362\u540e\u7684\u8f93\u51fa,\u4f5c\u4e3aRoIAlign\u7684\u6743\u91cd\u4ee5\u53cabase bounding box\u7684\u8f93\u51fa\u6e90\uff0c\u800c\u8fd9\u4e2a\u6a21\u5757\u6700\u540e\u7ed9\u51fa\u7684 F^{SAM} \u662fRoIAlign\u5bf9\u5e94bounding box\u53d6\u5185\u5bb9\u8f93\u5165\u5230\u4e0b\u4e00\u5c42\u7684\u8f93\u51fa\u6e90\u3002 \u5b9e\u9a8c\u7ed3\u679c \u6700\u6d45\u7684\u6a21\u5757\u6700\u7ec8\u80fd\u5728\u9a81\u9f99845\u4e0a\u8dd1\u523025hz\u3002","title":"ThunderNet: Towards Real-time Generic Object Detection on Mobile Devices"},{"location":"Building_Blocks/ThunderNet:_Towards_Real-time_Generic_Object_Detection_on_Mobile_Devices/#thundernet-towards-real-time-generic-object-detection-on-mobile-devices","text":"\u8fd9\u7bc7\u8bba\u6587\u5c06\u4e00\u4e2atwo-stage\u7684detection\u7f51\u7edc\u5c3d\u53ef\u80fd\u5730\u8f7b\u91cf\u5316\u4ee5\u5b9e\u73b0\u5b9e\u65f6\u8ba1\u7b97\u7684\u76ee\u6807\uff0c\u8fd9\u7bc7\u6587\u7ae0 \u6709\u4e00\u7bc7\u5bf9\u8bfb\u8005\u5f88\u53cb\u597d\u7684Medieum\u89e3\u8bfb\uff0c\u8fd9\u91cc\u505a\u4e00\u4e2a\u5f15\u7528 . \u4e0e\u672c\u7f51\u9875\u5176\u4ed6\u6587\u7ae0\u4e00\u6837\uff0c\u672c\u6587\u4e0e\u5176\u76f8\u6bd4\u4f1a\u66f4\u6ce8\u91cd\u65b9\u6cd5\u7684\u89e3\u8bfb\u3002","title":"ThunderNet: Towards Real-time Generic Object Detection on Mobile Devices"},{"location":"Building_Blocks/ThunderNet:_Towards_Real-time_Generic_Object_Detection_on_Mobile_Devices/#pipeline","text":"\u5176\u4e2dSNet\u7f51\u7edc\u662f\u57fa\u4e8e ShuffleNetV2 .\u9ed8\u8ba4\u7684\u8f93\u5165\u5206\u8fa8\u7387\u662f 320\\times320 ,\u672c\u6587\u5728backbone\u65b9\u9762\u7684\u63d0\u5347\u4e3b\u8981\u662f\u63d0\u5347\u611f\u53d7\u573a\u7684\u5927\u5c0f\u3002","title":"\u603b\u4f53PipeLine"},{"location":"Building_Blocks/ThunderNet:_Towards_Real-time_Generic_Object_Detection_on_Mobile_Devices/#context-enhancement-module","text":"\u8fd9\u4e00\u4e2a\u6a21\u578b\u7684\u8fd0\u7b97\u5728\u56fe\u4e2d\u8f83\u4e3a\u6e05\u695a\uff0c\u5b9e\u8d28\u4e0a\u5c31\u662f\u7528\u5c3d\u53ef\u80fd\u5c11\u7684\u8fd0\u7b97\u91cf\uff0c\u5b9e\u73b0\u8f83\u4e3a\u590d\u6742\u591a\u6837\u7684\u590d\u5408\u611f\u53d7\u91ce\u3002","title":"Context Enhancement Module"},{"location":"Building_Blocks/ThunderNet:_Towards_Real-time_Generic_Object_Detection_on_Mobile_Devices/#spatial-attention-module","text":"\u5728RoI resize\u4e4b\u524d\uff0c\u5b9e\u73b0\u5bf9channel\u7684\u4e00\u4e2areweights\u3002 \u5c06\u8fd9\u5f20\u56fe\u653e\u56depipeline\u56fe\u4e2d\u53ef\u4ee5\u770b\u5230\uff0c F^{RPN} \u662fCEM\u8f6c\u6362\u540e\u7684\u8f93\u51fa,\u4f5c\u4e3aRoIAlign\u7684\u6743\u91cd\u4ee5\u53cabase bounding box\u7684\u8f93\u51fa\u6e90\uff0c\u800c\u8fd9\u4e2a\u6a21\u5757\u6700\u540e\u7ed9\u51fa\u7684 F^{SAM} \u662fRoIAlign\u5bf9\u5e94bounding box\u53d6\u5185\u5bb9\u8f93\u5165\u5230\u4e0b\u4e00\u5c42\u7684\u8f93\u51fa\u6e90\u3002","title":"Spatial Attention Module"},{"location":"Building_Blocks/ThunderNet:_Towards_Real-time_Generic_Object_Detection_on_Mobile_Devices/#_1","text":"\u6700\u6d45\u7684\u6a21\u5757\u6700\u7ec8\u80fd\u5728\u9a81\u9f99845\u4e0a\u8dd1\u523025hz\u3002","title":"\u5b9e\u9a8c\u7ed3\u679c"},{"location":"Building_Blocks/deformable_convnet_v2/","text":"Deformable ConvNets V2: More Deformable, Better Results \u8fd9\u7bc7\u8bba\u6587\u4e00\u65b9\u9762\u8ba8\u8bba\u4e86\u4e00\u4e9b\u8bc4\u4ef7deformable convolution\u6a21\u5757\u6027\u80fd\u7684metric,\u5e76\u7528\u4e00\u4e9b\u5b9e\u9a8c\u5f15\u5165\u3002\u5728\u6a21\u5757\u8bbe\u8ba1\u4e0a\u7ed9\u51fadeformable convolution\u7684\u7ec6\u8282. \u7ed3\u6784\u89e3\u8bfb \u672c\u6587\u7684\u5173\u952e\u60f3\u6cd5\u662f\u5141\u8bb8deformable conv\u6a21\u5757\u5728\u540c\u4e00\u5f20\u56fe\u7247\u540c\u4e00\u4e2achannel\u3001\u4e0d\u540c\u5730\u65b9\u6709\u4e0d\u540c\u7684behavior,\u800c\u539f\u6765\u7684conv\u4ee5\u53ca\u521d\u59cb\u7684deformable conv\u90fd\u662f\u5904\u5904\u76f8\u540c\u7684\u7279\u5f81\u3002\u8ba1\u7b97\u516c\u5f0f y(p) = \\sum^K_{k=1}w_k\\dot x(p + p_k + \\Delta p_k) \\dot \\Delta m_k \u5176\u4e2d p, x(p), y(p) \u8868\u793a\u4f4d\u7f6e p \u4ee5\u53ca\u5f53\u524d\u4f4d\u7f6e\u4e0a\u7684\u8f93\u5165\u3001\u8f93\u51fafeature map\u3002 K \u4e3a\u5377\u79ef\u6838\u7684\u6570\u91cf\uff0c p_k\uff0c w_k \u4e3a\u539f\u7248\u53ef\u53d8\u5f62\u5377\u79ef\u5b66\u4e60\u5230\u7684offset\u4ee5\u53ca\u6743\u91cd(\u5728\u540c\u4e00\u56fe\u7247\u540c\u4e00channel\u5904\u5904\u76f8\u540c), \\Delta p_k, \\Delta m_k \u4e3a\u65b0\u7248\u589e\u52a0\u7684\uff0c\u4e0e\u5f53\u524d\u533a\u57df\u76f8\u5173\u7684offset\u4ee5\u53ca\u6743\u91cd \u800c \\Delta p_k, \\Delta m_k \u7531\u5f53\u524d\u4f4d\u7f6e\u5377\u79ef\u4ea7\u751f\uff0c\u6bd4\u5982\u4f7f\u7528K=9\uff0c\u5bf9\u5f53\u524d\u4f4d\u7f6e\u4f7f\u7528\u6b63\u5e38\u5377\u79ef\uff0c\u5f97\u523027\u4e2achannel\uff0c\u524d18\u4e2achannel\u5206\u522b\u5bf9\u5e94 \\Delta p_k \u7684\u4e24\u4e2a\u5750\u6807,\u540e9\u4e2achannel\u7ecf\u8fc7sigmoid\u6fc0\u6d3b\u540e\u53d8\u4e3a \\Delta m_k \u7ec6\u8282 \u53ef\u4ee5\u5b66\u4e60\u672c\u6587github\u4e2d\u4f7f\u7528cuda\u8f85\u52a9\u5e2e\u5fd9\u5f00\u53d1pytorch\u5b50\u6a21\u5757\uff0c\u5982\u679c\u53ef\u80fd\u53ef\u4ee5\u9002\u5f53\u5b66\u4e60\u3002\u6709\u52a0\u901f\u4ee3\u7801\u8fd0\u884c\u7684\u6f5c\u80fd\u3002","title":"Deformable ConvNets V2: More Deformable, Better Results"},{"location":"Building_Blocks/deformable_convnet_v2/#deformable-convnets-v2-more-deformable-better-results","text":"\u8fd9\u7bc7\u8bba\u6587\u4e00\u65b9\u9762\u8ba8\u8bba\u4e86\u4e00\u4e9b\u8bc4\u4ef7deformable convolution\u6a21\u5757\u6027\u80fd\u7684metric,\u5e76\u7528\u4e00\u4e9b\u5b9e\u9a8c\u5f15\u5165\u3002\u5728\u6a21\u5757\u8bbe\u8ba1\u4e0a\u7ed9\u51fadeformable convolution\u7684\u7ec6\u8282.","title":"Deformable ConvNets V2: More Deformable, Better Results"},{"location":"Building_Blocks/deformable_convnet_v2/#_1","text":"\u672c\u6587\u7684\u5173\u952e\u60f3\u6cd5\u662f\u5141\u8bb8deformable conv\u6a21\u5757\u5728\u540c\u4e00\u5f20\u56fe\u7247\u540c\u4e00\u4e2achannel\u3001\u4e0d\u540c\u5730\u65b9\u6709\u4e0d\u540c\u7684behavior,\u800c\u539f\u6765\u7684conv\u4ee5\u53ca\u521d\u59cb\u7684deformable conv\u90fd\u662f\u5904\u5904\u76f8\u540c\u7684\u7279\u5f81\u3002\u8ba1\u7b97\u516c\u5f0f y(p) = \\sum^K_{k=1}w_k\\dot x(p + p_k + \\Delta p_k) \\dot \\Delta m_k \u5176\u4e2d p, x(p), y(p) \u8868\u793a\u4f4d\u7f6e p \u4ee5\u53ca\u5f53\u524d\u4f4d\u7f6e\u4e0a\u7684\u8f93\u5165\u3001\u8f93\u51fafeature map\u3002 K \u4e3a\u5377\u79ef\u6838\u7684\u6570\u91cf\uff0c p_k\uff0c w_k \u4e3a\u539f\u7248\u53ef\u53d8\u5f62\u5377\u79ef\u5b66\u4e60\u5230\u7684offset\u4ee5\u53ca\u6743\u91cd(\u5728\u540c\u4e00\u56fe\u7247\u540c\u4e00channel\u5904\u5904\u76f8\u540c), \\Delta p_k, \\Delta m_k \u4e3a\u65b0\u7248\u589e\u52a0\u7684\uff0c\u4e0e\u5f53\u524d\u533a\u57df\u76f8\u5173\u7684offset\u4ee5\u53ca\u6743\u91cd \u800c \\Delta p_k, \\Delta m_k \u7531\u5f53\u524d\u4f4d\u7f6e\u5377\u79ef\u4ea7\u751f\uff0c\u6bd4\u5982\u4f7f\u7528K=9\uff0c\u5bf9\u5f53\u524d\u4f4d\u7f6e\u4f7f\u7528\u6b63\u5e38\u5377\u79ef\uff0c\u5f97\u523027\u4e2achannel\uff0c\u524d18\u4e2achannel\u5206\u522b\u5bf9\u5e94 \\Delta p_k \u7684\u4e24\u4e2a\u5750\u6807,\u540e9\u4e2achannel\u7ecf\u8fc7sigmoid\u6fc0\u6d3b\u540e\u53d8\u4e3a \\Delta m_k","title":"\u7ed3\u6784\u89e3\u8bfb"},{"location":"Building_Blocks/deformable_convnet_v2/#_2","text":"\u53ef\u4ee5\u5b66\u4e60\u672c\u6587github\u4e2d\u4f7f\u7528cuda\u8f85\u52a9\u5e2e\u5fd9\u5f00\u53d1pytorch\u5b50\u6a21\u5757\uff0c\u5982\u679c\u53ef\u80fd\u53ef\u4ee5\u9002\u5f53\u5b66\u4e60\u3002\u6709\u52a0\u901f\u4ee3\u7801\u8fd0\u884c\u7684\u6f5c\u80fd\u3002","title":"\u7ec6\u8282"},{"location":"Robotics_with_DL/Aggressive_Driving_with_Model_Predictive_Path_Integral_Control/","text":"Aggressive Driving with Model Predictive Path Integral Control \u672c\u7bc7\u8bba\u6587\u5c06Path integral Control\u4f7f\u7528\u5728\u81ea\u52a8\u9a7e\u9a76\u4e4b\u4e2d\uff0cPath integral Control\u5c5e\u4e8e\u968f\u673a\u6700\u4f18\u63a7\u5236\u7684\u7b97\u6cd5\uff0c\u6982\u5ff5\u5927\u6982\u662f\u8fd9\u6837\u7684\uff0c\u4f7f\u7528\u968f\u673a\u63a7\u5236\u503c\u8fdb\u884c\u63a2\u7d22\u4e0e\u9884\u6d4b\uff0c\u7136\u540e\u4e0e\u5176\u9009\u62e9\u5176\u4e2d\u6700\u4f18\u7684\uff0c\u7efc\u5408\u5404\u4e2a\u70b9\u7684\u6210\u672c\u4ee5\u53ca\u884c\u52a8\u8f68\u8ff9\uff0c\u5f97\u5230\u4e00\u4e2a\u7ecf\u9a8c\u4e0a\u7684\u6700\u4f18\u63a7\u5236\u7ed3\u679c\u3002 \u5728\u6bcf\u4e00\u4e2a\u65f6\u523b\uff1a \u786e\u5b9a\u53c2\u6570\uff0c\u968f\u673a\u91c7\u6837\u6570K\uff0c\u9884\u6d4b\u6b65\u957fN\uff0c\u521d\u59cb\u5316N\u4e2a\u521d\u59cb\u7684\u63a7\u5236\u5e8f\u5217\u3002 \u5bf9\u6bcf\u4e00\u4e2a\u91c7\u6837\u70b9(\u5e76\u884c\u8fdb\u884c)\uff0c\u52a0\u5165\u968f\u673a\u6270\u52a8\u5e8f\u5217\u5e76\u5f80\u524d\u9884\u6d4bN\u6b65\uff0c\u5f97\u5230\u5206\u522b\u7684\u603bcost \u8fd9\u91cc\u6ce8\u610f\u56fe\u4e2d\u7684 HG^{-1} = \\gamma \u662f\u4e00\u4e2a\u66f4\u65b0\u63a7\u5236\u53c2\u6570 \u4f7f\u7528\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u7684\u601d\u8def\uff0c\u53ea\u6267\u884c\u7b2c\u4e00\u4e2a\u63a7\u5236\u7ed3\u679c \u5b9e\u73b0\u7ec6\u8282\uff1a 1. \u6bcf\u4e00\u4e2a\u91c7\u6837\u70b9\u7684\u9884\u6d4b\u66f4\u65b0\u4ee5\u53ca\u6c42\u548c\u53ef\u4ee5\u7528GPU\u5e76\u884c\u5b8c\u6210(\u7528\u4e0a\u5343\u4e2a\u968f\u673a\u91c7\u6837\u6837\u672c) 2. \u5728\u5b9e\u65f6\u6267\u884c\u7684\u65f6\u5019\uff0c\u6bcf\u4e2a\u65f6\u523b\u53ea\u9700\u8981\u968f\u673a\u4f18\u5316\u6574\u4e2a\u5e8f\u5217\u4e00\u6b65\uff0c\u5e8f\u5217\u540e\u9762\u5730\u65b9\u53ef\u4ee5\u4f7f\u7528\u524d\u4e00\u4e2a\u65f6\u95f4\u6b65\u65f6\u7684\u4f18\u5316\u7ed3\u679c\u3002 3. \u672c\u6587\u63a7\u5236\u7684\u65f6\u5019\u8fd8\u662f\u5bf9\u63a7\u5236\u7ed3\u679c\u8fdb\u884c\u4e86\u5e73\u6ed1\u3002 \u7406\u8bba\u7ec6\u8282\uff1a 1. \u8981\u5b9e\u73b0\u4e0a\u6587\u56fe\u4e2d\u7684\u7b97\u6cd5\u8fd9\u4e00\u5316\u7b80\uff0c\u8981\u6c42\u7684\u662f\u968f\u673a\u566a\u58f0\u7684\u4f5c\u7528\u77e9\u9635 B \u7684\u4e0d\u53ef\u63a7\u5236\u4e0e\u53ef\u63a7\u5236\u90e8\u5206\uff0c\u4e0d\u53ef\u4ee5\u6709\u76f8\u5173\u9879 2. HG^{-1} = G_c^{-1} B_c \uff0c G_c \u5c31\u662f\u7cfb\u7edf\u52a8\u6001\u65b9\u7a0b\u4e2d\u7684\u53ef\u63a7\u90e8\u5206, B_c \u662f\u5e03\u6717\u6f02\u79fb\u5bf9\u5e94\u7684\u53ef\u63a7\u90e8\u5206\uff0c\u5728\u6211\u4eec\u4f18\u5316\u7684\u65f6\u5019\u5f80\u5f80\u4e24\u4e2a\u77e9\u9635\u662f\u76f8\u540c\u7684(\u5047\u8bbe\u63a7\u5236\u7ed3\u679c\u4ee5\u53ca\u6210\u672c\u4e0a\u662f\u4eff\u5c04\u7684)\uff0c\u90a3\u4e48\u8fd9\u4e2a \\gamma = 1 \u4e3a\u5e38\u6001 3. \\lambda \u662f\u6e29\u5ea6\uff0c\u4f1a\u63a7\u5236\u5141\u8bb8\u6ce2\u52a8\u7684\u81ea\u7531\u80fd\u7684\u5927\u5c0f,\u76f4\u89c9\u7ed3\u679c\u662f\u5f53 \\lambda \u8d8a\u5c0f\u7684\u65f6\u5019\uff0c\u7ed3\u679c\u66f4\u8d8b\u5411\u76f4\u63a5\u53d6\u6700\u4f18\uff0c\u5f53 \\lambda \u8d8a\u5927\u7684\u65f6\u5019\uff0c\u7ed3\u679c\u66f4\u8d8b\u5411\u4e8e\u968f\u673a\u9009\u62e9\u3002","title":"Aggressive Driving with Model Predictive Path Integral Control"},{"location":"Robotics_with_DL/Aggressive_Driving_with_Model_Predictive_Path_Integral_Control/#aggressive-driving-with-model-predictive-path-integral-control","text":"\u672c\u7bc7\u8bba\u6587\u5c06Path integral Control\u4f7f\u7528\u5728\u81ea\u52a8\u9a7e\u9a76\u4e4b\u4e2d\uff0cPath integral Control\u5c5e\u4e8e\u968f\u673a\u6700\u4f18\u63a7\u5236\u7684\u7b97\u6cd5\uff0c\u6982\u5ff5\u5927\u6982\u662f\u8fd9\u6837\u7684\uff0c\u4f7f\u7528\u968f\u673a\u63a7\u5236\u503c\u8fdb\u884c\u63a2\u7d22\u4e0e\u9884\u6d4b\uff0c\u7136\u540e\u4e0e\u5176\u9009\u62e9\u5176\u4e2d\u6700\u4f18\u7684\uff0c\u7efc\u5408\u5404\u4e2a\u70b9\u7684\u6210\u672c\u4ee5\u53ca\u884c\u52a8\u8f68\u8ff9\uff0c\u5f97\u5230\u4e00\u4e2a\u7ecf\u9a8c\u4e0a\u7684\u6700\u4f18\u63a7\u5236\u7ed3\u679c\u3002 \u5728\u6bcf\u4e00\u4e2a\u65f6\u523b\uff1a \u786e\u5b9a\u53c2\u6570\uff0c\u968f\u673a\u91c7\u6837\u6570K\uff0c\u9884\u6d4b\u6b65\u957fN\uff0c\u521d\u59cb\u5316N\u4e2a\u521d\u59cb\u7684\u63a7\u5236\u5e8f\u5217\u3002 \u5bf9\u6bcf\u4e00\u4e2a\u91c7\u6837\u70b9(\u5e76\u884c\u8fdb\u884c)\uff0c\u52a0\u5165\u968f\u673a\u6270\u52a8\u5e8f\u5217\u5e76\u5f80\u524d\u9884\u6d4bN\u6b65\uff0c\u5f97\u5230\u5206\u522b\u7684\u603bcost \u8fd9\u91cc\u6ce8\u610f\u56fe\u4e2d\u7684 HG^{-1} = \\gamma \u662f\u4e00\u4e2a\u66f4\u65b0\u63a7\u5236\u53c2\u6570 \u4f7f\u7528\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u7684\u601d\u8def\uff0c\u53ea\u6267\u884c\u7b2c\u4e00\u4e2a\u63a7\u5236\u7ed3\u679c \u5b9e\u73b0\u7ec6\u8282\uff1a 1. \u6bcf\u4e00\u4e2a\u91c7\u6837\u70b9\u7684\u9884\u6d4b\u66f4\u65b0\u4ee5\u53ca\u6c42\u548c\u53ef\u4ee5\u7528GPU\u5e76\u884c\u5b8c\u6210(\u7528\u4e0a\u5343\u4e2a\u968f\u673a\u91c7\u6837\u6837\u672c) 2. \u5728\u5b9e\u65f6\u6267\u884c\u7684\u65f6\u5019\uff0c\u6bcf\u4e2a\u65f6\u523b\u53ea\u9700\u8981\u968f\u673a\u4f18\u5316\u6574\u4e2a\u5e8f\u5217\u4e00\u6b65\uff0c\u5e8f\u5217\u540e\u9762\u5730\u65b9\u53ef\u4ee5\u4f7f\u7528\u524d\u4e00\u4e2a\u65f6\u95f4\u6b65\u65f6\u7684\u4f18\u5316\u7ed3\u679c\u3002 3. \u672c\u6587\u63a7\u5236\u7684\u65f6\u5019\u8fd8\u662f\u5bf9\u63a7\u5236\u7ed3\u679c\u8fdb\u884c\u4e86\u5e73\u6ed1\u3002 \u7406\u8bba\u7ec6\u8282\uff1a 1. \u8981\u5b9e\u73b0\u4e0a\u6587\u56fe\u4e2d\u7684\u7b97\u6cd5\u8fd9\u4e00\u5316\u7b80\uff0c\u8981\u6c42\u7684\u662f\u968f\u673a\u566a\u58f0\u7684\u4f5c\u7528\u77e9\u9635 B \u7684\u4e0d\u53ef\u63a7\u5236\u4e0e\u53ef\u63a7\u5236\u90e8\u5206\uff0c\u4e0d\u53ef\u4ee5\u6709\u76f8\u5173\u9879 2. HG^{-1} = G_c^{-1} B_c \uff0c G_c \u5c31\u662f\u7cfb\u7edf\u52a8\u6001\u65b9\u7a0b\u4e2d\u7684\u53ef\u63a7\u90e8\u5206, B_c \u662f\u5e03\u6717\u6f02\u79fb\u5bf9\u5e94\u7684\u53ef\u63a7\u90e8\u5206\uff0c\u5728\u6211\u4eec\u4f18\u5316\u7684\u65f6\u5019\u5f80\u5f80\u4e24\u4e2a\u77e9\u9635\u662f\u76f8\u540c\u7684(\u5047\u8bbe\u63a7\u5236\u7ed3\u679c\u4ee5\u53ca\u6210\u672c\u4e0a\u662f\u4eff\u5c04\u7684)\uff0c\u90a3\u4e48\u8fd9\u4e2a \\gamma = 1 \u4e3a\u5e38\u6001 3. \\lambda \u662f\u6e29\u5ea6\uff0c\u4f1a\u63a7\u5236\u5141\u8bb8\u6ce2\u52a8\u7684\u81ea\u7531\u80fd\u7684\u5927\u5c0f,\u76f4\u89c9\u7ed3\u679c\u662f\u5f53 \\lambda \u8d8a\u5c0f\u7684\u65f6\u5019\uff0c\u7ed3\u679c\u66f4\u8d8b\u5411\u76f4\u63a5\u53d6\u6700\u4f18\uff0c\u5f53 \\lambda \u8d8a\u5927\u7684\u65f6\u5019\uff0c\u7ed3\u679c\u66f4\u8d8b\u5411\u4e8e\u968f\u673a\u9009\u62e9\u3002","title":"Aggressive Driving with Model Predictive Path Integral Control"},{"location":"Robotics_with_DL/Backprop KF Learning Discriminative DeterministicState Estimators/","text":"Backprop KF: Learning Discriminative DeterministicState Estimators \u8fd9\u662f\u4e00\u7bc7\u6bd4\u8f83\u65e9\u671f\u7684\u8bba\u6587\uff0c\u4ecb\u7ecd\u7684\u662f\u53ef\u5fae\u5206\u5361\u5c14\u66fc\u6ee4\u6ce2\u3002 \u6838\u5fc3\u7ed3\u6784 \u7528CNN\u8f93\u51fa\u4e00\u7ef4\u7684\u89c2\u6d4b\u77e2\u91cf\uff0c\u4ee5\u53ca\u89c2\u6d4b\u7684covariance\u77e9\u9635\u3002 \u89c2\u6d4b\u7684covariance\u77e9\u9635\u7684\u751f\u6210\u65b9\u5f0f\uff1a Relu->diag->square \u5176\u4f59\u4e2d\u95f4\u516c\u5f0f\u4e0e\u5361\u5c14\u66fc\u6ee4\u6ce2\u4e00\u81f4\uff0c\u6a21\u578b\u52a8\u6001\u65b9\u7a0b\u4e0e\u89c2\u6d4b\u65b9\u7a0b\u7686(\u72b6\u6001\u7a7a\u95f4ABCD\uff0cQ\u77e9\u9635)\u7686\u4e3a\u53ef\u5b66\u4e60\u7684\u53c2\u6570","title":"Backprop KF: Learning Discriminative DeterministicState Estimators"},{"location":"Robotics_with_DL/Backprop KF Learning Discriminative DeterministicState Estimators/#backprop-kf-learning-discriminative-deterministicstate-estimators","text":"\u8fd9\u662f\u4e00\u7bc7\u6bd4\u8f83\u65e9\u671f\u7684\u8bba\u6587\uff0c\u4ecb\u7ecd\u7684\u662f\u53ef\u5fae\u5206\u5361\u5c14\u66fc\u6ee4\u6ce2\u3002","title":"Backprop KF: Learning Discriminative DeterministicState Estimators"},{"location":"Robotics_with_DL/Backprop KF Learning Discriminative DeterministicState Estimators/#_1","text":"\u7528CNN\u8f93\u51fa\u4e00\u7ef4\u7684\u89c2\u6d4b\u77e2\u91cf\uff0c\u4ee5\u53ca\u89c2\u6d4b\u7684covariance\u77e9\u9635\u3002 \u89c2\u6d4b\u7684covariance\u77e9\u9635\u7684\u751f\u6210\u65b9\u5f0f\uff1a Relu->diag->square \u5176\u4f59\u4e2d\u95f4\u516c\u5f0f\u4e0e\u5361\u5c14\u66fc\u6ee4\u6ce2\u4e00\u81f4\uff0c\u6a21\u578b\u52a8\u6001\u65b9\u7a0b\u4e0e\u89c2\u6d4b\u65b9\u7a0b\u7686(\u72b6\u6001\u7a7a\u95f4ABCD\uff0cQ\u77e9\u9635)\u7686\u4e3a\u53ef\u5b66\u4e60\u7684\u53c2\u6570","title":"\u6838\u5fc3\u7ed3\u6784"},{"location":"Robotics_with_DL/ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst/","text":"ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst \u8fd9\u7bc7RSS\u8bba\u6587\u6765\u81ea\u4e8eWaymo,\u82f1\u6587\u540d\u5b57\u7684\u7ffb\u8bd1\u610f\u601d\u662f\"\u53f8\u673a\u7f51\",\u7ed9\u51fa\u4e86\u4e00\u4e2aimitation learning\u7cfb\u7edf\uff0c\u5e76\u5b9e\u73b0\u4e86\u4e0a\u8f66\u6d4b\u8bd5\uff0c\u4e3a\u4e86\u4fdd\u8bc1\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u672c\u6587\u505a\u4e86\u5f88\u591a\u7684\u9009\u62e9\u4e0e\u52a0\u5f3a\uff0c\u503c\u5f97\u4e86\u89e3\u3002\u8fd9\u7bc7\u8bba\u6587\u6709 \u6765\u81eawaymo\u7684\u5b98\u65b9medium\u82f1\u6587\u89e3\u8bfb Imitation Learning\u7684\u5e38\u89c1\u95ee\u9898 \u4eceraw data\u5230\u5e95\u5c42 control\uff0cgeneralization\u96be\u5ea6\u5f88\u5927\uff0c\u4e0d\u9002\u7528\u4e8e\u4e0d\u540c\u7684\u4f20\u611f\u4e0e\u5e95\u5c42\u7269\u7406\u6a21\u578b\uff0c\u7f51\u7edc\u88ab\u8feb\u5f00\u73af\u5730\u5b66\u4e60\u5e95\u5c42\u7269\u7406\u6a21\u578b\uff0c\u6d6a\u8d39\u7f51\u7edc\u80fd\u529b\u3002 \u5373\u65f6\u8f6c\u6362\u4e3a\u672c\u6587\u7ed9\u51fa\u7684\u4e2d\u5c42\u8f93\u5165\u8f93\u51fa(processed percepetion and planning and map information -> target poses sequences),\u964d\u4f4e\u4e86\u7f51\u7edc\u7684\u4eff\u771f\u96be\u5ea6\uff0c30M\u7684\u6570\u636e\u70b9\u4ecd\u4e0d\u8db3\u4ee5\u4f7f\u4f20\u7edf\u7684Cloning\u7b97\u6cd5\u5f97\u5230\u597d\u7684\u7ed3\u679c\u3002 \u672c\u6587\u7f51\u7edc\u7684\u8f93\u5165\u8f93\u51fadata representation \u516b\u5f20\u56fe\u5206\u522b\u4e3a: 1. \u57ce\u5e02\u9053\u8def\u5730\u56fe 2. traffic light\u53ef\u901a\u884c\u4ee5\u53ca\u65f6\u95f4\u4fe1\u606f(\u5b9e\u9645\u4e0a\u662f\u7ed9\u4e86\u8fde\u7eed\u51e0\u5f20\u56fe\u7684) 3. \u901f\u5ea6\u9650\u5236 4. \u76ee\u6807\u8def\u5f84(\u7c7b\u4f3c\u5730\u56feAPP\u7684\u6307\u793a) 5. \u5f53\u524dagent\u4f4d\u7f6e 6. \u6700\u8fd1\u4e00\u7cfb\u5217\u7684\u52a8\u6001\u969c\u788d\u7269\u7684\u4f4d\u7f6e 7. \u8fc7\u53bb\u4e00\u6bb5\u65f6\u95f4\u7684agent poses 8. \u672a\u6765\u7684agent poses(\u8f93\u51fa) \u6240\u6709\u8f93\u5165\u56fe\u4ee5\u8f66\u8f86\u5f53\u524d\u5750\u6807\u7cfb\u7ed9\u51fa\uff0c\u8f66\u8f86\u5f53\u524dpose\u4f1a\u56fa\u5b9a\u5728\u4e00\u4e2a (u_0, v_0) \u70b9,\u8bad\u7ec3\u7684\u65f6\u5019\u4f1a\u989d\u5916\u5bf9\u6570\u636e\u4e2d\u7684\u8f66\u5b50\u7684heading\u52a0\u4e00\u4e2a\u6270\u52a8\uff0c\u76f8\u5f53\u4e8e\u8bad\u7ec3\u65f6\u7684\u8fd9\u4e9bfeature map\u4f1a\u76f8\u5bf9\u6709\u989d\u5916\u7684\u65cb\u8f6c\u3002 \u7f51\u7edc\u7ed3\u6784 \u6574\u4f53\u7ed3\u6784\u5982\u56fe\uff0c\u6838\u5fc3\u90e8\u5206\u4e3a\"\u8f93\u5165->\u7279\u5f81\u63d0\u53d6->RNN->\u671d\u5411\u3001\u901f\u5ea6\u3001\u672a\u6765\u76ee\u6807\u70b9\u3001\u5916\u6765heat map\"\u3002additional target \u5305\u62ecroad mask\u4ee5\u53ca\u4e00\u4e2adynamic object prediction \u4ee5\u4e0b\u52a8\u56fe\u8868\u8fbe\u4e86Agent RNN\u7684RNN\u7279\u5f81(\u5305\u62ecmemory) \u5411\u4e13\u5bb6\u6a21\u4eff\u5b66\u4e60 \u51e0\u4e2acost\u662f\u5e38\u89c1\u7684\uff0c\u8fd9\u91cc\u4e3b\u8981\u8bb0\u5f55\u4e00\u4e2atrick Past Motion Dropout \u8bad\u7ec3\u7684\u65f6\u5019\uff0c\u7531\u4e8e\u4e13\u5bb6\u7684\u8def\u5f84\u592a\u5e73\u6ed1\uff0c\u6709\u65f6\u5019\u53ea\u9700\u8981\u5bf9\u5148\u524d\u51e0\u4e2a\u65f6\u95f4\u70b9\u7684\u8def\u5f84\u70b9\u8fdb\u884c\u63d2\u503c\u5c31\u80fd\u987a\u5229\u5f97\u5230\u540e\u9762\u7684\u76ee\u6807\u70b9\uff0c\u4e14\u8bef\u5dee\u5f88\u5c0f\uff0c\u8fd9\u91cc\u4e3a\u4e86\u51cf\u8f7b\u8fd9\u4e2a\u95ee\u9898\uff0c\u5728\u8bad\u7ec3\u7684\u8fc7\u7a0b\u4e2d\u4f1a\u968f\u673adrop\u6389\u4e00\u4e9b\u5386\u53f2\u7684poses\uff0c\u5177\u4f53\u6765\u8bf4\u5c31\u662f50%\u7684training data\u91cc\u9762\u5386\u53f2poses\u4e3a\u7a7a\uff0c\u53ea\u5269\u4e0b\u5f53\u524dpose \u63d0\u5347\u96be\u5ea6 \u5408\u6210\u5e72\u6270 \u5c06\u4e00\u4e9b\u5e73\u6ed1\u7684\u4e13\u5bb6path\u4e2d\u95f4\uff0c\u968f\u673a\u9009\u4e00\u4e9b\u70b9\u6c34\u5e73\u6270\u52a8\uff0c\u7136\u540e\u7528\u5e73\u6ed1\u7684\u63d2\u503c\u91cd\u65b0\u751f\u6210\u5047\u7684\u4e13\u5bb6\u8f68\u8ff9\uff0c \u8fd9\u4e9b\u65b0\u7684\u8f68\u8ff9\u53ef\u80fd\u4f1a\u78b0\u649e\uff0c\u6240\u4ee5\u8fd9\u7c7bdata\u7684weight\u53ea\u6709\u6b63\u786edata\u76840.1\uff0c\u4e0d\u8fc7\u53ef\u4ee5\u5f88\u597d\u7684\u589e\u52a0\u6b63\u5e38\u53f8\u673a\u4e0d\u4f1a\u5230\u8fbe\u7684\u5371\u9669\u60c5\u666f \u8f85\u52a9loss \u78b0\u649e loss\uff0c\u4e3b\u8981\u5728\u4e8e\u60e9\u7f5aperturbation\u7684\u65f6\u5019\u7684\u4e00\u4e9b\u78b0\u649e on road loss: \u51e0\u4f55loss\uff0c\u52a0\u5f3a\u4e0e\u539f\u8f68\u8ff9\u7684\u91cd\u5408\u5ea6 road masking \u4e0e prediction \u6a21\u4effdropout \u6709\u4e00\u5b9a\u7684\u6982\u7387\u4e0d\u9700\u8981\u7f51\u7edc\u5b9e\u73b0imitation\uff0c\u8ba9imitation\u90e8\u5206loss\u4e3a0\uff0c\u53ea\u7559\u4e0b\u524d\u4e00\u6bb5\u5199\u5230\u7684\u9644\u52a0loss","title":"ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst"},{"location":"Robotics_with_DL/ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst/#chauffeurnet-learning-to-drive-by-imitating-the-best-and-synthesizing-the-worst","text":"\u8fd9\u7bc7RSS\u8bba\u6587\u6765\u81ea\u4e8eWaymo,\u82f1\u6587\u540d\u5b57\u7684\u7ffb\u8bd1\u610f\u601d\u662f\"\u53f8\u673a\u7f51\",\u7ed9\u51fa\u4e86\u4e00\u4e2aimitation learning\u7cfb\u7edf\uff0c\u5e76\u5b9e\u73b0\u4e86\u4e0a\u8f66\u6d4b\u8bd5\uff0c\u4e3a\u4e86\u4fdd\u8bc1\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u672c\u6587\u505a\u4e86\u5f88\u591a\u7684\u9009\u62e9\u4e0e\u52a0\u5f3a\uff0c\u503c\u5f97\u4e86\u89e3\u3002\u8fd9\u7bc7\u8bba\u6587\u6709 \u6765\u81eawaymo\u7684\u5b98\u65b9medium\u82f1\u6587\u89e3\u8bfb","title":"ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst"},{"location":"Robotics_with_DL/ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst/#imitation-learning","text":"\u4eceraw data\u5230\u5e95\u5c42 control\uff0cgeneralization\u96be\u5ea6\u5f88\u5927\uff0c\u4e0d\u9002\u7528\u4e8e\u4e0d\u540c\u7684\u4f20\u611f\u4e0e\u5e95\u5c42\u7269\u7406\u6a21\u578b\uff0c\u7f51\u7edc\u88ab\u8feb\u5f00\u73af\u5730\u5b66\u4e60\u5e95\u5c42\u7269\u7406\u6a21\u578b\uff0c\u6d6a\u8d39\u7f51\u7edc\u80fd\u529b\u3002 \u5373\u65f6\u8f6c\u6362\u4e3a\u672c\u6587\u7ed9\u51fa\u7684\u4e2d\u5c42\u8f93\u5165\u8f93\u51fa(processed percepetion and planning and map information -> target poses sequences),\u964d\u4f4e\u4e86\u7f51\u7edc\u7684\u4eff\u771f\u96be\u5ea6\uff0c30M\u7684\u6570\u636e\u70b9\u4ecd\u4e0d\u8db3\u4ee5\u4f7f\u4f20\u7edf\u7684Cloning\u7b97\u6cd5\u5f97\u5230\u597d\u7684\u7ed3\u679c\u3002","title":"Imitation Learning\u7684\u5e38\u89c1\u95ee\u9898"},{"location":"Robotics_with_DL/ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst/#data-representation","text":"\u516b\u5f20\u56fe\u5206\u522b\u4e3a: 1. \u57ce\u5e02\u9053\u8def\u5730\u56fe 2. traffic light\u53ef\u901a\u884c\u4ee5\u53ca\u65f6\u95f4\u4fe1\u606f(\u5b9e\u9645\u4e0a\u662f\u7ed9\u4e86\u8fde\u7eed\u51e0\u5f20\u56fe\u7684) 3. \u901f\u5ea6\u9650\u5236 4. \u76ee\u6807\u8def\u5f84(\u7c7b\u4f3c\u5730\u56feAPP\u7684\u6307\u793a) 5. \u5f53\u524dagent\u4f4d\u7f6e 6. \u6700\u8fd1\u4e00\u7cfb\u5217\u7684\u52a8\u6001\u969c\u788d\u7269\u7684\u4f4d\u7f6e 7. \u8fc7\u53bb\u4e00\u6bb5\u65f6\u95f4\u7684agent poses 8. \u672a\u6765\u7684agent poses(\u8f93\u51fa) \u6240\u6709\u8f93\u5165\u56fe\u4ee5\u8f66\u8f86\u5f53\u524d\u5750\u6807\u7cfb\u7ed9\u51fa\uff0c\u8f66\u8f86\u5f53\u524dpose\u4f1a\u56fa\u5b9a\u5728\u4e00\u4e2a (u_0, v_0) \u70b9,\u8bad\u7ec3\u7684\u65f6\u5019\u4f1a\u989d\u5916\u5bf9\u6570\u636e\u4e2d\u7684\u8f66\u5b50\u7684heading\u52a0\u4e00\u4e2a\u6270\u52a8\uff0c\u76f8\u5f53\u4e8e\u8bad\u7ec3\u65f6\u7684\u8fd9\u4e9bfeature map\u4f1a\u76f8\u5bf9\u6709\u989d\u5916\u7684\u65cb\u8f6c\u3002","title":"\u672c\u6587\u7f51\u7edc\u7684\u8f93\u5165\u8f93\u51fadata representation"},{"location":"Robotics_with_DL/ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst/#_1","text":"\u6574\u4f53\u7ed3\u6784\u5982\u56fe\uff0c\u6838\u5fc3\u90e8\u5206\u4e3a\"\u8f93\u5165->\u7279\u5f81\u63d0\u53d6->RNN->\u671d\u5411\u3001\u901f\u5ea6\u3001\u672a\u6765\u76ee\u6807\u70b9\u3001\u5916\u6765heat map\"\u3002additional target \u5305\u62ecroad mask\u4ee5\u53ca\u4e00\u4e2adynamic object prediction \u4ee5\u4e0b\u52a8\u56fe\u8868\u8fbe\u4e86Agent RNN\u7684RNN\u7279\u5f81(\u5305\u62ecmemory)","title":"\u7f51\u7edc\u7ed3\u6784"},{"location":"Robotics_with_DL/ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst/#_2","text":"\u51e0\u4e2acost\u662f\u5e38\u89c1\u7684\uff0c\u8fd9\u91cc\u4e3b\u8981\u8bb0\u5f55\u4e00\u4e2atrick","title":"\u5411\u4e13\u5bb6\u6a21\u4eff\u5b66\u4e60"},{"location":"Robotics_with_DL/ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst/#past-motion-dropout","text":"\u8bad\u7ec3\u7684\u65f6\u5019\uff0c\u7531\u4e8e\u4e13\u5bb6\u7684\u8def\u5f84\u592a\u5e73\u6ed1\uff0c\u6709\u65f6\u5019\u53ea\u9700\u8981\u5bf9\u5148\u524d\u51e0\u4e2a\u65f6\u95f4\u70b9\u7684\u8def\u5f84\u70b9\u8fdb\u884c\u63d2\u503c\u5c31\u80fd\u987a\u5229\u5f97\u5230\u540e\u9762\u7684\u76ee\u6807\u70b9\uff0c\u4e14\u8bef\u5dee\u5f88\u5c0f\uff0c\u8fd9\u91cc\u4e3a\u4e86\u51cf\u8f7b\u8fd9\u4e2a\u95ee\u9898\uff0c\u5728\u8bad\u7ec3\u7684\u8fc7\u7a0b\u4e2d\u4f1a\u968f\u673adrop\u6389\u4e00\u4e9b\u5386\u53f2\u7684poses\uff0c\u5177\u4f53\u6765\u8bf4\u5c31\u662f50%\u7684training data\u91cc\u9762\u5386\u53f2poses\u4e3a\u7a7a\uff0c\u53ea\u5269\u4e0b\u5f53\u524dpose","title":"Past Motion Dropout"},{"location":"Robotics_with_DL/ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst/#_3","text":"","title":"\u63d0\u5347\u96be\u5ea6"},{"location":"Robotics_with_DL/ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst/#_4","text":"\u5c06\u4e00\u4e9b\u5e73\u6ed1\u7684\u4e13\u5bb6path\u4e2d\u95f4\uff0c\u968f\u673a\u9009\u4e00\u4e9b\u70b9\u6c34\u5e73\u6270\u52a8\uff0c\u7136\u540e\u7528\u5e73\u6ed1\u7684\u63d2\u503c\u91cd\u65b0\u751f\u6210\u5047\u7684\u4e13\u5bb6\u8f68\u8ff9\uff0c \u8fd9\u4e9b\u65b0\u7684\u8f68\u8ff9\u53ef\u80fd\u4f1a\u78b0\u649e\uff0c\u6240\u4ee5\u8fd9\u7c7bdata\u7684weight\u53ea\u6709\u6b63\u786edata\u76840.1\uff0c\u4e0d\u8fc7\u53ef\u4ee5\u5f88\u597d\u7684\u589e\u52a0\u6b63\u5e38\u53f8\u673a\u4e0d\u4f1a\u5230\u8fbe\u7684\u5371\u9669\u60c5\u666f","title":"\u5408\u6210\u5e72\u6270"},{"location":"Robotics_with_DL/ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst/#loss","text":"\u78b0\u649e loss\uff0c\u4e3b\u8981\u5728\u4e8e\u60e9\u7f5aperturbation\u7684\u65f6\u5019\u7684\u4e00\u4e9b\u78b0\u649e on road loss: \u51e0\u4f55loss\uff0c\u52a0\u5f3a\u4e0e\u539f\u8f68\u8ff9\u7684\u91cd\u5408\u5ea6 road masking \u4e0e prediction","title":"\u8f85\u52a9loss"},{"location":"Robotics_with_DL/ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst/#dropout","text":"\u6709\u4e00\u5b9a\u7684\u6982\u7387\u4e0d\u9700\u8981\u7f51\u7edc\u5b9e\u73b0imitation\uff0c\u8ba9imitation\u90e8\u5206loss\u4e3a0\uff0c\u53ea\u7559\u4e0b\u524d\u4e00\u6bb5\u5199\u5230\u7684\u9644\u52a0loss","title":"\u6a21\u4effdropout"},{"location":"Robotics_with_DL/Cognitive Mapping and Planning for Visual Navigation/","text":"Cognitive Mapping and Planning for Visual Navigation \u8fd9\u7bc7\u8bba\u6587\u57282017\u5e74\u63d0\u51fa\u4e86\u76f4\u63a5\u5229\u7528\u89c6\u89c9\u8fdb\u884c\u5bfc\u822a\u7684\u601d\u8def \u603b\u4f53\u7ed3\u6784: \u8f93\u5165\u4e3aEgomotion, Goal, \u89c6\u89c9\u56fe\u50cf\u8f93\u5165, \u8f93\u51fa\u65f6action\uff0c\u4e2d\u95f4\u4f7f\u7528\u53ef\u5fae\u5206Mapper\u548c\u53ef\u5fae\u5206Planner Mapper \u8fd9\u91cc\u7ed9\u51fa\u7684mapper\u7ed3\u6784\u5982\u4e0a\u56fe\uff0c\u5df2\u77e5\u4e0a\u4e00\u65f6\u523b\u5bf9\u73af\u5883\u5efa\u56fe\u7ed3\u679c\u4ee5\u53ca\u672c\u4f53\u8fd0\u52a8\uff0c\u901a\u8fc7\u53ef\u5fae\u5206\u7684\u56fe\u7247\u5e73\u79fb\u548c\u65cb\u8f6c\uff0c\u5f97\u5230\u5bf9\u73b0\u5728\u5730\u56fe\u7684\u4f30\u8ba1\uff0c\u4e0e\u65b0\u56fe\u7247\u7ecf\u8fc7encoder\u3001decoder\u4e4b\u540e\u7684\u8f93\u51fa\u8fdb\u884c\u5408\u5e76\uff0c\u5f97\u5230\u5f53\u524d\u4e16\u754c\u7684\u4f30\u8ba1\u3002 Planner \u8fd9\u91cc\u7ed9\u51fa\u7684\u591a\u5c42\u7ea7Planner\u7ed3\u6784\u5982\u4e0a\u56fe\uff0c\u7b97\u6cd5\u5982\u4e0b \u5728\u6700\u5927\u7684\u5730\u56fe\u6700\u5c0f\u5b9e\u9645\u8ddd\u79bb\u5206\u8fa8\u7387\u7684costmap(\u6765\u81eamapper)\u4e0a\u5e26\u7740goal\u4fe1\u606f(\u5377\u79ef\u5408\u6210)\uff0c\u8fdb\u884cvalue-iteration(\u65b9\u6cd5\u540cQMDP\u4e2d\u63d0\u5230\u7684planner\u7684\u505a\u6cd5) \u5206\u5272\u51faValue Map\u4e2d\u5fc3\u90e8\u5206\uff0c\u4e0b\u91c7\u6837,\u4e0eGoal\u548cCostmap\u5377\u79ef\u5408\u6210\uff0c\u518d\u8fdb\u884cvalue-iteration \u91cd\u590d2\uff0c\u76f4\u5230\u5206\u8fa8\u7387\u8db3\u591f\u5c0f\u4e3a\u6b62\uff0c\u6700\u7ec8\u5168\u8fde\u63a5\u8f93\u5165\u884c\u52a8\u503c\u3002 \u663e\u7136\u8fd9\u4e2aplanner\u4e0eMapper\u90fd\u662f\u53ef\u5bfc\u7684\u8fd0\u7b97\u8fc7\u7a0b\uff0c\u53ef\u4ee5\u7aef\u5230\u7aef\u5b66\u4e60\u3002\u7f3a\u70b9\u5728\u4e8eValue-iteration\u7528\u4e8eplanner\u8fd9\u4e2a\u76ee\u524d\u53ea\u57282D\u5e73\u9762\u5bfc\u822a\u4e2d\u89c2\u5bdf\u8fc7\uff0c\u6709\u5f85\u8003\u8651\u3002","title":"Cognitive Mapping and Planning for Visual Navigation"},{"location":"Robotics_with_DL/Cognitive Mapping and Planning for Visual Navigation/#cognitive-mapping-and-planning-for-visual-navigation","text":"\u8fd9\u7bc7\u8bba\u6587\u57282017\u5e74\u63d0\u51fa\u4e86\u76f4\u63a5\u5229\u7528\u89c6\u89c9\u8fdb\u884c\u5bfc\u822a\u7684\u601d\u8def \u603b\u4f53\u7ed3\u6784: \u8f93\u5165\u4e3aEgomotion, Goal, \u89c6\u89c9\u56fe\u50cf\u8f93\u5165, \u8f93\u51fa\u65f6action\uff0c\u4e2d\u95f4\u4f7f\u7528\u53ef\u5fae\u5206Mapper\u548c\u53ef\u5fae\u5206Planner","title":"Cognitive Mapping and Planning for Visual Navigation"},{"location":"Robotics_with_DL/Cognitive Mapping and Planning for Visual Navigation/#mapper","text":"\u8fd9\u91cc\u7ed9\u51fa\u7684mapper\u7ed3\u6784\u5982\u4e0a\u56fe\uff0c\u5df2\u77e5\u4e0a\u4e00\u65f6\u523b\u5bf9\u73af\u5883\u5efa\u56fe\u7ed3\u679c\u4ee5\u53ca\u672c\u4f53\u8fd0\u52a8\uff0c\u901a\u8fc7\u53ef\u5fae\u5206\u7684\u56fe\u7247\u5e73\u79fb\u548c\u65cb\u8f6c\uff0c\u5f97\u5230\u5bf9\u73b0\u5728\u5730\u56fe\u7684\u4f30\u8ba1\uff0c\u4e0e\u65b0\u56fe\u7247\u7ecf\u8fc7encoder\u3001decoder\u4e4b\u540e\u7684\u8f93\u51fa\u8fdb\u884c\u5408\u5e76\uff0c\u5f97\u5230\u5f53\u524d\u4e16\u754c\u7684\u4f30\u8ba1\u3002","title":"Mapper"},{"location":"Robotics_with_DL/Cognitive Mapping and Planning for Visual Navigation/#planner","text":"\u8fd9\u91cc\u7ed9\u51fa\u7684\u591a\u5c42\u7ea7Planner\u7ed3\u6784\u5982\u4e0a\u56fe\uff0c\u7b97\u6cd5\u5982\u4e0b \u5728\u6700\u5927\u7684\u5730\u56fe\u6700\u5c0f\u5b9e\u9645\u8ddd\u79bb\u5206\u8fa8\u7387\u7684costmap(\u6765\u81eamapper)\u4e0a\u5e26\u7740goal\u4fe1\u606f(\u5377\u79ef\u5408\u6210)\uff0c\u8fdb\u884cvalue-iteration(\u65b9\u6cd5\u540cQMDP\u4e2d\u63d0\u5230\u7684planner\u7684\u505a\u6cd5) \u5206\u5272\u51faValue Map\u4e2d\u5fc3\u90e8\u5206\uff0c\u4e0b\u91c7\u6837,\u4e0eGoal\u548cCostmap\u5377\u79ef\u5408\u6210\uff0c\u518d\u8fdb\u884cvalue-iteration \u91cd\u590d2\uff0c\u76f4\u5230\u5206\u8fa8\u7387\u8db3\u591f\u5c0f\u4e3a\u6b62\uff0c\u6700\u7ec8\u5168\u8fde\u63a5\u8f93\u5165\u884c\u52a8\u503c\u3002 \u663e\u7136\u8fd9\u4e2aplanner\u4e0eMapper\u90fd\u662f\u53ef\u5bfc\u7684\u8fd0\u7b97\u8fc7\u7a0b\uff0c\u53ef\u4ee5\u7aef\u5230\u7aef\u5b66\u4e60\u3002\u7f3a\u70b9\u5728\u4e8eValue-iteration\u7528\u4e8eplanner\u8fd9\u4e2a\u76ee\u524d\u53ea\u57282D\u5e73\u9762\u5bfc\u822a\u4e2d\u89c2\u5bdf\u8fc7\uff0c\u6709\u5f85\u8003\u8651\u3002","title":"Planner"},{"location":"Robotics_with_DL/Composable_Action-Conditioned_Predictors_Flexible_Off-Policy_Learning_for_Robot_Navigation/","text":"Composable Action-Conditioned Predictors: Flexible Off-Policy Learning for Robot Navigation \u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7075\u6d3b\u7684\u3001\u5c11\u76d1\u7763\u7684\u589e\u5f3a\u5b66\u4e60\u5bfc\u822a\u6846\u67b6\u3002\u6a21\u578b\u7684\u5b66\u4e60\u8fc7\u7a0b\u4f7f\u7528\u8f83\u4e3a\u6709\u9650\u7684\u76d1\u7763\uff0c\u540c\u4e00\u4e2a\u6a21\u578b\u53ef\u5728deploy\u65f6\u901a\u8fc7\u4fee\u6539reward\u51fd\u6570\u662f\u7684\u673a\u5668\u4eba\u8fbe\u5230\u6211\u4eec\u60f3\u8981\u7684\u5bfc\u822a\u6548\u679c CAPs\u6a21\u578b\u4ecb\u7ecd CAPs\u7ed3\u6784\u7684\u76ee\u7684\u662f\u901a\u8fc7\u8f93\u5165\u7684\u56fe\u7247\u3001\u72b6\u6001\u5e8f\u5217\uff0c\u8f93\u51fa\u5f53\u524d\u72b6\u6001\u4e0b\u51e0\u4e2a\u91cd\u8981\u7684encoded event\u7684\u76f8\u5173\u53c2\u6570\u3002\u672c\u8bba\u6587\u4f7f\u7528\u7684\u662fcollision, heading\uff0c or road lanes and doorways(\u95e8\u5728\u56fe\u7247\u4e2d\u7684\u6bd4\u4f8b)\u3002\u8fc7\u7a0b\u662foff-policy\u7684\uff0c\u6a21\u578b\u53d6\u51b3\u4e8e\u4e00\u4e2a\u957f\u5ea6\u4e3aN\u7684\u672a\u6765\u7684action list\uff0c\u6570\u636e\u91c7\u96c6\u8fc7\u7a0b\u91c7\u7528\u7684policy\u4e0e\u6700\u7ec8deploy\u6ca1\u6709\u5fc5\u7136\u8054\u7cfb\u3002 \u5728deploy\u7684\u65f6\u5019\uff0c\u7528\u6237\u57fa\u4e8eencoded event\u5b9a\u4e49\u65b0\u7684reward function\uff0c \u7cfb\u7edf\u901a\u8fc7MPC\u4f18\u5316\u5b9e\u73b0\u63a7\u5236\u3002 \u6df1\u5ea6\u5b66\u4e60\u7ed3\u6784 \u5377\u79ef\u63d0\u7279\u5f81->concat\u72b6\u6001\u5411\u91cf->\u5168\u8fde\u63a5-> multiplicative integration LSTM \u7684\u521d\u59cb\u72b6\u6001\u503c->\u8f93\u5165\u5e8f\u5217action->\u901a\u8fc7FC\u5206\u652f\u8f93\u51fa\u5404\u4e2aencoded event\u7684\u53c2\u6570 encoded events (event cues) \u8fd9\u91cc\u9009\u62e9\u7684collision\u4ee5\u53caheading\u4ee5\u53ca\u901f\u5ea6\u7b49\u53ef\u4ee5\u901a\u8fc7\u8f66\u8eab\u4f20\u611f\u5668\u6d4b\u5f97\u81ea\u52a8\u6807\u6ce8\uff0croad lanes\u548cdoorways\u8fd9\u91cc\u4f7f\u7528\u4e86\u4e00\u4e2apretrained FCN\u8fdb\u884c\u8bed\u4e49\u5206\u5272\u76f4\u63a5\u5f97\u5230\u7ed3\u679c \u4e09\u4e2a\u5b9e\u9a8c\u9879\u76ee \u4eff\u771f\u68ee\u6797\u8d70\u52a8 \u5956\u52b1\u51fd\u6570\u4e3a\uff1a R\\left(\\hat{E}_{t}^{(H, I)}\\right)=\\sum_{t^{\\prime}=t}^{t+H-1} 500 \\cdot\\left(1-\\hat{e}_{t^{\\prime}}^{(c o l l)}\\right)+\\left(\\cos \\left(\\hat{e}_{t^{\\prime}}^{(h e a d i n g)}-\\mathrm{GOAL}_{-} \\mathrm{HEADING}\\right)-1\\right) Carla\u4eff\u771f\u8fd0\u884c \u5956\u52b1\u51fd\u6570\u4e3a \\begin{aligned} R\\left(\\hat{E}_{t}^{(H, I)}\\right)=& \\sum_{t^{\\prime}=t}^{t+H-1} 50 \\cdot\\left(1-\\hat{e}_{t^{\\prime}}^{(c o l l)}\\right)-3 \\cdot \\frac{\\left|\\hat{e}_{t^{\\prime}}^{(s p e e d)}-\\operatorname{GOAL}_{-} \\operatorname{SPEB}\\right|}{\\operatorname{GOAL}_{-} \\operatorname{SPEED}}+5 \\cdot \\hat{e}_{t^{\\prime}}^{(l a n e-s e e n)}\\left(1-\\left|\\hat{e}_{t^{\\prime}}^{\\left(l a n e_{-} d i f f\\right)}\\right|\\right) \\\\ &-\\frac{5}{\\pi} \\cdot\\left|\\hat{e}_{t^{\\prime}}^{(h e a d i n g)}-\\operatorname{GOAL}_{-} \\operatorname{HEADING}\\right|-0.15 \\cdot\\left\\|\\mathbf{a}_{t^{\\prime}}^{(s t e e r)}\\right\\|_{2}^{2} \\end{aligned} \u9700\u8981\u9884\u6d4b\u7684\u5185\u5bb9\u5305\u62ec\uff1a\u78b0\u649e\u3001\u901f\u5ea6\u3001\u53ef\u89c1\u9053\u8def\u6bd4\u7387\u3001\u53ef\u89c1\u9053\u8def\u6bd4\u7387\u53d8\u5316\u7387\u3001\u671d\u5411 \u5b9e\u9645\u8f66\u8f86\u8fd0\u884c R\\left(\\hat{E}_{t}^{(H, I)}\\right)=\\sum_{t^{\\prime}=t}^{t+H-1}\\left(1-\\hat{e}_{t^{\\prime}}^{(c o l l)}\\right) \\cdot\\left[1-\\frac{0.1}{\\pi} \\cdot\\left|\\hat{e}_{t^{\\prime}}^{(h e a d i n g)}-\\operatorname{coth}_{-} \\operatorname{HEADING}\\right|+0.05 \\cdot \\hat{e}_{t^{\\prime}}^{(d o o r-f r a c)}\\right]-0.01 \\cdot\\left\\|\\mathbf{a}_{t^{\\prime}}\\right\\|_{2}^{2} \u9700\u8981\u9884\u6d4b\u7684\u5185\u5bb9\u5305\u62ec\uff1a\u78b0\u649e\u3001\u671d\u5411\u3001\u623f\u95f4\u95e8\u5360\u753b\u9762\u6bd4\u7387 \u5b83\u4eec\u4e3a\u4e86\u8bad\u7ec3Segmentation\u7f51\u7edc\u6807\u6ce8\u4e86\u8bad\u7ec3\u8fc7\u7a0b\u4e2d0.2%\u7684\u56fe\u50cf\u6570\u636e\u3002","title":"Composable Action-Conditioned Predictors: Flexible Off-Policy Learning for Robot Navigation"},{"location":"Robotics_with_DL/Composable_Action-Conditioned_Predictors_Flexible_Off-Policy_Learning_for_Robot_Navigation/#composable-action-conditioned-predictors-flexible-off-policy-learning-for-robot-navigation","text":"\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7075\u6d3b\u7684\u3001\u5c11\u76d1\u7763\u7684\u589e\u5f3a\u5b66\u4e60\u5bfc\u822a\u6846\u67b6\u3002\u6a21\u578b\u7684\u5b66\u4e60\u8fc7\u7a0b\u4f7f\u7528\u8f83\u4e3a\u6709\u9650\u7684\u76d1\u7763\uff0c\u540c\u4e00\u4e2a\u6a21\u578b\u53ef\u5728deploy\u65f6\u901a\u8fc7\u4fee\u6539reward\u51fd\u6570\u662f\u7684\u673a\u5668\u4eba\u8fbe\u5230\u6211\u4eec\u60f3\u8981\u7684\u5bfc\u822a\u6548\u679c","title":"Composable Action-Conditioned Predictors: Flexible Off-Policy Learning for Robot Navigation"},{"location":"Robotics_with_DL/Composable_Action-Conditioned_Predictors_Flexible_Off-Policy_Learning_for_Robot_Navigation/#caps","text":"CAPs\u7ed3\u6784\u7684\u76ee\u7684\u662f\u901a\u8fc7\u8f93\u5165\u7684\u56fe\u7247\u3001\u72b6\u6001\u5e8f\u5217\uff0c\u8f93\u51fa\u5f53\u524d\u72b6\u6001\u4e0b\u51e0\u4e2a\u91cd\u8981\u7684encoded event\u7684\u76f8\u5173\u53c2\u6570\u3002\u672c\u8bba\u6587\u4f7f\u7528\u7684\u662fcollision, heading\uff0c or road lanes and doorways(\u95e8\u5728\u56fe\u7247\u4e2d\u7684\u6bd4\u4f8b)\u3002\u8fc7\u7a0b\u662foff-policy\u7684\uff0c\u6a21\u578b\u53d6\u51b3\u4e8e\u4e00\u4e2a\u957f\u5ea6\u4e3aN\u7684\u672a\u6765\u7684action list\uff0c\u6570\u636e\u91c7\u96c6\u8fc7\u7a0b\u91c7\u7528\u7684policy\u4e0e\u6700\u7ec8deploy\u6ca1\u6709\u5fc5\u7136\u8054\u7cfb\u3002 \u5728deploy\u7684\u65f6\u5019\uff0c\u7528\u6237\u57fa\u4e8eencoded event\u5b9a\u4e49\u65b0\u7684reward function\uff0c \u7cfb\u7edf\u901a\u8fc7MPC\u4f18\u5316\u5b9e\u73b0\u63a7\u5236\u3002","title":"CAPs\u6a21\u578b\u4ecb\u7ecd"},{"location":"Robotics_with_DL/Composable_Action-Conditioned_Predictors_Flexible_Off-Policy_Learning_for_Robot_Navigation/#_1","text":"\u5377\u79ef\u63d0\u7279\u5f81->concat\u72b6\u6001\u5411\u91cf->\u5168\u8fde\u63a5-> multiplicative integration LSTM \u7684\u521d\u59cb\u72b6\u6001\u503c->\u8f93\u5165\u5e8f\u5217action->\u901a\u8fc7FC\u5206\u652f\u8f93\u51fa\u5404\u4e2aencoded event\u7684\u53c2\u6570","title":"\u6df1\u5ea6\u5b66\u4e60\u7ed3\u6784"},{"location":"Robotics_with_DL/Composable_Action-Conditioned_Predictors_Flexible_Off-Policy_Learning_for_Robot_Navigation/#encoded-events-event-cues","text":"\u8fd9\u91cc\u9009\u62e9\u7684collision\u4ee5\u53caheading\u4ee5\u53ca\u901f\u5ea6\u7b49\u53ef\u4ee5\u901a\u8fc7\u8f66\u8eab\u4f20\u611f\u5668\u6d4b\u5f97\u81ea\u52a8\u6807\u6ce8\uff0croad lanes\u548cdoorways\u8fd9\u91cc\u4f7f\u7528\u4e86\u4e00\u4e2apretrained FCN\u8fdb\u884c\u8bed\u4e49\u5206\u5272\u76f4\u63a5\u5f97\u5230\u7ed3\u679c","title":"encoded events (event cues)"},{"location":"Robotics_with_DL/Composable_Action-Conditioned_Predictors_Flexible_Off-Policy_Learning_for_Robot_Navigation/#_2","text":"","title":"\u4e09\u4e2a\u5b9e\u9a8c\u9879\u76ee"},{"location":"Robotics_with_DL/Composable_Action-Conditioned_Predictors_Flexible_Off-Policy_Learning_for_Robot_Navigation/#_3","text":"\u5956\u52b1\u51fd\u6570\u4e3a\uff1a R\\left(\\hat{E}_{t}^{(H, I)}\\right)=\\sum_{t^{\\prime}=t}^{t+H-1} 500 \\cdot\\left(1-\\hat{e}_{t^{\\prime}}^{(c o l l)}\\right)+\\left(\\cos \\left(\\hat{e}_{t^{\\prime}}^{(h e a d i n g)}-\\mathrm{GOAL}_{-} \\mathrm{HEADING}\\right)-1\\right)","title":"\u4eff\u771f\u68ee\u6797\u8d70\u52a8"},{"location":"Robotics_with_DL/Composable_Action-Conditioned_Predictors_Flexible_Off-Policy_Learning_for_Robot_Navigation/#carla","text":"\u5956\u52b1\u51fd\u6570\u4e3a \\begin{aligned} R\\left(\\hat{E}_{t}^{(H, I)}\\right)=& \\sum_{t^{\\prime}=t}^{t+H-1} 50 \\cdot\\left(1-\\hat{e}_{t^{\\prime}}^{(c o l l)}\\right)-3 \\cdot \\frac{\\left|\\hat{e}_{t^{\\prime}}^{(s p e e d)}-\\operatorname{GOAL}_{-} \\operatorname{SPEB}\\right|}{\\operatorname{GOAL}_{-} \\operatorname{SPEED}}+5 \\cdot \\hat{e}_{t^{\\prime}}^{(l a n e-s e e n)}\\left(1-\\left|\\hat{e}_{t^{\\prime}}^{\\left(l a n e_{-} d i f f\\right)}\\right|\\right) \\\\ &-\\frac{5}{\\pi} \\cdot\\left|\\hat{e}_{t^{\\prime}}^{(h e a d i n g)}-\\operatorname{GOAL}_{-} \\operatorname{HEADING}\\right|-0.15 \\cdot\\left\\|\\mathbf{a}_{t^{\\prime}}^{(s t e e r)}\\right\\|_{2}^{2} \\end{aligned} \u9700\u8981\u9884\u6d4b\u7684\u5185\u5bb9\u5305\u62ec\uff1a\u78b0\u649e\u3001\u901f\u5ea6\u3001\u53ef\u89c1\u9053\u8def\u6bd4\u7387\u3001\u53ef\u89c1\u9053\u8def\u6bd4\u7387\u53d8\u5316\u7387\u3001\u671d\u5411","title":"Carla\u4eff\u771f\u8fd0\u884c"},{"location":"Robotics_with_DL/Composable_Action-Conditioned_Predictors_Flexible_Off-Policy_Learning_for_Robot_Navigation/#_4","text":"R\\left(\\hat{E}_{t}^{(H, I)}\\right)=\\sum_{t^{\\prime}=t}^{t+H-1}\\left(1-\\hat{e}_{t^{\\prime}}^{(c o l l)}\\right) \\cdot\\left[1-\\frac{0.1}{\\pi} \\cdot\\left|\\hat{e}_{t^{\\prime}}^{(h e a d i n g)}-\\operatorname{coth}_{-} \\operatorname{HEADING}\\right|+0.05 \\cdot \\hat{e}_{t^{\\prime}}^{(d o o r-f r a c)}\\right]-0.01 \\cdot\\left\\|\\mathbf{a}_{t^{\\prime}}\\right\\|_{2}^{2} \u9700\u8981\u9884\u6d4b\u7684\u5185\u5bb9\u5305\u62ec\uff1a\u78b0\u649e\u3001\u671d\u5411\u3001\u623f\u95f4\u95e8\u5360\u753b\u9762\u6bd4\u7387 \u5b83\u4eec\u4e3a\u4e86\u8bad\u7ec3Segmentation\u7f51\u7edc\u6807\u6ce8\u4e86\u8bad\u7ec3\u8fc7\u7a0b\u4e2d0.2%\u7684\u56fe\u50cf\u6570\u636e\u3002","title":"\u5b9e\u9645\u8f66\u8f86\u8fd0\u884c"},{"location":"Robotics_with_DL/Differentiable Algorithm Networks forComposable Robot Learning/","text":"Differentiable Algorithm Networks for Composable Robot Learning \u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u53ef\u5fae\u5206\u7b97\u6cd5\u7f51\u7edc\uff0c\u5176\u5b9e\u4e5f\u5c31\u662f\u5206\u6a21\u5757\u5730\u5b9e\u73b0\u53ef\u5fae\u5206\u7aef\u5230\u7aef\u8bad\u7ec3\u3002 \u57fa\u672c\u601d\u8def\u548cQMDP-Net\u4e00\u81f4\u3002","title":"Differentiable Algorithm Networks for Composable Robot Learning"},{"location":"Robotics_with_DL/Differentiable Algorithm Networks forComposable Robot Learning/#differentiable-algorithm-networks-for-composable-robot-learning","text":"\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u53ef\u5fae\u5206\u7b97\u6cd5\u7f51\u7edc\uff0c\u5176\u5b9e\u4e5f\u5c31\u662f\u5206\u6a21\u5757\u5730\u5b9e\u73b0\u53ef\u5fae\u5206\u7aef\u5230\u7aef\u8bad\u7ec3\u3002 \u57fa\u672c\u601d\u8def\u548cQMDP-Net\u4e00\u81f4\u3002","title":"Differentiable Algorithm Networks for Composable Robot Learning"},{"location":"Robotics_with_DL/Differentiable MPC for End-to-end Planning and Control/","text":"Differentiable MPC for End-to-end Planning and Control \u8fd9\u7bc7\u8bba\u6587\u5ef6\u7eed\u4e86 OptNet \u7684\u601d\u8def\uff0c\u4e5f\u5c31\u662f\u901a\u8fc7\u6c42\u89e3\u53ef\u5b66\u4e60\u7684\u4e8c\u6b21\u6700\u4f18\u6765\u5f97\u5230\u6700\u4f18\u63a7\u5236\u7684\u6548\u679c","title":"Differentiable MPC for End-to-end Planning and Control"},{"location":"Robotics_with_DL/Differentiable MPC for End-to-end Planning and Control/#differentiable-mpc-for-end-to-end-planning-and-control","text":"\u8fd9\u7bc7\u8bba\u6587\u5ef6\u7eed\u4e86 OptNet \u7684\u601d\u8def\uff0c\u4e5f\u5c31\u662f\u901a\u8fc7\u6c42\u89e3\u53ef\u5b66\u4e60\u7684\u4e8c\u6b21\u6700\u4f18\u6765\u5f97\u5230\u6700\u4f18\u63a7\u5236\u7684\u6548\u679c","title":"Differentiable MPC for End-to-end Planning and Control"},{"location":"Robotics_with_DL/Intention-Net Integrating Planning and DeepLearning for Goal-Directed Autonomous Navigation/","text":"Intention-Net: Integrating Planning and DeepLearning for Goal-Directed Autonomous Navigation \u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86Intention Net\u3002\u7ed9\u51fa\u4e86\u4e24\u79cd\u6982\u5ff5\u4ee5\u53ca\uff0c\u4e00\u4e2a\u662fDLM(Discrete Local Motion)\u53ca\u5176\u7f51\u7edc\uff0c\u4e00\u4e2a\u662fLPE(local path and environment)\u53ca\u5176\u7f51\u7edc DLM\uff1a\u79bb\u6563\u5c40\u90e8\u8fd0\u52a8 \u672c\u6587\u7684\u79bb\u6563\u5c40\u90e8\u8fd0\u52a8\u4e5f\u5c31\u662f\u6307\u5f53\u524d\u5efa\u8bae\uff08\u547d\u4ee4\uff09\u7684\u5c40\u90e8\u8fd0\u52a8\uff0c\u6bd4\u5982\u8bf4\u5de6\u53f3\u8f6c\u3001\u76f4\u884c\u4ee5\u53ca\u505c\u8f66\uff0c\u8bba\u6587\u5b9e\u73b0\u7684\u662f\u901a\u8fc7\u5f53\u524d\u8def\u5f84\u7684\u66f2\u7387\u6765\u5224\u5b9a\u5c40\u90e8\u8fd0\u52a8\u7684\u3002 \u4f46\u662f\u53ef\u4ee5\u7531\u5b9a\u4e49\u770b\u5230\uff0c\u8fd9\u4e2a\u662f\u4e00\u4e2a\u4e0d\u5b8c\u6574\u7684\u63cf\u8ff0\uff0c\u6bd4\u5982\u8bf4\u524d\u65b9\u6709\u591a\u4e2a\u5206\u5c94\u53e3\u65f6\u5de6\u53f3\u8f6c\u4fe1\u606f\u5e76\u4e0d\u5145\u5206\u3002 LPE\uff1a\u5c40\u90e8\u8def\u5f84\u4e0e\u73af\u5883 \u672c\u6587\u7684\u5c40\u90e8\u8def\u5f84\u4e0e\u73af\u5883\uff0c\u7528\u4e00\u4e2a224*224\u7684\u9e1f\u77b0\u89c6\u89d2\u7684\u56fe\u7247\uff0c\u56fe\u4e2d\u5305\u542b\u5730\u56fe\u4e2d\u7684\u969c\u788d\u7269\u4fe1\u606f(costmap)\u3001\u6700\u8fd1\u8d70\u8fc7\u7684\u8f68\u8ff9\u3001\u4ee5\u53ca\u5c06\u6765\u89c4\u5212\u7684\u8f68\u8ff9 \u7f51\u7edc\u7ed3\u6784 \u5206\u522b\u7528\u8fd9\u4e24\u4e2a\u7ed3\u6784\uff0c\u5728\u63a5\u53d7\u8def\u5f84\u89c4\u5212\u7684\u5c40\u90e8\u8def\u5f84\u8f93\u5165\u4ee5\u53ca\u5730\u56fe\u4fe1\u606f\u4e4b\u540e\u8f93\u51fa\u63a7\u5236\u6307\u4ee4\uff0c\u53ef\u4ee5\u7aef\u5230\u7aef\u5b66\u4e60\u3002","title":"Intention-Net: Integrating Planning and DeepLearning for Goal-Directed Autonomous Navigation"},{"location":"Robotics_with_DL/Intention-Net Integrating Planning and DeepLearning for Goal-Directed Autonomous Navigation/#intention-net-integrating-planning-and-deeplearning-for-goal-directed-autonomous-navigation","text":"\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86Intention Net\u3002\u7ed9\u51fa\u4e86\u4e24\u79cd\u6982\u5ff5\u4ee5\u53ca\uff0c\u4e00\u4e2a\u662fDLM(Discrete Local Motion)\u53ca\u5176\u7f51\u7edc\uff0c\u4e00\u4e2a\u662fLPE(local path and environment)\u53ca\u5176\u7f51\u7edc","title":"Intention-Net: Integrating Planning and DeepLearning for Goal-Directed Autonomous Navigation"},{"location":"Robotics_with_DL/Intention-Net Integrating Planning and DeepLearning for Goal-Directed Autonomous Navigation/#dlm","text":"\u672c\u6587\u7684\u79bb\u6563\u5c40\u90e8\u8fd0\u52a8\u4e5f\u5c31\u662f\u6307\u5f53\u524d\u5efa\u8bae\uff08\u547d\u4ee4\uff09\u7684\u5c40\u90e8\u8fd0\u52a8\uff0c\u6bd4\u5982\u8bf4\u5de6\u53f3\u8f6c\u3001\u76f4\u884c\u4ee5\u53ca\u505c\u8f66\uff0c\u8bba\u6587\u5b9e\u73b0\u7684\u662f\u901a\u8fc7\u5f53\u524d\u8def\u5f84\u7684\u66f2\u7387\u6765\u5224\u5b9a\u5c40\u90e8\u8fd0\u52a8\u7684\u3002 \u4f46\u662f\u53ef\u4ee5\u7531\u5b9a\u4e49\u770b\u5230\uff0c\u8fd9\u4e2a\u662f\u4e00\u4e2a\u4e0d\u5b8c\u6574\u7684\u63cf\u8ff0\uff0c\u6bd4\u5982\u8bf4\u524d\u65b9\u6709\u591a\u4e2a\u5206\u5c94\u53e3\u65f6\u5de6\u53f3\u8f6c\u4fe1\u606f\u5e76\u4e0d\u5145\u5206\u3002","title":"DLM\uff1a\u79bb\u6563\u5c40\u90e8\u8fd0\u52a8"},{"location":"Robotics_with_DL/Intention-Net Integrating Planning and DeepLearning for Goal-Directed Autonomous Navigation/#lpe","text":"\u672c\u6587\u7684\u5c40\u90e8\u8def\u5f84\u4e0e\u73af\u5883\uff0c\u7528\u4e00\u4e2a224*224\u7684\u9e1f\u77b0\u89c6\u89d2\u7684\u56fe\u7247\uff0c\u56fe\u4e2d\u5305\u542b\u5730\u56fe\u4e2d\u7684\u969c\u788d\u7269\u4fe1\u606f(costmap)\u3001\u6700\u8fd1\u8d70\u8fc7\u7684\u8f68\u8ff9\u3001\u4ee5\u53ca\u5c06\u6765\u89c4\u5212\u7684\u8f68\u8ff9","title":"LPE\uff1a\u5c40\u90e8\u8def\u5f84\u4e0e\u73af\u5883"},{"location":"Robotics_with_DL/Intention-Net Integrating Planning and DeepLearning for Goal-Directed Autonomous Navigation/#_1","text":"\u5206\u522b\u7528\u8fd9\u4e24\u4e2a\u7ed3\u6784\uff0c\u5728\u63a5\u53d7\u8def\u5f84\u89c4\u5212\u7684\u5c40\u90e8\u8def\u5f84\u8f93\u5165\u4ee5\u53ca\u5730\u56fe\u4fe1\u606f\u4e4b\u540e\u8f93\u51fa\u63a7\u5236\u6307\u4ee4\uff0c\u53ef\u4ee5\u7aef\u5230\u7aef\u5b66\u4e60\u3002","title":"\u7f51\u7edc\u7ed3\u6784"},{"location":"Robotics_with_DL/MachineLearningForRobotPlanningAndContrlGeorgiaTech/","text":"Machine Learning for Robot Planning and Control from Byron Boots Georgia Tech Robot Learning Lab \u672c\u6587\u5148\u8ba8\u8bba\u5f00\u8f66\u8fd9\u4e2a\u95ee\u9898\uff0c\u5e76\u5f15\u51fa\u6df1\u5ea6\u5b66\u4e60\u5728\u673a\u5668\u4eba\u63a7\u5236\u4e0e\u89c4\u5212\u4e2d\u7684\u5229\u7528\u7684\u4e00\u4e2a\u4e09\u89d2\u56fe\u3002 MPC \u7b2c\u4e00\u90e8\u5206\u5148\u96c6\u4e2d\u8ba8\u8bbaMPC\uff0cMPC\u662f\u4e00\u4e2a\u6210\u529f\u7684\u7b97\u6cd5\u4ee5\u53ca\u89e3\u51b3\u95ee\u9898\u7684\u65b9\u5f0f\uff0c\u4f46\u662f\u5927\u5bb6\u666e\u904d\u8ba4\u4e3a\u6210\u529f\u7684\u4f20\u7edfMPC\u6709\u4e00\u4e9b\u95ee\u9898\u3002\u603b\u7ed3\u8d77\u6765\uff0cMPC\u95ee\u9898\u4e00\u662f\u975e\u7ebf\u6027(\u52a8\u529b\u5b66\u4e0e\u7ea6\u675f)\uff0c\u95ee\u9898\u4e8c\u662f\u6a21\u578b\u4e0d\u51c6\u786e\u3002 \u7136\u540e\u4ecb\u7ecd\u4e86 MPPI\u7b97\u6cd5 \u8fd9\u91cc\u63cf\u8ff0\u7684\u53e6\u4e00\u4e2a\u95ee\u9898\u662f\u5728\u4f7f\u7528MPPI\u7b97\u6cd5\u5b9e\u65f6\u5b66\u4e60\u7684\u65f6\u5019\uff0c\u5b58\u5728\u4e00\u4e2a\u63a2\u7d22\u7684\u95ee\u9898\uff0c\u8f93\u5165\u9700\u8981\u4e30\u5bcc\uff0c\u540c\u65f6\u4e0e\u5b9e\u9645\u7684\u8f93\u5165\u5206\u5e03\u76f8\u4f3c\u3002 \u8981\u7f13\u89e3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6f14\u8bb2\u8005\u4f7f\u7528\u7684\u5176\u4e2d\u4e00\u4e2a\u65b9\u6cd5\u662f\u5148\u7528human driver\u5f97\u5230\u521d\u59cb\u6570\u636e\uff0c\u5bf9\u6a21\u578b\u8fdb\u884c\u521d\u59cb\u8bad\u7ec3(bootstrapping)\u3002 Imitation \u63a5\u7740\u6211\u4eec\u8ba8\u8bba\u6a21\u4eff\u5b66\u4e60\u4ee5\u53ca\u5728\u4e13\u5bb6\u5f15\u5bfc\u4e0b\u7684\u63a2\u7d22\u95ee\u9898\u3002 \u8fd9\u91cc\u6307\u5411\u4e86 AggreVaTeD (Aggregate Values to Imitate) [Sun, Venkatraman, Gordon, Boots, Bagnell; ICML 2017]\u3002 \u6682\u672a\u6536\u5f55\u6b64\u8bba\u6587 Parameterized a Robot \u8fd9\u91cc\u6307\u5411\u4e86differentiable MPC(\u8fd9\u7bc7\u8bba\u6587\u53c8\u5f88\u91cd\u8981\u5730\u53c2\u8003\u4e86OptNet)\uff0c","title":"Machine Learning for Robot Planning and Control from  Byron Boots Georgia Tech Robot Learning Lab"},{"location":"Robotics_with_DL/MachineLearningForRobotPlanningAndContrlGeorgiaTech/#machine-learning-for-robot-planning-and-control-from-byron-boots-georgia-tech-robot-learning-lab","text":"\u672c\u6587\u5148\u8ba8\u8bba\u5f00\u8f66\u8fd9\u4e2a\u95ee\u9898\uff0c\u5e76\u5f15\u51fa\u6df1\u5ea6\u5b66\u4e60\u5728\u673a\u5668\u4eba\u63a7\u5236\u4e0e\u89c4\u5212\u4e2d\u7684\u5229\u7528\u7684\u4e00\u4e2a\u4e09\u89d2\u56fe\u3002","title":"Machine Learning for Robot Planning and Control from  Byron Boots Georgia Tech Robot Learning Lab"},{"location":"Robotics_with_DL/MachineLearningForRobotPlanningAndContrlGeorgiaTech/#mpc","text":"\u7b2c\u4e00\u90e8\u5206\u5148\u96c6\u4e2d\u8ba8\u8bbaMPC\uff0cMPC\u662f\u4e00\u4e2a\u6210\u529f\u7684\u7b97\u6cd5\u4ee5\u53ca\u89e3\u51b3\u95ee\u9898\u7684\u65b9\u5f0f\uff0c\u4f46\u662f\u5927\u5bb6\u666e\u904d\u8ba4\u4e3a\u6210\u529f\u7684\u4f20\u7edfMPC\u6709\u4e00\u4e9b\u95ee\u9898\u3002\u603b\u7ed3\u8d77\u6765\uff0cMPC\u95ee\u9898\u4e00\u662f\u975e\u7ebf\u6027(\u52a8\u529b\u5b66\u4e0e\u7ea6\u675f)\uff0c\u95ee\u9898\u4e8c\u662f\u6a21\u578b\u4e0d\u51c6\u786e\u3002 \u7136\u540e\u4ecb\u7ecd\u4e86 MPPI\u7b97\u6cd5 \u8fd9\u91cc\u63cf\u8ff0\u7684\u53e6\u4e00\u4e2a\u95ee\u9898\u662f\u5728\u4f7f\u7528MPPI\u7b97\u6cd5\u5b9e\u65f6\u5b66\u4e60\u7684\u65f6\u5019\uff0c\u5b58\u5728\u4e00\u4e2a\u63a2\u7d22\u7684\u95ee\u9898\uff0c\u8f93\u5165\u9700\u8981\u4e30\u5bcc\uff0c\u540c\u65f6\u4e0e\u5b9e\u9645\u7684\u8f93\u5165\u5206\u5e03\u76f8\u4f3c\u3002 \u8981\u7f13\u89e3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6f14\u8bb2\u8005\u4f7f\u7528\u7684\u5176\u4e2d\u4e00\u4e2a\u65b9\u6cd5\u662f\u5148\u7528human driver\u5f97\u5230\u521d\u59cb\u6570\u636e\uff0c\u5bf9\u6a21\u578b\u8fdb\u884c\u521d\u59cb\u8bad\u7ec3(bootstrapping)\u3002","title":"MPC"},{"location":"Robotics_with_DL/MachineLearningForRobotPlanningAndContrlGeorgiaTech/#imitation","text":"\u63a5\u7740\u6211\u4eec\u8ba8\u8bba\u6a21\u4eff\u5b66\u4e60\u4ee5\u53ca\u5728\u4e13\u5bb6\u5f15\u5bfc\u4e0b\u7684\u63a2\u7d22\u95ee\u9898\u3002 \u8fd9\u91cc\u6307\u5411\u4e86 AggreVaTeD (Aggregate Values to Imitate) [Sun, Venkatraman, Gordon, Boots, Bagnell; ICML 2017]\u3002 \u6682\u672a\u6536\u5f55\u6b64\u8bba\u6587","title":"Imitation"},{"location":"Robotics_with_DL/MachineLearningForRobotPlanningAndContrlGeorgiaTech/#parameterized-a-robot","text":"\u8fd9\u91cc\u6307\u5411\u4e86differentiable MPC(\u8fd9\u7bc7\u8bba\u6587\u53c8\u5f88\u91cd\u8981\u5730\u53c2\u8003\u4e86OptNet)\uff0c","title":"Parameterized a Robot"},{"location":"Robotics_with_DL/OptNet_Differentiable_Optimization_as_a_Layer_in_Neural_Networks/","text":"OptNet: Differentiable Optimization as a Layer in Neural Networks \u8fd9\u7bc7\u8bba\u6587\u5b9a\u4e49\u4e86\u4e00\u4e2a\u57fa\u4e8e\u7ebf\u6027\u4e8c\u6b21\u4f18\u5316\u7684\u65b0\u7684\u795e\u7ecf\u7f51\u7edc\u5c42 \u8fd9\u4e2a\u5c42\u5bf9\u5e94\u7684\u4f18\u5316\u95ee\u9898\u5982\u4e0b z_{i+1} = argmin(frac{1}{2} z^T Q(z_i) z + q(z_i) z) \u7b26\u5408\u7ea6\u675f A(z_i)z = b(z_i) \u4e0e G(z_i)z <= h(z_i) \u5176\u4e2d Q,q,A,b,G,h \u90fd\u662f\u53ef\u4ee5\u8ddf\u968f\u8f93\u5165 z \u53d8\u5316\u7684\u503c\uff0c\u8bba\u6587\u63d0\u51fa\u4e86\u6c42\u89e3\u8fd9\u4e2a\u4f18\u5316\u95ee\u9898\u4ee5\u53ca\u6c42\u51fa\u8fd9\u4e2a\u4f18\u5316\u95ee\u9898\u5bf9\u5e94\u7684\u68af\u5ea6\u7684\u5feb\u901f\u65b9\u5f0f\u3002 \u6838\u5fc3\u601d\u8def\u4e0e\u516c\u5f0f \u6838\u5fc3\u601d\u8def\u662f\u5728\u53cd\u4f20\u7684\u65f6\u5019\u4f7f\u7528KKT condition\uff0c\u4e5f\u5c31\u662f\u5047\u8bbe\u4f18\u5316\u95ee\u9898\u5df2\u7ecf\u5f97\u5230\u4e86\u6700\u4f18\u89e3\uff0c\u5bf9KKT condition\u8fdb\u884c\u6c42\u5fae\u5206\u5f97\u5230\u5404\u4e2a\u5143\u7d20\u4e4b\u95f4\u7684\u5fae\u5206\u5173\u7cfb\uff08\u8bba\u6587\u516c\u5f0f6-8\uff09 \u53e6\u5916\u9700\u8981\u5728GPU\u4e0a\u5b9e\u73b0\u5b8c\u6574\u7684\u4f18\u5316\u7b97\u6cd5\uff0c\u4f5c\u8005\u4f7f\u7528\u4e86\u516c\u5f0f(9-10)\uff08\u66f4\u591a\u7684\u516c\u5f0f\u5efa\u8bae\u67e5\u770bgithub\uff0cqpth\u5e93\uff09","title":"OptNet: Differentiable Optimization as a Layer in Neural Networks"},{"location":"Robotics_with_DL/OptNet_Differentiable_Optimization_as_a_Layer_in_Neural_Networks/#optnet-differentiable-optimization-as-a-layer-in-neural-networks","text":"\u8fd9\u7bc7\u8bba\u6587\u5b9a\u4e49\u4e86\u4e00\u4e2a\u57fa\u4e8e\u7ebf\u6027\u4e8c\u6b21\u4f18\u5316\u7684\u65b0\u7684\u795e\u7ecf\u7f51\u7edc\u5c42 \u8fd9\u4e2a\u5c42\u5bf9\u5e94\u7684\u4f18\u5316\u95ee\u9898\u5982\u4e0b z_{i+1} = argmin(frac{1}{2} z^T Q(z_i) z + q(z_i) z) \u7b26\u5408\u7ea6\u675f A(z_i)z = b(z_i) \u4e0e G(z_i)z <= h(z_i) \u5176\u4e2d Q,q,A,b,G,h \u90fd\u662f\u53ef\u4ee5\u8ddf\u968f\u8f93\u5165 z \u53d8\u5316\u7684\u503c\uff0c\u8bba\u6587\u63d0\u51fa\u4e86\u6c42\u89e3\u8fd9\u4e2a\u4f18\u5316\u95ee\u9898\u4ee5\u53ca\u6c42\u51fa\u8fd9\u4e2a\u4f18\u5316\u95ee\u9898\u5bf9\u5e94\u7684\u68af\u5ea6\u7684\u5feb\u901f\u65b9\u5f0f\u3002","title":"OptNet: Differentiable Optimization as a Layer in Neural Networks"},{"location":"Robotics_with_DL/OptNet_Differentiable_Optimization_as_a_Layer_in_Neural_Networks/#_1","text":"\u6838\u5fc3\u601d\u8def\u662f\u5728\u53cd\u4f20\u7684\u65f6\u5019\u4f7f\u7528KKT condition\uff0c\u4e5f\u5c31\u662f\u5047\u8bbe\u4f18\u5316\u95ee\u9898\u5df2\u7ecf\u5f97\u5230\u4e86\u6700\u4f18\u89e3\uff0c\u5bf9KKT condition\u8fdb\u884c\u6c42\u5fae\u5206\u5f97\u5230\u5404\u4e2a\u5143\u7d20\u4e4b\u95f4\u7684\u5fae\u5206\u5173\u7cfb\uff08\u8bba\u6587\u516c\u5f0f6-8\uff09 \u53e6\u5916\u9700\u8981\u5728GPU\u4e0a\u5b9e\u73b0\u5b8c\u6574\u7684\u4f18\u5316\u7b97\u6cd5\uff0c\u4f5c\u8005\u4f7f\u7528\u4e86\u516c\u5f0f(9-10)\uff08\u66f4\u591a\u7684\u516c\u5f0f\u5efa\u8bae\u67e5\u770bgithub\uff0cqpth\u5e93\uff09","title":"\u6838\u5fc3\u601d\u8def\u4e0e\u516c\u5f0f"},{"location":"Robotics_with_DL/PHOTOREALISTIC IMAGE RECONSTRUCTION FROM_HYBRID_INTENSITY_AND_EVENT_BASED_SENSOR/","text":"Photorealistic Image Reconstruction From Hybrid Intensity and Event Based Sensor \u8fd9\u7bc7\u8bba\u6587\u89e3\u51b3\u7684\u4efb\u52a1\u5982\u4e0b\uff0c\u8f93\u5165\u8fde\u7eed\u7684\u666e\u901a\u56fe\u7247\u4ee5\u53ca\u4e00\u7cfb\u5217\u5bc6\u96c6\u7684event camera\u4fe1\u606f\uff0c\u8fd8\u539f\u51fa\u66f4\u52a0\u771f\u5b9e\u7684\u539f\u59cb\u56fe\u7247,\u5173\u4e8eevent camera\u7684\u57fa\u7840\u539f\u7406\u4ee5\u53ca\u5bf9\u56fe\u7247\u7684\u589e\u5f3a\uff0c\u8fd9\u91cc\u53ef\u53c2\u8003 \u8fd9\u7bc7\u8bba\u6587 \u5de5\u4f5c\u6d41\u7a0b \u8fd9\u91cc\u5206\u4e3a\u56db\u4e2a\u6b65\u9aa4\uff0c\u7b2c\u4e00\u6b65\u662f\u901a\u8fc7\u4e24\u5f20\u57fa\u7840\u56fe\u7247\u5f97\u5230\u6df1\u5ea6\u4f30\u8ba1\u3002\u7b2c\u4e8c\u6b65\u662f\u4f7f\u7528event frames\u5b9e\u73b0\u5bf9\u4e2d\u95f4\u5e27\u7684\u63d2\u503c\uff0c\u7b2c\u4e09\u6b65\u662f\u5bf9\u63d2\u503c\u7ed3\u679c\u4f7f\u7528VO\u5f97\u5230\u4e00\u4e2a\u4f4d\u59ff\u4f30\u8ba1\uff0c\u7b2c\u56db\u6b65\u662f\u6839\u636e\u6df1\u5ea6\u4e0e\u59ff\u6001\u5f97\u5230\u8f6c\u6362\u540e\u7684\u5f3a\u5ea6\u56fe\u3002 \u6df1\u5ea6\u4f30\u8ba1 \u901a\u8fc7\u5149\u6d41\u521d\u59cb\u5316\u6df1\u5ea6\u4f30\u8ba1 d_k, d_{k+1} \uff0c\u5c06\u76f8\u5bf9\u4f4d\u79fb\u4e0e\u65cb\u8f6c\u521d\u59cb\u5316\u4e3a0,\u6839\u636e\u6df1\u5ea6\u4ee5\u53ca\u4f4d\u79fb\uff0c\u53ef\u4ee5\u8ba9\u4e24\u5f20\u56fe\u76f8\u4e92\u8f6c\u6362\uff0c\u8fd9\u91cc\u5b9a\u4e49\u91cd\u6784\u635f\u5931 \\mathcal{L}_{p h}\\left(d_{k}, d_{k+1}, \\xi\\right)=\\left\\|\\left(\\hat{I}_{k}-I_{k}\\right)\\right\\|_{1}+\\left\\|\\left(\\hat{I}_{k+1}-I_{k+1}\\right)\\right\\|_{1} \u8fdb\u4e00\u6b65\u5b9a\u4e49\u4e00\u4e2a\u4e0eedge\u6709\u5173\u7684\u635f\u5931 \\mathcal{L}_{s m}(d)=\\sum\\left\\|\\nabla_{x} d\\right\\| e^{-\\beta\\left\\|\\nabla_{x} I\\right\\|}+\\left\\|\\nabla_{y} d\\right\\| e^{-\\beta\\left\\|\\nabla_{y} I\\right\\|} \u5176\u4e2d d \u4e3a\u6df1\u5ea6\u56fe \\nabla_x, \\nabla_y \u6307\u7684\u662fx,y\u65b9\u5411\u7684\u8fd0\u7b97\u7b26, \u4f18\u5316\u4ee5\u4e0a\u4e24\u4e2a\u635f\u5931\u51fd\u6570\u7684\u52a0\u6743\u6c42\u548c\u662f\u4e00\u4e2a\u975e\u51f8\u95ee\u9898\uff0c\u6211\u4eec\u9700\u8981\u4e00\u4e2a\u597d\u7684\u5c40\u90e8\u89e3\u4f5c\u4e3a\u521d\u59cb\u89e3\u3002\u8fd9\u91cc\u4f7f\u7528 PWC-Net \u751f\u6210\u521d\u59cb\u5149\u6d41\uff0c\u8fd9\u91cc\u4f7f\u7528\u5149\u6d41\u7684inverse\u76f4\u63a5\u5f97\u5230\u6df1\u5ea6\u521d\u59cb\u503c\u3002 \u76f8\u5bf9\u4f4d\u79fb\u4f30\u8ba1 \u8fd9\u91cc\u4f7f\u7528event camera\u5bf9\u4e24\u5e27\u4e4b\u95f4\u7684\u56fe\u50cf\u8fdb\u884c\u63d2\u503c\uff0c\u751f\u6210\u4e00\u7cfb\u5217\u7684\u4e2d\u95f4\u56fe\u50cf\u3002 \\begin{aligned} \\mathcal{L}_{p}\\left(\\xi_{k}^{j}\\right) &=\\left\\|E_{k}^{0}-\\hat{E}_{k}^{0}\\right\\|_{1} \\\\ \\mathcal{L}_{p}\\left(\\xi_{k+1}^{j}\\right) &=\\left\\|E_{k+1}^{0}-\\hat{E}_{k+1}^{0}\\right\\|_{1} \\end{aligned} \\xi_{k}^{j}, \\xi_{k+1}^{j}=\\underset{\\xi_{k}^{j}, \\xi_{k+1}^{j}}{\\arg \\min } \\mathcal{L}_{p}\\left(\\xi_{k}^{j}\\right)+\\mathcal{L}_{p}\\left(\\xi_{k+1}^{j}\\right)+\\lambda_{r} \\mathcal{L}_{p}\\left(\\xi_{k}^{j}, \\xi_{k+1}^{j}\\right) \u5176\u4e2d \\xi^j_k,\\xi^j_{k+1} \u5206\u522b\u6307\u4ee3\u7b2c j \u5f20\u4e2d\u95f4\u56fe\u76f8\u5bf9\u4e8e\u7b2c\u4e00\u5e27\u3001\u4e0b\u4e00\u5e27\u4e4b\u95f4\u7684\u76f8\u5bf9\u4f4d\u59ff\u53d8\u5316\uff0c \u878d\u5408 \u6839\u636e\u6df1\u5ea6\u3001\u591a\u4e2a\u4e2d\u95f4\u503c\u7684\u4f4d\u59ff\uff0c\u5c06\u7b2c\u4e00\u5e27\u4e0e\u7b2c\u4e8c\u5e27\u5206\u522b\u5411\u540e\u3001\u5411\u524dwarp\uff0calpha-blend\u4e24\u6b21\u7684\u7ed3\u679c\uff0c\u5f97\u5230\u4e00\u7cfb\u5217\u66f4\u7cbe\u786e\u7684\u9996\u5c3e\u4e0e\u4e2d\u95f4\u56fe\u3002","title":"Photorealistic Image Reconstruction From Hybrid Intensity and Event Based Sensor"},{"location":"Robotics_with_DL/PHOTOREALISTIC IMAGE RECONSTRUCTION FROM_HYBRID_INTENSITY_AND_EVENT_BASED_SENSOR/#photorealistic-image-reconstruction-from-hybrid-intensity-and-event-based-sensor","text":"\u8fd9\u7bc7\u8bba\u6587\u89e3\u51b3\u7684\u4efb\u52a1\u5982\u4e0b\uff0c\u8f93\u5165\u8fde\u7eed\u7684\u666e\u901a\u56fe\u7247\u4ee5\u53ca\u4e00\u7cfb\u5217\u5bc6\u96c6\u7684event camera\u4fe1\u606f\uff0c\u8fd8\u539f\u51fa\u66f4\u52a0\u771f\u5b9e\u7684\u539f\u59cb\u56fe\u7247,\u5173\u4e8eevent camera\u7684\u57fa\u7840\u539f\u7406\u4ee5\u53ca\u5bf9\u56fe\u7247\u7684\u589e\u5f3a\uff0c\u8fd9\u91cc\u53ef\u53c2\u8003 \u8fd9\u7bc7\u8bba\u6587","title":"Photorealistic Image Reconstruction From Hybrid Intensity and Event Based Sensor"},{"location":"Robotics_with_DL/PHOTOREALISTIC IMAGE RECONSTRUCTION FROM_HYBRID_INTENSITY_AND_EVENT_BASED_SENSOR/#_1","text":"\u8fd9\u91cc\u5206\u4e3a\u56db\u4e2a\u6b65\u9aa4\uff0c\u7b2c\u4e00\u6b65\u662f\u901a\u8fc7\u4e24\u5f20\u57fa\u7840\u56fe\u7247\u5f97\u5230\u6df1\u5ea6\u4f30\u8ba1\u3002\u7b2c\u4e8c\u6b65\u662f\u4f7f\u7528event frames\u5b9e\u73b0\u5bf9\u4e2d\u95f4\u5e27\u7684\u63d2\u503c\uff0c\u7b2c\u4e09\u6b65\u662f\u5bf9\u63d2\u503c\u7ed3\u679c\u4f7f\u7528VO\u5f97\u5230\u4e00\u4e2a\u4f4d\u59ff\u4f30\u8ba1\uff0c\u7b2c\u56db\u6b65\u662f\u6839\u636e\u6df1\u5ea6\u4e0e\u59ff\u6001\u5f97\u5230\u8f6c\u6362\u540e\u7684\u5f3a\u5ea6\u56fe\u3002","title":"\u5de5\u4f5c\u6d41\u7a0b"},{"location":"Robotics_with_DL/PHOTOREALISTIC IMAGE RECONSTRUCTION FROM_HYBRID_INTENSITY_AND_EVENT_BASED_SENSOR/#_2","text":"\u901a\u8fc7\u5149\u6d41\u521d\u59cb\u5316\u6df1\u5ea6\u4f30\u8ba1 d_k, d_{k+1} \uff0c\u5c06\u76f8\u5bf9\u4f4d\u79fb\u4e0e\u65cb\u8f6c\u521d\u59cb\u5316\u4e3a0,\u6839\u636e\u6df1\u5ea6\u4ee5\u53ca\u4f4d\u79fb\uff0c\u53ef\u4ee5\u8ba9\u4e24\u5f20\u56fe\u76f8\u4e92\u8f6c\u6362\uff0c\u8fd9\u91cc\u5b9a\u4e49\u91cd\u6784\u635f\u5931 \\mathcal{L}_{p h}\\left(d_{k}, d_{k+1}, \\xi\\right)=\\left\\|\\left(\\hat{I}_{k}-I_{k}\\right)\\right\\|_{1}+\\left\\|\\left(\\hat{I}_{k+1}-I_{k+1}\\right)\\right\\|_{1} \u8fdb\u4e00\u6b65\u5b9a\u4e49\u4e00\u4e2a\u4e0eedge\u6709\u5173\u7684\u635f\u5931 \\mathcal{L}_{s m}(d)=\\sum\\left\\|\\nabla_{x} d\\right\\| e^{-\\beta\\left\\|\\nabla_{x} I\\right\\|}+\\left\\|\\nabla_{y} d\\right\\| e^{-\\beta\\left\\|\\nabla_{y} I\\right\\|} \u5176\u4e2d d \u4e3a\u6df1\u5ea6\u56fe \\nabla_x, \\nabla_y \u6307\u7684\u662fx,y\u65b9\u5411\u7684\u8fd0\u7b97\u7b26, \u4f18\u5316\u4ee5\u4e0a\u4e24\u4e2a\u635f\u5931\u51fd\u6570\u7684\u52a0\u6743\u6c42\u548c\u662f\u4e00\u4e2a\u975e\u51f8\u95ee\u9898\uff0c\u6211\u4eec\u9700\u8981\u4e00\u4e2a\u597d\u7684\u5c40\u90e8\u89e3\u4f5c\u4e3a\u521d\u59cb\u89e3\u3002\u8fd9\u91cc\u4f7f\u7528 PWC-Net \u751f\u6210\u521d\u59cb\u5149\u6d41\uff0c\u8fd9\u91cc\u4f7f\u7528\u5149\u6d41\u7684inverse\u76f4\u63a5\u5f97\u5230\u6df1\u5ea6\u521d\u59cb\u503c\u3002","title":"\u6df1\u5ea6\u4f30\u8ba1"},{"location":"Robotics_with_DL/PHOTOREALISTIC IMAGE RECONSTRUCTION FROM_HYBRID_INTENSITY_AND_EVENT_BASED_SENSOR/#_3","text":"\u8fd9\u91cc\u4f7f\u7528event camera\u5bf9\u4e24\u5e27\u4e4b\u95f4\u7684\u56fe\u50cf\u8fdb\u884c\u63d2\u503c\uff0c\u751f\u6210\u4e00\u7cfb\u5217\u7684\u4e2d\u95f4\u56fe\u50cf\u3002 \\begin{aligned} \\mathcal{L}_{p}\\left(\\xi_{k}^{j}\\right) &=\\left\\|E_{k}^{0}-\\hat{E}_{k}^{0}\\right\\|_{1} \\\\ \\mathcal{L}_{p}\\left(\\xi_{k+1}^{j}\\right) &=\\left\\|E_{k+1}^{0}-\\hat{E}_{k+1}^{0}\\right\\|_{1} \\end{aligned} \\xi_{k}^{j}, \\xi_{k+1}^{j}=\\underset{\\xi_{k}^{j}, \\xi_{k+1}^{j}}{\\arg \\min } \\mathcal{L}_{p}\\left(\\xi_{k}^{j}\\right)+\\mathcal{L}_{p}\\left(\\xi_{k+1}^{j}\\right)+\\lambda_{r} \\mathcal{L}_{p}\\left(\\xi_{k}^{j}, \\xi_{k+1}^{j}\\right) \u5176\u4e2d \\xi^j_k,\\xi^j_{k+1} \u5206\u522b\u6307\u4ee3\u7b2c j \u5f20\u4e2d\u95f4\u56fe\u76f8\u5bf9\u4e8e\u7b2c\u4e00\u5e27\u3001\u4e0b\u4e00\u5e27\u4e4b\u95f4\u7684\u76f8\u5bf9\u4f4d\u59ff\u53d8\u5316\uff0c","title":"\u76f8\u5bf9\u4f4d\u79fb\u4f30\u8ba1"},{"location":"Robotics_with_DL/PHOTOREALISTIC IMAGE RECONSTRUCTION FROM_HYBRID_INTENSITY_AND_EVENT_BASED_SENSOR/#_4","text":"\u6839\u636e\u6df1\u5ea6\u3001\u591a\u4e2a\u4e2d\u95f4\u503c\u7684\u4f4d\u59ff\uff0c\u5c06\u7b2c\u4e00\u5e27\u4e0e\u7b2c\u4e8c\u5e27\u5206\u522b\u5411\u540e\u3001\u5411\u524dwarp\uff0calpha-blend\u4e24\u6b21\u7684\u7ed3\u679c\uff0c\u5f97\u5230\u4e00\u7cfb\u5217\u66f4\u7cbe\u786e\u7684\u9996\u5c3e\u4e0e\u4e2d\u95f4\u56fe\u3002","title":"\u878d\u5408"},{"location":"Robotics_with_DL/Path Integral Networks_End-to-End Differentiable Optimal Control/","text":"Path Integral Networks: End-to-End Differentiable Optimal Control \u8fd9\u7bc7\u8bba\u6587\u5c06\u8def\u5f84\u79ef\u5206\u63a7\u5236\u7528\u5728\u4e86\u7aef\u5230\u7aef\u7684\u53ef\u5fae\u5206\u6700\u4f18\u63a7\u5236\u4e2d\uff0cPath Integral Control \u53ef\u4ee5\u53c2\u8003 \u8fd9\u7bc7 \u57fa\u672cPath Integral\u7b97\u6cd5 \u7c7b\u4f3c\u4e8ePath Integal \u63a7\u5236\u8bba\u6587\u4e2d\u7ed9\u51fa\u7684\u7b97\u6cd5\uff0c\u6ce8\u610f\u7cfb\u7edf\u5728\u6a21\u578b\u9884\u6d4b\u4ee5\u53careward\u9884\u6d4b\u7684\u65f6\u5019\u4f7f\u7528\u7684\u51fd\u6570\u4e3a\u795e\u7ecf\u7f51\u7edc\u5c42\u3002\u7531\u6b64\u53ef\u4ee5\u5f15\u51fa\u4ee5\u4e0b\u7684\u7ed3\u6784\u56fe \u5728\u6709\u4e13\u5bb6\u8f93\u5165\u53c2\u8003\u7684\u60c5\u51b5\u4e0b\uff0c\u6a21\u578b\u9884\u6d4b\u51fd\u6570\u4ee5\u53careward\u7684\u9884\u6d4b\u51fd\u6570\u53ef\u4ee5\u7aef\u5230\u7aef\u5b66\u4e60\u3002","title":"Path Integral Networks: End-to-End Differentiable Optimal Control"},{"location":"Robotics_with_DL/Path Integral Networks_End-to-End Differentiable Optimal Control/#path-integral-networks-end-to-end-differentiable-optimal-control","text":"\u8fd9\u7bc7\u8bba\u6587\u5c06\u8def\u5f84\u79ef\u5206\u63a7\u5236\u7528\u5728\u4e86\u7aef\u5230\u7aef\u7684\u53ef\u5fae\u5206\u6700\u4f18\u63a7\u5236\u4e2d\uff0cPath Integral Control \u53ef\u4ee5\u53c2\u8003 \u8fd9\u7bc7","title":"Path Integral Networks: End-to-End Differentiable Optimal Control"},{"location":"Robotics_with_DL/Path Integral Networks_End-to-End Differentiable Optimal Control/#path-integral","text":"\u7c7b\u4f3c\u4e8ePath Integal \u63a7\u5236\u8bba\u6587\u4e2d\u7ed9\u51fa\u7684\u7b97\u6cd5\uff0c\u6ce8\u610f\u7cfb\u7edf\u5728\u6a21\u578b\u9884\u6d4b\u4ee5\u53careward\u9884\u6d4b\u7684\u65f6\u5019\u4f7f\u7528\u7684\u51fd\u6570\u4e3a\u795e\u7ecf\u7f51\u7edc\u5c42\u3002\u7531\u6b64\u53ef\u4ee5\u5f15\u51fa\u4ee5\u4e0b\u7684\u7ed3\u6784\u56fe","title":"\u57fa\u672cPath Integral\u7b97\u6cd5"},{"location":"Robotics_with_DL/QMDP-Net_ Deep Learning for Planning underPartial Observability/","text":"QMDP-Net: Deep Learning for Planning under Partial Observability \u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u7684QMDP\u7f51\u7edc\uff0c\u76ee\u7684\u662f\u5f53\u673a\u5668\u4eba\u53ea\u80fd\u89c2\u6d4b\u5230\u573a\u666f\u7684\u4e00\u90e8\u5206\u4e14\u4e0d\u80fd\u786e\u5b9a\u81ea\u5df1\u7684\u72b6\u6001\u7684\u65f6\u5019\uff0c\u5982\u679c\u5728\u4e0d\u786e\u5b9a\u6027\u4e2d\u4e00\u8fb9\u63a2\u7d22\u4e00\u8fb9\u8fdb\u884c\u89c4\u5212\u3002 \u672c\u6587\u7684\u56fe\u4e00\u8bf4\u660e\u4e86\u672c\u6587\u53ef\u4ee5\u4f7f\u7528\u6a21\u4eff\u5b66\u4e60\uff0c\u5b66\u4f1a\u4e00\u4e9b\u63a2\u7d22\u7684\u65b9\u5f0f\uff0c\u7136\u540e\u673a\u5668\u4eba\u80fd\u591f\u65b0\u7684\u8ff7\u5bab\u4e2d\u6210\u529f\u5bfc\u822a\u3002 \u4e3b\u8981\u8d21\u732e\u4e0e\u7f51\u7edc\u7ed3\u6784 \u5b8f\u89c2\u6765\u770b\uff0c\u4e00\u4e2aPolicy\u7684\u8f93\u5165\u662f\u5386\u53f2\u4e00\u7cfb\u5217\u7684actions\u548cobservations\uff0c\u8f93\u51fa\u7684\u662f\u4e00\u4e2a\u4e0b\u4e00\u4e2aaction\u3002\u800cQMDP\u7f51\u7edc\u7531\u4e24\u90e8\u5206\u7ec4\u6210\uff0c\u4e00\u4e2a\u662fRNN\u7ed3\u6784\u7684\u8d1d\u53f6\u65af\u6ee4\u6ce2\u5668\uff08\u7528\u4e8e\u7f16\u7801\u4fe1\u606f\uff09\uff0c\u4e00\u4e2a\u662fQMDP planner\u7f51\u7edc\u3002 \u6ee4\u6ce2\u6a21\u5757 \u6ee4\u6ce2\u6a21\u5757\uff0c\u5c06\u4e00\u4e2abelief\u3001\u884c\u52a8\u4ee5\u53ca\u89c2\u6d4b\u6620\u5c04\u5230\u4e0b\u4e00\u4e2abelief b_{t+1} = f(b_t|a_t, o_t) \u3002\u5b9e\u9645\u4e0a\u4f1a\u5206\u4e24\u6b65\uff0c\u7b2c\u4e00\u6b65\u8003\u8651action\uff0c\u7b2c\u4e8c\u6b65\u8003\u8651\u89c2\u6d4b\u3002 \u5bf9\u4e8e\u672c\u6587\u7684\u4e00\u4e2a N*N \u7f51\u683c\u7684\u5bfc\u822a\u4efb\u52a1\uff0cbelief\u662f\u4e00\u4e2aN*N\u7684\u5f20\u91cf\uff0c\u5927\u81f4\u8868\u8fbe\u7684\u662f\u5bf9\u673a\u5668\u4eba\u5f53\u524d\u4f4d\u7f6e\u7684\u7f6e\u4fe1\u5ea6\u3002 \u56fe\u4e2d\u7684 f_T \u662f\u4e00\u4e2a\u5e26\u6709|A|\u7ec4\u6ee4\u6ce2\u5668\u7684\u5377\u79ef\uff0c\u8f93\u51fa\u7684 b_t^\\prime \u662f\u4e0d\u540c\u8fd0\u52a8\u6761\u4ef6\u4e0b\uff0c\u7269\u4f53\u5bf9\u81ea\u8eab\u65b0\u7684\u4f4d\u7f6e\u7684\u4e00\u4e2a\u4f30\u8ba1\u3002 \u7406\u8bba\u4e0a\u6765\u8bf4\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528hard indexing\u53d6\u51fa\u5f53\u524d\u884c\u52a8\u5bf9\u5e94\u7684\u8fd0\u52a8\u540e\u7684\u4f30\u8ba1\uff0c\u4f46\u662f\u8fd9\u91cc\u8bba\u6587\u91c7\u7528\u4e86soft index\uff0c\u7528\u5168\u8fde\u63a5\u5c42\u5c06action\u6620\u5c04\u5230 f_A(a) (\u5f62\u72b6\u4e3aA\u7684\u5f20\u91cf)\u4e2d\uff0c\u518d\u7528\u6c42\u548c(\u70b9\u4e58\uff0c\u5173\u4e8eA\u8fd9\u4e2a\u7ef4\u5ea6\u6c42\u548c)\u7684\u5f62\u5f0f\u6267\u884csoft indexing\u3002 \u89c2\u6d4b\u6a21\u578b\u8f93\u51fa\u4e00\u4e2a N*N*O \u7684\u5f20\u91cf\uff0c\u5176\u4e2d\u6bcf\u4e00\u4e2a\u6570\u4ee3\u8868\u7684\u662f\u7f51\u683c\u5f53\u524d\u70b9\u5f97\u5230\u67d0\u4e00\u4e2a\u6d4b\u91cf\u503c\u7684\u6982\u7387\u3002\u540c\u6837\u91c7\u7528\u4e00\u4e2a\u5168\u8fde\u63a5\u6620\u5c04\u4ee5\u53casoft indexing\uff0c\u5f97\u5230\u4e00\u4e2aN*N\u7684\u6839\u636e\u89c2\u6d4b\u5f97\u5230\u7684\u4f30\u8ba1\u3002 \u5c06\u8fd0\u52a8\u4e0e\u89c2\u6d4b\u5f97\u5230\u7684\u4f30\u8ba1\u4f7f\u7528element-wise multiplication\u878d\u5408 planner \u6a21\u5757 \u4f7f\u7528Value-iteration\u5c42\u8ba1\u7b97\u51fa\u4e00\u4e2aN*N\u7684\u4ef7\u503c\u56fe\u3002\u8fd9\u4e2a\u5c42\u7684\u7b97\u6cd5\u662f 1. \u5c06\u521d\u59cb \\theta \u7528\u4e00\u4e2a\u5377\u79ef\u5c42\u6620\u5c04\u5230Reward\u56fe( N*N*A )\uff0c\u521d\u59cb\u5316Q\u51fd\u6570\u56fe 2. \u5bf9Q\u51fd\u6570\u56fe\u7684Action\u7ef4\u4f5cmax pool (1*1) \u5f97\u5230 V_k 3. \u5377\u79ef V_k \u4ee3\u8868state transition\u518d\u52a0\u4e0areward\u56fe\u5f97\u5230\u65b0\u7684Q\u51fd\u6570\u56fe 4. \u8fed\u4ee32\u30013\u591a\u6b21\uff0c\u5f97\u5230\u6700\u7ec8\u7684Q\u51fd\u6570 \u51b3\u7b56\u7684\u65f6\u5019\uff0c\u5c06Q\u51fd\u6570 (N*N*A) \u4e0e b_t (N*N) \u76f8\u4e58\uff0c\u5e76\u6c42\u548c\u5f97\u5230 q(a) (\u5f62\u72b6\u4e3aA\u7684\u5f20\u91cf) \u518d\u7528\u5168\u8fde\u63a5\u5c06\u8fd9\u4e2aq\u6620\u5c04\u5230action\u4e2d\u3002 \u6a21\u4eff\u8bad\u7ec3\u4e0e\u4f7f\u7528 \u6574\u4e2a\u8fd0\u7b97\u662f\u53ef\u5bfc\uff0c\u56e0\u800c\u53ef\u4ee5\u4f7f\u7528\u6a21\u4eff\u5b66\u4e60\u540c\u65f6\u8bad\u7ec3\u6ee4\u6ce2\u6a21\u5757\u4ee5\u53ca\u89c4\u5212\u6a21\u5757\u3002 \u5b9e\u9a8c\u76f4\u89c9 \u53efgeneralize\u5230\u65b0\u73af\u5883 \u7528soft index\u4ee5\u53ca\u53ef\u5b66\u4e60\u7684transition\u6709\u6548\u7684\u89e3\u51b3\u4e86\u4e0d\u786e\u5b9a\u6027\u95ee\u9898 QMDP-net\u5b66\u4e60\u5230\u7684\u6a21\u578b\u4e0d\u6b63\u786e\uff0c\u4f46\u662f\u6709\u7528 \u5728N\u6bd4\u8f83\u5c0f\u7684\u73af\u5883\u4e2d\u5f97\u5230\u7684\u7f51\u7edc\u53ef\u4ee5\u5feb\u901f\u5b66\u4e60\u5230N\u6bd4\u8f83\u5927\u7684\u73af\u5883 \u53ef\u4ee5\u7528CNN-LSTM\u7ed3\u6784\u66ff\u4ee3\u672c\u6587\u7684filter \u6a21\u5757\uff0c\u4f46\u662f\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u672c\u6587\u7684\u6548\u679c\u66f4\u597d(\u66f4\u591aregularization)","title":"QMDP-Net: Deep Learning for Planning under Partial Observability"},{"location":"Robotics_with_DL/QMDP-Net_ Deep Learning for Planning underPartial Observability/#qmdp-net-deep-learning-for-planning-under-partial-observability","text":"\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u7684QMDP\u7f51\u7edc\uff0c\u76ee\u7684\u662f\u5f53\u673a\u5668\u4eba\u53ea\u80fd\u89c2\u6d4b\u5230\u573a\u666f\u7684\u4e00\u90e8\u5206\u4e14\u4e0d\u80fd\u786e\u5b9a\u81ea\u5df1\u7684\u72b6\u6001\u7684\u65f6\u5019\uff0c\u5982\u679c\u5728\u4e0d\u786e\u5b9a\u6027\u4e2d\u4e00\u8fb9\u63a2\u7d22\u4e00\u8fb9\u8fdb\u884c\u89c4\u5212\u3002 \u672c\u6587\u7684\u56fe\u4e00\u8bf4\u660e\u4e86\u672c\u6587\u53ef\u4ee5\u4f7f\u7528\u6a21\u4eff\u5b66\u4e60\uff0c\u5b66\u4f1a\u4e00\u4e9b\u63a2\u7d22\u7684\u65b9\u5f0f\uff0c\u7136\u540e\u673a\u5668\u4eba\u80fd\u591f\u65b0\u7684\u8ff7\u5bab\u4e2d\u6210\u529f\u5bfc\u822a\u3002","title":"QMDP-Net: Deep Learning for Planning under Partial Observability"},{"location":"Robotics_with_DL/QMDP-Net_ Deep Learning for Planning underPartial Observability/#_1","text":"\u5b8f\u89c2\u6765\u770b\uff0c\u4e00\u4e2aPolicy\u7684\u8f93\u5165\u662f\u5386\u53f2\u4e00\u7cfb\u5217\u7684actions\u548cobservations\uff0c\u8f93\u51fa\u7684\u662f\u4e00\u4e2a\u4e0b\u4e00\u4e2aaction\u3002\u800cQMDP\u7f51\u7edc\u7531\u4e24\u90e8\u5206\u7ec4\u6210\uff0c\u4e00\u4e2a\u662fRNN\u7ed3\u6784\u7684\u8d1d\u53f6\u65af\u6ee4\u6ce2\u5668\uff08\u7528\u4e8e\u7f16\u7801\u4fe1\u606f\uff09\uff0c\u4e00\u4e2a\u662fQMDP planner\u7f51\u7edc\u3002","title":"\u4e3b\u8981\u8d21\u732e\u4e0e\u7f51\u7edc\u7ed3\u6784"},{"location":"Robotics_with_DL/QMDP-Net_ Deep Learning for Planning underPartial Observability/#_2","text":"\u6ee4\u6ce2\u6a21\u5757\uff0c\u5c06\u4e00\u4e2abelief\u3001\u884c\u52a8\u4ee5\u53ca\u89c2\u6d4b\u6620\u5c04\u5230\u4e0b\u4e00\u4e2abelief b_{t+1} = f(b_t|a_t, o_t) \u3002\u5b9e\u9645\u4e0a\u4f1a\u5206\u4e24\u6b65\uff0c\u7b2c\u4e00\u6b65\u8003\u8651action\uff0c\u7b2c\u4e8c\u6b65\u8003\u8651\u89c2\u6d4b\u3002 \u5bf9\u4e8e\u672c\u6587\u7684\u4e00\u4e2a N*N \u7f51\u683c\u7684\u5bfc\u822a\u4efb\u52a1\uff0cbelief\u662f\u4e00\u4e2aN*N\u7684\u5f20\u91cf\uff0c\u5927\u81f4\u8868\u8fbe\u7684\u662f\u5bf9\u673a\u5668\u4eba\u5f53\u524d\u4f4d\u7f6e\u7684\u7f6e\u4fe1\u5ea6\u3002 \u56fe\u4e2d\u7684 f_T \u662f\u4e00\u4e2a\u5e26\u6709|A|\u7ec4\u6ee4\u6ce2\u5668\u7684\u5377\u79ef\uff0c\u8f93\u51fa\u7684 b_t^\\prime \u662f\u4e0d\u540c\u8fd0\u52a8\u6761\u4ef6\u4e0b\uff0c\u7269\u4f53\u5bf9\u81ea\u8eab\u65b0\u7684\u4f4d\u7f6e\u7684\u4e00\u4e2a\u4f30\u8ba1\u3002 \u7406\u8bba\u4e0a\u6765\u8bf4\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528hard indexing\u53d6\u51fa\u5f53\u524d\u884c\u52a8\u5bf9\u5e94\u7684\u8fd0\u52a8\u540e\u7684\u4f30\u8ba1\uff0c\u4f46\u662f\u8fd9\u91cc\u8bba\u6587\u91c7\u7528\u4e86soft index\uff0c\u7528\u5168\u8fde\u63a5\u5c42\u5c06action\u6620\u5c04\u5230 f_A(a) (\u5f62\u72b6\u4e3aA\u7684\u5f20\u91cf)\u4e2d\uff0c\u518d\u7528\u6c42\u548c(\u70b9\u4e58\uff0c\u5173\u4e8eA\u8fd9\u4e2a\u7ef4\u5ea6\u6c42\u548c)\u7684\u5f62\u5f0f\u6267\u884csoft indexing\u3002 \u89c2\u6d4b\u6a21\u578b\u8f93\u51fa\u4e00\u4e2a N*N*O \u7684\u5f20\u91cf\uff0c\u5176\u4e2d\u6bcf\u4e00\u4e2a\u6570\u4ee3\u8868\u7684\u662f\u7f51\u683c\u5f53\u524d\u70b9\u5f97\u5230\u67d0\u4e00\u4e2a\u6d4b\u91cf\u503c\u7684\u6982\u7387\u3002\u540c\u6837\u91c7\u7528\u4e00\u4e2a\u5168\u8fde\u63a5\u6620\u5c04\u4ee5\u53casoft indexing\uff0c\u5f97\u5230\u4e00\u4e2aN*N\u7684\u6839\u636e\u89c2\u6d4b\u5f97\u5230\u7684\u4f30\u8ba1\u3002 \u5c06\u8fd0\u52a8\u4e0e\u89c2\u6d4b\u5f97\u5230\u7684\u4f30\u8ba1\u4f7f\u7528element-wise multiplication\u878d\u5408","title":"\u6ee4\u6ce2\u6a21\u5757"},{"location":"Robotics_with_DL/QMDP-Net_ Deep Learning for Planning underPartial Observability/#planner","text":"\u4f7f\u7528Value-iteration\u5c42\u8ba1\u7b97\u51fa\u4e00\u4e2aN*N\u7684\u4ef7\u503c\u56fe\u3002\u8fd9\u4e2a\u5c42\u7684\u7b97\u6cd5\u662f 1. \u5c06\u521d\u59cb \\theta \u7528\u4e00\u4e2a\u5377\u79ef\u5c42\u6620\u5c04\u5230Reward\u56fe( N*N*A )\uff0c\u521d\u59cb\u5316Q\u51fd\u6570\u56fe 2. \u5bf9Q\u51fd\u6570\u56fe\u7684Action\u7ef4\u4f5cmax pool (1*1) \u5f97\u5230 V_k 3. \u5377\u79ef V_k \u4ee3\u8868state transition\u518d\u52a0\u4e0areward\u56fe\u5f97\u5230\u65b0\u7684Q\u51fd\u6570\u56fe 4. \u8fed\u4ee32\u30013\u591a\u6b21\uff0c\u5f97\u5230\u6700\u7ec8\u7684Q\u51fd\u6570 \u51b3\u7b56\u7684\u65f6\u5019\uff0c\u5c06Q\u51fd\u6570 (N*N*A) \u4e0e b_t (N*N) \u76f8\u4e58\uff0c\u5e76\u6c42\u548c\u5f97\u5230 q(a) (\u5f62\u72b6\u4e3aA\u7684\u5f20\u91cf) \u518d\u7528\u5168\u8fde\u63a5\u5c06\u8fd9\u4e2aq\u6620\u5c04\u5230action\u4e2d\u3002","title":"planner \u6a21\u5757"},{"location":"Robotics_with_DL/QMDP-Net_ Deep Learning for Planning underPartial Observability/#_3","text":"\u6574\u4e2a\u8fd0\u7b97\u662f\u53ef\u5bfc\uff0c\u56e0\u800c\u53ef\u4ee5\u4f7f\u7528\u6a21\u4eff\u5b66\u4e60\u540c\u65f6\u8bad\u7ec3\u6ee4\u6ce2\u6a21\u5757\u4ee5\u53ca\u89c4\u5212\u6a21\u5757\u3002","title":"\u6a21\u4eff\u8bad\u7ec3\u4e0e\u4f7f\u7528"},{"location":"Robotics_with_DL/QMDP-Net_ Deep Learning for Planning underPartial Observability/#_4","text":"\u53efgeneralize\u5230\u65b0\u73af\u5883 \u7528soft index\u4ee5\u53ca\u53ef\u5b66\u4e60\u7684transition\u6709\u6548\u7684\u89e3\u51b3\u4e86\u4e0d\u786e\u5b9a\u6027\u95ee\u9898 QMDP-net\u5b66\u4e60\u5230\u7684\u6a21\u578b\u4e0d\u6b63\u786e\uff0c\u4f46\u662f\u6709\u7528 \u5728N\u6bd4\u8f83\u5c0f\u7684\u73af\u5883\u4e2d\u5f97\u5230\u7684\u7f51\u7edc\u53ef\u4ee5\u5feb\u901f\u5b66\u4e60\u5230N\u6bd4\u8f83\u5927\u7684\u73af\u5883 \u53ef\u4ee5\u7528CNN-LSTM\u7ed3\u6784\u66ff\u4ee3\u672c\u6587\u7684filter \u6a21\u5757\uff0c\u4f46\u662f\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u672c\u6587\u7684\u6548\u679c\u66f4\u597d(\u66f4\u591aregularization)","title":"\u5b9e\u9a8c\u76f4\u89c9"},{"location":"Robotics_with_DL/Robustness_to_Out-of-Distribution_Inputs_via_Task-Aware_Generative_Uncertainty/","text":"Robustness to Out-of-Distribution Inputs via Task-Aware Generative Uncertainty \u8d1d\u53f6\u65af\u7406\u8bba\u80cc\u666f \u7f51\u7edc\u8bad\u7ec3\u7684\u65f6\u5019\u76f8\u5f53\u4e8e\u5bfb\u627e\u53c2\u6570 w \u6ee1\u8db3 w_{MAP} =argmax_{w}\\sum_ip(y_i|x_i,A_i,w) \u5176\u4e2d y,x,A,w \u5206\u522b\u4e3a\u89c2\u6d4b\u503c\uff0c\u884c\u52a8\u5e8f\u5217\u4ee5\u53ca\u53c2\u6570\u77e2\u91cf\u3002\u8fd9\u4e2a\u65b9\u6cd5\u53ef\u4ee5\u4f30\u6d4b\u8f93\u51fa\u7ed3\u679c\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u4f46\u662f\u4e0d\u80fd\u4f30\u8ba1\u6a21\u578b\u672c\u8eab\u53c2\u6570\u9009\u62e9\u7684\u4e0d\u786e\u5b9a\u6027\u3002 p(y|x,A) = \\int p(y|x,A,w)p(w|D_{train})dw \u7406\u8bba\u4e0a\u6765\u8bf4\u8fd9\u4e2a\u79ef\u5206\u662f\u65e0\u6cd5\u6c42\u89e3\u7684\u3002 \u5c3d\u7ba1\u8d1d\u53f6\u65af\u65b9\u6cd5\u53ef\u4ee5\u5904\u7406\u7531\u4e8e\u6570\u636e\u91cf\u4e0d\u8db3\u5f15\u8d77\u7684\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\uff0c\u4f46\u662f\u5bf9\u4e8e\u4e0etraining data\u5206\u5e03\u4e0d\u540c\u7684\u8f93\u5165\uff0c\u5176\u4f30\u8ba1\u503c\u4e0d\u591f\u51c6\u786e\u3002\u8fd9\u4e9b\u60c5\u51b5\u8bb0\u4e3a p(y|x^*,A) \u7f51\u7edc\u4e0e\u5b9e\u9645\u7b97\u6cd5 \u8bad\u7ec3\u65f6\uff1a \u6839\u636e\u8f93\u5165\u56fe\u7247\uff0c\u8bad\u7ec3\u4e00\u4e2a VAE \uff0c\u53e6\u5916\u6b63\u5e38\u5730\u4f7f\u7528\u539f\u6765\u9700\u8981\u7684\u6a21\u578b(\u672c\u6587\u4e3a\u4e00\u4e2a\u5377\u79ef+LSTM\u6a21\u578b)\u5f97\u5230 p(y|x,A) \u6d4b\u8bd5\u65f6: \u5c06\u6d4b\u8bd5\u8f93\u5165\u653e\u5230VAE\u4e2d\uff0c\u5728\u4e2d\u95f4\u9690\u5c42\u4e2d\u591a\u6b21\u91c7\u6837\u5f97\u5230\u591a\u4e2a\u8f93\u51fa\u56fe\u7247\uff0c\u6b63\u5e38\u5730\u4f7f\u7528\u539f\u6765\u7684\u6a21\u578b\u5f97\u5230\u591a\u4e2a\u8f93\u51fa\u7ed3\u679c\uff0c\u5bf9\u5176\u6c42\u5747\u503c\u4e0e\u65b9\u5dee\u5f97\u5230\u5bf9\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u7684\u4f30\u8ba1 \u80cc\u540e\u7684\u4e00\u4e9b\u5206\u6790 \u672c\u6587\u4e00\u4e2a\u4e0e\u5176\u4ed6\u6587\u7ae0\u4e0d\u540c\u7684\u7406\u7531\u662f\uff0c\u4e0d\u5e94\u8be5\u5355\u7eaf\u5730\u56e0\u4e3a\u6d4b\u8bd5\u65f6\u8f93\u5165\u56fe\u7247\u4e0e\u8bad\u7ec3\u65f6\u4e0d\u540c\u5c31\u5224\u65ad\u7ed3\u679c\u4f1a\u6709\u5f88\u5927\u7684\u4e0d\u786e\u5b9a\u6027\u3002\u7b80\u5355\u7684\u4f8b\u5b50\u6bd4\u5982\u8bf4\u5929\u82b1\u677f\u7684\u989c\u8272\uff0c\u5982\u679c\u6d4b\u8bd5\u65f6\u4e0e\u8bad\u7ec3\u65f6\u4e0d\u540c\uff0c\u4e00\u4e2a\u6b63\u5e38\u597d\u7684\u673a\u5668\u4eba\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e0d\u4f1a\u56e0\u6b64\u5f97\u5230\u4e0d\u540c\u7684\u884c\u52a8\u8f93\u51fa\uff0c\"\u8f93\u51fa\u7ed3\u679c\u7684\u4e0d\u786e\u5b9a\u6027\u4e0d\u4f1a\u56e0\u65e0\u5173\u90e8\u5206\u7684\u533a\u522b\u800c\u63d0\u5347\"\u3002\u8fd9\u4e2a\u60c5\u51b5\u5728\u672c\u6587\u7684\u6a21\u578b\u4e2d\u4e5f\u6709\u6240\u4f53\u73b0\uff0c\u4f5c\u8005\u5b9e\u9a8c\u5ba4\u80fd\u53d1\u73b0VAE\u6d4b\u8bd5\u65f6\u8f93\u51fa\u7684\u56fe\u7247\u7684\u5929\u82b1\u677f\u989c\u8272\u4e0e\u5b9e\u9645\u7684\u8f93\u5165\u4e0d\u7b26\u5408\uff0c\u4f46\u662f\u6700\u7ec8\u8f93\u51fa\u7684\u884c\u52a8\u5dee\u522b\u4e0d\u5927\uff0c\u4e5f\u5c31\u4e0d\u4f1a\u63d0\u5347\u5bf9\u5e94\u7684\u4e0d\u786e\u5b9a\u6027\u3002\u8fd9\u4e5f\u662f\u4f5c\u8005\u5728\u4f30\u8ba1\u4e0d\u786e\u5b9a\u6027\u7684\u65f6\u5019\uff0c\u575a\u6301\u8981\u53bb\u5230\u6700\u540e\u884c\u52a8\u8f93\u51fa\u65f6\u518d\u4f30\u8ba1\u4e0d\u786e\u5b9a\u6027\uff0c\u800c\u4e0d\u662f\u4ece\u56fe\u50cf\u7684\u8f93\u5165\u5c31\u5f00\u59cb\u4f30\u8ba1\u3002","title":"Robustness to Out-of-Distribution Inputs via Task-Aware Generative Uncertainty"},{"location":"Robotics_with_DL/Robustness_to_Out-of-Distribution_Inputs_via_Task-Aware_Generative_Uncertainty/#robustness-to-out-of-distribution-inputs-via-task-aware-generative-uncertainty","text":"","title":"Robustness to Out-of-Distribution Inputs via Task-Aware Generative Uncertainty"},{"location":"Robotics_with_DL/Robustness_to_Out-of-Distribution_Inputs_via_Task-Aware_Generative_Uncertainty/#_1","text":"\u7f51\u7edc\u8bad\u7ec3\u7684\u65f6\u5019\u76f8\u5f53\u4e8e\u5bfb\u627e\u53c2\u6570 w \u6ee1\u8db3 w_{MAP} =argmax_{w}\\sum_ip(y_i|x_i,A_i,w) \u5176\u4e2d y,x,A,w \u5206\u522b\u4e3a\u89c2\u6d4b\u503c\uff0c\u884c\u52a8\u5e8f\u5217\u4ee5\u53ca\u53c2\u6570\u77e2\u91cf\u3002\u8fd9\u4e2a\u65b9\u6cd5\u53ef\u4ee5\u4f30\u6d4b\u8f93\u51fa\u7ed3\u679c\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u4f46\u662f\u4e0d\u80fd\u4f30\u8ba1\u6a21\u578b\u672c\u8eab\u53c2\u6570\u9009\u62e9\u7684\u4e0d\u786e\u5b9a\u6027\u3002 p(y|x,A) = \\int p(y|x,A,w)p(w|D_{train})dw \u7406\u8bba\u4e0a\u6765\u8bf4\u8fd9\u4e2a\u79ef\u5206\u662f\u65e0\u6cd5\u6c42\u89e3\u7684\u3002 \u5c3d\u7ba1\u8d1d\u53f6\u65af\u65b9\u6cd5\u53ef\u4ee5\u5904\u7406\u7531\u4e8e\u6570\u636e\u91cf\u4e0d\u8db3\u5f15\u8d77\u7684\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\uff0c\u4f46\u662f\u5bf9\u4e8e\u4e0etraining data\u5206\u5e03\u4e0d\u540c\u7684\u8f93\u5165\uff0c\u5176\u4f30\u8ba1\u503c\u4e0d\u591f\u51c6\u786e\u3002\u8fd9\u4e9b\u60c5\u51b5\u8bb0\u4e3a p(y|x^*,A)","title":"\u8d1d\u53f6\u65af\u7406\u8bba\u80cc\u666f"},{"location":"Robotics_with_DL/Robustness_to_Out-of-Distribution_Inputs_via_Task-Aware_Generative_Uncertainty/#_2","text":"\u8bad\u7ec3\u65f6\uff1a \u6839\u636e\u8f93\u5165\u56fe\u7247\uff0c\u8bad\u7ec3\u4e00\u4e2a VAE \uff0c\u53e6\u5916\u6b63\u5e38\u5730\u4f7f\u7528\u539f\u6765\u9700\u8981\u7684\u6a21\u578b(\u672c\u6587\u4e3a\u4e00\u4e2a\u5377\u79ef+LSTM\u6a21\u578b)\u5f97\u5230 p(y|x,A) \u6d4b\u8bd5\u65f6: \u5c06\u6d4b\u8bd5\u8f93\u5165\u653e\u5230VAE\u4e2d\uff0c\u5728\u4e2d\u95f4\u9690\u5c42\u4e2d\u591a\u6b21\u91c7\u6837\u5f97\u5230\u591a\u4e2a\u8f93\u51fa\u56fe\u7247\uff0c\u6b63\u5e38\u5730\u4f7f\u7528\u539f\u6765\u7684\u6a21\u578b\u5f97\u5230\u591a\u4e2a\u8f93\u51fa\u7ed3\u679c\uff0c\u5bf9\u5176\u6c42\u5747\u503c\u4e0e\u65b9\u5dee\u5f97\u5230\u5bf9\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u7684\u4f30\u8ba1","title":"\u7f51\u7edc\u4e0e\u5b9e\u9645\u7b97\u6cd5"},{"location":"Robotics_with_DL/Robustness_to_Out-of-Distribution_Inputs_via_Task-Aware_Generative_Uncertainty/#_3","text":"\u672c\u6587\u4e00\u4e2a\u4e0e\u5176\u4ed6\u6587\u7ae0\u4e0d\u540c\u7684\u7406\u7531\u662f\uff0c\u4e0d\u5e94\u8be5\u5355\u7eaf\u5730\u56e0\u4e3a\u6d4b\u8bd5\u65f6\u8f93\u5165\u56fe\u7247\u4e0e\u8bad\u7ec3\u65f6\u4e0d\u540c\u5c31\u5224\u65ad\u7ed3\u679c\u4f1a\u6709\u5f88\u5927\u7684\u4e0d\u786e\u5b9a\u6027\u3002\u7b80\u5355\u7684\u4f8b\u5b50\u6bd4\u5982\u8bf4\u5929\u82b1\u677f\u7684\u989c\u8272\uff0c\u5982\u679c\u6d4b\u8bd5\u65f6\u4e0e\u8bad\u7ec3\u65f6\u4e0d\u540c\uff0c\u4e00\u4e2a\u6b63\u5e38\u597d\u7684\u673a\u5668\u4eba\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e0d\u4f1a\u56e0\u6b64\u5f97\u5230\u4e0d\u540c\u7684\u884c\u52a8\u8f93\u51fa\uff0c\"\u8f93\u51fa\u7ed3\u679c\u7684\u4e0d\u786e\u5b9a\u6027\u4e0d\u4f1a\u56e0\u65e0\u5173\u90e8\u5206\u7684\u533a\u522b\u800c\u63d0\u5347\"\u3002\u8fd9\u4e2a\u60c5\u51b5\u5728\u672c\u6587\u7684\u6a21\u578b\u4e2d\u4e5f\u6709\u6240\u4f53\u73b0\uff0c\u4f5c\u8005\u5b9e\u9a8c\u5ba4\u80fd\u53d1\u73b0VAE\u6d4b\u8bd5\u65f6\u8f93\u51fa\u7684\u56fe\u7247\u7684\u5929\u82b1\u677f\u989c\u8272\u4e0e\u5b9e\u9645\u7684\u8f93\u5165\u4e0d\u7b26\u5408\uff0c\u4f46\u662f\u6700\u7ec8\u8f93\u51fa\u7684\u884c\u52a8\u5dee\u522b\u4e0d\u5927\uff0c\u4e5f\u5c31\u4e0d\u4f1a\u63d0\u5347\u5bf9\u5e94\u7684\u4e0d\u786e\u5b9a\u6027\u3002\u8fd9\u4e5f\u662f\u4f5c\u8005\u5728\u4f30\u8ba1\u4e0d\u786e\u5b9a\u6027\u7684\u65f6\u5019\uff0c\u575a\u6301\u8981\u53bb\u5230\u6700\u540e\u884c\u52a8\u8f93\u51fa\u65f6\u518d\u4f30\u8ba1\u4e0d\u786e\u5b9a\u6027\uff0c\u800c\u4e0d\u662f\u4ece\u56fe\u50cf\u7684\u8f93\u5165\u5c31\u5f00\u59cb\u4f30\u8ba1\u3002","title":"\u80cc\u540e\u7684\u4e00\u4e9b\u5206\u6790"},{"location":"Robotics_with_DL/SuperPoint:Self-Supervised_Interest_Point_Detection_and_Description/","text":"SuperPoint: Self-Supervised Interest Point Detection and Description \u8fd9\u7bc7\u8bba\u6587\u5b8c\u6210\u7684\u4efb\u52a1\u662f\u4ece\u4e00\u5f20\u56fe\u4e2d\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u63d0\u53d6\u51fakeypoints\uff0c\u8fd9\u4e9bkeypoints\u7684\u5173\u952e\u662f\u8981\u6c42\u5bf9\u65cb\u8f6c\uff0cscale\uff0c\u5e73\u79fb\u9c81\u68d2\u3002 Training procedure \u8bad\u7ec3\u8fc7\u7a0b\u9700\u8981\u4e09\u4e2a\u9636\u6bb5\uff0c\u7b2c\u4e00\u4e2a\u9636\u6bb5\uff0c\u4f7f\u7528\u4e00\u4e9b\u7b80\u5355\u7684\u51e0\u4f55\u56fe\u7247,\u7528\u4e00\u4e9b\u6ca1\u6709\u6b67\u4e49\u7684\u56fe\u7247\u548ckeypoint\uff0c\u8fdb\u884c\u521d\u59cb\u8bad\u7ec3\u3002 \u7b2c\u4e8c\u9636\u6bb5\uff0c\u4f7f\u7528\u4e00\u4e9b\u6ca1\u6709label\u7684\u771f\u5b9e\u56fe\u7247\uff0c\u5bf9\u540c\u4e00\u5f20\u56fe\uff0c\u4f7f\u7528Homographic transform(\u65cb\u8f6c\u5e73\u79fb\u7b49\u7684\u7ec4\u5408),\u8f6c\u6362\u6210\u4e00\u4e2abatch\u7684\u56fe.\u7528\u524d\u6587\u7684detector\uff0c\u751f\u6210keypoint\uff0c\u518d\u8f6c\u6362\u4e3a\u539f\u56fe\u5750\u6807\u7cfb\u4e2d\u3002\u8fd9\u4e2abatch\u4f1a\u5728\u5f53\u524d\u56fe\u5f62\u6210\u4e00\u4e2akeypoint\u7684heatmap. \\mathbf{x}=\\mathcal{H}^{-1} f_{\\theta}(\\mathcal{H}(I)) \\hat{F}\\left(I ; f_{\\theta}\\right)=\\frac{1}{N_{h}} \\sum_{i=1}^{N_{h}} \\mathcal{H}_{i}^{-1} f_{\\theta}\\left(\\mathcal{H}_{i}(I)\\right) \u7b2c\u4e09\u9636\u6bb5\uff0c\u4f7f\u7528joint training\u3002\u8fdb\u884c\u8bad\u7ec3 \u7f51\u7edc\u6a21\u578b \u7b2c\u4e00\u9636\u6bb5\u53ea\u4f7f\u7528\u4e0a\u90e8\u5206\u90a3\u4e00\u652f\uff0c\u7b2c\u4e09\u9636\u6bb5\u4f1a\u6709descriptor\u90e8\u5206\u3002 Encoder\u7c7b\u4f3c\u4e8eVGG, Interest Point Decoder\uff0c65\u4e2aChannels,\u610f\u601d\u662f\u5468\u8fb9 8\\times 8 \u4e2a\u65b9\u5757\u6709keypoint\u7684\u6982\u7387\uff0c\u8fd8\u6709\u4e00\u4e2a\u662f\u7a7a\u7c7b. \u8fd9\u91cc\u7684 reshape \u5bf9\u5e94\u7684\u662fpytorch.nn.pixelshuffel\u64cd\u4f5c\uff0c\u5c06channel\u7684\u5185\u5bb9\u7ffb\u5230feature map\u7a7a\u95f4\u7684\u533a\u57df\u3002 \u5982\u679cground truth\u91cc\u9762 8\\times 8 \u533a\u57df\u91cc\u9762\u6709\u4e0d\u6b62\u4e00\u4e2a\u70b9\u5219\u968f\u673a\u9009\u53d6\u4e00\u4e2a\u4f5c\u4e3a\u8be5\u533a\u57df\u91cc\u9762\u6709\u6548\u7684ground truth\u3002 \u8fd9\u91cc\u4f7f\u7528cross-entropy,\u8ba1\u7b97 \\mathcal{L}_p \u8fdb\u884c\u8bad\u7ec3\u3002 descriptor\u7684\u8bad\u7ec3\uff0c\u4f9d\u9760\u7684\u662f\u540c\u4e00\u5f20\u56fe\uff0c\u5c06\u56fehomographic transform\u5230\u53e6\u4e00\u5f20\u56fe\u53bb\uff0c\u8981\u6c42keypoint\u5bf9\u5e94\u7684\u4f4d\u7f6e\u63cf\u8ff0\u76f8\u540c\u3002 s_{h w h^{\\prime} w^{\\prime}} \u6307\u4ee3\u5bf9\u5e94\u5173\u7cfb s_{h w h^{\\prime} w^{\\prime}}=\\left\\{\\begin{array}{ll}{1,} & {\\text { if } \\| \\widehat{\\mathcal{H} \\mathbf{p}_{h w}}-\\mathbf{p}_{h^{\\prime} w^{\\prime}}|| \\leq 8} \\\\ {0,} & {\\text { otherwise }}\\end{array}\\right. \\begin{aligned} l_{d}\\left(\\mathbf{d}, \\mathbf{d}^{\\prime} ; s\\right) &=\\lambda_{d} * s * \\max \\left(0, m_{p}-\\mathbf{d}^{T} \\mathbf{d}^{\\prime}\\right) \\\\ &+(1-s) * \\max \\left(0, \\mathbf{d}^{T} \\mathbf{d}^{\\prime}-m_{n}\\right) \\end{aligned} \\begin{aligned} \\mathcal{L}_{d}\\left(\\mathcal{D}, \\mathcal{D}^{\\prime}, S\\right) &=\\\\ \\frac{1}{\\left(H_{c} W_{c}\\right)^{2}} &\\sum_{h=1}^{H_{c}, W_{c} H_{c}, W_{c}} l_{d}\\left(\\mathbf{d}_{h w}, \\mathbf{d}_{h^{\\prime} w^{\\prime}}^{\\prime} ; s_{h w h^{\\prime} w^{\\prime}}\\right) \\end{aligned} \\begin{aligned} \\mathcal{L}\\left(\\mathcal{X}, \\mathcal{X}^{\\prime}, \\mathcal{D}, \\mathcal{D}^{\\prime} ; Y, Y^{\\prime}, S\\right) &=\\\\ \\mathcal{L}_{p}(\\mathcal{X}, Y)&+\\mathcal{L}_{p}\\left(\\mathcal{X}^{\\prime}, Y^{\\prime}\\right)+\\lambda \\mathcal{L}_{d}\\left(\\mathcal{D}, \\mathcal{D}^{\\prime}, S\\right) \\end{aligned}","title":"SuperPoint: Self-Supervised Interest Point Detection and Description"},{"location":"Robotics_with_DL/SuperPoint:Self-Supervised_Interest_Point_Detection_and_Description/#superpoint-self-supervised-interest-point-detection-and-description","text":"\u8fd9\u7bc7\u8bba\u6587\u5b8c\u6210\u7684\u4efb\u52a1\u662f\u4ece\u4e00\u5f20\u56fe\u4e2d\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u63d0\u53d6\u51fakeypoints\uff0c\u8fd9\u4e9bkeypoints\u7684\u5173\u952e\u662f\u8981\u6c42\u5bf9\u65cb\u8f6c\uff0cscale\uff0c\u5e73\u79fb\u9c81\u68d2\u3002","title":"SuperPoint: Self-Supervised Interest Point Detection and Description"},{"location":"Robotics_with_DL/SuperPoint:Self-Supervised_Interest_Point_Detection_and_Description/#training-procedure","text":"\u8bad\u7ec3\u8fc7\u7a0b\u9700\u8981\u4e09\u4e2a\u9636\u6bb5\uff0c\u7b2c\u4e00\u4e2a\u9636\u6bb5\uff0c\u4f7f\u7528\u4e00\u4e9b\u7b80\u5355\u7684\u51e0\u4f55\u56fe\u7247,\u7528\u4e00\u4e9b\u6ca1\u6709\u6b67\u4e49\u7684\u56fe\u7247\u548ckeypoint\uff0c\u8fdb\u884c\u521d\u59cb\u8bad\u7ec3\u3002 \u7b2c\u4e8c\u9636\u6bb5\uff0c\u4f7f\u7528\u4e00\u4e9b\u6ca1\u6709label\u7684\u771f\u5b9e\u56fe\u7247\uff0c\u5bf9\u540c\u4e00\u5f20\u56fe\uff0c\u4f7f\u7528Homographic transform(\u65cb\u8f6c\u5e73\u79fb\u7b49\u7684\u7ec4\u5408),\u8f6c\u6362\u6210\u4e00\u4e2abatch\u7684\u56fe.\u7528\u524d\u6587\u7684detector\uff0c\u751f\u6210keypoint\uff0c\u518d\u8f6c\u6362\u4e3a\u539f\u56fe\u5750\u6807\u7cfb\u4e2d\u3002\u8fd9\u4e2abatch\u4f1a\u5728\u5f53\u524d\u56fe\u5f62\u6210\u4e00\u4e2akeypoint\u7684heatmap. \\mathbf{x}=\\mathcal{H}^{-1} f_{\\theta}(\\mathcal{H}(I)) \\hat{F}\\left(I ; f_{\\theta}\\right)=\\frac{1}{N_{h}} \\sum_{i=1}^{N_{h}} \\mathcal{H}_{i}^{-1} f_{\\theta}\\left(\\mathcal{H}_{i}(I)\\right) \u7b2c\u4e09\u9636\u6bb5\uff0c\u4f7f\u7528joint training\u3002\u8fdb\u884c\u8bad\u7ec3","title":"Training procedure"},{"location":"Robotics_with_DL/SuperPoint:Self-Supervised_Interest_Point_Detection_and_Description/#_1","text":"\u7b2c\u4e00\u9636\u6bb5\u53ea\u4f7f\u7528\u4e0a\u90e8\u5206\u90a3\u4e00\u652f\uff0c\u7b2c\u4e09\u9636\u6bb5\u4f1a\u6709descriptor\u90e8\u5206\u3002 Encoder\u7c7b\u4f3c\u4e8eVGG, Interest Point Decoder\uff0c65\u4e2aChannels,\u610f\u601d\u662f\u5468\u8fb9 8\\times 8 \u4e2a\u65b9\u5757\u6709keypoint\u7684\u6982\u7387\uff0c\u8fd8\u6709\u4e00\u4e2a\u662f\u7a7a\u7c7b. \u8fd9\u91cc\u7684 reshape \u5bf9\u5e94\u7684\u662fpytorch.nn.pixelshuffel\u64cd\u4f5c\uff0c\u5c06channel\u7684\u5185\u5bb9\u7ffb\u5230feature map\u7a7a\u95f4\u7684\u533a\u57df\u3002 \u5982\u679cground truth\u91cc\u9762 8\\times 8 \u533a\u57df\u91cc\u9762\u6709\u4e0d\u6b62\u4e00\u4e2a\u70b9\u5219\u968f\u673a\u9009\u53d6\u4e00\u4e2a\u4f5c\u4e3a\u8be5\u533a\u57df\u91cc\u9762\u6709\u6548\u7684ground truth\u3002 \u8fd9\u91cc\u4f7f\u7528cross-entropy,\u8ba1\u7b97 \\mathcal{L}_p \u8fdb\u884c\u8bad\u7ec3\u3002 descriptor\u7684\u8bad\u7ec3\uff0c\u4f9d\u9760\u7684\u662f\u540c\u4e00\u5f20\u56fe\uff0c\u5c06\u56fehomographic transform\u5230\u53e6\u4e00\u5f20\u56fe\u53bb\uff0c\u8981\u6c42keypoint\u5bf9\u5e94\u7684\u4f4d\u7f6e\u63cf\u8ff0\u76f8\u540c\u3002 s_{h w h^{\\prime} w^{\\prime}} \u6307\u4ee3\u5bf9\u5e94\u5173\u7cfb s_{h w h^{\\prime} w^{\\prime}}=\\left\\{\\begin{array}{ll}{1,} & {\\text { if } \\| \\widehat{\\mathcal{H} \\mathbf{p}_{h w}}-\\mathbf{p}_{h^{\\prime} w^{\\prime}}|| \\leq 8} \\\\ {0,} & {\\text { otherwise }}\\end{array}\\right. \\begin{aligned} l_{d}\\left(\\mathbf{d}, \\mathbf{d}^{\\prime} ; s\\right) &=\\lambda_{d} * s * \\max \\left(0, m_{p}-\\mathbf{d}^{T} \\mathbf{d}^{\\prime}\\right) \\\\ &+(1-s) * \\max \\left(0, \\mathbf{d}^{T} \\mathbf{d}^{\\prime}-m_{n}\\right) \\end{aligned} \\begin{aligned} \\mathcal{L}_{d}\\left(\\mathcal{D}, \\mathcal{D}^{\\prime}, S\\right) &=\\\\ \\frac{1}{\\left(H_{c} W_{c}\\right)^{2}} &\\sum_{h=1}^{H_{c}, W_{c} H_{c}, W_{c}} l_{d}\\left(\\mathbf{d}_{h w}, \\mathbf{d}_{h^{\\prime} w^{\\prime}}^{\\prime} ; s_{h w h^{\\prime} w^{\\prime}}\\right) \\end{aligned} \\begin{aligned} \\mathcal{L}\\left(\\mathcal{X}, \\mathcal{X}^{\\prime}, \\mathcal{D}, \\mathcal{D}^{\\prime} ; Y, Y^{\\prime}, S\\right) &=\\\\ \\mathcal{L}_{p}(\\mathcal{X}, Y)&+\\mathcal{L}_{p}\\left(\\mathcal{X}^{\\prime}, Y^{\\prime}\\right)+\\lambda \\mathcal{L}_{d}\\left(\\mathcal{D}, \\mathcal{D}^{\\prime}, S\\right) \\end{aligned}","title":"\u7f51\u7edc\u6a21\u578b"},{"location":"Robotics_with_DL/Universal Planning Networks/","text":"Universal Planning Networks \u8fd9\u7bc7\u8bba\u6587\u7ed9\u51fa\u4e86\u4e00\u4e2a\u901a\u7528\u7684\u7528\u4e8eplanning\u7684\u7f51\u7edc\u7ed3\u6784\uff0c\u76ee\u7684\u662f\u8f93\u51fa\u4e00\u7cfb\u5217\u7684state\u4ee5\u63a5\u8fd1goal state\u3002\u5b83\u4e00\u65b9\u9762\u53ef\u4ee5\u7528\u4e8eplanning\uff0c\u4e5f\u53ef\u4ee5\u6839\u636e\u5b66\u4e60\u5230\u7684\u53c2\u6570\u7ed9\u51fa\u5f3a\u5316\u5b66\u4e60\u4f7f\u7528\u7684\u6210\u672c\u51fd\u6570 \u4e3b\u8981\u8d21\u732e 1. \u7f51\u7edc\u7ed3\u6784\u4e0e\u7b97\u6cd5 \u7ed9\u51fa\u5f53\u524d\u89c2\u6d4b o_t \u4ee5\u53ca\u76ee\u6807\u89c2\u6d4b o_g \u4f5c\u4e3a\u8f93\u5165\u56fe\u50cf\uff0c \\hat a_t \u4e3a t \u65f6\u523b\u9884\u6d4b\u7684\u884c\u52a8 \u5728GDP(Gradien Descent Planner)\u4e2d\uff0c\u7528\u53ef\u5b66\u4e60\u7684\u7f16\u7801\u5668 f_\\phi \u5c06\u89c2\u6d4b o_t \u8f6c\u6362\u4e3alatent space x_t ,\u518d\u7528\u53ef\u5b66\u4e60\u7684\u6a21\u578b\u8f6c\u6362\u53c2\u6570 \\hat x_{t+1} = g_\\theta(x_t, a_t) \u5b66\u4e60 n_p \u6b65\u3002\u5176\u4e2d\u7684action a_t \u4e3a\u968f\u673a\u521d\u59cb\u5316\uff0c\u5176\u540e\u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u8fdb\u884c\u4f18\u5316\u66f4\u65b0\u3002 \u4e2a\u4eba\u7406\u89e3\uff0c\u5176\u5b9e state transition\u7ed3\u6784\u53ef\u4ee5\u4f7f\u7528res\u6b8b\u5dee\u8fde\u63a5\u66f4\u79d1\u5b66 \u3002 \u89c4\u5212\u8fc7\u7a0b\u4e2d\u7684\u635f\u5931\u51fd\u6570 L_{plan}^{(i)} \u4e3a\u6700\u7ec8\u9884\u6d4b\u7684 x_{t+T+1} \u4e0e x_g \u7684\u8ddd\u79bb\uff08\u53ef\u5bfc\uff09\u3002 \u5bf9planner\u7684\u8bad\u7ec3\u53ef\u4ee5\u7528Imitation\uff0c\u56e0\u4e3aGDP\u7ed9\u51faaction\u7684\u7b97\u6cd5\u5c3d\u7ba1\u6709\u68af\u5ea6\u7684\u4f7f\u7528\uff0c\u4f46\u662f\u662f\u5b8c\u5168\u53ef\u5bfc\u7684\u3002\u5728\u8fd9\u4e2a\u57fa\u7840\u4e0a\u7ed9\u51fa\u76f8\u5bf9\u53c2\u8003\u884c\u52a8\u7684\u635f\u5931\u51fd\u6570 L_{imitate} = ||\\hat a_{t:T} - a^{*}_{t:t+T}||_2^2 ,\u7528\u68af\u5ea6\u66f4\u65b0\u7f16\u7801\u5668\u4ee5\u53ca\u8fc7\u7a0b\u7f51\u7edc\u7684\u53c2\u6570\u3002 \u672c\u6587\u8fdb\u4e00\u6b65\u4ecb\u7ecd\u4e86\u4f7f\u7528\u8fd9\u4e2a\u5b66\u4e60\u5230\u7684\u7f16\u7801\u5668\u4e0e\u7cfb\u7edf\u6a21\u578b\u6765\u8f85\u52a9\u5f3a\u5316\u5b66\u4e60\u7684\u8fd0\u52a8\u751f\u6210\u3002 \u4e2a\u4eba\u7406\u89e3\uff0c\u8fd9\u4e2a\u6587\u7ae0\u7684\u4ee3\u7801\u96be\u5ea6\u5728\u4e8e\u6a21\u4eff\u5b66\u4e60\u7684\u65f6\u5019\uff0c\u4e00\u65b9\u9762\u9700\u8981\u7528\u68af\u5ea6\u66f4\u65b0\u8fd0\u52a8\uff0c\u53e6\u4e00\u65b9\u9762\u8981\u8fdb\u4e00\u6b65\u7684\u7528\u68af\u5ea6\u66f4\u65b0\u7cfb\u7edf\u53c2\u6570\u3002 pytorch\u4ee5\u53caTensorflow\u9ed8\u8ba4\u60c5\u51b5\u4e0b\u53ea\u4f1a\u8bb0\u4f4f\u4e00\u6b21\u8fd0\u7b97\u8fc7\u7a0b\u4e2d\u7684\u68af\u5ea6\u4fe1\u606f \uff0c\u7136\u540e\u5728\u68af\u5ea6\u66f4\u65b0\u7684\u65f6\u5019\u9700\u8981\u5220\u9664\u6b64\u524d\u8bb0\u5f55\u7684\u6240\u6709\u8fd0\u7b97\u56fe\u3002\u4f46\u662f\u8fd9\u91cc\u6a21\u4eff\u7684\u65f6\u5019\u4f3c\u4e4e\u9700\u8981\u6211\u4eec\u8bb0\u4f4f\u68af\u5ea6\u66f4\u65b0\u7684\u65f6\u5019\u4f7f\u7528\u7684\u6574\u4e2a\u8fd0\u7b97\u56fe ( \u4e5f\u53ef\u80fd\u53ea\u9700\u8981\u6700\u540e\u4e00\u6b65\uff0c\u5e76\u4fdd\u7559\u6700\u540e\u4e00\u6b65\u7684\u68af\u5ea6 )","title":"Universal Planning Networks"},{"location":"Robotics_with_DL/Universal Planning Networks/#universal-planning-networks","text":"\u8fd9\u7bc7\u8bba\u6587\u7ed9\u51fa\u4e86\u4e00\u4e2a\u901a\u7528\u7684\u7528\u4e8eplanning\u7684\u7f51\u7edc\u7ed3\u6784\uff0c\u76ee\u7684\u662f\u8f93\u51fa\u4e00\u7cfb\u5217\u7684state\u4ee5\u63a5\u8fd1goal state\u3002\u5b83\u4e00\u65b9\u9762\u53ef\u4ee5\u7528\u4e8eplanning\uff0c\u4e5f\u53ef\u4ee5\u6839\u636e\u5b66\u4e60\u5230\u7684\u53c2\u6570\u7ed9\u51fa\u5f3a\u5316\u5b66\u4e60\u4f7f\u7528\u7684\u6210\u672c\u51fd\u6570","title":"Universal Planning Networks"},{"location":"Robotics_with_DL/Universal Planning Networks/#_1","text":"","title":"\u4e3b\u8981\u8d21\u732e"},{"location":"Robotics_with_DL/Universal Planning Networks/#1","text":"\u7ed9\u51fa\u5f53\u524d\u89c2\u6d4b o_t \u4ee5\u53ca\u76ee\u6807\u89c2\u6d4b o_g \u4f5c\u4e3a\u8f93\u5165\u56fe\u50cf\uff0c \\hat a_t \u4e3a t \u65f6\u523b\u9884\u6d4b\u7684\u884c\u52a8 \u5728GDP(Gradien Descent Planner)\u4e2d\uff0c\u7528\u53ef\u5b66\u4e60\u7684\u7f16\u7801\u5668 f_\\phi \u5c06\u89c2\u6d4b o_t \u8f6c\u6362\u4e3alatent space x_t ,\u518d\u7528\u53ef\u5b66\u4e60\u7684\u6a21\u578b\u8f6c\u6362\u53c2\u6570 \\hat x_{t+1} = g_\\theta(x_t, a_t) \u5b66\u4e60 n_p \u6b65\u3002\u5176\u4e2d\u7684action a_t \u4e3a\u968f\u673a\u521d\u59cb\u5316\uff0c\u5176\u540e\u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u8fdb\u884c\u4f18\u5316\u66f4\u65b0\u3002 \u4e2a\u4eba\u7406\u89e3\uff0c\u5176\u5b9e state transition\u7ed3\u6784\u53ef\u4ee5\u4f7f\u7528res\u6b8b\u5dee\u8fde\u63a5\u66f4\u79d1\u5b66 \u3002 \u89c4\u5212\u8fc7\u7a0b\u4e2d\u7684\u635f\u5931\u51fd\u6570 L_{plan}^{(i)} \u4e3a\u6700\u7ec8\u9884\u6d4b\u7684 x_{t+T+1} \u4e0e x_g \u7684\u8ddd\u79bb\uff08\u53ef\u5bfc\uff09\u3002 \u5bf9planner\u7684\u8bad\u7ec3\u53ef\u4ee5\u7528Imitation\uff0c\u56e0\u4e3aGDP\u7ed9\u51faaction\u7684\u7b97\u6cd5\u5c3d\u7ba1\u6709\u68af\u5ea6\u7684\u4f7f\u7528\uff0c\u4f46\u662f\u662f\u5b8c\u5168\u53ef\u5bfc\u7684\u3002\u5728\u8fd9\u4e2a\u57fa\u7840\u4e0a\u7ed9\u51fa\u76f8\u5bf9\u53c2\u8003\u884c\u52a8\u7684\u635f\u5931\u51fd\u6570 L_{imitate} = ||\\hat a_{t:T} - a^{*}_{t:t+T}||_2^2 ,\u7528\u68af\u5ea6\u66f4\u65b0\u7f16\u7801\u5668\u4ee5\u53ca\u8fc7\u7a0b\u7f51\u7edc\u7684\u53c2\u6570\u3002 \u672c\u6587\u8fdb\u4e00\u6b65\u4ecb\u7ecd\u4e86\u4f7f\u7528\u8fd9\u4e2a\u5b66\u4e60\u5230\u7684\u7f16\u7801\u5668\u4e0e\u7cfb\u7edf\u6a21\u578b\u6765\u8f85\u52a9\u5f3a\u5316\u5b66\u4e60\u7684\u8fd0\u52a8\u751f\u6210\u3002 \u4e2a\u4eba\u7406\u89e3\uff0c\u8fd9\u4e2a\u6587\u7ae0\u7684\u4ee3\u7801\u96be\u5ea6\u5728\u4e8e\u6a21\u4eff\u5b66\u4e60\u7684\u65f6\u5019\uff0c\u4e00\u65b9\u9762\u9700\u8981\u7528\u68af\u5ea6\u66f4\u65b0\u8fd0\u52a8\uff0c\u53e6\u4e00\u65b9\u9762\u8981\u8fdb\u4e00\u6b65\u7684\u7528\u68af\u5ea6\u66f4\u65b0\u7cfb\u7edf\u53c2\u6570\u3002 pytorch\u4ee5\u53caTensorflow\u9ed8\u8ba4\u60c5\u51b5\u4e0b\u53ea\u4f1a\u8bb0\u4f4f\u4e00\u6b21\u8fd0\u7b97\u8fc7\u7a0b\u4e2d\u7684\u68af\u5ea6\u4fe1\u606f \uff0c\u7136\u540e\u5728\u68af\u5ea6\u66f4\u65b0\u7684\u65f6\u5019\u9700\u8981\u5220\u9664\u6b64\u524d\u8bb0\u5f55\u7684\u6240\u6709\u8fd0\u7b97\u56fe\u3002\u4f46\u662f\u8fd9\u91cc\u6a21\u4eff\u7684\u65f6\u5019\u4f3c\u4e4e\u9700\u8981\u6211\u4eec\u8bb0\u4f4f\u68af\u5ea6\u66f4\u65b0\u7684\u65f6\u5019\u4f7f\u7528\u7684\u6574\u4e2a\u8fd0\u7b97\u56fe ( \u4e5f\u53ef\u80fd\u53ea\u9700\u8981\u6700\u540e\u4e00\u6b65\uff0c\u5e76\u4fdd\u7559\u6700\u540e\u4e00\u6b65\u7684\u68af\u5ea6 )","title":"1. \u7f51\u7edc\u7ed3\u6784\u4e0e\u7b97\u6cd5"},{"location":"The Theory/Channel_Pruning_for_Accelerating_Very_Deep_Neural_Networks/","text":"Channel Pruning for Accelerating Very Deep Neural Networks \u8fd9\u7bc7\u6587\u7ae0\u4ecb\u7ecd\u4e86\u4e00\u79cd\u5b9e\u73b0channel pruning\u7684\u7b97\u6cd5\u3002\u5176\u6838\u5fc3\u7b97\u6cd5\u4ee3\u7801\u5728\u8be5\u5e93\u7684./lib/net.py -> R3\u65b9\u6cd5\u4e2d\u3002 \u5bf9pretrained\u7684\u6a21\u578b\uff0c\u8981\u8fdb\u884c\u6a21\u578b\u7684\u4fee\u526a\uff0c\u672c\u6587\u63d0\u5230\u6709\u4e09\u79cd\u65b9\u6cd5\uff0c\u7b2c\u4e00\u79cd\u662fsparse connection, \u7b2c\u4e8c\u79cd\u662ftensor factorization,\u7b2c\u4e09\u79cd\u662fchannel pruning. sparse connection\u7531\u4e8e\u5f15\u5165\u4e86\u4e0d\u89c4\u5219\u7684\u6a21\u578b\u7ed3\u6784\uff0c\u4f1a\u5bfc\u81f4\u5728GPU\u4e0a\u7684\u6267\u884c\u6548\u7387\u4e0b\u964d(\u5c3d\u7ba1flops\u4e0b\u964d\u4e86)\u3002tensor factorization\u672c\u8d28\u4e0a\u662f\u5bf9\u6743\u91cd\u77e9\u9635\u7684\u5206\u89e3\uff0c\u5bf9\u4e8e\u73b0\u4ee3\u7684Res-Connect\u6548\u679c\u4e0d\u4f73\u3002channel pruning\u4e0d\u6539\u53d8\u7ed3\u6784\uff0c\u4e0d\u6539\u53d8\u5e76\u884c\u8fd0\u884c\u60c5\u51b5\uff0c\u4ec5\u4ec5\u6539\u53d8channel\u6570\u91cf\u3002\u4e09\u79cd\u65b9\u5f0f\u7684\u56fe\u793a\u5982\u4e0b\uff1a \u7b97\u6cd5\u4ecb\u7ecd \u8fd9\u4e2a\u7b97\u6cd5\u5206\u4e3a\u4e24\u6b65\u8fed\u4ee3\uff0c\u5206\u522b\u4e3achannel selection \u4ee5\u53ca reconstruction.\u7b2c\u4e00\u6b65\u627e\u5230\u6700\u6709\u4fe1\u606f\u91cf\u7684channel\uff0c\u4fee\u526a\u5197\u4f59\u7684channel\uff0c\u8fd9\u91cc\u4f7f\u7528\u7684\u662fLasso regression, \u7b2c\u4e8c\u6b65reconstruct with Linear least square. \u4ee4\u8f93\u5165\u7684feature map\u7684channel\u6570\u4e3a c , \u5377\u79ef\u6838 W \u7684\u6743\u91cd\u4e3a n\\times c \\times k_h \\times k_w ,\u5377\u79ef\u6838\u6bcf\u6b21\u5377\u79ef\u4f1a\u5728\u4e00\u4e2a\u50cf\u7d20\u70b9\u4e0a\u751f\u6210\u4e00\u4e2a N\\times n \u7684\u8f93\u51fa\u77e9\u9635 Y ,\u5176\u4e2d N \u4e3abatch_num\uff0c\u8fd9\u91cc\u6682\u65f6\u4e0d\u8003\u8651bias\u9879\u3002\u8981\u5c06 c \u4fee\u526a\u4e3a c' .\u540c\u65f6\u6700\u5c0f\u5316reconstruction error\uff0c\u8fd9\u4e2a\u4f18\u5316\u95ee\u9898\u662f \\begin{array}{c}{\\underset{\\boldsymbol{\\beta}, \\mathbf{W}}{\\arg \\min } \\frac{1}{2 N}\\left\\|\\mathbf{Y}-\\sum_{i=1}^{c} \\beta_{i} \\mathbf{X}_{\\mathbf{i}} \\mathbf{W}_{\\mathbf{i}}^{\\top}\\right\\|_{F}^{2}} \\\\ {\\text { subject to }\\|\\boldsymbol{\\beta}\\|_{0} \\leq c^{\\prime}}\\end{array} \u5176\u4e2d ||\\cdot||_F \u4e3a\u4e8c\u9636\u8303\u6570, X_i \u662f\u4e00\u4e2a N\\times k_h k_w \u7684\u77e9\u9635\u88c1\u526a\u81ea\u8f93\u5165 X , \\beta \u662f\u957f\u5ea6\u4e3a c \u7684\u77e2\u91cf\u53c2\u6570\u3002 \u6c42\u89e3\u8fd9\u4e2a\u95ee\u9898\u662fNP\u96be\u7684,\u8fd9\u91cc\u9996\u5148\u5c06\u95ee\u9898\u7528l1\u8303\u6570\u677e\u5f1b\u4e3a \\begin{array}{l}{\\underset{\\boldsymbol{\\beta}, \\mathbf{W}}{\\arg \\min } \\frac{1}{2 N}\\left\\|\\mathrm{Y}-\\sum_{i=1}^{c} \\beta_{i} \\mathrm{X}_{\\mathrm{i}} \\mathrm{W}_{\\mathrm{i}}^{\\top}\\right\\|_{F}^{2}+\\lambda\\|\\boldsymbol{\\beta}\\|_{1}} \\\\ {\\text { subject to }\\|\\boldsymbol{\\beta}\\|_{0} \\leq c^{\\prime}, \\forall i\\left\\|\\mathrm{W}_{\\mathrm{i}}\\right\\|_{F}=1}\\end{array} \u540c\u65f6\u9650\u5236 ||W_i||_F = 1 \u7136\u540e\u5728\u4ee5\u4e0b\u4e24\u4e2a\u6b65\u9aa4\u4e2d\u8fed\u4ee3 \\beta \u5b50\u95ee\u9898 \u9996\u5148\u9501\u5b9a W ,\u6c42\u89e3 \\beta \u4f5c\u4e3achannel selection\u95ee\u9898,\u8fd9\u53d8\u6210\u4e86\u96f6\u8303\u6570\u7684LASSO regression,\u4ee3\u7801\u4e2d\u53ef\u4ee5\u77e5\u9053\u4f5c\u8005\u662f\u4f7f\u7528sklearn\u7684Lasso regression\u51fd\u6570\u505a\u7684\u3002 W \u5b50\u95ee\u9898 \u9501\u5b9a \\beta ,\u95ee\u9898\u53d8\u4e3a argmin_{W'} ||Y - X'(W')^T||^2_F ,\u8fd9\u91cc\u7684 X' = [\\beta_1X_1, \\beta_2 X_2 ...] ( N\\times ck_hk_w ), W' \u5f62\u72b6\u4e3a n\\times c k_hk_w , W' = [W_1, W_2...] ,\u4e4b\u540e\u518d\u4ee4 \\beta_i \\leftarrow \\beta_i ||W_i||_F, W_i \\leftarrow W_i/||W_i||_F ,\u8fd9\u91cc\u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u7ebf\u6027\u56de\u5f52\u3002 \u4f18\u5316\u8fc7\u7a0b \u4ece\u5df2\u7ecf\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u4e2d\u521d\u59cb\u5316W, \\lambda=0, ||\\beta||_0 = c .\u9010\u6e10\u589e\u52a0 \\lambda ,\u5bf9\u4e8e\u6bcf\u4e00\u4e2a \\lambda \uff0c\u8fed\u4ee3\u4e24\u4e2a\u5b50\u95ee\u9898\u7684\u6c42\u89e3\u76f4\u5230 ||\\beta||_0 \u7a33\u5b9a,\u9010\u6e10\u589e\u52a0 \\lambda \u76f4\u5230\u6ee1\u8db3 ||\\beta||_0 \\leq c' .\u540e\u6765\u53c8\u53d1\u73b0\u8fd9\u6837\u592a\u6162\uff0c\u4e8e\u662f\u6267\u884c\u5b50\u95ee\u9898(1)\u591a\u6b21\uff0c\u76f4\u5230 \\beta \u6ee1\u8db3\uff0c\u7136\u540e\u4ec5\u6267\u884c\u4e00\u6b21\u5b50\u95ee\u9898(2) \u5168\u6a21\u578b\u4fee\u5efa \u5728\u4fee\u526a\u65f6\uff0c\u6bcf\u4e00\u4e2a\u5c42\u5355\u72ec\u5904\u7406,\u9700\u8981\u6ce8\u610f\u7684\u662f\u6700\u4f18\u5316\u95ee\u9898\u4e2d\u7684 Y \u9700\u8981\u4f7f\u7528\u7684\u662f\u539f\u6a21\u578b\u7684\u8f93\u51fa\u4f5c\u4e3a\u76ee\u6807 Y \uff0c\u8f93\u5165 X \u5219\u662f\u4fee\u526a\u540e\u7684\u6a21\u578b\u7684\uff0c\u8fd9\u6837\u53ef\u4ee5\u907f\u514d\u8bef\u5dee\u7684\u7d2f\u79ef\u3002 \u5904\u7406\u591a\u5206\u652f\u6a21\u578b \u8fd9\u91cc\u4e3b\u8981\u8ba8\u8bbaResNet. \u8fd9\u91cc\u4e00\u5171\u6709\u4e09\u4e2a\u5377\u79ef\u5c42\uff0c\u7531\u4e8eResNet\u9700\u8981\u4fdd\u6301\u4e0d\u540c\u5c42\u4e4b\u95f4channel\u6570\u7684\u7a33\u5b9a\uff0c\u6240\u4ee5\u53ea\u6709\u4e2d\u95f4\u7684bottlenect\u4e5f\u5c31\u662f c1 \u7684\u8f93\u5165\u5c42\u53ef\u4ee5\u5982\u524d\u6587\u4e00\u6837\u6b63\u5e38\u4fee\u526a\u3002 \u6700\u540e\u4e00\u5c42\u7684\u4fee\u526a \u8fd9\u91cc\u5c06\u4f18\u5316\u76ee\u6807\u4ece Y_2 \u6539\u4e3a Y_1 - Y_1'+Y_2 ,\u8fd9\u91cc Y_1' \u662f\u524d\u9762\u5c42\u4fee\u526a\u540e\u8f93\u51fa\u7684feature map, \u7b2c\u4e00\u5c42\u7684\u4fee\u526a \u589e\u52a0\u4e00\u4e2asampler\u5c42\uff0c\u6b63\u5e38\u51cf\u5c11 c_0 \u5377\u79ef\u5c42\u7684\u8f93\u5165channel\u6570\uff0c\u6ce8\u610f\u8fd9\u4e2asampler\u4e0d\u6539\u53d8short-connection\u8def\u5f84\u4e0a\u7684 Y_1","title":"Channel Pruning for Accelerating Very Deep Neural Networks"},{"location":"The Theory/Channel_Pruning_for_Accelerating_Very_Deep_Neural_Networks/#channel-pruning-for-accelerating-very-deep-neural-networks","text":"\u8fd9\u7bc7\u6587\u7ae0\u4ecb\u7ecd\u4e86\u4e00\u79cd\u5b9e\u73b0channel pruning\u7684\u7b97\u6cd5\u3002\u5176\u6838\u5fc3\u7b97\u6cd5\u4ee3\u7801\u5728\u8be5\u5e93\u7684./lib/net.py -> R3\u65b9\u6cd5\u4e2d\u3002 \u5bf9pretrained\u7684\u6a21\u578b\uff0c\u8981\u8fdb\u884c\u6a21\u578b\u7684\u4fee\u526a\uff0c\u672c\u6587\u63d0\u5230\u6709\u4e09\u79cd\u65b9\u6cd5\uff0c\u7b2c\u4e00\u79cd\u662fsparse connection, \u7b2c\u4e8c\u79cd\u662ftensor factorization,\u7b2c\u4e09\u79cd\u662fchannel pruning. sparse connection\u7531\u4e8e\u5f15\u5165\u4e86\u4e0d\u89c4\u5219\u7684\u6a21\u578b\u7ed3\u6784\uff0c\u4f1a\u5bfc\u81f4\u5728GPU\u4e0a\u7684\u6267\u884c\u6548\u7387\u4e0b\u964d(\u5c3d\u7ba1flops\u4e0b\u964d\u4e86)\u3002tensor factorization\u672c\u8d28\u4e0a\u662f\u5bf9\u6743\u91cd\u77e9\u9635\u7684\u5206\u89e3\uff0c\u5bf9\u4e8e\u73b0\u4ee3\u7684Res-Connect\u6548\u679c\u4e0d\u4f73\u3002channel pruning\u4e0d\u6539\u53d8\u7ed3\u6784\uff0c\u4e0d\u6539\u53d8\u5e76\u884c\u8fd0\u884c\u60c5\u51b5\uff0c\u4ec5\u4ec5\u6539\u53d8channel\u6570\u91cf\u3002\u4e09\u79cd\u65b9\u5f0f\u7684\u56fe\u793a\u5982\u4e0b\uff1a","title":"Channel Pruning for Accelerating Very Deep Neural Networks"},{"location":"The Theory/Channel_Pruning_for_Accelerating_Very_Deep_Neural_Networks/#_1","text":"\u8fd9\u4e2a\u7b97\u6cd5\u5206\u4e3a\u4e24\u6b65\u8fed\u4ee3\uff0c\u5206\u522b\u4e3achannel selection \u4ee5\u53ca reconstruction.\u7b2c\u4e00\u6b65\u627e\u5230\u6700\u6709\u4fe1\u606f\u91cf\u7684channel\uff0c\u4fee\u526a\u5197\u4f59\u7684channel\uff0c\u8fd9\u91cc\u4f7f\u7528\u7684\u662fLasso regression, \u7b2c\u4e8c\u6b65reconstruct with Linear least square. \u4ee4\u8f93\u5165\u7684feature map\u7684channel\u6570\u4e3a c , \u5377\u79ef\u6838 W \u7684\u6743\u91cd\u4e3a n\\times c \\times k_h \\times k_w ,\u5377\u79ef\u6838\u6bcf\u6b21\u5377\u79ef\u4f1a\u5728\u4e00\u4e2a\u50cf\u7d20\u70b9\u4e0a\u751f\u6210\u4e00\u4e2a N\\times n \u7684\u8f93\u51fa\u77e9\u9635 Y ,\u5176\u4e2d N \u4e3abatch_num\uff0c\u8fd9\u91cc\u6682\u65f6\u4e0d\u8003\u8651bias\u9879\u3002\u8981\u5c06 c \u4fee\u526a\u4e3a c' .\u540c\u65f6\u6700\u5c0f\u5316reconstruction error\uff0c\u8fd9\u4e2a\u4f18\u5316\u95ee\u9898\u662f \\begin{array}{c}{\\underset{\\boldsymbol{\\beta}, \\mathbf{W}}{\\arg \\min } \\frac{1}{2 N}\\left\\|\\mathbf{Y}-\\sum_{i=1}^{c} \\beta_{i} \\mathbf{X}_{\\mathbf{i}} \\mathbf{W}_{\\mathbf{i}}^{\\top}\\right\\|_{F}^{2}} \\\\ {\\text { subject to }\\|\\boldsymbol{\\beta}\\|_{0} \\leq c^{\\prime}}\\end{array} \u5176\u4e2d ||\\cdot||_F \u4e3a\u4e8c\u9636\u8303\u6570, X_i \u662f\u4e00\u4e2a N\\times k_h k_w \u7684\u77e9\u9635\u88c1\u526a\u81ea\u8f93\u5165 X , \\beta \u662f\u957f\u5ea6\u4e3a c \u7684\u77e2\u91cf\u53c2\u6570\u3002 \u6c42\u89e3\u8fd9\u4e2a\u95ee\u9898\u662fNP\u96be\u7684,\u8fd9\u91cc\u9996\u5148\u5c06\u95ee\u9898\u7528l1\u8303\u6570\u677e\u5f1b\u4e3a \\begin{array}{l}{\\underset{\\boldsymbol{\\beta}, \\mathbf{W}}{\\arg \\min } \\frac{1}{2 N}\\left\\|\\mathrm{Y}-\\sum_{i=1}^{c} \\beta_{i} \\mathrm{X}_{\\mathrm{i}} \\mathrm{W}_{\\mathrm{i}}^{\\top}\\right\\|_{F}^{2}+\\lambda\\|\\boldsymbol{\\beta}\\|_{1}} \\\\ {\\text { subject to }\\|\\boldsymbol{\\beta}\\|_{0} \\leq c^{\\prime}, \\forall i\\left\\|\\mathrm{W}_{\\mathrm{i}}\\right\\|_{F}=1}\\end{array} \u540c\u65f6\u9650\u5236 ||W_i||_F = 1 \u7136\u540e\u5728\u4ee5\u4e0b\u4e24\u4e2a\u6b65\u9aa4\u4e2d\u8fed\u4ee3","title":"\u7b97\u6cd5\u4ecb\u7ecd"},{"location":"The Theory/Channel_Pruning_for_Accelerating_Very_Deep_Neural_Networks/#beta","text":"\u9996\u5148\u9501\u5b9a W ,\u6c42\u89e3 \\beta \u4f5c\u4e3achannel selection\u95ee\u9898,\u8fd9\u53d8\u6210\u4e86\u96f6\u8303\u6570\u7684LASSO regression,\u4ee3\u7801\u4e2d\u53ef\u4ee5\u77e5\u9053\u4f5c\u8005\u662f\u4f7f\u7528sklearn\u7684Lasso regression\u51fd\u6570\u505a\u7684\u3002","title":"\\beta \u5b50\u95ee\u9898"},{"location":"The Theory/Channel_Pruning_for_Accelerating_Very_Deep_Neural_Networks/#w","text":"\u9501\u5b9a \\beta ,\u95ee\u9898\u53d8\u4e3a argmin_{W'} ||Y - X'(W')^T||^2_F ,\u8fd9\u91cc\u7684 X' = [\\beta_1X_1, \\beta_2 X_2 ...] ( N\\times ck_hk_w ), W' \u5f62\u72b6\u4e3a n\\times c k_hk_w , W' = [W_1, W_2...] ,\u4e4b\u540e\u518d\u4ee4 \\beta_i \\leftarrow \\beta_i ||W_i||_F, W_i \\leftarrow W_i/||W_i||_F ,\u8fd9\u91cc\u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u7ebf\u6027\u56de\u5f52\u3002","title":"W \u5b50\u95ee\u9898"},{"location":"The Theory/Channel_Pruning_for_Accelerating_Very_Deep_Neural_Networks/#_2","text":"\u4ece\u5df2\u7ecf\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u4e2d\u521d\u59cb\u5316W, \\lambda=0, ||\\beta||_0 = c .\u9010\u6e10\u589e\u52a0 \\lambda ,\u5bf9\u4e8e\u6bcf\u4e00\u4e2a \\lambda \uff0c\u8fed\u4ee3\u4e24\u4e2a\u5b50\u95ee\u9898\u7684\u6c42\u89e3\u76f4\u5230 ||\\beta||_0 \u7a33\u5b9a,\u9010\u6e10\u589e\u52a0 \\lambda \u76f4\u5230\u6ee1\u8db3 ||\\beta||_0 \\leq c' .\u540e\u6765\u53c8\u53d1\u73b0\u8fd9\u6837\u592a\u6162\uff0c\u4e8e\u662f\u6267\u884c\u5b50\u95ee\u9898(1)\u591a\u6b21\uff0c\u76f4\u5230 \\beta \u6ee1\u8db3\uff0c\u7136\u540e\u4ec5\u6267\u884c\u4e00\u6b21\u5b50\u95ee\u9898(2)","title":"\u4f18\u5316\u8fc7\u7a0b"},{"location":"The Theory/Channel_Pruning_for_Accelerating_Very_Deep_Neural_Networks/#_3","text":"\u5728\u4fee\u526a\u65f6\uff0c\u6bcf\u4e00\u4e2a\u5c42\u5355\u72ec\u5904\u7406,\u9700\u8981\u6ce8\u610f\u7684\u662f\u6700\u4f18\u5316\u95ee\u9898\u4e2d\u7684 Y \u9700\u8981\u4f7f\u7528\u7684\u662f\u539f\u6a21\u578b\u7684\u8f93\u51fa\u4f5c\u4e3a\u76ee\u6807 Y \uff0c\u8f93\u5165 X \u5219\u662f\u4fee\u526a\u540e\u7684\u6a21\u578b\u7684\uff0c\u8fd9\u6837\u53ef\u4ee5\u907f\u514d\u8bef\u5dee\u7684\u7d2f\u79ef\u3002","title":"\u5168\u6a21\u578b\u4fee\u5efa"},{"location":"The Theory/Channel_Pruning_for_Accelerating_Very_Deep_Neural_Networks/#_4","text":"\u8fd9\u91cc\u4e3b\u8981\u8ba8\u8bbaResNet. \u8fd9\u91cc\u4e00\u5171\u6709\u4e09\u4e2a\u5377\u79ef\u5c42\uff0c\u7531\u4e8eResNet\u9700\u8981\u4fdd\u6301\u4e0d\u540c\u5c42\u4e4b\u95f4channel\u6570\u7684\u7a33\u5b9a\uff0c\u6240\u4ee5\u53ea\u6709\u4e2d\u95f4\u7684bottlenect\u4e5f\u5c31\u662f c1 \u7684\u8f93\u5165\u5c42\u53ef\u4ee5\u5982\u524d\u6587\u4e00\u6837\u6b63\u5e38\u4fee\u526a\u3002","title":"\u5904\u7406\u591a\u5206\u652f\u6a21\u578b"},{"location":"The Theory/Channel_Pruning_for_Accelerating_Very_Deep_Neural_Networks/#_5","text":"\u8fd9\u91cc\u5c06\u4f18\u5316\u76ee\u6807\u4ece Y_2 \u6539\u4e3a Y_1 - Y_1'+Y_2 ,\u8fd9\u91cc Y_1' \u662f\u524d\u9762\u5c42\u4fee\u526a\u540e\u8f93\u51fa\u7684feature map,","title":"\u6700\u540e\u4e00\u5c42\u7684\u4fee\u526a"},{"location":"The Theory/Channel_Pruning_for_Accelerating_Very_Deep_Neural_Networks/#_6","text":"\u589e\u52a0\u4e00\u4e2asampler\u5c42\uff0c\u6b63\u5e38\u51cf\u5c11 c_0 \u5377\u79ef\u5c42\u7684\u8f93\u5165channel\u6570\uff0c\u6ce8\u610f\u8fd9\u4e2asampler\u4e0d\u6539\u53d8short-connection\u8def\u5f84\u4e0a\u7684 Y_1","title":"\u7b2c\u4e00\u5c42\u7684\u4fee\u526a"},{"location":"The Theory/Do Better ImageNet Models Transfer Better/","text":"Do Better ImageNet Models Transfer Better? \u8fd9\u7bc7\u8bba\u6587\u8ba4\u771f\u5730\u6d4b\u8bd5\u4e86\u4e0d\u540cImageNet Models\u7684transfer learning\u80fd\u529b\u3002\u521d\u6b65\u5b9e\u9a8c\u65b9\u5f0f\u662f\u572812\u4e2a\u4e0d\u540c\u79cd\u7c7b\u4e0d\u540csize\u7684\u8bad\u7ec3\u96c6\u4e2d\uff0c\u752816\u4e2apretrained \u7f51\u7edc\u5206\u522b\u8fdb\u884cfix-feature-extractor logistic regression\u3001fine-tuning\u3001re-train. \u90fd\u7528grid-search \u5bfb\u627e\u6700\u4f18\u5b66\u4e60\u7387\u7b49\u8d85\u53c2\u6570\u3002 metrics in comparison \u7ecf\u9a8c\u7ed3\u8bba\uff1a 1. ImageNet \u7684\u51c6\u786e\u7387\u80fd\u9884\u6d4blogistic regression\u7684\u51c6\u786e\u7387\uff0c\u4e24\u8005\u6709\u8f83\u5f3a\u7684\u6b63\u76f8\u5173\u6027\uff0c\u4f46\u662fregularization setting\u4f1a\u6709\u5f71\u54cd\u3002 Google\u4f7f\u7528\u76f8\u540c\u7684training setting\u65f6\uff0c\u7ed3\u8bba\u524d\u534a\u53e5\u6210\u7acb\uff0c\u5728imageNet\u8868\u73b0\u6700\u597d\u7684Inception-ResNet v2 and NASNet Large\u7a33\u5750\u524d\u4e24\u540d\u3002\u4f46\u662f\u4ece\u516c\u5f00\u80fd\u83b7\u5f97\u7684checkpoint\u4e2d\u5f00\u59cbtrain\u7684\u8bdd,ResNet\u548cDenseNet\u51e0\u4e4e\u603b\u662f\u6700\u597d\u7684\uff0c\u4e14transfer and basic accuracy\u7684\u76f8\u5173\u6027\u5f88\u5dee\uff0c\u8fdb\u4e00\u6b65\u7814\u7a76\u53d1\u73b0\u8fd9\u4e2a\u662f\u56e0\u4e3aregularization\u3002 \u627e\u5230\u56db\u4e2a\u635f\u5bb3Inception Net transfer accuracy\u7684\u64cd\u4f5c\uff0c\u5206\u522b\u662f \u5728batchnorm\u5c42\u4e0d\u4f7f\u7528scale parameter(\u4e0d\u5b66\u4e60\u65b9\u5dee) label smoothing(\u6e90\u81eainception-v3,\u5728\u8bad\u7ec3\u65f6\u6709\u4e00\u5b9a\u6982\u7387\u4e0d\u91c7\u53d6\u539flabel\uff0c\u800c\u5747\u5300\u968f\u673a\u9009\u62e9\u53e6\u4e00\u4e2aclass\u4f5c\u4e3aground truth) dropout \u989d\u5916\u7684\u5206\u7c7b\u8f93\u51fa(\u5728\u65e9\u671f\u5c42\u63d0\u524d\u8f93\u51fa\u7ed3\u679c) \u8fd9\u4e9b\u65b9\u6cd5\u5bf9top-1\u51c6\u786e\u7387\u63d0\u5347\u4e0d\u52301%\uff0c\u4f46\u662f\u5728transfer\u4e0a\u9020\u6210\u635f\u5bb3\uff0c\u5728\u76f8\u5bf9log\u6bd4\u4f8b\u4e0a\u6765\u8bf4\u76f8\u5f53\u4e8e\u628a\u6700\u597d\u7684backbone\u6362\u6210\u6700\u5f31\u7684backbone\uff0c\u8fd9\u4e2a\u4e0d\u4f46\u80fd\u5728transfer learning\u7684\u7ed3\u679c\u4e0a\u770b\u5230\u5dee\u522b\uff0c\u5728t-SNE\u7684\u53ef\u89c6\u5316\u7ed3\u679c\u4e2d\u4e5f\u53ef\u89c1\u5230\u3002 2. ImageNet\u51c6\u786e\u7387\u80fd\u9884\u6d4bfine-tunning\u7684\u8868\u73b0 regularizaion \u8fd8\u6709training setting\u7684\u6548\u679c\u5728fine-tuning\u7684\u7ed3\u679c\u4e0a\u5f71\u54cd\u4e0d\u5927(\u6709\u4e00\u5b9a\u635f\u4f24\uff0c\u6709\u4e9b\u8fd8\u6ca1\u6709\u635f\u4f24\uff0c\u6839\u636e\u56fe5\uff0c\u53ef\u4ee5\u8bf4\u662f\u6570\u636e\u4e0a\u4e0d\u663e\u8457)\u3002 \u4f46\u662f\u8fd9\u4e2a\u76f8\u5173\u6027\u5728\u4e0d\u540cdataset\u4e0a\u6709\u4e0d\u540c\uff0c\u5728\u5c0f\u7684\u6570\u636e\u96c6\u4e0a\u76f8\u5173\u6027\u6700\u660e\u663e 3. ImageNet\u51c6\u786e\u7387\u80fd\u9884\u6d4b\u968f\u673a\u521d\u59cb\u5316\u65f6\u7684\u8868\u73b0 \u8fd9\u4e2a\u76f8\u5173\u6027\u76f8\u5bf9\u5c0f\u4e00\u4e9b\uff0c\u800c\u4e14\u66f4\u7ec6\u81f4\u5730\u770b\uff0c\u6570\u636e\u96c6\u5927\u5c0f\u8f83\u5c0f\u65f6\u76f8\u5173\u6027\u4e0d\u663e\u8457\uff0c\u4f46\u662f\u5bf9\u4e8e\u5927\u6570\u636e\u96c6\uff0c\u76f8\u5173\u6027\u4f1a\u5f88\u663e\u8457\u3002 4. \u9009\u62e9\u66f4\u597d\u7684backbone\u6a21\u578b\u6027\u80fd\u63d0\u5347\u6bd4\u5f97\u4e0a\u4e3atransfer learning\u4e13\u95e8\u8bbe\u8ba1\u7684\u7279\u6b8a\u65b9\u6cd5 \u7ed3\u679c\u8868\u660epretrained model\u5bf9transfer\u7ed3\u679c\u5f88\u91cd\u8981\uff0c\u672c\u6587\u58f0\u79f0\u5728\u76ee\u524d\u4f7f\u7528\u7684dataset\u4e2d\uff0c\u5b83\u4eec\u901a\u8fc7\u66f4\u6362\u5e76fine-tuning backbone\u8d85\u8fc7\u4e86\u6587\u4e2d\u63d0\u5230\u7684N\u79cdtransfer learning\u7b97\u6cd5\u3002 \u672c\u6587\u6700\u540e\u8868\u793atransfer tricks\u4e0e\u66f4\u6362backbone\u5e76\u4e0d\u77db\u76fe\uff0c\u751a\u81f3\u53ef\u4ee5\u76f8\u4e92\u53e0\u52a0\uff0c\u4f46\u662f\u8fd9\u4e2a\u63d0\u5347\u5e45\u5ea6\u503c\u5f97\u5173\u6ce8 5. \u5bf9\u4e8e\u5206\u7c7b\u66f4\u7ec6\u81f4\u7684\u5982\u8f66\u5206\u7c7b\u4ee5\u53ca\u98de\u884c\u5668\u5206\u7c7b\uff0cImageNet Pretraining\u4e0e\u968f\u673a\u521d\u59cb\u5316\u76f8\u6bd4\u5dee\u8ddd\u4e0d\u5927 \u5176\u4f59\u5927\u90e8\u5206\u6570\u636e\u4e4b\u4e2d\uff0cfine_tune > pretrained > random\u662f\u663e\u8457\u5730 6. ImageNet\u52a0\u901f\u6536\u655b 7. \u5982\u4f55\u9009\u62e9\u662f\u5426pretrained \u7ed3\u8bba\uff1a \u6570\u636e\u6700\u5c11\u662flogistic regression\u53ef\u80fd\u662f\u6700\u597d\u7684(\u901f\u5ea6\u5feb\uff0c\u6027\u80fd\u597d)\uff0c\u5927\u4e00\u4e9b\u7684dataset,fine-tuning\u6700\u597d\uff0c\u66f4\u5927\u7684\u6570\u636e\u96c6\u4e2d\uff0c\u968f\u673a\u521d\u59cb\u5316\u7684\u6700\u7ec8\u6027\u80fd\u4f1a\u903c\u8fd1pretrained","title":"Do Better ImageNet Models Transfer Better?"},{"location":"The Theory/Do Better ImageNet Models Transfer Better/#do-better-imagenet-models-transfer-better","text":"\u8fd9\u7bc7\u8bba\u6587\u8ba4\u771f\u5730\u6d4b\u8bd5\u4e86\u4e0d\u540cImageNet Models\u7684transfer learning\u80fd\u529b\u3002\u521d\u6b65\u5b9e\u9a8c\u65b9\u5f0f\u662f\u572812\u4e2a\u4e0d\u540c\u79cd\u7c7b\u4e0d\u540csize\u7684\u8bad\u7ec3\u96c6\u4e2d\uff0c\u752816\u4e2apretrained \u7f51\u7edc\u5206\u522b\u8fdb\u884cfix-feature-extractor logistic regression\u3001fine-tuning\u3001re-train. \u90fd\u7528grid-search \u5bfb\u627e\u6700\u4f18\u5b66\u4e60\u7387\u7b49\u8d85\u53c2\u6570\u3002","title":"Do Better ImageNet Models Transfer Better?"},{"location":"The Theory/Do Better ImageNet Models Transfer Better/#metrics-in-comparison","text":"","title":"metrics in comparison"},{"location":"The Theory/Do Better ImageNet Models Transfer Better/#_1","text":"","title":"\u7ecf\u9a8c\u7ed3\u8bba\uff1a"},{"location":"The Theory/Do Better ImageNet Models Transfer Better/#1-imagenet-logistic-regressionregularization-setting","text":"Google\u4f7f\u7528\u76f8\u540c\u7684training setting\u65f6\uff0c\u7ed3\u8bba\u524d\u534a\u53e5\u6210\u7acb\uff0c\u5728imageNet\u8868\u73b0\u6700\u597d\u7684Inception-ResNet v2 and NASNet Large\u7a33\u5750\u524d\u4e24\u540d\u3002\u4f46\u662f\u4ece\u516c\u5f00\u80fd\u83b7\u5f97\u7684checkpoint\u4e2d\u5f00\u59cbtrain\u7684\u8bdd,ResNet\u548cDenseNet\u51e0\u4e4e\u603b\u662f\u6700\u597d\u7684\uff0c\u4e14transfer and basic accuracy\u7684\u76f8\u5173\u6027\u5f88\u5dee\uff0c\u8fdb\u4e00\u6b65\u7814\u7a76\u53d1\u73b0\u8fd9\u4e2a\u662f\u56e0\u4e3aregularization\u3002 \u627e\u5230\u56db\u4e2a\u635f\u5bb3Inception Net transfer accuracy\u7684\u64cd\u4f5c\uff0c\u5206\u522b\u662f \u5728batchnorm\u5c42\u4e0d\u4f7f\u7528scale parameter(\u4e0d\u5b66\u4e60\u65b9\u5dee) label smoothing(\u6e90\u81eainception-v3,\u5728\u8bad\u7ec3\u65f6\u6709\u4e00\u5b9a\u6982\u7387\u4e0d\u91c7\u53d6\u539flabel\uff0c\u800c\u5747\u5300\u968f\u673a\u9009\u62e9\u53e6\u4e00\u4e2aclass\u4f5c\u4e3aground truth) dropout \u989d\u5916\u7684\u5206\u7c7b\u8f93\u51fa(\u5728\u65e9\u671f\u5c42\u63d0\u524d\u8f93\u51fa\u7ed3\u679c) \u8fd9\u4e9b\u65b9\u6cd5\u5bf9top-1\u51c6\u786e\u7387\u63d0\u5347\u4e0d\u52301%\uff0c\u4f46\u662f\u5728transfer\u4e0a\u9020\u6210\u635f\u5bb3\uff0c\u5728\u76f8\u5bf9log\u6bd4\u4f8b\u4e0a\u6765\u8bf4\u76f8\u5f53\u4e8e\u628a\u6700\u597d\u7684backbone\u6362\u6210\u6700\u5f31\u7684backbone\uff0c\u8fd9\u4e2a\u4e0d\u4f46\u80fd\u5728transfer learning\u7684\u7ed3\u679c\u4e0a\u770b\u5230\u5dee\u522b\uff0c\u5728t-SNE\u7684\u53ef\u89c6\u5316\u7ed3\u679c\u4e2d\u4e5f\u53ef\u89c1\u5230\u3002","title":"1. ImageNet \u7684\u51c6\u786e\u7387\u80fd\u9884\u6d4blogistic regression\u7684\u51c6\u786e\u7387\uff0c\u4e24\u8005\u6709\u8f83\u5f3a\u7684\u6b63\u76f8\u5173\u6027\uff0c\u4f46\u662fregularization setting\u4f1a\u6709\u5f71\u54cd\u3002"},{"location":"The Theory/Do Better ImageNet Models Transfer Better/#2-imagenetfine-tunning","text":"regularizaion \u8fd8\u6709training setting\u7684\u6548\u679c\u5728fine-tuning\u7684\u7ed3\u679c\u4e0a\u5f71\u54cd\u4e0d\u5927(\u6709\u4e00\u5b9a\u635f\u4f24\uff0c\u6709\u4e9b\u8fd8\u6ca1\u6709\u635f\u4f24\uff0c\u6839\u636e\u56fe5\uff0c\u53ef\u4ee5\u8bf4\u662f\u6570\u636e\u4e0a\u4e0d\u663e\u8457)\u3002 \u4f46\u662f\u8fd9\u4e2a\u76f8\u5173\u6027\u5728\u4e0d\u540cdataset\u4e0a\u6709\u4e0d\u540c\uff0c\u5728\u5c0f\u7684\u6570\u636e\u96c6\u4e0a\u76f8\u5173\u6027\u6700\u660e\u663e","title":"2. ImageNet\u51c6\u786e\u7387\u80fd\u9884\u6d4bfine-tunning\u7684\u8868\u73b0"},{"location":"The Theory/Do Better ImageNet Models Transfer Better/#3-imagenet","text":"\u8fd9\u4e2a\u76f8\u5173\u6027\u76f8\u5bf9\u5c0f\u4e00\u4e9b\uff0c\u800c\u4e14\u66f4\u7ec6\u81f4\u5730\u770b\uff0c\u6570\u636e\u96c6\u5927\u5c0f\u8f83\u5c0f\u65f6\u76f8\u5173\u6027\u4e0d\u663e\u8457\uff0c\u4f46\u662f\u5bf9\u4e8e\u5927\u6570\u636e\u96c6\uff0c\u76f8\u5173\u6027\u4f1a\u5f88\u663e\u8457\u3002","title":"3. ImageNet\u51c6\u786e\u7387\u80fd\u9884\u6d4b\u968f\u673a\u521d\u59cb\u5316\u65f6\u7684\u8868\u73b0"},{"location":"The Theory/Do Better ImageNet Models Transfer Better/#4-backbonetransfer-learning","text":"\u7ed3\u679c\u8868\u660epretrained model\u5bf9transfer\u7ed3\u679c\u5f88\u91cd\u8981\uff0c\u672c\u6587\u58f0\u79f0\u5728\u76ee\u524d\u4f7f\u7528\u7684dataset\u4e2d\uff0c\u5b83\u4eec\u901a\u8fc7\u66f4\u6362\u5e76fine-tuning backbone\u8d85\u8fc7\u4e86\u6587\u4e2d\u63d0\u5230\u7684N\u79cdtransfer learning\u7b97\u6cd5\u3002 \u672c\u6587\u6700\u540e\u8868\u793atransfer tricks\u4e0e\u66f4\u6362backbone\u5e76\u4e0d\u77db\u76fe\uff0c\u751a\u81f3\u53ef\u4ee5\u76f8\u4e92\u53e0\u52a0\uff0c\u4f46\u662f\u8fd9\u4e2a\u63d0\u5347\u5e45\u5ea6\u503c\u5f97\u5173\u6ce8","title":"4. \u9009\u62e9\u66f4\u597d\u7684backbone\u6a21\u578b\u6027\u80fd\u63d0\u5347\u6bd4\u5f97\u4e0a\u4e3atransfer learning\u4e13\u95e8\u8bbe\u8ba1\u7684\u7279\u6b8a\u65b9\u6cd5"},{"location":"The Theory/Do Better ImageNet Models Transfer Better/#5-imagenet-pretraining","text":"\u5176\u4f59\u5927\u90e8\u5206\u6570\u636e\u4e4b\u4e2d\uff0cfine_tune > pretrained > random\u662f\u663e\u8457\u5730","title":"5. \u5bf9\u4e8e\u5206\u7c7b\u66f4\u7ec6\u81f4\u7684\u5982\u8f66\u5206\u7c7b\u4ee5\u53ca\u98de\u884c\u5668\u5206\u7c7b\uff0cImageNet Pretraining\u4e0e\u968f\u673a\u521d\u59cb\u5316\u76f8\u6bd4\u5dee\u8ddd\u4e0d\u5927"},{"location":"The Theory/Do Better ImageNet Models Transfer Better/#6-imagenet","text":"","title":"6. ImageNet\u52a0\u901f\u6536\u655b"},{"location":"The Theory/Do Better ImageNet Models Transfer Better/#7-pretrained","text":"\u7ed3\u8bba\uff1a \u6570\u636e\u6700\u5c11\u662flogistic regression\u53ef\u80fd\u662f\u6700\u597d\u7684(\u901f\u5ea6\u5feb\uff0c\u6027\u80fd\u597d)\uff0c\u5927\u4e00\u4e9b\u7684dataset,fine-tuning\u6700\u597d\uff0c\u66f4\u5927\u7684\u6570\u636e\u96c6\u4e2d\uff0c\u968f\u673a\u521d\u59cb\u5316\u7684\u6700\u7ec8\u6027\u80fd\u4f1a\u903c\u8fd1pretrained","title":"7. \u5982\u4f55\u9009\u62e9\u662f\u5426pretrained"},{"location":"The Theory/FreeAnchor_Learning_to_Match_Anchors_for_Visual_Object_Detection/","text":"FreeAnchor: Learning to Match Anchors for Visual Object Detection \u8fd9\u7bc7\u8bba\u6587\u6765\u81ea\u4e8eNIPS2019,\u4ecb\u7ecd\u4e86\u65b0\u7684\u65b9\u5f0f\u6765\u5b9e\u73b02D object detection\u4e2d\u7684matching. \u603b\u4f53\u601d\u8def\u6765\u8bf4\uff0c\u4f7f\u7528\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u7684\u6846\u67b6\u5728Object Detection\u7684\u8fc7\u7a0b\u4e2d\uff0c\u91c7\u7528\u4e00\u4e2a\u5355\u4e00\u7684loss\uff0c\u540c\u65f6\u5b8c\u6210proposal\u4e0eobject\u7684\u5339\u914d\u4ee5\u53ca\u56de\u5f52\u8bad\u7ec3\uff0c\u5c06\u4e2d\u95f4matching\u6b65\u9aa4\u81ea\u52a8\u5316\u4e86 \u6838\u5fc3\u7b97\u6cd5 \u7f51\u7edc\u6b63\u5e38\u524d\u4f20\u7ed9\u51fa\u4e00\u7cfb\u5217\u7684anchor box,\u6bcf\u4e00\u4e2aanchor box\u6709\u5206\u7c7b\u4ee5\u53calocalization\u4fe1\u606f \u5bf9\u6bcf\u4e00\u4e2a\u969c\u788d\u7269\uff0c\u9009\u62e9\u4e0e\u5b83IOU\u6700\u5927\u7684n\u4e2aanchor\uff0c\u5e26\u6709\u4e00\u4e2athreshold\uff0c\u5982\u679c\u4e00\u4e2aanchor\u4e0e\u591a\u4e2a\u7269\u4f53\u5339\u914d\uff0c \u5219\u4f7f\u8fd9\u4e2aanchor\u53ea\u4e0eIOU\u6700\u5927\u90a3\u4e2a\u7269\u4f53\u5339\u914d(\u662f\u5426\u6709\u8fd9\u4e2a\u9650\u5236\u9700\u8981\u770b\u5177\u4f53\u4ee3\u7801\u5b9e\u73b0) \u5bf9\u5f53\u524d\u7684\u5339\u914d\u5206\u914d\u8ba1\u7b97\u4e00\u4e2aLoss \u53cd\u4f20\u8bad\u7ec3 \u57fa\u4e8e\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u7684\u5339\u914dLoss \u5148\u7ed9\u51fa\u6700\u7ec8\u7684\u516c\u5f0f \\mathcal{L}^{\\prime}(\\theta)=-w_{1} \\sum_{i} \\log \\left(\\operatorname{Mean}-\\max \\left(X_{i}\\right)\\right)+w_{2} \\sum_{j} F L_{-}\\left(P\\left\\{a_{j} \\in A_{-}\\right\\}\\left(1-\\mathcal{P}(\\theta)_{j}^{b g}\\right)\\right) \u5176\u4e2d X_{i}=\\left\\{\\mathcal{P}(\\theta)_{i j}^{c l s} \\mathcal{P}(\\theta)_{i j}^{l o c} | a_{j} \\in A_{i}\\right\\} \u4ee3\u8868\u6bcf\u4e00\u4e2a\u7269\u4f53\u5bf9\u5e94\u7684anchor bag\u7684Likelihood \uff0c\u7b2c\u4e8c\u9879\u5219\u4ee3\u8868\u6ca1\u6709\u88ab\u9009\u5165anchor bag\u7684anchor\u4f5c\u4e3abackground\u7684Focal Loss\uff0cFocal Loss\u6e90\u81ea\u4e0e \u8fd9\u7bc7\u6587\u7ae0 ,\u76f4\u89c9\u5c31\u662f\u5bf9\u4e8e\u628a\u63e1\u5df2\u7ecf\u5f88\u5927\u7684\u6b63\u786e\u7684\u70b9\u964d\u4f4e\u6743\u91cd\uff0c \u5bf9\u96be\u5ea6\u8f83\u5927\u7684\u90e8\u5206\u589e\u52a0\u5b83\u4eec\u5728cost\u4e2d\u7684\u6743\u91cd\u3002 \u7b2c\u4e00\u9879\u3001Mean-max\u4ee5\u53ca\u6982\u7387\u5b9a\u4e49 Mean-max\u51fd\u6570\u8868\u8fbe\u5f0f\u4e3a: \\operatorname{Mean}-\\max (X)=\\frac{\\sum_{x_{j} \\in X} \\frac{x_{j}}{1-x_{j}}}{\\sum_{x_{j} \\in X} \\frac{1}{1-x_{j}}} \u5176\u5bf9\u5e94\u7684\u51fd\u6570\u56fe\u50cf\u4e3a \u76f4\u89c9\u6765\u8bf4\uff0c\u5c31\u662f\u5f53likelihood\u51fd\u6570\u503c\u8f83\u5c0f\uff0c\u7f51\u7edc\u521a\u521d\u59cb\u5316\u7684\u65f6\u5019\uff0c\u51fd\u6570\u7ed3\u679c\u8fd1\u4f3c\u4e8e\u5404\u4e2a\u6570\u7684\u5e73\u5747\u503c\uff0c \u5f53\u6709\u90e8\u5206likelihood\u51fd\u6570\u8f83\u5927\uff0c\u7f51\u7edc\u8bad\u7ec3\u6210\u719f\u4e4b\u540e\uff0c\u51fd\u6570\u7ed3\u679c\u8fd1\u4f3c\u4e8e\u5404\u4e2a\u6570\u7684max. \u6839\u636e\u4f5c\u8005\u7684\u8bbe\u8ba1 P(\\theta)^{cls}_{ij} = e^{-L(\\theta)^{cls}_{ij}} , Loc\u540c\u7406\uff0c\u7686\u4e3a\u5bf9\u5e94\u57fa\u7840cost\u51fd\u6570\u503c\u7684\u8d1f\u6307\u6570 Background\u9879\u5b9a\u4e49 P\\left\\{a_{j} \\in A_{-}\\right\\} = 1-\\max _{i} P\\left\\{a_{j} \\rightarrow b_{i}\\right\\} \u6307proposal\u6846 a_j \u4e0d\u4e0e\u6240\u6709\u7269\u4f53\u91cd\u5408\u7684\u6982\u7387 \u5176\u4e2d P\\left\\{a_{j} \\rightarrow b_{i}\\right\\}=\\text { Saturated linear }\\left(I o U_{i j}^{l o c}, t, \\max _{j}\\left(I o U_{i j}^{l o c}\\right)\\right) \\text { Saturated linear }\\left(x, t_{1}, t_{2}\\right)=\\left\\{\\begin{array}{ll}{0,} & {x \\leq t_{1}} \\\\ {\\frac{x-t_{1}}{t_{2}-t_{1}},} & {t_{1}<x<t_{2}} \\\\ {1,} & {x \\geq t_{2}}\\end{array}\\right.","title":"FreeAnchor: Learning to Match Anchors for Visual Object Detection"},{"location":"The Theory/FreeAnchor_Learning_to_Match_Anchors_for_Visual_Object_Detection/#freeanchor-learning-to-match-anchors-for-visual-object-detection","text":"\u8fd9\u7bc7\u8bba\u6587\u6765\u81ea\u4e8eNIPS2019,\u4ecb\u7ecd\u4e86\u65b0\u7684\u65b9\u5f0f\u6765\u5b9e\u73b02D object detection\u4e2d\u7684matching. \u603b\u4f53\u601d\u8def\u6765\u8bf4\uff0c\u4f7f\u7528\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u7684\u6846\u67b6\u5728Object Detection\u7684\u8fc7\u7a0b\u4e2d\uff0c\u91c7\u7528\u4e00\u4e2a\u5355\u4e00\u7684loss\uff0c\u540c\u65f6\u5b8c\u6210proposal\u4e0eobject\u7684\u5339\u914d\u4ee5\u53ca\u56de\u5f52\u8bad\u7ec3\uff0c\u5c06\u4e2d\u95f4matching\u6b65\u9aa4\u81ea\u52a8\u5316\u4e86","title":"FreeAnchor: Learning to Match Anchors for Visual Object Detection"},{"location":"The Theory/FreeAnchor_Learning_to_Match_Anchors_for_Visual_Object_Detection/#_1","text":"\u7f51\u7edc\u6b63\u5e38\u524d\u4f20\u7ed9\u51fa\u4e00\u7cfb\u5217\u7684anchor box,\u6bcf\u4e00\u4e2aanchor box\u6709\u5206\u7c7b\u4ee5\u53calocalization\u4fe1\u606f \u5bf9\u6bcf\u4e00\u4e2a\u969c\u788d\u7269\uff0c\u9009\u62e9\u4e0e\u5b83IOU\u6700\u5927\u7684n\u4e2aanchor\uff0c\u5e26\u6709\u4e00\u4e2athreshold\uff0c\u5982\u679c\u4e00\u4e2aanchor\u4e0e\u591a\u4e2a\u7269\u4f53\u5339\u914d\uff0c \u5219\u4f7f\u8fd9\u4e2aanchor\u53ea\u4e0eIOU\u6700\u5927\u90a3\u4e2a\u7269\u4f53\u5339\u914d(\u662f\u5426\u6709\u8fd9\u4e2a\u9650\u5236\u9700\u8981\u770b\u5177\u4f53\u4ee3\u7801\u5b9e\u73b0) \u5bf9\u5f53\u524d\u7684\u5339\u914d\u5206\u914d\u8ba1\u7b97\u4e00\u4e2aLoss \u53cd\u4f20\u8bad\u7ec3","title":"\u6838\u5fc3\u7b97\u6cd5"},{"location":"The Theory/FreeAnchor_Learning_to_Match_Anchors_for_Visual_Object_Detection/#loss","text":"\u5148\u7ed9\u51fa\u6700\u7ec8\u7684\u516c\u5f0f \\mathcal{L}^{\\prime}(\\theta)=-w_{1} \\sum_{i} \\log \\left(\\operatorname{Mean}-\\max \\left(X_{i}\\right)\\right)+w_{2} \\sum_{j} F L_{-}\\left(P\\left\\{a_{j} \\in A_{-}\\right\\}\\left(1-\\mathcal{P}(\\theta)_{j}^{b g}\\right)\\right) \u5176\u4e2d X_{i}=\\left\\{\\mathcal{P}(\\theta)_{i j}^{c l s} \\mathcal{P}(\\theta)_{i j}^{l o c} | a_{j} \\in A_{i}\\right\\} \u4ee3\u8868\u6bcf\u4e00\u4e2a\u7269\u4f53\u5bf9\u5e94\u7684anchor bag\u7684Likelihood \uff0c\u7b2c\u4e8c\u9879\u5219\u4ee3\u8868\u6ca1\u6709\u88ab\u9009\u5165anchor bag\u7684anchor\u4f5c\u4e3abackground\u7684Focal Loss\uff0cFocal Loss\u6e90\u81ea\u4e0e \u8fd9\u7bc7\u6587\u7ae0 ,\u76f4\u89c9\u5c31\u662f\u5bf9\u4e8e\u628a\u63e1\u5df2\u7ecf\u5f88\u5927\u7684\u6b63\u786e\u7684\u70b9\u964d\u4f4e\u6743\u91cd\uff0c \u5bf9\u96be\u5ea6\u8f83\u5927\u7684\u90e8\u5206\u589e\u52a0\u5b83\u4eec\u5728cost\u4e2d\u7684\u6743\u91cd\u3002","title":"\u57fa\u4e8e\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u7684\u5339\u914dLoss"},{"location":"The Theory/FreeAnchor_Learning_to_Match_Anchors_for_Visual_Object_Detection/#mean-max","text":"Mean-max\u51fd\u6570\u8868\u8fbe\u5f0f\u4e3a: \\operatorname{Mean}-\\max (X)=\\frac{\\sum_{x_{j} \\in X} \\frac{x_{j}}{1-x_{j}}}{\\sum_{x_{j} \\in X} \\frac{1}{1-x_{j}}} \u5176\u5bf9\u5e94\u7684\u51fd\u6570\u56fe\u50cf\u4e3a \u76f4\u89c9\u6765\u8bf4\uff0c\u5c31\u662f\u5f53likelihood\u51fd\u6570\u503c\u8f83\u5c0f\uff0c\u7f51\u7edc\u521a\u521d\u59cb\u5316\u7684\u65f6\u5019\uff0c\u51fd\u6570\u7ed3\u679c\u8fd1\u4f3c\u4e8e\u5404\u4e2a\u6570\u7684\u5e73\u5747\u503c\uff0c \u5f53\u6709\u90e8\u5206likelihood\u51fd\u6570\u8f83\u5927\uff0c\u7f51\u7edc\u8bad\u7ec3\u6210\u719f\u4e4b\u540e\uff0c\u51fd\u6570\u7ed3\u679c\u8fd1\u4f3c\u4e8e\u5404\u4e2a\u6570\u7684max. \u6839\u636e\u4f5c\u8005\u7684\u8bbe\u8ba1 P(\\theta)^{cls}_{ij} = e^{-L(\\theta)^{cls}_{ij}} , Loc\u540c\u7406\uff0c\u7686\u4e3a\u5bf9\u5e94\u57fa\u7840cost\u51fd\u6570\u503c\u7684\u8d1f\u6307\u6570","title":"\u7b2c\u4e00\u9879\u3001Mean-max\u4ee5\u53ca\u6982\u7387\u5b9a\u4e49"},{"location":"The Theory/FreeAnchor_Learning_to_Match_Anchors_for_Visual_Object_Detection/#background","text":"P\\left\\{a_{j} \\in A_{-}\\right\\} = 1-\\max _{i} P\\left\\{a_{j} \\rightarrow b_{i}\\right\\} \u6307proposal\u6846 a_j \u4e0d\u4e0e\u6240\u6709\u7269\u4f53\u91cd\u5408\u7684\u6982\u7387 \u5176\u4e2d P\\left\\{a_{j} \\rightarrow b_{i}\\right\\}=\\text { Saturated linear }\\left(I o U_{i j}^{l o c}, t, \\max _{j}\\left(I o U_{i j}^{l o c}\\right)\\right) \\text { Saturated linear }\\left(x, t_{1}, t_{2}\\right)=\\left\\{\\begin{array}{ll}{0,} & {x \\leq t_{1}} \\\\ {\\frac{x-t_{1}}{t_{2}-t_{1}},} & {t_{1}<x<t_{2}} \\\\ {1,} & {x \\geq t_{2}}\\end{array}\\right.","title":"Background\u9879\u5b9a\u4e49"},{"location":"The Theory/Rethinking ImageNet Pre-training/","text":"Rethinking ImageNet Pre-training \u8fd9\u7bc7\u8bba\u6587\u6765\u81ea\u4f55\u51ef\u660e\u7684\u8bba\u6587\u8ba8\u8bba\u4e86pretraining\u5bf9detection task\u7684\u5f71\u54cd\uff0c\u5206\u6790\u4e86\u6570\u4e2a\u8981\u7d20 \u4e3b\u8981\u7ed3\u8bba pretrained\u52a0\u901f\u6536\u655b imagenet pretrained\u4e0d\u4e00\u5b9a\u63d0\u5347regularization\uff0c\u9664\u975e\u539f\u6765\u6570\u636e\u96c6\u91cf\u771f\u7684\u5f88\u5c0f \u5f53\u8bad\u7ec3\u4efb\u52a1\u5bf9\u4f4d\u7f6e\u4fe1\u606f\u975e\u5e38\u654f\u611f\u65f6\uff0c\u6bd4\u5982key-point\u68c0\u6d4b\uff0cimagenet pretrained\u7528\u5904\u4e0d\u5927 \u5176\u4ed6\u6280\u672f\u7ec6\u8282 Normalization\u5fc5\u4e0d\u53ef\u5c11\uff0c\u4f46\u662f\u7531\u4e8eDetection\u9ad8\u6e05\u56fe\u8981\u6c42\u9ad8\uff0c\u663e\u5b58\u4e0d\u591f\uff0c\u6240\u4ee5\u5982\u679c\u9700\u8981\u4ece\u5934\u5f00\u59cbtrain batch normalization\u4f1a\u56e0\u4e3abatch\u592a\u5c0f\u5f71\u54cd\u6548\u679c\uff0c\u6240\u4ee5\u5c1d\u8bd5GroupNorm\u7b49\u3002 \u5bf9\u4e8e\u6570\u636e\u91cf\u8db3\u591f\u5927\u7684detection task\u6765\u8bf4\uff0cpretrain\u53ef\u4ee5\u4f7f\u7ed3\u679c\u66f4\u5feb\u6536\u655b\uff0c\u4f46\u662frandom-initialization\u8db3\u591f\u957fepoch\u540e\u5f97\u5230\u7684\u7ed3\u679c\u4e00\u822c\u4e0d\u4f1a\u5dee\u4e8epretrain\uff0c\u5f53\u7136\u8981\u6c42\u6709GN \u4f7f\u7528\u521d\u59cb\u5b66\u4e60\u7387(\u8f83\u5927\u7684\u5b66\u4e60\u7387)\uff0c\u8bad\u7ec3\u66f4\u957f\u7684\u65f6\u95f4\u662f\u6709\u7528\u7684\uff0c\u957f\u65f6\u95f4\u4f7f\u7528\u4f4e\u5b66\u4e60\u7387\u63d0\u9ad8\u51c6\u786e\u7387\u7ecf\u5e38\u4f1a\u5bfc\u81f4overfitting","title":"Rethinking ImageNet Pre-training"},{"location":"The Theory/Rethinking ImageNet Pre-training/#rethinking-imagenet-pre-training","text":"\u8fd9\u7bc7\u8bba\u6587\u6765\u81ea\u4f55\u51ef\u660e\u7684\u8bba\u6587\u8ba8\u8bba\u4e86pretraining\u5bf9detection task\u7684\u5f71\u54cd\uff0c\u5206\u6790\u4e86\u6570\u4e2a\u8981\u7d20","title":"Rethinking ImageNet Pre-training"},{"location":"The Theory/Rethinking ImageNet Pre-training/#_1","text":"pretrained\u52a0\u901f\u6536\u655b imagenet pretrained\u4e0d\u4e00\u5b9a\u63d0\u5347regularization\uff0c\u9664\u975e\u539f\u6765\u6570\u636e\u96c6\u91cf\u771f\u7684\u5f88\u5c0f \u5f53\u8bad\u7ec3\u4efb\u52a1\u5bf9\u4f4d\u7f6e\u4fe1\u606f\u975e\u5e38\u654f\u611f\u65f6\uff0c\u6bd4\u5982key-point\u68c0\u6d4b\uff0cimagenet pretrained\u7528\u5904\u4e0d\u5927","title":"\u4e3b\u8981\u7ed3\u8bba"},{"location":"The Theory/Rethinking ImageNet Pre-training/#_2","text":"Normalization\u5fc5\u4e0d\u53ef\u5c11\uff0c\u4f46\u662f\u7531\u4e8eDetection\u9ad8\u6e05\u56fe\u8981\u6c42\u9ad8\uff0c\u663e\u5b58\u4e0d\u591f\uff0c\u6240\u4ee5\u5982\u679c\u9700\u8981\u4ece\u5934\u5f00\u59cbtrain batch normalization\u4f1a\u56e0\u4e3abatch\u592a\u5c0f\u5f71\u54cd\u6548\u679c\uff0c\u6240\u4ee5\u5c1d\u8bd5GroupNorm\u7b49\u3002 \u5bf9\u4e8e\u6570\u636e\u91cf\u8db3\u591f\u5927\u7684detection task\u6765\u8bf4\uff0cpretrain\u53ef\u4ee5\u4f7f\u7ed3\u679c\u66f4\u5feb\u6536\u655b\uff0c\u4f46\u662frandom-initialization\u8db3\u591f\u957fepoch\u540e\u5f97\u5230\u7684\u7ed3\u679c\u4e00\u822c\u4e0d\u4f1a\u5dee\u4e8epretrain\uff0c\u5f53\u7136\u8981\u6c42\u6709GN \u4f7f\u7528\u521d\u59cb\u5b66\u4e60\u7387(\u8f83\u5927\u7684\u5b66\u4e60\u7387)\uff0c\u8bad\u7ec3\u66f4\u957f\u7684\u65f6\u95f4\u662f\u6709\u7528\u7684\uff0c\u957f\u65f6\u95f4\u4f7f\u7528\u4f4e\u5b66\u4e60\u7387\u63d0\u9ad8\u51c6\u786e\u7387\u7ecf\u5e38\u4f1a\u5bfc\u81f4overfitting","title":"\u5176\u4ed6\u6280\u672f\u7ec6\u8282"},{"location":"The Theory/ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design/","text":"ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design \u8fd9\u7bc7\u6587\u7ae0\u4e0d\u4ec5\u5f15\u8fdb\u4e86ShuffleNet V2,\u66f4\u91cd\u8981\u7684\u662f\u63d0\u4f9b\u4e86\u5927\u91cf\u4f18\u5316\u7f51\u7edc\u7ed3\u6784\u3001\u52a0\u901f\u8fd0\u7b97\u3001\u63d0\u5347\u6548\u7387\u7684\u7f51\u7edc\u642d\u5efa\u5efa\u8bae\u3002 \u4e3a\u4ec0\u4e48FLOPs\u6307\u6807\u8fd8\u4e0d\u5145\u5206 FLOPs\u6307\u7684\u662f\u7f51\u7edc\u8fd0\u7b97\u8fc7\u7a0b\u4e2d\u9700\u8981\u6267\u884c\u7684\u4e58\u52a0\u6b65\u9aa4\u6b21\u6570\u3002 \u4f17\u6240\u5468\u77e5\uff0c\u5927\u91cf\u7f51\u7edc\u5982MobileNet,\u91c7\u7528group convolution \u4e0e depth-wise convolution,\u4e0edense convolution\u7f51\u7edc\u76f8\u6bd4\uff0c\u51e0\u4f55\u7ea7\u5730\u964d\u4f4e\u4e86\u6bcf\u4e00\u5c42\u7684FLOPs.\u4f46\u662fFLOPs\u5e76\u4e0d\u662f\u4e00\u4e2a\u5bf9\u8fd0\u7b97\u901f\u5ea6\u4e0e\u8fd0\u7b97\u590d\u6742\u5ea6\u6700\u76f4\u63a5\u7684\u4f30\u91cf\u6307\u6807\uff0c\u5b83\u53ea\u662f\u4e00\u4e2a\u8fd1\u4f3c\u3002\u4e0d\u540c\u7684\u7f51\u7edc\uff0c\u5c3d\u7ba1\u6709\u76f8\u4f3c\u7684FLOPs\uff0c\u5176\u901f\u5ea6\u4e5f\u4f1a\u6709\u5f88\u5927\u4e0d\u540c\u3002 FLOPs\u4e0e\u5b9e\u9645\u5ef6\u8fdf\u4e4b\u95f4\u4e00\u5927\u5dee\u522b\u5728\u4e8e\u6ca1\u6709\u8003\u8651Memory access cost(MAC),\u7b2c\u4e8c\u5927\u533a\u522b\u5728\u4e8e\u5e73\u884c\u8fd0\u7b97\u5ea6(degree of parallelism).\u540c\u65f6\u76f8\u540c\u7684\u8fd0\u7b97\u7ed3\u679c\u4f1a\u56e0\u5e73\u53f0\u800c\u5f02\uff0c \u524d\u6587 \u63d0\u51fa\u7684\u901a\u8fc7matrix decomposition\u964d\u7ef4\u52a0\u901f\uff0c\u7406\u8bba\u4e0a\u6765\u8bf4\u80fd\u6709\u66f4\u4f4e\u7684FLOPs,\u4f46\u662f\u5728GPU\u4e0a\u7684\u6267\u884c\u901f\u5ea6\u5374\u66f4\u6162\uff0c\u539f\u56e0\u662f\u67d0\u4e00\u4e2a\u7248\u672c\u7684CUDNN\u4e3a 3\\times 3 \u5377\u79ef\u7279\u6b8a\u4f18\u5316\u8fc7\u3002 \u56e0\u6b64\u63d0\u51fa\u5efa\u8bae\u5e94\u8be5\u7528\u901f\u5ea6\u800c\u975eFLOPs\u8fdb\u884c\u8ba8\u8bba\uff0c\u5e76\u4e14\u9700\u8981\u8bf4\u660e\u5e73\u53f0\u3002 \u672c\u6587\u7684\u8d21\u732e\u5c31\u662f\u5148\u63d0\u51fa\u4e86\u8bbe\u8ba1\u9ad8\u6548\u7f51\u7edc\u7684\u4e00\u4e9b\u5efa\u8bae\uff0c\u5e76\u63d0\u51fashuffleNet V2 \u5b9e\u7528\u5efa\u8bae \u5efa\u8bae\u4e00,\u4f7f\u7528\u7b49channel\u5bbd\u5ea6\u4ee5\u51cf\u5c11MAC 1 \\times 1 \u5377\u79ef\u7684FLOPs\u4e3a B = hwc_1c_2 ,\u5047\u8bbe\u5185\u5b58\u8db3\u591f\u5927\uff0cMAC\u4e3a MAC=hw(c_1+c_2)+c_1c_2 \u8fdb\u4e00\u6b65\u63a8\u5f97 MAC \\ge 2\\sqrt{hwB} + \\frac{B}{hw} \u56e0\u6b64\u5bf9\u4e8e\u76f8\u7b49\u7684FLOPs\u4ee5\u53ca\u76f8\u540c\u7684feature map\u5927\u5c0f\uff0c\u8f93\u5165\u8f93\u51fachannel\u6570\u4e00\u81f4\u65f6\uff0cMAC\u6700\u5c0f\u3002\u5c3d\u7ba1\u8fd9\u53ea\u662f\u7406\u8bba\u503c\uff0c\u4f46\u662f\u5b9e\u9a8c\u53ef\u4ee5\u8bc1\u660e\u8fd9\u4e00\u70b9(\u672c\u6587\u5bf9\u4e0d\u540c\u7684 1\\times 1 \u5377\u79ef\u7684c1,c2\u914d\u6bd4\u8fdb\u884c\u4e86\u5b9e\u9a8c\u5bf9\u6bd4\uff0c\u8bc1\u660e\u4e86\u8fd9\u70b9)\u3002 \u5efa\u8bae\u4e8c\uff0c\u8fc7\u591a\u7684group convolution\u63d0\u5347\u4e86MAC \u7406\u8bba\u5206\u6790 \\begin{aligned} \\mathrm{MAC} &=h w\\left(c_{1}+c_{2}\\right)+\\frac{c_{1} c_{2}}{g} \\\\ &=h w c_{1}+\\frac{B g}{c_{1}}+\\frac{B}{h w} \\end{aligned} MAC\u4e0e g the number of groups \u6b63\u76f8\u5173\u3002 \u5728\u540c\u7b49FLOPs\u7684\u60c5\u51b5\u4e0b\uff0cgroup number\u8d8a\u5927\u901f\u5ea6\u8d8a\u6162\uff0c\u4f46\u662f\u503c\u5f97\u6ce8\u610f\u7684\u662f\u4e3a\u4e86\u4fdd\u8bc1\u540c\u7b49FLOPs,\u589e\u5927group number\u65f6channel\u6570\u4e5f\u4f1a\u63d0\u5347\u3002\u6548\u679c\u5728GPU\u4e0a\u6bd4\u8f83\u660e\u663e\u3002 \u5efa\u8bae\u4e09\uff0c\u7f51\u7edc\u7684\u788e\u7247\u5316\u964d\u4f4e\u4e86\u5e76\u884c\u5ea6 \u8fd9\u91cc\u6307\u7684\u662f\u4e00\u4e2ablock\u91cc\u9762\u5e76\u884c\u7684\u5377\u79ef\u4e0epooling\u5c42\uff0c\u8fd9\u4e9b\u5e73\u884c\u4f46\u4e0d\u5e76\u884c\u7684\u8fd0\u7b97\u4f1a\u591a\u6b21\u89e6\u53d1GPU\u7684\u542f\u52a8\u4e0e\u540c\u6b65\u3002\u788e\u7247\u5316\u8fd0\u884c\u5728GPU\u4e0a\u5f71\u54cd\u8f83\u5927\uff0c\u5728CPU\u4e0a\u5f71\u54cd\u4e0d\u5927 \u5efa\u8bae\u56db\uff0cReLU,\u5143\u7d20\u95f4\u76f8\u52a0\u7b49element-wise operators\u540c\u6837\u4e0d\u53ef\u5ffd\u7565 \u5220\u9664ResNet\u4e2d\u7684ReLU\u4e0eshortcut\u4f1a\u770b\u5230\u7ea620%\u7684\u52a0\u901f\uff0c\u5c3d\u7ba1\u5b83\u4eec\u5f88\u5fc5\u8981\uff0c\u4f46\u662f\u5374\u662f\u4e8b\u5b9e\u4e0a\u5f71\u54cd\u901f\u5ea6\u7684\u3002 ShuffleNet V2: \u57fa\u672c\u5355\u5143\u7ed3\u6784\u53ca\u5176\u4e0eShuffleNet V1\u7684\u6bd4\u8f83\u5982\u56fe \u76f4\u89c9\uff1a \u7528 1\\times 1 \u5377\u79ef\u66ff\u4ee3Group Convolution+ channel shuffle \u4f7f\u7528Concat + Channel Shuffle\u66ff\u4ee3Add downsampling\u65f6\u4e0d\u4f7f\u7528avg pooling Channel split\u5c31\u662f\u7b80\u5355\u5730torch.split(dim=1) \u8fde\u7eed\u51fa\u73b0\u7684Concat, Channel Shuffle, Channel Split\u53ef\u4ee5\u653e\u5728\u4e00\u8d77\u4f5c\u4e3a\u4e00\u4e2a\u7edf\u4e00\u7684element-wise operation\u3002","title":"ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design"},{"location":"The Theory/ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design/#shufflenet-v2-practical-guidelines-for-efficient-cnn-architecture-design","text":"\u8fd9\u7bc7\u6587\u7ae0\u4e0d\u4ec5\u5f15\u8fdb\u4e86ShuffleNet V2,\u66f4\u91cd\u8981\u7684\u662f\u63d0\u4f9b\u4e86\u5927\u91cf\u4f18\u5316\u7f51\u7edc\u7ed3\u6784\u3001\u52a0\u901f\u8fd0\u7b97\u3001\u63d0\u5347\u6548\u7387\u7684\u7f51\u7edc\u642d\u5efa\u5efa\u8bae\u3002","title":"ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design"},{"location":"The Theory/ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design/#flops","text":"FLOPs\u6307\u7684\u662f\u7f51\u7edc\u8fd0\u7b97\u8fc7\u7a0b\u4e2d\u9700\u8981\u6267\u884c\u7684\u4e58\u52a0\u6b65\u9aa4\u6b21\u6570\u3002 \u4f17\u6240\u5468\u77e5\uff0c\u5927\u91cf\u7f51\u7edc\u5982MobileNet,\u91c7\u7528group convolution \u4e0e depth-wise convolution,\u4e0edense convolution\u7f51\u7edc\u76f8\u6bd4\uff0c\u51e0\u4f55\u7ea7\u5730\u964d\u4f4e\u4e86\u6bcf\u4e00\u5c42\u7684FLOPs.\u4f46\u662fFLOPs\u5e76\u4e0d\u662f\u4e00\u4e2a\u5bf9\u8fd0\u7b97\u901f\u5ea6\u4e0e\u8fd0\u7b97\u590d\u6742\u5ea6\u6700\u76f4\u63a5\u7684\u4f30\u91cf\u6307\u6807\uff0c\u5b83\u53ea\u662f\u4e00\u4e2a\u8fd1\u4f3c\u3002\u4e0d\u540c\u7684\u7f51\u7edc\uff0c\u5c3d\u7ba1\u6709\u76f8\u4f3c\u7684FLOPs\uff0c\u5176\u901f\u5ea6\u4e5f\u4f1a\u6709\u5f88\u5927\u4e0d\u540c\u3002 FLOPs\u4e0e\u5b9e\u9645\u5ef6\u8fdf\u4e4b\u95f4\u4e00\u5927\u5dee\u522b\u5728\u4e8e\u6ca1\u6709\u8003\u8651Memory access cost(MAC),\u7b2c\u4e8c\u5927\u533a\u522b\u5728\u4e8e\u5e73\u884c\u8fd0\u7b97\u5ea6(degree of parallelism).\u540c\u65f6\u76f8\u540c\u7684\u8fd0\u7b97\u7ed3\u679c\u4f1a\u56e0\u5e73\u53f0\u800c\u5f02\uff0c \u524d\u6587 \u63d0\u51fa\u7684\u901a\u8fc7matrix decomposition\u964d\u7ef4\u52a0\u901f\uff0c\u7406\u8bba\u4e0a\u6765\u8bf4\u80fd\u6709\u66f4\u4f4e\u7684FLOPs,\u4f46\u662f\u5728GPU\u4e0a\u7684\u6267\u884c\u901f\u5ea6\u5374\u66f4\u6162\uff0c\u539f\u56e0\u662f\u67d0\u4e00\u4e2a\u7248\u672c\u7684CUDNN\u4e3a 3\\times 3 \u5377\u79ef\u7279\u6b8a\u4f18\u5316\u8fc7\u3002 \u56e0\u6b64\u63d0\u51fa\u5efa\u8bae\u5e94\u8be5\u7528\u901f\u5ea6\u800c\u975eFLOPs\u8fdb\u884c\u8ba8\u8bba\uff0c\u5e76\u4e14\u9700\u8981\u8bf4\u660e\u5e73\u53f0\u3002 \u672c\u6587\u7684\u8d21\u732e\u5c31\u662f\u5148\u63d0\u51fa\u4e86\u8bbe\u8ba1\u9ad8\u6548\u7f51\u7edc\u7684\u4e00\u4e9b\u5efa\u8bae\uff0c\u5e76\u63d0\u51fashuffleNet V2","title":"\u4e3a\u4ec0\u4e48FLOPs\u6307\u6807\u8fd8\u4e0d\u5145\u5206"},{"location":"The Theory/ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design/#_1","text":"","title":"\u5b9e\u7528\u5efa\u8bae"},{"location":"The Theory/ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design/#channelmac","text":"1 \\times 1 \u5377\u79ef\u7684FLOPs\u4e3a B = hwc_1c_2 ,\u5047\u8bbe\u5185\u5b58\u8db3\u591f\u5927\uff0cMAC\u4e3a MAC=hw(c_1+c_2)+c_1c_2 \u8fdb\u4e00\u6b65\u63a8\u5f97 MAC \\ge 2\\sqrt{hwB} + \\frac{B}{hw} \u56e0\u6b64\u5bf9\u4e8e\u76f8\u7b49\u7684FLOPs\u4ee5\u53ca\u76f8\u540c\u7684feature map\u5927\u5c0f\uff0c\u8f93\u5165\u8f93\u51fachannel\u6570\u4e00\u81f4\u65f6\uff0cMAC\u6700\u5c0f\u3002\u5c3d\u7ba1\u8fd9\u53ea\u662f\u7406\u8bba\u503c\uff0c\u4f46\u662f\u5b9e\u9a8c\u53ef\u4ee5\u8bc1\u660e\u8fd9\u4e00\u70b9(\u672c\u6587\u5bf9\u4e0d\u540c\u7684 1\\times 1 \u5377\u79ef\u7684c1,c2\u914d\u6bd4\u8fdb\u884c\u4e86\u5b9e\u9a8c\u5bf9\u6bd4\uff0c\u8bc1\u660e\u4e86\u8fd9\u70b9)\u3002","title":"\u5efa\u8bae\u4e00,\u4f7f\u7528\u7b49channel\u5bbd\u5ea6\u4ee5\u51cf\u5c11MAC"},{"location":"The Theory/ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design/#group-convolutionmac","text":"\u7406\u8bba\u5206\u6790 \\begin{aligned} \\mathrm{MAC} &=h w\\left(c_{1}+c_{2}\\right)+\\frac{c_{1} c_{2}}{g} \\\\ &=h w c_{1}+\\frac{B g}{c_{1}}+\\frac{B}{h w} \\end{aligned} MAC\u4e0e g the number of groups \u6b63\u76f8\u5173\u3002 \u5728\u540c\u7b49FLOPs\u7684\u60c5\u51b5\u4e0b\uff0cgroup number\u8d8a\u5927\u901f\u5ea6\u8d8a\u6162\uff0c\u4f46\u662f\u503c\u5f97\u6ce8\u610f\u7684\u662f\u4e3a\u4e86\u4fdd\u8bc1\u540c\u7b49FLOPs,\u589e\u5927group number\u65f6channel\u6570\u4e5f\u4f1a\u63d0\u5347\u3002\u6548\u679c\u5728GPU\u4e0a\u6bd4\u8f83\u660e\u663e\u3002","title":"\u5efa\u8bae\u4e8c\uff0c\u8fc7\u591a\u7684group convolution\u63d0\u5347\u4e86MAC"},{"location":"The Theory/ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design/#_2","text":"\u8fd9\u91cc\u6307\u7684\u662f\u4e00\u4e2ablock\u91cc\u9762\u5e76\u884c\u7684\u5377\u79ef\u4e0epooling\u5c42\uff0c\u8fd9\u4e9b\u5e73\u884c\u4f46\u4e0d\u5e76\u884c\u7684\u8fd0\u7b97\u4f1a\u591a\u6b21\u89e6\u53d1GPU\u7684\u542f\u52a8\u4e0e\u540c\u6b65\u3002\u788e\u7247\u5316\u8fd0\u884c\u5728GPU\u4e0a\u5f71\u54cd\u8f83\u5927\uff0c\u5728CPU\u4e0a\u5f71\u54cd\u4e0d\u5927","title":"\u5efa\u8bae\u4e09\uff0c\u7f51\u7edc\u7684\u788e\u7247\u5316\u964d\u4f4e\u4e86\u5e76\u884c\u5ea6"},{"location":"The Theory/ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design/#reluelement-wise-operators","text":"\u5220\u9664ResNet\u4e2d\u7684ReLU\u4e0eshortcut\u4f1a\u770b\u5230\u7ea620%\u7684\u52a0\u901f\uff0c\u5c3d\u7ba1\u5b83\u4eec\u5f88\u5fc5\u8981\uff0c\u4f46\u662f\u5374\u662f\u4e8b\u5b9e\u4e0a\u5f71\u54cd\u901f\u5ea6\u7684\u3002","title":"\u5efa\u8bae\u56db\uff0cReLU,\u5143\u7d20\u95f4\u76f8\u52a0\u7b49element-wise operators\u540c\u6837\u4e0d\u53ef\u5ffd\u7565"},{"location":"The Theory/ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design/#shufflenet-v2","text":"\u57fa\u672c\u5355\u5143\u7ed3\u6784\u53ca\u5176\u4e0eShuffleNet V1\u7684\u6bd4\u8f83\u5982\u56fe \u76f4\u89c9\uff1a \u7528 1\\times 1 \u5377\u79ef\u66ff\u4ee3Group Convolution+ channel shuffle \u4f7f\u7528Concat + Channel Shuffle\u66ff\u4ee3Add downsampling\u65f6\u4e0d\u4f7f\u7528avg pooling Channel split\u5c31\u662f\u7b80\u5355\u5730torch.split(dim=1) \u8fde\u7eed\u51fa\u73b0\u7684Concat, Channel Shuffle, Channel Split\u53ef\u4ee5\u653e\u5728\u4e00\u8d77\u4f5c\u4e3a\u4e00\u4e2a\u7edf\u4e00\u7684element-wise operation\u3002","title":"ShuffleNet V2:"},{"location":"The Theory/UNDERSTANDING DEEP LEARNING REQUIRES RETHINKING GENERALIZATION/","text":"Understanding Deep Learning Requires Rethinking Generalization \u8fd9\u7bc7\u6587\u7ae0\u8ba8\u8bba\u7f51\u7edc\u7684generalization\u80fd\u529b\u3002 \u4e00\u4e2a\u7279\u6b8a\u7684\u5b9e\u9a8c\uff1a \u5728\u4e00\u4e2a dataset\u4e2d \uff0c\u5c06 label\u6539\u4e3a\u5b8c\u5168\u968f\u673a\u62bd\u53d6 \uff0c\u5b9e\u9a8c\u8bc1\u660e\uff0c\u76ee\u524d\u7684\u795e\u7ecf\u7f51\u7edc\u80fd\u591f\u5b8c\u5168\u8bb0\u5fc6\u6240\u6709\u7684\u968f\u673a label \uff0c\u4f18\u5316\u96be\u5ea6\u5e76\u6ca1\u6709\u663e\u8457\u63d0\u5347\uff0c\u4f46\u662f\u660e\u786e\u53ef\u4ee5\u77e5\u9053\uff0c generalization\u7684\u7ed3\u679c\u5fc5\u7136\u7b49\u540c\u4e8e\u968f\u673a ( training \u4e0e testing\u5b8c\u5168\u4e0d\u76f8\u5173 ) \u3002 \u6240\u4ee5\u9996\u5148\u53ef\u4ee5\u77e5\u9053\u4f18\u5316\u662f\u5426\u987a\u5229\u4e0e\u80fd\u5426generalize\u6ca1\u6709\u76f4\u63a5\u663e\u8457\u7684\u5173\u7cfb \u5173\u4e8eregularization\u6280\u5de7\uff1a \u6570\u636e\u589e\u5f3a\u3001weight delay( l_2 regularizer)\u3001dropout\uff0c\u7ecf\u9a8c\u4e0a\u90fd\u80fd\u63d0\u5347\u7f51\u7edc\u7684test\u51c6\u786e\u7387\uff0c\u4f46\u662f\u5728fitting random labels\u7684\u65f6\u5019\u90fd\u662f\u80fd\u8fbe\u5230training accuracy = 100%,test accuracy\u4ecd\u7136\u662f10%. BatchNorm\u548cEarlyStop\u90fd\u662f\u6709\u6548\u7684\u3002","title":"Understanding Deep Learning Requires Rethinking Generalization"},{"location":"The Theory/UNDERSTANDING DEEP LEARNING REQUIRES RETHINKING GENERALIZATION/#understanding-deep-learning-requires-rethinking-generalization","text":"\u8fd9\u7bc7\u6587\u7ae0\u8ba8\u8bba\u7f51\u7edc\u7684generalization\u80fd\u529b\u3002 \u4e00\u4e2a\u7279\u6b8a\u7684\u5b9e\u9a8c\uff1a \u5728\u4e00\u4e2a dataset\u4e2d \uff0c\u5c06 label\u6539\u4e3a\u5b8c\u5168\u968f\u673a\u62bd\u53d6 \uff0c\u5b9e\u9a8c\u8bc1\u660e\uff0c\u76ee\u524d\u7684\u795e\u7ecf\u7f51\u7edc\u80fd\u591f\u5b8c\u5168\u8bb0\u5fc6\u6240\u6709\u7684\u968f\u673a label \uff0c\u4f18\u5316\u96be\u5ea6\u5e76\u6ca1\u6709\u663e\u8457\u63d0\u5347\uff0c\u4f46\u662f\u660e\u786e\u53ef\u4ee5\u77e5\u9053\uff0c generalization\u7684\u7ed3\u679c\u5fc5\u7136\u7b49\u540c\u4e8e\u968f\u673a ( training \u4e0e testing\u5b8c\u5168\u4e0d\u76f8\u5173 ) \u3002 \u6240\u4ee5\u9996\u5148\u53ef\u4ee5\u77e5\u9053\u4f18\u5316\u662f\u5426\u987a\u5229\u4e0e\u80fd\u5426generalize\u6ca1\u6709\u76f4\u63a5\u663e\u8457\u7684\u5173\u7cfb \u5173\u4e8eregularization\u6280\u5de7\uff1a \u6570\u636e\u589e\u5f3a\u3001weight delay( l_2 regularizer)\u3001dropout\uff0c\u7ecf\u9a8c\u4e0a\u90fd\u80fd\u63d0\u5347\u7f51\u7edc\u7684test\u51c6\u786e\u7387\uff0c\u4f46\u662f\u5728fitting random labels\u7684\u65f6\u5019\u90fd\u662f\u80fd\u8fbe\u5230training accuracy = 100%,test accuracy\u4ecd\u7136\u662f10%. BatchNorm\u548cEarlyStop\u90fd\u662f\u6709\u6548\u7684\u3002","title":"Understanding Deep Learning Requires Rethinking Generalization"},{"location":"papers/4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks/","text":"4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks \u8fd9\u7bc7\u8bba\u6587\u4f7f\u7528\u7a00\u758f\u77e2\u91cf\u3001\u5e7f\u4e49\u7a00\u758f\u5377\u79ef\uff0c\u62d3\u5c55\u4e863D\u30014D\u5377\u79ef\uff0c\u52a0\u901f\u4e86\u7a00\u758f\u7684\u70b9\u4e91\u7684\u9ad8\u7ef4\u5377\u79ef\u3002 \u76ee\u524d\u6ca1\u770b\u61c2\u539f\u7406\uff0c\u800c\u4e14\u6709\u5927\u91cf\u57fa\u4e8eGPU cuda\u7684\u5de5\u7a0b\u5de5\u4f5c\u3002","title":"4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks"},{"location":"papers/4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks/#4d-spatio-temporal-convnets-minkowski-convolutional-neural-networks","text":"\u8fd9\u7bc7\u8bba\u6587\u4f7f\u7528\u7a00\u758f\u77e2\u91cf\u3001\u5e7f\u4e49\u7a00\u758f\u5377\u79ef\uff0c\u62d3\u5c55\u4e863D\u30014D\u5377\u79ef\uff0c\u52a0\u901f\u4e86\u7a00\u758f\u7684\u70b9\u4e91\u7684\u9ad8\u7ef4\u5377\u79ef\u3002 \u76ee\u524d\u6ca1\u770b\u61c2\u539f\u7406\uff0c\u800c\u4e14\u6709\u5927\u91cf\u57fa\u4e8eGPU cuda\u7684\u5de5\u7a0b\u5de5\u4f5c\u3002","title":"4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks"},{"location":"papers/Actor-Critic Instance Segmentation/","text":"Actor-Critic Instance Segmentation \u8fd9\u7bc7\u8bba\u6587\u4f7f\u7528actor critic \u5f3a\u5316\u5b66\u4e60\uff0c\u4fbf\u4e8e\u9884\u6d4b\u4e00\u7cfb\u5217\u7684segmentation result \u6574\u4f53\u7ed3\u6784 \u5f3a\u5316\u5b66\u4e60\u5b9a\u4e49 \u72b6\u6001\u7a7a\u95f4 s_t = (I, M_t) \u5176\u4e2d I \u4e3a\u8f93\u5165\u56fe\u7247\uff0c M_t \u4e3a\u7b2c t \u65f6\u523b\u7684\u7efc\u5408mask \u884c\u52a8 a_t \u662fdecoder\u7684\u8f93\u5165\uff0c\u662f\u4e00\u4e2a\u8f83\u4e3a\u4f4e\u7ef4\u7684\u8fde\u7eed\u77e2\u91cf \u72b6\u6001\u8f6c\u79fb T = (I, max(M_t, D(a_t))) \uff0c\u76f8\u5f53\u4e8e\u5c06\u65b0decode\u7684mask\u52a0\u548c\u5728\u539f\u6765\u7684\u7d2f\u52a0mask\u4e0a reward\uff0c\u5148\u5b9a\u4e49 \\phi_t = max(\\sum_{i=1}^t F(S_i, T_{ki})) \u610f\u601d\u662f\u5bfb\u627e\u6700\u4f18\u7684predicted instance-ground truth\u642d\u914d\uff0c\u5f97\u5230\u7684\u6700\u5927\u5956\u52b1\uff0c\u7136\u540ereward\u5c31\u662f r_t = \\phi(s_{t+1}) - \\phi(s_t) \u4f7f\u7528\u91cd\u70b9\uff1a 1. decoder\u9700\u8981\u63d0\u524dtrain\u597d\uff0c\u6700\u597d\u4e0d\u8981\u6539\u53d8,\u9700\u8981\u7684\u662f\u4e00\u4e2aconditional variational encoder(cVAE) 2. \u9700\u8981\u5141\u8bb8critics warm-up AC training","title":"Actor-Critic Instance Segmentation"},{"location":"papers/Actor-Critic Instance Segmentation/#actor-critic-instance-segmentation","text":"\u8fd9\u7bc7\u8bba\u6587\u4f7f\u7528actor critic \u5f3a\u5316\u5b66\u4e60\uff0c\u4fbf\u4e8e\u9884\u6d4b\u4e00\u7cfb\u5217\u7684segmentation result","title":"Actor-Critic Instance Segmentation"},{"location":"papers/Actor-Critic Instance Segmentation/#_1","text":"","title":"\u6574\u4f53\u7ed3\u6784"},{"location":"papers/Actor-Critic Instance Segmentation/#_2","text":"\u72b6\u6001\u7a7a\u95f4 s_t = (I, M_t) \u5176\u4e2d I \u4e3a\u8f93\u5165\u56fe\u7247\uff0c M_t \u4e3a\u7b2c t \u65f6\u523b\u7684\u7efc\u5408mask \u884c\u52a8 a_t \u662fdecoder\u7684\u8f93\u5165\uff0c\u662f\u4e00\u4e2a\u8f83\u4e3a\u4f4e\u7ef4\u7684\u8fde\u7eed\u77e2\u91cf \u72b6\u6001\u8f6c\u79fb T = (I, max(M_t, D(a_t))) \uff0c\u76f8\u5f53\u4e8e\u5c06\u65b0decode\u7684mask\u52a0\u548c\u5728\u539f\u6765\u7684\u7d2f\u52a0mask\u4e0a reward\uff0c\u5148\u5b9a\u4e49 \\phi_t = max(\\sum_{i=1}^t F(S_i, T_{ki})) \u610f\u601d\u662f\u5bfb\u627e\u6700\u4f18\u7684predicted instance-ground truth\u642d\u914d\uff0c\u5f97\u5230\u7684\u6700\u5927\u5956\u52b1\uff0c\u7136\u540ereward\u5c31\u662f r_t = \\phi(s_{t+1}) - \\phi(s_t) \u4f7f\u7528\u91cd\u70b9\uff1a 1. decoder\u9700\u8981\u63d0\u524dtrain\u597d\uff0c\u6700\u597d\u4e0d\u8981\u6539\u53d8,\u9700\u8981\u7684\u662f\u4e00\u4e2aconditional variational encoder(cVAE) 2. \u9700\u8981\u5141\u8bb8critics warm-up AC training","title":"\u5f3a\u5316\u5b66\u4e60\u5b9a\u4e49"},{"location":"papers/Associative_Embedding:End-to-End_Learning_for_Joint_Detection_and_Grouping/","text":"Associative Embedding: End-to-End Learning for Joint Detection and Grouping \u8fd9\u7bc7\u8bba\u6587\u5bf9\u6211\u6765\u8bf4\u662f CornerNet \u7684\u524d\u7f6e.\u4e24\u7bc7\u4e5f\u662f\u540c\u4e00\u4e2a\u4f5c\u8005\u3002 Associative Embedding \u7b80\u4ecb \u8fd9\u7bc7\u8bba\u6587\u4f7f\u75281D embedding\uff0c\u76ee\u7684\u662f\u8bad\u7ec3\u7f51\u7edc\u5bf9\u6765\u81ea\u540c\u4e00\u4e2agroup\u7684detection\u8f93\u51fa\u76f8\u4f3c\u7684tags\uff0cdifferent tags for detection\u3002 Stacked Hourglass Architecture hourglass\u7ed3\u6784\u53ef\u4ee5\u5728 \u8fd9\u7bc7\u8bba\u6587 \u770b\u5230\u4e5f\u5728 CornerNet \u8fd9\u7bc7\u8bba\u6587\u7528\u8fc7\uff0c\u5927\u5bb6\u7a0d\u6709\u4e0d\u540c\uff0c\u4e0d\u8fc7\u603b\u4f53\u601d\u8def\u4e00\u81f4\u3002 \u591a\u4eba\u80a2\u4f53\u4f30\u8ba1 \u672c\u6587\u4f7f\u7528\u524d\u9762\u7684backbone\u9884\u6d4b\u6bcf\u4e00\u4e2apixel\u7684detection score for each joint(\"left writst\", \"right shoulder\")\uff0c \u8981\u8fdb\u4e00\u6b65\u5b8c\u6210\u6574\u4e2akeypoint detections\u3002\u5982\u679c\u6709 m \u4e2a\u5173\u8282,\u5219\u8f93\u51fa 2m \u4e2achannel,\u5176\u4e2d m \u4e2a\u4f5c\u4e3adetection\u7684heatmap, m \u4e2a\u4f5c\u4e3agrouping\u7684 tags\u3002 \u6574\u4e2acost: \\begin{aligned} L_{g}(h, T)=& \\frac{1}{N} \\sum_{n} \\sum_{k}\\left(\\bar{h}_{n}-h_{k}\\left(x_{n k},\\right)\\right)^{2} \\\\ &+\\frac{1}{N^{2}} \\sum_{n} \\sum_{n^{\\prime}} \\exp \\left\\{-\\frac{1}{2 \\sigma^{2}}\\left(\\bar{h}_{n}-\\bar{h}_{n^{\\prime}}\\right)^{2}\\right\\} \\end{aligned} \u5176\u4e2d h(x) \u662fpixel x \u5bf9\u5e94\u7684tag value\u3002 T = {(x_{nk})} ,\u5176\u4e2d x_{nk} \u662f\u7b2c n \u4e2a\u4eba\u7684\u7b2c k \u4e2a\u8eab\u4f53\u5173\u8282\u7684pixel\u4f4d\u7f6e. \\bar{h}_{n}=\\frac{1}{K} \\sum_{k} h_{k}\\left(x_{n k}\\right) inference\u65f6\u7684\u6d41\u7a0b \u9996\u5148\u5bf9\u7b2c\u4e00\u4e2a\u5173\u8282\uff0c\u7ed9\u4e00\u4e2a\u9608\u503c\uff0c\u7136\u540e\u505anon-max suppression.\u5f97\u5230\u5404\u4e2a\u4eba\u7269\u7684\u521d\u59cb\u4f30\u8ba1\u3002 \u4e4b\u540e\u5bf9\u5176\u4ed6\u6bcf\u4e00\u4e2a\u5173\u8282\uff0c\u505a\u4e00\u4e2amaximum matching\uff0c\u540c\u65f6\u57fa\u4e8etag value\u4ee5\u53cadetection score\u3002","title":"Associative Embedding: End-to-End Learning for Joint Detection and Grouping"},{"location":"papers/Associative_Embedding:End-to-End_Learning_for_Joint_Detection_and_Grouping/#associative-embedding-end-to-end-learning-for-joint-detection-and-grouping","text":"\u8fd9\u7bc7\u8bba\u6587\u5bf9\u6211\u6765\u8bf4\u662f CornerNet \u7684\u524d\u7f6e.\u4e24\u7bc7\u4e5f\u662f\u540c\u4e00\u4e2a\u4f5c\u8005\u3002","title":"Associative Embedding: End-to-End Learning for Joint Detection and Grouping"},{"location":"papers/Associative_Embedding:End-to-End_Learning_for_Joint_Detection_and_Grouping/#associative-embedding","text":"\u8fd9\u7bc7\u8bba\u6587\u4f7f\u75281D embedding\uff0c\u76ee\u7684\u662f\u8bad\u7ec3\u7f51\u7edc\u5bf9\u6765\u81ea\u540c\u4e00\u4e2agroup\u7684detection\u8f93\u51fa\u76f8\u4f3c\u7684tags\uff0cdifferent tags for detection\u3002","title":"Associative Embedding \u7b80\u4ecb"},{"location":"papers/Associative_Embedding:End-to-End_Learning_for_Joint_Detection_and_Grouping/#stacked-hourglass-architecture","text":"hourglass\u7ed3\u6784\u53ef\u4ee5\u5728 \u8fd9\u7bc7\u8bba\u6587 \u770b\u5230\u4e5f\u5728 CornerNet \u8fd9\u7bc7\u8bba\u6587\u7528\u8fc7\uff0c\u5927\u5bb6\u7a0d\u6709\u4e0d\u540c\uff0c\u4e0d\u8fc7\u603b\u4f53\u601d\u8def\u4e00\u81f4\u3002","title":"Stacked Hourglass Architecture"},{"location":"papers/Associative_Embedding:End-to-End_Learning_for_Joint_Detection_and_Grouping/#_1","text":"\u672c\u6587\u4f7f\u7528\u524d\u9762\u7684backbone\u9884\u6d4b\u6bcf\u4e00\u4e2apixel\u7684detection score for each joint(\"left writst\", \"right shoulder\")\uff0c \u8981\u8fdb\u4e00\u6b65\u5b8c\u6210\u6574\u4e2akeypoint detections\u3002\u5982\u679c\u6709 m \u4e2a\u5173\u8282,\u5219\u8f93\u51fa 2m \u4e2achannel,\u5176\u4e2d m \u4e2a\u4f5c\u4e3adetection\u7684heatmap, m \u4e2a\u4f5c\u4e3agrouping\u7684 tags\u3002 \u6574\u4e2acost: \\begin{aligned} L_{g}(h, T)=& \\frac{1}{N} \\sum_{n} \\sum_{k}\\left(\\bar{h}_{n}-h_{k}\\left(x_{n k},\\right)\\right)^{2} \\\\ &+\\frac{1}{N^{2}} \\sum_{n} \\sum_{n^{\\prime}} \\exp \\left\\{-\\frac{1}{2 \\sigma^{2}}\\left(\\bar{h}_{n}-\\bar{h}_{n^{\\prime}}\\right)^{2}\\right\\} \\end{aligned} \u5176\u4e2d h(x) \u662fpixel x \u5bf9\u5e94\u7684tag value\u3002 T = {(x_{nk})} ,\u5176\u4e2d x_{nk} \u662f\u7b2c n \u4e2a\u4eba\u7684\u7b2c k \u4e2a\u8eab\u4f53\u5173\u8282\u7684pixel\u4f4d\u7f6e. \\bar{h}_{n}=\\frac{1}{K} \\sum_{k} h_{k}\\left(x_{n k}\\right) inference\u65f6\u7684\u6d41\u7a0b \u9996\u5148\u5bf9\u7b2c\u4e00\u4e2a\u5173\u8282\uff0c\u7ed9\u4e00\u4e2a\u9608\u503c\uff0c\u7136\u540e\u505anon-max suppression.\u5f97\u5230\u5404\u4e2a\u4eba\u7269\u7684\u521d\u59cb\u4f30\u8ba1\u3002 \u4e4b\u540e\u5bf9\u5176\u4ed6\u6bcf\u4e00\u4e2a\u5173\u8282\uff0c\u505a\u4e00\u4e2amaximum matching\uff0c\u540c\u65f6\u57fa\u4e8etag value\u4ee5\u53cadetection score\u3002","title":"\u591a\u4eba\u80a2\u4f53\u4f30\u8ba1"},{"location":"papers/CONVOLUTIONAL CRFS  FOR SEMANTIC SEGMENTATION/","text":"Convolutional CRFs for Semantic Segmentation \u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u5377\u79ef\u7248\u7684Conditional Random Field(CRF)\u7528\u4e8e\u4f18\u5316\u8bed\u4e49\u5206\u5272\u7684\u7ed3\u679c\u3002\u9996\u5148\u56de\u987e(\u5bf9\u5199review\u7684\u6211\u6b64\u65f6\u662f\u65b0\u5b66\u7684) FullCRF\u7684\u7b97\u6cd5\uff0c\u7136\u540e\u63d0\u51fa\u4e86ConvCRF\u7684\u7b97\u6cd5\u4ee5\u53caimplementation, \u4f5c\u8005\u4ee3\u7801\u5df2\u5f00\u6e90 FullCRF CRF\u7684\u539f\u610f\u5728\u4e8e\u8ba9\u7279\u5f81\u76f8\u4f3c\u7684\u70b9\u8f93\u51fa\u76f8\u4f3c\u7684\u503c\uff0c\u6700\u540e\u8f6c\u6362\u4e3a\u4f18\u5316\u4e00\u4e0b\u8fd9\u4e2a\u6761\u4ef6\u6982\u7387: E(\\hat{x} | I)=\\sum_{i \\leq N} \\psi_{u}\\left(\\hat{x}_{i} | I\\right)+\\sum_{i \\neq j \\leq N} \\psi_{p}\\left(\\hat{x}_{i}, \\hat{x}_{j} | I\\right) \u7b2c\u4e00\u9879\u4e3a\u57fa\u7840\u5168\u8bed\u4e49\u5206\u5272\u7f51\u7edc\u8f93\u51fa\u7684\u503c\uff0c\u7b2c\u4e8c\u9879\u4f53\u73b0\u56fe\u7247\u4e2d\u4e0d\u540c\u4f4d\u7f6e\u7684\u76f8\u4e92\u5f71\u54cd\u3002FullCRF\u4e2d\uff0c\u7b2c\u4e8c\u9879\u8ba1\u7b97\u516c\u5f0f\u4e3a \\psi_{p}\\left(x_{i}, x_{j} | I\\right) :=\\mu\\left(x_{i}, x_{j}\\right) \\sum_{m=1}^{M} w^{(m)} k_{G}^{(m)}\\left(f_{i}^{I}, f_{j}^{I}\\right) \u5176\u4e2d \\mu(x_i,x_j) = |x_i \\neq x_j| \u4e5f\u5c31\u662f\u56fe\u4e2d\u6bcf\u4e00\u4e2a\u70b9(\u9664\u4e86\u70b9i\u4e4b\u5916).\u5e38\u7528\u7684\u6838\u51fd\u6570 k \u6709\u5982\u4ee5\u4e0b\u7684\u9ad8\u65af\u51fd\u6570 k\\left(f_{i}^{I}, f_{j}^{I}\\right) :=w^{(1)} \\exp \\left(-\\frac{\\left|p_{i}-p_{j}\\right|^{2}}{2 \\theta_{\\alpha}^{2}}-\\frac{\\left|I_{i}-I_{j}\\right|^{2}}{2 \\theta_{\\beta}^{2}}\\right)+w^{(2)} \\exp \\left(-\\frac{\\left|p_{i}-p_{j}\\right|^{2}}{2 \\theta_{\\gamma}^{2}}\\right) \u5176\u4e2d w^{(1)},\\theta \u7b49\u662f\u4ec5\u6709\u7684\u53ef\u5b66\u4e60\u53c2\u6570\uff0c\u76f4\u89c9\u800c\u8a00\uff0c\u5c31\u662f\u7279\u5f81\u76f8\u4f3c\u8005\u76f8\u4e92\u5f71\u54cd\u5927\uff0c\u8ddd\u79bb\u8fd1\u8005\u76f8\u4e92\u5f71\u54cd\u5927\u3002 \u6700\u7ec8\u5b9e\u73b0\u7684\u8fed\u4ee3\u7b97\u6cd5: ConvCRF ConvCRF\u5148\u5047\u8bbe\u4e24\u4e2a\u66fc\u54c8\u987f\u8ddd\u79bb\u5927\u4e8e\u4e00\u5b9a\u9608\u503c k \u7684\u70b9\u76f8\u4e92\u72ec\u7acb\uff0c\u8fd9\u4e2a k \u79f0\u4e3aConvCRF\u7684filter size.\u8fd9\u4e5f\u5c31\u662fConvCRF\u5bf9\u524d\u6587 \\mu(x_i,x_j) \u7684\u9884\u8bbe\u65b9\u5f0f \u5bf9\u4e8e\u4f4d\u4e8e x,y \u7684\u70b9\u5b83\u5bf9\u5e94\u7684\u5377\u79ef\u6838/CRF\u6838\u4e3a k_{g}[b, d x, d y, x, y] :=\\exp \\left(-\\sum_{i=1}^{d} \\frac{\\left|f_{i}^{(d)}[b, x, y]-f_{i}^{(d)}[b, x-d x, y-d y]\\right|^{2}}{2 \\dot{\\theta}_{i}^{2}}\\right) \u5176\u4e2d \\theta_i \u4e3a\u53ef\u5b66\u4e60\u7684\u53d8\u91cf f_i \u4e3a\u7279\u5f81\u5411\u91cf,\u5377\u79ef\u8303\u56f4\u5185\u7684\u6bcf\u4e00\u4e2apair\u6709\u4e00\u4e2a\u5bf9\u5e94\u7684, K=\\sum^s_{i=1}w_i g_i \u7ed3\u679cQ,combined message\u5219\u7531\u6b64\u5f0f\u5b50\u7ed9\u51fa Q[b, c, x, y]=\\sum_{d x, d y \\leq k} K[b, d x, d y, x, y] \\cdot P[b, c, x+d x, y+d y] \u4f5c\u8005\u63d0\u5230\uff0c\u8fd9\u4e2a\u8fd0\u7b97\u64cd\u4f5c\u53ef\u4ee5\u8bf4\u7c7b\u4f3c\u4e8elocally connected layers(every pixel has its own filter),\u533a\u522b\u5728\u4e8e\u6bcf\u4e00\u4e2akernel\u5728channel\u65b9\u5411\u4e0a\u662f\u4e00\u4e2a\u5e38\u6570(\u53ea\u8d1f\u8d23\u52a0\u6743\u6c42\u548c\u6574\u4e2afeature vector\u800c\u4e0d\u9700\u8981\u91cd\u6574feature)\u3002 (\u9898\u5916\u8bdd\uff0clocally connected layer\u76ee\u524d\u6709keras implementation\u4f46\u662f\u8fd8\u6ca1\u6709officail pytorch implementation\uff0c \u53c2\u8003 )","title":"Convolutional CRFs for Semantic Segmentation"},{"location":"papers/CONVOLUTIONAL CRFS  FOR SEMANTIC SEGMENTATION/#convolutional-crfs-for-semantic-segmentation","text":"\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u5377\u79ef\u7248\u7684Conditional Random Field(CRF)\u7528\u4e8e\u4f18\u5316\u8bed\u4e49\u5206\u5272\u7684\u7ed3\u679c\u3002\u9996\u5148\u56de\u987e(\u5bf9\u5199review\u7684\u6211\u6b64\u65f6\u662f\u65b0\u5b66\u7684) FullCRF\u7684\u7b97\u6cd5\uff0c\u7136\u540e\u63d0\u51fa\u4e86ConvCRF\u7684\u7b97\u6cd5\u4ee5\u53caimplementation, \u4f5c\u8005\u4ee3\u7801\u5df2\u5f00\u6e90","title":"Convolutional CRFs for Semantic Segmentation"},{"location":"papers/CONVOLUTIONAL CRFS  FOR SEMANTIC SEGMENTATION/#fullcrf","text":"CRF\u7684\u539f\u610f\u5728\u4e8e\u8ba9\u7279\u5f81\u76f8\u4f3c\u7684\u70b9\u8f93\u51fa\u76f8\u4f3c\u7684\u503c\uff0c\u6700\u540e\u8f6c\u6362\u4e3a\u4f18\u5316\u4e00\u4e0b\u8fd9\u4e2a\u6761\u4ef6\u6982\u7387: E(\\hat{x} | I)=\\sum_{i \\leq N} \\psi_{u}\\left(\\hat{x}_{i} | I\\right)+\\sum_{i \\neq j \\leq N} \\psi_{p}\\left(\\hat{x}_{i}, \\hat{x}_{j} | I\\right) \u7b2c\u4e00\u9879\u4e3a\u57fa\u7840\u5168\u8bed\u4e49\u5206\u5272\u7f51\u7edc\u8f93\u51fa\u7684\u503c\uff0c\u7b2c\u4e8c\u9879\u4f53\u73b0\u56fe\u7247\u4e2d\u4e0d\u540c\u4f4d\u7f6e\u7684\u76f8\u4e92\u5f71\u54cd\u3002FullCRF\u4e2d\uff0c\u7b2c\u4e8c\u9879\u8ba1\u7b97\u516c\u5f0f\u4e3a \\psi_{p}\\left(x_{i}, x_{j} | I\\right) :=\\mu\\left(x_{i}, x_{j}\\right) \\sum_{m=1}^{M} w^{(m)} k_{G}^{(m)}\\left(f_{i}^{I}, f_{j}^{I}\\right) \u5176\u4e2d \\mu(x_i,x_j) = |x_i \\neq x_j| \u4e5f\u5c31\u662f\u56fe\u4e2d\u6bcf\u4e00\u4e2a\u70b9(\u9664\u4e86\u70b9i\u4e4b\u5916).\u5e38\u7528\u7684\u6838\u51fd\u6570 k \u6709\u5982\u4ee5\u4e0b\u7684\u9ad8\u65af\u51fd\u6570 k\\left(f_{i}^{I}, f_{j}^{I}\\right) :=w^{(1)} \\exp \\left(-\\frac{\\left|p_{i}-p_{j}\\right|^{2}}{2 \\theta_{\\alpha}^{2}}-\\frac{\\left|I_{i}-I_{j}\\right|^{2}}{2 \\theta_{\\beta}^{2}}\\right)+w^{(2)} \\exp \\left(-\\frac{\\left|p_{i}-p_{j}\\right|^{2}}{2 \\theta_{\\gamma}^{2}}\\right) \u5176\u4e2d w^{(1)},\\theta \u7b49\u662f\u4ec5\u6709\u7684\u53ef\u5b66\u4e60\u53c2\u6570\uff0c\u76f4\u89c9\u800c\u8a00\uff0c\u5c31\u662f\u7279\u5f81\u76f8\u4f3c\u8005\u76f8\u4e92\u5f71\u54cd\u5927\uff0c\u8ddd\u79bb\u8fd1\u8005\u76f8\u4e92\u5f71\u54cd\u5927\u3002 \u6700\u7ec8\u5b9e\u73b0\u7684\u8fed\u4ee3\u7b97\u6cd5:","title":"FullCRF"},{"location":"papers/CONVOLUTIONAL CRFS  FOR SEMANTIC SEGMENTATION/#convcrf","text":"ConvCRF\u5148\u5047\u8bbe\u4e24\u4e2a\u66fc\u54c8\u987f\u8ddd\u79bb\u5927\u4e8e\u4e00\u5b9a\u9608\u503c k \u7684\u70b9\u76f8\u4e92\u72ec\u7acb\uff0c\u8fd9\u4e2a k \u79f0\u4e3aConvCRF\u7684filter size.\u8fd9\u4e5f\u5c31\u662fConvCRF\u5bf9\u524d\u6587 \\mu(x_i,x_j) \u7684\u9884\u8bbe\u65b9\u5f0f \u5bf9\u4e8e\u4f4d\u4e8e x,y \u7684\u70b9\u5b83\u5bf9\u5e94\u7684\u5377\u79ef\u6838/CRF\u6838\u4e3a k_{g}[b, d x, d y, x, y] :=\\exp \\left(-\\sum_{i=1}^{d} \\frac{\\left|f_{i}^{(d)}[b, x, y]-f_{i}^{(d)}[b, x-d x, y-d y]\\right|^{2}}{2 \\dot{\\theta}_{i}^{2}}\\right) \u5176\u4e2d \\theta_i \u4e3a\u53ef\u5b66\u4e60\u7684\u53d8\u91cf f_i \u4e3a\u7279\u5f81\u5411\u91cf,\u5377\u79ef\u8303\u56f4\u5185\u7684\u6bcf\u4e00\u4e2apair\u6709\u4e00\u4e2a\u5bf9\u5e94\u7684, K=\\sum^s_{i=1}w_i g_i \u7ed3\u679cQ,combined message\u5219\u7531\u6b64\u5f0f\u5b50\u7ed9\u51fa Q[b, c, x, y]=\\sum_{d x, d y \\leq k} K[b, d x, d y, x, y] \\cdot P[b, c, x+d x, y+d y] \u4f5c\u8005\u63d0\u5230\uff0c\u8fd9\u4e2a\u8fd0\u7b97\u64cd\u4f5c\u53ef\u4ee5\u8bf4\u7c7b\u4f3c\u4e8elocally connected layers(every pixel has its own filter),\u533a\u522b\u5728\u4e8e\u6bcf\u4e00\u4e2akernel\u5728channel\u65b9\u5411\u4e0a\u662f\u4e00\u4e2a\u5e38\u6570(\u53ea\u8d1f\u8d23\u52a0\u6743\u6c42\u548c\u6574\u4e2afeature vector\u800c\u4e0d\u9700\u8981\u91cd\u6574feature)\u3002 (\u9898\u5916\u8bdd\uff0clocally connected layer\u76ee\u524d\u6709keras implementation\u4f46\u662f\u8fd8\u6ca1\u6709officail pytorch implementation\uff0c \u53c2\u8003 )","title":"ConvCRF"},{"location":"papers/CenterNet:_Keypoint_Triplets_for_Object_Detection/","text":"CenterNet: Keypoint Triplets for Object Detection CenterNet\u4e5f\u5c31\u662f\u901a\u8fc7\u8f93\u51fa\u6bcf\u4e00\u4e2aobject\u4e3a\u5de6\u4e0a\u89d2\u3001\u53f3\u4e0a\u89d2\u4e0e\u4e2d\u5fc3\u70b9\u7684\u4e00\u4e2atriplet,\u8fd9\u4e2a\u601d\u8def\u6e90\u81ea\u4e8e CornerNet \u3002 \u603b\u4f53\u7ed3\u6784\u4e0epipeline \u4e0eCornerNet\u76f8\u4f3c\u7684\uff0cbackbone\u7684\u9009\u62e9\u4e5f\u662f stacked hourglass \u7b2c\u4e00\u5206\u652f\u7ecf\u8fc7\u65b0\u7684Cascade Corner Pooling(\u65b0\u7684\u64cd\u4f5c)\u5f97\u5230Corner Heatmaps\u5e76\u901a\u8fc7 associative embedding \u5f97\u5230\u521d\u59cb2D\u6846\u3002 \u7b2c\u4e8c\u5206\u652f\u7ecf\u8fc7Center Pooling\u5f97\u5230Center Heatmap\u3002 \u6700\u540e\u62fc\u5728\u4e00\u8d77\u5f97\u5230\u8f93\u51fa\u3002 \u878d\u5408\u68c0\u6d4bkeypoints \u7b97\u6cd5 1. \u9009\u62e9top-k\u4e2a\u4e2d\u5fc3keypoints 2. \u4f7f\u7528\u5bf9\u5e94offset\u6295\u5f71\u5230\u8f93\u5165\u56fe\u7247\u4e2d 3. \u5bf9\u6bcf\u4e00\u4e2acorner heatmap\u8f93\u51fa\u76842D box\uff0c\u67e5\u627e\u6709\u4e2d\u5fc3\u70b9\u662f\u5426\u5728\u4e2d\u5fc3\u533a\u57df 4. \u5982\u679c\u6709\u4e2d\u5fc3\u70b9\u5728\u4e2d\u5fc3\u533a\u57df\uff0c\u4fdd\u7559\u8fd9\u4e2a\u6846 \u5bf9\u4e2d\u5fc3\u533a\u57df\u7684\u5b9a\u4e49\uff1a \u6ee1\u8db3: \\left\\{\\begin{array}{l}{\\operatorname{ct} 1_{x}=\\frac{(n+1) \\operatorname{tl}_{x}+(n-1) \\operatorname{br}_{x}}{2 n}} \\\\ {\\operatorname{ct} l_{y}=\\frac{(n+1) \\operatorname{tl}_{y}+(n-1) \\operatorname{br}_{y}}{2 n}} \\\\ {\\operatorname{cbr}_{x}=\\frac{\\left.(n-1) \\operatorname{tl}\\right|_{x}+(n+1) \\operatorname{br}_{x}}{2 n}} \\\\ {\\operatorname{cbr}_{y}=\\frac{(n-1) \\operatorname{tl}_{y}+(n+1) \\operatorname{br}_{y}}{2 n}}\\end{array}\\right. \u672c\u6587\u4e3b\u8981\u6307\u4ee3 n \u4e3a3\u548c5,\u5206\u522b\u5bf9\u5e94scale\u5c0f\u4e8e\u548c\u5927\u4e8e150\u76842Dbox\u3002 Center Pooling \u4e0e Cascade Corner Pooling \u7b80\u5355\u6765\u8bf4\uff0cCenter Pooling\u7684\u7b97\u6cd5\u5c31\u662f\u53d6\u540c\u884c\u3001\u540c\u5217\u7684\u6700\u5927\u503c\u5e76\u7d2f\u52a0\u3002Cascade Corner Pooling\u7684\u7b97\u6cd5\u662f\uff0c\u53d6\u540c\u884c\u3001\u540c\u5217\u7684\u6700\u5927\u503c\uff0c\u518d\u5728\u5bf9\u5e94\u7684\u53d6\u6700\u503c\u7684\u70b9\u5bfb\u627e\u540c\u5217\u3001\u540c\u884c(\u9519\u5f00)\u7684\u6700\u5927\u503c\uff0c\u8f93\u51fa\u4e3a4\u4e2a\u70b9\u7684\u7d2f\u52a0\u3002 \u53ef\u89c6\u5316\u663e\u793a\u5982\u56fe \u90fd\u53ef\u4ee5\u7528 Corner Pooling\u5b9e\u73b0 \u3002\u5982\u56fe","title":"CenterNet: Keypoint Triplets for Object Detection"},{"location":"papers/CenterNet:_Keypoint_Triplets_for_Object_Detection/#centernet-keypoint-triplets-for-object-detection","text":"CenterNet\u4e5f\u5c31\u662f\u901a\u8fc7\u8f93\u51fa\u6bcf\u4e00\u4e2aobject\u4e3a\u5de6\u4e0a\u89d2\u3001\u53f3\u4e0a\u89d2\u4e0e\u4e2d\u5fc3\u70b9\u7684\u4e00\u4e2atriplet,\u8fd9\u4e2a\u601d\u8def\u6e90\u81ea\u4e8e CornerNet \u3002","title":"CenterNet: Keypoint Triplets for Object Detection"},{"location":"papers/CenterNet:_Keypoint_Triplets_for_Object_Detection/#pipeline","text":"\u4e0eCornerNet\u76f8\u4f3c\u7684\uff0cbackbone\u7684\u9009\u62e9\u4e5f\u662f stacked hourglass \u7b2c\u4e00\u5206\u652f\u7ecf\u8fc7\u65b0\u7684Cascade Corner Pooling(\u65b0\u7684\u64cd\u4f5c)\u5f97\u5230Corner Heatmaps\u5e76\u901a\u8fc7 associative embedding \u5f97\u5230\u521d\u59cb2D\u6846\u3002 \u7b2c\u4e8c\u5206\u652f\u7ecf\u8fc7Center Pooling\u5f97\u5230Center Heatmap\u3002 \u6700\u540e\u62fc\u5728\u4e00\u8d77\u5f97\u5230\u8f93\u51fa\u3002","title":"\u603b\u4f53\u7ed3\u6784\u4e0epipeline"},{"location":"papers/CenterNet:_Keypoint_Triplets_for_Object_Detection/#keypoints","text":"\u7b97\u6cd5 1. \u9009\u62e9top-k\u4e2a\u4e2d\u5fc3keypoints 2. \u4f7f\u7528\u5bf9\u5e94offset\u6295\u5f71\u5230\u8f93\u5165\u56fe\u7247\u4e2d 3. \u5bf9\u6bcf\u4e00\u4e2acorner heatmap\u8f93\u51fa\u76842D box\uff0c\u67e5\u627e\u6709\u4e2d\u5fc3\u70b9\u662f\u5426\u5728\u4e2d\u5fc3\u533a\u57df 4. \u5982\u679c\u6709\u4e2d\u5fc3\u70b9\u5728\u4e2d\u5fc3\u533a\u57df\uff0c\u4fdd\u7559\u8fd9\u4e2a\u6846 \u5bf9\u4e2d\u5fc3\u533a\u57df\u7684\u5b9a\u4e49\uff1a \u6ee1\u8db3: \\left\\{\\begin{array}{l}{\\operatorname{ct} 1_{x}=\\frac{(n+1) \\operatorname{tl}_{x}+(n-1) \\operatorname{br}_{x}}{2 n}} \\\\ {\\operatorname{ct} l_{y}=\\frac{(n+1) \\operatorname{tl}_{y}+(n-1) \\operatorname{br}_{y}}{2 n}} \\\\ {\\operatorname{cbr}_{x}=\\frac{\\left.(n-1) \\operatorname{tl}\\right|_{x}+(n+1) \\operatorname{br}_{x}}{2 n}} \\\\ {\\operatorname{cbr}_{y}=\\frac{(n-1) \\operatorname{tl}_{y}+(n+1) \\operatorname{br}_{y}}{2 n}}\\end{array}\\right. \u672c\u6587\u4e3b\u8981\u6307\u4ee3 n \u4e3a3\u548c5,\u5206\u522b\u5bf9\u5e94scale\u5c0f\u4e8e\u548c\u5927\u4e8e150\u76842Dbox\u3002","title":"\u878d\u5408\u68c0\u6d4bkeypoints"},{"location":"papers/CenterNet:_Keypoint_Triplets_for_Object_Detection/#center-pooling-cascade-corner-pooling","text":"\u7b80\u5355\u6765\u8bf4\uff0cCenter Pooling\u7684\u7b97\u6cd5\u5c31\u662f\u53d6\u540c\u884c\u3001\u540c\u5217\u7684\u6700\u5927\u503c\u5e76\u7d2f\u52a0\u3002Cascade Corner Pooling\u7684\u7b97\u6cd5\u662f\uff0c\u53d6\u540c\u884c\u3001\u540c\u5217\u7684\u6700\u5927\u503c\uff0c\u518d\u5728\u5bf9\u5e94\u7684\u53d6\u6700\u503c\u7684\u70b9\u5bfb\u627e\u540c\u5217\u3001\u540c\u884c(\u9519\u5f00)\u7684\u6700\u5927\u503c\uff0c\u8f93\u51fa\u4e3a4\u4e2a\u70b9\u7684\u7d2f\u52a0\u3002 \u53ef\u89c6\u5316\u663e\u793a\u5982\u56fe \u90fd\u53ef\u4ee5\u7528 Corner Pooling\u5b9e\u73b0 \u3002\u5982\u56fe","title":"Center Pooling \u4e0e Cascade Corner Pooling"},{"location":"papers/Continuous-time_Intensity_Estimation_Using_Event_Cameras/","text":"Continuous-time Intensity Estimation Using Event Cameras \u8fd9\u7bc7\u6587\u7ae0\u7ed9\u51fa\u4e86\u4e00\u4e2a\u4f7f\u7528event camera\u589e\u5f3a\u666e\u901acamera\u7684\u7b97\u6cd5\u3002 Event Camera \u4e0e\u6570\u5b66\u57fa\u7840 \u8bbe p, t \u4e3a\u5750\u6807\u4e0e\u65f6\u95f4, Y(p,t_j) \u4ee3\u8868\u539f\u7167\u7247\u5bf9\u5e94\u5750\u6807\u3001\u65f6\u95f4\u4e0a\u7684\u5149\u5f3a\u5ea6\u3002 event camera,\u6bcf\u4e00\u4e2a\u50cf\u7d20\u4f1a\u5b58\u50a8\u5149\u5f3a\u7684\u53d8\u5316\uff0c\u8d85\u8fc7\u4e00\u4e2a\u9608\u503c c \u540e\u4f1a\u53d1\u51fa\u4e00\u4e2a\u5bf9\u5e94\u7684\u51b2\u6fc0\uff0c\u4f1a\u5728\u5404\u4e2a\u65f6\u523b\u5728\u5404\u4e2a\u76f8\u673a\u50cf\u7d20stream,\u7ed9\u51fa e_i(p,t)=\\sigma^p_i c \\delta(t-t^p_i) ,\u5176\u4e2d \\delta \u4e3a\u51b2\u6fc0\u51fd\u6570\u3002 \\sigma \u6307\u6b63\u8d1f\u6781\u6027 E(\\boldsymbol{p}, t):=\\sum_{i=1}^{\\infty} e_{i}(\\boldsymbol{p}, t)=\\sum_{i=1}^{\\infty} \\sigma_{i}^{p} c \\delta\\left(t-t_{i}^{p}\\right) \u53d6log\u4e3a: L^{E}(\\boldsymbol{p}, t):=\\int_{0}^{t} E(\\boldsymbol{p}, \\tau) d \\tau=\\int_{0}^{t} \\sum_{i=1}^{\\infty} \\sigma_{i}^{\\boldsymbol{p}} c \\delta\\left(\\tau-t_{i}^{\\boldsymbol{p}}\\right) d \\tau \u4e92\u8865\u6ee4\u6ce2\u5668 \u516c\u5f0fODE\uff1a \\frac{\\partial}{\\partial t} \\hat{L}(\\boldsymbol{p}, t)=E(\\boldsymbol{p}, t)-\\alpha\\left(\\hat{L}(\\boldsymbol{p}, t)-L^{F}(\\boldsymbol{p}, t)\\right) (\u4e2a\u4eba\u7406\u89e3\u5176\u4f20\u9012\u51fd\u6570\u4e3a \\hat L = \\frac{s}{s+\\alpha}L^E + \\frac{\\alpha}{s+\\alpha}L^F ) \u672c\u6587\u63d0\u5230\uff0c\u7528\u4f4e\u901a\u6ee4\u6ce2\u5668\u5904\u7406\u76f8\u673a\u539f\u6570\u636e\uff0c\u7528\u9ad8\u901a\u6ee4\u6ce2\u5668\u5904\u7406event camera\u7684\u6570\u636e. \u5177\u4f53\u7b97\u6cd5: \u7b2c\u516d\u884c\uff1a\u6307\u7684\u662f\u65f6\u95f4\u95f4\u9694\u5185\uff0c\u76f8\u5f53\u4e8e\u524d\u6587\u63d0\u5230\u7684ODE\u53f3\u8fb9\u53ea\u6709\u7b2c\u4e8c\u9879\uff0c\u6c42\u89e3\u8fd9\u4e2a\u5e38\u5fae\u5206\u65b9\u7a0b\u3002 \u7b2c\u516b\u884c\uff1a \\hat{L}\\left(\\boldsymbol{p}, \\hat{t}_{k+1}^{p}\\right)=\\hat{L}\\left(\\boldsymbol{p},\\left(\\hat{t}_{k+1}^{p}\\right)^{-}\\right)+\\sigma_{k+1}^{\\boldsymbol{p}} c \u662f\u5c06\u51b2\u6fc0\u503c\u76f4\u63a5\u52a0\u5230\u5bf9\u5e94\u7684\u5750\u6807\u4e2d \u7b2c\u5341\u884c\uff0c\u6ce8\u610f\u4e0d\u76f4\u63a5\u6539\u53d8\u8f93\u51fa\u7684 \\hat L \uff0c\u4f46\u662f\u4f1a\u6539\u53d8\u540e\u9762\u5faa\u73af\u7684\u7b2c13\u884c \u7b2c\u5341\u4e00\u884c\uff0c\u63cf\u8ff0\u7684\u662f\u6839\u636e\u8fc7\u66dd\u5149\u6216\u8005\u4f4e\u66dd\u5149\u7684\u53ef\u80fd(\u6bcf\u4e2a\u5750\u6807\u70b9\u6709\u5bf9\u5e94\u7684 \\alpha_p \u503c,\u4e0e\u5f53\u524d\u76f8\u673a\u5bf9\u5e94\u5750\u6807\u7684\u5149\u5f3a L^F \u6709\u5173).\u76f4\u89c9\u4e0a\u6765\u8bf4 \\alpha \u8d8a\u5c0f\uff0c\u8d8a\u4fe1\u4efbevent camera,\u5728\u5149\u5f3a\u63a5\u8fd1\u6700\u5927\u6700\u5c0f\u503c\u7684\u65f6\u5019\u4fe1\u4efbevent camera,\u5149\u5f3a\u4e2d\u95f4\u503c\u7684\u65f6\u5019\u76f8\u5bf9\u66f4\u4fe1\u4efb\u57fa\u7840\u76f8\u673a\uff0c\u5176\u516c\u5f0f\u5982\u4e0b: \\alpha(\\boldsymbol{p}, t)=\\left\\{\\begin{array}{ll}{\\lambda \\alpha_{1}+(1-\\lambda) \\alpha_{1} \\frac{\\left(L^{F}(\\boldsymbol{p}, t)-L_{\\min }\\right)}{\\left(L_{1}-L_{\\min }\\right)}} & {L_{\\min } \\leq L^{F}(\\boldsymbol{p}, t)<L_{1}} \\\\ {\\alpha_{1}} & {L_{1} \\leq L^{F}(\\boldsymbol{p}, t) \\leq L_{2}} \\\\ {\\lambda \\alpha_{1}+(1-\\lambda) \\alpha_{1} \\frac{\\left(L^{F}(\\boldsymbol{p}, t)-L_{\\max }\\right)}{\\left(L_{2}-L_{\\max }\\right)}} & {L_{2}<L^{F}(\\boldsymbol{p}, t) \\leq L_{\\max }}\\end{array}\\right. \u672c\u6587 \\alpha_1 = 2 \\pi, \\lambda=0.1 [L_1, L_2] = [L_{min} +k, L_{max} -k], k = 0.05*(L_{max}-L_{min}) \u5728\u672c\u4eba(Owen Liu)\u7535\u8111\u91cc\u9762\u8fd0\u884c\u5f97\u5230\u7684\u7ed3\u679c \u4e0a\u534a\u56fe\u4e3a\u539f\u56fe\uff0c\u4e0b\u534a\u56fe\u4e3a\u589e\u5f3a\u540e\u7684\u56fe.","title":"Continuous-time Intensity Estimation Using Event Cameras"},{"location":"papers/Continuous-time_Intensity_Estimation_Using_Event_Cameras/#continuous-time-intensity-estimation-using-event-cameras","text":"\u8fd9\u7bc7\u6587\u7ae0\u7ed9\u51fa\u4e86\u4e00\u4e2a\u4f7f\u7528event camera\u589e\u5f3a\u666e\u901acamera\u7684\u7b97\u6cd5\u3002","title":"Continuous-time Intensity Estimation Using Event Cameras"},{"location":"papers/Continuous-time_Intensity_Estimation_Using_Event_Cameras/#event-camera","text":"\u8bbe p, t \u4e3a\u5750\u6807\u4e0e\u65f6\u95f4, Y(p,t_j) \u4ee3\u8868\u539f\u7167\u7247\u5bf9\u5e94\u5750\u6807\u3001\u65f6\u95f4\u4e0a\u7684\u5149\u5f3a\u5ea6\u3002 event camera,\u6bcf\u4e00\u4e2a\u50cf\u7d20\u4f1a\u5b58\u50a8\u5149\u5f3a\u7684\u53d8\u5316\uff0c\u8d85\u8fc7\u4e00\u4e2a\u9608\u503c c \u540e\u4f1a\u53d1\u51fa\u4e00\u4e2a\u5bf9\u5e94\u7684\u51b2\u6fc0\uff0c\u4f1a\u5728\u5404\u4e2a\u65f6\u523b\u5728\u5404\u4e2a\u76f8\u673a\u50cf\u7d20stream,\u7ed9\u51fa e_i(p,t)=\\sigma^p_i c \\delta(t-t^p_i) ,\u5176\u4e2d \\delta \u4e3a\u51b2\u6fc0\u51fd\u6570\u3002 \\sigma \u6307\u6b63\u8d1f\u6781\u6027 E(\\boldsymbol{p}, t):=\\sum_{i=1}^{\\infty} e_{i}(\\boldsymbol{p}, t)=\\sum_{i=1}^{\\infty} \\sigma_{i}^{p} c \\delta\\left(t-t_{i}^{p}\\right) \u53d6log\u4e3a: L^{E}(\\boldsymbol{p}, t):=\\int_{0}^{t} E(\\boldsymbol{p}, \\tau) d \\tau=\\int_{0}^{t} \\sum_{i=1}^{\\infty} \\sigma_{i}^{\\boldsymbol{p}} c \\delta\\left(\\tau-t_{i}^{\\boldsymbol{p}}\\right) d \\tau","title":"Event Camera \u4e0e\u6570\u5b66\u57fa\u7840"},{"location":"papers/Continuous-time_Intensity_Estimation_Using_Event_Cameras/#_1","text":"\u516c\u5f0fODE\uff1a \\frac{\\partial}{\\partial t} \\hat{L}(\\boldsymbol{p}, t)=E(\\boldsymbol{p}, t)-\\alpha\\left(\\hat{L}(\\boldsymbol{p}, t)-L^{F}(\\boldsymbol{p}, t)\\right) (\u4e2a\u4eba\u7406\u89e3\u5176\u4f20\u9012\u51fd\u6570\u4e3a \\hat L = \\frac{s}{s+\\alpha}L^E + \\frac{\\alpha}{s+\\alpha}L^F ) \u672c\u6587\u63d0\u5230\uff0c\u7528\u4f4e\u901a\u6ee4\u6ce2\u5668\u5904\u7406\u76f8\u673a\u539f\u6570\u636e\uff0c\u7528\u9ad8\u901a\u6ee4\u6ce2\u5668\u5904\u7406event camera\u7684\u6570\u636e. \u5177\u4f53\u7b97\u6cd5: \u7b2c\u516d\u884c\uff1a\u6307\u7684\u662f\u65f6\u95f4\u95f4\u9694\u5185\uff0c\u76f8\u5f53\u4e8e\u524d\u6587\u63d0\u5230\u7684ODE\u53f3\u8fb9\u53ea\u6709\u7b2c\u4e8c\u9879\uff0c\u6c42\u89e3\u8fd9\u4e2a\u5e38\u5fae\u5206\u65b9\u7a0b\u3002 \u7b2c\u516b\u884c\uff1a \\hat{L}\\left(\\boldsymbol{p}, \\hat{t}_{k+1}^{p}\\right)=\\hat{L}\\left(\\boldsymbol{p},\\left(\\hat{t}_{k+1}^{p}\\right)^{-}\\right)+\\sigma_{k+1}^{\\boldsymbol{p}} c \u662f\u5c06\u51b2\u6fc0\u503c\u76f4\u63a5\u52a0\u5230\u5bf9\u5e94\u7684\u5750\u6807\u4e2d \u7b2c\u5341\u884c\uff0c\u6ce8\u610f\u4e0d\u76f4\u63a5\u6539\u53d8\u8f93\u51fa\u7684 \\hat L \uff0c\u4f46\u662f\u4f1a\u6539\u53d8\u540e\u9762\u5faa\u73af\u7684\u7b2c13\u884c \u7b2c\u5341\u4e00\u884c\uff0c\u63cf\u8ff0\u7684\u662f\u6839\u636e\u8fc7\u66dd\u5149\u6216\u8005\u4f4e\u66dd\u5149\u7684\u53ef\u80fd(\u6bcf\u4e2a\u5750\u6807\u70b9\u6709\u5bf9\u5e94\u7684 \\alpha_p \u503c,\u4e0e\u5f53\u524d\u76f8\u673a\u5bf9\u5e94\u5750\u6807\u7684\u5149\u5f3a L^F \u6709\u5173).\u76f4\u89c9\u4e0a\u6765\u8bf4 \\alpha \u8d8a\u5c0f\uff0c\u8d8a\u4fe1\u4efbevent camera,\u5728\u5149\u5f3a\u63a5\u8fd1\u6700\u5927\u6700\u5c0f\u503c\u7684\u65f6\u5019\u4fe1\u4efbevent camera,\u5149\u5f3a\u4e2d\u95f4\u503c\u7684\u65f6\u5019\u76f8\u5bf9\u66f4\u4fe1\u4efb\u57fa\u7840\u76f8\u673a\uff0c\u5176\u516c\u5f0f\u5982\u4e0b: \\alpha(\\boldsymbol{p}, t)=\\left\\{\\begin{array}{ll}{\\lambda \\alpha_{1}+(1-\\lambda) \\alpha_{1} \\frac{\\left(L^{F}(\\boldsymbol{p}, t)-L_{\\min }\\right)}{\\left(L_{1}-L_{\\min }\\right)}} & {L_{\\min } \\leq L^{F}(\\boldsymbol{p}, t)<L_{1}} \\\\ {\\alpha_{1}} & {L_{1} \\leq L^{F}(\\boldsymbol{p}, t) \\leq L_{2}} \\\\ {\\lambda \\alpha_{1}+(1-\\lambda) \\alpha_{1} \\frac{\\left(L^{F}(\\boldsymbol{p}, t)-L_{\\max }\\right)}{\\left(L_{2}-L_{\\max }\\right)}} & {L_{2}<L^{F}(\\boldsymbol{p}, t) \\leq L_{\\max }}\\end{array}\\right. \u672c\u6587 \\alpha_1 = 2 \\pi, \\lambda=0.1 [L_1, L_2] = [L_{min} +k, L_{max} -k], k = 0.05*(L_{max}-L_{min})","title":"\u4e92\u8865\u6ee4\u6ce2\u5668"},{"location":"papers/Continuous-time_Intensity_Estimation_Using_Event_Cameras/#owen-liu","text":"\u4e0a\u534a\u56fe\u4e3a\u539f\u56fe\uff0c\u4e0b\u534a\u56fe\u4e3a\u589e\u5f3a\u540e\u7684\u56fe.","title":"\u5728\u672c\u4eba(Owen Liu)\u7535\u8111\u91cc\u9762\u8fd0\u884c\u5f97\u5230\u7684\u7ed3\u679c"},{"location":"papers/CornerNet-Lite_Efficient_Keypoint_Based_Object_Detection/","text":"CornerNet-Lite: Efficient Keypoint Based Object Detection \u8fd9\u7bc7\u8bba\u6587\u5728\u8fdb\u884cobject detection\u7684\u65f6\u5019\uff0c\u4f7f\u7528\u7684\u662f\u57fa\u4e8ekeypoint\u7684\u65b9\u6cd5\u800c\u4e0d\u662f\u57fa\u4e8eproposal\u7684\u65b9\u6cd5\u3002\u5efa\u8bae\u5148\u9605\u8bfb \u8fd9\u7bc7\u8bba\u6587 \u7f51\u7edc\u7ed3\u6784 \u4f7f\u7528attention map\u9884\u6d4b\u4e00\u7cfb\u5217\u4e0d\u540cscale\u7684keypoint\uff0c\u5728\u8fd9\u4e2akeypoint\u5468\u56f4crop\u51fa\u4e00\u5b9a\u91cf\u7684\u65b9\u5757\u56fe\uff0c\u8fdb\u884c\u5206\u7c7b\u3001\u6c47\u603b\uff0c\u7136\u540e\u8fdb\u884cNMS\u3002","title":"CornerNet-Lite: Efficient Keypoint Based Object Detection"},{"location":"papers/CornerNet-Lite_Efficient_Keypoint_Based_Object_Detection/#cornernet-lite-efficient-keypoint-based-object-detection","text":"\u8fd9\u7bc7\u8bba\u6587\u5728\u8fdb\u884cobject detection\u7684\u65f6\u5019\uff0c\u4f7f\u7528\u7684\u662f\u57fa\u4e8ekeypoint\u7684\u65b9\u6cd5\u800c\u4e0d\u662f\u57fa\u4e8eproposal\u7684\u65b9\u6cd5\u3002\u5efa\u8bae\u5148\u9605\u8bfb \u8fd9\u7bc7\u8bba\u6587","title":"CornerNet-Lite: Efficient Keypoint Based Object Detection"},{"location":"papers/CornerNet-Lite_Efficient_Keypoint_Based_Object_Detection/#_1","text":"\u4f7f\u7528attention map\u9884\u6d4b\u4e00\u7cfb\u5217\u4e0d\u540cscale\u7684keypoint\uff0c\u5728\u8fd9\u4e2akeypoint\u5468\u56f4crop\u51fa\u4e00\u5b9a\u91cf\u7684\u65b9\u5757\u56fe\uff0c\u8fdb\u884c\u5206\u7c7b\u3001\u6c47\u603b\uff0c\u7136\u540e\u8fdb\u884cNMS\u3002","title":"\u7f51\u7edc\u7ed3\u6784"},{"location":"papers/DESPOT-\u03b1: Online POMDP Planning With Large State And Observation Spaces/","text":"DESPOT-\u03b1: Online POMDP Planning With Large State And Observation Spaces Under Construction \u5bf9\u8fd9\u7bc7\u6587\u7ae0\u7684\u7406\u89e3\u8fd8\u6ca1\u5b8c\u5168\uff0c\u8fd9\u7bc7\u6587\u7ae0\u6709\u4e00\u4e2a\u91cd\u8981\u7684 \u524d\u7f6e \u4e5f\u6ca1\u8bfb\u5b8c\u3002\u6570\u5b66\u96be\u5ea6\u8f83\u9ad8\u3002\u8fd9\u91cc\u5c1d\u8bd5\u540c\u65f6\u5199\u4e24\u4e2a\u6587\u7ae0\u7684review\u3002\u8fd9\u4e24\u7bc7\u6587\u7ae0\u89e3\u7b54\u7684\u90fd\u662f\u6c42\u89e3POMDP(partially observable markov decision process)\u7684\u95ee\u9898\uff0c\u57fa\u672c\u601d\u8def\u662f\u8499\u7279\u5361\u6d1b\u7b97\u6cd5(\u7136\u800c\u8fd8\u6709\u5927\u91cf\u7684\u6570\u5b66\u7406\u8bba\u4ee5\u53ca\u5206\u6790\uff0c\u76ee\u524d\u5e76\u672a\u5b66\u8d2f\u901a) \u524d\u7f6e\u8bba\u6587\u7b97\u6cd5:","title":"DESPOT-\u03b1: Online POMDP Planning With Large State And Observation Spaces"},{"location":"papers/DESPOT-\u03b1: Online POMDP Planning With Large State And Observation Spaces/#despot-online-pomdp-planning-with-large-state-and-observation-spaces","text":"","title":"DESPOT-\u03b1: Online POMDP Planning With Large State And Observation Spaces"},{"location":"papers/DESPOT-\u03b1: Online POMDP Planning With Large State And Observation Spaces/#under-construction","text":"\u5bf9\u8fd9\u7bc7\u6587\u7ae0\u7684\u7406\u89e3\u8fd8\u6ca1\u5b8c\u5168\uff0c\u8fd9\u7bc7\u6587\u7ae0\u6709\u4e00\u4e2a\u91cd\u8981\u7684 \u524d\u7f6e \u4e5f\u6ca1\u8bfb\u5b8c\u3002\u6570\u5b66\u96be\u5ea6\u8f83\u9ad8\u3002\u8fd9\u91cc\u5c1d\u8bd5\u540c\u65f6\u5199\u4e24\u4e2a\u6587\u7ae0\u7684review\u3002\u8fd9\u4e24\u7bc7\u6587\u7ae0\u89e3\u7b54\u7684\u90fd\u662f\u6c42\u89e3POMDP(partially observable markov decision process)\u7684\u95ee\u9898\uff0c\u57fa\u672c\u601d\u8def\u662f\u8499\u7279\u5361\u6d1b\u7b97\u6cd5(\u7136\u800c\u8fd8\u6709\u5927\u91cf\u7684\u6570\u5b66\u7406\u8bba\u4ee5\u53ca\u5206\u6790\uff0c\u76ee\u524d\u5e76\u672a\u5b66\u8d2f\u901a) \u524d\u7f6e\u8bba\u6587\u7b97\u6cd5:","title":"Under Construction"},{"location":"papers/Deep High-Resolution Representation Learning for Human Pose Estimation/","text":"Deep High-Resolution Representation Learning for Human Pose Estimation \u8fd9\u7bc7\u8bba\u6587\u7ed9\u51faHRnet,\u601d\u8def\u5173\u952e\u662f\u4fdd\u7559\u4e0d\u540cscale\u7684feature map\uff0c\u5e76\u5728\u524d\u4f20\u8fc7\u7a0b\u4e2d\u8ba9\u4ed6\u4eec\u4ea4\u6362\u4fe1\u606f\u3002","title":"Deep High-Resolution Representation Learning for Human Pose Estimation"},{"location":"papers/Deep High-Resolution Representation Learning for Human Pose Estimation/#deep-high-resolution-representation-learning-for-human-pose-estimation","text":"\u8fd9\u7bc7\u8bba\u6587\u7ed9\u51faHRnet,\u601d\u8def\u5173\u952e\u662f\u4fdd\u7559\u4e0d\u540cscale\u7684feature map\uff0c\u5e76\u5728\u524d\u4f20\u8fc7\u7a0b\u4e2d\u8ba9\u4ed6\u4eec\u4ea4\u6362\u4fe1\u606f\u3002","title":"Deep High-Resolution Representation Learning for Human Pose Estimation"},{"location":"papers/Deep Multi-Sensor Lane Detection/","text":"Deep Multi-Sensor Lane Detection \u8fd9\u7bc7\u8bba\u6587\u7ed9\u51fa\u7528lidar\u548c\u56fe\u7247\u4e24\u8005\u5171\u540c\u8fdb\u884c\u5b66\u4e60\u4fa6\u6d4b\u9053\u8def\u7ebf\u7684\u7b97\u6cd5 \u5173\u952e\u70b9\uff1a \u4f5c\u8005\u7528\u56fe\u7247\u793a\u4f8b\u8bf4\u660e\uff0c\u5373\u4f7f\u5728\u76f8\u673a\u5750\u6807\u7cfb(\u56fe\u7247)\u4e2d\u5b9e\u73b0\u4e86\u8fd1\u4e4e\u5b8c\u7f8e\u7cbe\u786e\u7684road-segmentation,\u8f6c\u6362\u5230\u4fef\u89c6\u56fe\u7684\u65f6\u5019\u7cbe\u786e\u5ea6\u4ecd\u7136\u5f88\u4f4e\uff0c\u6240\u4ee5\u9700\u8981\u7528\u4fef\u89c6\u56fe\u76f4\u63a5\u5904\u7406\u3002 \u8f93\u51fa\u7684\u4fef\u89c6\u56fe\u4e2d\u6bcf\u4e00\u4e2a\u50cf\u7d20\u4ee3\u8868\u7684\u662f\u8be5\u70b9\u8ddd\u79bb\u6700\u8fd1\u9053\u8def\u7ebf\u7684\u8ddd\u79bb\u3002\u4e0e\u76f4\u63a5segmentation\u76f8\u6bd4\uff0c\u53ef\u4ee5\u7f13\u89e3\u8f93\u51fa\u7ed3\u679c\u4ec5\u4e0e\u7ed3\u679c\u7a0d\u7a0doffset\u65f6\u7684loss\u8fc7\u5927\u7b49\u7684\u95ee\u9898\u3002 \u70b9\u4e91\u8bc6\u522b\u8def\u5f84\u65f6\uff0c\u5730\u9762\u70b9\u8fc7\u4e8e\u7a00\u758f\uff0c\u6240\u4ee5\u9700\u8981\u6570\u4e2a\u70b9\u4e91\u6d4b\u91cf\u7ed3\u679c\u5408\u5e76\u4e00\u8d77\u4f7f\u7528\uff0c\u7136\u540e\u538b\u5728\u5e73\u9762\u56fe\u4e2d\u8f93\u5165CNN\u3002","title":"Deep Multi-Sensor Lane Detection"},{"location":"papers/Deep Multi-Sensor Lane Detection/#deep-multi-sensor-lane-detection","text":"\u8fd9\u7bc7\u8bba\u6587\u7ed9\u51fa\u7528lidar\u548c\u56fe\u7247\u4e24\u8005\u5171\u540c\u8fdb\u884c\u5b66\u4e60\u4fa6\u6d4b\u9053\u8def\u7ebf\u7684\u7b97\u6cd5 \u5173\u952e\u70b9\uff1a \u4f5c\u8005\u7528\u56fe\u7247\u793a\u4f8b\u8bf4\u660e\uff0c\u5373\u4f7f\u5728\u76f8\u673a\u5750\u6807\u7cfb(\u56fe\u7247)\u4e2d\u5b9e\u73b0\u4e86\u8fd1\u4e4e\u5b8c\u7f8e\u7cbe\u786e\u7684road-segmentation,\u8f6c\u6362\u5230\u4fef\u89c6\u56fe\u7684\u65f6\u5019\u7cbe\u786e\u5ea6\u4ecd\u7136\u5f88\u4f4e\uff0c\u6240\u4ee5\u9700\u8981\u7528\u4fef\u89c6\u56fe\u76f4\u63a5\u5904\u7406\u3002 \u8f93\u51fa\u7684\u4fef\u89c6\u56fe\u4e2d\u6bcf\u4e00\u4e2a\u50cf\u7d20\u4ee3\u8868\u7684\u662f\u8be5\u70b9\u8ddd\u79bb\u6700\u8fd1\u9053\u8def\u7ebf\u7684\u8ddd\u79bb\u3002\u4e0e\u76f4\u63a5segmentation\u76f8\u6bd4\uff0c\u53ef\u4ee5\u7f13\u89e3\u8f93\u51fa\u7ed3\u679c\u4ec5\u4e0e\u7ed3\u679c\u7a0d\u7a0doffset\u65f6\u7684loss\u8fc7\u5927\u7b49\u7684\u95ee\u9898\u3002 \u70b9\u4e91\u8bc6\u522b\u8def\u5f84\u65f6\uff0c\u5730\u9762\u70b9\u8fc7\u4e8e\u7a00\u758f\uff0c\u6240\u4ee5\u9700\u8981\u6570\u4e2a\u70b9\u4e91\u6d4b\u91cf\u7ed3\u679c\u5408\u5e76\u4e00\u8d77\u4f7f\u7528\uff0c\u7136\u540e\u538b\u5728\u5e73\u9762\u56fe\u4e2d\u8f93\u5165CNN\u3002","title":"Deep Multi-Sensor Lane Detection"},{"location":"papers/DeepICP:_An_End-to-End_Deep_Neural_Network_for_3D_Point_Cloud_Registration/","text":"DeepICP: An End-to-End Deep Neural Network for 3D Point Cloud Registration \u7aef\u5230\u7aef\u65b9\u6cd5\u5b9e\u73b0\u57fa\u4e8ekeypoint\u7684\u70b9\u4e91ICP,\u8f93\u5165\u662f\u4e24\u5e27\u76f8\u90bb\u7684\u70b9\u4e91\uff0c\u4e00\u4e2a\u5bf9\u4e8e\u76f8\u5bf9\u8fd0\u52a8\u7684\u521d\u59cb\u4f30\u8ba1\u3002 \u6574\u4f53\u7ed3\u6784 \u7279\u5f81\u63d0\u53d6\u5c42 \u4e24\u5e27\u70b9\u4e91\u9996\u5148\u8f93\u5165\u5230\u4e00\u4e2a\u5171\u7528\u7684\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u3002\u4f7f\u7528\u7684\u7f51\u7edc\u4e0ePointNet++\u4e00\u81f4\u3002\u4f5c\u8005\u7684\u4e00\u4e2a\u7406\u8bba\u662f\u8bf4\u8fd9\u91cc\u4f1a\u5e26\u6709\u4e00\u4e9b\u8bed\u4e49\u4fe1\u606f\uff0c\u8fd9\u4e9b\u8bed\u4e49\u4fe1\u606f\u53ef\u4ee5\u6709\u6548\u5730\u5e2e\u52a9\u907f\u514d\u52a8\u6001\u7269\u4f53\u3002 \u70b9\u52a0\u6743 \u7406\u8bba\u4e0a\u6765\u8bf4\uff0c\u5177\u6709\u5f3a\u7279\u5f81\u7684\u70b9\u5e94\u8be5\u4f1a\u5206\u914d\u66f4\u5927\u7684\u6743\u91cd\u3002\u8fd9\u91cc\u7684\u505a\u6cd5\u662f\u5bf9\u6bcf\u4e00\u4e2a\u70b9\u8fdb\u884c\u4e09\u5c42\u5168\u8fde\u63a5\uff0c\u524d\u9762\u4e24\u5c42\u5e26\u6709batchnorm\u4ee5\u53caReLU\uff0c\u6700\u540e\u4e00\u5c42softplus\u6fc0\u6d3b: y = ln(1 + e^x) ,\u6700\u540e\u9009\u51fa\u8f93\u51fa\u6743\u91cd\u6700\u5927\u7684N\u4e2a\u70b9\uff0c\u8fd9\u4e9b\u70b9\u4ee5\u53ca\u5bf9\u5e94\u7684\u6743\u91cd\u5728\u540e\u7eed\u7ee7\u7eed\u4f7f\u7528\u3002 \u6df1\u5ea6\u7279\u5f81\u63d0\u53d6(embedding) \u4f7f\u7528\u4e00\u4e2amini-PointNet(\u6709\u5f85\u5f15\u7528\u8bf4\u660e), \u5bf9\u524d\u9762\u63d0\u51fa\u7684N\u4e2akeypoint\uff0c\u5728\u534a\u5f84\u4e3a d \u7684\u8303\u56f4\u5185\uff0c\u6536\u96c6K\u4e2a\u4e34\u8fd1\u70b9(\u53ef\u91cd\u590d),\u5bf9\u8fd9\u4e9b\u70b9\uff0c\u628a\u4ed6\u4eec\u7684\u76f8\u5bf9\u5750\u6807normalized by d \uff0c\u518d\u52a0\u4e0alidar\u5f3a\u5ea6\uff0c\u8fd9\u4e9b\u7279\u5f81\u4e0e\u7279\u5f81\u63d0\u53d6\u5c42\u7684\u7279\u5f81concat\uff0c mini-pointNet \u7531\u4e09\u5c42\u5168\u8fde\u63a5\u548cmax-pooling\u7ec4\u6210\uff0c\u8f93\u5165\u662f N\\times K \\times 36 \u7684\u77e2\u91cf\uff0c\u8f93\u51fa\u662f\u4e00\u4e2a,\u8f93\u51fa\u4ecd\u7136\u662f N\\times 32 \u7ef4\u7684\u5411\u91cf \u5bf9\u5e94\u70b9\u751f\u6210 \u4f20\u7edfICP\u76f4\u63a5\u9009\u62e9\u6700\u9760\u8fd1\u7684\u70b9\u6700\u4e3a\u5bf9\u5e94\u70b9\uff0c\u8fd9\u4f7f\u5f97\u53cd\u5411\u4f20\u64ad\u65e0\u6cd5\u8fdb\u884c\uff0c\u800c\u4e14\u7531\u4e8e\u70b9\u4e91\u7684\u7a00\u758f\u7279\u6027\uff0c\u5f88\u591a\u65f6\u5019\u6839\u672c\u4e0d\u5b58\u5728\u5bf9\u5e94\u70b9\uff0c\u8fd9\u91cc\u63d0\u51fa\u4e86\u4f7f\u7528CPG\u5c42. \u9996\u5148\u5c06N\u4e2a\u5728\u6e90\u70b9\u4e91\u7684keypoint\u901a\u8fc7\u9884\u4f30\u8ba1\u7684\u8f6c\u79fb\u77e9\u9635\u8fdb\u884c\u4e00\u6b21\u5750\u6807\u53d8\u6362\u3002\u5728\u8f6c\u6362\u540e\u7684\u4f4d\u7f6e\u4e0a\uff0c\u5c06\u5b83\u7684\u4e34\u8fd1\u7a7a\u95f4\u5206\u4e3a (\\frac{2r}{s} + 1, \\frac{2r}{s} + 1, \\frac{2r}{s} + 1) 3D\u7f51\u683c\uff0c\u6bcf\u4e00\u4e2a\u7f51\u683c\u7684\u4e2d\u5fc3{ y^{'}_j, j=1,...,C }\u53ef\u7406\u89e3\u4e3a\u53ef\u80fd\u7684\u5bf9\u5e94\u70b9\uff0c\u4e0e\u524d\u6587\u6df1\u5ea6\u7279\u5f81\u63d0\u53d6\u4e00\u81f4\uff0c\u4f7f\u7528\u7279\u5f81\u63d0\u53d6\u5f97\u5230 N\\times C \\times 32 \u7684\u77e2\u91cf\u3002\u6765\u81ea\u6e90\u57df\u4e0e\u76ee\u6807\u57df\u7684\u7279\u5f81\u9001\u52303D CNN + softmax\u4e2d\uff0c\u76ee\u6807\u662f\u5b66\u4e60\u4e00\u4e2asimilarity distance metric. Loss \u51fd\u6570 \u5bf9\u4e8e\u6bcf\u4e00\u4e2akeypoint\uff0c\u6211\u4eec\u901a\u8fc7GT\u53ef\u4ee5\u77e5\u9053\u5b83\u6700\u540e\u7684cooresponding points\uff0c\u7528GT\u7684\u5bf9\u5e94\u70b9\u4e0e\u9884\u6d4b\u7684\u5bf9\u5e94\u70b9\u4e4b\u95f4\u7684\u8bef\u5dee\u53ef\u4ee5\u7ed9\u51fa\u4e00\u4e2aLoss \u5c06\u6240\u6709\u7684\u5bf9\u5e94\u70b9\u878d\u5408\u8d77\u6765\uff0c\u53ef\u4ee5\u7528SVD\u6c42\u51faR\uff0cT\uff0c\u7528RT\u4ee3\u66ff\u9884\u6d4b\u7684\u5bf9\u5e94\u70b9\u6c42\u51fa\u7b2c\u4e8c\u4e2aloss\uff0cTensorflow\u63d0\u4f9b\u4e86\u53ef\u5fae\u5206\u7684SVD\u5b9e\u73b0\uff0c \u6700\u7ec8loss\u4e3a\u4e24\u8005\u7684\u878d\u5408","title":"DeepICP: An End-to-End Deep Neural Network for 3D Point Cloud Registration"},{"location":"papers/DeepICP:_An_End-to-End_Deep_Neural_Network_for_3D_Point_Cloud_Registration/#deepicp-an-end-to-end-deep-neural-network-for-3d-point-cloud-registration","text":"\u7aef\u5230\u7aef\u65b9\u6cd5\u5b9e\u73b0\u57fa\u4e8ekeypoint\u7684\u70b9\u4e91ICP,\u8f93\u5165\u662f\u4e24\u5e27\u76f8\u90bb\u7684\u70b9\u4e91\uff0c\u4e00\u4e2a\u5bf9\u4e8e\u76f8\u5bf9\u8fd0\u52a8\u7684\u521d\u59cb\u4f30\u8ba1\u3002","title":"DeepICP: An End-to-End Deep Neural Network for 3D Point Cloud Registration"},{"location":"papers/DeepICP:_An_End-to-End_Deep_Neural_Network_for_3D_Point_Cloud_Registration/#_1","text":"","title":"\u6574\u4f53\u7ed3\u6784"},{"location":"papers/DeepICP:_An_End-to-End_Deep_Neural_Network_for_3D_Point_Cloud_Registration/#_2","text":"\u4e24\u5e27\u70b9\u4e91\u9996\u5148\u8f93\u5165\u5230\u4e00\u4e2a\u5171\u7528\u7684\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u3002\u4f7f\u7528\u7684\u7f51\u7edc\u4e0ePointNet++\u4e00\u81f4\u3002\u4f5c\u8005\u7684\u4e00\u4e2a\u7406\u8bba\u662f\u8bf4\u8fd9\u91cc\u4f1a\u5e26\u6709\u4e00\u4e9b\u8bed\u4e49\u4fe1\u606f\uff0c\u8fd9\u4e9b\u8bed\u4e49\u4fe1\u606f\u53ef\u4ee5\u6709\u6548\u5730\u5e2e\u52a9\u907f\u514d\u52a8\u6001\u7269\u4f53\u3002","title":"\u7279\u5f81\u63d0\u53d6\u5c42"},{"location":"papers/DeepICP:_An_End-to-End_Deep_Neural_Network_for_3D_Point_Cloud_Registration/#_3","text":"\u7406\u8bba\u4e0a\u6765\u8bf4\uff0c\u5177\u6709\u5f3a\u7279\u5f81\u7684\u70b9\u5e94\u8be5\u4f1a\u5206\u914d\u66f4\u5927\u7684\u6743\u91cd\u3002\u8fd9\u91cc\u7684\u505a\u6cd5\u662f\u5bf9\u6bcf\u4e00\u4e2a\u70b9\u8fdb\u884c\u4e09\u5c42\u5168\u8fde\u63a5\uff0c\u524d\u9762\u4e24\u5c42\u5e26\u6709batchnorm\u4ee5\u53caReLU\uff0c\u6700\u540e\u4e00\u5c42softplus\u6fc0\u6d3b: y = ln(1 + e^x) ,\u6700\u540e\u9009\u51fa\u8f93\u51fa\u6743\u91cd\u6700\u5927\u7684N\u4e2a\u70b9\uff0c\u8fd9\u4e9b\u70b9\u4ee5\u53ca\u5bf9\u5e94\u7684\u6743\u91cd\u5728\u540e\u7eed\u7ee7\u7eed\u4f7f\u7528\u3002","title":"\u70b9\u52a0\u6743"},{"location":"papers/DeepICP:_An_End-to-End_Deep_Neural_Network_for_3D_Point_Cloud_Registration/#embedding","text":"\u4f7f\u7528\u4e00\u4e2amini-PointNet(\u6709\u5f85\u5f15\u7528\u8bf4\u660e), \u5bf9\u524d\u9762\u63d0\u51fa\u7684N\u4e2akeypoint\uff0c\u5728\u534a\u5f84\u4e3a d \u7684\u8303\u56f4\u5185\uff0c\u6536\u96c6K\u4e2a\u4e34\u8fd1\u70b9(\u53ef\u91cd\u590d),\u5bf9\u8fd9\u4e9b\u70b9\uff0c\u628a\u4ed6\u4eec\u7684\u76f8\u5bf9\u5750\u6807normalized by d \uff0c\u518d\u52a0\u4e0alidar\u5f3a\u5ea6\uff0c\u8fd9\u4e9b\u7279\u5f81\u4e0e\u7279\u5f81\u63d0\u53d6\u5c42\u7684\u7279\u5f81concat\uff0c mini-pointNet \u7531\u4e09\u5c42\u5168\u8fde\u63a5\u548cmax-pooling\u7ec4\u6210\uff0c\u8f93\u5165\u662f N\\times K \\times 36 \u7684\u77e2\u91cf\uff0c\u8f93\u51fa\u662f\u4e00\u4e2a,\u8f93\u51fa\u4ecd\u7136\u662f N\\times 32 \u7ef4\u7684\u5411\u91cf","title":"\u6df1\u5ea6\u7279\u5f81\u63d0\u53d6(embedding)"},{"location":"papers/DeepICP:_An_End-to-End_Deep_Neural_Network_for_3D_Point_Cloud_Registration/#_4","text":"\u4f20\u7edfICP\u76f4\u63a5\u9009\u62e9\u6700\u9760\u8fd1\u7684\u70b9\u6700\u4e3a\u5bf9\u5e94\u70b9\uff0c\u8fd9\u4f7f\u5f97\u53cd\u5411\u4f20\u64ad\u65e0\u6cd5\u8fdb\u884c\uff0c\u800c\u4e14\u7531\u4e8e\u70b9\u4e91\u7684\u7a00\u758f\u7279\u6027\uff0c\u5f88\u591a\u65f6\u5019\u6839\u672c\u4e0d\u5b58\u5728\u5bf9\u5e94\u70b9\uff0c\u8fd9\u91cc\u63d0\u51fa\u4e86\u4f7f\u7528CPG\u5c42. \u9996\u5148\u5c06N\u4e2a\u5728\u6e90\u70b9\u4e91\u7684keypoint\u901a\u8fc7\u9884\u4f30\u8ba1\u7684\u8f6c\u79fb\u77e9\u9635\u8fdb\u884c\u4e00\u6b21\u5750\u6807\u53d8\u6362\u3002\u5728\u8f6c\u6362\u540e\u7684\u4f4d\u7f6e\u4e0a\uff0c\u5c06\u5b83\u7684\u4e34\u8fd1\u7a7a\u95f4\u5206\u4e3a (\\frac{2r}{s} + 1, \\frac{2r}{s} + 1, \\frac{2r}{s} + 1) 3D\u7f51\u683c\uff0c\u6bcf\u4e00\u4e2a\u7f51\u683c\u7684\u4e2d\u5fc3{ y^{'}_j, j=1,...,C }\u53ef\u7406\u89e3\u4e3a\u53ef\u80fd\u7684\u5bf9\u5e94\u70b9\uff0c\u4e0e\u524d\u6587\u6df1\u5ea6\u7279\u5f81\u63d0\u53d6\u4e00\u81f4\uff0c\u4f7f\u7528\u7279\u5f81\u63d0\u53d6\u5f97\u5230 N\\times C \\times 32 \u7684\u77e2\u91cf\u3002\u6765\u81ea\u6e90\u57df\u4e0e\u76ee\u6807\u57df\u7684\u7279\u5f81\u9001\u52303D CNN + softmax\u4e2d\uff0c\u76ee\u6807\u662f\u5b66\u4e60\u4e00\u4e2asimilarity distance metric.","title":"\u5bf9\u5e94\u70b9\u751f\u6210"},{"location":"papers/DeepICP:_An_End-to-End_Deep_Neural_Network_for_3D_Point_Cloud_Registration/#loss","text":"\u5bf9\u4e8e\u6bcf\u4e00\u4e2akeypoint\uff0c\u6211\u4eec\u901a\u8fc7GT\u53ef\u4ee5\u77e5\u9053\u5b83\u6700\u540e\u7684cooresponding points\uff0c\u7528GT\u7684\u5bf9\u5e94\u70b9\u4e0e\u9884\u6d4b\u7684\u5bf9\u5e94\u70b9\u4e4b\u95f4\u7684\u8bef\u5dee\u53ef\u4ee5\u7ed9\u51fa\u4e00\u4e2aLoss \u5c06\u6240\u6709\u7684\u5bf9\u5e94\u70b9\u878d\u5408\u8d77\u6765\uff0c\u53ef\u4ee5\u7528SVD\u6c42\u51faR\uff0cT\uff0c\u7528RT\u4ee3\u66ff\u9884\u6d4b\u7684\u5bf9\u5e94\u70b9\u6c42\u51fa\u7b2c\u4e8c\u4e2aloss\uff0cTensorflow\u63d0\u4f9b\u4e86\u53ef\u5fae\u5206\u7684SVD\u5b9e\u73b0\uff0c \u6700\u7ec8loss\u4e3a\u4e24\u8005\u7684\u878d\u5408","title":"Loss \u51fd\u6570"},{"location":"papers/DroNet Learning to Fly by Driving/","text":"DroNet: Learning to Fly by Driving \u6838\u5fc3\u662f\u4e00\u4e2a\u6a21\u4eff\u5b66\u4e60\uff0c\u8f93\u51fa\u8235\u89d2\u4ee5\u53ca\u78b0\u649e\u6982\u7387\uff0c\u78b0\u649e\u6982\u7387\u6765\u81ea\u4e8e\u4f5c\u8005\u989d\u5916\u624b\u5de5\u6807\u6ce8\u7684\u6570\u636e\u96c6\u3002 \u7a81\u51fa\u7684\u7ed3\u679c\u662f\u7528\u65e0\u4eba\u8f66\u6536\u96c6\u7684\u6570\u636e\u80fd\u591f\u6269\u5c55\u5230\u65e0\u4eba\u673a\u4f7f\u7528\u3002","title":"DroNet: Learning to Fly by Driving"},{"location":"papers/DroNet Learning to Fly by Driving/#dronet-learning-to-fly-by-driving","text":"\u6838\u5fc3\u662f\u4e00\u4e2a\u6a21\u4eff\u5b66\u4e60\uff0c\u8f93\u51fa\u8235\u89d2\u4ee5\u53ca\u78b0\u649e\u6982\u7387\uff0c\u78b0\u649e\u6982\u7387\u6765\u81ea\u4e8e\u4f5c\u8005\u989d\u5916\u624b\u5de5\u6807\u6ce8\u7684\u6570\u636e\u96c6\u3002 \u7a81\u51fa\u7684\u7ed3\u679c\u662f\u7528\u65e0\u4eba\u8f66\u6536\u96c6\u7684\u6570\u636e\u80fd\u591f\u6269\u5c55\u5230\u65e0\u4eba\u673a\u4f7f\u7528\u3002","title":"DroNet: Learning to Fly by Driving"},{"location":"papers/End-to-end Driving Deploying through Uncertainty-Aware ImitationLearning and Stochastic Visual Domain Adaptation/","text":"End-to-end Driving Deploying through Uncertainty-Aware Imitation Learning and Stochastic Visual Domain Adaptation \u8fd9\u662f\u4e00\u7bc7\u672c\u5b9e\u9a8c\u5ba4\u5e08\u5144\u7684\u4e00\u7bc7\u6587\u7ae0\u3002\u8bb2\u7684\u662f\u7aef\u5230\u7aef\u7684\u5e26\u6709\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7684\u6a21\u4eff\u5b66\u4e60\u4ee5\u53catransfer learning\u7684\u4f5c\u7528 \u5e26\u6709\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7684\u6a21\u4eff\u5b66\u4e60 \u5c06\u56de\u5f52\u4efb\u52a1\u8f6c\u5316\u4e3a\u4ee5\u4e0b\u65b9\u7a0b: [y, \\sigma] = f^\\theta(x) L(\\theta)=\\frac{1}{2} \\frac{||y-\\hat y||^2}{\\sigma^2} + \\frac{1}{2}log \\sigma^2 \u65b9\u7a0b\u4e00\u662f\u795e\u7ecf\u7f51\u7edc\u7684forward pass\uff0c\u65b9\u7a0b\u4e8c\u662f\u56de\u5f52\u7684cost function\u3002 real-to-sim \u8f6c\u6362 \u5e08\u5144\u7684\u53e6\u4e00\u7bc7\u8bba\u6587\u53c8\u63d0\u5230\u4f7f\u7528Real-to-sim\u7684\u5b9e\u65f6\u8f6c\u6362\uff0c\u53ef\u4ee5\u8ba9\u5728simulation\u4e0b\u8bad\u7ec3\u7684agent\u5728\u9762\u5bf9\u73b0\u5b9e\u5f97\u5230\u7684\u56fe\u7247\u65f6\u6709\u66f4\u597d\u7684\u8868\u73b0\u3002\u672c\u6587\u7684\u601d\u8def\u662f\u5c06\u6d4b\u8bd5domain\u8f6c\u6362\u5230\u8bad\u7ec3\u7684\u4e09\u4e2adomain\u4e2d\uff0c\u5e76\u5206\u522b\u7ed9\u51fa\u8f93\u51fa\u3002","title":"End-to-end Driving Deploying through Uncertainty-Aware Imitation Learning and Stochastic Visual Domain Adaptation"},{"location":"papers/End-to-end Driving Deploying through Uncertainty-Aware ImitationLearning and Stochastic Visual Domain Adaptation/#end-to-end-driving-deploying-through-uncertainty-aware-imitation-learning-and-stochastic-visual-domain-adaptation","text":"\u8fd9\u662f\u4e00\u7bc7\u672c\u5b9e\u9a8c\u5ba4\u5e08\u5144\u7684\u4e00\u7bc7\u6587\u7ae0\u3002\u8bb2\u7684\u662f\u7aef\u5230\u7aef\u7684\u5e26\u6709\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7684\u6a21\u4eff\u5b66\u4e60\u4ee5\u53catransfer learning\u7684\u4f5c\u7528","title":"End-to-end Driving Deploying through Uncertainty-Aware Imitation Learning and Stochastic Visual Domain Adaptation"},{"location":"papers/End-to-end Driving Deploying through Uncertainty-Aware ImitationLearning and Stochastic Visual Domain Adaptation/#_1","text":"\u5c06\u56de\u5f52\u4efb\u52a1\u8f6c\u5316\u4e3a\u4ee5\u4e0b\u65b9\u7a0b: [y, \\sigma] = f^\\theta(x) L(\\theta)=\\frac{1}{2} \\frac{||y-\\hat y||^2}{\\sigma^2} + \\frac{1}{2}log \\sigma^2 \u65b9\u7a0b\u4e00\u662f\u795e\u7ecf\u7f51\u7edc\u7684forward pass\uff0c\u65b9\u7a0b\u4e8c\u662f\u56de\u5f52\u7684cost function\u3002","title":"\u5e26\u6709\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7684\u6a21\u4eff\u5b66\u4e60"},{"location":"papers/End-to-end Driving Deploying through Uncertainty-Aware ImitationLearning and Stochastic Visual Domain Adaptation/#real-to-sim","text":"\u5e08\u5144\u7684\u53e6\u4e00\u7bc7\u8bba\u6587\u53c8\u63d0\u5230\u4f7f\u7528Real-to-sim\u7684\u5b9e\u65f6\u8f6c\u6362\uff0c\u53ef\u4ee5\u8ba9\u5728simulation\u4e0b\u8bad\u7ec3\u7684agent\u5728\u9762\u5bf9\u73b0\u5b9e\u5f97\u5230\u7684\u56fe\u7247\u65f6\u6709\u66f4\u597d\u7684\u8868\u73b0\u3002\u672c\u6587\u7684\u601d\u8def\u662f\u5c06\u6d4b\u8bd5domain\u8f6c\u6362\u5230\u8bad\u7ec3\u7684\u4e09\u4e2adomain\u4e2d\uff0c\u5e76\u5206\u522b\u7ed9\u51fa\u8f93\u51fa\u3002","title":"real-to-sim \u8f6c\u6362"},{"location":"papers/Fast and Furious Real Time End-to-End 3D Detection, Tracking and MotionForecasting with a Single Convolutional Net/","text":"Fast and Furious: Real Time End-to-End 3D Detection, Tracking and MotionForecasting with a Single Convolutional Net \u8fd9\u7bc7\u8bba\u6587\u7684\u5173\u952e\u662f\u7ed3\u5408\u65f6\u5e8f\u4fe1\u606f\uff0c\u8981\u540c\u65f6\u5b9e\u73b03D detection\u4ee5\u53catracking\u751a\u81f3forecasting,\u4f7f\u7528\u5355\u4e00\u7684Lidar\u6570\u636e \u70b9\u4e91\u4fe1\u606f\u7684\u5904\u7406\u529e\u6cd5 \u5c06\u5355\u5e27\u70b9\u4e91\u8f6c\u6362\u4e3a2Dcostmap\uff0c\u70b9\u7684\u9ad8\u5ea6\u4f5c\u4e3a\u8f93\u5165\u7684\u4e00\u4e2afeature\u3002 \u5c06\u591a\u5e27\u70b9\u4e91\u8f6c\u6362\u5230\u540c\u4e00\u4e2a\u5750\u6807\u7cfb\u4e2d\uff0c\u6bcf\u4e00\u5e27\u53ef\u4ee5\u5355\u72ec\u5f62\u6210\u4e00\u4e2a3D Tensor\uff0c\u7ed3\u5408\u8d77\u6765\u6210\u4e3a\u4e00\u4e2a4D Tensor \u878d\u5408\u65f6\u5e8f\u4fe1\u606f\u7684\u65b9\u6cd5 \u7b2c\u4e00\u79cd\u65b9\u6cd5\u662fEarly Fusion,\u5728\u4e00\u5f00\u59cb\u5c31\u4f7f\u75281D Conv\u5c06\u591a\u4e2aCostmap\u7ed3\u5408\u6210\u4e00\u4e2aCostmap \u7b2c\u4e8c\u79cd\u65b9\u6cd5\u662fLate Fusion,\u4f7f\u75283D Conv\u5206\u4e24\u6b65\u7ed3\u5408\u3002 \u8f93\u51fabounding box \u4ee5\u53ca\u9884\u6d4b \u76f4\u63a5\u8f93\u51fa\u4e00\u7cfb\u5217\u7684bounding box\u548c\u79cd\u7c7b\u4fe1\u606f","title":"Fast and Furious: Real Time End-to-End 3D Detection, Tracking and MotionForecasting with a Single Convolutional Net"},{"location":"papers/Fast and Furious Real Time End-to-End 3D Detection, Tracking and MotionForecasting with a Single Convolutional Net/#fast-and-furious-real-time-end-to-end-3d-detection-tracking-and-motionforecasting-with-a-single-convolutional-net","text":"\u8fd9\u7bc7\u8bba\u6587\u7684\u5173\u952e\u662f\u7ed3\u5408\u65f6\u5e8f\u4fe1\u606f\uff0c\u8981\u540c\u65f6\u5b9e\u73b03D detection\u4ee5\u53catracking\u751a\u81f3forecasting,\u4f7f\u7528\u5355\u4e00\u7684Lidar\u6570\u636e","title":"Fast and Furious: Real Time End-to-End 3D Detection, Tracking and MotionForecasting with a Single Convolutional Net"},{"location":"papers/Fast and Furious Real Time End-to-End 3D Detection, Tracking and MotionForecasting with a Single Convolutional Net/#_1","text":"\u5c06\u5355\u5e27\u70b9\u4e91\u8f6c\u6362\u4e3a2Dcostmap\uff0c\u70b9\u7684\u9ad8\u5ea6\u4f5c\u4e3a\u8f93\u5165\u7684\u4e00\u4e2afeature\u3002 \u5c06\u591a\u5e27\u70b9\u4e91\u8f6c\u6362\u5230\u540c\u4e00\u4e2a\u5750\u6807\u7cfb\u4e2d\uff0c\u6bcf\u4e00\u5e27\u53ef\u4ee5\u5355\u72ec\u5f62\u6210\u4e00\u4e2a3D Tensor\uff0c\u7ed3\u5408\u8d77\u6765\u6210\u4e3a\u4e00\u4e2a4D Tensor","title":"\u70b9\u4e91\u4fe1\u606f\u7684\u5904\u7406\u529e\u6cd5"},{"location":"papers/Fast and Furious Real Time End-to-End 3D Detection, Tracking and MotionForecasting with a Single Convolutional Net/#_2","text":"\u7b2c\u4e00\u79cd\u65b9\u6cd5\u662fEarly Fusion,\u5728\u4e00\u5f00\u59cb\u5c31\u4f7f\u75281D Conv\u5c06\u591a\u4e2aCostmap\u7ed3\u5408\u6210\u4e00\u4e2aCostmap \u7b2c\u4e8c\u79cd\u65b9\u6cd5\u662fLate Fusion,\u4f7f\u75283D Conv\u5206\u4e24\u6b65\u7ed3\u5408\u3002","title":"\u878d\u5408\u65f6\u5e8f\u4fe1\u606f\u7684\u65b9\u6cd5"},{"location":"papers/Fast and Furious Real Time End-to-End 3D Detection, Tracking and MotionForecasting with a Single Convolutional Net/#bounding-box","text":"\u76f4\u63a5\u8f93\u51fa\u4e00\u7cfb\u5217\u7684bounding box\u548c\u79cd\u7c7b\u4fe1\u606f","title":"\u8f93\u51fabounding box \u4ee5\u53ca\u9884\u6d4b"},{"location":"papers/Gated2Depth:_Real-Time_Dense_Lidar_From_Gated_Images/","text":"Gated2Depth: Real-Time Dense Lidar From Gated Images \u8fd9\u7bc7\u8bba\u6587\u4f7f\u7528Gated Image\u4f30\u8ba1\u7a20\u5bc6\u7684\u6df1\u5ea6\u56fe\u3002\u4eae\u70b9\u6709\u51e0\u4e2a\uff0c\u9996\u5148\u662f\u5bf9Gate Imaging\u7684\u539f\u7406\u8ba4\u8bc6\u4ee5\u53ca\u4f7f\u7528\uff0c\u5176\u6b21\u662f\u5176\u7528\u7a00\u758f\u70b9\u4e91\u4f5c\u4e3a\u76d1\u7763\u6765\u6e90\uff0c\u8fdb\u884c\u534a\u76d1\u7763\u7684\u5b66\u4e60. Gated Imaging\u57fa\u672c\u539f\u7406 Gated camera\u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u4e3b\u52a8\u7684TOF\u76f8\u673a\uff0c\u4e0e\u6fc0\u5149\u6e90\u65f6\u95f4\u540c\u6b65\uff0c\u7cfb\u7edf\u53ef\u4ee5\u63a7\u5236\u76f8\u673a\u7684\u5feb\u95e8\u63a5\u53d7\u5149\u7167\u7684\u65f6\u95f4\uff0c\u5982\u4e0a\u56fe\uff0c\u6bcf\u4e00\u5f20\u56fe\u91cc\u9762\u53ea\u4f1a\u663e\u793a\u4e00\u4e2a\u8ddd\u79bb\u533a\u95f4\u5185\u7684\u7269\u4f53\uff0c\u800c\u6bcf\u4e00\u5f20\u56fe\u4e2d\u6bcf\u4e00\u4e2a\u50cf\u7d20\u7684\u6570\u503c\u4ee3\u8868\u5bf9\u5e94\u50cf\u7d20\u7684\u53cd\u5c04\u7684\u6fc0\u5149\u5f3a\u5ea6\u3002 \u66f4\u591a\u4fe1\u606f\u53ef\u4ee5\u770b NIT\u7684\u4ea7\u54c1pdf \u4ee5\u53ca wiki\u9875\u9762 Depth Learning Pipeline \u8f93\u5165\u5230\u7f51\u7edc\u7684\u8f93\u5165\u662f3\u5c42\u7684\u539f\u59cbgated image.\u4f7f\u7528\u751f\u6210\u7f51\u7edc G \u8f93\u51fa\u591a\u5c3a\u5bf8\u7684\u6df1\u5ea6\u4f30\u8ba1\u56fe\uff0c\u7ed3\u6784\u91c7\u7528\u7684\u662f\u7ecf\u5178\u7684 Unet(pdf) \uff0c\u6709\u4e09\u4e2aloss\u51fd\u6570\u3002\u5176\u4e2d\u7b2c\u4e00\u4e2a\u635f\u5931\u662f \\mathcal{L}_{mult} \u662f\u7a00\u758f\u7684\uff0c\u7528\u7a00\u758f\u7684\u6fc0\u5149\u96f7\u8fbe\u70b9\u4e91\u56fe\u8fdb\u884c\u76d1\u7763\u3002\u540e\u4e24\u4e2aloss\u5728\u540e\u6587\u63cf\u8ff0 \u56fe\u4e2d\u6709\u4e00\u4e2a\u5206\u7c7b\u5668D,\u7c7b\u4f3c\u4e8ePathchGAN. \u5728\u7b2c\u4e00\u4e2a\u8bad\u7ec3\u9636\u6bb5\uff0c\u672c\u6587\u7528\u4eff\u771f\u5408\u6210\u7684\u6570\u636e\u7528\u7c7b\u4f3cLeast-square GAN\u7684\u65b9\u5f0f\uff0c\u8ba9\u8fd9\u4e2a\u5206\u7c7b\u5668\u7f51\u7edc\u5224\u65ad\u4e00\u5f20\u6df1\u5ea6\u56fe\u662f\u6765\u81ea\u4e8e\u5408\u6210\u7684\u6b63\u786e\u56fe\u8fd8\u662f\u6765\u81ea\u4e8eGenerator\u7684\u8f93\u51fa\u3002 \u7b2c\u4e8c\u4e2a\u9636\u6bb5\uff0c\u672c\u6587\u7528\u771f\u5b9egated image,\u7136\u540e\u4fdd\u6301\u5206\u7c7b\u5668\u56fa\u5b9a\uff0c\u540c\u65f6\u7528\u6fc0\u5149\u96f7\u8fbe\u70b9\u4e91\u8fdb\u884c\u76d1\u7763\u8bad\u7ec3, \u635f\u5931\u51fd\u6570 \\mathcal{L} = \\mathcal{L}_{mult} + \\lambda_s \\mathcal{L}_{smooth} + \\lambda_a \\mathcal{L}_{adv} \u76f4\u63a5\u76d1\u7763 \\mathcal{L}_{\\mathrm{mult}}(d, \\tilde{d})=\\sum_{i=1}^{M} \\lambda_{m_{i}} \\mathcal{L}_{\\mathrm{Ll}}\\left(d^{(i)}, \\tilde{d}^{(i)}\\right) \u5176\u4e2d d^{(i)} \u8fd8\u6709 \\tilde{d}^{(i)} \u6307\u4ee3\u5728 scale (i), \\mathcal{L}_{L1} \u6307\u5728\u5bf9\u5e94\u5c3a\u5ea6\u4e0a\u7684\u635f\u5931\u3002\u6bcf\u4e00\u4e2a\u5c3a\u5ea6\u90fd\u662f\u4f7f\u7528 L_1 \u635f\u5931 \u5728\u4f7f\u7528\u5408\u6210\u8bad\u7ec3\u96c6\u8bad\u7ec3\u65f6\uff0c\u6240\u6709\u50cf\u7d20\u90fd\u6709\u5bf9\u5e94\u7684\u8bef\u5dee\u503c\u3002\u5728\u4f7f\u7528\u5b9e\u9645\u7684\u635f\u5931\u51fd\u6570\u65f6\uff0c\u53ea\u6709\u90e8\u5206\u50cf\u7d20\u6709\u76d1\u7763\uff0c\u5982\u4e0b \\mathcal{L}_{\\mathrm{LI}}\\left(d^{(i)}, \\tilde{d}^{(i)}\\right)=\\frac{1}{N} \\sum_{j, k}\\left|d_{j k}^{(i)}-\\tilde{d}_{j k}^{(i)}\\right| m_{j k}^{(i)} \u5149\u6ed1\u635f\u5931 \\mathcal{L}_{\\text {smooth }}=\\frac{1}{N} \\sum_{i, j}\\left|\\partial_{x} d_{i, j}\\right| \\epsilon^{-\\left|\\partial_{x} z_{i, j}\\right|}+\\left|\\partial_{y} d_{i, j}\\right| \\epsilon^{-\\left|\\partial_{y} z_{i, j}\\right|} \u5176\u4e2d z \u4e3a\u8f93\u5165\u56fe\u7247\u7684\u5f3a\u5ea6\u503c\uff0c d \u662f\u6df1\u5ea6\u503c\uff0c \u5bf9\u6297\u635f\u5931 \\begin{aligned} \\mathcal{L}_{\\mathrm{adv}}=& \\frac{1}{2} \\mathbb{E}_{y \\sim p_{\\mathrm{depth}}(y)}\\left[(D(y)-1)^{2}\\right]+\\\\ & \\frac{1}{2} \\mathbb{E}_{x \\sim p_{\\mathrm{gated}}(x)}\\left[(D(G(x)))^{2}\\right] \\end{aligned}","title":"Gated2Depth: Real-Time Dense Lidar From Gated Images"},{"location":"papers/Gated2Depth:_Real-Time_Dense_Lidar_From_Gated_Images/#gated2depth-real-time-dense-lidar-from-gated-images","text":"\u8fd9\u7bc7\u8bba\u6587\u4f7f\u7528Gated Image\u4f30\u8ba1\u7a20\u5bc6\u7684\u6df1\u5ea6\u56fe\u3002\u4eae\u70b9\u6709\u51e0\u4e2a\uff0c\u9996\u5148\u662f\u5bf9Gate Imaging\u7684\u539f\u7406\u8ba4\u8bc6\u4ee5\u53ca\u4f7f\u7528\uff0c\u5176\u6b21\u662f\u5176\u7528\u7a00\u758f\u70b9\u4e91\u4f5c\u4e3a\u76d1\u7763\u6765\u6e90\uff0c\u8fdb\u884c\u534a\u76d1\u7763\u7684\u5b66\u4e60.","title":"Gated2Depth: Real-Time Dense Lidar From Gated Images"},{"location":"papers/Gated2Depth:_Real-Time_Dense_Lidar_From_Gated_Images/#gated-imaging","text":"Gated camera\u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u4e3b\u52a8\u7684TOF\u76f8\u673a\uff0c\u4e0e\u6fc0\u5149\u6e90\u65f6\u95f4\u540c\u6b65\uff0c\u7cfb\u7edf\u53ef\u4ee5\u63a7\u5236\u76f8\u673a\u7684\u5feb\u95e8\u63a5\u53d7\u5149\u7167\u7684\u65f6\u95f4\uff0c\u5982\u4e0a\u56fe\uff0c\u6bcf\u4e00\u5f20\u56fe\u91cc\u9762\u53ea\u4f1a\u663e\u793a\u4e00\u4e2a\u8ddd\u79bb\u533a\u95f4\u5185\u7684\u7269\u4f53\uff0c\u800c\u6bcf\u4e00\u5f20\u56fe\u4e2d\u6bcf\u4e00\u4e2a\u50cf\u7d20\u7684\u6570\u503c\u4ee3\u8868\u5bf9\u5e94\u50cf\u7d20\u7684\u53cd\u5c04\u7684\u6fc0\u5149\u5f3a\u5ea6\u3002 \u66f4\u591a\u4fe1\u606f\u53ef\u4ee5\u770b NIT\u7684\u4ea7\u54c1pdf \u4ee5\u53ca wiki\u9875\u9762","title":"Gated Imaging\u57fa\u672c\u539f\u7406"},{"location":"papers/Gated2Depth:_Real-Time_Dense_Lidar_From_Gated_Images/#depth-learning-pipeline","text":"\u8f93\u5165\u5230\u7f51\u7edc\u7684\u8f93\u5165\u662f3\u5c42\u7684\u539f\u59cbgated image.\u4f7f\u7528\u751f\u6210\u7f51\u7edc G \u8f93\u51fa\u591a\u5c3a\u5bf8\u7684\u6df1\u5ea6\u4f30\u8ba1\u56fe\uff0c\u7ed3\u6784\u91c7\u7528\u7684\u662f\u7ecf\u5178\u7684 Unet(pdf) \uff0c\u6709\u4e09\u4e2aloss\u51fd\u6570\u3002\u5176\u4e2d\u7b2c\u4e00\u4e2a\u635f\u5931\u662f \\mathcal{L}_{mult} \u662f\u7a00\u758f\u7684\uff0c\u7528\u7a00\u758f\u7684\u6fc0\u5149\u96f7\u8fbe\u70b9\u4e91\u56fe\u8fdb\u884c\u76d1\u7763\u3002\u540e\u4e24\u4e2aloss\u5728\u540e\u6587\u63cf\u8ff0 \u56fe\u4e2d\u6709\u4e00\u4e2a\u5206\u7c7b\u5668D,\u7c7b\u4f3c\u4e8ePathchGAN. \u5728\u7b2c\u4e00\u4e2a\u8bad\u7ec3\u9636\u6bb5\uff0c\u672c\u6587\u7528\u4eff\u771f\u5408\u6210\u7684\u6570\u636e\u7528\u7c7b\u4f3cLeast-square GAN\u7684\u65b9\u5f0f\uff0c\u8ba9\u8fd9\u4e2a\u5206\u7c7b\u5668\u7f51\u7edc\u5224\u65ad\u4e00\u5f20\u6df1\u5ea6\u56fe\u662f\u6765\u81ea\u4e8e\u5408\u6210\u7684\u6b63\u786e\u56fe\u8fd8\u662f\u6765\u81ea\u4e8eGenerator\u7684\u8f93\u51fa\u3002 \u7b2c\u4e8c\u4e2a\u9636\u6bb5\uff0c\u672c\u6587\u7528\u771f\u5b9egated image,\u7136\u540e\u4fdd\u6301\u5206\u7c7b\u5668\u56fa\u5b9a\uff0c\u540c\u65f6\u7528\u6fc0\u5149\u96f7\u8fbe\u70b9\u4e91\u8fdb\u884c\u76d1\u7763\u8bad\u7ec3,","title":"Depth Learning Pipeline"},{"location":"papers/Gated2Depth:_Real-Time_Dense_Lidar_From_Gated_Images/#_1","text":"\\mathcal{L} = \\mathcal{L}_{mult} + \\lambda_s \\mathcal{L}_{smooth} + \\lambda_a \\mathcal{L}_{adv}","title":"\u635f\u5931\u51fd\u6570"},{"location":"papers/Gated2Depth:_Real-Time_Dense_Lidar_From_Gated_Images/#_2","text":"\\mathcal{L}_{\\mathrm{mult}}(d, \\tilde{d})=\\sum_{i=1}^{M} \\lambda_{m_{i}} \\mathcal{L}_{\\mathrm{Ll}}\\left(d^{(i)}, \\tilde{d}^{(i)}\\right) \u5176\u4e2d d^{(i)} \u8fd8\u6709 \\tilde{d}^{(i)} \u6307\u4ee3\u5728 scale (i), \\mathcal{L}_{L1} \u6307\u5728\u5bf9\u5e94\u5c3a\u5ea6\u4e0a\u7684\u635f\u5931\u3002\u6bcf\u4e00\u4e2a\u5c3a\u5ea6\u90fd\u662f\u4f7f\u7528 L_1 \u635f\u5931 \u5728\u4f7f\u7528\u5408\u6210\u8bad\u7ec3\u96c6\u8bad\u7ec3\u65f6\uff0c\u6240\u6709\u50cf\u7d20\u90fd\u6709\u5bf9\u5e94\u7684\u8bef\u5dee\u503c\u3002\u5728\u4f7f\u7528\u5b9e\u9645\u7684\u635f\u5931\u51fd\u6570\u65f6\uff0c\u53ea\u6709\u90e8\u5206\u50cf\u7d20\u6709\u76d1\u7763\uff0c\u5982\u4e0b \\mathcal{L}_{\\mathrm{LI}}\\left(d^{(i)}, \\tilde{d}^{(i)}\\right)=\\frac{1}{N} \\sum_{j, k}\\left|d_{j k}^{(i)}-\\tilde{d}_{j k}^{(i)}\\right| m_{j k}^{(i)}","title":"\u76f4\u63a5\u76d1\u7763"},{"location":"papers/Gated2Depth:_Real-Time_Dense_Lidar_From_Gated_Images/#_3","text":"\\mathcal{L}_{\\text {smooth }}=\\frac{1}{N} \\sum_{i, j}\\left|\\partial_{x} d_{i, j}\\right| \\epsilon^{-\\left|\\partial_{x} z_{i, j}\\right|}+\\left|\\partial_{y} d_{i, j}\\right| \\epsilon^{-\\left|\\partial_{y} z_{i, j}\\right|} \u5176\u4e2d z \u4e3a\u8f93\u5165\u56fe\u7247\u7684\u5f3a\u5ea6\u503c\uff0c d \u662f\u6df1\u5ea6\u503c\uff0c","title":"\u5149\u6ed1\u635f\u5931"},{"location":"papers/Gated2Depth:_Real-Time_Dense_Lidar_From_Gated_Images/#_4","text":"\\begin{aligned} \\mathcal{L}_{\\mathrm{adv}}=& \\frac{1}{2} \\mathbb{E}_{y \\sim p_{\\mathrm{depth}}(y)}\\left[(D(y)-1)^{2}\\right]+\\\\ & \\frac{1}{2} \\mathbb{E}_{x \\sim p_{\\mathrm{gated}}(x)}\\left[(D(G(x)))^{2}\\right] \\end{aligned}","title":"\u5bf9\u6297\u635f\u5931"},{"location":"papers/Gaussian_YOLOv3:_An_Accurate_and_Fast_Object_Detector_Using_Localization_Uncertainty_for_Autonomous_Driving/","text":"Gaussian YOLOv3: An Accurate and Fast Object Detector Using Localization Uncertainty for Autonomous Driving \u8fd9\u7bc7\u8bba\u6587\u5f15\u5165\u4e86Gaussian Yolov3,\u5728inference\u4e2d\u9884\u6d4b\u5b9a\u4f4d\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u51cf\u5c11\u4e86False Positive,\u4ee5\u63d0\u5347\u70b9\u6570\u3002\u8fd9\u4e2a\u8bba\u6587\u7684\u4e3b\u8981\u601d\u8def\u8d21\u732e\u5728\u4e8e\uff0c\u5728inference\u7684\u65f6\u5019\u901a\u8fc7\u5bf9\u8fb9\u6846\u7684\u4e0d\u786e\u5b9a\u6027\u7684\u4f30\u8ba1\u4fee\u6b63inference\u65f6\u7684\u4f30\u8ba1\u3002\u4f7f\u5f97NMS\u65f6\u4f1a\u771f\u6b63\u9009\u62e9\u5bf9\u4f4d\u7f6e\u786e\u5b9a\u6027\u6700\u9ad8\u7684\u6846\u3002 Gaussian Yolov3 \u7ed3\u6784 Yolov3\u56de\u5f52\u8f93\u51fa\u7684bbox\u7ed3\u6784\u5305\u62ec t_x, t_y, t_w, t_h ,\u8fd9\u6837\u53ef\u4ee5\u7528\u9ad8\u65af\u6a21\u578b\u6765\u4f30\u8ba1\u3002\u672c\u6587\u7684\u7b97\u6cd5\u8f93\u5165\u5982\u56fe \u8f93\u51fa\u7ed3\u6784 \\begin{aligned} \\mu_{t_{x}}=\\sigma\\left(\\hat{\\mu}_{t_{x}}\\right), \\mu_{t_{y}} &=\\sigma\\left(\\hat{\\mu}_{t_{y}}\\right), \\mu_{t_{w}}=\\hat{\\mu}_{t_{w}}, \\mu_{t_{h}}=\\hat{\\mu}_{t_{h}} \\\\ \\Sigma_{t_{x}} &=\\sigma\\left(\\hat{\\Sigma}_{t_{x}}\\right), \\Sigma_{t_{y}}=\\sigma\\left(\\hat{\\Sigma}_{t_{y}}\\right) \\\\ \\Sigma_{t_{w}} &=\\sigma\\left(\\hat{\\Sigma}_{t_{w}}\\right), \\Sigma_{t_{h}}=\\sigma\\left(\\hat{\\Sigma}_{t_{h}}\\right) \\\\ \\sigma(x) &=\\frac{1}{(1+\\exp (-x))} \\end{aligned} \u635f\u5931\u51fd\u6570 \u8fd9\u91cc\u7528negative log likelihood\u635f\u5931 \\begin{aligned} L_x = - \\sum_{i=1}^W \\sum_{j=1}^H \\sum_{k=1}^K \\gamma_{ijk}log(N&(x^G_{jik}|\\mu_{t_x}(x_{ijk}))),\\\\ &\\sum_{t_x}(x_{ijk})) + \\epsilon) \\end{aligned} \u5176\u4e2dW,H,\u4e3agrids\u8f93\u51fa,K\u662fanchors\u7684\u6570\u91cf. inference \u5f53\u8f93\u51fa\u7684\u65f6\u5019,inference\u65f6\u5c06\u5404\u4e2aindex\u7684\u4e0d\u786e\u5b9a\u6027\u53d6\u5747\u503c\uff0c\u8fd9\u6837\u4f1a\u5bf9\u7c7b\u522b\u7684class score,\u4f1a\u5f62\u6210\u5f71\u54cd. C r .=\\sigma(\\text {Object}) \\times \\sigma\\left(\\text {Class}_{i}\\right) \\times\\left(1-\\text {Uncertainty}_{\\text {aver}}\\right)","title":"Gaussian YOLOv3: An Accurate and Fast Object Detector Using Localization Uncertainty for Autonomous Driving"},{"location":"papers/Gaussian_YOLOv3:_An_Accurate_and_Fast_Object_Detector_Using_Localization_Uncertainty_for_Autonomous_Driving/#gaussian-yolov3-an-accurate-and-fast-object-detector-using-localization-uncertainty-for-autonomous-driving","text":"\u8fd9\u7bc7\u8bba\u6587\u5f15\u5165\u4e86Gaussian Yolov3,\u5728inference\u4e2d\u9884\u6d4b\u5b9a\u4f4d\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u51cf\u5c11\u4e86False Positive,\u4ee5\u63d0\u5347\u70b9\u6570\u3002\u8fd9\u4e2a\u8bba\u6587\u7684\u4e3b\u8981\u601d\u8def\u8d21\u732e\u5728\u4e8e\uff0c\u5728inference\u7684\u65f6\u5019\u901a\u8fc7\u5bf9\u8fb9\u6846\u7684\u4e0d\u786e\u5b9a\u6027\u7684\u4f30\u8ba1\u4fee\u6b63inference\u65f6\u7684\u4f30\u8ba1\u3002\u4f7f\u5f97NMS\u65f6\u4f1a\u771f\u6b63\u9009\u62e9\u5bf9\u4f4d\u7f6e\u786e\u5b9a\u6027\u6700\u9ad8\u7684\u6846\u3002","title":"Gaussian YOLOv3: An Accurate and Fast Object Detector Using Localization Uncertainty for Autonomous Driving"},{"location":"papers/Gaussian_YOLOv3:_An_Accurate_and_Fast_Object_Detector_Using_Localization_Uncertainty_for_Autonomous_Driving/#gaussian-yolov3","text":"Yolov3\u56de\u5f52\u8f93\u51fa\u7684bbox\u7ed3\u6784\u5305\u62ec t_x, t_y, t_w, t_h ,\u8fd9\u6837\u53ef\u4ee5\u7528\u9ad8\u65af\u6a21\u578b\u6765\u4f30\u8ba1\u3002\u672c\u6587\u7684\u7b97\u6cd5\u8f93\u5165\u5982\u56fe","title":"Gaussian Yolov3 \u7ed3\u6784"},{"location":"papers/Gaussian_YOLOv3:_An_Accurate_and_Fast_Object_Detector_Using_Localization_Uncertainty_for_Autonomous_Driving/#_1","text":"\\begin{aligned} \\mu_{t_{x}}=\\sigma\\left(\\hat{\\mu}_{t_{x}}\\right), \\mu_{t_{y}} &=\\sigma\\left(\\hat{\\mu}_{t_{y}}\\right), \\mu_{t_{w}}=\\hat{\\mu}_{t_{w}}, \\mu_{t_{h}}=\\hat{\\mu}_{t_{h}} \\\\ \\Sigma_{t_{x}} &=\\sigma\\left(\\hat{\\Sigma}_{t_{x}}\\right), \\Sigma_{t_{y}}=\\sigma\\left(\\hat{\\Sigma}_{t_{y}}\\right) \\\\ \\Sigma_{t_{w}} &=\\sigma\\left(\\hat{\\Sigma}_{t_{w}}\\right), \\Sigma_{t_{h}}=\\sigma\\left(\\hat{\\Sigma}_{t_{h}}\\right) \\\\ \\sigma(x) &=\\frac{1}{(1+\\exp (-x))} \\end{aligned}","title":"\u8f93\u51fa\u7ed3\u6784"},{"location":"papers/Gaussian_YOLOv3:_An_Accurate_and_Fast_Object_Detector_Using_Localization_Uncertainty_for_Autonomous_Driving/#_2","text":"\u8fd9\u91cc\u7528negative log likelihood\u635f\u5931 \\begin{aligned} L_x = - \\sum_{i=1}^W \\sum_{j=1}^H \\sum_{k=1}^K \\gamma_{ijk}log(N&(x^G_{jik}|\\mu_{t_x}(x_{ijk}))),\\\\ &\\sum_{t_x}(x_{ijk})) + \\epsilon) \\end{aligned} \u5176\u4e2dW,H,\u4e3agrids\u8f93\u51fa,K\u662fanchors\u7684\u6570\u91cf.","title":"\u635f\u5931\u51fd\u6570"},{"location":"papers/Gaussian_YOLOv3:_An_Accurate_and_Fast_Object_Detector_Using_Localization_Uncertainty_for_Autonomous_Driving/#inference","text":"\u5f53\u8f93\u51fa\u7684\u65f6\u5019,inference\u65f6\u5c06\u5404\u4e2aindex\u7684\u4e0d\u786e\u5b9a\u6027\u53d6\u5747\u503c\uff0c\u8fd9\u6837\u4f1a\u5bf9\u7c7b\u522b\u7684class score,\u4f1a\u5f62\u6210\u5f71\u54cd. C r .=\\sigma(\\text {Object}) \\times \\sigma\\left(\\text {Class}_{i}\\right) \\times\\left(1-\\text {Uncertainty}_{\\text {aver}}\\right)","title":"inference"},{"location":"papers/Gaze  Training  by  Modulated  Dropout  Improves  Imitation  Learning/","text":"Gaze Training by Modulated Dropout Improves Imitation Learning \u8fd9\u7bc7\u8bba\u6587\u6e90\u81ea\u4e8e\u5b9e\u9a8c\u5ba4\u5e08\u59d0\u3002 \u6838\u5fc3\u8d21\u732e\uff0c\u7528encoder-decoder\u8bad\u7ec3\u4e00\u4e2aGaze_map\u751f\u6210\u7f51\u7edc(\u6570\u636e\u6765\u81ea\u4e8e\u4eba\u5de5\u6807\u6ce8),\u7136\u540e\u5728\u6a21\u4eff\u5b66\u4e60\u7684\u65f6\u5019\u4f7f\u7528Gaze-modulated Dropout,\u8fd9\u4e2a\u6a21\u5757\u7684\u601d\u8def\u662f\u5728\u4f7f\u7528dropout\u7684\u65f6\u5019\uff0c\u51cf\u5c11gaze_map\u76f8\u5173\u90e8\u5206\u7684dropout\uff0c\u5c31\u50cf\u4eba\u773c\u6ce8\u89c6\u5355\u4e00\u533a\u57df\u4e00\u6837\u3002\u6ce8\u610f\u8fd9\u91cc\u4f7f\u7528\u7684dropout\u662ftensorflow\u9ed8\u8ba4\u7248\u672c\u7684dropout\u800c\u4e0d\u662fpytorch\u9ed8\u8ba4\u7684dropout2d(spatial-dropout).","title":"Gaze  Training  by  Modulated  Dropout  Improves  Imitation  Learning"},{"location":"papers/Gaze  Training  by  Modulated  Dropout  Improves  Imitation  Learning/#gaze-training-by-modulated-dropout-improves-imitation-learning","text":"\u8fd9\u7bc7\u8bba\u6587\u6e90\u81ea\u4e8e\u5b9e\u9a8c\u5ba4\u5e08\u59d0\u3002 \u6838\u5fc3\u8d21\u732e\uff0c\u7528encoder-decoder\u8bad\u7ec3\u4e00\u4e2aGaze_map\u751f\u6210\u7f51\u7edc(\u6570\u636e\u6765\u81ea\u4e8e\u4eba\u5de5\u6807\u6ce8),\u7136\u540e\u5728\u6a21\u4eff\u5b66\u4e60\u7684\u65f6\u5019\u4f7f\u7528Gaze-modulated Dropout,\u8fd9\u4e2a\u6a21\u5757\u7684\u601d\u8def\u662f\u5728\u4f7f\u7528dropout\u7684\u65f6\u5019\uff0c\u51cf\u5c11gaze_map\u76f8\u5173\u90e8\u5206\u7684dropout\uff0c\u5c31\u50cf\u4eba\u773c\u6ce8\u89c6\u5355\u4e00\u533a\u57df\u4e00\u6837\u3002\u6ce8\u610f\u8fd9\u91cc\u4f7f\u7528\u7684dropout\u662ftensorflow\u9ed8\u8ba4\u7248\u672c\u7684dropout\u800c\u4e0d\u662fpytorch\u9ed8\u8ba4\u7684dropout2d(spatial-dropout).","title":"Gaze  Training  by  Modulated  Dropout  Improves  Imitation  Learning"},{"location":"papers/Joint_Unsupervised_Learning_of_Optical_Flow_and_Depth_by_Watching_Stereo_Videos/","text":"Joint Unsupervised Learning of Optical Flow and Depth by Watching Stereo Videos \u6b63\u5982\u9898\u76ee\u8868\u793a\uff0c\u672c\u6587\u7684\u76ee\u6807\u662f\u4f7f\u7528\u8fde\u7eed\u7684\u53cc\u76ee\u89c6\u9891\uff0c\u540c\u65f6\u9884\u6d4b\u5149\u6d41\u3001\u6df1\u5ea6\u4ee5\u53ca\u76f8\u673a\u8fd0\u52a8\u3002\u5927\u5e45\u5ea6\u91cd\u7528\u524d\u4eba\u7684\u7814\u7a76\uff0c\u7279\u70b9\u662f\u6ce8\u91cd\u5bf9\u8fd0\u52a8\u4ee5\u53ca\u906e\u6321\u7269\u4f53\u7684\u53bb\u9664 \u4e3b\u4f53\u6d41\u7a0b\u56fe \u8fd9\u4e2apipeline\u5206\u4e3a\u597d\u51e0\u4e2astages \u9996\u5148\uff0c\u7528PWC-Flow\u9884\u6d4b\u5de6\u76ee\u76f8\u673a\u7684\u4e24\u5f20\u56fe\u4e4b\u95f4\u7684\u5149\u6d41 F_{12}^{opt} \uff0c\u7528MotionNet\u9884\u6d4b\u5de6\u76ee\u76f8\u673a\u4e24\u5f20\u56fe\u4e4b\u95f4\u7684\u8fd0\u52a8 T_{12} , \u7528PWD-Disp\u4f30\u8ba1\u53cc\u76ee\u76f8\u673a\u4e4b\u95f4\u7684\u89c6\u5dee\uff0c\u7528\u89c6\u5dee\u53ef\u4ee5\u8f6c\u6362\u4e3a\u6df1\u5ea6 D = B f_x / d \u3002 \u7b2c\u4e8c\uff0c\u7ed3\u5408 D_1, T_{12} \uff0c\u6211\u4eec\u53ef\u4ee5\u8ba1\u7b97\u51fa\u56e0\u76f8\u673a\u521a\u4f53\u8fd0\u52a8\u800c\u4ea7\u751f\u7684\u5149\u6d41\uff0c\u8bb0\u4e3a F^{rig}_{12} \uff0c\u56fe\u4e2d\u672a\u5448\u73b0\u3002\u7136\u540erigid-alignment module\u5c06\u76f8\u673a\u8fd0\u52a8\u4ece T_{12} \u7cbe\u4fee\u4e3a T_{12}' ,\u5e76\u8fdb\u4e00\u6b65\u5f97\u5230\u7cbe\u4fee\u7684 F^{rig'}_{12} \u7b2c\u4e09\uff0cConsistency check\u53bb\u9664\u8fd0\u52a8\u533a\u57df\u3002 \u7b2c\u4e00\u3001\u7f51\u7edc\u7ed3\u6784 PWC-Flow\u6309\u7167 \u8fd9\u7bc7\u6587\u7ae0 \u7684 \u4ecb\u7ecd MotionNet\u6309\u7167 \u8fd9\u7bc7\u6587\u7ae0 \u7684 \u4ecb\u7ecd PWC-Disp\u4ecePWC-Flow\u66f4\u6539\uff0c\u5728Cost volumn\u8ba1\u7b97\u7684\u65f6\u5019\u5f3a\u8feb\u5b83\u53ea\u5728\u6c34\u5e73\u65b9\u5411\u4e0a\u641c\u7d22\uff0c\u8f93\u51fa\u5f62\u72b6\u81ea\u7136\u53d8\u6210\u4e86 d\\times H \\times W \u7b2c\u4e8c\u3001Rigid Alighment Module \u8fd9\u4e2a\u6a21\u5757\u76ee\u6807\u662f\u7b2c\u4e00\u6b65\u7cbe\u4fee \u9996\u5148\u901a\u8fc7 Q_t(i,j) = D_t(i,j) K^{-1P_t(i,j)} \u5c06\u5f53\u524d\u56fe\u50cf\u8f6c\u6362\u4e3a\u76f8\u673a\u5750\u6807\u7cfb\uff0c3D\u7a7a\u95f4\u4e2d\u7684\u70b9\uff0c\u7136\u540e\u4f7f\u7528 T_{12} \u8f6c\u6362\uff0c\u5f97\u5230\u5bf9\u5e94\u70b9\u5728\u7b2c\u4e8c\u65f6\u523b\u76f8\u673a\u5750\u6807\u7cfb\u4e2d\u7684\u70b9 \\hat Q_1 \u3002 \\widetilde Q_1 \u5219\u8868\u793a Q_2 \u901a\u8fc7\u5149\u6d41 F^{opt}_{12} \u56de\u5230\u7b2c\u4e00\u65f6\u523b\u7684\u5750\u6807\uff0c \u901a\u8fc7\u6c42\u89e3\u4ee5\u4e0a\u4e24\u4e2a\u6b65\u9aa4\uff0c\u53ef\u4ee5\u5f97\u5230\u7cbe\u4fee\u7684T \u7b2c\u4e09\u3001Consistent Check \u7cbe\u4fee\u7684rigid\u5149\u6d41\u4e0e\u7f51\u7edc\u5149\u6d41\u7684\u5dee\u4e2d\uff0c\u503c\u8fc7\u5927\u6216\u8005\u88ab\u906e\u6321\u7684\u90e8\u5206\u4f1a\u88ab\u8fc7\u6ee4\u6389\uff0c\u4f7f\u7528thresholding\u7ed9\u51fa\u4e00\u4e2amask\uff0c\u53ea\u6709mask\u4e2d\u8ba4\u4e3a\u662f\u9759\u6b62\u7269\u4f53\u7684\u624d\u4f1a\u8fdb\u884closs\u8ba1\u7b97\u3002","title":"Joint Unsupervised Learning of Optical Flow and Depth by Watching Stereo Videos"},{"location":"papers/Joint_Unsupervised_Learning_of_Optical_Flow_and_Depth_by_Watching_Stereo_Videos/#joint-unsupervised-learning-of-optical-flow-and-depth-by-watching-stereo-videos","text":"\u6b63\u5982\u9898\u76ee\u8868\u793a\uff0c\u672c\u6587\u7684\u76ee\u6807\u662f\u4f7f\u7528\u8fde\u7eed\u7684\u53cc\u76ee\u89c6\u9891\uff0c\u540c\u65f6\u9884\u6d4b\u5149\u6d41\u3001\u6df1\u5ea6\u4ee5\u53ca\u76f8\u673a\u8fd0\u52a8\u3002\u5927\u5e45\u5ea6\u91cd\u7528\u524d\u4eba\u7684\u7814\u7a76\uff0c\u7279\u70b9\u662f\u6ce8\u91cd\u5bf9\u8fd0\u52a8\u4ee5\u53ca\u906e\u6321\u7269\u4f53\u7684\u53bb\u9664","title":"Joint Unsupervised Learning of Optical Flow and Depth by Watching Stereo Videos"},{"location":"papers/Joint_Unsupervised_Learning_of_Optical_Flow_and_Depth_by_Watching_Stereo_Videos/#_1","text":"\u8fd9\u4e2apipeline\u5206\u4e3a\u597d\u51e0\u4e2astages \u9996\u5148\uff0c\u7528PWC-Flow\u9884\u6d4b\u5de6\u76ee\u76f8\u673a\u7684\u4e24\u5f20\u56fe\u4e4b\u95f4\u7684\u5149\u6d41 F_{12}^{opt} \uff0c\u7528MotionNet\u9884\u6d4b\u5de6\u76ee\u76f8\u673a\u4e24\u5f20\u56fe\u4e4b\u95f4\u7684\u8fd0\u52a8 T_{12} , \u7528PWD-Disp\u4f30\u8ba1\u53cc\u76ee\u76f8\u673a\u4e4b\u95f4\u7684\u89c6\u5dee\uff0c\u7528\u89c6\u5dee\u53ef\u4ee5\u8f6c\u6362\u4e3a\u6df1\u5ea6 D = B f_x / d \u3002 \u7b2c\u4e8c\uff0c\u7ed3\u5408 D_1, T_{12} \uff0c\u6211\u4eec\u53ef\u4ee5\u8ba1\u7b97\u51fa\u56e0\u76f8\u673a\u521a\u4f53\u8fd0\u52a8\u800c\u4ea7\u751f\u7684\u5149\u6d41\uff0c\u8bb0\u4e3a F^{rig}_{12} \uff0c\u56fe\u4e2d\u672a\u5448\u73b0\u3002\u7136\u540erigid-alignment module\u5c06\u76f8\u673a\u8fd0\u52a8\u4ece T_{12} \u7cbe\u4fee\u4e3a T_{12}' ,\u5e76\u8fdb\u4e00\u6b65\u5f97\u5230\u7cbe\u4fee\u7684 F^{rig'}_{12} \u7b2c\u4e09\uff0cConsistency check\u53bb\u9664\u8fd0\u52a8\u533a\u57df\u3002","title":"\u4e3b\u4f53\u6d41\u7a0b\u56fe"},{"location":"papers/Joint_Unsupervised_Learning_of_Optical_Flow_and_Depth_by_Watching_Stereo_Videos/#_2","text":"PWC-Flow\u6309\u7167 \u8fd9\u7bc7\u6587\u7ae0 \u7684 \u4ecb\u7ecd MotionNet\u6309\u7167 \u8fd9\u7bc7\u6587\u7ae0 \u7684 \u4ecb\u7ecd PWC-Disp\u4ecePWC-Flow\u66f4\u6539\uff0c\u5728Cost volumn\u8ba1\u7b97\u7684\u65f6\u5019\u5f3a\u8feb\u5b83\u53ea\u5728\u6c34\u5e73\u65b9\u5411\u4e0a\u641c\u7d22\uff0c\u8f93\u51fa\u5f62\u72b6\u81ea\u7136\u53d8\u6210\u4e86 d\\times H \\times W","title":"\u7b2c\u4e00\u3001\u7f51\u7edc\u7ed3\u6784"},{"location":"papers/Joint_Unsupervised_Learning_of_Optical_Flow_and_Depth_by_Watching_Stereo_Videos/#rigid-alighment-module","text":"\u8fd9\u4e2a\u6a21\u5757\u76ee\u6807\u662f\u7b2c\u4e00\u6b65\u7cbe\u4fee \u9996\u5148\u901a\u8fc7 Q_t(i,j) = D_t(i,j) K^{-1P_t(i,j)} \u5c06\u5f53\u524d\u56fe\u50cf\u8f6c\u6362\u4e3a\u76f8\u673a\u5750\u6807\u7cfb\uff0c3D\u7a7a\u95f4\u4e2d\u7684\u70b9\uff0c\u7136\u540e\u4f7f\u7528 T_{12} \u8f6c\u6362\uff0c\u5f97\u5230\u5bf9\u5e94\u70b9\u5728\u7b2c\u4e8c\u65f6\u523b\u76f8\u673a\u5750\u6807\u7cfb\u4e2d\u7684\u70b9 \\hat Q_1 \u3002 \\widetilde Q_1 \u5219\u8868\u793a Q_2 \u901a\u8fc7\u5149\u6d41 F^{opt}_{12} \u56de\u5230\u7b2c\u4e00\u65f6\u523b\u7684\u5750\u6807\uff0c \u901a\u8fc7\u6c42\u89e3\u4ee5\u4e0a\u4e24\u4e2a\u6b65\u9aa4\uff0c\u53ef\u4ee5\u5f97\u5230\u7cbe\u4fee\u7684T","title":"\u7b2c\u4e8c\u3001Rigid Alighment Module"},{"location":"papers/Joint_Unsupervised_Learning_of_Optical_Flow_and_Depth_by_Watching_Stereo_Videos/#consistent-check","text":"\u7cbe\u4fee\u7684rigid\u5149\u6d41\u4e0e\u7f51\u7edc\u5149\u6d41\u7684\u5dee\u4e2d\uff0c\u503c\u8fc7\u5927\u6216\u8005\u88ab\u906e\u6321\u7684\u90e8\u5206\u4f1a\u88ab\u8fc7\u6ee4\u6389\uff0c\u4f7f\u7528thresholding\u7ed9\u51fa\u4e00\u4e2amask\uff0c\u53ea\u6709mask\u4e2d\u8ba4\u4e3a\u662f\u9759\u6b62\u7269\u4f53\u7684\u624d\u4f1a\u8fdb\u884closs\u8ba1\u7b97\u3002","title":"\u7b2c\u4e09\u3001Consistent Check"},{"location":"papers/LO-Net: Deep Real-time Lidar Odometry/","text":"LO-Net: Deep Real-time Lidar Odometry \u8fd9\u7bc7\u6587\u7ae0\u4e3b\u8981\u6709\u4e09\u4e2a\u8d21\u732e\uff0c\u7b2c\u4e00\u63d0\u51fa\u4e86scan-to-scan lidar odometry\u7f51\u7edc\uff0c\u540c\u65f6\u4f30\u8ba1\u9762\u7684\u6cd5\u5411\u4ee5\u53camask for dynamic regions\u3002\u7b2c\u4e8c\u878d\u5408\u76f8\u90bb\u4e24\u5e27\u7f51\u7edc\u8fdb\u884c\u4f30\u8ba1\uff0c\u7b2c\u4e09\uff0c\u878d\u5408\u4e00\u4e2amapping module. \u6ce8\u610fGithub \u94fe\u63a5\u4ee3\u7801\u5c1a\u672a\u516c\u5e03\u3002 \u7f51\u7edc\u4e3b\u8981\u7ed3\u6784 \u6574\u4f53\u6765\u8bf4\uff0c\u7f51\u7edc\u7531\u4e09\u4e2a\u7f51\u7edc\u6784\u6210\uff0c\u5206\u522b\u662f\u6cd5\u5411\u4f30\u8ba1\u7f51\u7edc(point wise)\uff0cmask \u4f30\u8ba1\u7f51\u7edc\u4ee5\u53ca\u4e00\u4e2a\u5171\u7528\u53c2\u6570\u7684\u53cc\u751f\u59ff\u6001\u56de\u5f52\u4e3b\u7f51\u8def\u3002\u5b83\u4ee5\u4e24\u4e2a\u76f8\u90bb\u7684lidar\u70b9\u4f5c\u4e3a\u8f93\u5165\uff0c\u4f30\u8ba1\u51fa6\u81ea\u7531\u5ea6\u7684\u76f8\u5bf9\u8fd0\u52a8\u3001\u70b9\u4e91\u5404\u70b9\u7684\u9762\u6cd5\u5411\u4ee5\u53ca\u52a8\u6001\u533a\u57dfmask\u3002odometry\u7684\u8f93\u51fa\u4f1a\u901a\u8fc7mapping\u6a21\u5757\u8fdb\u4e00\u6b65\u63d0\u9ad8\uff0c\u6700\u7ec8\u7684\u8f93\u51fa\u4f1a\u662f\u76f8\u5bf9\u4e8e\u521d\u59cb\u4f4d\u7f6e\u7684\u504f\u79fb \u8f93\u5165\u7f16\u7801 \u4e3a\u4e86\u8ba9\u7f51\u7edc\u7684\u6570\u636e\u7f16\u6392\u53d8\u5f97\u7d27\u51d1\uff0c\u8fd9\u91cc\u4f7f\u7528\u5706\u67f1\u5750\u6807\u7cfb \\alpha = arctan(y/x)/\\Delta \\alpha \\beta = arcsin(z/\\sqrt{x^2+y^2 + z^2} / \u0394\u03b2) \u5982\u679c\u540c\u4e00\u4e2a \\alpha, \\beta \u5750\u6807\u6709\u4e0d\u6b62\u4e00\u4e2a\u70b9\uff0c\u5219\u4ee5\u6700\u8fd1\u7684\u70b9\u4e3a\u51c6\uff0c\u6bcf\u4e00\u4e2a\u70b9\u7684\u7279\u5f81\u5305\u62ec\u5f3a\u5ea6\u503c\u4ee5\u53ca\u8ddd\u79bb\u503c\u3002 \u51e0\u4f55\u7ea6\u675f \u6cd5\u5411\u4f30\u8ba1 \u4e25\u8c28\u6765\u8bf4\uff0c\u4ee5\u4e0a\u56fe\u4e3a\u4f8b\u5b50\uff0c\u70b9\u4e91\u7684\u6cd5\u5411\u5e94\u8be5\u7531\u70b9 X^i \u4ee5\u53ca\u5176 k \u4e2a\u76f8\u90bb\u7684\u70b9\uff0c\u7531\u4e0b\u5f0f\u5b9a\u4e49 \\argmin_{\\mathcal{N}(X^i)} ||[w_{i1}(X^{i_1}-X^i),...]^T\\mathcal{N}(X^i)||_2 \u4e5f\u5c31\u662f\u5bfb\u627e\u4e00\u4e2a\u77e2\u91cf\uff0c\u4f7f\u5f97\u8fd9\u4e2a\u77e2\u91cf\u4e0ek\u4e2a\u76f8\u90bb\u70b9\u77e2\u91cf\u7684\u70b9\u4e58\u7684\u52a0\u6743\u6c42\u548c\u503c(\u6216\u8005\u662f\u52a0\u6743\u8303\u6570)\u6700\u5c0f.\u4e00\u822c\u6765\u8bf4\u8ddd\u79bb\u8d8a\u8fd1\u6743\u91cd\u8d8a\u5927\uff0c\u8ddd\u79bb\u8d8a\u8fdc\u6743\u91cd\u8d8a\u5c0f\u3002 \u672c\u6587\u4e3a\u4e86\u7b80\u5316\u8fd9\u4e00\u8ba1\u7b97\uff0c\u4f7f\u7528\u4ee5\u4e0b\u65b9\u7a0b \\mathcal{N}(X^i) = \\sum_{X^{i_k}, X^{i_j} in \\mathcal{P}} (w_{ik}(X^{i_k} - X^i) \\times w_{ij}(X^{i_j} - X^i)) \u5176\u4e2d \\mathcal{P} \u4e3a\u5f53\u524d\u70b9\u7684\u4e34\u8fd1\u70b9\u3002 \u76f8\u90bb\u4e24\u7c07\u70b9\u4e91\u4e4b\u95f4\u6709\u4e00\u5b9a\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u4ee4 P \u4e3a\u6295\u5f71\u8fc7\u7a0b\u800c T_t \u4e3a\u76f8\u5bf9\u4f4d\u79fb\uff0c\u53ef\u4ee5\u627e\u5230\u70b9 X^{\\alpha \\beta}_{t-1} \u7684\u5bf9\u5e94\u70b9 \\hat X^{\\alpha \\beta}_t = P T_t P^{-1} X^{\\alpha\\beta}_{t-1} \u7531\u4e8e\u76f8\u5bf9\u5e94\u7684\u70b9\u6cd5\u5411\u4f30\u8ba1\u7406\u5e94\u6bd4\u8f83\u76f8\u4f3c\uff0c\u6240\u4ee5\u4e00\u4e2a\u7ea6\u675f\u662f \\mathcal{L}_n = \\sum_{\\alpha \\beta}||\\mathcal{N}(\\hat X^{\\alpha\\beta}_t) - \\mathcal{N}(X^{\\alpha\\beta}_t) ||_1 \\dot e^{|\\nabla_r(\\hat X^{\\alpha \\beta}_t)|} \u5176\u4e2d \\nabla_r(\\hat X^{\\alpha \\beta}_t) \u662f\u8ddd\u79bb\u5173\u4e8e \\alpha \\beta \u7684\u5fae\u5206\uff0c\u610f\u601d\u662f\u53d8\u5316\u8d8a\u5267\u70c8\u7684\u5730\u65b9\u8d8a\u91cd\u8981 \u91cc\u7a0b\u56de\u5f52 \u8fd9\u91cc\u8ba9\u7f51\u7edc\u5728\u5b8c\u5168\u8fde\u63a5\u5c42\u8f93\u51fa7\u4e2a\u6570\u503c\uff0c\u524d\u4e09\u4e2a\u662f\u5e73\u79fb\u5411\u91cf\uff0c\u540e\u9762\u56db\u4e2a\u662f\u56db\u5143\u6570\u3002\u5927\u90e8\u5206\u7f51\u7edc\u5c42\u4f7f\u7528\u7684\u662f fireConv \u7531\u4e8e\u70b9\u4e91\u7684\u7279\u6027\uff0cfeature map\u7684\u9ad8\u5ea6\u8fdc\u5c0f\u4e8e\u5bbd\u5ea6(360\u00b0\u70b9\u4e91)\uff0c\u6240\u4ee5\u5728\u4e0b\u91c7\u6837\u7684\u65f6\u5019\u53ea\u5bf9\u5bbd\u5ea6\u8fdb\u884cmax pooling \u5728\u5b66\u4e60\u65f6\u7531\u4e8e\u65cb\u8f6c\u4e0e\u5e73\u79fb\u7684\u5355\u4f4d\u4e0d\u540c\uff0c\u540c\u65f6\u4e3a\u4e86\u907f\u514d\u8c03\u8282\u8d85\u53c2\uff0c\u4f7f\u7528\u81ea\u52a8\u5b66\u4e60\u7684\u53c2\u6570(\u4e2a\u4eba\u6ce8\u89e3:\u5c3d\u7ba1\u516c\u5f0f\u4e0d\u540c\uff0c\u5f15\u7528\u7684\u6587\u7ae0\u4e5f\u4e0d\u4e00\u81f4\uff0c\u4f46\u662f\u57fa\u672c\u53ef\u4ee5\u786e\u8ba4\u7406\u8bba\u672c\u8d28\u6765\u81ea\u4e8e multi-loss ) \\begin{aligned} \\mathcal{L}_{o} &=\\mathcal{L}_{x}\\left(S_{t-1} ; S_{t}\\right) \\exp \\left(-s_{x}\\right)+s_{x} \\\\ &+\\mathcal{L}_{q}\\left(S_{t-1} ; S_{t}\\right) \\exp \\left(-s_{q}\\right)+s_{q} \\end{aligned} Mask\u4f30\u8ba1 \u8f93\u51fa\u7684mask\u4f1a\u5f71\u54cd\u5230\u51e0\u4f55\u7ea6\u675f\u7684cost function\uff0c\u88ab\u6539\u9020\u4e3a \\mathcal{L}_{n}=\\sum_{\\alpha \\beta} \\mathcal{M}\\left(X_{t}^{\\alpha \\beta}\\right)\\left\\|\\mathcal{N}\\left(\\hat{X}_{t}^{\\alpha \\beta}\\right)-\\mathcal{N}\\left(X_{t}^{\\alpha \\beta}\\right)\\right\\|_{1} \\cdot e^{\\left|\\nabla r\\left(\\hat{X}_{t}^{\\alpha \\beta}\\right)\\right|} \u6ce8\u610f\u5230\u7531\u4e8emask prediction\u6ca1\u6709ground truth \u6240\u4ee5\u5c06\u6240\u6709mask\u8bbe\u7f6e\u4e3a0\u53ef\u4ee5\u8ba9cost\u53d8\u5f97\u6700\u5c0f\uff0c\u6240\u4ee5\u9644\u52a0\u4ee5\u4e0b\u7684cost\uff0c\u76ee\u6807\u662f\u8ba9\u7f51\u7edc\u80fd\u591f\u6743\u8861\u3002 \\mathcal{L}_{r}=-\\sum_{\\alpha \\beta} \\log P\\left(\\mathcal{M}\\left(X_{t}^{\\alpha \\beta}\\right)=1\\right) Mapping refinement * \u8868\u793a\u7684\u662f\u5bf9\u6cd5\u5411\u4f30\u8ba1\u7684\u4e00\u4e2a\u9884\u8bbe\u7684 3\\times 5 \u5377\u79ef\uff0c\u4e2d\u592e\u4e3a-14.\u5176\u4ed6\u503c\u4e3a1\uff0c\u662f\u4e00\u4e2a\u9ad8\u901a\u6ee4\u6ce2\u5668\u3002feature map\u4e0a\u503c\u6700\u5c0f\u7684 n_c \u4e2amask\u5916\u7684\u70b9\u9009\u51fa\u6765\uff0c\u8ba4\u4e3a\u662f\u5e73\u9762\u533a\u57df\u3002 \\mathbf{\\Pi} \u6307\u7684\u662f\u8ba1\u7b97lidar pose\u7684\u5148\u9a8c\u8ba1\u7b97(\u5047\u8bbe\u4e0a\u4e00\u65f6\u523b\u8f6c\u6362\u77e9\u9635\u4e0d\u53d8) M_{init} = M_{t-1}M^{-1}_{t-2}M_{t-1} \\mathbf{\\Psi} \u9996\u5148\u5229\u7528\u7f51\u7edc\u9884\u6d4b\u7684\u4e24\u5e27\u95f4\u4f4d\u79fb\u7ebf\u6027\u63d2\u503c\u8865\u507f\u8fd0\u52a8\u7578\u53d8\uff0c\u7136\u540e\u7528 M_{init} \u5c06\u65b0\u7684\u70b9\u4e91\u8f6c\u79fb\u5230\u4e16\u754c\u5750\u6807\u7cfb\u4e0b\u3002 \u5047\u8bbe p_i \u662f\u5f53\u524dscan\u7684\u70b9\uff0c m_i \u662f\u5bf9\u5e94\u70b9\uff0c\u800c n_i \u662f\u5bf9\u5e94\u70b9\u7684\u6cd5\u5411\u3002\u5168\u5c40mapping\u7684\u76ee\u6807\u5c31\u662f\u8981\u627e\u5230\u4e00\u4e2a\u6700\u4f18\u7684 M \u4f7f\u5f97 \\hat{\\mathbf{M}}_{o p t}=\\underset{\\hat{\\mathbf{M}}}{\\arg \\min } \\sum_{i}\\left(\\left(\\hat{\\mathbf{M}} \\cdot \\boldsymbol{p}_{i}-\\boldsymbol{m}_{i}\\right) \\cdot \\boldsymbol{n}_{i}\\right)^{2} \\Theta :\u8fed\u4ee3\u5730\u6c42\u89e3\u4e0a\u6587\u63d0\u5230\u7684\u65b9\u7a0b\uff0c \\mathbf{M}_{t}=\\prod_{k=1}^{n_{i t e r}} \\hat{\\mathbf{M}}_{k} \\mathbf{M}_{i n i t} \\Phi \u6839\u636e\u4f18\u5316\u540e\u7684\u4f4d\u79fb\u7ed3\u679c\u751f\u6210\u6700\u7ec8\u7684\u70b9\u4e91\u7ed3\u679c\u3002 \\sum,N \u5c06\u65b0\u7684\u70b9\u4e91\u52a0\u5230\u5730\u56fe\u4e2d\uff0c\u7136\u540e\u6e05\u9664\u6700\u65e7\u7684\u70b9\u4e91\uff0c\u53ea\u4fdd\u5b58\u6700\u65e7\u7684 n_m \u4e2a\u70b9\u4e91","title":"LO-Net: Deep Real-time Lidar Odometry"},{"location":"papers/LO-Net: Deep Real-time Lidar Odometry/#lo-net-deep-real-time-lidar-odometry","text":"\u8fd9\u7bc7\u6587\u7ae0\u4e3b\u8981\u6709\u4e09\u4e2a\u8d21\u732e\uff0c\u7b2c\u4e00\u63d0\u51fa\u4e86scan-to-scan lidar odometry\u7f51\u7edc\uff0c\u540c\u65f6\u4f30\u8ba1\u9762\u7684\u6cd5\u5411\u4ee5\u53camask for dynamic regions\u3002\u7b2c\u4e8c\u878d\u5408\u76f8\u90bb\u4e24\u5e27\u7f51\u7edc\u8fdb\u884c\u4f30\u8ba1\uff0c\u7b2c\u4e09\uff0c\u878d\u5408\u4e00\u4e2amapping module. \u6ce8\u610fGithub \u94fe\u63a5\u4ee3\u7801\u5c1a\u672a\u516c\u5e03\u3002","title":"LO-Net: Deep Real-time Lidar Odometry"},{"location":"papers/LO-Net: Deep Real-time Lidar Odometry/#_1","text":"\u6574\u4f53\u6765\u8bf4\uff0c\u7f51\u7edc\u7531\u4e09\u4e2a\u7f51\u7edc\u6784\u6210\uff0c\u5206\u522b\u662f\u6cd5\u5411\u4f30\u8ba1\u7f51\u7edc(point wise)\uff0cmask \u4f30\u8ba1\u7f51\u7edc\u4ee5\u53ca\u4e00\u4e2a\u5171\u7528\u53c2\u6570\u7684\u53cc\u751f\u59ff\u6001\u56de\u5f52\u4e3b\u7f51\u8def\u3002\u5b83\u4ee5\u4e24\u4e2a\u76f8\u90bb\u7684lidar\u70b9\u4f5c\u4e3a\u8f93\u5165\uff0c\u4f30\u8ba1\u51fa6\u81ea\u7531\u5ea6\u7684\u76f8\u5bf9\u8fd0\u52a8\u3001\u70b9\u4e91\u5404\u70b9\u7684\u9762\u6cd5\u5411\u4ee5\u53ca\u52a8\u6001\u533a\u57dfmask\u3002odometry\u7684\u8f93\u51fa\u4f1a\u901a\u8fc7mapping\u6a21\u5757\u8fdb\u4e00\u6b65\u63d0\u9ad8\uff0c\u6700\u7ec8\u7684\u8f93\u51fa\u4f1a\u662f\u76f8\u5bf9\u4e8e\u521d\u59cb\u4f4d\u7f6e\u7684\u504f\u79fb","title":"\u7f51\u7edc\u4e3b\u8981\u7ed3\u6784"},{"location":"papers/LO-Net: Deep Real-time Lidar Odometry/#_2","text":"\u4e3a\u4e86\u8ba9\u7f51\u7edc\u7684\u6570\u636e\u7f16\u6392\u53d8\u5f97\u7d27\u51d1\uff0c\u8fd9\u91cc\u4f7f\u7528\u5706\u67f1\u5750\u6807\u7cfb \\alpha = arctan(y/x)/\\Delta \\alpha \\beta = arcsin(z/\\sqrt{x^2+y^2 + z^2} / \u0394\u03b2) \u5982\u679c\u540c\u4e00\u4e2a \\alpha, \\beta \u5750\u6807\u6709\u4e0d\u6b62\u4e00\u4e2a\u70b9\uff0c\u5219\u4ee5\u6700\u8fd1\u7684\u70b9\u4e3a\u51c6\uff0c\u6bcf\u4e00\u4e2a\u70b9\u7684\u7279\u5f81\u5305\u62ec\u5f3a\u5ea6\u503c\u4ee5\u53ca\u8ddd\u79bb\u503c\u3002","title":"\u8f93\u5165\u7f16\u7801"},{"location":"papers/LO-Net: Deep Real-time Lidar Odometry/#_3","text":"","title":"\u51e0\u4f55\u7ea6\u675f"},{"location":"papers/LO-Net: Deep Real-time Lidar Odometry/#_4","text":"\u4e25\u8c28\u6765\u8bf4\uff0c\u4ee5\u4e0a\u56fe\u4e3a\u4f8b\u5b50\uff0c\u70b9\u4e91\u7684\u6cd5\u5411\u5e94\u8be5\u7531\u70b9 X^i \u4ee5\u53ca\u5176 k \u4e2a\u76f8\u90bb\u7684\u70b9\uff0c\u7531\u4e0b\u5f0f\u5b9a\u4e49 \\argmin_{\\mathcal{N}(X^i)} ||[w_{i1}(X^{i_1}-X^i),...]^T\\mathcal{N}(X^i)||_2 \u4e5f\u5c31\u662f\u5bfb\u627e\u4e00\u4e2a\u77e2\u91cf\uff0c\u4f7f\u5f97\u8fd9\u4e2a\u77e2\u91cf\u4e0ek\u4e2a\u76f8\u90bb\u70b9\u77e2\u91cf\u7684\u70b9\u4e58\u7684\u52a0\u6743\u6c42\u548c\u503c(\u6216\u8005\u662f\u52a0\u6743\u8303\u6570)\u6700\u5c0f.\u4e00\u822c\u6765\u8bf4\u8ddd\u79bb\u8d8a\u8fd1\u6743\u91cd\u8d8a\u5927\uff0c\u8ddd\u79bb\u8d8a\u8fdc\u6743\u91cd\u8d8a\u5c0f\u3002 \u672c\u6587\u4e3a\u4e86\u7b80\u5316\u8fd9\u4e00\u8ba1\u7b97\uff0c\u4f7f\u7528\u4ee5\u4e0b\u65b9\u7a0b \\mathcal{N}(X^i) = \\sum_{X^{i_k}, X^{i_j} in \\mathcal{P}} (w_{ik}(X^{i_k} - X^i) \\times w_{ij}(X^{i_j} - X^i)) \u5176\u4e2d \\mathcal{P} \u4e3a\u5f53\u524d\u70b9\u7684\u4e34\u8fd1\u70b9\u3002 \u76f8\u90bb\u4e24\u7c07\u70b9\u4e91\u4e4b\u95f4\u6709\u4e00\u5b9a\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u4ee4 P \u4e3a\u6295\u5f71\u8fc7\u7a0b\u800c T_t \u4e3a\u76f8\u5bf9\u4f4d\u79fb\uff0c\u53ef\u4ee5\u627e\u5230\u70b9 X^{\\alpha \\beta}_{t-1} \u7684\u5bf9\u5e94\u70b9 \\hat X^{\\alpha \\beta}_t = P T_t P^{-1} X^{\\alpha\\beta}_{t-1} \u7531\u4e8e\u76f8\u5bf9\u5e94\u7684\u70b9\u6cd5\u5411\u4f30\u8ba1\u7406\u5e94\u6bd4\u8f83\u76f8\u4f3c\uff0c\u6240\u4ee5\u4e00\u4e2a\u7ea6\u675f\u662f \\mathcal{L}_n = \\sum_{\\alpha \\beta}||\\mathcal{N}(\\hat X^{\\alpha\\beta}_t) - \\mathcal{N}(X^{\\alpha\\beta}_t) ||_1 \\dot e^{|\\nabla_r(\\hat X^{\\alpha \\beta}_t)|} \u5176\u4e2d \\nabla_r(\\hat X^{\\alpha \\beta}_t) \u662f\u8ddd\u79bb\u5173\u4e8e \\alpha \\beta \u7684\u5fae\u5206\uff0c\u610f\u601d\u662f\u53d8\u5316\u8d8a\u5267\u70c8\u7684\u5730\u65b9\u8d8a\u91cd\u8981","title":"\u6cd5\u5411\u4f30\u8ba1"},{"location":"papers/LO-Net: Deep Real-time Lidar Odometry/#_5","text":"\u8fd9\u91cc\u8ba9\u7f51\u7edc\u5728\u5b8c\u5168\u8fde\u63a5\u5c42\u8f93\u51fa7\u4e2a\u6570\u503c\uff0c\u524d\u4e09\u4e2a\u662f\u5e73\u79fb\u5411\u91cf\uff0c\u540e\u9762\u56db\u4e2a\u662f\u56db\u5143\u6570\u3002\u5927\u90e8\u5206\u7f51\u7edc\u5c42\u4f7f\u7528\u7684\u662f fireConv \u7531\u4e8e\u70b9\u4e91\u7684\u7279\u6027\uff0cfeature map\u7684\u9ad8\u5ea6\u8fdc\u5c0f\u4e8e\u5bbd\u5ea6(360\u00b0\u70b9\u4e91)\uff0c\u6240\u4ee5\u5728\u4e0b\u91c7\u6837\u7684\u65f6\u5019\u53ea\u5bf9\u5bbd\u5ea6\u8fdb\u884cmax pooling \u5728\u5b66\u4e60\u65f6\u7531\u4e8e\u65cb\u8f6c\u4e0e\u5e73\u79fb\u7684\u5355\u4f4d\u4e0d\u540c\uff0c\u540c\u65f6\u4e3a\u4e86\u907f\u514d\u8c03\u8282\u8d85\u53c2\uff0c\u4f7f\u7528\u81ea\u52a8\u5b66\u4e60\u7684\u53c2\u6570(\u4e2a\u4eba\u6ce8\u89e3:\u5c3d\u7ba1\u516c\u5f0f\u4e0d\u540c\uff0c\u5f15\u7528\u7684\u6587\u7ae0\u4e5f\u4e0d\u4e00\u81f4\uff0c\u4f46\u662f\u57fa\u672c\u53ef\u4ee5\u786e\u8ba4\u7406\u8bba\u672c\u8d28\u6765\u81ea\u4e8e multi-loss ) \\begin{aligned} \\mathcal{L}_{o} &=\\mathcal{L}_{x}\\left(S_{t-1} ; S_{t}\\right) \\exp \\left(-s_{x}\\right)+s_{x} \\\\ &+\\mathcal{L}_{q}\\left(S_{t-1} ; S_{t}\\right) \\exp \\left(-s_{q}\\right)+s_{q} \\end{aligned}","title":"\u91cc\u7a0b\u56de\u5f52"},{"location":"papers/LO-Net: Deep Real-time Lidar Odometry/#mask","text":"\u8f93\u51fa\u7684mask\u4f1a\u5f71\u54cd\u5230\u51e0\u4f55\u7ea6\u675f\u7684cost function\uff0c\u88ab\u6539\u9020\u4e3a \\mathcal{L}_{n}=\\sum_{\\alpha \\beta} \\mathcal{M}\\left(X_{t}^{\\alpha \\beta}\\right)\\left\\|\\mathcal{N}\\left(\\hat{X}_{t}^{\\alpha \\beta}\\right)-\\mathcal{N}\\left(X_{t}^{\\alpha \\beta}\\right)\\right\\|_{1} \\cdot e^{\\left|\\nabla r\\left(\\hat{X}_{t}^{\\alpha \\beta}\\right)\\right|} \u6ce8\u610f\u5230\u7531\u4e8emask prediction\u6ca1\u6709ground truth \u6240\u4ee5\u5c06\u6240\u6709mask\u8bbe\u7f6e\u4e3a0\u53ef\u4ee5\u8ba9cost\u53d8\u5f97\u6700\u5c0f\uff0c\u6240\u4ee5\u9644\u52a0\u4ee5\u4e0b\u7684cost\uff0c\u76ee\u6807\u662f\u8ba9\u7f51\u7edc\u80fd\u591f\u6743\u8861\u3002 \\mathcal{L}_{r}=-\\sum_{\\alpha \\beta} \\log P\\left(\\mathcal{M}\\left(X_{t}^{\\alpha \\beta}\\right)=1\\right)","title":"Mask\u4f30\u8ba1"},{"location":"papers/LO-Net: Deep Real-time Lidar Odometry/#mapping-refinement","text":"* \u8868\u793a\u7684\u662f\u5bf9\u6cd5\u5411\u4f30\u8ba1\u7684\u4e00\u4e2a\u9884\u8bbe\u7684 3\\times 5 \u5377\u79ef\uff0c\u4e2d\u592e\u4e3a-14.\u5176\u4ed6\u503c\u4e3a1\uff0c\u662f\u4e00\u4e2a\u9ad8\u901a\u6ee4\u6ce2\u5668\u3002feature map\u4e0a\u503c\u6700\u5c0f\u7684 n_c \u4e2amask\u5916\u7684\u70b9\u9009\u51fa\u6765\uff0c\u8ba4\u4e3a\u662f\u5e73\u9762\u533a\u57df\u3002 \\mathbf{\\Pi} \u6307\u7684\u662f\u8ba1\u7b97lidar pose\u7684\u5148\u9a8c\u8ba1\u7b97(\u5047\u8bbe\u4e0a\u4e00\u65f6\u523b\u8f6c\u6362\u77e9\u9635\u4e0d\u53d8) M_{init} = M_{t-1}M^{-1}_{t-2}M_{t-1} \\mathbf{\\Psi} \u9996\u5148\u5229\u7528\u7f51\u7edc\u9884\u6d4b\u7684\u4e24\u5e27\u95f4\u4f4d\u79fb\u7ebf\u6027\u63d2\u503c\u8865\u507f\u8fd0\u52a8\u7578\u53d8\uff0c\u7136\u540e\u7528 M_{init} \u5c06\u65b0\u7684\u70b9\u4e91\u8f6c\u79fb\u5230\u4e16\u754c\u5750\u6807\u7cfb\u4e0b\u3002 \u5047\u8bbe p_i \u662f\u5f53\u524dscan\u7684\u70b9\uff0c m_i \u662f\u5bf9\u5e94\u70b9\uff0c\u800c n_i \u662f\u5bf9\u5e94\u70b9\u7684\u6cd5\u5411\u3002\u5168\u5c40mapping\u7684\u76ee\u6807\u5c31\u662f\u8981\u627e\u5230\u4e00\u4e2a\u6700\u4f18\u7684 M \u4f7f\u5f97 \\hat{\\mathbf{M}}_{o p t}=\\underset{\\hat{\\mathbf{M}}}{\\arg \\min } \\sum_{i}\\left(\\left(\\hat{\\mathbf{M}} \\cdot \\boldsymbol{p}_{i}-\\boldsymbol{m}_{i}\\right) \\cdot \\boldsymbol{n}_{i}\\right)^{2} \\Theta :\u8fed\u4ee3\u5730\u6c42\u89e3\u4e0a\u6587\u63d0\u5230\u7684\u65b9\u7a0b\uff0c \\mathbf{M}_{t}=\\prod_{k=1}^{n_{i t e r}} \\hat{\\mathbf{M}}_{k} \\mathbf{M}_{i n i t} \\Phi \u6839\u636e\u4f18\u5316\u540e\u7684\u4f4d\u79fb\u7ed3\u679c\u751f\u6210\u6700\u7ec8\u7684\u70b9\u4e91\u7ed3\u679c\u3002 \\sum,N \u5c06\u65b0\u7684\u70b9\u4e91\u52a0\u5230\u5730\u56fe\u4e2d\uff0c\u7136\u540e\u6e05\u9664\u6700\u65e7\u7684\u70b9\u4e91\uff0c\u53ea\u4fdd\u5b58\u6700\u65e7\u7684 n_m \u4e2a\u70b9\u4e91","title":"Mapping refinement"},{"location":"papers/Lane Detection and Classification usingCascaded CNNs/","text":"Lane Detection and Classification using Cascaded CNNs \u8fd9\u7bc7\u8bba\u6587\u7ed9\u51fa\u7684\u662f\u7aef\u5230\u7aef\u8def\u7ebf\u70b9\u7684\u5206\u5272\u3001\u805a\u7c7b\u4ee5\u53ca\u5206\u7c7b\u7684\u7b97\u6cd5\u3002 \u6574\u4f53\u7ed3\u6784\u5982\u56fe 1. Instance Segmentation \u7528\u7269\u4f53\u5206\u5272\u505a\u7b2c\u4e00\u6b65\uff0c\u53ea\u63a2\u6d4b\u6700\u591a4\u6761\u7ebf\u3002\u4e2d\u5fc3\u4e24\u6761\u4ee5\u53ca\u5de6\u53f3\u4e00\u6761\u3002 2. \u5206\u7c7b \u6570\u636e\u4e0a\u4f7f\u7528\u989d\u5916\u7684\u4eba\u5de5\u6807\u6ce8\uff0c\u5f97\u5230\u56fe\u68ee\u6570\u636e\u96c6\u7684\u9053\u8def\u7ebf\u7c7b\u522b\uff0c github \u4eceSegmentation\u7684\u70b9\u4e2d\u627e\u5230\u539f\u56fe\u4e0a\u7684\u70b9\uff0c\u4ece\u4e2d\u91c7\u6837\u56fa\u5b9a\u6570\u91cf\u7684\u70b9(\u4f5c\u4e3a\u7a33\u5b9a\u7684\u8f93\u5165\u5927\u5c0f)\u3002 \u628a\u8fd9\u4e9bdescriptor(\u56fa\u5b9a\u6570\u91cf)\u8f93\u5165\u5230\u53e6\u4e00\u4e2a\u5355\u72ec\u8bad\u7ec3\u7684CNN\u4e2d\u5b8c\u6210\u5206\u7c7b\u3002","title":"Lane Detection and Classification using Cascaded CNNs"},{"location":"papers/Lane Detection and Classification usingCascaded CNNs/#lane-detection-and-classification-using-cascaded-cnns","text":"\u8fd9\u7bc7\u8bba\u6587\u7ed9\u51fa\u7684\u662f\u7aef\u5230\u7aef\u8def\u7ebf\u70b9\u7684\u5206\u5272\u3001\u805a\u7c7b\u4ee5\u53ca\u5206\u7c7b\u7684\u7b97\u6cd5\u3002 \u6574\u4f53\u7ed3\u6784\u5982\u56fe","title":"Lane Detection and Classification using Cascaded CNNs"},{"location":"papers/Lane Detection and Classification usingCascaded CNNs/#1-instance-segmentation","text":"\u7528\u7269\u4f53\u5206\u5272\u505a\u7b2c\u4e00\u6b65\uff0c\u53ea\u63a2\u6d4b\u6700\u591a4\u6761\u7ebf\u3002\u4e2d\u5fc3\u4e24\u6761\u4ee5\u53ca\u5de6\u53f3\u4e00\u6761\u3002","title":"1. Instance Segmentation"},{"location":"papers/Lane Detection and Classification usingCascaded CNNs/#2","text":"\u6570\u636e\u4e0a\u4f7f\u7528\u989d\u5916\u7684\u4eba\u5de5\u6807\u6ce8\uff0c\u5f97\u5230\u56fe\u68ee\u6570\u636e\u96c6\u7684\u9053\u8def\u7ebf\u7c7b\u522b\uff0c github \u4eceSegmentation\u7684\u70b9\u4e2d\u627e\u5230\u539f\u56fe\u4e0a\u7684\u70b9\uff0c\u4ece\u4e2d\u91c7\u6837\u56fa\u5b9a\u6570\u91cf\u7684\u70b9(\u4f5c\u4e3a\u7a33\u5b9a\u7684\u8f93\u5165\u5927\u5c0f)\u3002 \u628a\u8fd9\u4e9bdescriptor(\u56fa\u5b9a\u6570\u91cf)\u8f93\u5165\u5230\u53e6\u4e00\u4e2a\u5355\u72ec\u8bad\u7ec3\u7684CNN\u4e2d\u5b8c\u6210\u5206\u7c7b\u3002","title":"2. \u5206\u7c7b"},{"location":"papers/PWC-Net_CNNs_for_Optical_Flow_Using_Pyramid_Warping_and_Cost_Volume/","text":"PWC-Net: CNNs for Optical Flow Using Pyramid, Warping, and Cost Volume \u8fd9\u7bc7\u8bba\u6587\u662f Joint Unsupervised Learning of Optical Flow and Depth by Watching Stereo Videos \u7684\u524d\u7f6e \u7f51\u7edc\u7ed3\u6784 \u8f93\u5165\u7684\u7279\u5f81\u5206\u4e3a6\u5c42\uff0c\u7b2c\u4e00\u5c42\u4e3a\u8f93\u5165\u56fe\u7247\uff0c\u7b2c\u4e8c\u5c42\u5f00\u59cb\u4e3aConvNet\u4e0b\u91c7\u6837\u7684\u8f93\u51fa, \u8f93\u51fa\u5149\u6d41 Warping Layer \u5728\u7b2cL\u5c42\uff0c\u5c06\u7b2c\u4e8c\u5f20\u56fe\u7b2cl+1\u5c42\u7684feature\u901a\u8fc7\u4e0a\u91c7\u6837\u8f6c\u6362\u5230\u7b2c\u4e00\u5f20\u56fe c^l_w(x) = c^l_2(x + up_2(w^{l+1})(x)) \u91c7\u7528\u7684\u662fbilinear interpolation Cost volume layer \u8868\u793a\u7684\u662f\u4e00\u4e2apixel\u4e0e\u4e0b\u4e00\u65f6\u523b\u5bf9\u5e94pixel match\u7684cost\u3002\u4f7f\u7528\u7279\u5f81\u7684coorelation\u6765\u8868\u793a cv^l(x1, x2) = \\frac{1}{N} (c^l_1(x_1))^T c^l_w(x_2) \u5177\u4f53\uff1a\u8f93\u51fa\u662f d^2\\times H^l \\times W^l \u5176\u5b9e\u5c31\u662f\u5de6\u89c6\u89d2\u6bcf\u4e00\u4e2a\u70b9 x_1 \u4e0ewarp\u7ed3\u679c\u5bf9\u5e94\u5468\u56f4 d\\times d \u4e2apixels\u7684\u7279\u5f81\u5411\u91cf\u6c42\u76f8\u5173\u6027 Optical flow estimator \u8fd9\u662f\u4e00\u4e2a\u591a\u5c42CNN\uff0c\u8f93\u5165\u662fCost Volumn, \u7b2c\u4e00\u56fe\u7684\u7279\u5f81\u4ee5\u53ca\u4e0a\u91c7\u6837\u7684\u5149\u6d41\uff0c\u5b83\u7684\u8f93\u51fa\u662f\u7b2c l \u5c42\u7684\u5149\u6d41 w^l .\u4e0d\u540c\u5c42\u4e4b\u95f4\u7684CNN\u7279\u5f81\u4e0d\u5171\u4eab\uff0c Context Network \u4f7f\u7528\u6700\u7ec8\u8f93\u51fa\u7684\u5149\u6d41\u4ee5\u53ca\u524d\u4e00\u5c42\u7684\u7279\u5f81\u4f5c\u4e3a\u8f93\u5165\uff0c\u518d\u8f93\u51fa\u66f4\u7cbe\u786e\u7684\u5149\u6d41\u503c\uff0c\u591a\u4f7f\u7528dilated Conv\u53bb\u63d0\u5347\u611f\u53d7\u91ce","title":"PWC-Net: CNNs for Optical Flow Using Pyramid, Warping, and Cost Volume"},{"location":"papers/PWC-Net_CNNs_for_Optical_Flow_Using_Pyramid_Warping_and_Cost_Volume/#pwc-net-cnns-for-optical-flow-using-pyramid-warping-and-cost-volume","text":"\u8fd9\u7bc7\u8bba\u6587\u662f Joint Unsupervised Learning of Optical Flow and Depth by Watching Stereo Videos \u7684\u524d\u7f6e","title":"PWC-Net: CNNs for Optical Flow Using Pyramid, Warping, and Cost Volume"},{"location":"papers/PWC-Net_CNNs_for_Optical_Flow_Using_Pyramid_Warping_and_Cost_Volume/#_1","text":"\u8f93\u5165\u7684\u7279\u5f81\u5206\u4e3a6\u5c42\uff0c\u7b2c\u4e00\u5c42\u4e3a\u8f93\u5165\u56fe\u7247\uff0c\u7b2c\u4e8c\u5c42\u5f00\u59cb\u4e3aConvNet\u4e0b\u91c7\u6837\u7684\u8f93\u51fa, \u8f93\u51fa\u5149\u6d41","title":"\u7f51\u7edc\u7ed3\u6784"},{"location":"papers/PWC-Net_CNNs_for_Optical_Flow_Using_Pyramid_Warping_and_Cost_Volume/#warping-layer","text":"\u5728\u7b2cL\u5c42\uff0c\u5c06\u7b2c\u4e8c\u5f20\u56fe\u7b2cl+1\u5c42\u7684feature\u901a\u8fc7\u4e0a\u91c7\u6837\u8f6c\u6362\u5230\u7b2c\u4e00\u5f20\u56fe c^l_w(x) = c^l_2(x + up_2(w^{l+1})(x)) \u91c7\u7528\u7684\u662fbilinear interpolation","title":"Warping Layer"},{"location":"papers/PWC-Net_CNNs_for_Optical_Flow_Using_Pyramid_Warping_and_Cost_Volume/#cost-volume-layer","text":"\u8868\u793a\u7684\u662f\u4e00\u4e2apixel\u4e0e\u4e0b\u4e00\u65f6\u523b\u5bf9\u5e94pixel match\u7684cost\u3002\u4f7f\u7528\u7279\u5f81\u7684coorelation\u6765\u8868\u793a cv^l(x1, x2) = \\frac{1}{N} (c^l_1(x_1))^T c^l_w(x_2) \u5177\u4f53\uff1a\u8f93\u51fa\u662f d^2\\times H^l \\times W^l \u5176\u5b9e\u5c31\u662f\u5de6\u89c6\u89d2\u6bcf\u4e00\u4e2a\u70b9 x_1 \u4e0ewarp\u7ed3\u679c\u5bf9\u5e94\u5468\u56f4 d\\times d \u4e2apixels\u7684\u7279\u5f81\u5411\u91cf\u6c42\u76f8\u5173\u6027","title":"Cost volume layer"},{"location":"papers/PWC-Net_CNNs_for_Optical_Flow_Using_Pyramid_Warping_and_Cost_Volume/#optical-flow-estimator","text":"\u8fd9\u662f\u4e00\u4e2a\u591a\u5c42CNN\uff0c\u8f93\u5165\u662fCost Volumn, \u7b2c\u4e00\u56fe\u7684\u7279\u5f81\u4ee5\u53ca\u4e0a\u91c7\u6837\u7684\u5149\u6d41\uff0c\u5b83\u7684\u8f93\u51fa\u662f\u7b2c l \u5c42\u7684\u5149\u6d41 w^l .\u4e0d\u540c\u5c42\u4e4b\u95f4\u7684CNN\u7279\u5f81\u4e0d\u5171\u4eab\uff0c","title":"Optical flow estimator"},{"location":"papers/PWC-Net_CNNs_for_Optical_Flow_Using_Pyramid_Warping_and_Cost_Volume/#context-network","text":"\u4f7f\u7528\u6700\u7ec8\u8f93\u51fa\u7684\u5149\u6d41\u4ee5\u53ca\u524d\u4e00\u5c42\u7684\u7279\u5f81\u4f5c\u4e3a\u8f93\u5165\uff0c\u518d\u8f93\u51fa\u66f4\u7cbe\u786e\u7684\u5149\u6d41\u503c\uff0c\u591a\u4f7f\u7528dilated Conv\u53bb\u63d0\u5347\u611f\u53d7\u91ce","title":"Context Network"},{"location":"papers/PointFlow : 3D Point Cloud Generation with Continuous Normalizing Flows/","text":"PointFlow : 3D Point Cloud Generation with Continuous Normalizing Flows \u8fd9\u7bc7\u8bba\u6587\u6709\u4e00\u4e2a project page \uff0c\u6839\u636e \u89c6\u9891 \u5b8c\u6210\u7684\u4e00\u4e2a\u4efb\u52a1\u53ef\u4ee5\u8fd9\u6837\u63cf\u8ff0\u3002\u6bcf\u4e00\u4e2a\u7269\u4f53\u7684\u4e00\u79cd\u70b9\u4e91\u8868\u8fbe\u53ef\u4ee5\u7406\u89e3\u4e3a\u4ece\u4e00\u4e2a\u7531\u5f62\u72b6\u51b3\u5b9a\u7684\u6982\u7387\u5206\u5e03\u91c7\u6837\u70b9\u3002\u6211\u4eec\u53ef\u4ee5\u5229\u7528\u4e00\u4e2a\u5750\u6807\u8f6c\u6362\u51fd\u6570\uff0c\u5c06\u9ad8\u65af\u91c7\u6837\u70b9\u4e91\u8f6c\u6362\u4e3a\u6700\u540e\u7684\u8f93\u51fa\u3002\u672c\u6587\u7ed9\u51fa\u7684\u7f51\u7edc\u53ef\u4ee5\u6839\u636e\u7c7b\u522b\uff0c\u4ee5\u53ca\u4e00\u4e9b\u968f\u673a\u6570\uff0c\u91c7\u6837\u51fa\u4e0d\u540c\u5f62\u72b6\u7684\u4e00\u4e2a\u5750\u6807\u8f6c\u6362\u51fd\u6570\u3002 Background: Continuous normalizing flow \u5b9a\u4e49 f_1,...,f_n \u6307\u4ee3\u4e00\u7cfb\u5217\u7684\u53ef\u9006\u53d8\u6362\u3002\u8f93\u5165\u9690\u53d8\u91cf y \u7684\u6982\u7387\u5206\u5e03\u4e3a P(y) . x=f_{n} \\circ f_{n-1} \\circ \\cdots \\circ f_{1}(y) \u4f5c\u4e3a\u8f93\u51fa\u3002\u8f93\u51fa\u53d8\u91cf\u7684\u6982\u7387\u5bc6\u5ea6\u5219\u53d8\u4e3a \\log P(x)=\\log P(y)-\\sum_{k=1}^{n} \\log \\left|\\operatorname{det} \\frac{\\partial f_{k}}{\\partial y_{k-1}}\\right| \u8fd9\u6837 y \u53ef\u4ee5\u4ece x \u4f7f\u7528inverse flow\u8ba1\u7b97: y=f_{1}^{-1} \\circ \\cdots \\circ f_{n}^{-1}(x) . \u8fd9\u91cc f_1,...,f_n \u5728\u8fd9\u91cc\u5b9e\u4f53\u5316\u4f5c\u4e3a\u795e\u7ecf\u7f51\u7edc\uff0c\u8fd9\u6837\u5bfc\u6570\u7684\u884c\u5217\u5f0f\u8ba1\u7b97\u96be\u5ea6\u4e0d\u5927\u3002 continuous normalizing flow(CNF) for P(x) \u5c31\u662f x=y\\left(t_{0}\\right)+\\int_{t_{0}}^{t_{1}} f(y(t), t) d t, \\quad y\\left(t_{0}\\right) \\sim P(y) \\log P(x)=\\log P\\left(y\\left(t_{0}\\right)\\right)-\\int_{t_{0}}^{t_{1}} \\operatorname{Tr}\\left(\\frac{\\partial f}{\\partial y(t)}\\right) d t inverse flow y(t_0) = x + \\int^{t_0}_{t_1}f(y(t),t)dt .\u8fd9\u91cc\u7684 f \u4ecd\u7136\u662f\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc,\u7528ODE\u6c42\u89e3\u5668\u4f5c\u4e3a\u8f93\u51fa\u3002\u8fd9\u91cc\u7684\u5173\u952e\u601d\u7ef4\u8f6c\u53d8\u662f\u5229\u7528\u4e86\uff0c Neural Ordinary Equation \u7684\u601d\u8def\uff0c\u5c06\u8fde\u7eed\u53e0\u5c42\u7684\u5171\u4eab\u6743\u91cd\u7684\u795e\u7ecf\u7f51\u7edc\u7528\u5e38\u5fae\u5206\u65b9\u7a0b\u4ee3\u66ff.\u7528\u8fd9\u4e2aneural ODE\u7684\u4e00\u4e2a\u91cd\u70b9\u662f\u4f7f\u5f97\u9006\u53d8\u6362\u53ef\u4ee5\u540c\u6837\u901a\u8fc7ODE\u65f6\u95f4\u4e0a\u76f8\u53cd\u7684\u4e00\u4e2aforward pass\u5b9e\u73b0\u3002 Variational auto-encoder \u539f\u6587 .VAE\u4e2d\uff0c z \u662flatent space,\u5305\u542b\u4e00\u4e2a\u63cf\u8ff0 P_\\theta(X|z) \u4f5c\u4e3adecoder,\u8fd8\u5b66\u4e60\u4e00\u4e2aencoder Q_\\phi(z|X) ,\u5b83\u4eec\u5171\u540c\u8bad\u7ec3\u53bb\u6700\u5927\u5316\u89c2\u5bdf\u5668\u7684log-likelihood \\begin{aligned} \\log P_{\\theta}(X) & \\geq \\log P_{\\theta}(X)-D_{K L}\\left(Q_{\\phi}(z | X) \\| P_{\\theta}(z | X)\\right) \\\\ &=\\mathbb{E}_{Q_{\\phi}(z | x)}\\left[\\log P_{\\theta}(X | z)\\right]-D_{K L}\\left(Q_{\\phi}(z | X) \\| P_{\\psi}(z)\\right) \\\\ & \\triangleq \\mathcal{L}(X ; \\phi, \\psi, \\theta) \\end{aligned} z = \\mu_phi(X) + \\sigma_\\phi(X) \\epsilon .\u8fd9\u4e2a\u5747\u503c\u4e0e\u65b9\u5dee\u90fd\u662f\u7f51\u7edc\u76f4\u63a5\u7684\u8f93\u51fa\u3002 \u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5 \u9996\u5148\u5305\u542b\u4e09\u4e2a\u6a21\u5757\uff0c\u7b2c\u4e00\u4e2a\u662fencoder\uff0c Q_\\phi(z|X) ,\u5c06\u70b9\u4e91\u7f16\u7801\u4e3a\u4e00\u4e2a\u9690\u53d8\u91cf z ,\u4e00\u4e2a\u5148\u9a8c P\\psi(z) over shapes.\u7136\u540e\u4e00\u4e2adecoder, P_\\theta(X|z) . point generation from shape representations \\log P_{\\theta}(X | z)=\\sum_{x \\in X} \\log P_{\\theta}(x | z) \u5177\u4f53\u6765\u8bf4\uff0c\u4e00\u4e2a\u5728\u96c6\u5408 X \u4e2d\u7684\u70b9 x \uff0c\u662f\u4f7f\u7528CNF conditioned on z ,\u8f6c\u6362 y(t_0) \u7684\u7ed3\u679c,\u4e5f\u5c31\u662fneural ODE\u7684forward pass\u3002 x=G_{\\theta}\\left(y\\left(t_{0}\\right) ; z\\right) \\triangleq y\\left(t_{0}\\right)+\\int_{t_{0}}^{t_{1}} g_{\\theta}(y(t), t, z) d t, y\\left(t_{0}\\right) \\sim P(y) \u8fd9\u91cc g_\\theta \u5b9a\u4e49\u4e3aflow G_\\theta \u7684\u8fde\u7eed\u52a8\u529b\u5b66\u3002 G_{\\theta}^{-1}(x ; z)=x+\\int_{t_{1}}^{t_{0}} g_{\\theta}(y(t), t, z) d t with y(t_1)=x Flow-based \u5148\u9a8c over shapes \u56de\u987eKL-divergence(\u76f8\u5bf9\u71b5)\uff0c D_{KL}(p||q) = H(p, q) - H(p) forward\u65f6: z=F_{\\psi}\\left(w\\left(t_{0}\\right)\\right) \\triangleq w\\left(t_{0}\\right)+\\int_{t_{0}}^{t_{1}} f_{\\psi}(w(t), t) d t, w\\left(t_{0}\\right) \\sim P(w) \u6700\u7ec8training \u76ee\u6807 ELBO:VAE\u76ee\u6807 \\begin{aligned} \\mathcal{L}(X ; \\phi, \\psi, \\theta) &=\\mathbb{E}_{Q_{\\phi}(z | x)}\\left[\\log P_{\\psi}(z)+\\log P_{\\theta}(X | z)\\right]+H\\left[Q_{\\phi}(z | X)\\right] \\\\ &=\\mathbb{E}_{Q_{\\phi}(z | X)}\\left[\\log P\\left(F_{\\psi}^{-1}(z)\\right)-\\int_{t_{0}}^{t_{1}} \\operatorname{Tr}\\left(\\frac{\\partial f_{\\psi}}{\\partial w(t)}\\right) d t\\right.\\\\ &\\left.+\\sum_{x \\in X}\\left(\\log P\\left(G_{\\theta}^{-1}(x ; z)\\right)-\\int_{t_{0}}^{t_{1}} \\operatorname{Tr}\\left(\\frac{\\partial g_{\\theta}}{\\partial y(t)}\\right) d t\\right)\\right] \\\\ &+H\\left[Q_{\\phi}(z | X)\\right] \\end{aligned} \u53ef\u4ee5\u5206\u89e3\u4e3a\u4e09\u4e2a\u90e8\u5206 Prior:\u9f13\u52b1\u5927\u6982\u7387\uff0c\u8f83\u786e\u5b9a\u7684\u7ed3\u679c(\u8fd9\u91cc\u7528\u5355\u6b21\u8499\u7279\u5361\u6d1b\u91c7\u6837\u5bf9\u90a3\u4e2a\u671f\u671b\u8fdb\u884c\u4f30\u8ba1) \\mathbb{E}_{Q_{\\phi}(z | x)}\\left[\\log P_{\\psi}(z)\\right] \\approx \\frac{1}{L} \\sum_{l=1}^{L} \\log P_{\\psi}\\left(\\mu+\\epsilon_{l} \\odot \\sigma\\right) Reconstruction: \\mathcal{L}_{\\mathrm{recon}}(X ; \\theta, \\phi) \\triangleq \\mathbb{E}_{Q_{\\phi}}(z | x)\\left[\\log P_{\\theta}(X | z)\\right] Posterior Entropy: \\mathcal{L}_{\\mathrm{ent}}(X ; \\phi) \\triangleq H\\left[Q_{\\phi}(z | X)\\right]=\\frac{d}{2}(1+\\ln (2 \\pi))+\\sum_{i=1}^{d} \\ln \\sigma_{i} \u672c\u6587\u6a21\u578b\u9700\u8981\u6700\u5927\u5316\u8fd9\u4e2a\u76ee\u6807\u3002 \u603b\u89c8 \u8fdb\u4e00\u6b65\u7ec6\u8282\u89e3\u91ca\uff1a \u56fe\u4e2d\u7684 Q_\\phi \u4e3a\u7c7b\u4f3cpointNet\u7ed3\u6784\u7684\uff0cencoder\uff0c\u662f\u4e00\u7ef4\u5377\u79ef\uff0c\u6700\u540e\u5168\u8fde\u63a5\u8f93\u51fa\u4e24\u4e2a D_z \u7ef4\u5ea6\u7684\u5747\u503c\u4e0e\u65b9\u5dee\u9884\u6d4b f_\\phi \u4f7f\u7528\u7684\u662f FFJORD ,\u91cc\u9762\u4f7f\u7528\u4e86\u4e09\u4e2aconcatsquash\u5c42 \\mathrm{CS}(x, t)=\\left(W_{x} x+b_{x}\\right) \\sigma\\left(W_{t} t+b_{t}\\right)+\\left(W_{b} t+b_{b} t\\right) g_\\theta \u5904\u62d3\u5c55\u4e86concatsquash\u5c42\u4ee5\u4f7f\u5f97\u7ed3\u679c\u4e0ez\u76f8\u5173 \\begin{aligned} \\operatorname{CCS}(x, z, t)=&\\left(W_{x} x+b_{x}\\right) \\sigma\\left(W_{t t} t+W_{t z} z+b_{t}\\right) \\\\ &+\\left(W_{b t} t+W_{b z} z+b_{b} t\\right) \\end{aligned}","title":"PointFlow : 3D Point Cloud Generation with Continuous Normalizing Flows"},{"location":"papers/PointFlow : 3D Point Cloud Generation with Continuous Normalizing Flows/#pointflow-3d-point-cloud-generation-with-continuous-normalizing-flows","text":"\u8fd9\u7bc7\u8bba\u6587\u6709\u4e00\u4e2a project page \uff0c\u6839\u636e \u89c6\u9891 \u5b8c\u6210\u7684\u4e00\u4e2a\u4efb\u52a1\u53ef\u4ee5\u8fd9\u6837\u63cf\u8ff0\u3002\u6bcf\u4e00\u4e2a\u7269\u4f53\u7684\u4e00\u79cd\u70b9\u4e91\u8868\u8fbe\u53ef\u4ee5\u7406\u89e3\u4e3a\u4ece\u4e00\u4e2a\u7531\u5f62\u72b6\u51b3\u5b9a\u7684\u6982\u7387\u5206\u5e03\u91c7\u6837\u70b9\u3002\u6211\u4eec\u53ef\u4ee5\u5229\u7528\u4e00\u4e2a\u5750\u6807\u8f6c\u6362\u51fd\u6570\uff0c\u5c06\u9ad8\u65af\u91c7\u6837\u70b9\u4e91\u8f6c\u6362\u4e3a\u6700\u540e\u7684\u8f93\u51fa\u3002\u672c\u6587\u7ed9\u51fa\u7684\u7f51\u7edc\u53ef\u4ee5\u6839\u636e\u7c7b\u522b\uff0c\u4ee5\u53ca\u4e00\u4e9b\u968f\u673a\u6570\uff0c\u91c7\u6837\u51fa\u4e0d\u540c\u5f62\u72b6\u7684\u4e00\u4e2a\u5750\u6807\u8f6c\u6362\u51fd\u6570\u3002","title":"PointFlow : 3D Point Cloud Generation with Continuous Normalizing Flows"},{"location":"papers/PointFlow : 3D Point Cloud Generation with Continuous Normalizing Flows/#background-continuous-normalizing-flow","text":"\u5b9a\u4e49 f_1,...,f_n \u6307\u4ee3\u4e00\u7cfb\u5217\u7684\u53ef\u9006\u53d8\u6362\u3002\u8f93\u5165\u9690\u53d8\u91cf y \u7684\u6982\u7387\u5206\u5e03\u4e3a P(y) . x=f_{n} \\circ f_{n-1} \\circ \\cdots \\circ f_{1}(y) \u4f5c\u4e3a\u8f93\u51fa\u3002\u8f93\u51fa\u53d8\u91cf\u7684\u6982\u7387\u5bc6\u5ea6\u5219\u53d8\u4e3a \\log P(x)=\\log P(y)-\\sum_{k=1}^{n} \\log \\left|\\operatorname{det} \\frac{\\partial f_{k}}{\\partial y_{k-1}}\\right| \u8fd9\u6837 y \u53ef\u4ee5\u4ece x \u4f7f\u7528inverse flow\u8ba1\u7b97: y=f_{1}^{-1} \\circ \\cdots \\circ f_{n}^{-1}(x) . \u8fd9\u91cc f_1,...,f_n \u5728\u8fd9\u91cc\u5b9e\u4f53\u5316\u4f5c\u4e3a\u795e\u7ecf\u7f51\u7edc\uff0c\u8fd9\u6837\u5bfc\u6570\u7684\u884c\u5217\u5f0f\u8ba1\u7b97\u96be\u5ea6\u4e0d\u5927\u3002 continuous normalizing flow(CNF) for P(x) \u5c31\u662f x=y\\left(t_{0}\\right)+\\int_{t_{0}}^{t_{1}} f(y(t), t) d t, \\quad y\\left(t_{0}\\right) \\sim P(y) \\log P(x)=\\log P\\left(y\\left(t_{0}\\right)\\right)-\\int_{t_{0}}^{t_{1}} \\operatorname{Tr}\\left(\\frac{\\partial f}{\\partial y(t)}\\right) d t inverse flow y(t_0) = x + \\int^{t_0}_{t_1}f(y(t),t)dt .\u8fd9\u91cc\u7684 f \u4ecd\u7136\u662f\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc,\u7528ODE\u6c42\u89e3\u5668\u4f5c\u4e3a\u8f93\u51fa\u3002\u8fd9\u91cc\u7684\u5173\u952e\u601d\u7ef4\u8f6c\u53d8\u662f\u5229\u7528\u4e86\uff0c Neural Ordinary Equation \u7684\u601d\u8def\uff0c\u5c06\u8fde\u7eed\u53e0\u5c42\u7684\u5171\u4eab\u6743\u91cd\u7684\u795e\u7ecf\u7f51\u7edc\u7528\u5e38\u5fae\u5206\u65b9\u7a0b\u4ee3\u66ff.\u7528\u8fd9\u4e2aneural ODE\u7684\u4e00\u4e2a\u91cd\u70b9\u662f\u4f7f\u5f97\u9006\u53d8\u6362\u53ef\u4ee5\u540c\u6837\u901a\u8fc7ODE\u65f6\u95f4\u4e0a\u76f8\u53cd\u7684\u4e00\u4e2aforward pass\u5b9e\u73b0\u3002","title":"Background: Continuous normalizing flow"},{"location":"papers/PointFlow : 3D Point Cloud Generation with Continuous Normalizing Flows/#variational-auto-encoder","text":"\u539f\u6587 .VAE\u4e2d\uff0c z \u662flatent space,\u5305\u542b\u4e00\u4e2a\u63cf\u8ff0 P_\\theta(X|z) \u4f5c\u4e3adecoder,\u8fd8\u5b66\u4e60\u4e00\u4e2aencoder Q_\\phi(z|X) ,\u5b83\u4eec\u5171\u540c\u8bad\u7ec3\u53bb\u6700\u5927\u5316\u89c2\u5bdf\u5668\u7684log-likelihood \\begin{aligned} \\log P_{\\theta}(X) & \\geq \\log P_{\\theta}(X)-D_{K L}\\left(Q_{\\phi}(z | X) \\| P_{\\theta}(z | X)\\right) \\\\ &=\\mathbb{E}_{Q_{\\phi}(z | x)}\\left[\\log P_{\\theta}(X | z)\\right]-D_{K L}\\left(Q_{\\phi}(z | X) \\| P_{\\psi}(z)\\right) \\\\ & \\triangleq \\mathcal{L}(X ; \\phi, \\psi, \\theta) \\end{aligned} z = \\mu_phi(X) + \\sigma_\\phi(X) \\epsilon .\u8fd9\u4e2a\u5747\u503c\u4e0e\u65b9\u5dee\u90fd\u662f\u7f51\u7edc\u76f4\u63a5\u7684\u8f93\u51fa\u3002","title":"Variational auto-encoder"},{"location":"papers/PointFlow : 3D Point Cloud Generation with Continuous Normalizing Flows/#_1","text":"\u9996\u5148\u5305\u542b\u4e09\u4e2a\u6a21\u5757\uff0c\u7b2c\u4e00\u4e2a\u662fencoder\uff0c Q_\\phi(z|X) ,\u5c06\u70b9\u4e91\u7f16\u7801\u4e3a\u4e00\u4e2a\u9690\u53d8\u91cf z ,\u4e00\u4e2a\u5148\u9a8c P\\psi(z) over shapes.\u7136\u540e\u4e00\u4e2adecoder, P_\\theta(X|z) .","title":"\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5"},{"location":"papers/PointFlow : 3D Point Cloud Generation with Continuous Normalizing Flows/#point-generation-from-shape-representations","text":"\\log P_{\\theta}(X | z)=\\sum_{x \\in X} \\log P_{\\theta}(x | z) \u5177\u4f53\u6765\u8bf4\uff0c\u4e00\u4e2a\u5728\u96c6\u5408 X \u4e2d\u7684\u70b9 x \uff0c\u662f\u4f7f\u7528CNF conditioned on z ,\u8f6c\u6362 y(t_0) \u7684\u7ed3\u679c,\u4e5f\u5c31\u662fneural ODE\u7684forward pass\u3002 x=G_{\\theta}\\left(y\\left(t_{0}\\right) ; z\\right) \\triangleq y\\left(t_{0}\\right)+\\int_{t_{0}}^{t_{1}} g_{\\theta}(y(t), t, z) d t, y\\left(t_{0}\\right) \\sim P(y) \u8fd9\u91cc g_\\theta \u5b9a\u4e49\u4e3aflow G_\\theta \u7684\u8fde\u7eed\u52a8\u529b\u5b66\u3002 G_{\\theta}^{-1}(x ; z)=x+\\int_{t_{1}}^{t_{0}} g_{\\theta}(y(t), t, z) d t with y(t_1)=x","title":"point generation from shape representations"},{"location":"papers/PointFlow : 3D Point Cloud Generation with Continuous Normalizing Flows/#flow-based-over-shapes","text":"\u56de\u987eKL-divergence(\u76f8\u5bf9\u71b5)\uff0c D_{KL}(p||q) = H(p, q) - H(p) forward\u65f6: z=F_{\\psi}\\left(w\\left(t_{0}\\right)\\right) \\triangleq w\\left(t_{0}\\right)+\\int_{t_{0}}^{t_{1}} f_{\\psi}(w(t), t) d t, w\\left(t_{0}\\right) \\sim P(w)","title":"Flow-based \u5148\u9a8c over shapes"},{"location":"papers/PointFlow : 3D Point Cloud Generation with Continuous Normalizing Flows/#training","text":"ELBO:VAE\u76ee\u6807 \\begin{aligned} \\mathcal{L}(X ; \\phi, \\psi, \\theta) &=\\mathbb{E}_{Q_{\\phi}(z | x)}\\left[\\log P_{\\psi}(z)+\\log P_{\\theta}(X | z)\\right]+H\\left[Q_{\\phi}(z | X)\\right] \\\\ &=\\mathbb{E}_{Q_{\\phi}(z | X)}\\left[\\log P\\left(F_{\\psi}^{-1}(z)\\right)-\\int_{t_{0}}^{t_{1}} \\operatorname{Tr}\\left(\\frac{\\partial f_{\\psi}}{\\partial w(t)}\\right) d t\\right.\\\\ &\\left.+\\sum_{x \\in X}\\left(\\log P\\left(G_{\\theta}^{-1}(x ; z)\\right)-\\int_{t_{0}}^{t_{1}} \\operatorname{Tr}\\left(\\frac{\\partial g_{\\theta}}{\\partial y(t)}\\right) d t\\right)\\right] \\\\ &+H\\left[Q_{\\phi}(z | X)\\right] \\end{aligned} \u53ef\u4ee5\u5206\u89e3\u4e3a\u4e09\u4e2a\u90e8\u5206 Prior:\u9f13\u52b1\u5927\u6982\u7387\uff0c\u8f83\u786e\u5b9a\u7684\u7ed3\u679c(\u8fd9\u91cc\u7528\u5355\u6b21\u8499\u7279\u5361\u6d1b\u91c7\u6837\u5bf9\u90a3\u4e2a\u671f\u671b\u8fdb\u884c\u4f30\u8ba1) \\mathbb{E}_{Q_{\\phi}(z | x)}\\left[\\log P_{\\psi}(z)\\right] \\approx \\frac{1}{L} \\sum_{l=1}^{L} \\log P_{\\psi}\\left(\\mu+\\epsilon_{l} \\odot \\sigma\\right) Reconstruction: \\mathcal{L}_{\\mathrm{recon}}(X ; \\theta, \\phi) \\triangleq \\mathbb{E}_{Q_{\\phi}}(z | x)\\left[\\log P_{\\theta}(X | z)\\right] Posterior Entropy: \\mathcal{L}_{\\mathrm{ent}}(X ; \\phi) \\triangleq H\\left[Q_{\\phi}(z | X)\\right]=\\frac{d}{2}(1+\\ln (2 \\pi))+\\sum_{i=1}^{d} \\ln \\sigma_{i} \u672c\u6587\u6a21\u578b\u9700\u8981\u6700\u5927\u5316\u8fd9\u4e2a\u76ee\u6807\u3002","title":"\u6700\u7ec8training \u76ee\u6807"},{"location":"papers/PointFlow : 3D Point Cloud Generation with Continuous Normalizing Flows/#_2","text":"\u8fdb\u4e00\u6b65\u7ec6\u8282\u89e3\u91ca\uff1a \u56fe\u4e2d\u7684 Q_\\phi \u4e3a\u7c7b\u4f3cpointNet\u7ed3\u6784\u7684\uff0cencoder\uff0c\u662f\u4e00\u7ef4\u5377\u79ef\uff0c\u6700\u540e\u5168\u8fde\u63a5\u8f93\u51fa\u4e24\u4e2a D_z \u7ef4\u5ea6\u7684\u5747\u503c\u4e0e\u65b9\u5dee\u9884\u6d4b f_\\phi \u4f7f\u7528\u7684\u662f FFJORD ,\u91cc\u9762\u4f7f\u7528\u4e86\u4e09\u4e2aconcatsquash\u5c42 \\mathrm{CS}(x, t)=\\left(W_{x} x+b_{x}\\right) \\sigma\\left(W_{t} t+b_{t}\\right)+\\left(W_{b} t+b_{b} t\\right) g_\\theta \u5904\u62d3\u5c55\u4e86concatsquash\u5c42\u4ee5\u4f7f\u5f97\u7ed3\u679c\u4e0ez\u76f8\u5173 \\begin{aligned} \\operatorname{CCS}(x, z, t)=&\\left(W_{x} x+b_{x}\\right) \\sigma\\left(W_{t t} t+W_{t z} z+b_{t}\\right) \\\\ &+\\left(W_{b t} t+W_{b z} z+b_{b} t\\right) \\end{aligned}","title":"\u603b\u89c8"},{"location":"papers/SSD Single Shot MultiBox Detector/","text":"SSD: Single Shot MultiBox Detector \u8bad\u7ec3loss\u7531\u5b9a\u4f4d\u4e0e\u5206\u7c7b\u4e24\u4e2a\u90e8\u5206\u7ec4\u6210 \u5173\u4e8e\u5b9a\u4f4dloss: \u5206\u4e3a\u6846\u7684\u4e2d\u70b9\u7684x\uff0cy\u4e0e\u5bbd\u5ea6\u4e0e\u9ad8\u5ea6\u3002 x, y\u7684\u76ee\u6807\u503c\u4e3a(\u6ce8\u610f\u4e0d\u540c\u5206\u8fa8\u7387\u4e2d\u683c\u5b50\u7684\u5bbd\u5ea6\u662f\u4e0d\u540c\u7684) \\frac{\u5b9e\u9645\u4e2d\u70b9\u7684\u4f4d\u7f6e-\u683c\u5b50\u4e2d\u70b9\u7684\u4f4d\u7f6e}{\u683c\u5b50\u5bbd\u5ea6} \u800c\u5bbd\u5ea6\u4e0e\u9ad8\u5ea6\u7684\u76ee\u6807\u503c\u4e3a log\\frac{\u76ee\u6807\u957f\u5bbd}{\u683c\u5b50\u957f\u5bbd}","title":"SSD: Single Shot MultiBox Detector"},{"location":"papers/SSD Single Shot MultiBox Detector/#ssd-single-shot-multibox-detector","text":"","title":"SSD: Single Shot MultiBox Detector"},{"location":"papers/SSD Single Shot MultiBox Detector/#loss","text":"","title":"\u8bad\u7ec3loss\u7531\u5b9a\u4f4d\u4e0e\u5206\u7c7b\u4e24\u4e2a\u90e8\u5206\u7ec4\u6210"},{"location":"papers/SSD Single Shot MultiBox Detector/#loss_1","text":"\u5206\u4e3a\u6846\u7684\u4e2d\u70b9\u7684x\uff0cy\u4e0e\u5bbd\u5ea6\u4e0e\u9ad8\u5ea6\u3002 x, y\u7684\u76ee\u6807\u503c\u4e3a(\u6ce8\u610f\u4e0d\u540c\u5206\u8fa8\u7387\u4e2d\u683c\u5b50\u7684\u5bbd\u5ea6\u662f\u4e0d\u540c\u7684) \\frac{\u5b9e\u9645\u4e2d\u70b9\u7684\u4f4d\u7f6e-\u683c\u5b50\u4e2d\u70b9\u7684\u4f4d\u7f6e}{\u683c\u5b50\u5bbd\u5ea6} \u800c\u5bbd\u5ea6\u4e0e\u9ad8\u5ea6\u7684\u76ee\u6807\u503c\u4e3a log\\frac{\u76ee\u6807\u957f\u5bbd}{\u683c\u5b50\u957f\u5bbd}","title":"\u5173\u4e8e\u5b9a\u4f4dloss:"},{"location":"papers/Unsupervised_Learning_of_Depth_and_Ego-Motion_from_Video/","text":"Unsupervised Learning of Depth and Ego-Motion from Video \u8fd9\u7bc7\u6587\u7ae0\u5bf9\u6211\u6765\u8bf4\u8bf4\u662f \u8fd9\u7bc7\u6587\u7ae0 \u7684\u524d\u7f6e \u8fd9\u7bc7\u6587\u7ae0\u89e3\u51b3\u7684\u95ee\u9898\u4e5f\u662f\u8f93\u5165\u89c6\u9891\uff0c\u8f93\u51fa\u6df1\u5ea6\u4e0e\u76f8\u673a\u8fd0\u52a8\u7684\u4f30\u8ba1 \u4e3bpipeline \u4f7f\u7528\u76f8\u90bb\u4e09\u5f20\u56fe\uff0c\u5c06\u5f53\u524d I_t \u8f93\u5165\u5230Depth CNN\u8f93\u51fa\u6df1\u5ea6\u56fe\uff0c\u5c06\u76f8\u90bb\u7684 I_{t-1}, I_{t+1} \u5171\u4e09\u5f20\u56fe\u8f93\u5165\u5230pose CNN(CNN\u76f4\u63a5\u8f93\u51fa\u516d\u81ea\u7531\u5ea6\u8fd0\u52a8)\u4e2d\u8f93\u51fa\u524d\u540e\u4e24\u4e2a\u76f8\u5bf9pose\uff0c\u5728\u5df2\u77e5\u5f53\u524d\u56fe\u7684\u6df1\u5ea6\u4ee5\u53ca\u8fd0\u52a8\uff0c\u5c06\u5f53\u524d\u56fe\u8f6c\u6362\u5230\u524d\u540e\u65f6\u523b\u7684\u56fe\u7247\u4e0a(\u4f7f\u7528bilinear intepolation\u8fdb\u884c\u53ef\u5bfc\u7684\u8f6c\u6362) \u672c\u6587\u8fd8\u6709\u66f4\u591a\u5185\u5bb9\u5982(Explainability mask)\uff0c\u6b64\u5904\u8ba8\u8bba\u5230\u6b64\u4e3a\u6b62\u3002","title":"Unsupervised Learning of Depth and Ego-Motion from Video"},{"location":"papers/Unsupervised_Learning_of_Depth_and_Ego-Motion_from_Video/#unsupervised-learning-of-depth-and-ego-motion-from-video","text":"\u8fd9\u7bc7\u6587\u7ae0\u5bf9\u6211\u6765\u8bf4\u8bf4\u662f \u8fd9\u7bc7\u6587\u7ae0 \u7684\u524d\u7f6e \u8fd9\u7bc7\u6587\u7ae0\u89e3\u51b3\u7684\u95ee\u9898\u4e5f\u662f\u8f93\u5165\u89c6\u9891\uff0c\u8f93\u51fa\u6df1\u5ea6\u4e0e\u76f8\u673a\u8fd0\u52a8\u7684\u4f30\u8ba1","title":"Unsupervised Learning of Depth and Ego-Motion from Video"},{"location":"papers/Unsupervised_Learning_of_Depth_and_Ego-Motion_from_Video/#pipeline","text":"\u4f7f\u7528\u76f8\u90bb\u4e09\u5f20\u56fe\uff0c\u5c06\u5f53\u524d I_t \u8f93\u5165\u5230Depth CNN\u8f93\u51fa\u6df1\u5ea6\u56fe\uff0c\u5c06\u76f8\u90bb\u7684 I_{t-1}, I_{t+1} \u5171\u4e09\u5f20\u56fe\u8f93\u5165\u5230pose CNN(CNN\u76f4\u63a5\u8f93\u51fa\u516d\u81ea\u7531\u5ea6\u8fd0\u52a8)\u4e2d\u8f93\u51fa\u524d\u540e\u4e24\u4e2a\u76f8\u5bf9pose\uff0c\u5728\u5df2\u77e5\u5f53\u524d\u56fe\u7684\u6df1\u5ea6\u4ee5\u53ca\u8fd0\u52a8\uff0c\u5c06\u5f53\u524d\u56fe\u8f6c\u6362\u5230\u524d\u540e\u65f6\u523b\u7684\u56fe\u7247\u4e0a(\u4f7f\u7528bilinear intepolation\u8fdb\u884c\u53ef\u5bfc\u7684\u8f6c\u6362) \u672c\u6587\u8fd8\u6709\u66f4\u591a\u5185\u5bb9\u5982(Explainability mask)\uff0c\u6b64\u5904\u8ba8\u8bba\u5230\u6b64\u4e3a\u6b62\u3002","title":"\u4e3bpipeline"},{"location":"papers/undone/ApplicationofHDRalgorithmstosolvedirectsunlightproblemswhenautonomousvehiclesusingmachinevisionsystemsaredrivingintosun/","text":"Application of HDR algorithms to solve direct sunlight problems when autonomous vehicles using machine vision systems are driving into sun","title":"Application of HDR algorithms to solve direct sunlight problems when autonomous vehicles using machine vision systems are driving into sun"},{"location":"papers/undone/ApplicationofHDRalgorithmstosolvedirectsunlightproblemswhenautonomousvehiclesusingmachinevisionsystemsaredrivingintosun/#application-of-hdr-algorithms-to-solve-direct-sunlight-problems-when-autonomous-vehicles-using-machine-vision-systems-are-driving-into-sun","text":"","title":"Application of HDR algorithms to solve direct sunlight problems when autonomous vehicles using machine vision systems are driving into sun"},{"location":"papers/undone/Autonomous  Racing  using  Learning  Model  Predictive  Control/","text":"Autonomous Racing using Learning Model Predictive Control","title":"Autonomous  Racing  using  Learning  Model  Predictive  Control"},{"location":"papers/undone/Autonomous  Racing  using  Learning  Model  Predictive  Control/#autonomous-racing-using-learning-model-predictive-control","text":"","title":"Autonomous  Racing  using  Learning  Model  Predictive  Control"},{"location":"papers/undone/Beyond Pixels Leveraging Geometry and Shape Cues for OnlineMulti-Object Tracking/","text":"Beyond Pixels: Leveraging Geometry and Shape Cues for OnlineMulti-Object Tracking","title":"Beyond Pixels: Leveraging Geometry and Shape Cues for OnlineMulti-Object Tracking"},{"location":"papers/undone/Beyond Pixels Leveraging Geometry and Shape Cues for OnlineMulti-Object Tracking/#beyond-pixels-leveraging-geometry-and-shape-cues-for-onlinemulti-object-tracking","text":"","title":"Beyond Pixels: Leveraging Geometry and Shape Cues for OnlineMulti-Object Tracking"},{"location":"papers/undone/Data-Driven Modeling and Control of an Autonomous Race Car/","text":"Data-Driven Modeling and Control of an Autonomous Race Car","title":"Data-Driven Modeling and Control of an Autonomous Race Car"},{"location":"papers/undone/Data-Driven Modeling and Control of an Autonomous Race Car/#data-driven-modeling-and-control-of-an-autonomous-race-car","text":"","title":"Data-Driven Modeling and Control of an Autonomous Race Car"},{"location":"papers/undone/Deep Hough Voting for 3D Object Detection in Point Clouds/","text":"Deep Hough Voting for 3D Object Detection in Point Clouds","title":"Deep Hough Voting for 3D Object Detection in Point Clouds"},{"location":"papers/undone/Deep Hough Voting for 3D Object Detection in Point Clouds/#deep-hough-voting-for-3d-object-detection-in-point-clouds","text":"","title":"Deep Hough Voting for 3D Object Detection in Point Clouds"},{"location":"papers/undone/Deep Imitative Models for Flexible Inference,Planning, and Control/","text":"Deep Imitative Models for Flexible Inference,Planning, and Control","title":"Deep Imitative Models for Flexible Inference,Planning, and Control"},{"location":"papers/undone/Deep Imitative Models for Flexible Inference,Planning, and Control/#deep-imitative-models-for-flexible-inferenceplanning-and-control","text":"","title":"Deep Imitative Models for Flexible Inference,Planning, and Control"},{"location":"papers/undone/END-TO-END LEARNABLE HISTOGRAM FILTERS/","text":"END-TO-END LEARNABLE HISTOGRAM FILTERS","title":"END-TO-END LEARNABLE HISTOGRAM FILTERS"},{"location":"papers/undone/END-TO-END LEARNABLE HISTOGRAM FILTERS/#end-to-end-learnable-histogram-filters","text":"","title":"END-TO-END LEARNABLE HISTOGRAM FILTERS"},{"location":"papers/undone/End-To-End Multi-Modal Sensors Fusion System ForUrban Automated Driving/","text":"End-To-End Multi-Modal Sensors Fusion System For Urban Automated Driving","title":"End-To-End Multi-Modal Sensors Fusion System For Urban Automated Driving"},{"location":"papers/undone/End-To-End Multi-Modal Sensors Fusion System ForUrban Automated Driving/#end-to-end-multi-modal-sensors-fusion-system-for-urban-automated-driving","text":"","title":"End-To-End Multi-Modal Sensors Fusion System For Urban Automated Driving"},{"location":"papers/undone/Enhanced  free  space  detection  in  multiple  lanes  based  on  single  CNNwith  scene  identification/","text":"Enhanced free space detection in multiple lanes based on single CNN with scene identification","title":"Enhanced  free  space  detection  in  multiple  lanes  based  on  single  CNN with  scene  identification"},{"location":"papers/undone/Enhanced  free  space  detection  in  multiple  lanes  based  on  single  CNNwith  scene  identification/#enhanced-free-space-detection-in-multiple-lanes-based-on-single-cnn-with-scene-identification","text":"","title":"Enhanced  free  space  detection  in  multiple  lanes  based  on  single  CNN with  scene  identification"},{"location":"papers/undone/Exploring the structure of a real-time, arbitrary neuralartistic stylization network/","text":"Exploring the structure of a real-time, arbitrary neuralartistic stylization network","title":"Exploring the structure of a real-time, arbitrary neuralartistic stylization network"},{"location":"papers/undone/Exploring the structure of a real-time, arbitrary neuralartistic stylization network/#exploring-the-structure-of-a-real-time-arbitrary-neuralartistic-stylization-network","text":"","title":"Exploring the structure of a real-time, arbitrary neuralartistic stylization network"},{"location":"papers/undone/From Perception to Decision A Data-driven Approach to End-to-endMotion Planning for Autonomous Ground Robots/","text":"From Perception to Decision: A Data-driven Approach to End-to-end Motion Planning for Autonomous Ground Robots","title":"From Perception to Decision: A Data-driven Approach to End-to-end Motion Planning for Autonomous Ground Robots"},{"location":"papers/undone/From Perception to Decision A Data-driven Approach to End-to-endMotion Planning for Autonomous Ground Robots/#from-perception-to-decision-a-data-driven-approach-to-end-to-end-motion-planning-for-autonomous-ground-robots","text":"","title":"From Perception to Decision: A Data-driven Approach to End-to-end Motion Planning for Autonomous Ground Robots"},{"location":"papers/undone/IMAGENET-TRAINEDCNNS   ARE   BIASED   TOWARDSTEXTURE;INCREASING SHAPE BIAS IMPROVESACCURACY AND ROBUSTNESS/","text":"IMAGENET-TRAINEDCNNS ARE BIASED TOWARDS TEXTURE;INCREASING SHAPE BIAS IMPROVES ACCURACY AND ROBUSTNESS","title":"IMAGENET-TRAINEDCNNS   ARE   BIASED   TOWARDS TEXTURE;INCREASING SHAPE BIAS IMPROVES ACCURACY AND ROBUSTNESS"},{"location":"papers/undone/IMAGENET-TRAINEDCNNS   ARE   BIASED   TOWARDSTEXTURE;INCREASING SHAPE BIAS IMPROVESACCURACY AND ROBUSTNESS/#imagenet-trainedcnns-are-biased-towards-textureincreasing-shape-bias-improves-accuracy-and-robustness","text":"","title":"IMAGENET-TRAINEDCNNS   ARE   BIASED   TOWARDS TEXTURE;INCREASING SHAPE BIAS IMPROVES ACCURACY AND ROBUSTNESS"},{"location":"papers/undone/InfoGAN Interpretable Representation Learning byInformation Maximizing Generative Adversarial Nets/","text":"InfoGAN: Interpretable Representation Learning byInformation Maximizing Generative Adversarial Nets","title":"InfoGAN: Interpretable Representation Learning byInformation Maximizing Generative Adversarial Nets"},{"location":"papers/undone/InfoGAN Interpretable Representation Learning byInformation Maximizing Generative Adversarial Nets/#infogan-interpretable-representation-learning-byinformation-maximizing-generative-adversarial-nets","text":"","title":"InfoGAN: Interpretable Representation Learning byInformation Maximizing Generative Adversarial Nets"},{"location":"papers/undone/LP-3DCNN Unveiling Local Phase in 3D Convolutional Neural Networks/","text":"LP-3DCNN: Unveiling Local Phase in 3D Convolutional Neural Networks","title":"LP-3DCNN: Unveiling Local Phase in 3D Convolutional Neural Networks"},{"location":"papers/undone/LP-3DCNN Unveiling Local Phase in 3D Convolutional Neural Networks/#lp-3dcnn-unveiling-local-phase-in-3d-convolutional-neural-networks","text":"","title":"LP-3DCNN: Unveiling Local Phase in 3D Convolutional Neural Networks"},{"location":"papers/undone/LiDAR Sensor modeling and Data augmentationwith GANs for Autonomous driving/","text":"LiDAR Sensor modeling and Data augmentationwith GANs for Autonomous driving","title":"LiDAR Sensor modeling and Data augmentationwith GANs for Autonomous driving"},{"location":"papers/undone/LiDAR Sensor modeling and Data augmentationwith GANs for Autonomous driving/#lidar-sensor-modeling-and-data-augmentationwith-gans-for-autonomous-driving","text":"","title":"LiDAR Sensor modeling and Data augmentationwith GANs for Autonomous driving"},{"location":"papers/undone/Libra R-CNN Towards Balanced Learning for Object Detection/","text":"Libra R-CNN: Towards Balanced Learning for Object Detection","title":"Libra R-CNN: Towards Balanced Learning for Object Detection"},{"location":"papers/undone/Libra R-CNN Towards Balanced Learning for Object Detection/#libra-r-cnn-towards-balanced-learning-for-object-detection","text":"","title":"Libra R-CNN: Towards Balanced Learning for Object Detection"},{"location":"papers/undone/MPC-Inspired Neural Network Policies for Sequential Decision Making/","text":"MPC-Inspired Neural Network Policies for Sequential Decision Making","title":"MPC-Inspired Neural Network Policies for Sequential Decision Making"},{"location":"papers/undone/MPC-Inspired Neural Network Policies for Sequential Decision Making/#mpc-inspired-neural-network-policies-for-sequential-decision-making","text":"","title":"MPC-Inspired Neural Network Policies for Sequential Decision Making"},{"location":"papers/undone/MULTI-SCALEDENSENETWORKSFORRESOURCEEFFICIENTIMAGECLASSIFICATION/","text":"MULTI-SCALE DENSE NETWORKS FOR RESOURCE EFFICIENT IMAGE CLASSIFICATION","title":"MULTI-SCALE DENSE NETWORKS FOR RESOURCE EFFICIENT IMAGE CLASSIFICATION"},{"location":"papers/undone/MULTI-SCALEDENSENETWORKSFORRESOURCEEFFICIENTIMAGECLASSIFICATION/#multi-scale-dense-networks-for-resource-efficient-image-classification","text":"","title":"MULTI-SCALE DENSE NETWORKS FOR RESOURCE EFFICIENT IMAGE CLASSIFICATION"},{"location":"papers/undone/Motion Planning for Autonomous Driving with a Conformal Spatiotemporal Lattice/","text":"Motion Planning for Autonomous Driving with a Conformal Spatiotemporal Lattice","title":"Motion Planning for Autonomous Driving with a Conformal Spatiotemporal Lattice"},{"location":"papers/undone/Motion Planning for Autonomous Driving with a Conformal Spatiotemporal Lattice/#motion-planning-for-autonomous-driving-with-a-conformal-spatiotemporal-lattice","text":"","title":"Motion Planning for Autonomous Driving with a Conformal Spatiotemporal Lattice"},{"location":"papers/undone/Optimization Beyond the Convolution Generalizing Spatial Relationswith End-to-End Metric Learning/","text":"Optimization Beyond the Convolution: Generalizing Spatial Relationswith End-to-End Metric Learning","title":"Optimization Beyond the Convolution: Generalizing Spatial Relationswith End-to-End Metric Learning"},{"location":"papers/undone/Optimization Beyond the Convolution Generalizing Spatial Relationswith End-to-End Metric Learning/#optimization-beyond-the-convolution-generalizing-spatial-relationswith-end-to-end-metric-learning","text":"","title":"Optimization Beyond the Convolution: Generalizing Spatial Relationswith End-to-End Metric Learning"},{"location":"papers/undone/POI Multiple Object Tracking with HighPerformance Detection and Appearance Feature/","text":"POI: Multiple Object Tracking with HighPerformance Detection and Appearance Feature","title":"POI: Multiple Object Tracking with HighPerformance Detection and Appearance Feature"},{"location":"papers/undone/POI Multiple Object Tracking with HighPerformance Detection and Appearance Feature/#poi-multiple-object-tracking-with-highperformance-detection-and-appearance-feature","text":"","title":"POI: Multiple Object Tracking with HighPerformance Detection and Appearance Feature"},{"location":"papers/undone/Probabilistic Decision-Making under Uncertainty for AutonomousDriving using Continuous POMDPs/","text":"Probabilistic Decision-Making under Uncertainty for AutonomousDriving using Continuous POMDPs","title":"Probabilistic Decision-Making under Uncertainty for AutonomousDriving using Continuous POMDPs"},{"location":"papers/undone/Probabilistic Decision-Making under Uncertainty for AutonomousDriving using Continuous POMDPs/#probabilistic-decision-making-under-uncertainty-for-autonomousdriving-using-continuous-pomdps","text":"","title":"Probabilistic Decision-Making under Uncertainty for AutonomousDriving using Continuous POMDPs"},{"location":"papers/undone/RETHINKINGSELF-DRIVING  MULTI-TASKKNOWL-EDGE  FORBETTERGENERALIZATION  ANDACCIDENTEXPLANATIONABILITY/","text":"RETHINKING SELF-DRIVING: MULTI-TASK KNOWLEDGE FOR BETTER GENERALIZATION AND ACCIDENT EXPLANATIONABILITY","title":"RETHINKING SELF-DRIVING:   MULTI-TASK KNOWLEDGE  FOR BETTER GENERALIZATION  AND ACCIDENT EXPLANATIONABILITY"},{"location":"papers/undone/RETHINKINGSELF-DRIVING  MULTI-TASKKNOWL-EDGE  FORBETTERGENERALIZATION  ANDACCIDENTEXPLANATIONABILITY/#rethinking-self-driving-multi-task-knowledge-for-better-generalization-and-accident-explanationability","text":"","title":"RETHINKING SELF-DRIVING:   MULTI-TASK KNOWLEDGE  FOR BETTER GENERALIZATION  AND ACCIDENT EXPLANATIONABILITY"},{"location":"papers/undone/Real-Time Freespace Segmentation on AutonomousRobots for Detection of Obstacles and Drop-Offs/","text":"Real-Time Freespace Segmentation on AutonomousRobots for Detection of Obstacles and Drop-Offs","title":"Real-Time Freespace Segmentation on AutonomousRobots for Detection of Obstacles and Drop-Offs"},{"location":"papers/undone/Real-Time Freespace Segmentation on AutonomousRobots for Detection of Obstacles and Drop-Offs/#real-time-freespace-segmentation-on-autonomousrobots-for-detection-of-obstacles-and-drop-offs","text":"","title":"Real-Time Freespace Segmentation on AutonomousRobots for Detection of Obstacles and Drop-Offs"},{"location":"papers/undone/Restricted Deformable Convolution basedRoad Scene Semantic SegmentationUsing Surround View Cameras/","text":"Restricted Deformable Convolution based Road Scene Semantic Segmentation Using Surround View Cameras","title":"Restricted Deformable Convolution based Road Scene Semantic Segmentation Using Surround View Cameras"},{"location":"papers/undone/Restricted Deformable Convolution basedRoad Scene Semantic SegmentationUsing Surround View Cameras/#restricted-deformable-convolution-based-road-scene-semantic-segmentation-using-surround-view-cameras","text":"","title":"Restricted Deformable Convolution based Road Scene Semantic Segmentation Using Surround View Cameras"},{"location":"papers/undone/Semantic Image Synthesis with Spatially-Adaptive Normalization/","text":"Semantic Image Synthesis with Spatially-Adaptive Normalization","title":"Semantic Image Synthesis with Spatially-Adaptive Normalization"},{"location":"papers/undone/Semantic Image Synthesis with Spatially-Adaptive Normalization/#semantic-image-synthesis-with-spatially-adaptive-normalization","text":"","title":"Semantic Image Synthesis with Spatially-Adaptive Normalization"},{"location":"papers/undone/Style Augmentation Data Augmentation via StyleRandomization/","text":"Style Augmentation: Data Augmentation via StyleRandomization","title":"Style Augmentation: Data Augmentation via StyleRandomization"},{"location":"papers/undone/Style Augmentation Data Augmentation via StyleRandomization/#style-augmentation-data-augmentation-via-stylerandomization","text":"","title":"Style Augmentation: Data Augmentation via StyleRandomization"},{"location":"papers/undone/TossingBot Learning to Throw Arbitrary Objectswith Residual Physics/","text":"TossingBot: Learning to Throw Arbitrary Objectswith Residual Physics","title":"TossingBot: Learning to Throw Arbitrary Objectswith Residual Physics"},{"location":"papers/undone/TossingBot Learning to Throw Arbitrary Objectswith Residual Physics/#tossingbot-learning-to-throw-arbitrary-objectswith-residual-physics","text":"","title":"TossingBot: Learning to Throw Arbitrary Objectswith Residual Physics"},{"location":"papers/undone/Toward Driving Scene Understanding A Dataset for Learning Driver Behavior and Causal Reasoning/","text":"Toward Driving Scene Understanding:A Dataset for Learning Driver Behavior and Causal Reasoning","title":"Toward Driving Scene Understanding:A Dataset for Learning Driver Behavior and Causal Reasoning"},{"location":"papers/undone/Toward Driving Scene Understanding A Dataset for Learning Driver Behavior and Causal Reasoning/#toward-driving-scene-understandinga-dataset-for-learning-driver-behavior-and-causal-reasoning","text":"","title":"Toward Driving Scene Understanding:A Dataset for Learning Driver Behavior and Causal Reasoning"},{"location":"papers/undone/Towards Practical Hierarchical ReinforcementLearning for Multi-lane Autonomous Driving/","text":"Towards Practical Hierarchical ReinforcementLearning for Multi-lane Autonomous Driving","title":"Towards Practical Hierarchical ReinforcementLearning for Multi-lane Autonomous Driving"},{"location":"papers/undone/Towards Practical Hierarchical ReinforcementLearning for Multi-lane Autonomous Driving/#towards-practical-hierarchical-reinforcementlearning-for-multi-lane-autonomous-driving","text":"","title":"Towards Practical Hierarchical ReinforcementLearning for Multi-lane Autonomous Driving"},{"location":"papers/undone/Unsupervised Learning of Depth and Ego-Motion from Monocular VideoUsing 3D Geometric Constraints/","text":"Unsupervised Learning of Depth and Ego-Motion from Monocular VideoUsing 3D Geometric Constraints","title":"Unsupervised Learning of Depth and Ego-Motion from Monocular VideoUsing 3D Geometric Constraints"},{"location":"papers/undone/Unsupervised Learning of Depth and Ego-Motion from Monocular VideoUsing 3D Geometric Constraints/#unsupervised-learning-of-depth-and-ego-motion-from-monocular-videousing-3d-geometric-constraints","text":"","title":"Unsupervised Learning of Depth and Ego-Motion from Monocular VideoUsing 3D Geometric Constraints"},{"location":"papers/undone/Virtual-to-real  Deep  Reinforcement  Learning Continuous  Control  of  Mobile  Robots  for  Mapless  Navigation/","text":"Virtual-to-real Deep Reinforcement Learning:Continuous Control of Mobile Robots for Mapless Navigation","title":"Virtual-to-real  Deep  Reinforcement  Learning:Continuous  Control  of  Mobile  Robots  for  Mapless  Navigation"},{"location":"papers/undone/Virtual-to-real  Deep  Reinforcement  Learning Continuous  Control  of  Mobile  Robots  for  Mapless  Navigation/#virtual-to-real-deep-reinforcement-learningcontinuous-control-of-mobile-robots-for-mapless-navigation","text":"","title":"Virtual-to-real  Deep  Reinforcement  Learning:Continuous  Control  of  Mobile  Robots  for  Mapless  Navigation"},{"location":"papers/undone/Visual-based Autonomous Driving Deployment from a Stochastic andUncertainty-aware Perspective/","text":"Visual-based Autonomous Driving Deployment from a Stochastic andUncertainty-aware Perspective","title":"Visual-based Autonomous Driving Deployment from a Stochastic andUncertainty-aware Perspective"},{"location":"papers/undone/Visual-based Autonomous Driving Deployment from a Stochastic andUncertainty-aware Perspective/#visual-based-autonomous-driving-deployment-from-a-stochastic-anduncertainty-aware-perspective","text":"","title":"Visual-based Autonomous Driving Deployment from a Stochastic andUncertainty-aware Perspective"},{"location":"papers/undone/aaaaa/","text":"\u6536\u96c6\u4e86\u672a\u5b8c\u6210\u7684\u624b\u7a3f\uff0c\u4f46\u662f\u5f88\u591a\u6807\u9898\u5bf9\u5e94\u7684\u8bba\u6587\u90fd\u503c\u5f97\u4e00\u770b","title":"Aaaaa"}]}